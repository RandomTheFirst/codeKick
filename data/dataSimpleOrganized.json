[[{"term": "def", "name": "find_simple_cycles", "data": "def find_simple_cycles(dg):\n\t\"\"\" Find all simple cycles given a networkx graph.\n\tArgs:\n\t\tdg (obj): a networkx directed graph\n\tReturns:\n\t\tsimple_cycles (list of lists): a list of simple cycles ordered by number of segments.\n\t\"\"\"\n\tsimple_cycles = [c for c in nx.simple_cycles(dg) if len(c) > 2]\n\t#simple_cycles.sort(key=lambda cycle: len(cycle), reverse=True)\t # sort by number of segments\n\treturn simple_cycles\n\n", "description": " Find all simple cycles given a networkx graph.\n\tArgs:\n\t\tdg (obj): a networkx directed graph\n\tReturns:\n\t\tsimple_cycles (list of lists): a list of simple cycles ordered by number of segments.\n\t", "category": "simple", "imports": ["import networkx as nx", "import double_minute"]}, {"term": "def", "name": "simple_cycle_to_double_minute", "data": "def simple_cycle_to_double_minute(graph, simple_cycle):\n\t\"\"\" Convert a simple cycle to a DoubleMintue.\n\tArgs:\n\t\tgraph (obj): a networkx directed graph that contains the simple cycle\n\t\tsc (list): a simple cycle\n\tReturns:\n\t\tdouble_minute (obj): a DoubleMintue\n\t\"\"\"\n\tdm = double_minute.DoubleMinute()\n\tif simple_cycle[0][:-1] == simple_cycle[1][:-1]:\t# first two nodes form a segment edge\n\t\tdm.length += graph[simple_cycle[0][:-1] + 'L'][simple_cycle[1][:-1] + 'R']['Length']\n\t\tfirst_node = simple_cycle.pop(0)\n\t\tsimple_cycle.append(first_node)\n\telse:\n\t\tdm.length += graph[simple_cycle[0][:-1] + 'L'][simple_cycle[-1][:-1] + 'R']['Length']\n\n\tfor index, node in enumerate(simple_cycle[:-1]):\n\t\tif node[:-1] == simple_cycle[index + 1][:-1]:   # segment\n\t\t\tdm.length += graph[node[:-1] + 'L'][node[:-1] + 'R']['Length']\n\t\telse:\t\t\t\t\t\t\t\t\t\t   # non-segment edge\n\t\t\tord_num1 = node[:-1]\n\t\t\tend1 = node[-1]\n\t\t\tord_num2 = simple_cycle[index + 1][:-1]\n\t\t\tend2 = simple_cycle[index + 1][-1]\n\t\t\tedge_type = graph[node][simple_cycle[index+1]]['type'][0].lower()\n\t\t\tdirected_edge = double_minute.DirectedEdge(ord_num1, end1, ord_num2, end2, edge_type)\n\t\t\tdm.ordered_edges.append(directed_edge)\n\treturn dm\n\n", "description": " Convert a simple cycle to a DoubleMintue.\n\tArgs:\n\t\tgraph (obj): a networkx directed graph that contains the simple cycle\n\t\tsc (list): a simple cycle\n\tReturns:\n\t\tdouble_minute (obj): a DoubleMintue\n\t", "category": "simple", "imports": ["import networkx as nx", "import double_minute"]}, {"term": "def", "name": "simple_cycles_to_double_minutes", "data": "def simple_cycles_to_double_minutes(graph, simple_cycles):\n\t\"\"\" Convert simple cycles to double_minutes, then sort by length.\n\tArgs:\n\t\tgraph (obj): a networkx directed graph that contains the simple cycle\n\t\tsimple_cycles (list of lists): a list of simple cycles.\n\tReturns:\n\t\tdouble_minutes (list): a list of DoubleMinutes.\n\t\"\"\"\n\tdouble_minutes = []\n\tfor sc in simple_cycles:\n\t\tdouble_minutes.append(simple_cycle_to_double_minute(graph, sc))\n\tsorted_double_minutes = sorted(double_minutes, key=lambda dm: dm.length, reverse=True)\n\treturn sorted_double_minutes\n\n", "description": " Convert simple cycles to double_minutes, then sort by length.\n\tArgs:\n\t\tgraph (obj): a networkx directed graph that contains the simple cycle\n\t\tsimple_cycles (list of lists): a list of simple cycles.\n\tReturns:\n\t\tdouble_minutes (list): a list of DoubleMinutes.\n\t", "category": "simple", "imports": ["import networkx as nx", "import double_minute"]}, {"term": "def", "name": "simple_cycles_to_string", "data": "def simple_cycles_to_string(simple_cycles):\n\t\"\"\" Convert simple cycles to a string.\n\tArgs:\n\t\tsimple_cycles (list of lists): a list of simple cycles.\n\tReturns:\n\t\tNone\n\t\"\"\"\n\tto_string = ''\n\tto_string += 'Number of simple cycles: {}'.format(str(len(simple_cycles)))\n\tfor c in simple_cycles:\n\t\tto_string += c\n\tto_string += '\\n'\n\treturn to_string\n\n", "description": " Convert simple cycles to a string.\n\tArgs:\n\t\tsimple_cycles (list of lists): a list of simple cycles.\n\tReturns:\n\t\tNone\n\t", "category": "simple", "imports": ["import networkx as nx", "import double_minute"]}, {"term": "def", "name": "simple_cycle_to_string", "data": "def simple_cycle_to_string(graph, sc):\n\t\"\"\" Convert a simple cycle to a string.\n\tArgs:\n\t\tgraph (obj): a networkx directed graph\n\t\tsc (list): a simple cycle\n\tReturns:\n\t\tto_string (str): string representation of the simple cycle\n\t\"\"\"\n\tto_string = ''\n\ttotal_length = 0\n\tif sc[0][:-1] == sc[1][:-1]:\t\t\t# First two nodes form a segment edge\n\t\ttotal_length += graph[sc[0][:-1] + 'L'][sc[1][:-1] + 'R']['Length']\n\t\tfirst_node = sc.pop(0)\n\t\tsc.append(first_node)\n\telse:\n\t\ttotal_length += graph[sc[0][:-1] + 'L'][sc[-1][:-1] + 'R']['Length']\n\tin_segment = False\n\tfor index, node in enumerate(sc[:-1]):\n\t\tif in_segment:\n\t\t\tto_string += str(node[-1])\n\t\telse:\n\t\t\tto_string += str(node)\n\t\tif node[:-1] == sc[index+1][:-1]:   # segment edge\n\t\t\tin_segment = True\t\t\t   # next node is in segment\n\t\t\ttotal_length += graph[node[:-1] + 'L'][node[:-1] + 'R']['Length']\n\t\telse:\n\t\t\tto_string += ' -'\t\t\t   # non-segment edge\n\t\t\tto_string += str(graph[node][sc[index+1]]['type'][0].lower())\n\t\t\tto_string += '-> '\n\t\t\tin_segment = False\t\t\t  # next node is not in segment\n\tif sc[-1][:-1] == sc[-2][:-1]:\n\t\tto_string += str(sc[-1][-1])\n\telse:\n\t\tto_string += str(sc[-1])\n\tto_string += str('\\nLength: ' + str(total_length) + '\\n')\n\treturn to_string\n", "description": " Convert a simple cycle to a string.\n\tArgs:\n\t\tgraph (obj): a networkx directed graph\n\t\tsc (list): a simple cycle\n\tReturns:\n\t\tto_string (str): string representation of the simple cycle\n\t", "category": "simple", "imports": ["import networkx as nx", "import double_minute"]}], [{"term": "def", "name": "Create_simplified_variables", "data": "def Create_simplified_variables(df):\n\tdf[\"construction_year_class_simple\"] = df[\"construction_year_class\"]\n\tdf.loc[df[\"construction_year_class_simple\"].isin(['[1919, 1945]','[1000, 1918]']),\"construction_year_class_simple\"]='avant 1945'\n\tdf.loc[df[\"construction_year_class_simple\"].isin(['[1946, 1970]','[1991, 2005]','[1971, 1990]']), 'construction_year_class_simple']='[1946, 1990]'\n\tdf.loc[df[\"construction_year_class_simple\"].isin(['[2006, 2012]','[2013, 2100]']),\"construction_year_class_simple\"]='apr\u00e8s 2006'\n\n\tdf[\"living_area_class_simple\"] = df[\"living_area_class\"]\n\tdf.loc[df[\"living_area_class_simple\"].isin(['De 40 \u00e0 60 m\u00b2', 'De 30 \u00e0 40 m\u00b2', 'Moins de 30 m\u00b2']),\"living_area_class_simple\"]='moins de 60m2'\n\tdf.loc[df[\"living_area_class_simple\"].isin(['De 60 \u00e0 80 m\u00b2','De 80 \u00e0 100 m\u00b2']),\"living_area_class_simple\"]='De 60 \u00e0 100 m\u00b2'\n\tdf.loc[df[\"living_area_class_simple\"].isin(['De 100 \u00e0 120 m\u00b2', '120 m\u00b2 ou plus']),\"living_area_class_simple\"]='100 m\u00b2 ou plus'\n\n\tdf[\"occupancy_status_simple\"] = df[\"occupancy_status\"]\n\tdf.loc[df[\"occupancy_status_simple\"].isin(['owner','free accomodation']),\"occupancy_status_simple\"]='Propri\u00e9taire'\n\tdf.loc[df[\"occupancy_status_simple\"].isin(['renter', 'low rent housing']),\"occupancy_status_simple\"]='Locataire'\n\n\n\tdf[\"living_area_class_simple\"] = df[\"living_area_class\"]\n\tdf.loc[df[\"living_area_class_simple\"].isin(['De 40 \u00e0 60 m\u00b2', 'De 30 \u00e0 40 m\u00b2', 'Moins de 30 m\u00b2']),\"living_area_class_simple\"]='moins de 60m2'\n\tdf.loc[df[\"living_area_class_simple\"].isin(['De 60 \u00e0 80 m\u00b2','De 80 \u00e0 100 m\u00b2']),\"living_area_class_simple\"]='De 60 \u00e0 100 m\u00b2'\n\tdf.loc[df[\"living_area_class_simple\"].isin(['De 100 \u00e0 120 m\u00b2', '120 m\u00b2 ou plus']),\"living_area_class_simple\"]='100 m\u00b2 ou plus'\n\n\tdf[\"heating_system_simple\"] = df[\"heating_system\"]\n\tdf.loc[df[\"heating_system_simple\"].isin(['Autres','Chauffage urbain']),\"heating_system_simple\"]='Autres et Chauffage urbain'\n\tdf.loc[df[\"heating_system_simple\"].isin(['Chaudi\u00e8re fioul','Chaudi\u00e8re - autres']),\"heating_system_simple\"]='Chaudi\u00e8re fioul-autre'\n\n\treturn df\n", "description": null, "category": "simple", "imports": ["import pandas as pd"]}], [{"term": "def", "name": "fglGetDoublev", "data": "\tdef glGetDoublev( pname ):\n\t\t\"Natural writing of glGetDoublev using standard ctypes\"\n\t\toutput = c_double*sizes.get( pname )\n\t\tresult = output()\n\t\tresult = platform.OpenGL.glGetDoublev( pname, byref(result) )\n", "description": null, "category": "simple", "imports": ["from OpenGL import platform, arrays, error, wrapper, converters", "from OpenGL.raw import GL as simple", "import ctypes"]}, {"term": "def", "name": "addGLGetConstant", "data": "def addGLGetConstant( constant, arraySize ):\n\t\"\"\"Add a glGet* constant to return an output array of correct size\"\"\"\n", "description": "Add a glGet* constant to return an output array of correct size", "category": "simple", "imports": ["from OpenGL import platform, arrays, error, wrapper, converters", "from OpenGL.raw import GL as simple", "import ctypes"]}, {"term": "def", "name": "GL_GET_PIXEL_MAP_SIZE", "data": "def GL_GET_PIXEL_MAP_SIZE( pname ):\n\t\"\"\"Given a pname, lookup the size using a glGet query...\"\"\"\n\tconstant = PIXEL_MAP_SIZE_CONSTANT_MAP[ pname ]\n", "description": "Given a pname, lookup the size using a glGet query...", "category": "simple", "imports": ["from OpenGL import platform, arrays, error, wrapper, converters", "from OpenGL.raw import GL as simple", "import ctypes"]}], [{"term": "class", "name": "classSimpleTestService:", "data": "class SimpleTestService:\n\t...\n\n", "description": null, "category": "simple", "imports": ["import pytest", "from oop_di import ContainerDefinition, Extension", "from oop_di.exception import CircularImportException, DefinitionNotFound", "\tdef test_it_should_detect_circular_import_problem(self):"]}, {"term": "class", "name": "DimpleTestService", "data": "class DimpleTestService(SimpleTestService):\n\t...\n\n", "description": null, "category": "simple", "imports": ["import pytest", "from oop_di import ContainerDefinition, Extension", "from oop_di.exception import CircularImportException, DefinitionNotFound", "\tdef test_it_should_detect_circular_import_problem(self):"]}, {"term": "class", "name": "classDependentService:", "data": "class DependentService:\n\tdef __init__(self, simple: SimpleTestService):\n\t\tself.simple = simple\n\n", "description": null, "category": "simple", "imports": ["import pytest", "from oop_di import ContainerDefinition, Extension", "from oop_di.exception import CircularImportException, DefinitionNotFound", "\tdef test_it_should_detect_circular_import_problem(self):"]}, {"term": "class", "name": "classCircularImportProblem1:", "data": "class CircularImportProblem1:\n\tdef __init__(self, mention_it_self: \"CircularImportProblem1\"):\n\t\tself.mention_it_self = mention_it_self\n\n", "description": null, "category": "simple", "imports": ["import pytest", "from oop_di import ContainerDefinition, Extension", "from oop_di.exception import CircularImportException, DefinitionNotFound", "\tdef test_it_should_detect_circular_import_problem(self):"]}, {"term": "def", "name": "simple_factory", "data": "def simple_factory(simple: SimpleTestService):\n\treturn isinstance(simple, SimpleTestService)\n\n", "description": null, "category": "simple", "imports": ["import pytest", "from oop_di import ContainerDefinition, Extension", "from oop_di.exception import CircularImportException, DefinitionNotFound", "\tdef test_it_should_detect_circular_import_problem(self):"]}, {"term": "def", "name": "simple_factory_for_tagged", "data": "def simple_factory_for_tagged(tagged):\n\treturn len(tagged)\n\n", "description": null, "category": "simple", "imports": ["import pytest", "from oop_di import ContainerDefinition, Extension", "from oop_di.exception import CircularImportException, DefinitionNotFound", "\tdef test_it_should_detect_circular_import_problem(self):"]}, {"term": "class", "name": "classTestContainerDefinition:", "data": "class TestContainerDefinition:\n\tdef setup_method(self):\n\t\tself.sut = ContainerDefinition()\n\n\tdef test_it_should_compile_simple_service(self):\n\t\tself.sut.add_service(SimpleTestService)\n\t\tcontainer = self.sut.compile()\n\t\tservice = container.get(SimpleTestService)\n\t\tassert isinstance(service, SimpleTestService)\n\n\tdef test_it_should_compile_named_service(self):\n\t\tself.sut.add_named_service(\"xxx\", SimpleTestService)\n\t\tcontainer = self.sut.compile()\n\t\tservice = container.get(\"xxx\")\n\t\tassert isinstance(service, SimpleTestService)\n\n\tdef test_it_should_compile_dependent_service(self):\n\t\tself.sut.add_service(SimpleTestService)\n\t\tself.sut.add_service(DependentService)\n\t\tcontainer = self.sut.compile()\n\t\tservice = container.get(DependentService)\n\t\tassert isinstance(service, DependentService)\n\n\tdef test_it_should_detect_circular_import_problem(self):\n\t\tself.sut.add_named_service(\"CircularImportProblem1\", CircularImportProblem1)\n\t\twith pytest.raises(CircularImportException):\n\t\t\tself.sut.compile()\n\n\tdef test_it_should_notify_if_dependency_not_registered(self):\n\t\tself.sut.add_service(DependentService)\n\t\twith pytest.raises(DefinitionNotFound):\n\t\t\tself.sut.compile()\n\n\tdef test_it_should_compile_factory(self):\n\t\tself.sut.add_service(SimpleTestService)\n\t\tself.sut.add_factory(\"test\", simple_factory)\n\t\tcontainer = self.sut.compile()\n\t\tassert container.get(\"test\")\n\n\tdef test_it_should_compile_param(self):\n\t\tself.sut.add_param(\"test\", \"y\")\n\t\tcontainer = self.sut.compile()\n\t\tassert \"y\" == container.get(\"test\")\n\n\tdef test_it_should_inject_by_name_if_by_type_fails(self):\n\t\tself.sut.add_service(DependentService)\n\t\tself.sut.add_named_service(\"simple\", SimpleTestService)\n\t\tcontainer = self.sut.compile()\n\t\tassert isinstance(container.get(DependentService), DependentService)\n\n\tdef test_it_should_inject_binding_by_name(self):\n\t\tself.sut.add_service(DependentService, simple=\"dimple\")\n\t\tself.sut.add_service(SimpleTestService)\n\t\tself.sut.add_named_service(\"dimple\", DimpleTestService)\n\t\tcontainer = self.sut.compile()\n\t\tassert isinstance(container.get(DependentService).simple, DimpleTestService)\n\n\tdef test_it_should_compile_aliases(self):\n\t\tself.sut.add_service(DependentService, simple=\"dimple\")\n\t\tself.sut.add_service(SimpleTestService)\n\t\tself.sut.add_service(DimpleTestService)\n\t\tself.sut.add_alias(\"dimple\", DimpleTestService)\n\t\tcontainer = self.sut.compile()\n\t\tassert isinstance(container.get(DependentService).simple, DimpleTestService)\n\n\tdef test_it_should_pass_singleton_flag(self):\n\t\tself.sut.add_service(SimpleTestService)\n\t\tself.sut.add_named_service(\"x\", SimpleTestService, is_singleton=False)\n\t\tcontainer = self.sut.compile()\n\t\tassert container.get(SimpleTestService) == container.get(SimpleTestService)\n\t\tassert container.get(\"x\") != container.get(\"x\")\n\t\tassert isinstance(container.get(\"x\"), SimpleTestService)\n\n\tdef test_it_should_inject_tagged_services(self):\n\t\tself.sut.add_named_service(\"x\", SimpleTestService, tags=[\"tag1\", \"tag2\"])\n\t\tself.sut.add_named_service(\"y\", SimpleTestService, tags=[\"tag1\"])\n\t\tself.sut.add_named_service(\"z\", SimpleTestService, tags=[\"tag1\", \"tag2\"])\n\t\tself.sut.add_factory(\"threetags\", simple_factory_for_tagged, tagged=\"#tag1\")\n\t\tself.sut.add_factory(\"twotags\", simple_factory_for_tagged, tagged=\"#tag2\")\n\t\tcontainer = self.sut.compile()\n\t\tassert 3 == container.get(\"threetags\")\n\t\tassert 2 == container.get(\"twotags\")\n\n\tdef test_it_should_combine_extensions(self):\n\t\tclass Ext1(Extension):\n\t\t\tdef define(self):\n\t\t\t\tself.add_service(SimpleTestService, tags=[\"tag1\"])\n\n\t\tclass Ext2(Extension):\n\t\t\tdef define(self):\n\t\t\t\tself.add_service(DependentService, tags=[\"tag1\"])\n\n\t\tself.sut.add_factory(\"twotags\", simple_factory_for_tagged, tagged=\"#tag1\")\n\t\tself.sut.add_extension(Ext1())\n\t\tself.sut.add_extension(Ext2())\n\n\t\tcontainer = self.sut.compile()\n\t\tassert isinstance(container.get(DependentService), DependentService)\n\t\tassert 2 == container.get(\"twotags\")\n", "description": null, "category": "simple", "imports": ["import pytest", "from oop_di import ContainerDefinition, Extension", "from oop_di.exception import CircularImportException, DefinitionNotFound", "\tdef test_it_should_detect_circular_import_problem(self):"]}], [{"term": "def", "name": "trim", "data": "def trim(value, num):\n\treturn value[:num]\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "make_data_div", "data": "def make_data_div(value):\n\t\"\"\"A filter that uses a decorator (@mark_safe).\"\"\"\n\treturn '' % value\n\n", "description": "A filter that uses a decorator (@mark_safe).", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "noop", "data": "def noop(value, param=None):\n\t\"\"\"A noop filter that always return its first argument and does nothing with\n\tits second (optional) one.\n\tUseful for testing out whitespace in filter arguments (see #19882).\"\"\"\n\treturn value\n\n", "description": "A noop filter that always return its first argument and does nothing with\n\tits second (optional) one.\n\tUseful for testing out whitespace in filter arguments (see #19882).", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "context_stack_length", "data": "def context_stack_length(context):\n\treturn len(context.dicts)\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "no_params", "data": "def no_params():\n\t\"\"\"Expected no_params __doc__\"\"\"\n\treturn \"no_params - Expected result\"\n\n", "description": "Expected no_params __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "one_param", "data": "def one_param(arg):\n\t\"\"\"Expected one_param __doc__\"\"\"\n\treturn \"one_param - Expected result: %s\" % arg\n\n", "description": "Expected one_param __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "explicit_no_context", "data": "def explicit_no_context(arg):\n\t\"\"\"Expected explicit_no_context __doc__\"\"\"\n\treturn \"explicit_no_context - Expected result: %s\" % arg\n\n", "description": "Expected explicit_no_context __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "no_params_with_context", "data": "def no_params_with_context(context):\n\t\"\"\"Expected no_params_with_context __doc__\"\"\"\n\treturn \"no_params_with_context - Expected result (context value: %s)\" % context['value']\n\n", "description": "Expected no_params_with_context __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "params_and_context", "data": "def params_and_context(context, arg):\n\t\"\"\"Expected params_and_context __doc__\"\"\"\n\treturn \"params_and_context - Expected result (context value: %s): %s\" % (context['value'], arg)\n\n", "description": "Expected params_and_context __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_two_params", "data": "def simple_two_params(one, two):\n\t\"\"\"Expected simple_two_params __doc__\"\"\"\n\treturn \"simple_two_params - Expected result: %s, %s\" % (one, two)\n\n", "description": "Expected simple_two_params __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_keyword_only_param", "data": "def simple_keyword_only_param(*, kwarg):\n\treturn \"simple_keyword_only_param - Expected result: %s\" % kwarg\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_keyword_only_default", "data": "def simple_keyword_only_default(*, kwarg=42):\n\treturn \"simple_keyword_only_default - Expected result: %s\" % kwarg\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_one_default", "data": "def simple_one_default(one, two='hi'):\n\t\"\"\"Expected simple_one_default __doc__\"\"\"\n\treturn \"simple_one_default - Expected result: %s, %s\" % (one, two)\n\n", "description": "Expected simple_one_default __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_unlimited_args", "data": "def simple_unlimited_args(one, two='hi', *args):\n\t\"\"\"Expected simple_unlimited_args __doc__\"\"\"\n\treturn \"simple_unlimited_args - Expected result: %s\" % (\n\t\t', '.join(str(arg) for arg in [one, two, *args])\n\t)\n\n", "description": "Expected simple_unlimited_args __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_only_unlimited_args", "data": "def simple_only_unlimited_args(*args):\n\t\"\"\"Expected simple_only_unlimited_args __doc__\"\"\"\n\treturn \"simple_only_unlimited_args - Expected result: %s\" % ', '.join(str(arg) for arg in args)\n\n", "description": "Expected simple_only_unlimited_args __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_unlimited_args_kwargs", "data": "def simple_unlimited_args_kwargs(one, two='hi', *args, **kwargs):\n\t\"\"\"Expected simple_unlimited_args_kwargs __doc__\"\"\"\n\t# Sort the dictionary by key to guarantee the order for testing.\n\tsorted_kwarg = sorted(kwargs.items(), key=operator.itemgetter(0))\n\treturn \"simple_unlimited_args_kwargs - Expected result: %s / %s\" % (\n\t\t', '.join(str(arg) for arg in [one, two, *args]),\n\t\t', '.join('%s=%s' % (k, v) for (k, v) in sorted_kwarg)\n\t)\n\n", "description": "Expected simple_unlimited_args_kwargs __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_tag_without_context_parameter", "data": "def simple_tag_without_context_parameter(arg):\n\t\"\"\"Expected simple_tag_without_context_parameter __doc__\"\"\"\n\treturn \"Expected result\"\n\n", "description": "Expected simple_tag_without_context_parameter __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "escape_naive", "data": "def escape_naive(context):\n\t\"\"\"A tag that doesn't even think about escaping issues\"\"\"\n\treturn \"Hello {}!\".format(context['name'])\n\n", "description": "A tag that doesn't even think about escaping issues", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "escape_explicit", "data": "def escape_explicit(context):\n\t\"\"\"A tag that uses escape explicitly\"\"\"\n\treturn escape(\"Hello {}!\".format(context['name']))\n\n", "description": "A tag that uses escape explicitly", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "escape_format_html", "data": "def escape_format_html(context):\n\t\"\"\"A tag that uses format_html\"\"\"\n\treturn format_html(\"Hello {0}!\", context['name'])\n\n", "description": "A tag that uses format_html", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "current_app", "data": "def current_app(context):\n\treturn str(context.current_app)\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "use_l10n", "data": "def use_l10n(context):\n\treturn str(context.use_l10n)\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "minustwo_overridden_name", "data": "def minustwo_overridden_name(value):\n\treturn value - 2\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "counter", "data": "def counter(parser, token):\n\treturn CounterNode()\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "class", "name": "CounterNode", "data": "class CounterNode(template.Node):\n\tdef __init__(self):\n\t\tself.count = 0\n\n\tdef render(self, context):\n\t\tcount = self.count\n\t\tself.count = count + 1\n\t\treturn count\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}], [{"term": "class", "name": "SimpleArray", "data": "class SimpleArray(tuple):\n\n\tdef _op(self, op, other):\n\t\tdef _o2(x, y):\n\t\t\ttry:\n\t\t\t\treturn op(x, y)\n\t\t\texcept ZeroDivisionError:\n\t\t\t\treturn DataError('#DIV/0', traceback.format_exc())\n\t\t\texcept Exception:\n\t\t\t\treturn DataError('#ERR', traceback.format_exc())\n\n\t\tif isinstance(other, tuple):\n\t\t\tif len(other) != len(self):\n\t\t\t\traise TypeError(\"tuples must have same length for %s\" % op)\n\t\t\treturn self.__class__(map(_o2, self, other))\n\t\telse:\n\t\t\treturn self.__class__(_o2(z, other) for z in self)\n\n\tdef _cast(self, other):\n\t\tif isinstance(other, self.__class__):\n\t\t\treturn other\n\t\telif isinstance(other, tuple):\n\t\t\treturn self.__class__(other)\n\t\telse:\n\t\t\t# other is a scalar\n\t\t\treturn self.__class__(itertools.repeat(other, len(self)))\n\n\tdef __add__(self, other):\n\t\treturn self._op(operator.add, other)\n\n\t__radd__ = __add__\n\n\tdef __pos__(self):\n\t\treturn self.__class__(map(operator.pos, self))\n\n\tdef __neg__(self):\n\t\treturn self.__class__(map(operator.neg, self))\n\n\tdef __sub__(self, other):\n\t\treturn self._op(operator.sub, other)\n\n\tdef __rsub__(self, other):\n\t\treturn self._cast(other)._op(operator.sub, self)\n\n\tdef __mul__(self, other):\n\t\treturn self._op(operator.mul, other)\n\n\t__rmul__ = __mul__\n\n\tdef __div__(self, other):\n\t\treturn self._op(operator.div, other)\n\n\tdef __floordiv__(self, other):\n\t\treturn self._op(operator.floordiv, other)\n\n\tdef __truediv__(self, other):\n\t\treturn self._op(operator.truediv, other)\n\n\tdef __rdiv__(self, other):\n\t\treturn self._cast(other)._op(operator.div, self)\n\n\tdef __rfloordiv__(self, other):\n\t\treturn self._cast(other)._op(operator.floordiv, self)\n\n\tdef __rtruediv__(self, other):\n\t\treturn self._cast(other)._op(operator.truediv, self)\n\n\tdef __repr__(self):\n\t\treturn \"%s(%s)\" % (self.__class__.__name__, tuple.__repr__(self))\n\n", "description": null, "category": "simple", "imports": ["import itertools", "import operator", "import traceback", "from .data_error import DataError", "\timport doctest"]}, {"term": "def", "name": "named_simple_array", "data": "def named_simple_array(typename, field_names):\n\t\"\"\" Return a subclass of SimpleArray, with named properties.\n\n\tThis method is to SimpleArray what namedtuple is to tuple.\n\tIt's less sophisticated than namedtuple so some namedtuple\n\tadvanced use cases may not work, but it's good enough for\n\tour needs in mis_builder, ie referring to subkpi values\n\tby name.\n\t\"\"\"\n\tprops = dict(\n\t\t(field_name, property(operator.itemgetter(i)))\n\t\tfor i, field_name in enumerate(field_names)\n\t)\n\treturn type(typename, (SimpleArray, ), props)\n\n", "description": " Return a subclass of SimpleArray, with named properties.\n\n\tThis method is to SimpleArray what namedtuple is to tuple.\n\tIt's less sophisticated than namedtuple so some namedtuple\n\tadvanced use cases may not work, but it's good enough for\n\tour needs in mis_builder, ie referring to subkpi values\n\tby name.\n\t", "category": "simple", "imports": ["import itertools", "import operator", "import traceback", "from .data_error import DataError", "\timport doctest"]}], [{"term": "def", "name": "simple_filter", "data": "def simple_filter(value):\n", "description": null, "category": "simple", "imports": ["import unittest", "from lighty.templates import Template", "from lighty.templates.filter import filter_manager"]}, {"term": "def", "name": "argument_filter", "data": "def argument_filter(value, arg):\n", "description": null, "category": "simple", "imports": ["import unittest", "from lighty.templates import Template", "from lighty.templates.filter import filter_manager"]}, {"term": "def", "name": "multiarg_filter", "data": "def multiarg_filter(value, *args):\n", "description": null, "category": "simple", "imports": ["import unittest", "from lighty.templates import Template", "from lighty.templates.filter import filter_manager"]}, {"term": "class", "name": "TemplateFiltersTestCase", "data": "class TemplateFiltersTestCase(unittest.TestCase):\n\t\"\"\"Test case for block template tag\n\t\"\"\"\n\n\tdef assertResult(self, result, value):\n\t\tassert result == value, 'Error template execution: %s' % ' '.join((\n\t\t\t\t\t\t\t\t\t result, 'except', value))\n\n\tdef testSimpleFilter(self):\n\t\t'''Test simple template filter function applied to variable'''\n\t\tsimple_template = Template(name='simple-filter.html')\n\t\tsimple_template.parse(\"{{ simple_var|simple_filter }}\")\n\t\tresult = simple_template.execute({'simple_var': 'Hello'})\n\t\tself.assertResult(result, 'HELLO')\n\n\tdef testStringConstFilter(self):\n\t\t'''Test simple template filter function applied to string constant'''\n\t\tsimple_template = Template(name=\"consts-filter.html\")\n\t\tsimple_template.parse('{{ \"hello\"|simple_filter }}')\n\t\tresult = simple_template.execute({})\n\t\tself.assertResult(result, 'HELLO')\n\n\tdef testNumericConstFilter(self):\n\t\t'''Test simple template filter function applied to number'''\n\t\tsimple_template = Template(name=\"consts-filter.html\")\n\t\tsimple_template.parse('{{ 1|simple_filter }}')\n\t\tresult = simple_template.execute({})\n\t\tself.assertResult(result, '1')\n\n\tdef testArgFilter(self):\n\t\t'''Test calling template filter with arg value specified'''\n\t\targument_template = Template(name='argument-filter.html')\n\t\targument_template.parse('{{ simple_var|argument_filter:\"world\" }}')\n\t\tresult = argument_template.execute({'simple_var': 'Hello'})\n\t\tself.assertResult(result, 'Hello, world')\n\n\tdef testMultiargFilter(self):\n\t\t'''Test calling filter with multiply args'''\n\t\tmultiarg_template = Template(name='multiarg-filter.html')\n\t\tmultiarg_template.parse(\n\t\t\t\t\t\t\t'{{ simple_var|multiarg_filter:\"John\" \"Peter\" }}')\n\t\tresult = multiarg_template.execute({'simple_var': 'Hello'})\n\t\tself.assertResult(result, 'Hello, John, Peter')\n\n\tdef testMultiFilter(self):\n\t\t'''Test calling sequnce of filters'''\n\t\tmultifilter_template = Template(name='multifilter.html')\n\t\tmultifilter_template.parse(\n\t\t\t\t\t'{{ simple_var|simple_filter|argument_filter:\"world\" }}')\n\t\tresult = multifilter_template.execute({'simple_var': 'Hello'})\n\t\tself.assertResult(result, 'HELLO, world')\n\n\tdef testVaribaleArgFilter(self):\n\t\t'''Test calling filter with variable argument'''\n\t\tvarargfilter_template = Template(name='vararg-filter.html')\n\t\tvarargfilter_template.parse('{{ simple_var|argument_filter:arg }}')\n\t\tresult = varargfilter_template.execute({\n\t\t\t\t'simple_var': 'Hello',\n\t\t\t\t'arg': 'world'\n\t\t})\n\t\tself.assertResult(result, 'Hello, world')\n\n", "description": "Test case for block template tag\n\t", "category": "simple", "imports": ["import unittest", "from lighty.templates import Template", "from lighty.templates.filter import filter_manager"]}, {"term": "def", "name": "test", "data": "def test():\n\tsuite = unittest.TestSuite()\n\tsuite.addTest(TemplateFiltersTestCase('testSimpleFilter'))\n\tsuite.addTest(TemplateFiltersTestCase('testStringConstFilter'))\n\tsuite.addTest(TemplateFiltersTestCase('testNumericConstFilter'))\n\tsuite.addTest(TemplateFiltersTestCase('testArgFilter'))\n\tsuite.addTest(TemplateFiltersTestCase('testMultiargFilter'))\n\tsuite.addTest(TemplateFiltersTestCase('testMultiFilter'))\n\tsuite.addTest(TemplateFiltersTestCase('testVaribaleArgFilter'))\n\treturn suite\n", "description": null, "category": "simple", "imports": ["import unittest", "from lighty.templates import Template", "from lighty.templates.filter import filter_manager"]}], [], [{"term": "def", "name": "simple_graph", "data": "def simple_graph():\n\tg = Graph()\n\tg.vertices = dict()\n\tg.edges = []\n\tg.add_vertex(\"a\")\n\tg.add_vertex(\"b\")\n\tg.add_vertex(\"c\")\n\tg.add_edge(\"a\", \"b\", name=\"s\")\n\tg.add_edge(\"b\", \"c\", name=\"t\")\n\tg.add_edge(\"a\", \"a\", name=\"d\")\n\treturn g\n\n", "description": null, "category": "simple", "imports": ["import pytest", "from ..py_graph_t.Graph import Graph", "from ..py_graph_t.util.ValueBinding import ValueBinding", "from ..py_graph_t.edges.SimpleEdge import SimpleEdge", "from ..py_graph_t.vertex.SimpleVertex import SimpleVertex", "from ..py_graph_t.exceptions.SimpleGraphException import ("]}, {"term": "class", "name": "classTestGraph:", "data": "class TestGraph:\n\tg = Graph()\n\n\tdef test_add_vertex(self, simple_graph):\n\t\tsimple_graph.add_vertex(\"e\")\n\t\tassert simple_graph.vertex_exists(\"e\") is True\n\t\tassert \"e\" in simple_graph.get_all_vertex().keys()\n\n\tdef test_exception_add_vertex_duplicate(self, simple_graph):\n\t\twith pytest.raises(VertexDuplicatedException):\n\t\t\tassert simple_graph.add_vertex(\"a\")\n\n\tdef test_delete_vertex(self, simple_graph):\n\t\tnum_vertex = simple_graph.num_vertex()\n\t\tsimple_graph.add_vertex(\"e\")\n\t\tv = simple_graph.delete_vertex(\"e\")\n\t\tassert v.__str__() == \"V\u00c3\u00a9rtice e\"\n\t\tassert simple_graph.num_vertex() == num_vertex\n\n\tdef test_exception_delete_vertex_not_exists(self, simple_graph):\n\t\twith pytest.raises(VertexNotExistsException):\n\t\t\tassert simple_graph.delete_vertex(\"e\")\n\n\tdef test_delete_vertex_terminal(self, simple_graph):\n\t\tsimple_graph.delete_vertex(\"a\")\n\t\texpected = 1\n\t\tassert simple_graph.num_edges() == expected\n\n\tdef test_show_edge(self, simple_graph):\n\t\tvertex_z = simple_graph.add_vertex(\"z\")\n\t\tvertex_x = simple_graph.add_vertex(\"x\")\n\t\tedge_zx = simple_graph.add_edge(\"z\", \"x\", \"zx\")\n\t\tedge_test = SimpleEdge(\"zx\", vertex_z, vertex_x)\n\t\tassert simple_graph.show_edge(\"z\", \"x\") == edge_test\n\n\tdef test_exception_show_edge_vertex_not_exists(self, simple_graph):\n\t\tvertex_z = simple_graph.add_vertex(\"z\")\n\t\twith pytest.raises(VertexNotExistsException):\n\t\t\tassert simple_graph.show_edge(\"z\", \"x\")\n\n\tdef test_exception_show_edge_not_exists(self, simple_graph):\n\t\tvertex_z = simple_graph.add_vertex(\"z\")\n\t\tvertex_x = simple_graph.add_vertex(\"x\")\n\t\twith pytest.raises(EdgeNotFoundException):\n\t\t\tassert simple_graph.show_edge(\"z\", \"x\")\n\n\tdef test_add_edge(self, simple_graph):\n\t\tvertex_z = simple_graph.add_vertex(\"z\")\n\t\tvertex_x = simple_graph.add_vertex(\"x\")\n\t\tassert simple_graph.add_edge(\"z\", \"x\", \"zx\") == \\\n\t\t\tSimpleEdge(\"zx\", vertex_z, vertex_x)\n\n\tdef test_exception_add_edge_vertex_not_exists(self, simple_graph):\n\t\tvertex_z = simple_graph.add_vertex(\"z\")\n\t\tvertex_x = SimpleVertex(\"x\")\n\t\twith pytest.raises(VertexNotExistsException):\n\t\t\tassert simple_graph.add_edge(\"z\", \"x\", \"zx\") == \\\n\t\t\t\tSimpleEdge(\"zx\", vertex_z, vertex_x)\n\n\tdef test_exception_add_edge_name_exists(self, simple_graph):\n\t\tvertex_z = simple_graph.add_vertex(\"z\")\n\t\tvertex_x = simple_graph.add_vertex(\"x\")\n\t\twith pytest.raises(EdgeNameExistsException):\n\t\t\tassert simple_graph.add_edge(\"z\", \"x\", \"d\") == \\\n\t\t\t\tSimpleEdge(\"zx\", vertex_z, vertex_x)\n\n\tdef test_delete_edge(self, simple_graph):\n\t\tvertex_z = simple_graph.add_vertex(\"z\")\n\t\tvertex_x = simple_graph.add_vertex(\"x\")\n\t\tedge_test = simple_graph.add_edge(\"z\", \"x\", \"zx\")\n\t\tassert simple_graph.delete_edge(\"z\", \"x\") == edge_test\n\n\tdef test_delete_edge(self, simple_graph):\n\t\tvertex_z = simple_graph.add_vertex(\"z\")\n\t\tvertex_x = simple_graph.add_vertex(\"x\")\n\t\tedge_test = simple_graph.add_edge(\"z\", \"x\", \"zx\")\n\t\tassert simple_graph.delete_edge(\"z\", \"x\") == edge_test\n\n\tdef test_exception_delete_edge_not_exists(self, simple_graph):\n\t\tvertex_z = simple_graph.add_vertex(\"z\")\n\t\tvertex_x = simple_graph.add_vertex(\"x\")\n\t\twith pytest.raises(EdgeNotFoundException):\n\t\t\tassert simple_graph.delete_edge(\"z\", \"x\")\n\n\tdef test_is_terminal(self, simple_graph):\n\t\tvertex_z = simple_graph.add_vertex(\"z\")\n\t\tvertex_x = simple_graph.add_vertex(\"x\")\n\t\tedge_test = simple_graph.add_edge(\"z\", \"x\", \"zx\")\n\t\tassert simple_graph.is_terminal(edge_test, \"z\") is True\n\t\tassert simple_graph.is_terminal(edge_test, \"x\") is True\n\t\tassert simple_graph.is_terminal(edge_test, \"a\") is False\n\n\tdef test_num_vertex(self, simple_graph):\n\t\tassert simple_graph.num_vertex() == 3\n\t\tvertex_z = simple_graph.add_vertex(\"z\")\n\t\tvertex_x = simple_graph.add_vertex(\"x\")\n\t\tassert simple_graph.num_vertex() == 5\n\t\tsimple_graph.delete_vertex(\"z\")\n\t\tsimple_graph.delete_vertex(\"x\")\n\t\tassert simple_graph.num_vertex() == 3\n\n\tdef test_vertex_exists(self, simple_graph):\n\t\tvertex_z = simple_graph.add_vertex(\"z\")\n\t\tassert simple_graph.vertex_exists(\"a\") is True\n\t\tassert simple_graph.vertex_exists(\"z\") is True\n\t\tassert simple_graph.vertex_exists(\"x\") is False\n\n\tdef test_edge_exists(self, simple_graph):\n\t\tvertex_z = simple_graph.add_vertex(\"z\")\n\t\tvertex_x = simple_graph.add_vertex(\"x\")\n\t\tedge_test = simple_graph.add_edge(\"z\", \"x\", \"zx\")\n\t\tassert simple_graph.edge_exists(\"z\", \"x\") is True\n\n\tdef test_edge_not_exists(self, simple_graph):\n\t\tvertex_z = simple_graph.add_vertex(\"z\")\n\t\tassert simple_graph.edge_exists(\"z\", \"a\") is False\n\n\tdef test_num_edges(self, simple_graph):\n\t\tassert simple_graph.num_edges() == 3\n\t\tvertex_z = simple_graph.add_vertex(\"z\")\n\t\tvertex_x = simple_graph.add_vertex(\"x\")\n\t\tedge_test = simple_graph.add_edge(\"z\", \"x\", \"zx\")\n\t\tassert simple_graph.num_edges() == 4\n\t\tsimple_graph.delete_edge(\"z\", \"x\")\n\t\tassert simple_graph.num_edges() == 3\n\n\tdef test_vertex_neighbors(self, simple_graph):\n\t\tvertex_a = SimpleVertex(\"a\")\n\t\tvertex_b = SimpleVertex(\"b\")\n\t\texpected = [vertex_b, vertex_a]\n\t\tassert simple_graph.vertex_neighbors(\"a\") == expected\n\n\tdef test_exception_vertex_neighbors_vertex_not_exists(self, simple_graph):\n\t\twith pytest.raises(VertexNotExistsException):\n\t\t\tassert simple_graph.vertex_neighbors(\"z\")\n\n\tdef test_vertex_degree(self, simple_graph):\n\t\tassert simple_graph.vertex_degree(\"a\") == 2\n\n\tdef test_exception_vertex_degree_vertex_not_exists(self, simple_graph):\n\t\twith pytest.raises(VertexNotExistsException):\n\t\t\tassert simple_graph.vertex_degree(\"z\")\n\n\tdef test_is_vertices_adjacents(self, simple_graph):\n\t\tvertex_z = simple_graph.add_vertex(\"z\")\n\t\tvertex_x = simple_graph.add_vertex(\"x\")\n\t\tassert simple_graph.is_vertices_adjacents(\"a\", \"b\") is True\n\t\tassert simple_graph.is_vertices_adjacents(\"z\", \"x\") is False\n\n\tdef test_exception_is_vertices_adjacents_not_exists(self, simple_graph):\n\t\tvertex_x = simple_graph.add_vertex(\"x\")\n\t\twith pytest.raises(VertexNotExistsException):\n\t\t\tassert simple_graph.is_vertices_adjacents(\"z\", \"x\")\n\n\tdef test_get_all_vertex(self, simple_graph):\n\t\tvertex_a = SimpleVertex(\"a\")\n\t\tvertex_b = SimpleVertex(\"b\")\n\t\tvertex_c = SimpleVertex(\"c\")\n\t\texpected = {\"c\": vertex_c, \"b\": vertex_b, \"a\": vertex_a}\n\t\tassert simple_graph.get_all_vertex() == expected\n\n\tdef test_list_graph_vertices(self, simple_graph):\n\t\texpected = [\"a\", \"b\", \"c\"]\n\t\tassert simple_graph.list_graph_vertices() == expected\n\n\tdef test_list_graph_edges(self, simple_graph):\n\t\texpected = [\"s\", \"t\", \"d\"]\n\t\tassert simple_graph.list_graph_edges() == expected\n\n\tdef test_has_cycle(self, simple_graph):\n\t\tsimple_graph.delete_edge(\"a\", \"a\")\n\t\tvertex_z = simple_graph.add_vertex(\"z\")\n\t\tvertex_x = simple_graph.add_vertex(\"x\")\n\t\tsimple_graph.add_edge(\"z\", \"x\", \"zx\")\n\t\tsimple_graph.add_edge(\"z\", \"a\", \"za\")\n\t\tsimple_graph.add_edge(\"a\", \"x\", \"ax\")\n\t\tassert simple_graph.has_cycle() is True\n\n\tdef test_has_cycle_simples(self, simple_graph):\n\t\tassert simple_graph.has_cycle() is True\n\t\tsimple_graph.delete_edge(\"a\", \"a\")\n\t\tassert simple_graph.has_cycle() is False\n\n\tdef test_has_loop(self, simple_graph):\n\t\tassert simple_graph.has_loop() is True\n\t\tsimple_graph.delete_edge(\"a\", \"a\")\n\t\tassert simple_graph.has_cycle() is False\n\n\tdef test_check_regular_graph(self, simple_graph):\n\t\tsimple_graph.delete_edge(\"a\", \"a\")\n\t\tsimple_graph.add_edge(\"c\", \"a\", \"ca\")\n\t\tassert simple_graph.check_regular_graph() is True\n\n\tdef test_incidence_list(self, simple_graph):\n\t\tvb1 = ValueBinding(\"a\", \"s\", 1)\n\t\tvb2 = ValueBinding(\"a\", \"t\", 0)\n\t\tvb3 = ValueBinding(\"a\", \"d\", 2)\n\n\t\tvb4 = ValueBinding(\"b\", \"s\", 1)\n\t\tvb5 = ValueBinding(\"b\", \"t\", 1)\n\t\tvb6 = ValueBinding(\"b\", \"d\", 0)\n\n\t\tvb7 = ValueBinding(\"c\", \"s\", 0)\n\t\tvb8 = ValueBinding(\"c\", \"t\", 1)\n\t\tvb9 = ValueBinding(\"c\", \"d\", 0)\n\t\texpected = [vb1, vb2, vb3, vb4, vb5, vb6, vb7, vb8, vb9]\n\t\tassert simple_graph.incidence_list() == expected\n\n\tdef test_incidence_list_should_return_a_list(self, simple_graph):\n\t\tlist_ = simple_graph.incidence_list()\n\t\texpected = True\n\t\tassert isinstance(list_, list) == expected\n\n\tdef test_incidence_list_length(self, simple_graph):\n\t\tvertices_len = len(simple_graph.vertices)\n\t\tedges_len = len(simple_graph.edges)\n\t\texpected = vertices_len * edges_len\n\t\tresult = len(simple_graph.incidence_list())\n\t\tassert expected == result\n\n\tdef test_adjacency_matrix_should_return_dict(self, simple_graph):\n\t\tm = simple_graph.adjacency_matrix()\n\t\texpected = True\n\t\tassert isinstance(m, dict) == expected\n\n\tdef test_adjacency_matrix_get_correct_vertexes(self, simple_graph):\n\t\tm = simple_graph.adjacency_matrix()\n\t\tvertexes = m.keys()\n\t\tassert list(vertexes) == [\"a\", \"b\", \"c\"]\n\n\tdef test_adjacency_matrix_get_correct_edges(self, simple_graph):\n\t\tm = simple_graph.adjacency_matrix()\n\t\tedges = list(m.values())\n\t\tedges_a = edges[0]\n\t\tedges_b = edges[1]\n\t\tedges_c = edges[2]\n\n\t\tassert edges_a[\"a\"] == int(simple_graph.edge_exists(\"a\", \"a\"))*2\n\t\tassert edges_b[\"b\"] == int(simple_graph.edge_exists(\"b\", \"b\"))*2\n\t\tassert edges_c[\"c\"] == int(simple_graph.edge_exists(\"c\", \"c\"))*2\n\t\tassert edges_a[\"b\"] == edges_b[\"a\"]\n\t\tassert edges_a[\"c\"] == edges_c[\"a\"]\n\t\tassert edges_b[\"c\"] == edges_c[\"b\"]\n", "description": null, "category": "simple", "imports": ["import pytest", "from ..py_graph_t.Graph import Graph", "from ..py_graph_t.util.ValueBinding import ValueBinding", "from ..py_graph_t.edges.SimpleEdge import SimpleEdge", "from ..py_graph_t.vertex.SimpleVertex import SimpleVertex", "from ..py_graph_t.exceptions.SimpleGraphException import ("]}], [{"term": "class", "name": "SimpleGenerator", "data": "class SimpleGenerator(Generator):\n\tdef __init__(self, annotations_group, num_classes=0, image=None):\n\t\tself.annotations_group = annotations_group\n\t\tself.num_classes_\t  = num_classes\n\t\tself.image\t\t\t = image\n\t\tsuper(SimpleGenerator, self).__init__(group_method='none', shuffle_groups=False)\n\n\tdef num_classes(self):\n\t\treturn self.num_classes_\n\n\tdef load_image(self, image_index):\n\t\treturn self.image\n\n\tdef size(self):\n\t\treturn len(self.annotations_group)\n\n\tdef load_annotations(self, image_index):\n\t\tresult = self.annotations_group[image_index]\n\t\treturn result\n\n", "description": null, "category": "simple", "imports": ["import keras.backend", "from keras_retinanet.preprocessing.generator import Generator", "import numpy as np", "import pytest"]}, {"term": "class", "name": "TestLoadAnnotationsGroup", "data": "class TestLoadAnnotationsGroup(object):\n\tdef test_simple(self):\n\t\tinput_annotations_group = [\n\t\t\tnp.array([\n\t\t\t\t[  0,   0,  10,  10],\n\t\t\t\t[150, 150, 350, 350]\n\t\t\t]),\n\t\t]\n\t\texpected_annotations_group = input_annotations_group\n\n\t\tsimple_generator = SimpleGenerator(input_annotations_group)\n\t\tannotations_group = simple_generator.load_annotations_group(simple_generator.groups[0])\n\n\t\tnp.testing.assert_equal(expected_annotations_group, annotations_group)\n\n\tdef test_multiple(self):\n\t\tinput_annotations_group = [\n\t\t\tnp.array([\n\t\t\t\t[  0,   0,  10,  10],\n\t\t\t\t[150, 150, 350, 350]\n\t\t\t]),\n\t\t\tnp.array([\n\t\t\t\t[0, 0, 1, 1]\n\t\t\t])\n\t\t]\n\t\texpected_annotations_group = input_annotations_group\n\n\t\tsimple_generator = SimpleGenerator(input_annotations_group)\n\t\tannotations_group_0 = simple_generator.load_annotations_group(simple_generator.groups[0])\n\t\tannotations_group_1 = simple_generator.load_annotations_group(simple_generator.groups[1])\n\n\t\tnp.testing.assert_equal([expected_annotations_group[0]], annotations_group_0)\n\t\tnp.testing.assert_equal([expected_annotations_group[1]], annotations_group_1)\n\n", "description": null, "category": "simple", "imports": ["import keras.backend", "from keras_retinanet.preprocessing.generator import Generator", "import numpy as np", "import pytest"]}, {"term": "class", "name": "TestFilterAnnotations", "data": "class TestFilterAnnotations(object):\n\tdef test_simple_filter(self):\n\t\tinput_annotations_group = [\n\t\t\tnp.array([\n\t\t\t\t[  0,   0, 10, 10],\n\t\t\t\t[150, 150, 50, 50]\n\t\t\t]),\n\t\t]\n\n\t\tinput_image = np.zeros((500, 500, 3))\n\n\t\texpected_annotations_group = [\n\t\t\tnp.array([\n\t\t\t\t[0, 0, 10, 10],\n\t\t\t]),\n\t\t]\n\n\t\tsimple_generator = SimpleGenerator(input_annotations_group)\n\t\tannotations_group = simple_generator.load_annotations_group(simple_generator.groups[0])\n\t\t# expect a UserWarning\n\t\twith pytest.warns(UserWarning):\n\t\t\timage_group, annotations_group = simple_generator.filter_annotations([input_image], annotations_group, simple_generator.groups[0])\n\n\t\tnp.testing.assert_equal(expected_annotations_group, annotations_group)\n\n\tdef test_multiple_filter(self):\n\t\tinput_annotations_group = [\n\t\t\tnp.array([\n\t\t\t\t[  0,   0,  10,  10],\n\t\t\t\t[150, 150,  50,  50],\n\t\t\t\t[150, 150, 350, 350],\n\t\t\t\t[350, 350, 150, 150],\n\t\t\t\t[  1,   1,   2,   2],\n\t\t\t\t[  2,   2,   1,   1]\n\t\t\t]),\n\t\t\tnp.array([\n\t\t\t\t[0, 0, -1, -1]\n\t\t\t]),\n\t\t\tnp.array([\n\t\t\t\t[-10, -10,\t0,\t0],\n\t\t\t\t[-10, -10, -100, -100],\n\t\t\t\t[ 10,  10,  100,  100]\n\t\t\t]),\n\t\t\tnp.array([\n\t\t\t\t[ 10,  10,  100,  100],\n\t\t\t\t[ 10,  10,  600,  600]\n\t\t\t]),\n\t\t]\n\n\t\tinput_image = np.zeros((500, 500, 3))\n\n\t\texpected_annotations_group = [\n\t\t\tnp.array([\n\t\t\t\t[  0,   0,  10,  10],\n\t\t\t\t[150, 150, 350, 350],\n\t\t\t\t[  1,   1,   2,   2]\n\t\t\t]),\n\t\t\tnp.zeros((0, 4)),\n\t\t\tnp.array([\n\t\t\t\t[10, 10, 100, 100]\n\t\t\t]),\n\t\t\tnp.array([\n\t\t\t\t[ 10,  10,  100,  100]\n\t\t\t]),\n\t\t]\n\n\t\tsimple_generator = SimpleGenerator(input_annotations_group)\n\t\t# expect a UserWarning\n\t\tannotations_group_0 = simple_generator.load_annotations_group(simple_generator.groups[0])\n\t\twith pytest.warns(UserWarning):\n\t\t\timage_group, annotations_group_0 = simple_generator.filter_annotations([input_image], annotations_group_0, simple_generator.groups[0])\n\n\t\tannotations_group_1 = simple_generator.load_annotations_group(simple_generator.groups[1])\n\t\twith pytest.warns(UserWarning):\n\t\t\timage_group, annotations_group_1 = simple_generator.filter_annotations([input_image], annotations_group_1, simple_generator.groups[1])\n\n\t\tannotations_group_2 = simple_generator.load_annotations_group(simple_generator.groups[2])\n\t\twith pytest.warns(UserWarning):\n\t\t\timage_group, annotations_group_2 = simple_generator.filter_annotations([input_image], annotations_group_2, simple_generator.groups[2])\n\n\t\tnp.testing.assert_equal([expected_annotations_group[0]], annotations_group_0)\n\t\tnp.testing.assert_equal([expected_annotations_group[1]], annotations_group_1)\n\t\tnp.testing.assert_equal([expected_annotations_group[2]], annotations_group_2)\n\n\tdef test_complete(self):\n\t\tinput_annotations_group = [\n\t\t\tnp.array([\n\t\t\t\t[  0,   0, 50, 50, 0],  # one object of class 0\n\t\t\t\t[150, 150, 50, 50, 1],  # one object of class 1 with an invalid box\n\t\t\t], dtype=keras.backend.floatx()),\n\t\t]\n\n\t\tinput_image = np.zeros((500, 500, 3), dtype=np.uint8)\n\n\t\texpected_annotations_group = [\n\t\t\tnp.array([\n\t\t\t\t[0, 0, 10, 10],\n\t\t\t]),\n\t\t]\n\n\t\tsimple_generator = SimpleGenerator(input_annotations_group, image=input_image, num_classes=2)\n\t\t# expect a UserWarning\n\t\twith pytest.warns(UserWarning):\n\t\t\t_, [_, labels_batch] = simple_generator.next()\n\n\t\t# test that only object with class 0 is present in labels_batch\n\t\tlabels = np.unique(np.argmax(labels_batch == 1, axis=2))\n\t\tassert(len(labels) == 1 and labels[0] == 0), 'Expected only class 0 to be present, but got classes {}'.format(labels)\n", "description": null, "category": "simple", "imports": ["import keras.backend", "from keras_retinanet.preprocessing.generator import Generator", "import numpy as np", "import pytest"]}], [{"term": "def", "name": "fglGetDoublev", "data": "\tdef glGetDoublev( pname ):\n\t\t\"Natural writing of glGetDoublev using standard ctypes\"\n\t\toutput = c_double*sizes.get( pname )\n\t\tresult = output()\n\t\tresult = platform.OpenGL.glGetDoublev( pname, byref(result) )\n", "description": null, "category": "simple", "imports": ["from OpenGL import platform, arrays, error, wrapper, converters", "from OpenGL.raw import GL as simple", "import ctypes"]}, {"term": "def", "name": "addGLGetConstant", "data": "def addGLGetConstant( constant, arraySize ):\n\t\"\"\"Add a glGet* constant to return an output array of correct size\"\"\"\n", "description": "Add a glGet* constant to return an output array of correct size", "category": "simple", "imports": ["from OpenGL import platform, arrays, error, wrapper, converters", "from OpenGL.raw import GL as simple", "import ctypes"]}, {"term": "def", "name": "GL_GET_PIXEL_MAP_SIZE", "data": "def GL_GET_PIXEL_MAP_SIZE( pname ):\n\t\"\"\"Given a pname, lookup the size using a glGet query...\"\"\"\n\tconstant = PIXEL_MAP_SIZE_CONSTANT_MAP[ pname ]\n", "description": "Given a pname, lookup the size using a glGet query...", "category": "simple", "imports": ["from OpenGL import platform, arrays, error, wrapper, converters", "from OpenGL.raw import GL as simple", "import ctypes"]}], [{"term": "def", "name": "SimplePoint", "data": "def SimplePoint():\n\tnewpoints = []\n\n\tnewpoints.append([0.0, 0.0, 0.0])\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "SimpleLine", "data": "def SimpleLine(c1=[0.0, 0.0, 0.0], c2=[2.0, 2.0, 2.0]):\n\tnewpoints = []\n\n\tc3 = Vector(c2) - Vector(c1)\n\tnewpoints.append([0.0, 0.0, 0.0])\n\tnewpoints.append([c3[0], c3[1], c3[2]])\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "SimpleAngle", "data": "def SimpleAngle(length=1.0, angle=45.0):\n\tnewpoints = []\n\n\tangle = radians(angle)\n\tnewpoints.append([length, 0.0, 0.0])\n\tnewpoints.append([0.0, 0.0, 0.0])\n\tnewpoints.append([length * cos(angle), length * sin(angle), 0.0])\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "SimpleDistance", "data": "def SimpleDistance(length=1.0, center=True):\n\tnewpoints = []\n\n\tif center:\n\t\tnewpoints.append([-length / 2, 0.0, 0.0])\n\t\tnewpoints.append([length / 2, 0.0, 0.0])\n\telse:\n\t\tnewpoints.append([0.0, 0.0, 0.0])\n\t\tnewpoints.append([length, 0.0, 0.0])\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "SimpleCircle", "data": "def SimpleCircle(sides=4, radius=1.0):\n\tnewpoints = []\n\n\tangle = radians(360) / sides\n\tnewpoints.append([radius, 0, 0])\n\tj = 1\n\twhile j < sides:\n\t\tt = angle * j\n\t\tx = cos(t) * radius\n\t\ty = sin(t) * radius\n\t\tnewpoints.append([x, y, 0])\n\t\tj += 1\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "SimpleEllipse", "data": "def SimpleEllipse(a=2.0, b=1.0):\n\tnewpoints = []\n\n\tnewpoints.append([a, 0.0, 0.0])\n\tnewpoints.append([0.0, b, 0.0])\n\tnewpoints.append([-a, 0.0, 0.0])\n\tnewpoints.append([0.0, -b, 0.0])\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "SimpleArc", "data": "def SimpleArc(sides=0, radius=1.0, startangle=0.0, endangle=45.0):\n\tnewpoints = []\n\n\tstartangle = radians(startangle)\n\tendangle = radians(endangle)\n\tsides += 1\n\n\tangle = (endangle - startangle) / sides\n\tx = cos(startangle) * radius\n\ty = sin(startangle) * radius\n\tnewpoints.append([x, y, 0])\n\tj = 1\n\twhile j < sides:\n\t\tt = angle * j\n\t\tx = cos(t + startangle) * radius\n\t\ty = sin(t + startangle) * radius\n\t\tnewpoints.append([x, y, 0])\n\t\tj += 1\n\tx = cos(endangle) * radius\n\ty = sin(endangle) * radius\n\tnewpoints.append([x, y, 0])\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "SimpleSector", "data": "def SimpleSector(sides=0, radius=1.0, startangle=0.0, endangle=45.0):\n\tnewpoints = []\n\n\tstartangle = radians(startangle)\n\tendangle = radians(endangle)\n\tsides += 1\n\n\tnewpoints.append([0, 0, 0])\n\tangle = (endangle - startangle) / sides\n\tx = cos(startangle) * radius\n\ty = sin(startangle) * radius\n\tnewpoints.append([x, y, 0])\n\tj = 1\n\twhile j < sides:\n\t\tt = angle * j\n\t\tx = cos(t + startangle) * radius\n\t\ty = sin(t + startangle) * radius\n\t\tnewpoints.append([x, y, 0])\n\t\tj += 1\n\tx = cos(endangle) * radius\n\ty = sin(endangle) * radius\n\tnewpoints.append([x, y, 0])\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "SimpleSegment", "data": "def SimpleSegment(sides=0, a=2.0, b=1.0, startangle=0.0, endangle=45.0):\n\tnewpoints = []\n\n\tstartangle = radians(startangle)\n\tendangle = radians(endangle)\n\tsides += 1\n\n\tangle = (endangle - startangle) / sides\n\tx = cos(startangle) * a\n\ty = sin(startangle) * a\n\tnewpoints.append([x, y, 0])\n\tj = 1\n\twhile j < sides:\n\t\tt = angle * j\n\t\tx = cos(t + startangle) * a\n\t\ty = sin(t + startangle) * a\n\t\tnewpoints.append([x, y, 0])\n\t\tj += 1\n\tx = cos(endangle) * a\n\ty = sin(endangle) * a\n\tnewpoints.append([x, y, 0])\n\n\tx = cos(endangle) * b\n\ty = sin(endangle) * b\n\tnewpoints.append([x, y, 0])\n\tj = sides\n\twhile j > 0:\n\t\tt = angle * j\n\t\tx = cos(t + startangle) * b\n\t\ty = sin(t + startangle) * b\n\t\tnewpoints.append([x, y, 0])\n\t\tj -= 1\n\tx = cos(startangle) * b\n\ty = sin(startangle) * b\n\tnewpoints.append([x, y, 0])\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "SimpleRectangle", "data": "def SimpleRectangle(width=2.0, length=2.0, rounded=0.0, center=True):\n\tnewpoints = []\n\n\tr = rounded / 2\n\n\tif center:\n\t\tx = width / 2\n\t\ty = length / 2\n\t\tif rounded != 0.0:\n\t\t\tnewpoints.append([-x + r, y, 0.0])\n\t\t\tnewpoints.append([x - r, y, 0.0])\n\t\t\tnewpoints.append([x, y - r, 0.0])\n\t\t\tnewpoints.append([x, -y + r, 0.0])\n\t\t\tnewpoints.append([x - r, -y, 0.0])\n\t\t\tnewpoints.append([-x + r, -y, 0.0])\n\t\t\tnewpoints.append([-x, -y + r, 0.0])\n\t\t\tnewpoints.append([-x, y - r, 0.0])\n\t\telse:\n\t\t\tnewpoints.append([-x, y, 0.0])\n\t\t\tnewpoints.append([x, y, 0.0])\n\t\t\tnewpoints.append([x, -y, 0.0])\n\t\t\tnewpoints.append([-x, -y, 0.0])\n\n\telse:\n\t\tx = width\n\t\ty = length\n\t\tif rounded != 0.0:\n\t\t\tnewpoints.append([r, y, 0.0])\n\t\t\tnewpoints.append([x - r, y, 0.0])\n\t\t\tnewpoints.append([x, y - r, 0.0])\n\t\t\tnewpoints.append([x, r, 0.0])\n\t\t\tnewpoints.append([x - r, 0.0, 0.0])\n\t\t\tnewpoints.append([r, 0.0, 0.0])\n\t\t\tnewpoints.append([0.0, r, 0.0])\n\t\t\tnewpoints.append([0.0, y - r, 0.0])\n\t\telse:\n\t\t\tnewpoints.append([0.0, 0.0, 0.0])\n\t\t\tnewpoints.append([0.0, y, 0.0])\n\t\t\tnewpoints.append([x, y, 0.0])\n\t\t\tnewpoints.append([x, 0.0, 0.0])\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "SimpleRhomb", "data": "def SimpleRhomb(width=2.0, length=2.0, center=True):\n\tnewpoints = []\n\tx = width / 2\n\ty = length / 2\n\n\tif center:\n\t\tnewpoints.append([-x, 0.0, 0.0])\n\t\tnewpoints.append([0.0, y, 0.0])\n\t\tnewpoints.append([x, 0.0, 0.0])\n\t\tnewpoints.append([0.0, -y, 0.0])\n\telse:\n\t\tnewpoints.append([x, 0.0, 0.0])\n\t\tnewpoints.append([0.0, y, 0.0])\n\t\tnewpoints.append([x, length, 0.0])\n\t\tnewpoints.append([width, y, 0.0])\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "SimplePolygon", "data": "def SimplePolygon(sides=3, radius=1.0):\n\tnewpoints = []\n\tangle = radians(360.0) / sides\n\tj = 0\n\n\twhile j < sides:\n\t\tt = angle * j\n\t\tx = sin(t) * radius\n\t\ty = cos(t) * radius\n\t\tnewpoints.append([x, y, 0.0])\n\t\tj += 1\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "SimplePolygon_ab", "data": "def SimplePolygon_ab(sides=3, a=2.0, b=1.0):\n\tnewpoints = []\n\tangle = radians(360.0) / sides\n\tj = 0\n\n\twhile j < sides:\n\t\tt = angle * j\n\t\tx = sin(t) * a\n\t\ty = cos(t) * b\n\t\tnewpoints.append([x, y, 0.0])\n\t\tj += 1\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "SimpleTrapezoid", "data": "def SimpleTrapezoid(a=2.0, b=1.0, h=1.0, center=True):\n\tnewpoints = []\n\tx = a / 2\n\ty = b / 2\n\tr = h / 2\n\n\tif center:\n\t\tnewpoints.append([-x, -r, 0.0])\n\t\tnewpoints.append([-y, r, 0.0])\n\t\tnewpoints.append([y, r, 0.0])\n\t\tnewpoints.append([x, -r, 0.0])\n\n\telse:\n\t\tnewpoints.append([0.0, 0.0, 0.0])\n\t\tnewpoints.append([x - y, h, 0.0])\n\t\tnewpoints.append([x + y, h, 0.0])\n\t\tnewpoints.append([a, 0.0, 0.0])\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "align_matrix", "data": "def align_matrix(context, location):\n\tloc = Matrix.Translation(location)\n\tobj_align = context.user_preferences.edit.object_align\n\tif (context.space_data.type == 'VIEW_3D' and\n\t\t\tobj_align == 'VIEW'):\n\t\trot = context.space_data.region_3d.view_matrix.to_3x3().inverted().to_4x4()\n\telse:\n\t\trot = Matrix()\n\talign_matrix = loc * rot\n\n\treturn align_matrix\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "main", "data": "def main(context, self, align_matrix):\n\t# deselect all objects\n\tbpy.ops.object.select_all(action='DESELECT')\n\n\t# create object\n\tname = self.Simple_Type  # Type as name\n\n\t# create curve\n\tscene = bpy.context.scene\n\tnewCurve = bpy.data.curves.new(name, type='CURVE')  # curvedatablock\n\tnewSpline = newCurve.splines.new('BEZIER')\t\t  # spline\n\n\t# set curveOptions\n\tnewCurve.dimensions = self.shape\n\tnewSpline.use_endpoint_u = True\n\n\tsides = abs(int((self.Simple_endangle - self.Simple_startangle) / 90))\n\n\t# get verts\n\tif self.Simple_Type == 'Point':\n\t\tverts = SimplePoint()\n\t\tnewSpline.use_cyclic_u = False\n\n\tif self.Simple_Type == 'Line':\n\t\tverts = SimpleLine(self.Simple_startlocation, self.Simple_endlocation)\n\t\tnewSpline.use_cyclic_u = False\n\t\tnewCurve.dimensions = '3D'\n\n\tif self.Simple_Type == 'Distance':\n\t\tverts = SimpleDistance(self.Simple_length, self.Simple_center)\n\t\tnewSpline.use_cyclic_u = False\n\n\tif self.Simple_Type == 'Angle':\n\t\tverts = SimpleAngle(self.Simple_length, self.Simple_angle)\n\t\tnewSpline.use_cyclic_u = False\n\n\tif self.Simple_Type == 'Circle':\n\t\tif self.Simple_sides < 4:\n\t\t\tself.Simple_sides = 4\n\t\tverts = SimpleCircle(self.Simple_sides, self.Simple_radius)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Ellipse':\n\t\tverts = SimpleEllipse(self.Simple_a, self.Simple_b)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Arc':\n\t\tif self.Simple_sides < sides:\n\t\t\tself.Simple_sides = sides\n\t\tif self.Simple_radius == 0:\n\t\t\treturn {'FINISHED'}\n\t\tverts = SimpleArc(\n\t\t\t\t\tself.Simple_sides, self.Simple_radius,\n\t\t\t\t\tself.Simple_startangle, self.Simple_endangle\n\t\t\t\t\t)\n\t\tnewSpline.use_cyclic_u = False\n\n\tif self.Simple_Type == 'Sector':\n\t\tif self.Simple_sides < sides:\n\t\t\tself.Simple_sides = sides\n\n\t\tif self.Simple_radius == 0:\n\t\t\treturn {'FINISHED'}\n\n\t\tverts = SimpleSector(\n\t\t\t\t\tself.Simple_sides, self.Simple_radius,\n\t\t\t\t\tself.Simple_startangle, self.Simple_endangle\n\t\t\t\t\t)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Segment':\n\t\tif self.Simple_sides < sides:\n\t\t\tself.Simple_sides = sides\n\t\tif self.Simple_a == 0 or self.Simple_b == 0:\n\t\t\treturn {'FINISHED'}\n\t\tverts = SimpleSegment(\n\t\t\t\t\tself.Simple_sides, self.Simple_a, self.Simple_b,\n\t\t\t\t\tself.Simple_startangle, self.Simple_endangle\n\t\t\t\t\t)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Rectangle':\n\t\tverts = SimpleRectangle(\n\t\t\t\t\tself.Simple_width, self.Simple_length,\n\t\t\t\t\tself.Simple_rounded, self.Simple_center\n\t\t\t\t\t)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Rhomb':\n\t\tverts = SimpleRhomb(\n\t\t\t\t\tself.Simple_width, self.Simple_length, self.Simple_center\n\t\t\t\t\t)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Polygon':\n\t\tif self.Simple_sides < 3:\n\t\t\tself.Simple_sides = 3\n\t\tverts = SimplePolygon(\n\t\t\t\t\tself.Simple_sides, self.Simple_radius\n\t\t\t\t\t)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Polygon_ab':\n\t\tif self.Simple_sides < 3:\n\t\t\tself.Simple_sides = 3\n\t\tverts = SimplePolygon_ab(\n\t\t\t\t\tself.Simple_sides, self.Simple_a, self.Simple_b\n\t\t\t\t\t)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Trapezoid':\n\t\tverts = SimpleTrapezoid(\n\t\t\t\t\tself.Simple_a, self.Simple_b, self.Simple_h, self.Simple_center\n\t\t\t\t\t)\n\t\tnewSpline.use_cyclic_u = True\n\n\tvertArray = []\n\tfor v in verts:\n\t\tvertArray += v\n\n\tnewSpline.bezier_points.add(int(len(vertArray) * 0.333333333))\n\tnewSpline.bezier_points.foreach_set('co', vertArray)\n\n\t# create object with newCurve\n\tSimpleCurve = bpy.data.objects.new(name, newCurve)  # object\n\tscene.objects.link(SimpleCurve)  # place in active scene\n\tSimpleCurve.select = True  # set as selected\n\tscene.objects.active = SimpleCurve  # set as active\n\tSimpleCurve.matrix_world = align_matrix  # apply matrix\n\tSimpleCurve.rotation_euler = self.Simple_rotation_euler\n\n\tall_points = [p for p in newSpline.bezier_points]\n\td = 2 * 0.27606262\n\tn = 0\n\tfor p in all_points:\n\t\tp.handle_right_type = 'VECTOR'\n\t\tp.handle_left_type = 'VECTOR'\n\t\tn += 1\n\n\tif self.Simple_Type == 'Circle' or self.Simple_Type == 'Arc' or \\\n\t\t\tself.Simple_Type == 'Sector' or self.Simple_Type == 'Segment' or \\\n\t\t\tself.Simple_Type == 'Ellipse':\n\n\t\tfor p in all_points:\n\t\t\tp.handle_right_type = 'FREE'\n\t\t\tp.handle_left_type = 'FREE'\n\n\tif self.Simple_Type == 'Circle':\n\t\ti = 0\n\t\tfor p1 in all_points:\n\t\t\tif i != n - 1:\n\t\t\t\tp2 = all_points[i + 1]\n\t\t\t\tu1 = asin(p1.co.y / self.Simple_radius)\n\t\t\t\tu2 = asin(p2.co.y / self.Simple_radius)\n\t\t\t\tif p1.co.x > 0 and p2.co.x < 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\telif p1.co.x < 0 and p2.co.x > 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\tu = u2 - u1\n\t\t\t\tif u < 0:\n\t\t\t\t\tu = -u\n\t\t\t\tl = 4 / 3 * tan(1 / 4 * u) * self.Simple_radius\n\t\t\t\tv1 = Vector((-p1.co.y, p1.co.x, 0))\n\t\t\t\tv1.normalize()\n\t\t\t\tv2 = Vector((-p2.co.y, p2.co.x, 0))\n\t\t\t\tv2.normalize()\n\t\t\t\tvh1 = v1 * l\n\t\t\t\tvh2 = v2 * l\n\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) + vh1\n\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) - vh2\n\t\t\t\tp1.handle_right = v1\n\t\t\t\tp2.handle_left = v2\n\t\t\tif i == n - 1:\n\t\t\t\tp2 = all_points[0]\n\t\t\t\tu1 = asin(p1.co.y / self.Simple_radius)\n\t\t\t\tu2 = asin(p2.co.y / self.Simple_radius)\n\t\t\t\tif p1.co.x > 0 and p2.co.x < 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\telif p1.co.x < 0 and p2.co.x > 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\tu = u2 - u1\n\t\t\t\tif u < 0:\n\t\t\t\t\tu = -u\n\t\t\t\tl = 4 / 3 * tan(1 / 4 * u) * self.Simple_radius\n\t\t\t\tv1 = Vector((-p1.co.y, p1.co.x, 0))\n\t\t\t\tv1.normalize()\n\t\t\t\tv2 = Vector((-p2.co.y, p2.co.x, 0))\n\t\t\t\tv2.normalize()\n\t\t\t\tvh1 = v1 * l\n\t\t\t\tvh2 = v2 * l\n\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) + vh1\n\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) - vh2\n\t\t\t\tp1.handle_right = v1\n\t\t\t\tp2.handle_left = v2\n\t\t\ti += 1\n\n\tif self.Simple_Type == 'Ellipse':\n\t\tall_points[0].handle_right = Vector((self.Simple_a, self.Simple_b * d, 0))\n\t\tall_points[0].handle_left = Vector((self.Simple_a, -self.Simple_b * d, 0))\n\t\tall_points[1].handle_right = Vector((-self.Simple_a * d, self.Simple_b, 0))\n\t\tall_points[1].handle_left = Vector((self.Simple_a * d, self.Simple_b, 0))\n\t\tall_points[2].handle_right = Vector((-self.Simple_a, -self.Simple_b * d, 0))\n\t\tall_points[2].handle_left = Vector((-self.Simple_a, self.Simple_b * d, 0))\n\t\tall_points[3].handle_right = Vector((self.Simple_a * d, -self.Simple_b, 0))\n\t\tall_points[3].handle_left = Vector((-self.Simple_a * d, -self.Simple_b, 0))\n\n\tif self.Simple_Type == 'Arc':\n\t\ti = 0\n\t\tfor p1 in all_points:\n\t\t\tif i != n - 1:\n\t\t\t\tp2 = all_points[i + 1]\n\t\t\t\tu1 = asin(p1.co.y / self.Simple_radius)\n\t\t\t\tu2 = asin(p2.co.y / self.Simple_radius)\n\t\t\t\tif p1.co.x > 0 and p2.co.x < 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\telif p1.co.x < 0 and p2.co.x > 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\tu = u2 - u1\n\t\t\t\tif u < 0:\n\t\t\t\t\tu = -u\n\t\t\t\tl = 4 / 3 * tan(1 / 4 * u) * self.Simple_radius\n\t\t\t\tv1 = Vector((-p1.co.y, p1.co.x, 0))\n\t\t\t\tv1.normalize()\n\t\t\t\tv2 = Vector((-p2.co.y, p2.co.x, 0))\n\t\t\t\tv2.normalize()\n\t\t\t\tvh1 = v1 * l\n\t\t\t\tvh2 = v2 * l\n\t\t\t\tif self.Simple_startangle < self.Simple_endangle:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) + vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) - vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\t\t\t\telse:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) - vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) + vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\t\t\ti += 1\n\n\tif self.Simple_Type == 'Sector':\n\t\ti = 0\n\t\tfor p1 in all_points:\n\t\t\tif i == 0:\n\t\t\t\tp1.handle_right_type = 'VECTOR'\n\t\t\t\tp1.handle_left_type = 'VECTOR'\n\t\t\telif i != n - 1:\n\t\t\t\tp2 = all_points[i + 1]\n\t\t\t\tu1 = asin(p1.co.y / self.Simple_radius)\n\t\t\t\tu2 = asin(p2.co.y / self.Simple_radius)\n\t\t\t\tif p1.co.x > 0 and p2.co.x < 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\telif p1.co.x < 0 and p2.co.x > 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\tu = u2 - u1\n\t\t\t\tif u < 0:\n\t\t\t\t\tu = -u\n\t\t\t\tl = 4 / 3 * tan(1 / 4 * u) * self.Simple_radius\n\t\t\t\tv1 = Vector((-p1.co.y, p1.co.x, 0))\n\t\t\t\tv1.normalize()\n\t\t\t\tv2 = Vector((-p2.co.y, p2.co.x, 0))\n\t\t\t\tv2.normalize()\n\t\t\t\tvh1 = v1 * l\n\t\t\t\tvh2 = v2 * l\n\t\t\t\tif self.Simple_startangle < self.Simple_endangle:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) + vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) - vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\t\t\t\telse:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) - vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) + vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\t\t\ti += 1\n\n\tif self.Simple_Type == 'Segment':\n\t\ti = 0\n\t\tfor p1 in all_points:\n\t\t\tif i < n / 2 - 1:\n\t\t\t\tp2 = all_points[i + 1]\n\t\t\t\tu1 = asin(p1.co.y / self.Simple_a)\n\t\t\t\tu2 = asin(p2.co.y / self.Simple_a)\n\t\t\t\tif p1.co.x > 0 and p2.co.x < 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_a)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_a)\n\t\t\t\telif p1.co.x < 0 and p2.co.x > 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_a)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_a)\n\t\t\t\tu = u2 - u1\n\t\t\t\tif u < 0:\n\t\t\t\t\tu = -u\n\t\t\t\tl = 4 / 3 * tan(1 / 4 * u) * self.Simple_a\n\t\t\t\tv1 = Vector((-p1.co.y, p1.co.x, 0))\n\t\t\t\tv1.normalize()\n\t\t\t\tv2 = Vector((-p2.co.y, p2.co.x, 0))\n\t\t\t\tv2.normalize()\n\t\t\t\tvh1 = v1 * l\n\t\t\t\tvh2 = v2 * l\n\t\t\t\tif self.Simple_startangle < self.Simple_endangle:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) + vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) - vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\t\t\t\telse:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) - vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) + vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\t\t\telif i != n / 2 - 1 and i != n - 1:\n\t\t\t\tp2 = all_points[i + 1]\n\t\t\t\tu1 = asin(p1.co.y / self.Simple_b)\n\t\t\t\tu2 = asin(p2.co.y / self.Simple_b)\n\t\t\t\tif p1.co.x > 0 and p2.co.x < 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_b)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_b)\n\t\t\t\telif p1.co.x < 0 and p2.co.x > 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_b)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_b)\n\t\t\t\tu = u2 - u1\n\t\t\t\tif u < 0:\n\t\t\t\t\tu = -u\n\t\t\t\tl = 4 / 3 * tan(1 / 4 * u) * self.Simple_b\n\t\t\t\tv1 = Vector((-p1.co.y, p1.co.x, 0))\n\t\t\t\tv1.normalize()\n\t\t\t\tv2 = Vector((-p2.co.y, p2.co.x, 0))\n\t\t\t\tv2.normalize()\n\t\t\t\tvh1 = v1 * l\n\t\t\t\tvh2 = v2 * l\n\t\t\t\tif self.Simple_startangle < self.Simple_endangle:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) - vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) + vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\t\t\t\telse:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) + vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) - vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\n\t\t\ti += 1\n\t\tall_points[0].handle_left_type = 'VECTOR'\n\t\tall_points[n - 1].handle_right_type = 'VECTOR'\n\t\tall_points[int(n / 2) - 1].handle_right_type = 'VECTOR'\n\t\tall_points[int(n / 2)].handle_left_type = 'VECTOR'\n\n\tSimpleCurve.s_curve.Simple = True\n\tSimpleCurve.s_curve.Simple_Change = False\n\tSimpleCurve.s_curve.Simple_Type = self.Simple_Type\n\tSimpleCurve.s_curve.Simple_startlocation = self.Simple_startlocation\n\tSimpleCurve.s_curve.Simple_endlocation = self.Simple_endlocation\n\tSimpleCurve.s_curve.Simple_a = self.Simple_a\n\tSimpleCurve.s_curve.Simple_b = self.Simple_b\n\tSimpleCurve.s_curve.Simple_h = self.Simple_h\n\tSimpleCurve.s_curve.Simple_angle = self.Simple_angle\n\tSimpleCurve.s_curve.Simple_startangle = self.Simple_startangle\n\tSimpleCurve.s_curve.Simple_endangle = self.Simple_endangle\n\tSimpleCurve.s_curve.Simple_rotation_euler = self.Simple_rotation_euler\n\tSimpleCurve.s_curve.Simple_sides = self.Simple_sides\n\tSimpleCurve.s_curve.Simple_radius = self.Simple_radius\n\tSimpleCurve.s_curve.Simple_center = self.Simple_center\n\tSimpleCurve.s_curve.Simple_width = self.Simple_width\n\tSimpleCurve.s_curve.Simple_length = self.Simple_length\n\tSimpleCurve.s_curve.Simple_rounded = self.Simple_rounded\n\n\tbpy.ops.object.mode_set(mode='EDIT', toggle=True)\n\tbpy.ops.curve.select_all(action='SELECT')\n\tbpy.ops.object.mode_set(mode='OBJECT', toggle=True)\n\n\treturn\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "SimpleDelete", "data": "def SimpleDelete(name):\n\tif bpy.ops.object.mode_set.poll():\n\t\tbpy.ops.object.mode_set(mode='OBJECT')\n\n\tbpy.context.scene.objects.active = bpy.data.objects[name]\n\tbpy.ops.object.delete()\n\n\treturn\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "class", "name": "Simple", "data": "class Simple(Operator):\n\tbl_idname = \"curve.simple\"\n\tbl_label = \"Simple Curve\"\n\tbl_description = \"Construct a Simple Curve\"\n\tbl_options = {'REGISTER', 'UNDO'}\n\n\t# align_matrix for the invoke\n\talign_matrix = Matrix()\n\n\t# change properties\n\tSimple = BoolProperty(\n\t\t\tname=\"Simple\",\n\t\t\tdefault=True,\n\t\t\tdescription=\"Simple Curve\"\n\t\t\t)\n\tSimple_Change = BoolProperty(\n\t\t\tname=\"Change\",\n\t\t\tdefault=False,\n\t\t\tdescription=\"Change Simple Curve\"\n\t\t\t)\n\tSimple_Delete = StringProperty(\n\t\t\tname=\"Delete\",\n\t\t\tdescription=\"Delete Simple Curve\"\n\t\t\t)\n\t# general properties\n\tTypes = [('Point', \"Point\", \"Construct a Point\"),\n\t\t\t ('Line', \"Line\", \"Construct a Line\"),\n\t\t\t ('Distance', \"Distance\", \"Contruct a two point Distance\"),\n\t\t\t ('Angle', \"Angle\", \"Construct an Angle\"),\n\t\t\t ('Circle', \"Circle\", \"Construct a Circle\"),\n\t\t\t ('Ellipse', \"Ellipse\", \"Construct an Ellipse\"),\n\t\t\t ('Arc', \"Arc\", \"Construct an Arc\"),\n\t\t\t ('Sector', \"Sector\", \"Construct a Sector\"),\n\t\t\t ('Segment', \"Segment\", \"Construct a Segment\"),\n\t\t\t ('Rectangle', \"Rectangle\", \"Construct a Rectangle\"),\n\t\t\t ('Rhomb', \"Rhomb\", \"Construct a Rhomb\"),\n\t\t\t ('Polygon', \"Polygon\", \"Construct a Polygon\"),\n\t\t\t ('Polygon_ab', \"Polygon ab\", \"Construct a Polygon ab\"),\n\t\t\t ('Trapezoid', \"Trapezoid\", \"Construct a Trapezoid\")\n\t\t\t]\n\tSimple_Type = EnumProperty(\n\t\t\tname=\"Type\",\n\t\t\tdescription=\"Form of Curve to create\",\n\t\t\titems=Types\n\t\t\t)\n\t# Line properties\n\tSimple_startlocation = FloatVectorProperty(\n\t\t\tname=\"\",\n\t\t\tdescription=\"Start location\",\n\t\t\tdefault=(0.0, 0.0, 0.0),\n\t\t\tsubtype='TRANSLATION'\n\t\t\t)\n\tSimple_endlocation = FloatVectorProperty(\n\t\t\tname=\"\",\n\t\t\tdescription=\"End location\",\n\t\t\tdefault=(2.0, 2.0, 2.0),\n\t\t\tsubtype='TRANSLATION'\n\t\t\t)\n\tSimple_rotation_euler = FloatVectorProperty(\n\t\t\tname=\"\",\n\t\t\tdescription=\"Rotation\",\n\t\t\tdefault=(0.0, 0.0, 0.0),\n\t\t\tsubtype='EULER'\n\t\t\t)\n\t# Trapezoid properties\n\tSimple_a = FloatProperty(\n\t\t\tname=\"Side a\",\n\t\t\tdefault=2.0,\n\t\t\tmin=0.0, soft_min=0.0,\n\t\t\tunit='LENGTH',\n\t\t\tdescription=\"a side Value\"\n\t\t\t)\n\tSimple_b = FloatProperty(\n\t\t\tname=\"Side b\",\n\t\t\tdefault=1.0,\n\t\t\tmin=0.0, soft_min=0.0,\n\t\t\tunit='LENGTH',\n\t\t\tdescription=\"b side Value\"\n\t\t\t)\n\tSimple_h = FloatProperty(\n\t\t\tname=\"Height\",\n\t\t\tdefault=1.0,\n\t\t\tunit='LENGTH',\n\t\t\tdescription=\"Height of the Trapezoid - distance between a and b\"\n\t\t\t)\n\tSimple_angle = FloatProperty(\n\t\t\tname=\"Angle\",\n\t\t\tdefault=45.0,\n\t\t\tdescription=\"Angle\"\n\t\t\t)\n\tSimple_startangle = FloatProperty(\n\t\t\tname=\"Start angle\",\n\t\t\tdefault=0.0,\n\t\t\tmin=-360.0, soft_min=-360.0,\n\t\t\tmax=360.0, soft_max=360.0,\n\t\t\tdescription=\"Start angle\"\n\t\t\t)\n\tSimple_endangle = FloatProperty(\n\t\t\tname=\"End angle\",\n\t\t\tdefault=45.0,\n\t\t\tmin=-360.0, soft_min=-360.0,\n\t\t\tmax=360.0, soft_max=360.0,\n\t\t\tdescription=\"End angle\"\n\t\t\t)\n\tSimple_sides = IntProperty(\n\t\t\tname=\"Sides\",\n\t\t\tdefault=3,\n\t\t\tmin=0, soft_min=0,\n\t\t\tdescription=\"Sides\"\n\t\t\t)\n\tSimple_radius = FloatProperty(\n\t\t\tname=\"Radius\",\n\t\t\tdefault=1.0,\n\t\t\tmin=0.0, soft_min=0.0,\n\t\t\tunit='LENGTH',\n\t\t\tdescription=\"Radius\"\n\t\t\t)\n\tSimple_center = BoolProperty(\n\t\t\tname=\"Length center\",\n\t\t\tdefault=True,\n\t\t\tdescription=\"Length center\"\n\t\t\t)\n\n\tAngle_types = [('Degrees', \"Degrees\", \"Use Degrees\"),\n\t\t\t\t   ('Radians', \"Radians\", \"Use Radians\")]\n\tSimple_degrees_or_radians = EnumProperty(\n\t\t\tname=\"Degrees or radians\",\n\t\t\tdescription=\"Degrees or radians\",\n\t\t\titems=Angle_types\n\t\t\t)\n\t# Rectangle properties\n\tSimple_width = FloatProperty(\n\t\t\tname=\"Width\",\n\t\t\tdefault=2.0,\n\t\t\tmin=0.0, soft_min=0,\n\t\t\tunit='LENGTH',\n\t\t\tdescription=\"Width\"\n\t\t\t)\n\tSimple_length = FloatProperty(\n\t\t\tname=\"Length\",\n\t\t\tdefault=2.0,\n\t\t\tmin=0.0, soft_min=0.0,\n\t\t\tunit='LENGTH',\n\t\t\tdescription=\"Length\"\n\t\t\t)\n\tSimple_rounded = FloatProperty(\n\t\t\tname=\"Rounded\",\n\t\t\tdefault=0.0,\n\t\t\tmin=0.0, soft_min=0.0,\n\t\t\tunit='LENGTH',\n\t\t\tdescription=\"Rounded corners\"\n\t\t\t)\n\t# Curve Options\n\tshapeItems = [\n\t\t('2D', \"2D\", \"2D shape Curve\"),\n\t\t('3D', \"3D\", \"3D shape Curve\")]\n\tshape = EnumProperty(\n\t\t\tname=\"2D / 3D\",\n\t\t\titems=shapeItems,\n\t\t\tdescription=\"2D or 3D Curve\"\n\t\t\t)\n\n\tdef draw(self, context):\n\t\tlayout = self.layout\n\n\t\t# general options\n\t\tcol = layout.column()\n\t\tcol.prop(self, \"Simple_Type\")\n\n\t\tl = 0\n\t\ts = 0\n\n\t\tif self.Simple_Type == 'Line':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=self.Simple_Type + \" Options:\")\n\t\t\tcol.prop(self, \"Simple_endlocation\")\n\t\t\tv = Vector(self.Simple_endlocation) - Vector(self.Simple_startlocation)\n\t\t\tl = v.length\n\n\t\tif self.Simple_Type == 'Distance':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=self.Simple_Type + \" Options:\")\n\t\t\tcol.prop(self, \"Simple_length\")\n\t\t\tcol.prop(self, \"Simple_center\")\n\t\t\tl = self.Simple_length\n\n\t\tif self.Simple_Type == 'Angle':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=self.Simple_Type + \" Options:\")\n\t\t\tcol.prop(self, \"Simple_length\")\n\t\t\tcol.prop(self, \"Simple_angle\")\n\n\t\t\trow = layout.row()\n\t\t\trow.prop(self, \"Simple_degrees_or_radians\", expand=True)\n\n\t\tif self.Simple_Type == 'Circle':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=self.Simple_Type + \" Options:\")\n\t\t\tcol.prop(self, \"Simple_sides\")\n\t\t\tcol.prop(self, \"Simple_radius\")\n\n\t\t\tl = 2 * pi * abs(self.Simple_radius)\n\t\t\ts = pi * self.Simple_radius * self.Simple_radius\n\n\t\tif self.Simple_Type == 'Ellipse':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=self.Simple_Type + \" Options:\")\n\t\t\tcol.prop(self, \"Simple_a\", text=\"Radius a\")\n\t\t\tcol.prop(self, \"Simple_b\", text=\"Radius b\")\n\n\t\t\tl = pi * (3 * (self.Simple_a + self.Simple_b) -\n\t\t\t\t\t\t  sqrt((3 * self.Simple_a + self.Simple_b) *\n\t\t\t\t\t\t  (self.Simple_a + 3 * self.Simple_b)))\n\n\t\t\ts = pi * abs(self.Simple_b) * abs(self.Simple_a)\n\n\t\tif self.Simple_Type == 'Arc':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=self.Simple_Type + \" Options:\")\n\t\t\tcol.prop(self, \"Simple_sides\")\n\t\t\tcol.prop(self, \"Simple_radius\")\n\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.prop(self, \"Simple_startangle\")\n\t\t\tcol.prop(self, \"Simple_endangle\")\n\t\t\trow = layout.row()\n\t\t\trow.prop(self, \"Simple_degrees_or_radians\", expand=True)\n\n\t\t\tl = abs(pi * self.Simple_radius * (self.Simple_endangle - self.Simple_startangle) / 180)\n\n\t\tif self.Simple_Type == 'Sector':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=self.Simple_Type + \" Options:\")\n\t\t\tcol.prop(self, \"Simple_sides\")\n\t\t\tcol.prop(self, \"Simple_radius\")\n\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.prop(self, \"Simple_startangle\")\n\t\t\tcol.prop(self, \"Simple_endangle\")\n\t\t\trow = layout.row()\n\t\t\trow.prop(self, \"Simple_degrees_or_radians\", expand=True)\n\n\t\t\tl = abs(pi * self.Simple_radius *\n\t\t\t\t   (self.Simple_endangle - self.Simple_startangle) / 180) + self.Simple_radius * 2\n\n\t\t\ts = pi * self.Simple_radius * self.Simple_radius * \\\n\t\t\t\tabs(self.Simple_endangle - self.Simple_startangle) / 360\n\n\t\tif self.Simple_Type == 'Segment':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=self.Simple_Type + \" Options:\")\n\t\t\tcol.prop(self, \"Simple_sides\")\n\t\t\tcol.prop(self, \"Simple_a\", text=\"Radius a\")\n\t\t\tcol.prop(self, \"Simple_b\", text=\"Radius b\")\n\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.prop(self, \"Simple_startangle\")\n\t\t\tcol.prop(self, \"Simple_endangle\")\n\n\t\t\trow = layout.row()\n\t\t\trow.prop(self, \"Simple_degrees_or_radians\", expand=True)\n\n\t\t\tla = abs(pi * self.Simple_a * (self.Simple_endangle - self.Simple_startangle) / 180)\n\t\t\tlb = abs(pi * self.Simple_b * (self.Simple_endangle - self.Simple_startangle) / 180)\n\t\t\tl = abs(self.Simple_a - self.Simple_b) * 2 + la + lb\n\n\t\t\tsa = pi * self.Simple_a * self.Simple_a * \\\n\t\t\t\tabs(self.Simple_endangle - self.Simple_startangle) / 360\n\n\t\t\tsb = pi * self.Simple_b * self.Simple_b * \\\n\t\t\t\tabs(self.Simple_endangle - self.Simple_startangle) / 360\n\n\t\t\ts = abs(sa - sb)\n\n\t\tif self.Simple_Type == 'Rectangle':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=self.Simple_Type + \" Options:\")\n\t\t\tcol.prop(self, \"Simple_width\")\n\t\t\tcol.prop(self, \"Simple_length\")\n\t\t\tcol.prop(self, \"Simple_rounded\")\n\n\t\t\tbox.prop(self, \"Simple_center\")\n\t\t\tl = 2 * abs(self.Simple_width) + 2 * abs(self.Simple_length)\n\t\t\ts = abs(self.Simple_width) * abs(self.Simple_length)\n\n\t\tif self.Simple_Type == 'Rhomb':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=self.Simple_Type + \" Options:\")\n\t\t\tcol.prop(self, \"Simple_width\")\n\t\t\tcol.prop(self, \"Simple_length\")\n\t\t\tcol.prop(self, \"Simple_center\")\n\n\t\t\tg = hypot(self.Simple_width / 2, self.Simple_length / 2)\n\t\t\tl = 4 * g\n\t\t\ts = self.Simple_width * self.Simple_length / 2\n\n\t\tif self.Simple_Type == 'Polygon':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=self.Simple_Type + \" Options:\")\n\t\t\tcol.prop(self, \"Simple_sides\")\n\t\t\tcol.prop(self, \"Simple_radius\")\n\n\t\tif self.Simple_Type == 'Polygon_ab':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=\"Polygon ab Options:\")\n\t\t\tcol.prop(self, \"Simple_sides\")\n\t\t\tcol.prop(self, \"Simple_a\")\n\t\t\tcol.prop(self, \"Simple_b\")\n\n\t\tif self.Simple_Type == 'Trapezoid':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=self.Simple_Type + \" Options:\")\n\t\t\tcol.prop(self, \"Simple_a\")\n\t\t\tcol.prop(self, \"Simple_b\")\n\t\t\tcol.prop(self, \"Simple_h\")\n\n\t\t\tbox.prop(self, \"Simple_center\")\n\t\t\tg = hypot(self.Simple_h, (self.Simple_a - self.Simple_b) / 2)\n\t\t\tl = self.Simple_a + self.Simple_b + g * 2\n\t\t\ts = (abs(self.Simple_a) + abs(self.Simple_b)) / 2 * self.Simple_h\n\n\t\trow = layout.row()\n\t\trow.prop(self, \"shape\", expand=True)\n\t\tbox = layout.box()\n\t\tbox.label(\"Location:\")\n\t\tbox.prop(self, \"Simple_startlocation\")\n\t\tbox = layout.box()\n\t\tbox.label(\"Rotation:\")\n\t\tbox.prop(self, \"Simple_rotation_euler\")\n\n\t\tif l != 0 or s != 0:\n\t\t\tbox = layout.box()\n\t\t\tbox.label(text=\"Statistics:\", icon=\"INFO\")\n\t\tif l != 0:\n\t\t\tl_str = str(round(l, 4))\n\t\t\tbox.label(\"Length: \" + l_str)\n\t\tif s != 0:\n\t\t\ts_str = str(round(s, 4))\n\t\t\tbox.label(\"Area: \" + s_str)\n\n\t@classmethod\n\tdef poll(cls, context):\n\t\treturn context.scene is not None\n\n\tdef execute(self, context):\n\t\tif self.Simple_Change:\n\t\t\tSimpleDelete(self.Simple_Delete)\n\n\t\t# go to object mode\n\t\tif bpy.ops.object.mode_set.poll():\n\t\t\tbpy.ops.object.mode_set(mode='OBJECT')\n\n\t\t# turn off undo\n\t\tundo = bpy.context.user_preferences.edit.use_global_undo\n\t\tbpy.context.user_preferences.edit.use_global_undo = False\n\n\t\t# main function\n\t\tself.align_matrix = align_matrix(context, self.Simple_startlocation)\n\t\tmain(context, self, self.align_matrix)\n\n\t\t# restore pre operator undo state\n\t\tbpy.context.user_preferences.edit.use_global_undo = undo\n\n\t\treturn {'FINISHED'}\n\n\tdef invoke(self, context, event):\n\t\t# store creation_matrix\n\t\tif self.Simple_Change:\n\t\t\tbpy.context.scene.cursor_location = self.Simple_startlocation\n\t\telse:\n\t\t\tself.Simple_startlocation = bpy.context.scene.cursor_location\n\n\t\tself.align_matrix = align_matrix(context, self.Simple_startlocation)\n\t\tself.execute(context)\n\n\t\treturn {'FINISHED'}\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "class", "name": "BezierPointsFillet", "data": "class BezierPointsFillet(Operator):\n\tbl_idname = \"curve.bezier_points_fillet\"\n\tbl_label = \"Bezier points Fillet\"\n\tbl_description = \"Bezier points Fillet\"\n\tbl_options = {'REGISTER', 'UNDO'}\n\n\tFillet_radius = FloatProperty(\n\t\t\tname=\"Radius\",\n\t\t\tdefault=0.25,\n\t\t\tunit='LENGTH',\n\t\t\tdescription=\"Radius\"\n\t\t\t)\n\tTypes = [('Round', \"Round\", \"Round\"),\n\t\t\t ('Chamfer', \"Chamfer\", \"Chamfer\")]\n\tFillet_Type = EnumProperty(\n\t\t\tname=\"Type\",\n\t\t\tdescription=\"Fillet type\",\n\t\t\titems=Types\n\t\t\t)\n\n\tdef draw(self, context):\n\t\tlayout = self.layout\n\n\t\t# general options\n\t\tcol = layout.column()\n\t\tcol.prop(self, \"Fillet_radius\")\n\t\tcol.prop(self, \"Fillet_Type\", expand=True)\n\n\t@classmethod\n\tdef poll(cls, context):\n\t\treturn context.scene is not None\n\n\tdef execute(self, context):\n\t\t# go to object mode\n\t\tif bpy.ops.object.mode_set.poll():\n\t\t\tbpy.ops.object.mode_set(mode='OBJECT')\n\t\t\tbpy.ops.object.mode_set(mode='EDIT')\n\n\t\t# turn off undo\n\t\tundo = bpy.context.user_preferences.edit.use_global_undo\n\t\tbpy.context.user_preferences.edit.use_global_undo = False\n\n\t\t# main function\n\t\tspline = bpy.context.object.data.splines.active\n\t\tselected = [p for p in spline.bezier_points if p.select_control_point]\n\n\t\tbpy.ops.curve.handle_type_set(type='VECTOR')\n\t\tn = 0\n\t\tii = []\n\t\tfor p in spline.bezier_points:\n\t\t\tif p.select_control_point:\n\t\t\t\tii.append(n)\n\t\t\t\tn += 1\n\t\t\telse:\n\t\t\t\tn += 1\n\n\t\tif n > 2:\n\t\t\tjn = 0\n\t\t\tfor j in ii:\n\n\t\t\t\tj += jn\n\n\t\t\t\tselected_all = [p for p in spline.bezier_points]\n\n\t\t\t\tbpy.ops.curve.select_all(action='DESELECT')\n\n\t\t\t\tif j != 0 and j != n - 1:\n\t\t\t\t\tselected_all[j].select_control_point = True\n\t\t\t\t\tselected_all[j + 1].select_control_point = True\n\t\t\t\t\tbpy.ops.curve.subdivide()\n\t\t\t\t\tselected_all = [p for p in spline.bezier_points]\n\t\t\t\t\tselected4 = [selected_all[j - 1], selected_all[j],\n\t\t\t\t\t\t\t\t selected_all[j + 1], selected_all[j + 2]]\n\t\t\t\t\tjn += 1\n\t\t\t\t\tn += 1\n\n\t\t\t\telif j == 0:\n\t\t\t\t\tselected_all[j].select_control_point = True\n\t\t\t\t\tselected_all[j + 1].select_control_point = True\n\t\t\t\t\tbpy.ops.curve.subdivide()\n\t\t\t\t\tselected_all = [p for p in spline.bezier_points]\n\t\t\t\t\tselected4 = [selected_all[n], selected_all[0],\n\t\t\t\t\t\t\t\t selected_all[1], selected_all[2]]\n\t\t\t\t\tjn += 1\n\t\t\t\t\tn += 1\n\n\t\t\t\telif j == n - 1:\n\t\t\t\t\tselected_all[j].select_control_point = True\n\t\t\t\t\tselected_all[j - 1].select_control_point = True\n\t\t\t\t\tbpy.ops.curve.subdivide()\n\t\t\t\t\tselected_all = [p for p in spline.bezier_points]\n\t\t\t\t\tselected4 = [selected_all[0], selected_all[n],\n\t\t\t\t\t\t\t\t selected_all[n - 1], selected_all[n - 2]]\n\n\t\t\t\tselected4[2].co = selected4[1].co\n\t\t\t\ts1 = Vector(selected4[0].co) - Vector(selected4[1].co)\n\t\t\t\ts2 = Vector(selected4[3].co) - Vector(selected4[2].co)\n\t\t\t\ts1.normalize()\n\t\t\t\ts11 = Vector(selected4[1].co) + s1 * self.Fillet_radius\n\t\t\t\tselected4[1].co = s11\n\t\t\t\ts2.normalize()\n\t\t\t\ts22 = Vector(selected4[2].co) + s2 * self.Fillet_radius\n\t\t\t\tselected4[2].co = s22\n\n\t\t\t\tif self.Fillet_Type == 'Round':\n\t\t\t\t\tif j != n - 1:\n\t\t\t\t\t\tselected4[2].handle_right_type = 'VECTOR'\n\t\t\t\t\t\tselected4[1].handle_left_type = 'VECTOR'\n\t\t\t\t\t\tselected4[1].handle_right_type = 'ALIGNED'\n\t\t\t\t\t\tselected4[2].handle_left_type = 'ALIGNED'\n\t\t\t\t\telse:\n\t\t\t\t\t\tselected4[1].handle_right_type = 'VECTOR'\n\t\t\t\t\t\tselected4[2].handle_left_type = 'VECTOR'\n\t\t\t\t\t\tselected4[2].handle_right_type = 'ALIGNED'\n\t\t\t\t\t\tselected4[1].handle_left_type = 'ALIGNED'\n\t\t\t\tif self.Fillet_Type == 'Chamfer':\n\t\t\t\t\tselected4[2].handle_right_type = 'VECTOR'\n\t\t\t\t\tselected4[1].handle_left_type = 'VECTOR'\n\t\t\t\t\tselected4[1].handle_right_type = 'VECTOR'\n\t\t\t\t\tselected4[2].handle_left_type = 'VECTOR'\n\n\t\tbpy.ops.curve.select_all(action='SELECT')\n\t\tbpy.ops.curve.spline_type_set(type='BEZIER')\n\n\t\t# restore pre operator undo state\n\t\tbpy.context.user_preferences.edit.use_global_undo = undo\n\n\t\treturn {'FINISHED'}\n\n\tdef invoke(self, context, event):\n\t\tself.execute(context)\n\n\t\treturn {'FINISHED'}\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "subdivide_cubic_bezier", "data": "def subdivide_cubic_bezier(p1, p2, p3, p4, t):\n\tp12 = (p2 - p1) * t + p1\n\tp23 = (p3 - p2) * t + p2\n\tp34 = (p4 - p3) * t + p3\n\tp123 = (p23 - p12) * t + p12\n\tp234 = (p34 - p23) * t + p23\n\tp1234 = (p234 - p123) * t + p123\n\treturn [p12, p123, p1234, p234, p34]\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "class", "name": "BezierDivide", "data": "class BezierDivide(Operator):\n\tbl_idname = \"curve.bezier_spline_divide\"\n\tbl_label = \"Bezier Spline Divide\"\n\tbl_description = \"Bezier Divide (enters edit mode) for Fillet Curves\"\n\tbl_options = {'REGISTER', 'UNDO'}\n\n\t# align_matrix for the invoke\n\talign_matrix = Matrix()\n\n\tBezier_t = FloatProperty(\n\t\t\tname=\"t (0% - 100%)\",\n\t\t\tdefault=50.0,\n\t\t\tmin=0.0, soft_min=0.0,\n\t\t\tmax=100.0, soft_max=100.0,\n\t\t\tdescription=\"t (0% - 100%)\"\n\t\t\t)\n\n\t@classmethod\n\tdef poll(cls, context):\n\t\treturn context.scene is not None\n\n\tdef execute(self, context):\n\t\t# go to object mode\n\t\tif bpy.ops.object.mode_set.poll():\n\t\t\tbpy.ops.object.mode_set(mode='OBJECT')\n\t\t\tbpy.ops.object.mode_set(mode='EDIT')\n\n\t\t# turn off undo\n\t\tundo = bpy.context.user_preferences.edit.use_global_undo\n\t\tbpy.context.user_preferences.edit.use_global_undo = False\n\n\t\t# main function\n\t\tspline = bpy.context.object.data.splines.active\n\t\tselected_all = [p for p in spline.bezier_points if p.select_control_point]\n\t\th = subdivide_cubic_bezier(\n\t\t\t\t\tselected_all[0].co, selected_all[0].handle_right,\n\t\t\t\t\tselected_all[1].handle_left, selected_all[1].co, self.Bezier_t / 100\n\t\t\t\t\t)\n\n\t\tselected_all[0].handle_right_type = 'FREE'\n\t\tselected_all[0].handle_left_type = 'FREE'\n\t\tselected_all[1].handle_right_type = 'FREE'\n\t\tselected_all[1].handle_left_type = 'FREE'\n\t\tbpy.ops.curve.subdivide(1)\n\t\tselected_all = [p for p in spline.bezier_points if p.select_control_point]\n\n\t\tselected_all[0].handle_right = h[0]\n\t\tselected_all[1].co = h[2]\n\t\tselected_all[1].handle_left = h[1]\n\t\tselected_all[1].handle_right = h[3]\n\t\tselected_all[2].handle_left = h[4]\n\n\t\t# restore pre operator undo state\n\t\tbpy.context.user_preferences.edit.use_global_undo = undo\n\n\t\treturn {'FINISHED'}\n\n\tdef invoke(self, context, event):\n\t\tself.execute(context)\n\n\t\treturn {'FINISHED'}\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "class", "name": "SimplePanel", "data": "class SimplePanel(Panel):\n\tbl_label = \"Simple Curve\"\n\tbl_space_type = \"VIEW_3D\"\n\tbl_region_type = \"TOOLS\"\n\tbl_options = {'DEFAULT_CLOSED'}\n\tbl_category = \"Tools\"\n\n\t@classmethod\n\tdef poll(cls, context):\n\t\tif not context.active_object:\n\t\t\tpass\n\t\telif context.object.s_curve.Simple is True:\n\t\t\treturn (context.object)\n\n\tdef draw(self, context):\n\t\tif context.object.s_curve.Simple is True:\n\t\t\tlayout = self.layout\n\t\t\tobj = context.object\n\t\t\trow = layout.row()\n\n\t\t\tsimple_change = row.operator(\"curve.simple\", text=\"Change\",\n\t\t\t\t\t\t\t\t\t\ticon=\"OUTLINER_DATA_CURVE\")\n\t\t\tsimple_change.Simple_Change = True\n\t\t\tsimple_change.Simple_Delete = obj.name\n\t\t\tsimple_change.Simple_Type = obj.s_curve.Simple_Type\n\t\t\tsimple_change.Simple_startlocation = obj.location\n\t\t\tsimple_change.Simple_endlocation = obj.s_curve.Simple_endlocation\n\n\t\t\tsimple_change.Simple_a = obj.s_curve.Simple_a\n\t\t\tsimple_change.Simple_b = obj.s_curve.Simple_b\n\t\t\tsimple_change.Simple_h = obj.s_curve.Simple_h\n\n\t\t\tsimple_change.Simple_angle = obj.s_curve.Simple_angle\n\t\t\tsimple_change.Simple_startangle = obj.s_curve.Simple_startangle\n\t\t\tsimple_change.Simple_endangle = obj.s_curve.Simple_endangle\n\t\t\tsimple_change.Simple_rotation_euler = obj.rotation_euler\n\n\t\t\tsimple_change.Simple_sides = obj.s_curve.Simple_sides\n\t\t\tsimple_change.Simple_radius = obj.s_curve.Simple_radius\n\t\t\tsimple_change.Simple_center = obj.s_curve.Simple_center\n\t\t\tsimple_change.Simple_width = obj.s_curve.Simple_width\n\t\t\tsimple_change.Simple_length = obj.s_curve.Simple_length\n\t\t\tsimple_change.Simple_rounded = obj.s_curve.Simple_rounded\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "class", "name": "SimpleEdit", "data": "class SimpleEdit(Operator):\n\tbl_idname = \"object._simple_edit\"\n\tbl_label = \"Create Curves\"\n\tbl_description = \"Subdivide and Fillet Curves\"\n\tbl_options = {'REGISTER', 'UNDO'}\n\n\t@classmethod\n\tdef poll(cls, context):\n\t\tvertex = []\n\t\tnselected = []\n\t\tn = 0\n\t\tobj = context.active_object\n\t\tif obj is not None:\n\t\t\tif obj.type == 'CURVE':\n\t\t\t\tfor i in obj.data.splines:\n\t\t\t\t\tfor j in i.bezier_points:\n\t\t\t\t\t\tn += 1\n\t\t\t\t\t\tif j.select_control_point:\n\t\t\t\t\t\t\tnselected.append(n)\n\t\t\t\t\t\t\tvertex.append(obj.matrix_world * j.co)\n\n\t\t\tif len(vertex) > 0 and n > 2:\n\t\t\t\treturn (context.active_object)\n\t\t\tif len(vertex) == 2 and abs(nselected[0] - nselected[1]) == 1:\n\t\t\t\treturn (context.active_object)\n\n\t\tselected = 0\n\t\tfor obj in context.selected_objects:\n\t\t\tif obj.type == 'CURVE':\n\t\t\t\tselected += 1\n\n\t\tif selected >= 2:\n\t\t\treturn (context.selected_objects)\n\n\tdef draw(self, context):\n\t\tvertex = []\n\t\tselected = []\n\t\tn = 0\n\t\tobj = context.active_object\n\t\tif obj is not None:\n\t\t\tif obj.type == 'CURVE':\n\t\t\t\tfor i in obj.data.splines:\n\t\t\t\t\tfor j in i.bezier_points:\n\t\t\t\t\t\tn += 1\n\t\t\t\t\t\tif j.select_control_point:\n\t\t\t\t\t\t\tselected.append(n)\n\t\t\t\t\t\t\tvertex.append(obj.matrix_world * j.co)\n\n\t\t\tif len(vertex) > 0 and n > 2:\n\t\t\t\tlayout = self.layout\n\t\t\t\trow = layout.row()\n\t\t\t\trow.operator(\"curve.bezier_points_fillet\", text=\"Fillet\")\n\n\t\t\tif len(vertex) == 2 and abs(selected[0] - selected[1]) == 1:\n\t\t\t\tlayout = self.layout\n\t\t\t\trow = layout.row()\n\t\t\t\trow.operator(\"curve.bezier_spline_divide\", text=\"Divide\")\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "StartLocationUpdate", "data": "def StartLocationUpdate(self, context):\n\n\tbpy.context.scene.cursor_location = self.Simple_startlocation\n\treturn\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "class", "name": "SimpleVariables", "data": "class SimpleVariables(PropertyGroup):\n\n\tSimple = BoolProperty()\n\tSimple_Change = BoolProperty()\n\n\t# general properties\n\tTypes = [('Point', \"Point\", \"Construct a Point\"),\n\t\t\t ('Line', \"Line\", \"Construct a Line\"),\n\t\t\t ('Distance', \"Distance\", \"Contruct a two point Distance\"),\n\t\t\t ('Angle', \"Angle\", \"Construct an Angle\"),\n\t\t\t ('Circle', \"Circle\", \"Construct a Circle\"),\n\t\t\t ('Ellipse', \"Ellipse\", \"Construct an Ellipse\"),\n\t\t\t ('Arc', \"Arc\", \"Construct an Arc\"),\n\t\t\t ('Sector', \"Sector\", \"Construct a Sector\"),\n\t\t\t ('Segment', \"Segment\", \"Construct a Segment\"),\n\t\t\t ('Rectangle', \"Rectangle\", \"Construct a Rectangle\"),\n\t\t\t ('Rhomb', \"Rhomb\", \"Construct a Rhomb\"),\n\t\t\t ('Polygon', \"Polygon\", \"Construct a Polygon\"),\n\t\t\t ('Polygon_ab', \"Polygon ab\", \"Construct a Polygon ab\"),\n\t\t\t ('Trapezoid', \"Trapezoid\", \"Construct a Trapezoid\")\n\t\t\t]\n\tSimple_Type = EnumProperty(\n\t\t\tname=\"Type\",\n\t\t\tdescription=\"Form of Curve to create\",\n\t\t\titems=Types\n\t\t\t)\n\t# Line properties\n\tSimple_startlocation = FloatVectorProperty(\n\t\t\tname=\"Start location\",\n\t\t\tdescription=\"Start location\",\n\t\t\tdefault=(0.0, 0.0, 0.0),\n\t\t\tsubtype='TRANSLATION',\n\t\t\tupdate=StartLocationUpdate\n\t\t\t)\n\tSimple_endlocation = FloatVectorProperty(\n\t\t\tname=\"End location\",\n\t\t\tdescription=\"End location\",\n\t\t\tdefault=(2.0, 2.0, 2.0),\n\t\t\tsubtype='TRANSLATION'\n\t\t\t)\n\tSimple_rotation_euler = FloatVectorProperty(\n\t\t\tname=\"Rotation\",\n\t\t\tdescription=\"Rotation\",\n\t\t\tdefault=(0.0, 0.0, 0.0),\n\t\t\tsubtype='EULER'\n\t\t\t)\n\t# Trapezoid properties\n\tSimple_a = FloatProperty(\n\t\t\tname=\"Side a\",\n\t\t\tdefault=2.0,\n\t\t\tmin=0.0, soft_min=0.0,\n\t\t\tunit='LENGTH',\n\t\t\tdescription=\"a side Value\"\n\t\t\t)\n\tSimple_b = FloatProperty(\n\t\t\tname=\"Side b\",\n\t\t\tdefault=1.0,\n\t\t\tmin=0.0, soft_min=0.0,\n\t\t\tunit='LENGTH',\n\t\t\tdescription=\"b side Value\"\n\t\t\t)\n\tSimple_h = FloatProperty(\n\t\t\tname=\"Height\",\n\t\t\tdefault=1.0,\n\t\t\tunit='LENGTH',\n\t\t\tdescription=\"Height of the Trapezoid - distance between a and b\"\n\t\t\t)\n\tSimple_angle = FloatProperty(\n\t\t\tname=\"Angle\",\n\t\t\tdefault=45.0,\n\t\t\tdescription=\"Angle\"\n\t\t\t)\n\tSimple_startangle = FloatProperty(\n\t\t\tname=\"Start angle\",\n\t\t\tdefault=0.0,\n\t\t\tmin=-360.0, soft_min=-360.0,\n\t\t\tmax=360.0, soft_max=360.0,\n\t\t\tdescription=\"Start angle\"\n\t\t\t)\n\tSimple_endangle = FloatProperty(\n\t\t\tname=\"End angle\",\n\t\t\tdefault=45.0,\n\t\t\tmin=-360.0, soft_min=-360.0,\n\t\t\tmax=360.0, soft_max=360.0,\n\t\t\tdescription=\"End angle\"\n\t\t\t)\n\tSimple_sides = IntProperty(\n\t\t\tname=\"Sides\",\n\t\t\tdefault=3,\n\t\t\tmin=3, soft_min=3,\n\t\t\tdescription=\"Number of Sides\"\n\t\t\t)\n\tSimple_radius = FloatProperty(\n\t\t\tname=\"Radius\",\n\t\t\tdefault=1.0,\n\t\t\tmin=0.0, soft_min=0.0,\n\t\t\tunit='LENGTH',\n\t\t\tdescription=\"Radius\"\n\t\t\t)\n\tSimple_center = BoolProperty(\n\t\t\tname=\"Length center\",\n\t\t\tdefault=True,\n\t\t\tdescription=\"Length center\"\n\t\t\t)\n\t# Rectangle properties\n\tSimple_width = FloatProperty(\n\t\t\tname=\"Width\",\n\t\t\tdefault=2.0,\n\t\t\tmin=0.0, soft_min=0.0,\n\t\t\tunit='LENGTH',\n\t\t\tdescription=\"Width\"\n\t\t\t)\n\tSimple_length = FloatProperty(\n\t\t\tname=\"Length\",\n\t\t\tdefault=2.0,\n\t\t\tmin=0.0, soft_min=0.0,\n\t\t\tunit='LENGTH',\n\t\t\tdescription=\"Length\"\n\t\t\t)\n\tSimple_rounded = FloatProperty(\n\t\t\tname=\"Rounded\",\n\t\t\tdefault=0.0,\n\t\t\tunit='LENGTH',\n\t\t\tdescription=\"Rounded corners\"\n\t\t\t)\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "class", "name": "INFO_MT_simple_menu", "data": "class INFO_MT_simple_menu(Menu):\n\tbl_idname = \"INFO_MT_simple_menu\"\n\tbl_label = \"2D Objects\"\n\n\tdef draw(self, context):\n\t\tself.layout.operator_context = 'INVOKE_REGION_WIN'\n\n\t\toper1 = self.layout.operator(Simple.bl_idname, text=\"Angle\", icon=\"MOD_CURVE\")\n\t\toper1.Simple_Change = False\n\t\toper1.Simple_Type = \"Angle\"\n\n\t\toper2 = self.layout.operator(Simple.bl_idname, text=\"Arc\", icon=\"MOD_CURVE\")\n\t\toper2.Simple_Change = False\n\t\toper2.Simple_Type = \"Arc\"\n\n\t\toper3 = self.layout.operator(Simple.bl_idname, text=\"Circle\", icon=\"MOD_CURVE\")\n\t\toper3.Simple_Change = False\n\t\toper3.Simple_Type = \"Circle\"\n\n\t\toper4 = self.layout.operator(Simple.bl_idname, text=\"Distance\", icon=\"MOD_CURVE\")\n\t\toper4.Simple_Change = False\n\t\toper4.Simple_Type = \"Distance\"\n\n\t\toper5 = self.layout.operator(Simple.bl_idname, text=\"Ellipse\", icon=\"MOD_CURVE\")\n\t\toper5.Simple_Change = False\n\t\toper5.Simple_Type = \"Ellipse\"\n\n\t\toper6 = self.layout.operator(Simple.bl_idname, text=\"Line\", icon=\"MOD_CURVE\")\n\t\toper6.Simple_Change = False\n\t\toper6.Simple_Type = \"Line\"\n\n\t\toper7 = self.layout.operator(Simple.bl_idname, text=\"Point\", icon=\"MOD_CURVE\")\n\t\toper7.Simple_Change = False\n\t\toper7.Simple_Type = \"Point\"\n\n\t\toper8 = self.layout.operator(Simple.bl_idname, text=\"Polygon\", icon=\"MOD_CURVE\")\n\t\toper8.Simple_Change = False\n\t\toper8.Simple_Type = \"Polygon\"\n\n\t\toper9 = self.layout.operator(Simple.bl_idname, text=\"Polygon ab\", icon=\"MOD_CURVE\")\n\t\toper9.Simple_Change = False\n\t\toper9.Simple_Type = \"Polygon_ab\"\n\n\t\toper10 = self.layout.operator(Simple.bl_idname, text=\"Rectangle\", icon=\"MOD_CURVE\")\n\t\toper10.Simple_Change = False\n\t\toper10.Simple_Type = \"Rectangle\"\n\n\t\toper11 = self.layout.operator(Simple.bl_idname, text=\"Rhomb\", icon=\"MOD_CURVE\")\n\t\toper11.Simple_Change = False\n\t\toper11.Simple_Type = \"Rhomb\"\n\n\t\toper12 = self.layout.operator(Simple.bl_idname, text=\"Sector\", icon=\"MOD_CURVE\")\n\t\toper12.Simple_Change = False\n\t\toper12.Simple_Type = \"Sector\"\n\n\t\toper13 = self.layout.operator(Simple.bl_idname, text=\"Segment\", icon=\"MOD_CURVE\")\n\t\toper13.Simple_Change = False\n\t\toper13.Simple_Type = \"Segment\"\n\n\t\toper14 = self.layout.operator(Simple.bl_idname, text=\"Trapezoid\", icon=\"MOD_CURVE\")\n\t\toper14.Simple_Change = False\n\t\toper14.Simple_Type = \"Trapezoid\"\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "Simple_button", "data": "def Simple_button(self, context):\n\tlayout = self.layout\n\tlayout.separator()\n\tself.layout.menu(\"INFO_MT_simple_menu\", icon=\"MOD_CURVE\")\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "register", "data": "def register():\n\tbpy.utils.register_class(Simple)\n\tbpy.utils.register_class(BezierPointsFillet)\n\tbpy.utils.register_class(BezierDivide)\n\tbpy.utils.register_class(SimplePanel)\n\tbpy.utils.register_class(SimpleEdit)\n\tbpy.utils.register_class(INFO_MT_simple_menu)\n\tbpy.utils.register_class(SimpleVariables)\n\n\tbpy.types.INFO_MT_curve_add.append(Simple_button)\n\n\tbpy.types.Object.s_curve = PointerProperty(type=SimpleVariables)\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "unregister", "data": "def unregister():\n\tbpy.utils.unregister_class(Simple)\n\tbpy.utils.unregister_class(BezierPointsFillet)\n\tbpy.utils.unregister_class(BezierDivide)\n\tbpy.utils.unregister_class(SimplePanel)\n\tbpy.utils.unregister_class(SimpleEdit)\n\tbpy.utils.unregister_class(INFO_MT_simple_menu)\n\tbpy.utils.unregister_class(SimpleVariables)\n\n\tbpy.types.INFO_MT_curve_add.remove(Simple_button)\n\tdel bpy.types.Object.s_curve\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}], [{"term": "class", "name": "TestIsSimplePath", "data": "class TestIsSimplePath(object):\n\t\"\"\"Unit tests for the\n\t:func:`networkx.algorithms.simple_paths.is_simple_path` function.\n\n\t\"\"\"\n\n\tdef test_empty_list(self):\n\t\t\"\"\"Tests that the empty list is not a valid path, since there\n\t\tshould be a one-to-one correspondence between paths as lists of\n\t\tnodes and paths as lists of edges.\n\n\t\t\"\"\"\n\t\tG = nx.trivial_graph()\n\t\tassert_false(nx.is_simple_path(G, []))\n\n\tdef test_trivial_path(self):\n\t\t\"\"\"Tests that the trivial path, a path of length one, is\n\t\tconsidered a simple path in a graph.\n\n\t\t\"\"\"\n\t\tG = nx.trivial_graph()\n\t\tassert_true(nx.is_simple_path(G, [0]))\n\n\tdef test_trivial_nonpath(self):\n\t\t\"\"\"Tests that a list whose sole element is an object not in the\n\t\tgraph is not considered a simple path.\n\n\t\t\"\"\"\n\t\tG = nx.trivial_graph()\n\t\tassert_false(nx.is_simple_path(G, ['not a node']))\n\n\tdef test_simple_path(self):\n\t\tG = nx.path_graph(2)\n\t\tassert_true(nx.is_simple_path(G, [0, 1]))\n\n\tdef test_non_simple_path(self):\n\t\tG = nx.path_graph(2)\n\t\tassert_false(nx.is_simple_path(G, [0, 1, 0]))\n\n\tdef test_cycle(self):\n\t\tG = nx.cycle_graph(3)\n\t\tassert_false(nx.is_simple_path(G, [0, 1, 2, 0]))\n\n\tdef test_missing_node(self):\n\t\tG = nx.path_graph(2)\n\t\tassert_false(nx.is_simple_path(G, [0, 2]))\n\n\tdef test_directed_path(self):\n\t\tG = nx.DiGraph([(0, 1), (1, 2)])\n\t\tassert_true(nx.is_simple_path(G, [0, 1, 2]))\n\n\tdef test_directed_non_path(self):\n\t\tG = nx.DiGraph([(0, 1), (1, 2)])\n\t\tassert_false(nx.is_simple_path(G, [2, 1, 0]))\n\n\tdef test_directed_cycle(self):\n\t\tG = nx.DiGraph([(0, 1), (1, 2), (2, 0)])\n\t\tassert_false(nx.is_simple_path(G, [0, 1, 2, 0]))\n\n\tdef test_multigraph(self):\n\t\tG = nx.MultiGraph([(0, 1), (0, 1)])\n\t\tassert_true(nx.is_simple_path(G, [0, 1]))\n\n\tdef test_multidigraph(self):\n\t\tG = nx.MultiDiGraph([(0, 1), (0, 1), (1, 0), (1, 0)])\n\t\tassert_true(nx.is_simple_path(G, [0, 1]))\n\n", "description": "Unit tests for the\n\t:func:`networkx.algorithms.simple_paths.is_simple_path` function.\n\n\t", "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths", "data": "def test_all_simple_paths():\n\tG = nx.path_graph(4)\n\tpaths = nx.all_simple_paths(G,0,3)\n\tassert_equal(set(tuple(p) for p in paths),{(0,1,2,3)})\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_cutoff", "data": "def test_all_simple_paths_cutoff():\n\tG = nx.complete_graph(4)\n\tpaths = nx.all_simple_paths(G,0,1,cutoff=1)\n\tassert_equal(set(tuple(p) for p in paths),{(0,1)})\n\tpaths = nx.all_simple_paths(G,0,1,cutoff=2)\n\tassert_equal(set(tuple(p) for p in paths),{(0,1),(0,2,1),(0,3,1)})\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_multigraph", "data": "def test_all_simple_paths_multigraph():\n\tG = nx.MultiGraph([(1,2),(1,2)])\n\tpaths = nx.all_simple_paths(G,1,2)\n\tassert_equal(set(tuple(p) for p in paths),{(1,2),(1,2)})\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_multigraph_with_cutoff", "data": "def test_all_simple_paths_multigraph_with_cutoff():\n\tG = nx.MultiGraph([(1,2),(1,2),(1,10),(10,2)])\n\tpaths = nx.all_simple_paths(G,1,2, cutoff=1)\n\tassert_equal(set(tuple(p) for p in paths),{(1,2),(1,2)})\n\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_directed", "data": "def test_all_simple_paths_directed():\n\tG = nx.DiGraph()\n\tnx.add_path(G, [1, 2, 3])\n\tnx.add_path(G, [3, 2, 1])\n\tpaths = nx.all_simple_paths(G,1,3)\n\tassert_equal(set(tuple(p) for p in paths),{(1,2,3)})\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_empty", "data": "def test_all_simple_paths_empty():\n\tG = nx.path_graph(4)\n\tpaths = nx.all_simple_paths(G,0,3,cutoff=2)\n\tassert_equal(list(list(p) for p in paths),[])\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "hamiltonian_path", "data": "def hamiltonian_path(G,source):\n\tsource = arbitrary_element(G)\n\tneighbors = set(G[source])-set([source])\n\tn = len(G)\n\tfor target in neighbors:\n\t\tfor path in nx.all_simple_paths(G,source,target):\n\t\t\tif len(path) == n:\n\t\t\t\tyield path\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_hamiltonian_path", "data": "def test_hamiltonian_path():\n\tfrom itertools import permutations\n\tG=nx.complete_graph(4)\n\tpaths = [list(p) for p in hamiltonian_path(G,0)]\n\texact = [[0]+list(p) for p in permutations([1,2,3],3) ]\n\tassert_equal(sorted(paths),sorted(exact))\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_cutoff_zero", "data": "def test_cutoff_zero():\n\tG = nx.complete_graph(4)\n\tpaths = nx.all_simple_paths(G,0,3,cutoff=0)\n\tassert_equal(list(list(p) for p in paths),[])\n\tpaths = nx.all_simple_paths(nx.MultiGraph(G),0,3,cutoff=0)\n\tassert_equal(list(list(p) for p in paths),[])\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_source_missing", "data": "def test_source_missing():\n\tG = nx.Graph()\n\tnx.add_path(G, [1, 2, 3])\n\tpaths = list(nx.all_simple_paths(nx.MultiGraph(G),0,3))\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_target_missing", "data": "def test_target_missing():\n\tG = nx.Graph()\n\tnx.add_path(G, [1, 2, 3])\n\tpaths = list(nx.all_simple_paths(nx.MultiGraph(G),1,4))\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_shortest_simple_paths", "data": "def test_shortest_simple_paths():\n\tG = cnlti(nx.grid_2d_graph(4, 4), first_label=1, ordering=\"sorted\")\n\tpaths = nx.shortest_simple_paths(G, 1, 12)\n\tassert_equal(next(paths), [1, 2, 3, 4, 8, 12])\n\tassert_equal(next(paths), [1, 5, 6, 7, 8, 12])\n\tassert_equal([len(path) for path in nx.shortest_simple_paths(G, 1, 12)],\n\t\t\t\t sorted([len(path) for path in nx.all_simple_paths(G, 1, 12)]))\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_shortest_simple_paths_directed", "data": "def test_shortest_simple_paths_directed():\n\tG = nx.cycle_graph(7, create_using=nx.DiGraph())\n\tpaths = nx.shortest_simple_paths(G, 0, 3)\n\tassert_equal([path for path in paths], [[0, 1, 2, 3]])\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_Greg_Bernstein", "data": "def test_Greg_Bernstein():\n\tg1 = nx.Graph()\n\tg1.add_nodes_from([\"N0\", \"N1\", \"N2\", \"N3\", \"N4\"])\n\tg1.add_edge(\"N4\", \"N1\", weight=10.0, capacity=50, name=\"L5\")\n\tg1.add_edge(\"N4\", \"N0\", weight=7.0, capacity=40, name=\"L4\")\n\tg1.add_edge(\"N0\", \"N1\", weight=10.0, capacity=45, name=\"L1\")\n\tg1.add_edge(\"N3\", \"N0\", weight=10.0, capacity=50, name=\"L0\")\n\tg1.add_edge(\"N2\", \"N3\", weight=12.0, capacity=30, name=\"L2\")\n\tg1.add_edge(\"N1\", \"N2\", weight=15.0, capacity=42, name=\"L3\")\n\tsolution = [['N1', 'N0', 'N3'], ['N1', 'N2', 'N3'], ['N1', 'N4', 'N0', 'N3']]\n\tresult = list(nx.shortest_simple_paths(g1, 'N1', 'N3', weight='weight'))\n\tassert_equal(result, solution)\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_weighted_shortest_simple_path", "data": "def test_weighted_shortest_simple_path():\n\tdef cost_func(path):\n\t\treturn sum(G.edge[u][v]['weight'] for (u, v) in zip(path, path[1:]))\n\tG = nx.complete_graph(5)\n\tweight = {(u, v): random.randint(1, 100) for (u, v) in G.edges()}\n\tnx.set_edge_attributes(G, 'weight', weight)\n\tcost = 0\n\tfor path in nx.shortest_simple_paths(G, 0, 3, weight='weight'):\n\t\tthis_cost = cost_func(path)\n\t\tassert_true(cost <= this_cost)\n\t\tcost = this_cost\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_directed_weighted_shortest_simple_path", "data": "def test_directed_weighted_shortest_simple_path():\n\tdef cost_func(path):\n\t\treturn sum(G.edge[u][v]['weight'] for (u, v) in zip(path, path[1:]))\n\tG = nx.complete_graph(5)\n\tG = G.to_directed()\n\tweight = {(u, v): random.randint(1, 100) for (u, v) in G.edges()}\n\tnx.set_edge_attributes(G, 'weight', weight)\n\tcost = 0\n\tfor path in nx.shortest_simple_paths(G, 0, 3, weight='weight'):\n\t\tthis_cost = cost_func(path)\n\t\tassert_true(cost <= this_cost)\n\t\tcost = this_cost\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_weight_name", "data": "def test_weight_name():\n\tG = nx.cycle_graph(7)\n\tnx.set_edge_attributes(G, 'weight', 1)\n\tnx.set_edge_attributes(G, 'foo', 1)\n\tG.edge[1][2]['foo'] = 7\n\tpaths = list(nx.shortest_simple_paths(G, 0, 3, weight='foo'))\n\tsolution = [[0, 6, 5, 4, 3], [0, 1, 2, 3]]\n\tassert_equal(paths, solution)\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_ssp_source_missing", "data": "def test_ssp_source_missing():\n\tG = nx.Graph()\n\tnx.add_path(G, [1, 2, 3])\n\tpaths = list(nx.shortest_simple_paths(G, 0, 3))\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_ssp_target_missing", "data": "def test_ssp_target_missing():\n\tG = nx.Graph()\n\tnx.add_path(G, [1, 2, 3])\n\tpaths = list(nx.shortest_simple_paths(G, 1, 4))\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_ssp_multigraph", "data": "def test_ssp_multigraph():\n\tG = nx.MultiGraph()\n\tnx.add_path(G, [1, 2, 3])\n\tpaths = list(nx.shortest_simple_paths(G, 1, 4))\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_ssp_source_missing", "data": "def test_ssp_source_missing():\n\tG = nx.Graph()\n\tnx.add_path(G, [0, 1, 2])\n\tnx.add_path(G, [3, 4, 5])\n\tpaths = list(nx.shortest_simple_paths(G, 0, 3))\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_bidirectional_shortest_path_restricted", "data": "def test_bidirectional_shortest_path_restricted():\n\tgrid = cnlti(nx.grid_2d_graph(4,4), first_label=1, ordering=\"sorted\")\n\tcycle = nx.cycle_graph(7)\n\tdirected_cycle = nx.cycle_graph(7, create_using=nx.DiGraph())\n\tlength, path = _bidirectional_shortest_path(cycle, 0, 3)\n\tassert_equal(path, [0, 1, 2, 3])\n\tlength, path = _bidirectional_shortest_path(cycle, 0, 3, ignore_nodes=[1])\n\tassert_equal(path, [0, 6, 5, 4, 3])\n\tlength, path = _bidirectional_shortest_path(grid, 1, 12)\n\tassert_equal(path, [1, 2, 3, 4, 8, 12])\n\tlength, path = _bidirectional_shortest_path(grid, 1, 12, ignore_nodes=[2])\n\tassert_equal(path, [1, 5, 6, 10, 11, 12])\n\tlength, path = _bidirectional_shortest_path(grid, 1, 12, ignore_nodes=[2, 6])\n\tassert_equal(path, [1, 5, 9, 10, 11, 12])\n\tlength, path = _bidirectional_shortest_path(grid, 1, 12,\n\t\t\t\t\t\t\t\t\t\t\t\tignore_nodes=[2, 6],\n\t\t\t\t\t\t\t\t\t\t\t\tignore_edges=[(10, 11)])\n\tassert_equal(path, [1, 5, 9, 10, 14, 15, 16, 12])\n\tlength, path = _bidirectional_shortest_path(directed_cycle, 0, 3)\n\tassert_equal(path, [0, 1, 2, 3])\n\tassert_raises(\n\t\tnx.NetworkXNoPath,\n\t\t_bidirectional_shortest_path,\n\t\tdirected_cycle,\n\t\t0, 3,\n\t\tignore_nodes=[1],\n\t)\n\tlength, path = _bidirectional_shortest_path(directed_cycle, 0, 3,\n\t\t\t\t\t\t\t\t\t\t\t\tignore_edges=[(2, 1)])\n\tassert_equal(path, [0, 1, 2, 3])\n\tassert_raises(\n\t\tnx.NetworkXNoPath,\n\t\t_bidirectional_shortest_path,\n\t\tdirected_cycle,\n\t\t0, 3,\n\t\tignore_edges=[(1, 2)],\n\t)\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "validate_path", "data": "def validate_path(G, s, t, soln_len, path):\n\tassert_equal(path[0], s)\n\tassert_equal(path[-1], t)\n\tassert_equal(soln_len, sum(G[u][v].get('weight', 1)\n\t\t\t\t\tfor u, v in zip(path[:-1], path[1:])))\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "validate_length_path", "data": "def validate_length_path(G, s, t, soln_len, length, path):\n\tassert_equal(soln_len, length)\n\tvalidate_path(G, s, t, length, path)\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_bidirectional_dijksta_restricted", "data": "def test_bidirectional_dijksta_restricted():\n\tXG = nx.DiGraph()\n\tXG.add_weighted_edges_from([('s', 'u', 10), ('s', 'x', 5),\n\t\t\t\t\t\t\t\t('u', 'v', 1), ('u', 'x', 2),\n\t\t\t\t\t\t\t\t('v', 'y', 1), ('x', 'u', 3),\n\t\t\t\t\t\t\t\t('x', 'v', 5), ('x', 'y', 2),\n\t\t\t\t\t\t\t\t('y', 's', 7), ('y', 'v', 6)])\n\n\tXG3 = nx.Graph()\n\tXG3.add_weighted_edges_from([[0, 1, 2], [1, 2, 12],\n\t\t\t\t\t\t\t\t [2, 3, 1], [3, 4, 5],\n\t\t\t\t\t\t\t\t [4, 5, 1], [5, 0, 10]])\n\tvalidate_length_path(XG, 's', 'v', 9,\n\t\t\t\t\t\t *_bidirectional_dijkstra(XG, 's', 'v'))\n\tvalidate_length_path(XG, 's', 'v', 10,\n\t\t\t\t\t\t *_bidirectional_dijkstra(XG, 's', 'v', ignore_nodes=['u']))\n\tvalidate_length_path(XG, 's', 'v', 11,\n\t\t\t\t\t\t *_bidirectional_dijkstra(XG, 's', 'v', ignore_edges=[('s', 'x')]))\n\tassert_raises(\n\t\tnx.NetworkXNoPath,\n\t\t_bidirectional_dijkstra,\n\t\tXG,\n\t\t's', 'v',\n\t\tignore_nodes=['u'],\n\t\tignore_edges=[('s', 'x')],\n\t)\n\tvalidate_length_path(XG3, 0, 3, 15, *_bidirectional_dijkstra(XG3, 0, 3))\n\tvalidate_length_path(XG3, 0, 3, 16,\n\t\t\t\t\t\t *_bidirectional_dijkstra(XG3, 0, 3, ignore_nodes=[1]))\n\tvalidate_length_path(XG3, 0, 3, 16,\n\t\t\t\t\t\t *_bidirectional_dijkstra(XG3, 0, 3, ignore_edges=[(2, 3)]))\n\tassert_raises(\n\t\tnx.NetworkXNoPath,\n\t\t_bidirectional_dijkstra,\n\t\tXG3,\n\t\t0, 3,\n\t\tignore_nodes=[1],\n\t\tignore_edges=[(5, 4)],\n\t)\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_bidirectional_dijkstra_no_path", "data": "def test_bidirectional_dijkstra_no_path():\n\tG = nx.Graph()\n\tnx.add_path(G, [1, 2, 3])\n\tnx.add_path(G, [4, 5, 6])\n\tpath = _bidirectional_dijkstra(G, 1, 6)\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}], [], [{"term": "def", "name": "SimplePoint", "data": "def SimplePoint():\n\tnewpoints = []\n\n\tnewpoints.append([0.0, 0.0, 0.0])\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy_extras import object_utils", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *", "\tfrom bpy.utils import register_class", "\tfrom bpy.utils import unregister_class"]}, {"term": "def", "name": "SimpleLine", "data": "def SimpleLine(c1=[0.0, 0.0, 0.0], c2=[2.0, 2.0, 2.0]):\n\tnewpoints = []\n\n\tc3 = Vector(c2) - Vector(c1)\n\tnewpoints.append([0.0, 0.0, 0.0])\n\tnewpoints.append([c3[0], c3[1], c3[2]])\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy_extras import object_utils", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *", "\tfrom bpy.utils import register_class", "\tfrom bpy.utils import unregister_class"]}, {"term": "def", "name": "SimpleAngle", "data": "def SimpleAngle(length=1.0, angle=45.0):\n\tnewpoints = []\n\n\tangle = radians(angle)\n\tnewpoints.append([length, 0.0, 0.0])\n\tnewpoints.append([0.0, 0.0, 0.0])\n\tnewpoints.append([length * cos(angle), length * sin(angle), 0.0])\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy_extras import object_utils", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *", "\tfrom bpy.utils import register_class", "\tfrom bpy.utils import unregister_class"]}, {"term": "def", "name": "SimpleDistance", "data": "def SimpleDistance(length=1.0, center=True):\n\tnewpoints = []\n\n\tif center:\n\t\tnewpoints.append([-length / 2, 0.0, 0.0])\n\t\tnewpoints.append([length / 2, 0.0, 0.0])\n\telse:\n\t\tnewpoints.append([0.0, 0.0, 0.0])\n\t\tnewpoints.append([length, 0.0, 0.0])\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy_extras import object_utils", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *", "\tfrom bpy.utils import register_class", "\tfrom bpy.utils import unregister_class"]}, {"term": "def", "name": "SimpleCircle", "data": "def SimpleCircle(sides=4, radius=1.0):\n\tnewpoints = []\n\n\tangle = radians(360) / sides\n\tnewpoints.append([radius, 0, 0])\n\tif radius != 0 :\n\t\tj = 1\n\t\twhile j < sides:\n\t\t\tt = angle * j\n\t\t\tx = cos(t) * radius\n\t\t\ty = sin(t) * radius\n\t\t\tnewpoints.append([x, y, 0])\n\t\t\tj += 1\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy_extras import object_utils", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *", "\tfrom bpy.utils import register_class", "\tfrom bpy.utils import unregister_class"]}, {"term": "def", "name": "SimpleEllipse", "data": "def SimpleEllipse(a=2.0, b=1.0):\n\tnewpoints = []\n\n\tnewpoints.append([a, 0.0, 0.0])\n\tnewpoints.append([0.0, b, 0.0])\n\tnewpoints.append([-a, 0.0, 0.0])\n\tnewpoints.append([0.0, -b, 0.0])\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy_extras import object_utils", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *", "\tfrom bpy.utils import register_class", "\tfrom bpy.utils import unregister_class"]}, {"term": "def", "name": "SimpleArc", "data": "def SimpleArc(sides=0, radius=1.0, startangle=0.0, endangle=45.0):\n\tnewpoints = []\n\n\tstartangle = radians(startangle)\n\tendangle = radians(endangle)\n\tsides += 1\n\n\tangle = (endangle - startangle) / sides\n\tx = cos(startangle) * radius\n\ty = sin(startangle) * radius\n\tnewpoints.append([x, y, 0])\n\tj = 1\n\twhile j < sides:\n\t\tt = angle * j\n\t\tx = cos(t + startangle) * radius\n\t\ty = sin(t + startangle) * radius\n\t\tnewpoints.append([x, y, 0])\n\t\tj += 1\n\tx = cos(endangle) * radius\n\ty = sin(endangle) * radius\n\tnewpoints.append([x, y, 0])\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy_extras import object_utils", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *", "\tfrom bpy.utils import register_class", "\tfrom bpy.utils import unregister_class"]}, {"term": "def", "name": "SimpleSector", "data": "def SimpleSector(sides=0, radius=1.0, startangle=0.0, endangle=45.0):\n\tnewpoints = []\n\n\tstartangle = radians(startangle)\n\tendangle = radians(endangle)\n\tsides += 1\n\n\tnewpoints.append([0, 0, 0])\n\tangle = (endangle - startangle) / sides\n\tx = cos(startangle) * radius\n\ty = sin(startangle) * radius\n\tnewpoints.append([x, y, 0])\n\tj = 1\n\twhile j < sides:\n\t\tt = angle * j\n\t\tx = cos(t + startangle) * radius\n\t\ty = sin(t + startangle) * radius\n\t\tnewpoints.append([x, y, 0])\n\t\tj += 1\n\tx = cos(endangle) * radius\n\ty = sin(endangle) * radius\n\tnewpoints.append([x, y, 0])\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy_extras import object_utils", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *", "\tfrom bpy.utils import register_class", "\tfrom bpy.utils import unregister_class"]}, {"term": "def", "name": "SimpleSegment", "data": "def SimpleSegment(sides=0, a=2.0, b=1.0, startangle=0.0, endangle=45.0):\n\tnewpoints = []\n\n\tstartangle = radians(startangle)\n\tendangle = radians(endangle)\n\tsides += 1\n\n\tangle = (endangle - startangle) / sides\n\tx = cos(startangle) * a\n\ty = sin(startangle) * a\n\tnewpoints.append([x, y, 0])\n\tj = 1\n\twhile j < sides:\n\t\tt = angle * j\n\t\tx = cos(t + startangle) * a\n\t\ty = sin(t + startangle) * a\n\t\tnewpoints.append([x, y, 0])\n\t\tj += 1\n\tx = cos(endangle) * a\n\ty = sin(endangle) * a\n\tnewpoints.append([x, y, 0])\n\n\tx = cos(endangle) * b\n\ty = sin(endangle) * b\n\tnewpoints.append([x, y, 0])\n\tj = sides - 1\n\twhile j > 0:\n\t\tt = angle * j\n\t\tx = cos(t + startangle) * b\n\t\ty = sin(t + startangle) * b\n\t\tnewpoints.append([x, y, 0])\n\t\tj -= 1\n\tx = cos(startangle) * b\n\ty = sin(startangle) * b\n\tnewpoints.append([x, y, 0])\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy_extras import object_utils", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *", "\tfrom bpy.utils import register_class", "\tfrom bpy.utils import unregister_class"]}, {"term": "def", "name": "SimpleRectangle", "data": "def SimpleRectangle(width=2.0, length=2.0, rounded=0.0, center=True):\n\tnewpoints = []\n\n\tr = rounded / 2\n\n\tif center:\n\t\tx = width / 2\n\t\ty = length / 2\n\t\tif rounded != 0.0:\n\t\t\tnewpoints.append([-x + r, y, 0.0])\n\t\t\tnewpoints.append([x - r, y, 0.0])\n\t\t\tnewpoints.append([x, y - r, 0.0])\n\t\t\tnewpoints.append([x, -y + r, 0.0])\n\t\t\tnewpoints.append([x - r, -y, 0.0])\n\t\t\tnewpoints.append([-x + r, -y, 0.0])\n\t\t\tnewpoints.append([-x, -y + r, 0.0])\n\t\t\tnewpoints.append([-x, y - r, 0.0])\n\t\telse:\n\t\t\tnewpoints.append([-x, y, 0.0])\n\t\t\tnewpoints.append([x, y, 0.0])\n\t\t\tnewpoints.append([x, -y, 0.0])\n\t\t\tnewpoints.append([-x, -y, 0.0])\n\n\telse:\n\t\tx = width\n\t\ty = length\n\t\tif rounded != 0.0:\n\t\t\tnewpoints.append([r, y, 0.0])\n\t\t\tnewpoints.append([x - r, y, 0.0])\n\t\t\tnewpoints.append([x, y - r, 0.0])\n\t\t\tnewpoints.append([x, r, 0.0])\n\t\t\tnewpoints.append([x - r, 0.0, 0.0])\n\t\t\tnewpoints.append([r, 0.0, 0.0])\n\t\t\tnewpoints.append([0.0, r, 0.0])\n\t\t\tnewpoints.append([0.0, y - r, 0.0])\n\t\telse:\n\t\t\tnewpoints.append([0.0, 0.0, 0.0])\n\t\t\tnewpoints.append([0.0, y, 0.0])\n\t\t\tnewpoints.append([x, y, 0.0])\n\t\t\tnewpoints.append([x, 0.0, 0.0])\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy_extras import object_utils", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *", "\tfrom bpy.utils import register_class", "\tfrom bpy.utils import unregister_class"]}, {"term": "def", "name": "SimpleRhomb", "data": "def SimpleRhomb(width=2.0, length=2.0, center=True):\n\tnewpoints = []\n\tx = width / 2\n\ty = length / 2\n\n\tif center:\n\t\tnewpoints.append([-x, 0.0, 0.0])\n\t\tnewpoints.append([0.0, y, 0.0])\n\t\tnewpoints.append([x, 0.0, 0.0])\n\t\tnewpoints.append([0.0, -y, 0.0])\n\telse:\n\t\tnewpoints.append([x, 0.0, 0.0])\n\t\tnewpoints.append([0.0, y, 0.0])\n\t\tnewpoints.append([x, length, 0.0])\n\t\tnewpoints.append([width, y, 0.0])\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy_extras import object_utils", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *", "\tfrom bpy.utils import register_class", "\tfrom bpy.utils import unregister_class"]}, {"term": "def", "name": "SimplePolygon", "data": "def SimplePolygon(sides=3, radius=1.0):\n\tnewpoints = []\n\tangle = radians(360.0) / sides\n\tj = 0\n\n\twhile j < sides:\n\t\tt = angle * j\n\t\tx = sin(t) * radius\n\t\ty = cos(t) * radius\n\t\tnewpoints.append([x, y, 0.0])\n\t\tj += 1\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy_extras import object_utils", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *", "\tfrom bpy.utils import register_class", "\tfrom bpy.utils import unregister_class"]}, {"term": "def", "name": "SimplePolygon_ab", "data": "def SimplePolygon_ab(sides=3, a=2.0, b=1.0):\n\tnewpoints = []\n\tangle = radians(360.0) / sides\n\tj = 0\n\n\twhile j < sides:\n\t\tt = angle * j\n\t\tx = sin(t) * a\n\t\ty = cos(t) * b\n\t\tnewpoints.append([x, y, 0.0])\n\t\tj += 1\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy_extras import object_utils", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *", "\tfrom bpy.utils import register_class", "\tfrom bpy.utils import unregister_class"]}, {"term": "def", "name": "SimpleTrapezoid", "data": "def SimpleTrapezoid(a=2.0, b=1.0, h=1.0, center=True):\n\tnewpoints = []\n\tx = a / 2\n\ty = b / 2\n\tr = h / 2\n\n\tif center:\n\t\tnewpoints.append([-x, -r, 0.0])\n\t\tnewpoints.append([-y, r, 0.0])\n\t\tnewpoints.append([y, r, 0.0])\n\t\tnewpoints.append([x, -r, 0.0])\n\n\telse:\n\t\tnewpoints.append([0.0, 0.0, 0.0])\n\t\tnewpoints.append([x - y, h, 0.0])\n\t\tnewpoints.append([x + y, h, 0.0])\n\t\tnewpoints.append([a, 0.0, 0.0])\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy_extras import object_utils", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *", "\tfrom bpy.utils import register_class", "\tfrom bpy.utils import unregister_class"]}, {"term": "def", "name": "vertsToPoints", "data": "def vertsToPoints(Verts, splineType):\n\n\t# main vars\n\tvertArray = []\n\n\t# array for BEZIER spline output (V3)\n\tif splineType == 'BEZIER':\n\t\tfor v in Verts:\n\t\t\tvertArray += v\n\n\t# array for nonBEZIER output (V4)\n\telse:\n\t\tfor v in Verts:\n\t\t\tvertArray += v\n\t\t\tif splineType == 'NURBS':\n\t\t\t\t# for nurbs w=1\n\t\t\t\tvertArray.append(1)\n\t\t\telse:\n\t\t\t\t# for poly w=0\n\t\t\t\tvertArray.append(0)\n\treturn vertArray\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy_extras import object_utils", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *", "\tfrom bpy.utils import register_class", "\tfrom bpy.utils import unregister_class"]}, {"term": "def", "name": "main", "data": "def main(context, self, use_enter_edit_mode):\n\t# output splineType 'POLY' 'NURBS' 'BEZIER'\n\tsplineType = self.outputType\n\n\tsides = abs(int((self.Simple_endangle - self.Simple_startangle) / 90))\n\n\t# get verts\n\tif self.Simple_Type == 'Point':\n\t\tverts = SimplePoint()\n\n\tif self.Simple_Type == 'Line':\n\t\tverts = SimpleLine(self.location, self.Simple_endlocation)\n\n\tif self.Simple_Type == 'Distance':\n\t\tverts = SimpleDistance(self.Simple_length, self.Simple_center)\n\n\tif self.Simple_Type == 'Angle':\n\t\tverts = SimpleAngle(self.Simple_length, self.Simple_angle)\n\n\tif self.Simple_Type == 'Circle':\n\t\tif self.Simple_sides < 4:\n\t\t\tself.Simple_sides = 4\n\t\tif self.Simple_radius == 0:\n\t\t\treturn {'FINISHED'}\n\t\tverts = SimpleCircle(self.Simple_sides, self.Simple_radius)\n\n\tif self.Simple_Type == 'Ellipse':\n\t\tverts = SimpleEllipse(self.Simple_a, self.Simple_b)\n\n\tif self.Simple_Type == 'Arc':\n\t\tif self.Simple_sides < sides:\n\t\t\tself.Simple_sides = sides\n\t\tif self.Simple_radius == 0:\n\t\t\treturn {'FINISHED'}\n\t\tverts = SimpleArc(\n\t\t\t\t\tself.Simple_sides, self.Simple_radius,\n\t\t\t\t\tself.Simple_startangle, self.Simple_endangle\n\t\t\t\t\t)\n\n\tif self.Simple_Type == 'Sector':\n\t\tif self.Simple_sides < sides:\n\t\t\tself.Simple_sides = sides\n\t\tif self.Simple_radius == 0:\n\t\t\treturn {'FINISHED'}\n\t\tverts = SimpleSector(\n\t\t\t\t\tself.Simple_sides, self.Simple_radius,\n\t\t\t\t\tself.Simple_startangle, self.Simple_endangle\n\t\t\t\t\t)\n\n\tif self.Simple_Type == 'Segment':\n\t\tif self.Simple_sides < sides:\n\t\t\tself.Simple_sides = sides\n\t\tif self.Simple_a == 0 or self.Simple_b == 0 or self.Simple_a == self.Simple_b:\n\t\t\treturn {'FINISHED'}\n\t\tif self.Simple_a > self.Simple_b:\n\t\t\tverts = SimpleSegment(\n\t\t\t\t\tself.Simple_sides, self.Simple_a, self.Simple_b,\n\t\t\t\t\tself.Simple_startangle, self.Simple_endangle\n\t\t\t\t\t)\n\t\tif self.Simple_a < self.Simple_b:\n\t\t\tverts = SimpleSegment(\n\t\t\t\t\tself.Simple_sides, self.Simple_b, self.Simple_a,\n\t\t\t\t\tself.Simple_startangle, self.Simple_endangle\n\t\t\t\t\t)\n\n\tif self.Simple_Type == 'Rectangle':\n\t\tverts = SimpleRectangle(\n\t\t\t\t\tself.Simple_width, self.Simple_length,\n\t\t\t\t\tself.Simple_rounded, self.Simple_center\n\t\t\t\t\t)\n\n\tif self.Simple_Type == 'Rhomb':\n\t\tverts = SimpleRhomb(\n\t\t\t\t\tself.Simple_width, self.Simple_length, self.Simple_center\n\t\t\t\t\t)\n\n\tif self.Simple_Type == 'Polygon':\n\t\tif self.Simple_sides < 3:\n\t\t\tself.Simple_sides = 3\n\t\tverts = SimplePolygon(\n\t\t\t\t\tself.Simple_sides, self.Simple_radius\n\t\t\t\t\t)\n\n\tif self.Simple_Type == 'Polygon_ab':\n\t\tif self.Simple_sides < 3:\n\t\t\tself.Simple_sides = 3\n\t\tverts = SimplePolygon_ab(\n\t\t\t\t\tself.Simple_sides, self.Simple_a, self.Simple_b\n\t\t\t\t\t)\n\n\tif self.Simple_Type == 'Trapezoid':\n\t\tverts = SimpleTrapezoid(\n\t\t\t\t\tself.Simple_a, self.Simple_b, self.Simple_h, self.Simple_center\n\t\t\t\t\t)\n\n\t# turn verts into array\n\tvertArray = vertsToPoints(verts, splineType)\n\n\t# create object\n\tif bpy.context.mode == 'EDIT_CURVE':\n\n\t\tCurve = context.active_object\n\t\tnewSpline = Curve.data.splines.new(type=splineType)\t\t  # spline\n\telse:\n\t\tname = self.Simple_Type  # Type as name\n\n\t\tdataCurve = bpy.data.curves.new(name, type='CURVE')  # curve data block\n\t\tnewSpline = dataCurve.splines.new(type=splineType)\t\t  # spline\n\n\t\t# create object with new Curve\n\t\tCurve = object_utils.object_data_add(context, dataCurve, operator=self)  # place in active scene\n\t\tCurve.select_set(True)\n\n\tfor spline in Curve.data.splines:\n\t\tif spline.type == 'BEZIER':\n\t\t\tfor point in spline.bezier_points:\n\t\t\t\tpoint.select_control_point = False\n\t\t\t\tpoint.select_left_handle = False\n\t\t\t\tpoint.select_right_handle = False\n\t\telse:\n\t\t\tfor point in spline.points:\n\t\t\t\tpoint.select = False\n\n\t# create spline from vertarray\n\tall_points = []\n\tif splineType == 'BEZIER':\n\t\tnewSpline.bezier_points.add(int(len(vertArray) * 0.33))\n\t\tnewSpline.bezier_points.foreach_set('co', vertArray)\n\t\tfor point in newSpline.bezier_points:\n\t\t\tpoint.handle_right_type = self.handleType\n\t\t\tpoint.handle_left_type = self.handleType\n\t\t\tpoint.select_control_point = True\n\t\t\tpoint.select_left_handle = True\n\t\t\tpoint.select_right_handle = True\n\t\t\tall_points.append(point)\n\telse:\n\t\tnewSpline.points.add(int(len(vertArray) * 0.25 - 1))\n\t\tnewSpline.points.foreach_set('co', vertArray)\n\t\tnewSpline.use_endpoint_u = True\n\t\tfor point in newSpline.points:\n\t\t\tall_points.append(point)\n\t\t\tpoint.select = True\n\n\tn = len(all_points)\n\n\td = 2 * 0.27606262\n\n\tif splineType == 'BEZIER':\n\t\tif self.Simple_Type == 'Circle' or self.Simple_Type == 'Arc' or \\\n\t\t   self.Simple_Type == 'Sector' or self.Simple_Type == 'Segment' or \\\n\t\t   self.Simple_Type == 'Ellipse':\n\n\t\t\tfor p in all_points:\n\t\t\t\tp.handle_right_type = 'FREE'\n\t\t\t\tp.handle_left_type = 'FREE'\n\n\t\tif self.Simple_Type == 'Circle':\n\t\t\ti = 0\n\t\t\tfor p1 in all_points:\n\t\t\t\tif i != (n - 1):\n\t\t\t\t\tp2 = all_points[i + 1]\n\t\t\t\t\tu1 = asin(p1.co.y / self.Simple_radius)\n\t\t\t\t\tu2 = asin(p2.co.y / self.Simple_radius)\n\t\t\t\t\tif p1.co.x > 0 and p2.co.x < 0:\n\t\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\t\telif p1.co.x < 0 and p2.co.x > 0:\n\t\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\t\tu = u2 - u1\n\t\t\t\t\tif u < 0:\n\t\t\t\t\t\tu = -u\n\t\t\t\t\tl = 4 / 3 * tan(1 / 4 * u) * self.Simple_radius\n\t\t\t\t\tv1 = Vector((-p1.co.y, p1.co.x, 0))\n\t\t\t\t\tv1.normalize()\n\t\t\t\t\tv2 = Vector((-p2.co.y, p2.co.x, 0))\n\t\t\t\t\tv2.normalize()\n\t\t\t\t\tvh1 = v1 * l\n\t\t\t\t\tvh2 = v2 * l\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) + vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) - vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\t\t\t\tif i == (n - 1):\n\t\t\t\t\tp2 = all_points[0]\n\t\t\t\t\tu1 = asin(p1.co.y / self.Simple_radius)\n\t\t\t\t\tu2 = asin(p2.co.y / self.Simple_radius)\n\t\t\t\t\tif p1.co.x > 0 and p2.co.x < 0:\n\t\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\t\telif p1.co.x < 0 and p2.co.x > 0:\n\t\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\t\tu = u2 - u1\n\t\t\t\t\tif u < 0:\n\t\t\t\t\t\tu = -u\n\t\t\t\t\tl = 4 / 3 * tan(1 / 4 * u) * self.Simple_radius\n\t\t\t\t\tv1 = Vector((-p1.co.y, p1.co.x, 0))\n\t\t\t\t\tv1.normalize()\n\t\t\t\t\tv2 = Vector((-p2.co.y, p2.co.x, 0))\n\t\t\t\t\tv2.normalize()\n\t\t\t\t\tvh1 = v1 * l\n\t\t\t\t\tvh2 = v2 * l\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) + vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) - vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\t\t\t\ti += 1\n\n\t\tif self.Simple_Type == 'Ellipse':\n\t\t\tall_points[0].handle_right = Vector((self.Simple_a, self.Simple_b * d, 0))\n\t\t\tall_points[0].handle_left = Vector((self.Simple_a, -self.Simple_b * d, 0))\n\t\t\tall_points[1].handle_right = Vector((-self.Simple_a * d, self.Simple_b, 0))\n\t\t\tall_points[1].handle_left = Vector((self.Simple_a * d, self.Simple_b, 0))\n\t\t\tall_points[2].handle_right = Vector((-self.Simple_a, -self.Simple_b * d, 0))\n\t\t\tall_points[2].handle_left = Vector((-self.Simple_a, self.Simple_b * d, 0))\n\t\t\tall_points[3].handle_right = Vector((self.Simple_a * d, -self.Simple_b, 0))\n\t\t\tall_points[3].handle_left = Vector((-self.Simple_a * d, -self.Simple_b, 0))\n\n\t\tif self.Simple_Type == 'Arc':\n\t\t\ti = 0\n\t\t\tfor p1 in all_points:\n\t\t\t\tif i != (n - 1):\n\t\t\t\t\tp2 = all_points[i + 1]\n\t\t\t\t\tu1 = asin(p1.co.y / self.Simple_radius)\n\t\t\t\t\tu2 = asin(p2.co.y / self.Simple_radius)\n\t\t\t\t\tif p1.co.x > 0 and p2.co.x < 0:\n\t\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\t\telif p1.co.x < 0 and p2.co.x > 0:\n\t\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\t\tu = u2 - u1\n\t\t\t\t\tif u < 0:\n\t\t\t\t\t\tu = -u\n\t\t\t\t\tl = 4 / 3 * tan(1 / 4 * u) * self.Simple_radius\n\t\t\t\t\tv1 = Vector((-p1.co.y, p1.co.x, 0))\n\t\t\t\t\tv1.normalize()\n\t\t\t\t\tv2 = Vector((-p2.co.y, p2.co.x, 0))\n\t\t\t\t\tv2.normalize()\n\t\t\t\t\tvh1 = v1 * l\n\t\t\t\t\tvh2 = v2 * l\n\t\t\t\t\tif self.Simple_startangle < self.Simple_endangle:\n\t\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) + vh1\n\t\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) - vh2\n\t\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\t\tp2.handle_left = v2\n\t\t\t\t\telse:\n\t\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) - vh1\n\t\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) + vh2\n\t\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\t\tp2.handle_left = v2\n\t\t\t\ti += 1\n\t\t\tall_points[0].handle_left_type = 'VECTOR'\n\t\t\tall_points[-1].handle_right_type = 'VECTOR'\n\n\t\tif self.Simple_Type == 'Sector':\n\t\t\ti = 0\n\t\t\tfor p1 in all_points:\n\t\t\t\tif i == 0:\n\t\t\t\t\tp1.handle_right_type = 'VECTOR'\n\t\t\t\t\tp1.handle_left_type = 'VECTOR'\n\t\t\t\telif i != (n - 1):\n\t\t\t\t\tp2 = all_points[i + 1]\n\t\t\t\t\tu1 = asin(p1.co.y / self.Simple_radius)\n\t\t\t\t\tu2 = asin(p2.co.y / self.Simple_radius)\n\t\t\t\t\tif p1.co.x > 0 and p2.co.x < 0:\n\t\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\t\telif p1.co.x < 0 and p2.co.x > 0:\n\t\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\t\tu = u2 - u1\n\t\t\t\t\tif u < 0:\n\t\t\t\t\t\tu = -u\n\t\t\t\t\tl = 4 / 3 * tan(1 / 4 * u) * self.Simple_radius\n\t\t\t\t\tv1 = Vector((-p1.co.y, p1.co.x, 0))\n\t\t\t\t\tv1.normalize()\n\t\t\t\t\tv2 = Vector((-p2.co.y, p2.co.x, 0))\n\t\t\t\t\tv2.normalize()\n\t\t\t\t\tvh1 = v1 * l\n\t\t\t\t\tvh2 = v2 * l\n\t\t\t\t\tif self.Simple_startangle < self.Simple_endangle:\n\t\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) + vh1\n\t\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) - vh2\n\t\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\t\tp2.handle_left = v2\n\t\t\t\t\telse:\n\t\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) - vh1\n\t\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) + vh2\n\t\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\t\tp2.handle_left = v2\n\t\t\t\ti += 1\n\t\t\tall_points[0].handle_left_type = 'VECTOR'\n\t\t\tall_points[0].handle_right_type = 'VECTOR'\n\t\t\tall_points[1].handle_left_type = 'VECTOR'\n\t\t\tall_points[-1].handle_right_type = 'VECTOR'\n\n\t\tif self.Simple_Type == 'Segment':\n\t\t\ti = 0\n\t\t\tif self.Simple_a > self.Simple_b:\n\t\t\t\tSegment_a = self.Simple_a\n\t\t\t\tSegment_b = self.Simple_b\n\t\t\tif self.Simple_a < self.Simple_b:\n\t\t\t\tSegment_b = self.Simple_a\n\t\t\t\tSegment_a = self.Simple_b\n\t\t\tfor p1 in all_points:\n\t\t\t\tif i < (n / 2 - 1):\n\t\t\t\t\tp2 = all_points[i + 1]\n\t\t\t\t\tu1 = asin(p1.co.y / Segment_a)\n\t\t\t\t\tu2 = asin(p2.co.y / Segment_a)\n\t\t\t\t\tif p1.co.x > 0 and p2.co.x < 0:\n\t\t\t\t\t\tu1 = acos(p1.co.x / Segment_a)\n\t\t\t\t\t\tu2 = acos(p2.co.x / Segment_a)\n\t\t\t\t\telif p1.co.x < 0 and p2.co.x > 0:\n\t\t\t\t\t\tu1 = acos(p1.co.x / Segment_a)\n\t\t\t\t\t\tu2 = acos(p2.co.x / Segment_a)\n\t\t\t\t\tu = u2 - u1\n\t\t\t\t\tif u < 0:\n\t\t\t\t\t\tu = -u\n\t\t\t\t\tl = 4 / 3 * tan(1 / 4 * u) * Segment_a\n\t\t\t\t\tv1 = Vector((-p1.co.y, p1.co.x, 0))\n\t\t\t\t\tv1.normalize()\n\t\t\t\t\tv2 = Vector((-p2.co.y, p2.co.x, 0))\n\t\t\t\t\tv2.normalize()\n\t\t\t\t\tvh1 = v1 * l\n\t\t\t\t\tvh2 = v2 * l\n\t\t\t\t\tif self.Simple_startangle < self.Simple_endangle:\n\t\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) + vh1\n\t\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) - vh2\n\t\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\t\tp2.handle_left = v2\n\t\t\t\t\telse:\n\t\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) - vh1\n\t\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) + vh2\n\t\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\t\tp2.handle_left = v2\n\t\t\t\telif i != (n / 2 - 1) and i != (n - 1):\n\t\t\t\t\tp2 = all_points[i + 1]\n\t\t\t\t\tu1 = asin(p1.co.y / Segment_b)\n\t\t\t\t\tu2 = asin(p2.co.y / Segment_b)\n\t\t\t\t\tif p1.co.x > 0 and p2.co.x < 0:\n\t\t\t\t\t\tu1 = acos(p1.co.x / Segment_b)\n\t\t\t\t\t\tu2 = acos(p2.co.x / Segment_b)\n\t\t\t\t\telif p1.co.x < 0 and p2.co.x > 0:\n\t\t\t\t\t\tu1 = acos(p1.co.x / Segment_b)\n\t\t\t\t\t\tu2 = acos(p2.co.x / Segment_b)\n\t\t\t\t\tu = u2 - u1\n\t\t\t\t\tif u < 0:\n\t\t\t\t\t\tu = -u\n\t\t\t\t\tl = 4 / 3 * tan(1 / 4 * u) * Segment_b\n\t\t\t\t\tv1 = Vector((-p1.co.y, p1.co.x, 0))\n\t\t\t\t\tv1.normalize()\n\t\t\t\t\tv2 = Vector((-p2.co.y, p2.co.x, 0))\n\t\t\t\t\tv2.normalize()\n\t\t\t\t\tvh1 = v1 * l\n\t\t\t\t\tvh2 = v2 * l\n\t\t\t\t\tif self.Simple_startangle < self.Simple_endangle:\n\t\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) - vh1\n\t\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) + vh2\n\t\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\t\tp2.handle_left = v2\n\t\t\t\t\telse:\n\t\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) + vh1\n\t\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) - vh2\n\t\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\t\tp2.handle_left = v2\n\n\t\t\t\ti += 1\n\t\t\tall_points[0].handle_left_type = 'VECTOR'\n\t\t\tall_points[n - 1].handle_right_type = 'VECTOR'\n\t\t\tall_points[int(n / 2) - 1].handle_right_type = 'VECTOR'\n\t\t\tall_points[int(n / 2)].handle_left_type = 'VECTOR'\n\n\t# set newSpline Options\n\tnewSpline.use_cyclic_u = self.use_cyclic_u\n\tnewSpline.use_endpoint_u = self.endp_u\n\tnewSpline.order_u = self.order_u\n\n\t# set curve Options\n\tCurve.data.dimensions = self.shape\n\tCurve.data.use_path = True\n\tif self.shape == '3D':\n\t\tCurve.data.fill_mode = 'FULL'\n\telse:\n\t\tCurve.data.fill_mode = 'BOTH'\n\n\t# move and rotate spline in edit mode\n\tif bpy.context.mode == 'EDIT_CURVE':\n\t\tif self.align == \"WORLD\":\n\t\t\tlocation = self.location - context.active_object.location\n\t\t\tbpy.ops.transform.translate(value = location, orient_type='GLOBAL')\n\t\t\tbpy.ops.transform.rotate(value = self.rotation[0], orient_axis = 'X', orient_type='GLOBAL')\n\t\t\tbpy.ops.transform.rotate(value = self.rotation[1], orient_axis = 'Y', orient_type='GLOBAL')\n\t\t\tbpy.ops.transform.rotate(value = self.rotation[2], orient_axis = 'Z', orient_type='GLOBAL')\n\n\t\telif self.align == \"VIEW\":\n\t\t\tbpy.ops.transform.translate(value = self.location)\n\t\t\tbpy.ops.transform.rotate(value = self.rotation[0], orient_axis = 'X')\n\t\t\tbpy.ops.transform.rotate(value = self.rotation[1], orient_axis = 'Y')\n\t\t\tbpy.ops.transform.rotate(value = self.rotation[2], orient_axis = 'Z')\n\n\t\telif self.align == \"CURSOR\":\n\t\t\tlocation = context.active_object.location\n\t\t\tself.location = bpy.context.scene.cursor.location - location\n\t\t\tself.rotation = bpy.context.scene.cursor.rotation_euler\n\n\t\t\tbpy.ops.transform.translate(value = self.location)\n\t\t\tbpy.ops.transform.rotate(value = self.rotation[0], orient_axis = 'X')\n\t\t\tbpy.ops.transform.rotate(value = self.rotation[1], orient_axis = 'Y')\n\t\t\tbpy.ops.transform.rotate(value = self.rotation[2], orient_axis = 'Z')\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy_extras import object_utils", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *", "\tfrom bpy.utils import register_class", "\tfrom bpy.utils import unregister_class"]}, {"term": "def", "name": "menu", "data": "def menu(self, context):\n\toper1 = self.layout.operator(Simple.bl_idname, text=\"Angle\", icon=\"DRIVER_ROTATIONAL_DIFFERENCE\")\n\toper1.Simple_Type = \"Angle\"\n\toper1.use_cyclic_u = False\n\n\toper2 = self.layout.operator(Simple.bl_idname, text=\"Arc\", icon=\"MOD_THICKNESS\")\n\toper2.Simple_Type = \"Arc\"\n\toper2.use_cyclic_u = False\n\n\toper3 = self.layout.operator(Simple.bl_idname, text=\"Circle\", icon=\"ANTIALIASED\")\n\toper3.Simple_Type = \"Circle\"\n\toper3.use_cyclic_u = True\n\n\toper4 = self.layout.operator(Simple.bl_idname, text=\"Distance\", icon=\"DRIVER_DISTANCE\")\n\toper4.Simple_Type = \"Distance\"\n\toper4.use_cyclic_u = False\n\n\toper5 = self.layout.operator(Simple.bl_idname, text=\"Ellipse\", icon=\"MESH_TORUS\")\n\toper5.Simple_Type = \"Ellipse\"\n\toper5.use_cyclic_u = True\n\n\toper6 = self.layout.operator(Simple.bl_idname, text=\"Line\", icon=\"MOD_SIMPLIFY\")\n\toper6.Simple_Type = \"Line\"\n\toper6.use_cyclic_u = False\n\toper6.shape = '3D'\n\n\toper7 = self.layout.operator(Simple.bl_idname, text=\"Point\", icon=\"LAYER_ACTIVE\")\n\toper7.Simple_Type = \"Point\"\n\toper7.use_cyclic_u = False\n\n\toper8 = self.layout.operator(Simple.bl_idname, text=\"Polygon\", icon=\"SEQ_CHROMA_SCOPE\")\n\toper8.Simple_Type = \"Polygon\"\n\toper8.use_cyclic_u = True\n\n\toper9 = self.layout.operator(Simple.bl_idname, text=\"Polygon ab\", icon=\"SEQ_CHROMA_SCOPE\")\n\toper9.Simple_Type = \"Polygon_ab\"\n\toper9.use_cyclic_u = True\n\n\toper10 = self.layout.operator(Simple.bl_idname, text=\"Rectangle\", icon=\"MESH_PLANE\")\n\toper10.Simple_Type = \"Rectangle\"\n\toper10.use_cyclic_u = True\n\n\toper11 = self.layout.operator(Simple.bl_idname, text=\"Rhomb\", icon=\"DECORATE_ANIMATE\")\n\toper11.Simple_Type = \"Rhomb\"\n\toper11.use_cyclic_u = True\n\n\toper12 = self.layout.operator(Simple.bl_idname, text=\"Sector\", icon=\"CON_SHRINKWRAP\")\n\toper12.Simple_Type = \"Sector\"\n\toper12.use_cyclic_u = True\n\n\toper13 = self.layout.operator(Simple.bl_idname, text=\"Segment\", icon=\"MOD_SIMPLEDEFORM\")\n\toper13.Simple_Type = \"Segment\"\n\toper13.use_cyclic_u = True\n\n\toper14 = self.layout.operator(Simple.bl_idname, text=\"Trapezoid\", icon=\"MOD_EDGESPLIT\")\n\toper14.Simple_Type = \"Trapezoid\"\n\toper14.use_cyclic_u = True\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy_extras import object_utils", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *", "\tfrom bpy.utils import register_class", "\tfrom bpy.utils import unregister_class"]}, {"term": "class", "name": "Simple", "data": "class Simple(Operator, object_utils.AddObjectHelper):\n\tbl_idname = \"curve.simple\"\n\tbl_label = \"Simple Curve\"\n\tbl_description = \"Construct a Simple Curve\"\n\tbl_options = {'REGISTER', 'UNDO', 'PRESET'}\n\n\t# change properties\n\tSimple : BoolProperty(\n\t\t\tname=\"Simple\",\n\t\t\tdefault=True,\n\t\t\tdescription=\"Simple Curve\"\n\t\t\t)\n\tSimple_Change : BoolProperty(\n\t\t\tname=\"Change\",\n\t\t\tdefault=False,\n\t\t\tdescription=\"Change Simple Curve\"\n\t\t\t)\n\tSimple_Delete : StringProperty(\n\t\t\tname=\"Delete\",\n\t\t\tdescription=\"Delete Simple Curve\"\n\t\t\t)\n\t# general properties\n\tTypes = [('Point', \"Point\", \"Construct a Point\"),\n\t\t\t ('Line', \"Line\", \"Construct a Line\"),\n\t\t\t ('Distance', \"Distance\", \"Construct a two point Distance\"),\n\t\t\t ('Angle', \"Angle\", \"Construct an Angle\"),\n\t\t\t ('Circle', \"Circle\", \"Construct a Circle\"),\n\t\t\t ('Ellipse', \"Ellipse\", \"Construct an Ellipse\"),\n\t\t\t ('Arc', \"Arc\", \"Construct an Arc\"),\n\t\t\t ('Sector', \"Sector\", \"Construct a Sector\"),\n\t\t\t ('Segment', \"Segment\", \"Construct a Segment\"),\n\t\t\t ('Rectangle', \"Rectangle\", \"Construct a Rectangle\"),\n\t\t\t ('Rhomb', \"Rhomb\", \"Construct a Rhomb\"),\n\t\t\t ('Polygon', \"Polygon\", \"Construct a Polygon\"),\n\t\t\t ('Polygon_ab', \"Polygon ab\", \"Construct a Polygon ab\"),\n\t\t\t ('Trapezoid', \"Trapezoid\", \"Construct a Trapezoid\")\n\t\t\t]\n\tSimple_Type : EnumProperty(\n\t\t\tname=\"Type\",\n\t\t\tdescription=\"Form of Curve to create\",\n\t\t\titems=Types\n\t\t\t)\n\t# Line properties\n\tSimple_endlocation : FloatVectorProperty(\n\t\t\tname=\"\",\n\t\t\tdescription=\"End location\",\n\t\t\tdefault=(2.0, 2.0, 2.0),\n\t\t\tsubtype='TRANSLATION'\n\t\t\t)\n\t# Trapezoid properties\n\tSimple_a : FloatProperty(\n\t\t\tname=\"Side a\",\n\t\t\tdefault=2.0,\n\t\t\tmin=0.0, soft_min=0.0,\n\t\t\tunit='LENGTH',\n\t\t\tdescription=\"a side Value\"\n\t\t\t)\n\tSimple_b : FloatProperty(\n\t\t\tname=\"Side b\",\n\t\t\tdefault=1.0,\n\t\t\tmin=0.0, soft_min=0.0,\n\t\t\tunit='LENGTH',\n\t\t\tdescription=\"b side Value\"\n\t\t\t)\n\tSimple_h : FloatProperty(\n\t\t\tname=\"Height\",\n\t\t\tdefault=1.0,\n\t\t\tunit='LENGTH',\n\t\t\tdescription=\"Height of the Trapezoid - distance between a and b\"\n\t\t\t)\n\tSimple_angle : FloatProperty(\n\t\t\tname=\"Angle\",\n\t\t\tdefault=45.0,\n\t\t\tdescription=\"Angle\"\n\t\t\t)\n\tSimple_startangle : FloatProperty(\n\t\t\tname=\"Start angle\",\n\t\t\tdefault=0.0,\n\t\t\tmin=-360.0, soft_min=-360.0,\n\t\t\tmax=360.0, soft_max=360.0,\n\t\t\tdescription=\"Start angle\"\n\t\t\t)\n\tSimple_endangle : FloatProperty(\n\t\t\tname=\"End angle\",\n\t\t\tdefault=45.0,\n\t\t\tmin=-360.0, soft_min=-360.0,\n\t\t\tmax=360.0, soft_max=360.0,\n\t\t\tdescription=\"End angle\"\n\t\t\t)\n\tSimple_sides : IntProperty(\n\t\t\tname=\"Sides\",\n\t\t\tdefault=3,\n\t\t\tmin=0, soft_min=0,\n\t\t\tdescription=\"Sides\"\n\t\t\t)\n\tSimple_radius : FloatProperty(\n\t\t\tname=\"Radius\",\n\t\t\tdefault=1.0,\n\t\t\tmin=0.0, soft_min=0.0,\n\t\t\tunit='LENGTH',\n\t\t\tdescription=\"Radius\"\n\t\t\t)\n\tSimple_center : BoolProperty(\n\t\t\tname=\"Length center\",\n\t\t\tdefault=True,\n\t\t\tdescription=\"Length center\"\n\t\t\t)\n\n\tAngle_types = [('Degrees', \"Degrees\", \"Use Degrees\"),\n\t\t\t\t   ('Radians', \"Radians\", \"Use Radians\")]\n\tSimple_degrees_or_radians : EnumProperty(\n\t\t\tname=\"Degrees or radians\",\n\t\t\tdescription=\"Degrees or radians\",\n\t\t\titems=Angle_types\n\t\t\t)\n\t# Rectangle properties\n\tSimple_width : FloatProperty(\n\t\t\tname=\"Width\",\n\t\t\tdefault=2.0,\n\t\t\tmin=0.0, soft_min=0,\n\t\t\tunit='LENGTH',\n\t\t\tdescription=\"Width\"\n\t\t\t)\n\tSimple_length : FloatProperty(\n\t\t\tname=\"Length\",\n\t\t\tdefault=2.0,\n\t\t\tmin=0.0, soft_min=0.0,\n\t\t\tunit='LENGTH',\n\t\t\tdescription=\"Length\"\n\t\t\t)\n\tSimple_rounded : FloatProperty(\n\t\t\tname=\"Rounded\",\n\t\t\tdefault=0.0,\n\t\t\tmin=0.0, soft_min=0.0,\n\t\t\tunit='LENGTH',\n\t\t\tdescription=\"Rounded corners\"\n\t\t\t)\n\t# Curve Options\n\tshapeItems = [\n\t\t('2D', \"2D\", \"2D shape Curve\"),\n\t\t('3D', \"3D\", \"3D shape Curve\")]\n\tshape : EnumProperty(\n\t\t\tname=\"2D / 3D\",\n\t\t\titems=shapeItems,\n\t\t\tdescription=\"2D or 3D Curve\"\n\t\t\t)\n\toutputType : EnumProperty(\n\t\t\tname=\"Output splines\",\n\t\t\tdescription=\"Type of splines to output\",\n\t\t\titems=[\n\t\t\t('POLY', \"Poly\", \"Poly Spline type\"),\n\t\t\t('NURBS', \"Nurbs\", \"Nurbs Spline type\"),\n\t\t\t('BEZIER', \"Bezier\", \"Bezier Spline type\")],\n\t\t\tdefault='BEZIER'\n\t\t\t)\n\tuse_cyclic_u : BoolProperty(\n\t\t\tname=\"Cyclic\",\n\t\t\tdefault=True,\n\t\t\tdescription=\"make curve closed\"\n\t\t\t)\n\tendp_u : BoolProperty(\n\t\t\tname=\"Use endpoint u\",\n\t\t\tdefault=True,\n\t\t\tdescription=\"stretch to endpoints\"\n\t\t\t)\n\torder_u : IntProperty(\n\t\t\tname=\"Order u\",\n\t\t\tdefault=4,\n\t\t\tmin=2, soft_min=2,\n\t\t\tmax=6, soft_max=6,\n\t\t\tdescription=\"Order of nurbs spline\"\n\t\t\t)\n\thandleType : EnumProperty(\n\t\t\tname=\"Handle type\",\n\t\t\tdefault='VECTOR',\n\t\t\tdescription=\"Bezier handles type\",\n\t\t\titems=[\n\t\t\t('VECTOR', \"Vector\", \"Vector type Bezier handles\"),\n\t\t\t('AUTO', \"Auto\", \"Automatic type Bezier handles\")]\n\t\t\t)\n\tedit_mode : BoolProperty(\n\t\t\tname=\"Show in edit mode\",\n\t\t\tdefault=True,\n\t\t\tdescription=\"Show in edit mode\"\n\t\t\t)\n\n\tdef draw(self, context):\n\t\tlayout = self.layout\n\n\t\t# general options\n\t\tcol = layout.column()\n\t\tcol.prop(self, \"Simple_Type\")\n\n\t\tl = 0\n\t\ts = 0\n\n\t\tif self.Simple_Type == 'Line':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=self.Simple_Type + \" Options:\")\n\t\t\tcol.prop(self, \"Simple_endlocation\")\n\t\t\tv = Vector(self.Simple_endlocation) - Vector(self.location)\n\t\t\tl = v.length\n\n\t\tif self.Simple_Type == 'Distance':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=self.Simple_Type + \" Options:\")\n\t\t\tcol.prop(self, \"Simple_length\")\n\t\t\tcol.prop(self, \"Simple_center\")\n\t\t\tl = self.Simple_length\n\n\t\tif self.Simple_Type == 'Angle':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=self.Simple_Type + \" Options:\")\n\t\t\tcol.prop(self, \"Simple_length\")\n\t\t\tcol.prop(self, \"Simple_angle\")\n\n\t\tif self.Simple_Type == 'Circle':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=self.Simple_Type + \" Options:\")\n\t\t\tcol.prop(self, \"Simple_sides\")\n\t\t\tcol.prop(self, \"Simple_radius\")\n\n\t\t\tl = 2 * pi * abs(self.Simple_radius)\n\t\t\ts = pi * self.Simple_radius * self.Simple_radius\n\n\t\tif self.Simple_Type == 'Ellipse':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=self.Simple_Type + \" Options:\")\n\t\t\tcol.prop(self, \"Simple_a\", text=\"Radius a\")\n\t\t\tcol.prop(self, \"Simple_b\", text=\"Radius b\")\n\n\t\t\tl = pi * (3 * (self.Simple_a + self.Simple_b) -\n\t\t\t\t\t\t  sqrt((3 * self.Simple_a + self.Simple_b) *\n\t\t\t\t\t\t  (self.Simple_a + 3 * self.Simple_b)))\n\n\t\t\ts = pi * abs(self.Simple_b) * abs(self.Simple_a)\n\n\t\tif self.Simple_Type == 'Arc':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=self.Simple_Type + \" Options:\")\n\t\t\tcol.prop(self, \"Simple_sides\")\n\t\t\tcol.prop(self, \"Simple_radius\")\n\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.prop(self, \"Simple_startangle\")\n\t\t\tcol.prop(self, \"Simple_endangle\")\n\t\t\t#row = layout.row()\n\t\t\t#row.prop(self, \"Simple_degrees_or_radians\", expand=True)\n\n\t\t\tl = abs(pi * self.Simple_radius * (self.Simple_endangle - self.Simple_startangle) / 180)\n\n\t\tif self.Simple_Type == 'Sector':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=self.Simple_Type + \" Options:\")\n\t\t\tcol.prop(self, \"Simple_sides\")\n\t\t\tcol.prop(self, \"Simple_radius\")\n\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.prop(self, \"Simple_startangle\")\n\t\t\tcol.prop(self, \"Simple_endangle\")\n\t\t\t#row = layout.row()\n\t\t\t#row.prop(self, \"Simple_degrees_or_radians\", expand=True)\n\n\t\t\tl = abs(pi * self.Simple_radius *\n\t\t\t\t   (self.Simple_endangle - self.Simple_startangle) / 180) + self.Simple_radius * 2\n\n\t\t\ts = pi * self.Simple_radius * self.Simple_radius * \\\n\t\t\t\tabs(self.Simple_endangle - self.Simple_startangle) / 360\n\n\t\tif self.Simple_Type == 'Segment':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=self.Simple_Type + \" Options:\")\n\t\t\tcol.prop(self, \"Simple_sides\")\n\t\t\tcol.prop(self, \"Simple_a\", text=\"Radius a\")\n\t\t\tcol.prop(self, \"Simple_b\", text=\"Radius b\")\n\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.prop(self, \"Simple_startangle\")\n\t\t\tcol.prop(self, \"Simple_endangle\")\n\n\t\t\t#row = layout.row()\n\t\t\t#row.prop(self, \"Simple_degrees_or_radians\", expand=True)\n\n\t\t\tla = abs(pi * self.Simple_a * (self.Simple_endangle - self.Simple_startangle) / 180)\n\t\t\tlb = abs(pi * self.Simple_b * (self.Simple_endangle - self.Simple_startangle) / 180)\n\t\t\tl = abs(self.Simple_a - self.Simple_b) * 2 + la + lb\n\n\t\t\tsa = pi * self.Simple_a * self.Simple_a * \\\n\t\t\t\tabs(self.Simple_endangle - self.Simple_startangle) / 360\n\n\t\t\tsb = pi * self.Simple_b * self.Simple_b * \\\n\t\t\t\tabs(self.Simple_endangle - self.Simple_startangle) / 360\n\n\t\t\ts = abs(sa - sb)\n\n\t\tif self.Simple_Type == 'Rectangle':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=self.Simple_Type + \" Options:\")\n\t\t\tcol.prop(self, \"Simple_width\")\n\t\t\tcol.prop(self, \"Simple_length\")\n\t\t\tcol.prop(self, \"Simple_rounded\")\n\n\t\t\tbox.prop(self, \"Simple_center\")\n\t\t\tl = 2 * abs(self.Simple_width) + 2 * abs(self.Simple_length)\n\t\t\ts = abs(self.Simple_width) * abs(self.Simple_length)\n\n\t\tif self.Simple_Type == 'Rhomb':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=self.Simple_Type + \" Options:\")\n\t\t\tcol.prop(self, \"Simple_width\")\n\t\t\tcol.prop(self, \"Simple_length\")\n\t\t\tcol.prop(self, \"Simple_center\")\n\n\t\t\tg = hypot(self.Simple_width / 2, self.Simple_length / 2)\n\t\t\tl = 4 * g\n\t\t\ts = self.Simple_width * self.Simple_length / 2\n\n\t\tif self.Simple_Type == 'Polygon':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=self.Simple_Type + \" Options:\")\n\t\t\tcol.prop(self, \"Simple_sides\")\n\t\t\tcol.prop(self, \"Simple_radius\")\n\n\t\tif self.Simple_Type == 'Polygon_ab':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=\"Polygon ab Options:\")\n\t\t\tcol.prop(self, \"Simple_sides\")\n\t\t\tcol.prop(self, \"Simple_a\")\n\t\t\tcol.prop(self, \"Simple_b\")\n\n\t\tif self.Simple_Type == 'Trapezoid':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=self.Simple_Type + \" Options:\")\n\t\t\tcol.prop(self, \"Simple_a\")\n\t\t\tcol.prop(self, \"Simple_b\")\n\t\t\tcol.prop(self, \"Simple_h\")\n\n\t\t\tbox.prop(self, \"Simple_center\")\n\t\t\tg = hypot(self.Simple_h, (self.Simple_a - self.Simple_b) / 2)\n\t\t\tl = self.Simple_a + self.Simple_b + g * 2\n\t\t\ts = (abs(self.Simple_a) + abs(self.Simple_b)) / 2 * self.Simple_h\n\n\t\trow = layout.row()\n\t\trow.prop(self, \"shape\", expand=True)\n\n\t\t# output options\n\t\tcol = layout.column()\n\t\tcol.label(text=\"Output Curve Type:\")\n\t\tcol.row().prop(self, \"outputType\", expand=True)\n\n\t\tif self.outputType == 'NURBS':\n\t\t\tcol.prop(self, \"order_u\")\n\t\telif self.outputType == 'BEZIER':\n\t\t\tcol.row().prop(self, 'handleType', expand=True)\n\n\t\tcol = layout.column()\n\t\tcol.row().prop(self, \"use_cyclic_u\", expand=True)\n\n\t\tcol = layout.column()\n\t\tcol.row().prop(self, \"edit_mode\", expand=True)\n\n\t\tcol = layout.column()\n\t\t# AddObjectHelper props\n\t\tcol.prop(self, \"align\")\n\t\tcol.prop(self, \"location\")\n\t\tcol.prop(self, \"rotation\")\n\n\t\tif l != 0 or s != 0:\n\t\t\tbox = layout.box()\n\t\t\tbox.label(text=\"Statistics:\", icon=\"INFO\")\n\t\tif l != 0:\n\t\t\tl_str = str(round(l, 4))\n\t\t\tbox.label(text=\"Length: \" + l_str)\n\t\tif s != 0:\n\t\t\ts_str = str(round(s, 4))\n\t\t\tbox.label(text=\"Area: \" + s_str)\n\n\t@classmethod\n\tdef poll(cls, context):\n\t\treturn context.scene is not None\n\n\tdef execute(self, context):\n\n\t\t# turn off 'Enter Edit Mode'\n\t\tuse_enter_edit_mode = bpy.context.preferences.edit.use_enter_edit_mode\n\t\tbpy.context.preferences.edit.use_enter_edit_mode = False\n\n\t\t# main function\n\t\tmain(context, self, use_enter_edit_mode)\n\n\t\tif use_enter_edit_mode:\n\t\t\tbpy.ops.object.mode_set(mode = 'EDIT')\n\n\t\t# restore pre operator state\n\t\tbpy.context.preferences.edit.use_enter_edit_mode = use_enter_edit_mode\n\n\t\tif self.edit_mode:\n\t\t\tbpy.ops.object.mode_set(mode = 'EDIT')\n\t\telse:\n\t\t\tbpy.ops.object.mode_set(mode = 'OBJECT')\n\n\t\treturn {'FINISHED'}\n\n\tdef invoke(self, context, event):\n\n\t\tself.execute(context)\n\n\t\treturn {'FINISHED'}\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy_extras import object_utils", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *", "\tfrom bpy.utils import register_class", "\tfrom bpy.utils import unregister_class"]}, {"term": "def", "name": "register", "data": "def register():\n\tfrom bpy.utils import register_class\n\tfor cls in classes:\n\t\tregister_class(cls)\n\n\tbpy.types.VIEW3D_MT_curve_add.append(menu)\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy_extras import object_utils", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *", "\tfrom bpy.utils import register_class", "\tfrom bpy.utils import unregister_class"]}, {"term": "def", "name": "unregister", "data": "def unregister():\n\tfrom bpy.utils import unregister_class\n\tfor cls in reversed(classes):\n\t\tunregister_class(cls)\n\n\tbpy.types.VIEW3D_MT_curve_add.remove(menu)\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy_extras import object_utils", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *", "\tfrom bpy.utils import register_class", "\tfrom bpy.utils import unregister_class"]}], [{"term": "def", "name": "simple", "data": "def simple():\r\n\tprint('simple:', a + b)\r\n\r\n", "description": null, "category": "simple", "imports": []}, {"term": "def", "name": "simple", "data": "def simple():\r\n\t# \u041b\u043e\u043a\u0430\u043b\u044c\u043d\u043e\u0435 \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u043e \u0438\u043c\u0435\u043d  \u0438\u043c\u0435\u043d \u043f\u043e\u044f\u0432\u043b\u044f\u0435\u0442\u0441\u044f \u0432 \u043c\u043e\u043c\u0435\u043d\u0442 \u0432\u044b\u0437\u043e\u0432\u0430 \u0444\u0443\u043d\u043a\u0446\u0438\u0438\r\n\tc, d = 3, 4\r\n\tprint('simple:', c + d)\r\n\r\n", "description": null, "category": "simple", "imports": []}, {"term": "def", "name": "simple_2", "data": "def simple_2():\r\n\t# \u041b\u043e\u043a\u0430\u043b\u044c\u043d\u043e\u0435 \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u043e \u0438\u043c\u0435\u043d\r\n\tx, y = 3, 4\r\n\tprint('simple_2:', x + y)\r\n\t# print('simple_2:', c + d)\r\n", "description": null, "category": "simple", "imports": []}, {"term": "def", "name": "simple", "data": "def simple():\r\n\t# \u041b\u043e\u043a\u0430\u043b\u044c\u043d\u043e\u0435 \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u043e \u0438\u043c\u0435\u043d\r\n\ta, b = 3, 4\r\n\tprint('simple:', a + b)\r\n\r\n", "description": null, "category": "simple", "imports": []}, {"term": "def", "name": "simple", "data": "def simple():\r\n\t# \u041b\u043e\u043a\u0430\u043b\u044c\u043d\u043e\u0435 \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u043e \u0438\u043c\u0435\u043d\r\n\tb = 4\r\n\tprint('simple:', a + b)\r\n\r\n", "description": null, "category": "simple", "imports": []}, {"term": "def", "name": "simple", "data": "def simple():\r\n\t# \u041b\u043e\u043a\u0430\u043b\u044c\u043d\u043e\u0435 \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u043e \u0438\u043c\u0435\u043d\r\n\tprint('simple:', a + b)\r\n\ta = 9\r\n\tprint('simple:', a + b)\r\n\r\n", "description": null, "category": "simple", "imports": []}, {"term": "def", "name": "simple_3", "data": "def simple_3(a, b):\r\n\tprint('simple:', a + b)\r\n\r\n", "description": null, "category": "simple", "imports": []}], [], [], [{"term": "def", "name": "readData", "data": "def readData(path_patient, path_atlas):\r\n\tatlas_path = []\r\n\tatlas_manual_path = []\r\n\tpatient_path = []\r\n\tpatient_manual_path = []\r\n\t#Read in all the atlas\r\n\tfor file in os.listdir(path_atlas):\r\n\t\tfile_name = path_atlas + '\\\\' + file\t\r\n\t\tatlas_path.append(file_name + '\\\\' + 'mr_bffe.mhd')\r\n\t\tatlas_manual_path.append(file_name + '\\\\' + 'prostaat.mhd')\r\n\t#Read in all the patients\r\n\tfor file in os.listdir(path_patient):\r\n\t\tfile_name = path_patient + '\\\\' + file\r\n\t\tpatient_path.append(file_name + '\\\\' + 'mr_bffe.mhd')\r\n\t\tpatient_manual_path.append(file_name + '\\\\' + 'prostaat.mhd')\r\n\t\r\n", "description": null, "category": "simple", "imports": ["import SimpleITK\r", "import matplotlib.pyplot as plt\r", "import numpy as np\r", "import os\r"]}, {"term": "def", "name": "joinSeries", "data": "def joinSeries(population):\r\n\tvectorOfImages = SimpleITK.VectorOfImage()\r\n\t# Get the origin\r\n\torigin_image = SimpleITK.ReadImage(population[0])\r\n\torigin = origin_image.GetOrigin()\r\n\t#fill in the vector of images\r\n\tfor filename in population:\r\n\t\timage = SimpleITK.ReadImage(filename)\r\n\t\timage.SetOrigin(origin)\r\n\t\tvectorOfImages.push_back(image)\r\n\t\r\n\tatlas_image = SimpleITK.JoinSeriesImageFilter()\r\n\t#The current tolerance is too large\r\n\tatlas_image.SetGlobalDefaultCoordinateTolerance(1e3)\r\n\tats = atlas_image.Execute(vectorOfImages)\r\n\r\n", "description": null, "category": "simple", "imports": ["import SimpleITK\r", "import matplotlib.pyplot as plt\r", "import numpy as np\r", "import os\r"]}, {"term": "def", "name": "combainAtlas", "data": "def combainAtlas(path_patient = r'.\\Patient', path_atlas = r'.\\Atlas', if_print = 0):\r\n\t#Read in \r\n\tatlas, _ = readData(path_patient,path_atlas)\r\n\tatlas_image = joinSeries(atlas[0])\r\n\t#Excuete\r\n\tSimpleElastix = SimpleITK.SimpleElastix()\r\n\t\r\n\tif if_print == 1:\r\n\t\tSimpleElastix.LogToConsoleOn()\r\n\r\n\tSimpleElastix.SetFixedImage(atlas_image)\r\n\tSimpleElastix.SetMovingImage(atlas_image)\r\n\t\r\n\tgroupwiseParameter = SimpleITK.GetDefaultParameterMap('groupwise')\r\n\tgroupwiseParameter['FinalBSplineInterpolationOrder'] = '0'\r\n\tSimpleElastix.SetParameterMap(groupwiseParameter)\r\n\tSimpleElastix.PrintParameterMap()\r\n\t\r\n\tSimpleElastix.Execute()\r\n\t#Get transMartix\r\n\ttransMartix = SimpleElastix.GetTransformParameterMap()\r\n\tjoint_atlas = SimpleElastix.GetResultImage()\r\n\t\r\n\tSimpleITK.WriteImage(joint_atlas,'joint_atlas4D.mhd')\r\n \r\n", "description": null, "category": "simple", "imports": ["import SimpleITK\r", "import matplotlib.pyplot as plt\r", "import numpy as np\r", "import os\r"]}, {"term": "def", "name": "combainManuals", "data": "def combainManuals(transMartix, path_patient = r'.\\Patient', path_atlas = r'.\\Atlas'):\r\n\tatlas, _ = readData(path_patient,path_atlas)\r\n\tatlas_manuals = joinSeries(atlas[1])\r\n\r\n\tresultLabels = SimpleITK.Transformix(atlas_manuals, transMartix)\r\n\t\r\n\tjointLabel = labelVoting4D(resultLabels,len(atlas[1]))\r\n\t\r\n\tcompose = SimpleITK.ComposeImageFilter()\r\n\tcomposed_image = compose.Execute(jointLabel)\r\n\r\n\tSimpleITK.WriteImage(composed_image,'joint_label4D.mhd')\r\n\t\r\n", "description": null, "category": "simple", "imports": ["import SimpleITK\r", "import matplotlib.pyplot as plt\r", "import numpy as np\r", "import os\r"]}, {"term": "def", "name": "labelVoting4D", "data": "def labelVoting4D(resultLabels, number_atlas):\r\n\tvectorOfImages = SimpleITK.VectorOfImage()\r\n\tresultLabels = SimpleITK.GetArrayFromImage(resultLabels)\r\n\t\r\n\tfor i in range(number_atlas):\r\n\t\tchannals = SimpleITK.GetImageFromArray(resultLabels[i,:,:,:])\r\n\t\tvectorOfImages.push_back(SimpleITK.LabelVoting(channals,1))\r\n\t\r\n\treturn vectorOfImages\r\n", "description": null, "category": "simple", "imports": ["import SimpleITK\r", "import matplotlib.pyplot as plt\r", "import numpy as np\r", "import os\r"]}, {"term": "def", "name": "average4D", "data": "def average4D(joint_atlas_array, joint_label_array, path_patient = r'.\\Patient', path_atlas = r'.\\Atlas'):\r\n\tatlas, _ = readData(path_patient,path_atlas)\r\n\t\r\n\tchannals_atlas = np.max(joint_atlas_array, axis=0)\r\n\tchannals_label = np.max(joint_label_array, axis=3)\r\n\r\n\t#for i in range(1,len(atlas[0])-1):\r\n\t\t#channals_atlas += joint_atlas_array[i,:,:,:]\r\n\r\n\t#for i in range(1,len(atlas[0])-1):\r\n\t\t#channals_label += joint_label_array[:,:,:,i]\r\n\r\n\t#channals_atlas = channals_atlas / len(atlas[0])\r\n\t#channals_label = channals_label / len(atlas[0])\r\n\t\r\n\tchannals_labelInt = np.uint8(channals_label)  #  Transfer the 2D average label to 0 or 1\r\n\tchannals_atlasInt = np.int16(channals_atlas)\r\n\t\r\n\tchannals_labelInt =  SimpleITK.LabelVoting(SimpleITK.GetImageFromArray(channals_labelInt),1) \r\n\t\r\n\tSimpleITK.WriteImage(SimpleITK.GetImageFromArray(channals_atlasInt),'joint_atlas3D.mhd')\r\n\tSimpleITK.WriteImage(channals_labelInt,'joint_label3D.mhd')\r\n\t\r\n\treturn channals_atlas, channals_label\r\n", "description": null, "category": "simple", "imports": ["import SimpleITK\r", "import matplotlib.pyplot as plt\r", "import numpy as np\r", "import os\r"]}, {"term": "def", "name": "plot2D", "data": "def plot2D(atlas_average,label_average):\r\n\tplt.figure(1)\r\n\tplt.title('atlas_average2D')\r\n\tplt.imshow(np.sum(atlas_average, axis = 0), cmap='gray')\r\n\r\n\tplt.figure(2)\r\n\tplt.title('label_average2D')\r\n\tplt.imshow(np.sum(label_average, axis = 0), cmap='gray')\r\n\t\r\n\tplt.show()\r\n", "description": null, "category": "simple", "imports": ["import SimpleITK\r", "import matplotlib.pyplot as plt\r", "import numpy as np\r", "import os\r"]}, {"term": "def", "name": "loadResults", "data": "def loadResults():\r\n\tjoint_atlas = SimpleITK.ReadImage(r'.\\joint_atlas4D.mhd')\r\n\tjoint_label = SimpleITK.ReadImage(r'.\\joint_label4D.mhd')\r\n\t\r\n\tjoint_atlas_array = SimpleITK.GetArrayFromImage(joint_atlas)\r\n\tjoint_label_array =  SimpleITK.GetArrayFromImage(joint_label)\r\n\r\n\tatlas_average, label_average = average4D(joint_atlas_array, joint_label_array)\r\n\tplot2D(atlas_average, label_average)\r\n", "description": null, "category": "simple", "imports": ["import SimpleITK\r", "import matplotlib.pyplot as plt\r", "import numpy as np\r", "import os\r"]}], [{"term": "class", "name": "GnrCustomWebPage", "data": "class GnrCustomWebPage(object):\n\tpy_requires = \"gnrcomponents/testhandler:TestHandlerFull\"\n\n\tdef test_0_simpleTextareaSpeech(self, pane):\n\t\t\"\"\"simpleTextarea\"\"\"\n\t\tpane.simpleTextarea(value='^.simpleTextarea', height='200px', width='400px',speech=True,editor=True)\n\n\n\tdef test_2_simpleTextareaSpeech(self, pane):\n\t\t\"\"\"simpleTextarea\"\"\"\n\t\tpane.formbuilder(cols=1,border_spacing='3px').simpleTextarea(value='^.simpleTextarea', height='200px', width='400px')\n\n\tdef test_3_simpleTextareaSpeechFb(self, pane):\n\t\tfb = pane.formbuilder(cols=1,border_spacing='3px',fld_width='100%',width='400px')\n\t\tfb.simpleTextarea(value='^.simpleTextarea', height='200px',speech=True,lbl='Prova',editor=True)\n\n\n", "description": "simpleTextarea", "category": "simple", "imports": ["from builtins import object"]}], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [{"term": "class", "name": "testSimpleBars", "data": "class testSimpleBars(unittest.TestCase):\n\tdef setUp(self):\n\t\tpass\n\n\tdef test_str(self):\n\t\tself.assertEquals(str(SimpleBars(\"\t \")), \"\t \")\n\t\tself.assertEquals(str(SimpleBars(\"iTiTi\")), \"iTiTi\")\n\n\tdef test_len(self):\n\t\tself.assertEquals(len(SimpleBars(\"iTiTi\")),   5)\n\t\tself.assertEquals(len(SimpleBars(\" \" * 80)), 80)\n\n\tdef test_simple_rule(self):\n\t\tself.assertEquals(str(SimpleBars(\"\t \").next()), \"\t \")\n\t\tself.assertEquals(str(SimpleBars(\"  i  \").next()), \" iTi \")\n\t\tself.assertEquals(str(SimpleBars(\" i i \").next()), \"iT Ti\")\n\t\tself.assertEquals(str(SimpleBars(\"  T  \").next()), \"  i  \")\n\t\tself.assertEquals(str(SimpleBars(\" TiT \").next()), \"  T  \")\n\t\tself.assertEquals(str(SimpleBars(\" iTi \").next()), \"iTiTi\")\n\t\tself.assertEquals(str(SimpleBars(\" TTT \").next()), \" iii \")\n\n\tdef test_loop(self):\n\t\tbs = SimpleBars(\"Ti  \")\n\t\tself.assertEquals(str(bs.next()), \" Ti \")\n\t\tself.assertEquals(str(bs.next()), \"  Ti\")\n\t\tself.assertEquals(str(bs.next()), \"i  T\")\n\t\tself.assertEquals(str(bs.next()), \"Ti  \")\n\t\tbs = SimpleBars(\"  iT\")\n\t\tself.assertEquals(str(bs.next()), \" iT \")\n\t\tself.assertEquals(str(bs.next()), \"iT  \")\n\t\tself.assertEquals(str(bs.next()), \"T  i\")\n\t\tself.assertEquals(str(bs.next()), \"  iT\")\n\n\tdef tearDown(self):\n\t\tpass\n", "description": null, "category": "simple", "imports": ["from second_code import SimpleBars", "import unittest"]}], [{"term": "class", "name": "TextArea", "data": "class TextArea(object):  \r\n  \r\n\tdef __init__(self):  \r\n\t\tself.buffer = []  \r\n  \r\n\tdef write(self, *args, **kwargs):  \r\n\t\tself.buffer.append(args)  \r\n", "description": null, "category": "simple", "imports": ["import SimpleITK\r", "import os\r", "import re\r", "import sys\r"]}, {"term": "def", "name": "getMetricScore", "data": "def getMetricScore(elastixLogPath):\r\n\tfinalMetricValue = 0\r\n\tpattern = re.compile('Final metric value  = (?P[+-.0-9]{9})')\r\n\r\n\twith open(elastixLogPath) as log:\r\n\t\tm = re.search(pattern, log.read())\r\n\t\ttry:\r\n\t\t\tfinalMetricValue = float(m.group('value'))\r\n\t\texcept:\r\n\t\t\traise Exception('Final metric value not found in \"elastix.log\".')\r\n\tprint('The final score is %f' %finalMetricValue)\r\n\treturn finalMetricValue\r\n", "description": null, "category": "simple", "imports": ["import SimpleITK\r", "import os\r", "import re\r", "import sys\r"]}, {"term": "def", "name": "readData", "data": "def readData(path_patient = r'.\\Patient', path_atlas = r'.\\Atlas'):\r\n\t\"\"\"\r\n\tRead in all the data in the folder\r\n\tReturns the path of each file.\r\n\t\"\"\"\r\n\t#  List of path\r\n\tatlas_path = []\r\n\tatlas_manual_path = []\r\n\tpatient_path = []\r\n\tpatient_manual_path = []\r\n\t#  List of images\r\n\tatlas = []\r\n\tatlas_maunal = []\r\n\tpatient = []\r\n\tpatienr_manual = []\r\n\t#  Read in all the atlas\r\n\tfor file in os.listdir(path_atlas):\r\n\t\tfile_name = path_atlas + '\\\\' + file\t\r\n\t\tatlas_path.append(file_name + '\\\\' + 'mr_bffe.mhd')\r\n\t\tatlas_manual_path.append(file_name + '\\\\' + 'prostaat.mhd')\r\n\t\tatlas.append(SimpleITK.ReadImage(file_name + '\\\\' + 'mr_bffe.mhd'))\r\n\t\tatlas_maunal.append(SimpleITK.ReadImage(file_name + '\\\\' + 'prostaat.mhd'))\r\n\t#  Read in all the patients\r\n\tfor file in os.listdir(path_patient):\r\n\t\tfile_name = path_patient + '\\\\' + file\r\n\t\tpatient_path.append(file_name + '\\\\' + 'mr_bffe.mhd')\r\n\t\tpatient_manual_path.append(file_name + '\\\\' + 'prostaat.mhd')\r\n\t\tpatient.append(SimpleITK.ReadImage(file_name + '\\\\' + 'mr_bffe.mhd'))\r\n\t\tpatienr_manual.append(SimpleITK.ReadImage(file_name + '\\\\' + 'prostaat.mhd'))\r\n\tprint('There are %d atlases data and %d patient' %(len(atlas_path), len(patient_path)))\r\n\t\r\n\treturn [atlas, atlas_maunal], [patient, patienr_manual]\r\n", "description": "\r\n\tRead in all the data in the folder\r\n\tReturns the path of each file.\r\n\t", "category": "simple", "imports": ["import SimpleITK\r", "import os\r", "import re\r", "import sys\r"]}, {"term": "def", "name": "register", "data": "def register(atlas, patient, ifPrint = 0):\r\n\t\"\"\"\r\n\tDo the registeration.\r\n\tFirst it searches all the data from the altas floder. Then all the altas are \r\n\tregistered with the files in the patient floder.\r\n\tIt also records the scores in a scoreList.\r\n\tThe best registratons are saved.\r\n\tatlas0 = image, atlas1 = maunal\r\n\tpatient0 = image, patienr1 = manual\r\n\t\"\"\"\r\n\t#  Set the parameterMap\r\n\tparameterVec = setParameters0()\r\n\t#  Initilize a SimpleElastix instance\r\n\tSimpleElastix = SimpleITK.SimpleElastix()\r\n\tif ifPrint == 1:\r\n\t\tSimpleElastix.LogToConsoleOn()\r\n\t#  Set the parameterMap\r\n\tSimpleElastix.SetParameterMap(parameterVec)\r\n\tSimpleElastix.SetParameter('Interpolator', 'BSplineInterpolator') \r\n\t#  ifPrint\r\n\tif ifPrint == 0:\r\n\t\tSimpleElastix.PrintParameterMap()\r\n\t# A list to store results of patient image\r\n\tresultPatientImage = []\r\n\t# A list to store results of patient Manuals\r\n\tresultPatientManual = []\r\n\t# A list to store results of patient score\r\n\treslutPatientScore = []\r\n\t#  Lood through the patient folder\r\n\tfor patientImage, patientManual in zip(patient[0], patient[1]):\r\n\t\t#  A list to store all the reslut image\r\n\t\tresultImage = []\r\n\t\t#  A list to store all the reversed manuals\r\n\t\tresultManuals = []\r\n\t\t#  A list to store all the dice scores\r\n\t\tresultScore = []\r\n\t\t#  Set the fixed image\r\n\t\tSimpleElastix.SetFixedImage(patientImage)\r\n\t\t#  Get the origin of the fixed image\r\n\t\timageOrigin = patientImage.GetOrigin()\r\n\t\tmanualOrigin = patientManual.GetOrigin()\r\n\t\t#  Loop through the patient folder\r\n\t\tfor atlasImage, atlasManual in zip(atlas[0], atlas[1]):\r\n\t\t\t#  Set the origin of moving image\r\n\t\t\tatlasImage.SetOrigin(imageOrigin)\r\n\t\t\t#  Set the moving image\r\n\t\t\tSimpleElastix.SetMovingImage(atlasImage)\r\n\t\t\t#  Do the registration\r\n\t\t\tSimpleElastix.Execute()\r\n\t\t\tprint('\\nOne registration done!')\r\n\t\t\tresultImage.append(SimpleElastix.GetResultImage())\r\n\t\t\t#  Get the transform Matrix\r\n\t\t\ttransforMartix = SimpleElastix.GetTransformParameterMap()\r\n\t\t\t#  Apply the transform Matrix to the atlasManual\r\n\t\t\treversedManual = SimpleITK.Transformix(atlasManual, transforMartix)\r\n\t\t\t#  Label voting\r\n\t\t\treversedManual = SimpleITK.LabelVoting(reversedManual,1) \r\n\t\t\tprint('Label voting done!')\r\n\t\t\t#  Set the origin of reversed maunal\r\n\t\t\treversedManual.SetOrigin(manualOrigin)\r\n\t\t\tresultManuals.append(reversedManual) \r\n\t\t\t#  Calculate the dice score\r\n\t\t\tmeasureFilter = SimpleITK.LabelOverlapMeasuresImageFilter()\r\n\t\t\t#  Have to change the tolerance to make the code work\r\n\t\t\tmeasureFilter.SetGlobalDefaultCoordinateTolerance(1e3)\r\n\t\t\treversedOrigin = reversedManual.GetOrigin()\r\n\t\t\tatlasManual.SetOrigin(reversedOrigin)\r\n\t\t\tmeasureFilter.Execute(reversedManual, atlasManual)\r\n\t\t\tprint('Dice scores done!')\r\n\t\t\tdiceScore = measureFilter.GetDiceCoefficient()\r\n\t\t\tresultScore.append(diceScore)\r\n\t\t\tprint('The dice score is %f' %diceScore)\r\n\t\tresultPatientImage.append(resultImage)\r\n\t\tresultPatientManual.append(resultManuals)\r\n\t\t#reslutPatientScore.append(resultScore)\r\n\treturn resultPatientImage, resultPatientManual, reslutPatientScore\r\n", "description": "\r\n\tDo the registeration.\r\n\tFirst it searches all the data from the altas floder. Then all the altas are \r\n\tregistered with the files in the patient floder.\r\n\tIt also records the scores in a scoreList.\r\n\tThe best registratons are saved.\r\n\tatlas0 = image, atlas1 = maunal\r\n\tpatient0 = image, patienr1 = manual\r\n\t", "category": "simple", "imports": ["import SimpleITK\r", "import os\r", "import re\r", "import sys\r"]}, {"term": "def", "name": "setParameters0", "data": "def setParameters0():\r\n\t\"\"\"\r\n\tThis is the basic parameters set.\r\n\tNot to much defult values are changed\r\n\t\"\"\"\r\n\tparameterVec = SimpleITK.VectorOfParameterMap()\r\n\r\n\t#rigid = SimpleITK.GetDefaultParameterMap('rigid')\r\n\ttraslation = SimpleITK.GetDefaultParameterMap('translation')\r\n\taffine = SimpleITK.GetDefaultParameterMap('affine')\r\n\tbspline = SimpleITK.GetDefaultParameterMap('bspline')\r\n\r\n\ttraslation['FinalBSplineInterpolationOrder'] = '0'\r\n\taffine['FinalBSplineInterpolationOrder'] = '0'\r\n\tbspline['FinalBSplineInterpolationOrder'] = '0'\r\n\r\n\ttraslation['Registration'] = ['MultiMetricMultiResolutionRegistration']\r\n\taffine['Registration'] = ['MultiMetricMultiResolutionRegistration']\r\n\tbspline['Registration'] = ['MultiMetricMultiResolutionRegistration']\r\n\r\n\ttraslation['Metric'] = ['AdvancedMattesMutualInformation','AdvancedNormalizedCorrelation']\r\n\taffine['Metric'] = ['AdvancedMattesMutualInformation','AdvancedNormalizedCorrelation']\r\n\tbspline['Metric'] = ['AdvancedMattesMutualInformation','AdvancedNormalizedCorrelation']\r\n\t\r\n\ttraslation['Metric0Weight'] = '1'\r\n\ttraslation['Metric1Weight'] = '1'\r\n\t\r\n\taffine['Metric0Weight'] = '1'\r\n\taffine['Metric1Weight'] = '1'\r\n\t\r\n\tbspline['Metric0Weight'] = '1'\r\n\tbspline['Metric1Weight'] = '1'\r\n\t#parameterVec.append(rigid)\r\n\tparameterVec.append(traslation)\r\n\tparameterVec.append(affine)\r\n\tparameterVec.append(bspline)\r\n\treturn parameterVec\r\n", "description": "\r\n\tThis is the basic parameters set.\r\n\tNot to much defult values are changed\r\n\t", "category": "simple", "imports": ["import SimpleITK\r", "import os\r", "import re\r", "import sys\r"]}, {"term": "def", "name": "mutilRegistration", "data": "def mutilRegistration(resultScore, atlas, patient, ifPrint=0):\r\n\t\"\"\"\r\n\tSelect a the top three best results and register them to the unseen patient\r\n\tThen mix the segementation by label voting\r\n\t\"\"\"\r\n\t#  Set the parameterMap\r\n\tparameterVec = setParameters0()\r\n\t#  Initilize a SimpleElastix instance\r\n\tSimpleElastix = SimpleITK.SimpleElastix()\r\n\tSimpleElastix.SetLogToFile(True)\r\n\tif ifPrint == 1:\r\n\t\tSimpleElastix.LogToConsoleOn()\r\n\t#  Set the parameterMap\r\n\tSimpleElastix.SetParameterMap(parameterVec)\r\n\tSimpleElastix.SetParameter('Interpolator', 'BSplineInterpolator') \r\n\t#  ifPrint\r\n\tif ifPrint == 1:\r\n\t\tSimpleElastix.PrintParameterMap()\r\n\t#  A list to sotre resluts\r\n\tresultSegmentation = []\r\n\r\n\tfor i in range(len(resultScore)):\r\n\t\t#Loop through patient data\r\n\t\tresultLabels = SimpleITK.VectorOfImage()\r\n\t\t#  Set the fixed image\r\n\t\tSimpleElastix.SetFixedImage(patient[0][i])\r\n\t\timageOrigin = patient[0][i].GetOrigin()\r\n\t\tresultdownUp = sorted(resultScore[i],reverse = True)\r\n\t\tfor j in range(3):\r\n\t\t\ttopScore = resultdownUp[j]\r\n\t\t\tindexScore = resultScore[i].index(topScore)\r\n\t\t\tatlas[0][indexScore].SetOrigin(imageOrigin)\r\n\t\t\tSimpleElastix.SetMovingImage(atlas[0][indexScore])\r\n\t\t\tSimpleElastix.Execute()\r\n\t\t\tresultLabels.push_back(SimpleITK.Transformix(atlas[1][indexScore], SimpleElastix.GetTransformParameterMap()))\r\n\t\t\tprint('One registration done!')\r\n\t\t#  Label voting to pick the mixed label\r\n\t\tprint('One mix done!')\r\n\t\tfixedLabel = SimpleITK.LabelVoting(resultLabels)\r\n\t\t#  Calculate dice score\r\n\t\tmeasureFilter = SimpleITK.LabelOverlapMeasuresImageFilter()\r\n\t\t#  Have to change the tolerance to make the code work\r\n\t\tmeasureFilter.SetGlobalDefaultCoordinateTolerance(1e3)\r\n\t\treversedOrigin = patient[1][i].GetOrigin()\r\n\t\tfixedLabel.SetOrigin(reversedOrigin)\r\n\t\tmeasureFilter.Execute(fixedLabel, patient[1][i])\r\n\t\tdiceScore = measureFilter.GetDiceCoefficient()\r\n\t\tprint('The dice score with mixed segmentation is %f' %diceScore)\r\n\t\tSimpleITK.WriteImage(fixedLabel,r'.\\result\\mixedSegmentation' + 'Patient%f.mhd' %diceScore)\r\n\t\tresultSegmentation.append(fixedLabel)\r\n", "description": "\r\n\tSelect a the top three best results and register them to the unseen patient\r\n\tThen mix the segementation by label voting\r\n\t", "category": "simple", "imports": ["import SimpleITK\r", "import os\r", "import re\r", "import sys\r"]}, {"term": "def", "name": "selectResults", "data": "def selectResults(resultImage, resultManuals, resultScore):\r\n\t\"\"\"\r\n\tSelect the best results and save\r\n\t\"\"\"\r\n\tresultIm = []\r\n\tresultMn = []\r\n\tresultSc = []\r\n\tfor i in range(len(resultScore)):\r\n\t\tresult = resultScore[i]\r\n\t\tmaxPos = result.index(max(result))\r\n\t\tresultIm.append(resultImage[i][maxPos])\r\n\t\tresultMn.append(resultManuals[i][maxPos])\r\n\t\tresultSc.append(resultScore[i][maxPos])\r\n\tfor i in range(len(resultScore)):\r\n\t\tresult = resultScore[i]\r\n\t\tSimpleITK.WriteImage(resultIm[i],r'.\\result\\resultImage' + '(%f).mhd' %max(result))\r\n\t\tSimpleITK.WriteImage(resultMn[i],r'.\\result\\resultManual'+'(%f).mhd' %max(result))\r\n\treturn resultSc, resultIm, resultMn\r\n", "description": "\r\n\tSelect the best results and save\r\n\t", "category": "simple", "imports": ["import SimpleITK\r", "import os\r", "import re\r", "import sys\r"]}], [{"term": "class", "name": "SimpleSitemap", "data": "class SimpleSitemap(Sitemap):\n\tchangefreq = \"never\"\n\tpriority = 0.5\n\tlocation = '/location/'\n\tlastmod = datetime.now()\n\n\tdef items(self):\n\t\treturn [object()]\n", "description": null, "category": "simple", "imports": ["from datetime import datetime", "from django.conf.urls import patterns, url", "from django.contrib.sitemaps import Sitemap, GenericSitemap, FlatPageSitemap, views", "from django.contrib.auth.models import User", "from django.views.decorators.cache import cache_page", "from django.contrib.sitemaps.tests.base import TestModel"]}], [{"term": "class", "name": "TestLibraryInfo", "data": "class TestLibraryInfo(object):\n\tdef test_simple(self):\n\t\twith temppath('foo.ini') as path:\n\t\t\twith open(path,  'w') as f:\n\t\t\t\tf.write(simple)\n\t\t\tpkg = os.path.splitext(path)[0]\n\t\t\tout = read_config(pkg)\n\n\t\tassert_(out.cflags() == simple_d['cflags'])\n\t\tassert_(out.libs() == simple_d['libflags'])\n\t\tassert_(out.name == simple_d['name'])\n\t\tassert_(out.version == simple_d['version'])\n\n\tdef test_simple_variable(self):\n\t\twith temppath('foo.ini') as path:\n\t\t\twith open(path,  'w') as f:\n\t\t\t\tf.write(simple_variable)\n\t\t\tpkg = os.path.splitext(path)[0]\n\t\t\tout = read_config(pkg)\n\n\t\tassert_(out.cflags() == simple_variable_d['cflags'])\n\t\tassert_(out.libs() == simple_variable_d['libflags'])\n\t\tassert_(out.name == simple_variable_d['name'])\n\t\tassert_(out.version == simple_variable_d['version'])\n\t\tout.vars['prefix'] = '/Users/david'\n\t\tassert_(out.cflags() == '-I/Users/david/include')\n", "description": null, "category": "simple", "imports": ["from __future__ import division, absolute_import, print_function", "import os", "from numpy.distutils.npy_pkg_config import read_config, parse_flags", "from numpy.testing import temppath, assert_"]}, {"term": "class", "name": "TestParseFlags", "data": "class TestParseFlags(object):\n\tdef test_simple_cflags(self):\n\t\td = parse_flags(\"-I/usr/include\")\n\t\tassert_(d['include_dirs'] == ['/usr/include'])\n\n\t\td = parse_flags(\"-I/usr/include -DFOO\")\n\t\tassert_(d['include_dirs'] == ['/usr/include'])\n\t\tassert_(d['macros'] == ['FOO'])\n\n\t\td = parse_flags(\"-I /usr/include -DFOO\")\n\t\tassert_(d['include_dirs'] == ['/usr/include'])\n\t\tassert_(d['macros'] == ['FOO'])\n\n\tdef test_simple_lflags(self):\n\t\td = parse_flags(\"-L/usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tassert_(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tassert_(d['libraries'] == ['foo', 'bar'])\n\n\t\td = parse_flags(\"-L /usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tassert_(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tassert_(d['libraries'] == ['foo', 'bar'])\n", "description": null, "category": "simple", "imports": ["from __future__ import division, absolute_import, print_function", "import os", "from numpy.distutils.npy_pkg_config import read_config, parse_flags", "from numpy.testing import temppath, assert_"]}], [{"term": "class", "name": "SimpleSitemap", "data": "class SimpleSitemap(Sitemap):\n\tchangefreq = \"never\"\n\tpriority = 0.5\n\tlocation = '/location/'\n\tlastmod = datetime.now()\n\n\tdef items(self):\n\t\treturn [object()]\n", "description": null, "category": "simple", "imports": ["from datetime import datetime", "from django.conf.urls.defaults import *", "from django.contrib.sitemaps import Sitemap, GenericSitemap, FlatPageSitemap", "from django.contrib.auth.models import User"]}], [{"term": "def", "name": "test_count", "data": "def test_count(db: Session):\n\t# WHEN\n\tSimpleModelFactory()\n\n\t# THEN\n\tassert db.query(SimpleModel).count() == 1\n\n", "description": null, "category": "simple", "imports": ["from freezegun import freeze_time", "from sqlalchemy import exists, func, or_", "from sqlalchemy.orm import Session", "from src.models import SimpleModel", "from .factories import SimpleModelFactory"]}, {"term": "def", "name": "test_exists", "data": "def test_exists(db: Session):\n\t# GIVEN\n\tdb_obj = SimpleModelFactory(id=1)\n\tnon_existent_id = 2\n\n\t# WHEN & THEN\n\tassert db.query(exists().where(SimpleModel.id == db_obj.id)).scalar() is True\n\tassert db.query(exists().where(SimpleModel.id == non_existent_id)).scalar() is False\n\n", "description": null, "category": "simple", "imports": ["from freezegun import freeze_time", "from sqlalchemy import exists, func, or_", "from sqlalchemy.orm import Session", "from src.models import SimpleModel", "from .factories import SimpleModelFactory"]}, {"term": "def", "name": "test_filters", "data": "def test_filters(db: Session):\n\t# GIVEN\n\tSimpleModelFactory(col_1=\"foo\", col_2=\"spam\")\n\tSimpleModelFactory(col_1=\"foo\", col_2=\"eggs\")\n\tSimpleModelFactory(col_1=\"bar\", col_2=\"spam\")\n\n\t# WHEN\n\tfoo_count_1 = db.query(SimpleModel).filter_by(col_1=\"foo\").count()\n\tfoo_count_2 = db.query(SimpleModel).filter(SimpleModel.col_1 == \"foo\").count()\n\tfoo_or_spam_count = (\n\t\tdb.query(SimpleModel)\n\t\t.filter(or_(SimpleModel.col_1 == \"foo\", SimpleModel.col_2 == \"spam\"))\n\t\t.count()\n\t)\n\n\t# THEN\n\tassert foo_count_1 == foo_count_2 == 2\n\tassert foo_or_spam_count == 3\n\n", "description": null, "category": "simple", "imports": ["from freezegun import freeze_time", "from sqlalchemy import exists, func, or_", "from sqlalchemy.orm import Session", "from src.models import SimpleModel", "from .factories import SimpleModelFactory"]}, {"term": "def", "name": "test_order_by", "data": "def test_order_by(db: Session):\n\t# GIVEN\n\tSimpleModelFactory(col_1=\"zzz\")\n\tSimpleModelFactory(col_1=\"aaa\")\n\n\t# WHEN\n\tascending = db.query(SimpleModel.col_1).order_by(SimpleModel.col_1)\n\tdescending = db.query(SimpleModel.col_1).order_by(SimpleModel.col_1.desc())\n\n\t# THEN\n\tassert [row.col_1 for row in ascending] == [\"aaa\", \"zzz\"]\n\tassert [row.col_1 for row in descending] == [\"zzz\", \"aaa\"]\n\n", "description": null, "category": "simple", "imports": ["from freezegun import freeze_time", "from sqlalchemy import exists, func, or_", "from sqlalchemy.orm import Session", "from src.models import SimpleModel", "from .factories import SimpleModelFactory"]}, {"term": "def", "name": "test_avg_and_sum_simple", "data": "def test_avg_and_sum_simple(db: Session):\n\t# GIVEN\n\tSimpleModelFactory(value=0)\n\tSimpleModelFactory(value=5)\n\n\t# WHEN\n\tdb_objs = db.query(\n\t\tfunc.avg(SimpleModel.value).label(\"avg\"),\n\t\tfunc.sum(SimpleModel.value).label(\"sum\"),\n\t)\n\n\t# THEN\n\tassert db_objs[0].avg == 2.5\n\tassert db_objs[0].sum == 5.0\n\n", "description": null, "category": "simple", "imports": ["from freezegun import freeze_time", "from sqlalchemy import exists, func, or_", "from sqlalchemy.orm import Session", "from src.models import SimpleModel", "from .factories import SimpleModelFactory"]}, {"term": "def", "name": "test_avg_and_sum_grouped_by", "data": "def test_avg_and_sum_grouped_by(db: Session):\n\t# GIVEN\n\tSimpleModelFactory(type=SimpleModel.Type.NORMAL, value=0)\n\tSimpleModelFactory(type=SimpleModel.Type.NORMAL, value=5)\n\tSimpleModelFactory(type=SimpleModel.Type.SUPER, value=5)\n\tSimpleModelFactory(type=SimpleModel.Type.SUPER, value=10)\n\n\tdb_objs = (\n\t\tdb.query(\n\t\t\tSimpleModel.type,\n\t\t\tfunc.avg(SimpleModel.value).label(\"avg\"),\n\t\t\tfunc.sum(SimpleModel.value).label(\"sum\"),\n\t\t)\n\t\t.group_by(SimpleModel.type)\n\t\t.order_by(SimpleModel.type)\n\t)\n\n\tassert db_objs[0].type == SimpleModel.Type.NORMAL\n\tassert db_objs[0].avg == 2.5\n\tassert db_objs[0].sum == 5\n\n\tassert db_objs[1].type == SimpleModel.Type.SUPER\n\tassert db_objs[1].avg == 7.5\n\tassert db_objs[1].sum == 15\n\n", "description": null, "category": "simple", "imports": ["from freezegun import freeze_time", "from sqlalchemy import exists, func, or_", "from sqlalchemy.orm import Session", "from src.models import SimpleModel", "from .factories import SimpleModelFactory"]}, {"term": "def", "name": "test_avg_and_sum_annotated", "data": "def test_avg_and_sum_annotated(db: Session):\n\t# GIVEN\n\tSimpleModelFactory(type=SimpleModel.Type.NORMAL, value=0)\n\tSimpleModelFactory(type=SimpleModel.Type.NORMAL, value=5)\n\tSimpleModelFactory(type=SimpleModel.Type.SUPER, value=5)\n\tSimpleModelFactory(type=SimpleModel.Type.SUPER, value=10)\n\n\tavg_sum_subquery = (\n\t\tdb.query(\n\t\t\tSimpleModel.type,\n\t\t\tfunc.avg(SimpleModel.value).label(\"avg\"),\n\t\t\tfunc.sum(SimpleModel.value).label(\"sum\"),\n\t\t)\n\t\t.group_by(SimpleModel.type)\n\t\t.subquery()\n\t)\n\n\tdb_objs = (\n\t\tdb.query(\n\t\t\tSimpleModel,\n\t\t\tavg_sum_subquery.c.avg,\n\t\t\tavg_sum_subquery.c.sum,\n\t\t)\n\t\t.join(avg_sum_subquery, SimpleModel.type == avg_sum_subquery.c.type)\n\t\t.order_by(SimpleModel.type)\n\t)\n\n\tfor i in [0, 1]:\n\t\tassert db_objs[i].SimpleModel.type == SimpleModel.Type.NORMAL\n\t\tassert db_objs[i].avg == 2.5\n\t\tassert db_objs[i].sum == 5\n\n\tfor i in [2, 3]:\n\t\tassert db_objs[i].SimpleModel.type == SimpleModel.Type.SUPER\n\t\tassert db_objs[i].avg == 7.5\n\t\tassert db_objs[i].sum == 15\n\n", "description": null, "category": "simple", "imports": ["from freezegun import freeze_time", "from sqlalchemy import exists, func, or_", "from sqlalchemy.orm import Session", "from src.models import SimpleModel", "from .factories import SimpleModelFactory"]}, {"term": "def", "name": "test_class_getters_aka_quasi_manager", "data": "def test_class_getters_aka_quasi_manager(db: Session):\n\t# GIVEN\n\twith freeze_time(\"2020-01-02 03:45\") as older_timestamp:\n\t\ttimestamp = older_timestamp.time_to_freeze\n\t\tSimpleModelFactory(type=SimpleModel.Type.NORMAL, created_at=timestamp)\n\t\tSimpleModelFactory(type=SimpleModel.Type.SUPER, created_at=timestamp)\n\n\twith freeze_time(\"2021-02-03 04:56\") as newer_timestamp:\n\t\ttimestamp = newer_timestamp.time_to_freeze\n\t\tobj_to_return = SimpleModelFactory(type=SimpleModel.Type.NORMAL, created_at=timestamp)\n\t\tSimpleModelFactory(type=SimpleModel.Type.SUPER, created_at=timestamp)\n\n\t# WHEN\n\tresult = SimpleModel.get_latest_by_type(db, SimpleModel.Type.NORMAL)\n\n\t# THEN\n\tassert result == obj_to_return\n", "description": null, "category": "simple", "imports": ["from freezegun import freeze_time", "from sqlalchemy import exists, func, or_", "from sqlalchemy.orm import Session", "from src.models import SimpleModel", "from .factories import SimpleModelFactory"]}], [{"term": "def", "name": "in_tree", "data": "def in_tree(response, name, uclass, drv, depth, last_child):\n\tlines = [x.strip() for x in response.splitlines()]\n\tleaf = ' ' * 4 * depth;\n\tif not last_child:\n\t\tleaf = leaf + r'\\|'\n\telse:\n\t\tleaf = leaf + '`'\n\tleaf = leaf + '-- ' + name\n\tline = (r' *{:10.10}\t[0-9]*  \\[ [ +] \\]   {:20.20}  {}$'\n\t\t\t.format(uclass, drv, leaf))\n\tprog = re.compile(line)\n\tfor l in lines:\n\t\tif prog.match(l):\n\t\t\treturn True\n\treturn False\n\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}, {"term": "def", "name": "test_bind_unbind_with_node", "data": "def test_bind_unbind_with_node(u_boot_console):\n\n\t#bind /bind-test. Device should come up as well as its children\n\tresponse = u_boot_console.run_command('bind  /bind-test generic_simple_bus')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'generic_simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, False)\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'generic_simple_bus', 1, True)\n\n\t#Unbind child #1. No error expected and all devices should be there except for bind-test-child1\n\tresponse = u_boot_console.run_command('unbind  /bind-test/bind-test-child1')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'generic_simple_bus', 0, True)\n\tassert 'bind-test-child1' not in tree\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'generic_simple_bus', 1, True)\n\n\t#bind child #1. No error expected and all devices should be there\n\tresponse = u_boot_console.run_command('bind  /bind-test/bind-test-child1 phy_sandbox')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'generic_simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, True)\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'generic_simple_bus', 1, False)\n\n\t#Unbind child #2. No error expected and all devices should be there except for bind-test-child2\n\tresponse = u_boot_console.run_command('unbind  /bind-test/bind-test-child2')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'generic_simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, True)\n\tassert 'bind-test-child2' not in tree\n\n\n\t#Bind child #2. No error expected and all devices should be there\n\tresponse = u_boot_console.run_command('bind /bind-test/bind-test-child2 generic_simple_bus')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'generic_simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, False)\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'generic_simple_bus', 1, True)\n\n\t#Unbind parent. No error expected. All devices should be removed and unbound\n\tresponse = u_boot_console.run_command('unbind  /bind-test')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert 'bind-test' not in tree\n\tassert 'bind-test-child1' not in tree\n\tassert 'bind-test-child2' not in tree\n\n\t#try binding invalid node with valid driver\n\tresponse = u_boot_console.run_command('bind  /not-a-valid-node generic_simple_bus')\n\tassert response != ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert 'not-a-valid-node' not in tree\n\n\t#try binding valid node with invalid driver\n\tresponse = u_boot_console.run_command('bind  /bind-test not_a_driver')\n\tassert response != ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert 'bind-test' not in tree\n\n\t#bind /bind-test. Device should come up as well as its children\n\tresponse = u_boot_console.run_command('bind  /bind-test generic_simple_bus')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'generic_simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, False)\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'generic_simple_bus', 1, True)\n\n\tresponse = u_boot_console.run_command('unbind  /bind-test')\n\tassert response == ''\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}, {"term": "def", "name": "get_next_line", "data": "def get_next_line(tree, name):\n\ttreelines = [x.strip() for x in tree.splitlines() if x.strip()]\n\tchild_line = ''\n\tfor idx, line in enumerate(treelines):\n\t\tif ('-- ' + name) in line:\n\t\t\ttry:\n\t\t\t\tchild_line = treelines[idx+1]\n\t\t\texcept:\n\t\t\t\tpass\n\t\t\tbreak\n\treturn child_line\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}, {"term": "def", "name": "test_bind_unbind_with_uclass", "data": "def test_bind_unbind_with_uclass(u_boot_console):\n\t#bind /bind-test\n\tresponse = u_boot_console.run_command('bind  /bind-test generic_simple_bus')\n\tassert response == ''\n\n\t#make sure bind-test-child2 is there and get its uclass/index pair\n\ttree = u_boot_console.run_command('dm tree')\n\tchild2_line = [x.strip() for x in tree.splitlines() if '-- bind-test-child2' in x]\n\tassert len(child2_line) == 1\n\n\tchild2_uclass = child2_line[0].split()[0]\n\tchild2_index = int(child2_line[0].split()[1])\n\n\t#bind generic_simple_bus as a child of bind-test-child2\n\tresponse = u_boot_console.run_command('bind  {} {} generic_simple_bus'.format(child2_uclass, child2_index, 'generic_simple_bus'))\n\n\t#check that the child is there and its uclass/index pair is right\n\ttree = u_boot_console.run_command('dm tree')\n\n\tchild_of_child2_line = get_next_line(tree, 'bind-test-child2')\n\tassert child_of_child2_line\n\tchild_of_child2_index = int(child_of_child2_line.split()[1])\n\tassert in_tree(tree, 'generic_simple_bus', 'simple_bus', 'generic_simple_bus', 2, True)\n\tassert child_of_child2_index == child2_index + 1\n\n\t#unbind the child and check it has been removed\n\tresponse = u_boot_console.run_command('unbind  simple_bus {}'.format(child_of_child2_index))\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'generic_simple_bus', 1, True)\n\tassert not in_tree(tree, 'generic_simple_bus', 'simple_bus', 'generic_simple_bus', 2, True)\n\tchild_of_child2_line = get_next_line(tree, 'bind-test-child2')\n\tassert child_of_child2_line == ''\n\n\t#bind generic_simple_bus as a child of bind-test-child2\n\tresponse = u_boot_console.run_command('bind  {} {} generic_simple_bus'.format(child2_uclass, child2_index, 'generic_simple_bus'))\n\n\t#check that the child is there and its uclass/index pair is right\n\ttree = u_boot_console.run_command('dm tree')\n\ttreelines = [x.strip() for x in tree.splitlines() if x.strip()]\n\n\tchild_of_child2_line = get_next_line(tree, 'bind-test-child2')\n\tassert child_of_child2_line\n\tchild_of_child2_index = int(child_of_child2_line.split()[1])\n\tassert in_tree(tree, 'generic_simple_bus', 'simple_bus', 'generic_simple_bus', 2, True)\n\tassert child_of_child2_index == child2_index + 1\n\n\t#unbind the child and check it has been removed\n\tresponse = u_boot_console.run_command('unbind  {} {} generic_simple_bus'.format(child2_uclass, child2_index, 'generic_simple_bus'))\n\tassert response == ''\n\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'generic_simple_bus', 1, True)\n\n\tchild_of_child2_line = get_next_line(tree, 'bind-test-child2')\n\tassert child_of_child2_line == ''\n\n\t#unbind the child again and check it doesn't change the tree\n\ttree_old = u_boot_console.run_command('dm tree')\n\tresponse = u_boot_console.run_command('unbind  {} {} generic_simple_bus'.format(child2_uclass, child2_index, 'generic_simple_bus'))\n\ttree_new = u_boot_console.run_command('dm tree')\n\n\tassert response == ''\n\tassert tree_old == tree_new\n\n\tresponse = u_boot_console.run_command('unbind  /bind-test')\n\tassert response == ''\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}], [{"term": "def", "name": "simple_dtype", "data": "def simple_dtype():\n\tld = np.dtype(\"longdouble\")\n\treturn np.dtype(\n\t\t{\n\t\t\t\"names\": [\"bool_\", \"uint_\", \"float_\", \"ldbl_\"],\n\t\t\t\"formats\": [\"?\", \"u4\", \"f4\", \"f{}\".format(ld.itemsize)],\n\t\t\t\"offsets\": [0, 4, 8, (16 if ld.alignment > 4 else 12)],\n\t\t}\n\t)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "packed_dtype", "data": "def packed_dtype():\n\treturn np.dtype([(\"bool_\", \"?\"), (\"uint_\", \"u4\"), (\"float_\", \"f4\"), (\"ldbl_\", \"g\")])\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "dt_fmt", "data": "def dt_fmt():\n\tfrom sys import byteorder\n\n\te = \"<\" if byteorder == \"little\" else \">\"\n\treturn (\n\t\t\"{{'names':['bool_','uint_','float_','ldbl_'],\"\n\t\t\" 'formats':['?','\" + e + \"u4','\" + e + \"f4','\" + e + \"f{}'],\"\n\t\t\" 'offsets':[0,4,8,{}], 'itemsize':{}}}\"\n\t)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "simple_dtype_fmt", "data": "def simple_dtype_fmt():\n\tld = np.dtype(\"longdouble\")\n\tsimple_ld_off = 12 + 4 * (ld.alignment > 4)\n\treturn dt_fmt().format(ld.itemsize, simple_ld_off, simple_ld_off + ld.itemsize)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "packed_dtype_fmt", "data": "def packed_dtype_fmt():\n\tfrom sys import byteorder\n\n\treturn \"[('bool_', '?'), ('uint_', '{e}u4'), ('float_', '{e}f4'), ('ldbl_', '{e}f{}')]\".format(\n\t\tnp.dtype(\"longdouble\").itemsize, e=\"<\" if byteorder == \"little\" else \">\"\n\t)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "partial_ld_offset", "data": "def partial_ld_offset():\n\treturn (\n\t\t12\n\t\t+ 4 * (np.dtype(\"uint64\").alignment > 4)\n\t\t+ 8\n\t\t+ 8 * (np.dtype(\"longdouble\").alignment > 8)\n\t)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "partial_dtype_fmt", "data": "def partial_dtype_fmt():\n\tld = np.dtype(\"longdouble\")\n\tpartial_ld_off = partial_ld_offset()\n\treturn dt_fmt().format(ld.itemsize, partial_ld_off, partial_ld_off + ld.itemsize)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "partial_nested_fmt", "data": "def partial_nested_fmt():\n\tld = np.dtype(\"longdouble\")\n\tpartial_nested_off = 8 + 8 * (ld.alignment > 8)\n\tpartial_ld_off = partial_ld_offset()\n\tpartial_nested_size = partial_nested_off * 2 + partial_ld_off + ld.itemsize\n\treturn \"{{'names':['a'], 'formats':[{}], 'offsets':[{}], 'itemsize':{}}}\".format(\n\t\tpartial_dtype_fmt(), partial_nested_off, partial_nested_size\n\t)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "assert_equal", "data": "def assert_equal(actual, expected_data, expected_dtype):\n\tnp.testing.assert_equal(actual, np.array(expected_data, dtype=expected_dtype))\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_format_descriptors", "data": "def test_format_descriptors():\n\twith pytest.raises(RuntimeError) as excinfo:\n\t\tm.get_format_unbound()\n\tassert re.match(\n\t\t\"^NumPy type info missing for .*UnboundStruct.*$\", str(excinfo.value)\n\t)\n\n\tld = np.dtype(\"longdouble\")\n\tldbl_fmt = (\"4x\" if ld.alignment > 4 else \"\") + ld.char\n\tss_fmt = \"^T{?:bool_:3xI:uint_:f:float_:\" + ldbl_fmt + \":ldbl_:}\"\n\tdbl = np.dtype(\"double\")\n\tpartial_fmt = (\n\t\t\"^T{?:bool_:3xI:uint_:f:float_:\"\n\t\t+ str(4 * (dbl.alignment > 4) + dbl.itemsize + 8 * (ld.alignment > 8))\n\t\t+ \"xg:ldbl_:}\"\n\t)\n\tnested_extra = str(max(8, ld.alignment))\n\tassert m.print_format_descriptors() == [\n\t\tss_fmt,\n\t\t\"^T{?:bool_:I:uint_:f:float_:g:ldbl_:}\",\n\t\t\"^T{\" + ss_fmt + \":a:^T{?:bool_:I:uint_:f:float_:g:ldbl_:}:b:}\",\n\t\tpartial_fmt,\n\t\t\"^T{\" + nested_extra + \"x\" + partial_fmt + \":a:\" + nested_extra + \"x}\",\n\t\t\"^T{3s:a:3s:b:}\",\n\t\t\"^T{(3)4s:a:(2)i:b:(3)B:c:1x(4, 2)f:d:}\",\n\t\t\"^T{q:e1:B:e2:}\",\n\t\t\"^T{Zf:cflt:Zd:cdbl:}\",\n\t]\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_dtype", "data": "def test_dtype(simple_dtype):\n\tfrom sys import byteorder\n\n\te = \"<\" if byteorder == \"little\" else \">\"\n\n\tassert m.print_dtypes() == [\n\t\tsimple_dtype_fmt(),\n\t\tpacked_dtype_fmt(),\n\t\t\"[('a', {}), ('b', {})]\".format(simple_dtype_fmt(), packed_dtype_fmt()),\n\t\tpartial_dtype_fmt(),\n\t\tpartial_nested_fmt(),\n\t\t\"[('a', 'S3'), ('b', 'S3')]\",\n\t\t(\n\t\t\t\"{{'names':['a','b','c','d'], \"\n\t\t\t+ \"'formats':[('S4', (3,)),('\"\n\t\t\t+ e\n\t\t\t+ \"i4', (2,)),('u1', (3,)),('\"\n\t\t\t+ e\n\t\t\t+ \"f4', (4, 2))], \"\n\t\t\t+ \"'offsets':[0,12,20,24], 'itemsize':56}}\"\n\t\t).format(e=e),\n\t\t\"[('e1', '\" + e + \"i8'), ('e2', 'u1')]\",\n\t\t\"[('x', 'i1'), ('y', '\" + e + \"u8')]\",\n\t\t\"[('cflt', '\" + e + \"c8'), ('cdbl', '\" + e + \"c16')]\",\n\t]\n\n\td1 = np.dtype(\n\t\t{\n\t\t\t\"names\": [\"a\", \"b\"],\n\t\t\t\"formats\": [\"int32\", \"float64\"],\n\t\t\t\"offsets\": [1, 10],\n\t\t\t\"itemsize\": 20,\n\t\t}\n\t)\n\td2 = np.dtype([(\"a\", \"i4\"), (\"b\", \"f4\")])\n\tassert m.test_dtype_ctors() == [\n\t\tnp.dtype(\"int32\"),\n\t\tnp.dtype(\"float64\"),\n\t\tnp.dtype(\"bool\"),\n\t\td1,\n\t\td1,\n\t\tnp.dtype(\"uint32\"),\n\t\td2,\n\t]\n\n\tassert m.test_dtype_methods() == [\n\t\tnp.dtype(\"int32\"),\n\t\tsimple_dtype,\n\t\tFalse,\n\t\tTrue,\n\t\tnp.dtype(\"int32\").itemsize,\n\t\tsimple_dtype.itemsize,\n\t]\n\n\tassert m.trailing_padding_dtype() == m.buffer_to_dtype(\n\t\tnp.zeros(1, m.trailing_padding_dtype())\n\t)\n\n\tassert m.test_dtype_kind() == list(\"iiiiiuuuuuffffcccbMmO\")\n\tassert m.test_dtype_char_() == list(\"bhilqBHILQefdgFDG?MmO\")\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_recarray", "data": "def test_recarray(simple_dtype, packed_dtype):\n\telements = [(False, 0, 0.0, -0.0), (True, 1, 1.5, -2.5), (False, 2, 3.0, -5.0)]\n\n\tfor func, dtype in [\n\t\t(m.create_rec_simple, simple_dtype),\n\t\t(m.create_rec_packed, packed_dtype),\n\t]:\n\t\tarr = func(0)\n\t\tassert arr.dtype == dtype\n\t\tassert_equal(arr, [], simple_dtype)\n\t\tassert_equal(arr, [], packed_dtype)\n\n\t\tarr = func(3)\n\t\tassert arr.dtype == dtype\n\t\tassert_equal(arr, elements, simple_dtype)\n\t\tassert_equal(arr, elements, packed_dtype)\n\n\t\t# Show what recarray's look like in NumPy.\n\t\tassert type(arr[0]) == np.void\n\t\tassert type(arr[0].item()) == tuple\n\n\t\tif dtype == simple_dtype:\n\t\t\tassert m.print_rec_simple(arr) == [\n\t\t\t\t\"s:0,0,0,-0\",\n\t\t\t\t\"s:1,1,1.5,-2.5\",\n\t\t\t\t\"s:0,2,3,-5\",\n\t\t\t]\n\t\telse:\n\t\t\tassert m.print_rec_packed(arr) == [\n\t\t\t\t\"p:0,0,0,-0\",\n\t\t\t\t\"p:1,1,1.5,-2.5\",\n\t\t\t\t\"p:0,2,3,-5\",\n\t\t\t]\n\n\tnested_dtype = np.dtype([(\"a\", simple_dtype), (\"b\", packed_dtype)])\n\n\tarr = m.create_rec_nested(0)\n\tassert arr.dtype == nested_dtype\n\tassert_equal(arr, [], nested_dtype)\n\n\tarr = m.create_rec_nested(3)\n\tassert arr.dtype == nested_dtype\n\tassert_equal(\n\t\tarr,\n\t\t[\n\t\t\t((False, 0, 0.0, -0.0), (True, 1, 1.5, -2.5)),\n\t\t\t((True, 1, 1.5, -2.5), (False, 2, 3.0, -5.0)),\n\t\t\t((False, 2, 3.0, -5.0), (True, 3, 4.5, -7.5)),\n\t\t],\n\t\tnested_dtype,\n\t)\n\tassert m.print_rec_nested(arr) == [\n\t\t\"n:a=s:0,0,0,-0;b=p:1,1,1.5,-2.5\",\n\t\t\"n:a=s:1,1,1.5,-2.5;b=p:0,2,3,-5\",\n\t\t\"n:a=s:0,2,3,-5;b=p:1,3,4.5,-7.5\",\n\t]\n\n\tarr = m.create_rec_partial(3)\n\tassert str(arr.dtype) == partial_dtype_fmt()\n\tpartial_dtype = arr.dtype\n\tassert \"\" not in arr.dtype.fields\n\tassert partial_dtype.itemsize > simple_dtype.itemsize\n\tassert_equal(arr, elements, simple_dtype)\n\tassert_equal(arr, elements, packed_dtype)\n\n\tarr = m.create_rec_partial_nested(3)\n\tassert str(arr.dtype) == partial_nested_fmt()\n\tassert \"\" not in arr.dtype.fields\n\tassert \"\" not in arr.dtype.fields[\"a\"][0].fields\n\tassert arr.dtype.itemsize > partial_dtype.itemsize\n\tnp.testing.assert_equal(arr[\"a\"], m.create_rec_partial(3))\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_array_constructors", "data": "def test_array_constructors():\n\tdata = np.arange(1, 7, dtype=\"int32\")\n\tfor i in range(8):\n\t\tnp.testing.assert_array_equal(m.test_array_ctors(10 + i), data.reshape((3, 2)))\n\t\tnp.testing.assert_array_equal(m.test_array_ctors(20 + i), data.reshape((3, 2)))\n\tfor i in range(5):\n\t\tnp.testing.assert_array_equal(m.test_array_ctors(30 + i), data)\n\t\tnp.testing.assert_array_equal(m.test_array_ctors(40 + i), data)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_string_array", "data": "def test_string_array():\n\tarr = m.create_string_array(True)\n\tassert str(arr.dtype) == \"[('a', 'S3'), ('b', 'S3')]\"\n\tassert m.print_string_array(arr) == [\n\t\t\"a='',b=''\",\n\t\t\"a='a',b='a'\",\n\t\t\"a='ab',b='ab'\",\n\t\t\"a='abc',b='abc'\",\n\t]\n\tdtype = arr.dtype\n\tassert arr[\"a\"].tolist() == [b\"\", b\"a\", b\"ab\", b\"abc\"]\n\tassert arr[\"b\"].tolist() == [b\"\", b\"a\", b\"ab\", b\"abc\"]\n\tarr = m.create_string_array(False)\n\tassert dtype == arr.dtype\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_array_array", "data": "def test_array_array():\n\tfrom sys import byteorder\n\n\te = \"<\" if byteorder == \"little\" else \">\"\n\n\tarr = m.create_array_array(3)\n\tassert str(arr.dtype) == (\n\t\t\"{{'names':['a','b','c','d'], \"\n\t\t+ \"'formats':[('S4', (3,)),('\"\n\t\t+ e\n\t\t+ \"i4', (2,)),('u1', (3,)),('{e}f4', (4, 2))], \"\n\t\t+ \"'offsets':[0,12,20,24], 'itemsize':56}}\"\n\t).format(e=e)\n\tassert m.print_array_array(arr) == [\n\t\t\"a={{A,B,C,D},{K,L,M,N},{U,V,W,X}},b={0,1},\"\n\t\t+ \"c={0,1,2},d={{0,1},{10,11},{20,21},{30,31}}\",\n\t\t\"a={{W,X,Y,Z},{G,H,I,J},{Q,R,S,T}},b={1000,1001},\"\n\t\t+ \"c={10,11,12},d={{100,101},{110,111},{120,121},{130,131}}\",\n\t\t\"a={{S,T,U,V},{C,D,E,F},{M,N,O,P}},b={2000,2001},\"\n\t\t+ \"c={20,21,22},d={{200,201},{210,211},{220,221},{230,231}}\",\n\t]\n\tassert arr[\"a\"].tolist() == [\n\t\t[b\"ABCD\", b\"KLMN\", b\"UVWX\"],\n\t\t[b\"WXYZ\", b\"GHIJ\", b\"QRST\"],\n\t\t[b\"STUV\", b\"CDEF\", b\"MNOP\"],\n\t]\n\tassert arr[\"b\"].tolist() == [[0, 1], [1000, 1001], [2000, 2001]]\n\tassert m.create_array_array(0).dtype == arr.dtype\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_enum_array", "data": "def test_enum_array():\n\tfrom sys import byteorder\n\n\te = \"<\" if byteorder == \"little\" else \">\"\n\n\tarr = m.create_enum_array(3)\n\tdtype = arr.dtype\n\tassert dtype == np.dtype([(\"e1\", e + \"i8\"), (\"e2\", \"u1\")])\n\tassert m.print_enum_array(arr) == [\"e1=A,e2=X\", \"e1=B,e2=Y\", \"e1=A,e2=X\"]\n\tassert arr[\"e1\"].tolist() == [-1, 1, -1]\n\tassert arr[\"e2\"].tolist() == [1, 2, 1]\n\tassert m.create_enum_array(0).dtype == dtype\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_complex_array", "data": "def test_complex_array():\n\tfrom sys import byteorder\n\n\te = \"<\" if byteorder == \"little\" else \">\"\n\n\tarr = m.create_complex_array(3)\n\tdtype = arr.dtype\n\tassert dtype == np.dtype([(\"cflt\", e + \"c8\"), (\"cdbl\", e + \"c16\")])\n\tassert m.print_complex_array(arr) == [\n\t\t\"c:(0,0.25),(0.5,0.75)\",\n\t\t\"c:(1,1.25),(1.5,1.75)\",\n\t\t\"c:(2,2.25),(2.5,2.75)\",\n\t]\n\tassert arr[\"cflt\"].tolist() == [0.0 + 0.25j, 1.0 + 1.25j, 2.0 + 2.25j]\n\tassert arr[\"cdbl\"].tolist() == [0.5 + 0.75j, 1.5 + 1.75j, 2.5 + 2.75j]\n\tassert m.create_complex_array(0).dtype == dtype\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_signature", "data": "def test_signature(doc):\n\tassert (\n\t\tdoc(m.create_rec_nested)\n\t\t== \"create_rec_nested(arg0: int) -> numpy.ndarray[NestedStruct]\"\n\t)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_scalar_conversion", "data": "def test_scalar_conversion():\n\tn = 3\n\tarrays = [\n\t\tm.create_rec_simple(n),\n\t\tm.create_rec_packed(n),\n\t\tm.create_rec_nested(n),\n\t\tm.create_enum_array(n),\n\t]\n\tfuncs = [m.f_simple, m.f_packed, m.f_nested]\n\n\tfor i, func in enumerate(funcs):\n\t\tfor j, arr in enumerate(arrays):\n\t\t\tif i == j and i < 2:\n\t\t\t\tassert [func(arr[k]) for k in range(n)] == [k * 10 for k in range(n)]\n\t\t\telse:\n\t\t\t\twith pytest.raises(TypeError) as excinfo:\n\t\t\t\t\tfunc(arr[0])\n\t\t\t\tassert \"incompatible function arguments\" in str(excinfo.value)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_vectorize", "data": "def test_vectorize():\n\tn = 3\n\tarray = m.create_rec_simple(n)\n\tvalues = m.f_simple_vectorized(array)\n\tnp.testing.assert_array_equal(values, [0, 10, 20])\n\tarray_2 = m.f_simple_pass_thru_vectorized(array)\n\tnp.testing.assert_array_equal(array, array_2)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_cls_and_dtype_conversion", "data": "def test_cls_and_dtype_conversion(simple_dtype):\n\ts = m.SimpleStruct()\n\tassert s.astuple() == (False, 0, 0.0, 0.0)\n\tassert m.SimpleStruct.fromtuple(s.astuple()).astuple() == s.astuple()\n\n\ts.uint_ = 2\n\tassert m.f_simple(s) == 20\n\n\t# Try as recarray of shape==(1,).\n\ts_recarray = np.array([(False, 2, 0.0, 0.0)], dtype=simple_dtype)\n\t# Show that this will work for vectorized case.\n\tnp.testing.assert_array_equal(m.f_simple_vectorized(s_recarray), [20])\n\n\t# Show as a scalar that inherits from np.generic.\n\ts_scalar = s_recarray[0]\n\tassert isinstance(s_scalar, np.void)\n\tassert m.f_simple(s_scalar) == 20\n\n\t# Show that an *array* scalar (np.ndarray.shape == ()) does not convert.\n\t# More specifically, conversion to SimpleStruct is not implicit.\n\ts_recarray_scalar = s_recarray.reshape(())\n\tassert isinstance(s_recarray_scalar, np.ndarray)\n\tassert s_recarray_scalar.dtype == simple_dtype\n\twith pytest.raises(TypeError) as excinfo:\n\t\tm.f_simple(s_recarray_scalar)\n\tassert \"incompatible function arguments\" in str(excinfo.value)\n\t# Explicitly convert to m.SimpleStruct.\n\tassert m.f_simple(m.SimpleStruct.fromtuple(s_recarray_scalar.item())) == 20\n\n\t# Show that an array of dtype=object does *not* convert.\n\ts_array_object = np.array([s])\n\tassert s_array_object.dtype == object\n\twith pytest.raises(TypeError) as excinfo:\n\t\tm.f_simple_vectorized(s_array_object)\n\tassert \"incompatible function arguments\" in str(excinfo.value)\n\t# Explicitly convert to `np.array(..., dtype=simple_dtype)`\n\ts_array = np.array([s.astuple()], dtype=simple_dtype)\n\tnp.testing.assert_array_equal(m.f_simple_vectorized(s_array), [20])\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_register_dtype", "data": "def test_register_dtype():\n\twith pytest.raises(RuntimeError) as excinfo:\n\t\tm.register_dtype()\n\tassert \"dtype is already registered\" in str(excinfo.value)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_str_leak", "data": "def test_str_leak():\n\tfrom sys import getrefcount\n\n\tfmt = \"f4\"\n\tpytest.gc_collect()\n\tstart = getrefcount(fmt)\n\td = m.dtype_wrapper(fmt)\n\tassert d is np.dtype(\"f4\")\n\tdel d\n\tpytest.gc_collect()\n\tassert getrefcount(fmt) == start\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_compare_buffer_info", "data": "def test_compare_buffer_info():\n\tassert all(m.compare_buffer_info())\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}], [{"term": "def", "name": "glVertexPointerd", "data": "def glVertexPointerd( array ):\n\t\"Natural writing of glVertexPointerd using standard ctypes\"\n\targ2 = GL_DOUBLE\n\targ3 = 0 # stride\n\targ4 = arrays.asArray(array, GL_DOUBLE)\n\targ1 = arrays.arraySize( arg4, 'd' )\n\tplatform.OpenGL.glVertexPointer( arg1, arg2, arg3, arrays.ArrayDatatype.dataPointer(arg4) )\n\tglCheckError()\n\t# only store if we successfully set the value...\n\tstoredPointers[ GL_VERTEX_ARRAY ] = arg4\n", "description": null, "category": "simple", "imports": ["from OpenGL import platform, arrays, error, wrapper, contextdata, converters, constant, ERROR_ON_COPY", "from OpenGL.raw import GL as simple", "from OpenGL.raw.GL import annotations", "import ctypes", "import weakref", "\tfrom OpenGL.GL import glGetIntegerv", "\tfrom OpenGL.GL import selection, feedback"]}, {"term": "def", "name": "wrapPointerFunction", "data": "def wrapPointerFunction( name, baseFunction, glType, arrayType,startArgs, defaultSize ):\n\t\"\"\"Wrap the given pointer-setting function\"\"\"\n\tfunction= wrapper.wrapper( baseFunction )\n\tassert not getattr( function, 'pyConverters', None ), \"\"\"Reusing wrappers?\"\"\"\n\tif arrayType:\n\t\tarrayModuleType = arrays.GL_CONSTANT_TO_ARRAY_TYPE[ glType ]\n\t\tfunction.setPyConverter( 'pointer', arrays.asArrayType(arrayModuleType) )\n\telse:\n\t\tfunction.setPyConverter( 'pointer', arrays.AsArrayOfType('pointer','type') )\n\tfunction.setCConverter( 'pointer', converters.getPyArgsName( 'pointer' ) )\n\tif 'size' in function.argNames:\n\t\tfunction.setPyConverter( 'size' )\n\t\tfunction.setCConverter( 'size', arrays.arraySizeOfFirstType(arrayModuleType,defaultSize) )\n\tif 'type' in function.argNames:\n\t\tfunction.setPyConverter( 'type' )\n\t\tfunction.setCConverter( 'type', glType )\n\tif 'stride' in function.argNames:\n\t\tfunction.setPyConverter( 'stride' )\n\t\tfunction.setCConverter( 'stride', 0 )\n\tfunction.setStoreValues( arrays.storePointerType( 'pointer', arrayType ) )\n\tfunction.setReturnValues( wrapper.returnPyArgument( 'pointer' ) )\n\treturn name,function\n\n\n", "description": "Wrap the given pointer-setting function", "category": "simple", "imports": ["from OpenGL import platform, arrays, error, wrapper, contextdata, converters, constant, ERROR_ON_COPY", "from OpenGL.raw import GL as simple", "from OpenGL.raw.GL import annotations", "import ctypes", "import weakref", "\tfrom OpenGL.GL import glGetIntegerv", "\tfrom OpenGL.GL import selection, feedback"]}, {"term": "def", "name": "glDrawElementsTyped", "data": "def glDrawElementsTyped( type, suffix ):\n\tarrayType = arrays.GL_CONSTANT_TO_ARRAY_TYPE[ type ]\n\tfunction = wrapper.wrapper( \n\t\tsimple.glDrawElements \n\t).setPyConverter('type').setCConverter(\n\t\t'type', type\n\t).setPyConverter('count').setCConverter(\n\t\t'count', arrays.AsArrayTypedSize( 'indices', arrayType ),\n\t).setPyConverter(\n\t\t'indices', arrays.AsArrayTyped( 'indices', arrayType ),\n\t).setReturnValues(\n\t\twrapper.returnPyArgument( 'indices' )\n\t)\n", "description": null, "category": "simple", "imports": ["from OpenGL import platform, arrays, error, wrapper, contextdata, converters, constant, ERROR_ON_COPY", "from OpenGL.raw import GL as simple", "from OpenGL.raw.GL import annotations", "import ctypes", "import weakref", "\tfrom OpenGL.GL import glGetIntegerv", "\tfrom OpenGL.GL import selection, feedback"]}, {"term": "def", "name": "glSelectBuffer", "data": "def glSelectBuffer( size, buffer = None ):\n\t\"\"\"Create a selection buffer of the given size\n\t\"\"\"\n\tif buffer is None:\n\t\tbuffer = arrays.GLuintArray.zeros( (size,) )\n\tsimple.glSelectBuffer( size, buffer )\n\tcontextdata.setValue( simple.GL_SELECTION_BUFFER_POINTER, buffer )\n", "description": "Create a selection buffer of the given size\n\t", "category": "simple", "imports": ["from OpenGL import platform, arrays, error, wrapper, contextdata, converters, constant, ERROR_ON_COPY", "from OpenGL.raw import GL as simple", "from OpenGL.raw.GL import annotations", "import ctypes", "import weakref", "\tfrom OpenGL.GL import glGetIntegerv", "\tfrom OpenGL.GL import selection, feedback"]}, {"term": "def", "name": "glFeedbackBuffer", "data": "def glFeedbackBuffer( size, type, buffer = None ):\n\t\"\"\"Create a selection buffer of the given size\n\t\"\"\"\n\tif buffer is None:\n\t\tbuffer = arrays.GLfloatArray.zeros( (size,) )\n\tsimple.glFeedbackBuffer( size, type, buffer )\n\tcontextdata.setValue( simple.GL_FEEDBACK_BUFFER_POINTER, buffer )\n\tcontextdata.setValue( \"GL_FEEDBACK_BUFFER_TYPE\", type )\n\treturn buffer\n", "description": "Create a selection buffer of the given size\n\t", "category": "simple", "imports": ["from OpenGL import platform, arrays, error, wrapper, contextdata, converters, constant, ERROR_ON_COPY", "from OpenGL.raw import GL as simple", "from OpenGL.raw.GL import annotations", "import ctypes", "import weakref", "\tfrom OpenGL.GL import glGetIntegerv", "\tfrom OpenGL.GL import selection, feedback"]}, {"term": "def", "name": "glRenderMode", "data": "def glRenderMode( newMode ):\n\t\"\"\"Change to the given rendering mode\n\t\n\tIf the current mode is GL_FEEDBACK or GL_SELECT, return\n\tthe current buffer appropriate to the mode\n\t\"\"\"\n\t# must get the current mode to determine operation...\n\tfrom OpenGL.GL import glGetIntegerv\n\tfrom OpenGL.GL import selection, feedback\n\tcurrentMode = glGetIntegerv( simple.GL_RENDER_MODE )\n\ttry:\n\t\tcurrentMode = currentMode[0]\n\texcept (TypeError,ValueError,IndexError), err:\n\t\tpass\n\tif currentMode in (simple.GL_RENDER,0):\n\t\t# no array needs to be returned...\n\t\treturn simple.glRenderMode( newMode )\n\tresult = simple.glRenderMode( newMode )\n\t# result is now an integer telling us how many elements were copied...\n\t\n\tif result < 0:\n\t\tif currentMode == simple.GL_SELECT:\n\t\t\traise error.GLError(\n\t\t\t\tsimple.GL_STACK_OVERFLOW,\n\t\t\t\t\"glSelectBuffer too small to hold selection results\",\n\t\t\t)\n\t\telif currentMode == simple.GL_FEEDBACK:\n\t\t\traise error.GLError(\n\t\t\t\tsimple.GL_STACK_OVERFLOW,\n\t\t\t\t\"glFeedbackBuffer too small to hold selection results\",\n\t\t\t)\n\t\telse:\n\t\t\traise error.GLError(\n\t\t\t\tsimple.GL_STACK_OVERFLOW,\n\t\t\t\t\"Unknown glRenderMode buffer (%s) too small to hold selection results\"%(\n\t\t\t\t\tcurrentMode,\n\t\t\t\t),\n\t\t\t)\n\t# Okay, now that the easy cases are out of the way...\n\t#  Do we have a pre-stored pointer about which the user already knows?\n\tcontext = platform.GetCurrentContext()\n\tif context == 0:\n\t\traise error.Error(\n\t\t\t\"\"\"Returning from glRenderMode without a valid context!\"\"\"\n\t\t)\n\tarrayConstant, wrapperFunction = {\n\t\tsimple.GL_FEEDBACK: (simple.GL_FEEDBACK_BUFFER_POINTER,feedback.parseFeedback),\n\t\tsimple.GL_SELECT: (simple.GL_SELECTION_BUFFER_POINTER, selection.GLSelectRecord.fromArray),\n\t}[ currentMode ]\n\tcurrent = contextdata.getValue( arrayConstant )\n\t# XXX check to see if it's the *same* array we set currently!\n\tif current is None:\n\t\tcurrent = glGetPointerv( arrayConstant )\n\t# XXX now, can turn the array into the appropriate wrapper type...\n\tif wrapperFunction:\n\t\tcurrent = wrapperFunction( current, result )\n\treturn current\n", "description": "Change to the given rendering mode\n\t\n\tIf the current mode is GL_FEEDBACK or GL_SELECT, return\n\tthe current buffer appropriate to the mode\n\t", "category": "simple", "imports": ["from OpenGL import platform, arrays, error, wrapper, contextdata, converters, constant, ERROR_ON_COPY", "from OpenGL.raw import GL as simple", "from OpenGL.raw.GL import annotations", "import ctypes", "import weakref", "\tfrom OpenGL.GL import glGetIntegerv", "\tfrom OpenGL.GL import selection, feedback"]}, {"term": "def", "name": "glGetPointerv", "data": "def glGetPointerv( constant ):\n\t\"\"\"Retrieve a stored pointer constant\"\"\"\n\t# do we have a cached version of the pointer?\n\t# get the base pointer from the underlying operation\n\tvp = ctypes.voidp()\n\tsimple.glGetPointerv( constant, ctypes.byref(vp) )\n\tcurrent = contextdata.getValue( constant )\n\tif current is not None:\n\t\tif arrays.ArrayDatatype.dataPointer( current ) == vp.value:\n\t\t\treturn current\n\t# XXX should be coercing to the proper type and converting to an array\n", "description": "Retrieve a stored pointer constant", "category": "simple", "imports": ["from OpenGL import platform, arrays, error, wrapper, contextdata, converters, constant, ERROR_ON_COPY", "from OpenGL.raw import GL as simple", "from OpenGL.raw.GL import annotations", "import ctypes", "import weakref", "\tfrom OpenGL.GL import glGetIntegerv", "\tfrom OpenGL.GL import selection, feedback"]}], [{"term": "class", "name": "BrowserTestRunnerTest", "data": "class BrowserTestRunnerTest(unittest.TestCase):\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "_ExtractTestResults", "data": "  def _ExtractTestResults(self, test_result):\n\tdelimiter = test_result['path_delimiter']\n\tfailures = []\n\tsuccesses = []\n\tdef _IsLeafNode(node):\n\t  test_dict = node[1]\n\t  return ('expected' in test_dict and\n\t\t\t  isinstance(test_dict['expected'], basestring))\n\tnode_queues = []\n\tfor t in test_result['tests']:\n\t  node_queues.append((t, test_result['tests'][t]))\n\twhile node_queues:\n\t  node = node_queues.pop()\n\t  full_test_name, test_dict = node\n\t  if _IsLeafNode(node):\n\t\tif all(res not in test_dict['expected'].split() for res in\n\t\t\t   test_dict['actual'].split()):\n\t\t  failures.append(full_test_name)\n\t\telse:\n\t\t  successes.append(full_test_name)\n\t  else:\n\t\tfor k in test_dict:\n\t\t  node_queues.append(\n\t\t\t('%s%s%s' % (full_test_name, delimiter, k),\n\t\t\t test_dict[k]))\n\treturn successes, failures\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "baseTest", "data": "  def baseTest(self, test_filter,\n\t\t\t   failures, successes, test_name='SimpleTest'):\n\tconfig = project_config.ProjectConfig(\n\t\ttop_level_dir=os.path.join(util.GetTelemetryDir(), 'examples'),\n\t\tclient_configs=[],\n\t\tbenchmark_dirs=[\n\t\t\tos.path.join(util.GetTelemetryDir(), 'examples', 'browser_tests')]\n\t)\n\ttemp_file = tempfile.NamedTemporaryFile(delete=False)\n\ttemp_file.close()\n\ttemp_file_name = temp_file.name\n\ttry:\n\t  browser_test_runner.Run(\n\t\t  config,\n\t\t  [test_name,\n\t\t   '--write-full-results-to=%s' % temp_file_name,\n\t\t   '--test-filter=%s' % test_filter])\n\t  with open(temp_file_name) as f:\n\t\ttest_result = json.load(f)\n\n\t  actual_successes, actual_failures = self._ExtractTestResults(test_result)\n\t  self.assertEquals(set(actual_failures), set(failures))\n\t  self.assertEquals(set(actual_successes), set(successes))\n\tfinally:\n\t  os.remove(temp_file_name)\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "testJsonOutputFormatNegativeFilter", "data": "  def testJsonOutputFormatNegativeFilter(self):\n\tself.baseTest(\n\t  '^(add|multiplier).*',\n\t  ['browser_tests.simple_numeric_test.SimpleTest.add_1_and_2',\n\t   'browser_tests.simple_numeric_test.SimpleTest.add_7_and_3',\n\t   'browser_tests.simple_numeric_test.SimpleTest.multiplier_simple_2'],\n\t  ['browser_tests.simple_numeric_test.SimpleTest.add_2_and_3',\n\t   'browser_tests.simple_numeric_test.SimpleTest.multiplier_simple',\n\t   'browser_tests.simple_numeric_test.SimpleTest.multiplier_simple_3'])\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "testJsonOutputWhenSetupClassFailed", "data": "  def testJsonOutputWhenSetupClassFailed(self):\n\tself.baseTest(\n\t  '.*',\n\t  ['browser_tests.failed_tests.SetUpClassFailedTest.dummy_test_0',\n\t   'browser_tests.failed_tests.SetUpClassFailedTest.dummy_test_1',\n\t   'browser_tests.failed_tests.SetUpClassFailedTest.dummy_test_2'],\n\t  [], test_name='SetUpClassFailedTest')\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "testJsonOutputWhenTearDownClassFailed", "data": "  def testJsonOutputWhenTearDownClassFailed(self):\n\tself.baseTest(\n\t  '.*',\n\t  ['browser_tests.failed_tests.TearDownClassFailedTest.dummy_test_0',\n\t   'browser_tests.failed_tests.TearDownClassFailedTest.dummy_test_1',\n\t   'browser_tests.failed_tests.TearDownClassFailedTest.dummy_test_2'],\n\t  [], test_name='TearDownClassFailedTest')\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "testSetUpProcessCalledOnce", "data": "  def testSetUpProcessCalledOnce(self):\n\tself.baseTest(\n\t  '.*',\n\t  [],\n\t  ['browser_tests.process_tests.FailIfSetUpProcessCalledTwice.Dummy_0',\n\t   'browser_tests.process_tests.FailIfSetUpProcessCalledTwice.Dummy_1',\n\t   'browser_tests.process_tests.FailIfSetUpProcessCalledTwice.Dummy_2'],\n\t  test_name='FailIfSetUpProcessCalledTwice')\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "testTearDownProcessCalledOnce", "data": "  def testTearDownProcessCalledOnce(self):\n\tself.baseTest(\n\t  '.*',\n\t  [],\n\t  ['browser_tests.process_tests.FailIfTearDownProcessCalledTwice.Dummy_0',\n\t   'browser_tests.process_tests.FailIfTearDownProcessCalledTwice.Dummy_1',\n\t   'browser_tests.process_tests.FailIfTearDownProcessCalledTwice.Dummy_2'],\n\t  test_name='FailIfTearDownProcessCalledTwice')\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "testJsonOutputFormatPositiveFilter", "data": "  def testJsonOutputFormatPositiveFilter(self):\n\tself.baseTest(\n\t  '(TestSimple|TestException).*',\n\t  ['browser_tests.simple_numeric_test.SimpleTest.TestException',\n\t   'browser_tests.simple_numeric_test.SimpleTest.TestSimple'], [])\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "testExecutingTestsInSortedOrder", "data": "  def testExecutingTestsInSortedOrder(self):\n\talphabetical_tests = []\n\tprefix = 'browser_tests.simple_numeric_test.SimpleTest.Alphabetical_'\n\tfor i in xrange(20):\n\t  alphabetical_tests.append(prefix + str(i))\n\tfor c in string.uppercase[:26]:\n\t  alphabetical_tests.append(prefix + c)\n\tfor c in string.lowercase[:26]:\n\t  alphabetical_tests.append(prefix + c)\n\talphabetical_tests.sort()\n\tself.baseTest(\n\t\t'Alphabetical', [], alphabetical_tests)\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "shardingRangeTestHelper", "data": "  def shardingRangeTestHelper(self, total_shards, num_tests):\n\tshard_ranges = []\n\tfor shard_index in xrange(0, total_shards):\n\t  shard_ranges.append(run_browser_tests._TestRangeForShard(\n\t\ttotal_shards, shard_index, num_tests))\n\t# Make assertions about ranges\n\tnum_tests_run = 0\n\tfor i in xrange(0, len(shard_ranges)):\n\t  cur_range = shard_ranges[i]\n\t  if i < num_tests:\n\t\tself.assertGreater(cur_range[1], cur_range[0])\n\t\tnum_tests_run += (cur_range[1] - cur_range[0])\n\t  else:\n\t\t# Not enough tests to go around all of the shards.\n\t\tself.assertEquals(cur_range[0], cur_range[1])\n\t# Make assertions about non-overlapping ranges\n\tfor i in xrange(1, len(shard_ranges)):\n\t  prev_range = shard_ranges[i - 1]\n\t  cur_range = shard_ranges[i]\n\t  self.assertEquals(prev_range[1], cur_range[0])\n\t# Assert that we run all of the tests (very important)\n\tself.assertEquals(num_tests_run, num_tests)\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "testShardsWithPrimeNumTests", "data": "  def testShardsWithPrimeNumTests(self):\n\tfor total_shards in xrange(1, 20):\n\t  # Nice non-prime number\n\t  self.shardingRangeTestHelper(total_shards, 101)\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "testShardsWithDivisibleNumTests", "data": "  def testShardsWithDivisibleNumTests(self):\n\tfor total_shards in xrange(1, 6):\n\t  self.shardingRangeTestHelper(total_shards, 8)\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "testShardBoundaryConditions", "data": "  def testShardBoundaryConditions(self):\n\tself.shardingRangeTestHelper(1, 0)\n\tself.shardingRangeTestHelper(1, 1)\n\tself.shardingRangeTestHelper(2, 1)\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "baseShardingTest", "data": "  def baseShardingTest(self, total_shards, shard_index, failures, successes,\n\t\t\t\t\t   opt_abbr_input_json_file=None,\n\t\t\t\t\t   opt_test_filter='',\n\t\t\t\t\t   opt_filter_tests_after_sharding=False):\n\tconfig = project_config.ProjectConfig(\n\t\ttop_level_dir=os.path.join(util.GetTelemetryDir(), 'examples'),\n\t\tclient_configs=[],\n\t\tbenchmark_dirs=[\n\t\t\tos.path.join(util.GetTelemetryDir(), 'examples', 'browser_tests')]\n\t)\n\ttemp_file = tempfile.NamedTemporaryFile(delete=False)\n\ttemp_file.close()\n\ttemp_file_name = temp_file.name\n\topt_args = []\n\tif opt_abbr_input_json_file:\n\t  opt_args += [\n\t\t'--read-abbreviated-json-results-from=%s' % opt_abbr_input_json_file]\n\tif opt_test_filter:\n\t  opt_args += [\n\t\t'--test-filter=%s' % opt_test_filter]\n\tif opt_filter_tests_after_sharding:\n\t  opt_args += ['--filter-tests-after-sharding']\n\ttry:\n\t  browser_test_runner.Run(\n\t\t  config,\n\t\t  ['SimpleShardingTest',\n\t\t   '--write-full-results-to=%s' % temp_file_name,\n\t\t   '--total-shards=%d' % total_shards,\n\t\t   '--shard-index=%d' % shard_index] + opt_args)\n\t  with open(temp_file_name) as f:\n\t\ttest_result = json.load(f)\n\t  actual_successes, actual_failures = self._ExtractTestResults(test_result)\n\t  self.assertEquals(set(actual_failures), set(failures))\n\t  self.assertEquals(set(actual_successes), set(successes))\n\tfinally:\n\t  os.remove(temp_file_name)\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "testShardedTestRun", "data": "  def testShardedTestRun(self):\n\tself.baseShardingTest(3, 0, [], [\n\t  'browser_tests.simple_sharding_test.SimpleShardingTest.Test1',\n\t  'browser_tests.simple_sharding_test.SimpleShardingTest.Test2',\n\t  'browser_tests.simple_sharding_test.SimpleShardingTest.Test3',\n\t  'browser_tests.simple_sharding_test.SimpleShardingTest.passing_test_0',\n\t  'browser_tests.simple_sharding_test.SimpleShardingTest.passing_test_1',\n\t])\n\tself.baseShardingTest(3, 1, [], [\n\t  'browser_tests.simple_sharding_test.SimpleShardingTest.passing_test_2',\n\t  'browser_tests.simple_sharding_test.SimpleShardingTest.passing_test_3',\n\t  'browser_tests.simple_sharding_test.SimpleShardingTest.passing_test_4',\n\t  'browser_tests.simple_sharding_test.SimpleShardingTest.passing_test_5',\n\t])\n\tself.baseShardingTest(3, 2, [], [\n\t  'browser_tests.simple_sharding_test.SimpleShardingTest.passing_test_6',\n\t  'browser_tests.simple_sharding_test.SimpleShardingTest.passing_test_7',\n\t  'browser_tests.simple_sharding_test.SimpleShardingTest.passing_test_8',\n\t  'browser_tests.simple_sharding_test.SimpleShardingTest.passing_test_9',\n\t])\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "writeMockTestResultsFile", "data": "  def writeMockTestResultsFile(self):\n\tmock_test_results = {\n\t  'passes': [\n\t\t'Test1',\n\t\t'Test2',\n\t\t'Test3',\n\t\t'passing_test_0',\n\t\t'passing_test_1',\n\t\t'passing_test_2',\n\t\t'passing_test_3',\n\t\t'passing_test_4',\n\t\t'passing_test_5',\n\t\t'passing_test_6',\n\t\t'passing_test_7',\n\t\t'passing_test_8',\n\t\t'passing_test_9',\n\t  ],\n\t  'failures': [],\n\t  'valid': True,\n\t  'times': {\n\t\t'Test1': 3.0,\n\t\t'Test2': 3.0,\n\t\t'Test3': 3.0,\n\t\t'passing_test_0': 3.0,\n\t\t'passing_test_1': 2.0,\n\t\t'passing_test_2': 2.0,\n\t\t'passing_test_3': 2.0,\n\t\t'passing_test_4': 2.0,\n\t\t'passing_test_5': 1.0,\n\t\t'passing_test_6': 1.0,\n\t\t'passing_test_7': 1.0,\n\t\t'passing_test_8': 1.0,\n\t\t'passing_test_9': 0.5,\n\t  }\n\t}\n\ttemp_file = tempfile.NamedTemporaryFile(delete=False)\n\ttemp_file.close()\n\ttemp_file_name = temp_file.name\n\twith open(temp_file_name, 'w') as f:\n\t  json.dump(mock_test_results, f)\n\treturn temp_file_name\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "testSplittingShardsByTimes", "data": "  def testSplittingShardsByTimes(self):\n\ttemp_file_name = self.writeMockTestResultsFile()\n\t# It seems that the sorting order of the first four tests above is:\n\t#   passing_test_0, Test1, Test2, Test3\n\t# This is probably because the relative order of the \"fixed\" tests\n\t# (starting with \"Test\") and the generated ones (\"passing_\") is\n\t# not well defined, and the sorting is stable afterward.  The\n\t# expectations have been adjusted for this fact.\n\ttry:\n\t  self.baseShardingTest(\n\t\t4, 0, [],\n\t\t['browser_tests.simple_sharding_test.SimpleShardingTest.passing_test_0',\n\t\t 'browser_tests.simple_sharding_test.SimpleShardingTest.passing_test_1',\n\t\t 'browser_tests.simple_sharding_test.SimpleShardingTest.passing_test_5',\n\t\t 'browser_tests.simple_sharding_test.SimpleShardingTest.passing_test_9'\n\t\t], temp_file_name)\n\t  self.baseShardingTest(\n\t\t4, 1, [],\n\t\t['browser_tests.simple_sharding_test.SimpleShardingTest.Test1',\n\t\t 'browser_tests.simple_sharding_test.SimpleShardingTest.passing_test_2',\n\t\t 'browser_tests.simple_sharding_test.SimpleShardingTest.passing_test_6'\n\t\t], temp_file_name)\n\t  self.baseShardingTest(\n\t\t4, 2, [],\n\t\t['browser_tests.simple_sharding_test.SimpleShardingTest.Test2',\n\t\t 'browser_tests.simple_sharding_test.SimpleShardingTest.passing_test_3',\n\t\t 'browser_tests.simple_sharding_test.SimpleShardingTest.passing_test_7'\n\t\t], temp_file_name)\n\t  self.baseShardingTest(\n\t\t4, 3, [],\n\t\t['browser_tests.simple_sharding_test.SimpleShardingTest.Test3',\n\t\t 'browser_tests.simple_sharding_test.SimpleShardingTest.passing_test_4',\n\t\t 'browser_tests.simple_sharding_test.SimpleShardingTest.passing_test_8'\n\t\t], temp_file_name)\n\tfinally:\n\t  os.remove(temp_file_name)\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "testFilteringAfterSharding", "data": "  def testFilteringAfterSharding(self):\n\ttemp_file_name = self.writeMockTestResultsFile()\n\ttry:\n\t  self.baseShardingTest(\n\t\t4, 1, [],\n\t\t['browser_tests.simple_sharding_test.SimpleShardingTest.Test1',\n\t\t 'browser_tests.simple_sharding_test.SimpleShardingTest.passing_test_2',\n\t\t 'browser_tests.simple_sharding_test.SimpleShardingTest.passing_test_6'\n\t\t], temp_file_name,\n\t\topt_test_filter='(Test1|passing_test_2|passing_test_6)',\n\t\topt_filter_tests_after_sharding=True)\n\tfinally:\n\t  os.remove(temp_file_name)\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "testMedianComputation", "data": "  def testMedianComputation(self):\n\tself.assertEquals(2.0, run_browser_tests._MedianTestTime(\n\t  {'test1': 2.0, 'test2': 7.0, 'test3': 1.0}))\n\tself.assertEquals(2.0, run_browser_tests._MedianTestTime(\n\t  {'test1': 2.0}))\n\tself.assertEquals(0.0, run_browser_tests._MedianTestTime({}))\n\tself.assertEqual(4.0, run_browser_tests._MedianTestTime(\n\t  {'test1': 2.0, 'test2': 6.0, 'test3': 1.0, 'test4': 8.0}))\n\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "class", "name": "Algebra", "data": "class Algebra(\n\tserially_executed_browser_test_case.SeriallyExecutedBrowserTestCase):\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "GenerateTestCases_Simple", "data": "  def GenerateTestCases_Simple(cls, options):\n\tdel options  # Unused.\n\tyield 'testOne', (1, 2)\n\tyield 'testTwo', (3, 3)\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "Simple", "data": "  def Simple(self, x, y):\n\tself.assertEquals(x, y)\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "TestNumber", "data": "  def TestNumber(self):\n\tself.assertEquals(0, 1)\n\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "class", "name": "ErrorneousGeometric", "data": "class ErrorneousGeometric(\n\tserially_executed_browser_test_case.SeriallyExecutedBrowserTestCase):\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "GenerateTestCases_Compare", "data": "  def GenerateTestCases_Compare(cls, options):\n\tdel options  # Unused.\n\tassert False, 'I am a problematic generator'\n\tyield 'testBasic', ('square', 'circle')\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "Compare", "data": "  def Compare(self, x, y):\n\tself.assertEquals(x, y)\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "TestAngle", "data": "  def TestAngle(self):\n\tself.assertEquals(90, 450)\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "testLoadAllTestsInModule", "data": "  def testLoadAllTestsInModule(self):\n\tcontext = browser_test_context.TypTestContext()\n\tcontext.finder_options = options_for_unittests.GetCopy()\n\tcontext.test_class = Algebra\n\tcontext.test_case_ids_to_run.add(\n\t  'telemetry.testing.browser_test_runner_unittest.Algebra.TestNumber')\n\tcontext.test_case_ids_to_run.add(\n\t  'telemetry.testing.browser_test_runner_unittest.Algebra.testOne')\n\tcontext.Freeze()\n\tbrowser_test_context._global_test_context = context\n\ttry:\n\t  # This should not invoke GenerateTestCases of ErrorneousGeometric class,\n\t  # otherwise that would throw Exception.\n\t  tests = serially_executed_browser_test_case.LoadAllTestsInModule(\n\t\t  sys.modules[__name__])\n\t  self.assertEquals(sorted([t.id() for t in tests]),\n\t\t  ['telemetry.testing.browser_test_runner_unittest.Algebra.TestNumber',\n\t\t   'telemetry.testing.browser_test_runner_unittest.Algebra.testOne'])\n\tfinally:\n\t  browser_test_context._global_test_context = None\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}], [{"term": "class", "name": "classSimpleTreeNode:", "data": "class SimpleTreeNode:\n\t\n\tdef __init__(self, val, parent):\n\t\tself.NodeValue = val \n\t\tself.Parent = parent \n\t\tself.Children = [] \n", "description": null, "category": "simple", "imports": ["import unittest"]}, {"term": "class", "name": "classSimpleTree:", "data": "class SimpleTree:\n\n\tdef __init__(self, root):\n\t\tself.Root = root\n\t\n\tdef AddChild(self, ParentNode, NewChild):\n\t\tParentNode.Children.append(NewChild)\n\t\tNewChild.Parent = ParentNode\n  \n\tdef DeleteNode(self, NodeToDelete):\n\t\tNodeToDelete.Parent.Children.remove(NodeToDelete)\n\t\tNodeToDelete.Parent = None \n\n\tdef FindNodesByValue(self, val):\n\t\tx = self.GetAllNodes()\n\t\tresult = []\n\t\tfor node in x:\n\t\t\tif node.NodeValue == val:\n\t\t\t\tresult.append(node)\n\t\treturn result\n\n\tdef GetAllNodes(self,result = [], count = 0):\n\t\tif count == 0:\n\t\t\tif self.Root is not None:\n\t\t\t\tresult.append(self.Root)\n\t\t\telse:\n\t\t\t\treturn result\n\t\tfor i in range(len(result[count].Children)):\n\t\t\tresult.append(result[count].Children[i])\n\t\tcount += 1\n\t\tif count < len(result):\n\t\t\treturn self.GetAllNodes(result, count)\n\t\telse:\t\n\t\t\treturn result\n\n\t\"\"\"def GetAllNodes(self):\n\t\tresult = []\n\t\tcurNode = self.Root \n\t\tcont = True \n\t\tlevel = 1\n\t\tdepth = {1:0} \n\t\tdirection = True \n\t\tif curNode is None:\n\t\t\treturn result\n\t\telif len(curNode.Children) == 0:\n\t\t\tresult.append(curNode)\n\t\t\treturn result\n\t\telse:\n\t\t\tresult.append(curNode)  \n\t\twhile cont:\n\t\t\tif direction == True:\n\t\t\t\tif len(curNode.Children) != 0:\n\t\t\t\t\tlevel += 1\n\t\t\t\t\tif (level in depth) is False:\n\t\t\t\t\t\tcurNode = curNode.Children[0]\n\t\t\t\t\t\tresult.append(curNode)\n\t\t\t\t\t\tdepth[level] = 0\n\t\t\t\t\telse:\n\t\t\t\t\t\tdepth[level] += 1\n\t\t\t\t\t\tcurNode = curNode.Children[depth[leve]]\n\t\t\t\t\t\tresult.append(curNode)\t\t\t\t\t  \n\t\t\t\telse:\n\t\t\t\t\tcurNode = curNode.Parent\n\t\t\t\t\tdirection = False\n\t\t\telse:\n\t\t\t\tif len(curNode.Children) > depth[level]+1:\n\t\t\t\t\tdepth[level] += 1\n\t\t\t\t\tcurNode = curNode.Children[depth[level]]\n\t\t\t\t\tresult.append(curNode)\n\t\t\t\t\tdirection = True\n\t\t\t\telse:\n\t\t\t\t\tif curNode is self.Root:\n\t\t\t\t\t\treturn result\n\t\t\t\t\telse:\n\t\t\t\t\t\tcurNode = curNode.Parent\n\t\t\t\t\t\tdel depth[level]\n\t\t\t\t\t\tlevel -= 1\"\"\"\t\t\n\n\tdef FindNodesByValue(self, val):\n\t\tx = self.GetAllNodes()\n\t\tresult = []\n\t\tfor node in x:\n\t\t\tif node.NodeValue == val:\n\t\t\t\tresult.append(node)\n\t\treturn result\n\n\tdef MoveNode(self, OriginalNode, NewParent):\n\t\tOriginalNode.Parent.Children.remove(OriginalNode)\n\t\tNewParent.Children.append(OriginalNode)\n\t\tOriginalNode.Parent = NewParent\n   \n\tdef Count(self):\n\t\treturn len(self.GetAllNodes())\n\n\tdef LeafCount(self):\n\t\tx = self.GetAllNodes()\n\t\tresult = 0\n\t\tfor node in x:\n\t\t\tif len(node.Children) == 0:\n\t\t\t\tresult += 1\n\t\treturn result\n\n\tdef EvenTrees(self):\n\t\tallNodes = self.GetAllNodes()\n\t\tcount = len(allNodes)-1\n\t\tpool = []\n\t\tresult = []\n\t\twhile len(allNodes)>2:\n\t\t\tif len(pool) == 0:\n\t\t\t\tpool.append(allNodes.pop())\n\t\t\t\tcount -= 1\n\t\t\telse:\n\t\t\t\tif allNodes[count].Parent is pool[0].Parent:\n\t\t\t\t\tpool.append(allNodes.pop())\n\t\t\t\t\tcount -= 1\n\t\t\t\telse:\n\t\t\t\t\tif len(pool)%2 != 0:\n\t\t\t\t\t\tresult.insert(0, pool[0].Parent.Parent)\n\t\t\t\t\t\tresult.insert(1, pool[0].Parent)\n\t\t\t\t\t\tallNodes.remove(pool[0].Parent)\n\t\t\t\t\t\tpool = []\n\t\t\t\t\t\tcount = len(allNodes)-1\n\t\t\t\t\telse:\n\t\t\t\t\t\tpool = []\n\t\t\t\t\t\tcount = len(allNodes)-1\n\t\treturn result\n", "description": "def GetAllNodes(self):\n\t\tresult = []\n\t\tcurNode = self.Root \n\t\tcont = True \n\t\tlevel = 1\n\t\tdepth = {1:0} \n\t\tdirection = True \n\t\tif curNode is None:\n\t\t\treturn result\n\t\telif len(curNode.Children) == 0:\n\t\t\tresult.append(curNode)\n\t\t\treturn result\n\t\telse:\n\t\t\tresult.append(curNode)  \n\t\twhile cont:\n\t\t\tif direction == True:\n\t\t\t\tif len(curNode.Children) != 0:\n\t\t\t\t\tlevel += 1\n\t\t\t\t\tif (level in depth) is False:\n\t\t\t\t\t\tcurNode = curNode.Children[0]\n\t\t\t\t\t\tresult.append(curNode)\n\t\t\t\t\t\tdepth[level] = 0\n\t\t\t\t\telse:\n\t\t\t\t\t\tdepth[level] += 1\n\t\t\t\t\t\tcurNode = curNode.Children[depth[leve]]\n\t\t\t\t\t\tresult.append(curNode)\t\t\t\t\t  \n\t\t\t\telse:\n\t\t\t\t\tcurNode = curNode.Parent\n\t\t\t\t\tdirection = False\n\t\t\telse:\n\t\t\t\tif len(curNode.Children) > depth[level]+1:\n\t\t\t\t\tdepth[level] += 1\n\t\t\t\t\tcurNode = curNode.Children[depth[level]]\n\t\t\t\t\tresult.append(curNode)\n\t\t\t\t\tdirection = True\n\t\t\t\telse:\n\t\t\t\t\tif curNode is self.Root:\n\t\t\t\t\t\treturn result\n\t\t\t\t\telse:\n\t\t\t\t\t\tcurNode = curNode.Parent\n\t\t\t\t\t\tdel depth[level]\n\t\t\t\t\t\tlevel -= 1", "category": "simple", "imports": ["import unittest"]}, {"term": "class", "name": "TestSimpleTree", "data": "class TestSimpleTree(unittest.TestCase):\n\tdef setUp(self):\n\t\tself.simpleTree = SimpleTree(SimpleTreeNode(1,None))\n\n\t\"\"\"def testRoot(self):\n\t\tassert self.simpleTree.Root.NodeValue == 1\n\n\tdef testAddChildRoot(self):\n\t\tself.simpleTree.AddChild(self.simpleTree.Root, SimpleTreeNode(2, None))\n\t\tassert len(self.simpleTree.Root.Children) == 1\n\t\tassert self.simpleTree.Root.Children[0].NodeValue == 2\n\n\tdef testAddChildRoot(self):\n\t\tself.simpleTree.AddChild(self.simpleTree.Root, SimpleTreeNode(2, None))\n\t\tself.simpleTree.AddChild(self.simpleTree.Root, SimpleTreeNode(3, None))\n\t\tassert len(self.simpleTree.Root.Children) == 2\n\t\tassert self.simpleTree.Root.Children[0].NodeValue == 2\n\t\tassert self.simpleTree.Root.Children[1].NodeValue == 3\n\n\tdef testAddChildRootChild(self):\n\t\tself.simpleTree.AddChild(self.simpleTree.Root, SimpleTreeNode(2, None))\n\t\tself.simpleTree.AddChild(self.simpleTree.Root.Children[0], SimpleTreeNode(3, None))\n\t\tassert len(self.simpleTree.Root.Children[0].Children) == 1\n\t\tassert self.simpleTree.Root.Children[0].Children[0].NodeValue == 3\n\n\tdef testDeleteRootChild1(self):\n\t\tself.simpleTree.AddChild(self.simpleTree.Root, SimpleTreeNode(2, None))\n\t\tself.simpleTree.DeleteNode(self.simpleTree.Root.Children[0])\n\t\tassert len(self.simpleTree.Root.Children) == 0\n\n\tdef testDeleteRoot1Child2(self):\n\t\tself.simpleTree.AddChild(self.simpleTree.Root, SimpleTreeNode(2, None))\n\t\tself.simpleTree.AddChild(self.simpleTree.Root, SimpleTreeNode(3, None))\n\t\tself.simpleTree.DeleteNode(self.simpleTree.Root.Children[0])\n\t\tassert len(self.simpleTree.Root.Children) == 1\n\t\tassert self.simpleTree.Root.Children[0].NodeValue == 3\n\n\tdef testDeleteRoot2Child2(self):\n\t\tself.simpleTree.AddChild(self.simpleTree.Root, SimpleTreeNode(2, None))\n\t\tself.simpleTree.AddChild(self.simpleTree.Root, SimpleTreeNode(3, None))\n\t\tself.simpleTree.DeleteNode(self.simpleTree.Root.Children[1])\n\t\tassert len(self.simpleTree.Root.Children) == 1\n\t\tassert self.simpleTree.Root.Children[0].NodeValue == 2\"\"\"\n\n\tdef testGetAllNodes1Node(self):\n\t\ttestList = self.simpleTree.GetAllNodes()\n\t\tprint(testList)\n\t\tassert testList[0] == self.simpleTree.Root\n\n\tdef testGetAllNodes1Child(self):\n\t\tself.simpleTree.AddChild(self.simpleTree.Root, SimpleTreeNode(2, None))\n\t\ttestList = self.simpleTree.GetAllNodes()\n\t\tprint(testList)\n\t\tassert len(testList) == 2\n\t\tassert testList[0] == self.simpleTree.Root\n\t\tassert testList[1] == self.simpleTree.Root.Children[0]\n", "description": "def testRoot(self):\n\t\tassert self.simpleTree.Root.NodeValue == 1\n\n\tdef testAddChildRoot(self):\n\t\tself.simpleTree.AddChild(self.simpleTree.Root, SimpleTreeNode(2, None))\n\t\tassert len(self.simpleTree.Root.Children) == 1\n\t\tassert self.simpleTree.Root.Children[0].NodeValue == 2\n\n\tdef testAddChildRoot(self):\n\t\tself.simpleTree.AddChild(self.simpleTree.Root, SimpleTreeNode(2, None))\n\t\tself.simpleTree.AddChild(self.simpleTree.Root, SimpleTreeNode(3, None))\n\t\tassert len(self.simpleTree.Root.Children) == 2\n\t\tassert self.simpleTree.Root.Children[0].NodeValue == 2\n\t\tassert self.simpleTree.Root.Children[1].NodeValue == 3\n\n\tdef testAddChildRootChild(self):\n\t\tself.simpleTree.AddChild(self.simpleTree.Root, SimpleTreeNode(2, None))\n\t\tself.simpleTree.AddChild(self.simpleTree.Root.Children[0], SimpleTreeNode(3, None))\n\t\tassert len(self.simpleTree.Root.Children[0].Children) == 1\n\t\tassert self.simpleTree.Root.Children[0].Children[0].NodeValue == 3\n\n\tdef testDeleteRootChild1(self):\n\t\tself.simpleTree.AddChild(self.simpleTree.Root, SimpleTreeNode(2, None))\n\t\tself.simpleTree.DeleteNode(self.simpleTree.Root.Children[0])\n\t\tassert len(self.simpleTree.Root.Children) == 0\n\n\tdef testDeleteRoot1Child2(self):\n\t\tself.simpleTree.AddChild(self.simpleTree.Root, SimpleTreeNode(2, None))\n\t\tself.simpleTree.AddChild(self.simpleTree.Root, SimpleTreeNode(3, None))\n\t\tself.simpleTree.DeleteNode(self.simpleTree.Root.Children[0])\n\t\tassert len(self.simpleTree.Root.Children) == 1\n\t\tassert self.simpleTree.Root.Children[0].NodeValue == 3\n\n\tdef testDeleteRoot2Child2(self):\n\t\tself.simpleTree.AddChild(self.simpleTree.Root, SimpleTreeNode(2, None))\n\t\tself.simpleTree.AddChild(self.simpleTree.Root, SimpleTreeNode(3, None))\n\t\tself.simpleTree.DeleteNode(self.simpleTree.Root.Children[1])\n\t\tassert len(self.simpleTree.Root.Children) == 1\n\t\tassert self.simpleTree.Root.Children[0].NodeValue == 2", "category": "simple", "imports": ["import unittest"]}], [{"term": "class", "name": "SimpleSitemap", "data": "class SimpleSitemap(Sitemap):\n\tchangefreq = \"never\"\n\tpriority = 0.5\n\tlocation = '/location/'\n\tlastmod = datetime.now()\n\n\tdef items(self):\n\t\treturn [object()]\n\n", "description": null, "category": "simple", "imports": ["from datetime import date, datetime", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.urls import path", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "SimplePagedSitemap", "data": "class SimplePagedSitemap(Sitemap):\n\tdef items(self):\n\t\treturn [object() for x in range(Sitemap.limit + 1)]\n\n", "description": null, "category": "simple", "imports": ["from datetime import date, datetime", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.urls import path", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "SimpleI18nSitemap", "data": "class SimpleI18nSitemap(Sitemap):\n\tchangefreq = \"never\"\n\tpriority = 0.5\n\ti18n = True\n\n\tdef items(self):\n\t\treturn I18nTestModel.objects.order_by('pk').all()\n\n", "description": null, "category": "simple", "imports": ["from datetime import date, datetime", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.urls import path", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "AlternatesI18nSitemap", "data": "class AlternatesI18nSitemap(SimpleI18nSitemap):\n\talternates = True\n\n", "description": null, "category": "simple", "imports": ["from datetime import date, datetime", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.urls import path", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "LimitedI18nSitemap", "data": "class LimitedI18nSitemap(AlternatesI18nSitemap):\n\tlanguages = ['en', 'es']\n\n", "description": null, "category": "simple", "imports": ["from datetime import date, datetime", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.urls import path", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "XDefaultI18nSitemap", "data": "class XDefaultI18nSitemap(AlternatesI18nSitemap):\n\tx_default = True\n\n", "description": null, "category": "simple", "imports": ["from datetime import date, datetime", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.urls import path", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "EmptySitemap", "data": "class EmptySitemap(Sitemap):\n\tchangefreq = \"never\"\n\tpriority = 0.5\n\tlocation = '/location/'\n\n", "description": null, "category": "simple", "imports": ["from datetime import date, datetime", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.urls import path", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "FixedLastmodSitemap", "data": "class FixedLastmodSitemap(SimpleSitemap):\n\tlastmod = datetime(2013, 3, 13, 10, 0, 0)\n\n", "description": null, "category": "simple", "imports": ["from datetime import date, datetime", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.urls import path", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "FixedLastmodMixedSitemap", "data": "class FixedLastmodMixedSitemap(Sitemap):\n\tchangefreq = \"never\"\n\tpriority = 0.5\n\tlocation = '/location/'\n\tloop = 0\n\n\tdef items(self):\n\t\to1 = TestModel()\n\t\to1.lastmod = datetime(2013, 3, 13, 10, 0, 0)\n\t\to2 = TestModel()\n\t\treturn [o1, o2]\n\n", "description": null, "category": "simple", "imports": ["from datetime import date, datetime", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.urls import path", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "FixedNewerLastmodSitemap", "data": "class FixedNewerLastmodSitemap(SimpleSitemap):\n\tlastmod = datetime(2013, 4, 20, 5, 0, 0)\n\n", "description": null, "category": "simple", "imports": ["from datetime import date, datetime", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.urls import path", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "DateSiteMap", "data": "class DateSiteMap(SimpleSitemap):\n\tlastmod = date(2013, 3, 13)\n\n", "description": null, "category": "simple", "imports": ["from datetime import date, datetime", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.urls import path", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "TimezoneSiteMap", "data": "class TimezoneSiteMap(SimpleSitemap):\n\tlastmod = datetime(2013, 3, 13, 10, 0, 0, tzinfo=timezone.get_fixed_timezone(-300))\n\n", "description": null, "category": "simple", "imports": ["from datetime import date, datetime", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.urls import path", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "def", "name": "testmodelview", "data": "def testmodelview(request, id):\n\treturn HttpResponse()\n\n", "description": null, "category": "simple", "imports": ["from datetime import date, datetime", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.urls import path", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}], [{"term": "class", "name": "TestDictCache", "data": "class TestDictCache(unittest.TestCase):\n\t\"\"\" Test the DictCache backend\n\t\"\"\"\n\n\tdef setUp(self):\n\t\tfrom supycache.backends import DictCache\n\t\tself.cache = DictCache()\n\n\tdef tearDown(self):\n\t\tself.cache.clear()\n\n\tdef test_init(self):\n\t\t\"\"\"Testing DictCache constructor\"\"\"\n\t\tself.assertTrue(hasattr(self.cache, 'set'))\n\t\tself.assertTrue(hasattr(self.cache, 'get'))\n\t\tself.assertTrue(hasattr(self.cache, 'clear'))\n\n\tdef test_methods(self):\n\t\t\"\"\"Testing DictCache methods\"\"\"\n\t\tself.cache.set('key', 'value')\n\t\tself.assertTrue(self.cache.get('key') == 'value')\n\t\tself.assertTrue(bool(self.cache.get('non-existent')) == False)\n\t\tself.assertTrue(self.cache.clear() == None)\n\t\tself.assertTrue(len(self.cache._data) == 0)\n\n", "description": " Test the DictCache backend\n\t", "category": "simple", "imports": ["import unittest", "import supycache", "\t\tfrom supycache.backends import DictCache", "\tfrom supycache.backends import DictCache", "\t\tfrom supycache.backends import DictCache", "\t\tfrom supycache.backends import DictCache"]}, {"term": "def", "name": "test_get_set_default_backend", "data": "def test_get_set_default_backend():\n\t\"\"\"Testing get/set default_backend\"\"\"\n\treload(supycache) # - re-init\n\tfrom supycache.backends import DictCache\n\tassert(supycache.default_backend == None)\n\tassert(isinstance(supycache.get_default_backend(), DictCache))\n\tassert(isinstance(supycache.default_backend, DictCache))\n\tnew_backend = DictCache()\n\tsupycache.set_default_backend(new_backend)\n\tassert(supycache.get_default_backend() is new_backend)\n\tassert(supycache.default_backend is new_backend)\n", "description": "Testing get/set default_backend", "category": "simple", "imports": ["import unittest", "import supycache", "\t\tfrom supycache.backends import DictCache", "\tfrom supycache.backends import DictCache", "\t\tfrom supycache.backends import DictCache", "\t\tfrom supycache.backends import DictCache"]}, {"term": "class", "name": "TestCacheDecorators", "data": "class TestCacheDecorators(unittest.TestCase):\n\t\"\"\" Test the CacheDecorators\n\t\"\"\"\n\n\tdef setUp(self):\n\t\tfrom supycache.backends import DictCache\n\t\tself.backend = DictCache()\n\t\tsupycache.default_backend = self.backend\n\n\tdef tearDown(self):\n\t\tself.backend.clear()\n\n\tdef test_missing_options(self):\n\t\t\"\"\" missing option\n\t\t\"\"\"\n\t\twith self.assertRaises(KeyError) as context:\n\t\t\t@supycache.supycache()\n\t\t\tdef simple_function():\n\t\t\t\treturn 'dummy'\n\n\t\tself.assertTrue('expecting one of' in context.exception.message)\n\n\n\tdef test_do_not_ignore_errors(self):\n\t\t\"\"\" do not ignore errors\n\t\t\"\"\"\n\t\tfrom supycache.backends import DictCache\n\n\t\tclass TestException(Exception):\n\t\t\tpass\n\n\t\tclass DummyBackend:\n\t\t\tconfig = {}\n\n\t\t\tdef raise_exc(self, *args):\n\t\t\t\t\"\"\"dummy function to raise exception, used later\"\"\"\n\t\t\t\traise TestException()\n\n\t\tbackend = DummyBackend()\n\t\tsupycache.set_default_backend(backend) # override setUp()\n\n\t\t@supycache.supycache(cache_key='simple_key', ignore_errors=False)\n\t\tdef simple_function():\n\t\t\treturn 'simple_value'\n\n\t\t# - test exception in get() with ignore_errors=False\n\t\twith self.assertRaises(TestException) as context:\n\t\t\tbackend.get = backend.raise_exc\n\t\t\tsimple_function()\n\n\t\t# - test exception in set() with ignore_errors=False\n\t\twith self.assertRaises(TestException) as context:\n\t\t\tbackend.get = lambda key: None\n\t\t\tbackend.set = backend.raise_exc\n\t\t\tsimple_function()\n\n\t\t# - test exception in delete() with ignore_errors=False\n\t\twith self.assertRaises(TestException) as context:\n\t\t\tbackend.delete = backend.raise_exc\n\t\t\tsimple_function()\n\n\n\tdef test_decorator_for_cache_key_cache_miss(self):\n\t\t\"\"\" caching a simple key on a cache miss\n\t\t\"\"\"\n\t\t@supycache.supycache(cache_key='simple_key')\n\t\tdef simple_function():\n\t\t\treturn 'simple_value'\n\n\t\tsimple_function()\n\t\tself.assertTrue(self.backend.get('simple_key') == 'simple_value')\n\n\tdef test_decorator_for_cache_key_cached(self):\n\t\t\"\"\" caching a simple key and return from cache\n\t\t\"\"\"\n\n\t\t@supycache.supycache(cache_key='simple_key')\n\t\tdef simple_function(call_count):\n\t\t\treturn '%d:cached_value' % call_count\n\n\t\tsimple_function(1)\n\t\tself.assertTrue(self.backend.get('simple_key') == '1:cached_value')\n\n\t\tsimple_function(2)\n\t\tself.assertTrue(self.backend.get('simple_key') == '1:cached_value')\n\n\t\tsimple_function(3)\n\t\tself.assertTrue(self.backend.get('simple_key') == '1:cached_value')\n\n\n\tdef test_decorator_for_cache_key_positional_args(self):\n\t\t\"\"\" caching a key built from positional arguments and returning from cache\n\t\t\"\"\"\n\n\t\t@supycache.supycache(cache_key='{0}')\n\t\tdef simple_function(x, y):\n\t\t\treturn '%d:cached_value' % y\n\n\t\tsimple_function('key', 1)\n\t\tself.assertTrue(self.backend.get('key') == '1:cached_value')\n\n\t\tsimple_function('key', 2)\n\t\tself.assertTrue(self.backend.get('key') == '1:cached_value')\n\n\t\tsimple_function('new_key', 3)\n\t\tself.assertTrue(self.backend.get('new_key') == '3:cached_value')\n\n\n\tdef test_decorator_for_cache_key_keyword_args(self):\n\t\t\"\"\" caching a key built from keyword arguments and returning from cache\n\t\t\"\"\"\n\n\t\t@supycache.supycache(cache_key='{somearg}')\n\t\tdef simple_function(call_count, somearg):\n\t\t\treturn '%d:cached_value' % call_count\n\n\t\tsimple_function(1, somearg='key')\n\t\tself.assertTrue(self.backend.get('key') == '1:cached_value')\n\n\t\tsimple_function(2, somearg='key')\n\t\tself.assertTrue(self.backend.get('key') == '1:cached_value')\n\n\t\tsimple_function(3, somearg='new_key')\n\t\tself.assertTrue(self.backend.get('new_key') == '3:cached_value')\n\n\n\tdef test_decorator_for_cache_key_multi_args_simple(self):\n\t\t\"\"\" caching a key built from both positional and keyword arguments and returning from cache\n\t\t\"\"\"\n\n\t\t@supycache.supycache(cache_key='{0}_{keyword}')\n\t\tdef simple_function(positional, call_count, keyword=''):\n\t\t\treturn '%d:cached_value' % call_count\n\n\t\tsimple_function('some', 1, keyword='key')\n\t\tself.assertTrue(self.backend.get('some_key') == '1:cached_value')\n\n\t\tsimple_function('some', 2, keyword='key')\n\t\tself.assertTrue(self.backend.get('some_key') == '1:cached_value')\n\n\t\tsimple_function('some_other', 1, keyword='new_key')\n\t\tself.assertTrue(self.backend.get('some_other_new_key') == '1:cached_value')\n\n\n\tdef test_decorator_for_cache_key_multi_args_complex_list(self):\n\t\t\"\"\" caching a key built from elements of a list passed as an argument\n\t\t\"\"\"\n\n\t\t@supycache.supycache(cache_key='{0}_{arglist[0]}')\n\t\tdef simple_function(positional, call_count, arglist=None):\n\t\t\treturn '%d:cached_value' % call_count\n\n\t\tsimple_function('some', 1, arglist=['key', 'dummy'])\n\t\tself.assertTrue(self.backend.get('some_key') == '1:cached_value')\n\n\t\tsimple_function('some', 2, arglist=['key', 'changed'])\n\t\tself.assertTrue(self.backend.get('some_key') == '1:cached_value')\n\n\t\tsimple_function('some_other', 1, arglist=['new_key', 'dummy'])\n\t\tself.assertTrue(self.backend.get('some_other_new_key') == '1:cached_value')\n\n\t\tsimple_function('yet_another', 1, arglist=['new_key', 'dummy'])\n\t\tself.assertTrue(self.backend.get('yet_another_new_key') == '1:cached_value')\n\n\n\tdef test_decorator_for_cache_key_multi_args_complex_dict(self):\n\t\t\"\"\" caching a key built from elements of a dict passed as an argument\n\t\t\"\"\"\n\n\t\t@supycache.supycache(cache_key='{0}_{argdict[lookup]}')\n\t\tdef simple_function(positional, call_count, argdict=None):\n\t\t\treturn '%d:cached_value' % call_count\n\n\t\tsimple_function('some', 1, argdict={'lookup' : 'key'})\n\t\tself.assertTrue(self.backend.get('some_key') == '1:cached_value')\n\n\t\tsimple_function('some', 2, argdict={'lookup' : 'key'})\n\t\tself.assertTrue(self.backend.get('some_key') == '1:cached_value')\n\n\t\tsimple_function('some_other', 1, argdict={'lookup' : 'new_key'})\n\t\tself.assertTrue(self.backend.get('some_other_new_key') == '1:cached_value')\n\n\n\tdef test_decorator_for_cache_key_multi_args_complex_object(self):\n\t\t\"\"\" caching a key built from attributes of an object passed as an argument\n\t\t\"\"\"\n\n\t\t@supycache.supycache(cache_key='{0}_{arg.name}')\n\t\tdef simple_function(positional, call_count, arg):\n\t\t\treturn '%d:cached_value' % call_count\n\n\t\tclass DummyArg:\n\t\t\tdef __init__(self, value):\n\t\t\t\tself.name = value\n\n\t\tsimple_function('some', 1, arg=DummyArg('key'))\n\t\tself.assertTrue(self.backend.get('some_key') == '1:cached_value')\n\n\t\tsimple_function('some', 2, arg=DummyArg('key'))\n\t\tself.assertTrue(self.backend.get('some_key') == '1:cached_value')\n\n\t\tsimple_function('some_other', 1, arg=DummyArg('new_key'))\n\t\tself.assertTrue(self.backend.get('some_other_new_key') == '1:cached_value')\n\n\n\tdef test_decorator_for_expire_key_with_cached_key(self):\n\t\t\"\"\" expire a simple key which exists in cache\n\t\t\"\"\"\n\t\t@supycache.supycache(cache_key='simple_key')\n\t\tdef simple_function():\n\t\t\treturn 'simple_value'\n\n\t\t@supycache.supycache(expire_key='simple_key')\n\t\tdef simple_expiry():\n\t\t\treturn 'ignored_value'\n\n\t\tsimple_function()\n\t\tself.assertTrue(self.backend.get('simple_key') == 'simple_value')\n\n\t\tsimple_expiry()\n\t\tself.assertFalse(bool(self.backend.get('simple_key')))\n\n\n\tdef test_decorator_for_expire_key_with_non_cached_key(self):\n\t\t\"\"\" expire a simple key with does not exist in cache\n\t\t\"\"\"\n\n\t\t@supycache.supycache(cache_key='simple_key')\n\t\tdef simple_function():\n\t\t\treturn 'simple_value'\n\n\t\t@supycache.supycache(expire_key='simple_key')\n\t\tdef simple_expiry():\n\t\t\treturn 'ignored_value'\n\n\t\tsimple_function()\n\t\tself.assertTrue(self.backend.get('simple_key') == 'simple_value')\n\n\t\tsimple_expiry()\n\t\tself.assertFalse(bool(self.backend.get('simple_key')))\n\t\tself.assertFalse(bool(self.backend.get('simple_key')))\n\n\n\tdef test_decorator_for_expire_key_positional_args(self):\n\t\t\"\"\" expire a key built from positional arguments\n\t\t\"\"\"\n\n\t\t@supycache.supycache(cache_key='{0}')\n\t\tdef simple_function(x, y):\n\t\t\treturn 'cached_value'\n\n\t\t@supycache.supycache(expire_key='{0}')\n\t\tdef simple_expiry(x, y):\n\t\t\treturn 'ignored_value'\n\n\t\tsimple_function('simple_key', 1)\n\t\tself.assertTrue(self.backend.get('simple_key') == 'cached_value')\n\n\t\tsimple_expiry('simple_key', 'dummy')\n\t\tself.assertFalse(bool(self.backend.get('simple_key')))\n", "description": " Test the CacheDecorators\n\t", "category": "simple", "imports": ["import unittest", "import supycache", "\t\tfrom supycache.backends import DictCache", "\tfrom supycache.backends import DictCache", "\t\tfrom supycache.backends import DictCache", "\t\tfrom supycache.backends import DictCache"]}], [{"term": "class", "name": "TestSimpleMove", "data": "class TestSimpleMove(unittest.TestCase):\n\n\tdef test_init(self):\n\t\tm1 = SimpleMove(BLACK, P77, P76, PAWN)\n\t\tself.assertEqual(m1.turn, BLACK)\n\t\tself.assertEqual(m1.from_, P77)\n\t\tself.assertEqual(m1.to, P76)\n\t\tself.assertEqual(m1.piece_type, PAWN)\n\n\t\tm2 = SimpleMove(WHITE, HAND, P11, BISHOP)\n\t\tself.assertEqual(m2.turn, WHITE)\n\t\tself.assertEqual(m2.from_, HAND)\n\t\tself.assertEqual(m2.to, P11)\n\t\tself.assertEqual(m2.piece_type, BISHOP)\n\n\tdef test_init_invalid(self):\n\t\tself.assertRaises(AssertionError, SimpleMove, 1, 2, 3, 4)\n\t\tself.assertRaises(AssertionError, SimpleMove, None, None, None, None)\n\t\tself.assertRaises(AssertionError, SimpleMove, BLACK, None, None, None)\n\t\tself.assertRaises(AssertionError, SimpleMove, BLACK, P77, None, None)\n\t\tself.assertRaises(AssertionError, SimpleMove, BLACK, P77, P76, None)\n\t\tself.assertRaises(AssertionError, SimpleMove, BLACK, P77, P77, PAWN)\n\t\tself.assertRaises(AssertionError, SimpleMove, BLACK, P77, HAND, PAWN)\n\n\tdef test_eq(self):\n\t\tself.assertEqual(SimpleMove(BLACK, P77, P76, PAWN) == 1, False)\n\t\tself.assertEqual(SimpleMove(BLACK, P77, P76, PAWN) == SimpleMove(WHITE, P77, P76, PAWN), False)\n\t\tself.assertEqual(SimpleMove(BLACK, P77, P76, PAWN) == SimpleMove(BLACK, P77, P76, PAWN), True)\n\n\tdef test_str(self):\n\t\tself.assertEqual(str(SimpleMove(BLACK, P77, P76, PAWN)), '+7776FU')\n\n\tdef test_repr(self):\n\t\texp = 'SimpleMove(turn=Turn(value=0), from_=Pos(value=60), to=Pos(value=51), piece_type=PieceType(value=5))'\n\t\tself.assertEqual(repr(SimpleMove(BLACK, P77, P76, PAWN)), exp)\n\n\tdef test_wrap(self):\n\t\tself.assertEqual(SimpleMove.wrap(cmogcore.SimpleMove(0, 60, 51, 5)), SimpleMove(BLACK, P77, P76, PAWN))\n\t\tself.assertEqual(SimpleMove.wrap(SimpleMove(BLACK, P77, P76, PAWN)), SimpleMove(BLACK, P77, P76, PAWN))\n\n\tdef test_from_string(self):\n\t\tself.assertEqual(SimpleMove.from_string('+7776FU'), SimpleMove(BLACK, P77, P76, PAWN))\n\n\tdef test_from_string_invalid(self):\n\t\tself.assertRaises(ValueError, SimpleMove.from_string, '')\n\t\tself.assertRaises(ValueError, SimpleMove.from_string, '+')\n\t\tself.assertRaises(ValueError, SimpleMove.from_string, '+77')\n\t\tself.assertRaises(ValueError, SimpleMove.from_string, '+7776')\n\t\tself.assertRaises(ValueError, SimpleMove.from_string, '+7776FU ')\n\t\tself.assertRaises(ValueError, SimpleMove.from_string, 0)\n\t\tself.assertRaises(ValueError, SimpleMove.from_string, None)\n", "description": null, "category": "simple", "imports": ["import unittest", "from mogcore import *", "import cmogcore"]}], [{"term": "def", "name": "asInt", "data": "def asInt( value ):\n\tif isinstance( value, float ):\n\t\treturn int(round(value,0))\n\treturn value\n", "description": null, "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "def", "name": "fglReadPixels", "data": "\tdef glReadPixels( x,y,width,height,format,type=type, array=None ):\n\t\t\"\"\"Read specified pixels from the current display buffer\n\t\t\n\t\tThis typed version returns data in your specified default \n\t\tarray data-type format, or in the passed array, which will \n\t\tbe converted to the array-type required by the format.\n\t\t\"\"\"\n\t\tx,y,width,height = asInt(x),asInt(y),asInt(width),asInt(height)\n\t\tarrayType = arrays.GL_CONSTANT_TO_ARRAY_TYPE[ images.TYPE_TO_ARRAYTYPE.get(type,type) ]\n\t\tif array is None:\n\t\t\tarray = images.SetupPixelRead( format, (width,height), type )\n\t\telse:\n\t\t\tarray = arrayType.asArray( array )\n\t\timageData = arrayType.voidDataPointer( array )\n\t\tsimple.glReadPixels( \n\t\t\tint(x),int(y),\n\t\t\tint(width), int(height),\n\t\t\tformat,type, \n\t\t\timageData\n\t\t)\n", "description": "Read specified pixels from the current display buffer\n\t\t\n\t\tThis typed version returns data in your specified default \n\t\tarray data-type format, or in the passed array, which will \n\t\tbe converted to the array-type required by the format.\n\t\t", "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "def", "name": "fglGetTexImage", "data": "\tdef glGetTexImage( target, level,format,type=type ):\n\t\t\"\"\"Get a texture-level as an image\"\"\"\n\t\tfrom OpenGL.GL import glget\n\t\tdims = [glget.glGetTexLevelParameteriv( target, level, simple.GL_TEXTURE_WIDTH )]\n\t\tif target != simple.GL_TEXTURE_1D:\n\t\t\tdims.append( glget.glGetTexLevelParameteriv( target, level, simple.GL_TEXTURE_HEIGHT ) )\n\t\t\tif target != simple.GL_TEXTURE_2D:\n\t\t\t\tdims.append( glget.glGetTexLevelParameteriv( target, level, simple.GL_TEXTURE_DEPTH ) )\n\t\tarray = images.SetupPixelRead( format, tuple(dims), type )\n\t\tarrayType = arrays.GL_CONSTANT_TO_ARRAY_TYPE[ images.TYPE_TO_ARRAYTYPE.get(type,type) ]\n\t\tsimple.glGetTexImage( \n\t\t\ttarget, level, format, type, ctypes.c_void_p( arrayType.dataPointer(array)) \n\t\t)\n", "description": "Get a texture-level as an image", "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "def", "name": "glReadPixels", "data": "def glReadPixels( x,y,width,height,format,type, array=None, outputType=str ):\n\t\"\"\"Read specified pixels from the current display buffer\n\t\n\tx,y,width,height -- location and dimensions of the image to read \n\t\tfrom the buffer\n\tformat -- pixel format for the resulting data\n\ttype -- data-format for the resulting data\n\tarray -- optional array/offset into which to store the value\n\toutputType -- default (str) provides string output of the \n\t\tresults iff OpenGL.UNSIGNED_BYTE_IMAGES_AS_STRING is True \n\t\tand type == GL_UNSIGNED_BYTE.  Any other value will cause \n\t\toutput in the default array output format.\n\t\n\treturns the pixel data array in the format defined by the \n\tformat, type and outputType\n\t\"\"\"\n\tx,y,width,height = asInt(x),asInt(y),asInt(width),asInt(height)\n\t\n\tarrayType = arrays.GL_CONSTANT_TO_ARRAY_TYPE[ images.TYPE_TO_ARRAYTYPE.get(type,type) ]\n\tif array is None:\n\t\tarray = images.SetupPixelRead( format, (width,height), type )\n\telse:\n\t\tarray = arrayType.asArray( array )\n\timageData = arrayType.voidDataPointer( array )\n\tsimple.glReadPixels( \n\t\tx,y,width,height,\n\t\tformat,type, \n\t\timageData\n\t)\n\tif outputType is str:\n\t\treturn images.returnFormat( array, type )\n\telse:\n\t\treturn array\n", "description": "Read specified pixels from the current display buffer\n\t\n\tx,y,width,height -- location and dimensions of the image to read \n\t\tfrom the buffer\n\tformat -- pixel format for the resulting data\n\ttype -- data-format for the resulting data\n\tarray -- optional array/offset into which to store the value\n\toutputType -- default (str) provides string output of the \n\t\tresults iff OpenGL.UNSIGNED_BYTE_IMAGES_AS_STRING is True \n\t\tand type == GL_UNSIGNED_BYTE.  Any other value will cause \n\t\toutput in the default array output format.\n\t\n\treturns the pixel data array in the format defined by the \n\tformat, type and outputType\n\t", "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "def", "name": "glGetTexImage", "data": "def glGetTexImage( target, level,format,type, outputType=str ):\n\t\"\"\"Get a texture-level as an image\n\t\n\ttarget -- enum constant for the texture engine to be read \n\tlevel -- the mip-map level to read \n\tformat -- image format to read out the data \n\ttype -- data-type into which to read the data\n\t\n\toutputType -- default (str) provides string output of the \n\t\tresults iff OpenGL.UNSIGNED_BYTE_IMAGES_AS_STRING is True \n\t\tand type == GL_UNSIGNED_BYTE.  Any other value will cause \n\t\toutput in the default array output format.\n\t\n\treturns the pixel data array in the format defined by the \n\tformat, type and outputType\n\t\"\"\"\n\tfrom OpenGL.GL import glget\n\tdims = [glget.glGetTexLevelParameteriv( target, level, simple.GL_TEXTURE_WIDTH )]\n\tif target != simple.GL_TEXTURE_1D:\n\t\tdims.append( glget.glGetTexLevelParameteriv( target, level, simple.GL_TEXTURE_HEIGHT ) )\n\t\tif target != simple.GL_TEXTURE_2D:\n\t\t\tdims.append( glget.glGetTexLevelParameteriv( target, level, simple.GL_TEXTURE_DEPTH ) )\n\tarray = images.SetupPixelRead( format, tuple(dims), type )\n\tarrayType = arrays.GL_CONSTANT_TO_ARRAY_TYPE[ images.TYPE_TO_ARRAYTYPE.get(type,type) ]\n\tsimple.glGetTexImage( \n\t\ttarget, level, format, type, ctypes.c_void_p( arrayType.dataPointer(array)) \n\t)\n\tif outputType is str:\n\t\treturn images.returnFormat( array, type )\n\telse:\n\t\treturn array\n\n", "description": "Get a texture-level as an image\n\t\n\ttarget -- enum constant for the texture engine to be read \n\tlevel -- the mip-map level to read \n\tformat -- image format to read out the data \n\ttype -- data-type into which to read the data\n\t\n\toutputType -- default (str) provides string output of the \n\t\tresults iff OpenGL.UNSIGNED_BYTE_IMAGES_AS_STRING is True \n\t\tand type == GL_UNSIGNED_BYTE.  Any other value will cause \n\t\toutput in the default array output format.\n\t\n\treturns the pixel data array in the format defined by the \n\tformat, type and outputType\n\t", "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "def", "name": "asWrapper", "data": "def asWrapper( value ):\n\tif not isinstance( value, wrapper.Wrapper ):\n\t\treturn wrapper.wrapper( value )\n\treturn value\n", "description": null, "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "def", "name": "asIntConverter", "data": "def asIntConverter( value, *args ):\n\tif isinstance( value, float ):\n\t\treturn int(round(value,0))\n\treturn value\n", "description": null, "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "def", "name": "setDimensionsAsInts", "data": "def setDimensionsAsInts( baseOperation ):\n\t\"\"\"Set arguments with names in INT_DIMENSION_NAMES to asInt processing\"\"\"\n\tbaseOperation = asWrapper( baseOperation )\n\targNames = getattr( baseOperation, 'pyConverterNames', baseOperation.argNames )\n\tfor i,argName in enumerate(argNames):\n\t\tif argName in INT_DIMENSION_NAMES:\n\t\t\tbaseOperation.setPyConverter( argName, asIntConverter )\n\treturn baseOperation\n\n\t\n", "description": "Set arguments with names in INT_DIMENSION_NAMES to asInt processing", "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "class", "name": "ImageInputConverter", "data": "class ImageInputConverter( object ):\n\tdef __init__( self, rank, pixelsName=None, typeName='type' ):\n\t\tself.rank = rank\n\t\tself.typeName = typeName\n\t\tself.pixelsName = pixelsName\n\tdef finalise( self, wrapper ):\n\t\t\"\"\"Get our pixel index from the wrapper\"\"\"\n\t\tself.typeIndex = wrapper.pyArgIndex( self.typeName )\n\t\tself.pixelsIndex = wrapper.pyArgIndex( self.pixelsName )\n\tdef __call__( self, arg, baseOperation, pyArgs ):\n\t\t\"\"\"pyConverter for the pixels argument\"\"\"\n\t\timages.setupDefaultTransferMode()\n\t\timages.rankPacking( self.rank )\n\t\ttype = pyArgs[ self.typeIndex ]\n\t\tarrayType = arrays.GL_CONSTANT_TO_ARRAY_TYPE[ images.TYPE_TO_ARRAYTYPE[ type ] ]\n", "description": "Get our pixel index from the wrapper", "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "class", "name": "TypedImageInputConverter", "data": "class TypedImageInputConverter( ImageInputConverter ):\n\tdef __init__( self, rank, pixelsName, arrayType, typeName=None ):\n\t\tself.rank = rank\n\t\tself.arrayType = arrayType\n\t\tself.pixelsName = pixelsName\n\t\tself.typeName = typeName\n\tdef __call__( self, arg, baseOperation, pyArgs ):\n\t\t\"\"\"The pyConverter for the pixels\"\"\"\n\t\timages.setupDefaultTransferMode()\n\t\timages.rankPacking( self.rank )\n\t\treturn self.arrayType.asArray( arg )\n\tdef finalise( self, wrapper ):\n\t\t\"\"\"Get our pixel index from the wrapper\"\"\"\n\t\tself.pixelsIndex = wrapper.pyArgIndex( self.pixelsName )\n\tdef width( self, pyArgs, index, wrappedOperation ):\n\t\t\"\"\"Extract the width from the pixels argument\"\"\"\n\t\treturn self.arrayType.dimensions( pyArgs[self.pixelsIndex] )[0]\n\tdef height( self, pyArgs, index, wrappedOperation ):\n\t\t\"\"\"Extract the height from the pixels argument\"\"\"\n\t\treturn self.arrayType.dimensions( pyArgs[self.pixelsIndex] )[1]\n\tdef depth( self, pyArgs, index, wrappedOperation ):\n\t\t\"\"\"Extract the depth from the pixels argument\"\"\"\n\t\treturn self.arrayType.dimensions( pyArgs[self.pixelsIndex] )[2]\n\tdef type( self, pyArgs, index, wrappedOperation ):\n\t\t\"\"\"Provide the item-type argument from our stored value\n\t\t\n\t\tThis is used for pre-bound processing where we want to provide \n\t\tthe type by implication...\n\t\t\"\"\"\n\t\treturn self.typeName\n", "description": "The pyConverter for the pixels", "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "class", "name": "CompressedImageConverter", "data": "class CompressedImageConverter( object ):\n\tdef finalise( self, wrapper ):\n\t\t\"\"\"Get our pixel index from the wrapper\"\"\"\n\t\tself.dataIndex = wrapper.pyArgIndex( 'data' )\n\tdef __call__( self, pyArgs, index, wrappedOperation ):\n\t\t\"\"\"Create a data-size measurement for our image\"\"\"\n\t\targ = pyArgs[ self.dataIndex ]\n\t\treturn arrays.ArrayType.arrayByteCount( arg )\n\n\n", "description": "Get our pixel index from the wrapper", "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "def", "name": "setImageInput", "data": "def setImageInput( \n\tbaseOperation, arrayType=None, dimNames=DIMENSION_NAMES, \n", "description": null, "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "def", "name": "typedImageFunction", "data": "def typedImageFunction( suffix, arrayConstant,  baseFunction ):\n\t\"\"\"Produce a typed version of the given image function\"\"\"\n\tfunctionName = baseFunction.__name__\n\tfunctionName = '%(functionName)s%(suffix)s'%locals()\n\tif baseFunction:\n\t\tarrayType = arrays.GL_CONSTANT_TO_ARRAY_TYPE[ arrayConstant ]\n\t\tfunction = setDimensionsAsInts(\n\t\t\tsetImageInput(\n\t\t\t\tbaseFunction, \n\t\t\t\tarrayType,\n\t\t\t\ttypeName = arrayConstant,\n\t\t\t)\n\t\t)\n\t\treturn functionName, function\n\telse:\n\t\treturn functionName, baseFunction\n", "description": "Produce a typed version of the given image function", "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "def", "name": "_setDataSize", "data": "def _setDataSize( baseFunction, argument='imageSize' ):\n\t\"\"\"Set the data-size value to come from the data field\"\"\"\n\tif baseFunction:\n\t\tconverter = CompressedImageConverter()\n\t\treturn asWrapper( baseFunction ).setPyConverter(\n\t\t\targument\n\t\t).setCConverter( argument, converter )\n\telse:\n\t\treturn baseFunction\n", "description": "Set the data-size value to come from the data field", "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "def", "name": "compressedImageFunction", "data": "def compressedImageFunction( baseFunction ):\n\t\"\"\"Set the imageSize and dimensions-as-ints converters for baseFunction\"\"\"\n\tif baseFunction:\n\t\treturn setDimensionsAsInts(\n\t\t\t_setDataSize( \n\t\t\t\tbaseFunction, argument='imageSize'\n\t\t\t)\n\t\t)\n\telse:\n\t\treturn baseFunction\n", "description": "Set the imageSize and dimensions-as-ints converters for baseFunction", "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}], [{"term": "def", "name": "simple", "data": "def simple(e):\n\tcode = e.code\n\n\tif code.endswith('Exception'):\n\t\tcode = code.rstrip('Exception')\n\n\ttry:\n\t\t# Dynamically get the error class.\n\t\tsimple_e = getattr(sys.modules[__name__], code)(e)\n\texcept AttributeError:\n\t\t# Return original exception on failure.\n\t\treturn e\n\n\treturn simple_e\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "SimpleException", "data": "class SimpleException(BotoServerError):\n\tdef __init__(self, e):\n\t\tsuper(SimpleException, self).__init__(e.status, e.reason, e.body)\n\t\tself.error_message = self.message\n\n\tdef __repr__(self):\n\t\treturn self.__class__.__name__ + ': ' + self.error_message\n\tdef __str__(self):\n\t\treturn self.__class__.__name__ + ': ' + self.error_message\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "ValidationError", "data": "class ValidationError(SimpleException): pass\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "Throttling", "data": "class Throttling(SimpleException): pass\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "SourceBundleDeletion", "data": "class SourceBundleDeletion(SimpleException): pass\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}], [{"term": "def", "name": "simple", "data": "def simple(e):\n\tcode = e.code\n\n\tif code.endswith('Exception'):\n\t\tcode = code.rstrip('Exception')\n\n\ttry:\n\t\t# Dynamically get the error class.\n\t\tsimple_e = getattr(sys.modules[__name__], code)(e)\n\texcept AttributeError:\n\t\t# Return original exception on failure.\n\t\treturn e\n\n\treturn simple_e\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "SimpleException", "data": "class SimpleException(BotoServerError):\n\tdef __init__(self, e):\n\t\tsuper(SimpleException, self).__init__(e.status, e.reason, e.body)\n\t\tself.error_message = self.message\n\n\tdef __repr__(self):\n\t\treturn self.__class__.__name__ + ': ' + self.error_message\n\tdef __str__(self):\n\t\treturn self.__class__.__name__ + ': ' + self.error_message\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "ValidationError", "data": "class ValidationError(SimpleException): pass\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "Throttling", "data": "class Throttling(SimpleException): pass\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "SourceBundleDeletion", "data": "class SourceBundleDeletion(SimpleException): pass\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}], [{"term": "class", "name": "classTestIsSimplePath:", "data": "class TestIsSimplePath:\n\t\"\"\"Unit tests for the\n\t:func:`networkx.algorithms.simple_paths.is_simple_path` function.\n\n\t\"\"\"\n\n\tdef test_empty_list(self):\n\t\t\"\"\"Tests that the empty list is not a valid path, since there\n\t\tshould be a one-to-one correspondence between paths as lists of\n\t\tnodes and paths as lists of edges.\n\n\t\t\"\"\"\n\t\tG = nx.trivial_graph()\n\t\tassert not nx.is_simple_path(G, [])\n\n\tdef test_trivial_path(self):\n\t\t\"\"\"Tests that the trivial path, a path of length one, is\n\t\tconsidered a simple path in a graph.\n\n\t\t\"\"\"\n\t\tG = nx.trivial_graph()\n\t\tassert nx.is_simple_path(G, [0])\n\n\tdef test_trivial_nonpath(self):\n\t\t\"\"\"Tests that a list whose sole element is an object not in the\n\t\tgraph is not considered a simple path.\n\n\t\t\"\"\"\n\t\tG = nx.trivial_graph()\n\t\tassert not nx.is_simple_path(G, [\"not a node\"])\n\n\tdef test_simple_path(self):\n\t\tG = nx.path_graph(2)\n\t\tassert nx.is_simple_path(G, [0, 1])\n\n\tdef test_non_simple_path(self):\n\t\tG = nx.path_graph(2)\n\t\tassert not nx.is_simple_path(G, [0, 1, 0])\n\n\tdef test_cycle(self):\n\t\tG = nx.cycle_graph(3)\n\t\tassert not nx.is_simple_path(G, [0, 1, 2, 0])\n\n\tdef test_missing_node(self):\n\t\tG = nx.path_graph(2)\n\t\tassert not nx.is_simple_path(G, [0, 2])\n\n\tdef test_directed_path(self):\n\t\tG = nx.DiGraph([(0, 1), (1, 2)])\n\t\tassert nx.is_simple_path(G, [0, 1, 2])\n\n\tdef test_directed_non_path(self):\n\t\tG = nx.DiGraph([(0, 1), (1, 2)])\n\t\tassert not nx.is_simple_path(G, [2, 1, 0])\n\n\tdef test_directed_cycle(self):\n\t\tG = nx.DiGraph([(0, 1), (1, 2), (2, 0)])\n\t\tassert not nx.is_simple_path(G, [0, 1, 2, 0])\n\n\tdef test_multigraph(self):\n\t\tG = nx.MultiGraph([(0, 1), (0, 1)])\n\t\tassert nx.is_simple_path(G, [0, 1])\n\n\tdef test_multidigraph(self):\n\t\tG = nx.MultiDiGraph([(0, 1), (0, 1), (1, 0), (1, 0)])\n\t\tassert nx.is_simple_path(G, [0, 1])\n\n", "description": "Unit tests for the\n\t:func:`networkx.algorithms.simple_paths.is_simple_path` function.\n\n\t", "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths", "data": "def test_all_simple_paths():\n\tG = nx.path_graph(4)\n\tpaths = nx.all_simple_paths(G, 0, 3)\n\tassert {tuple(p) for p in paths} == {(0, 1, 2, 3)}\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_with_two_targets_emits_two_paths", "data": "def test_all_simple_paths_with_two_targets_emits_two_paths():\n\tG = nx.path_graph(4)\n\tG.add_edge(2, 4)\n\tpaths = nx.all_simple_paths(G, 0, [3, 4])\n\tassert {tuple(p) for p in paths} == {(0, 1, 2, 3), (0, 1, 2, 4)}\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_digraph_all_simple_paths_with_two_targets_emits_two_paths", "data": "def test_digraph_all_simple_paths_with_two_targets_emits_two_paths():\n\tG = nx.path_graph(4, create_using=nx.DiGraph())\n\tG.add_edge(2, 4)\n\tpaths = nx.all_simple_paths(G, 0, [3, 4])\n\tassert {tuple(p) for p in paths} == {(0, 1, 2, 3), (0, 1, 2, 4)}\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_with_two_targets_cutoff", "data": "def test_all_simple_paths_with_two_targets_cutoff():\n\tG = nx.path_graph(4)\n\tG.add_edge(2, 4)\n\tpaths = nx.all_simple_paths(G, 0, [3, 4], cutoff=3)\n\tassert {tuple(p) for p in paths} == {(0, 1, 2, 3), (0, 1, 2, 4)}\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_digraph_all_simple_paths_with_two_targets_cutoff", "data": "def test_digraph_all_simple_paths_with_two_targets_cutoff():\n\tG = nx.path_graph(4, create_using=nx.DiGraph())\n\tG.add_edge(2, 4)\n\tpaths = nx.all_simple_paths(G, 0, [3, 4], cutoff=3)\n\tassert {tuple(p) for p in paths} == {(0, 1, 2, 3), (0, 1, 2, 4)}\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_with_two_targets_in_line_emits_two_paths", "data": "def test_all_simple_paths_with_two_targets_in_line_emits_two_paths():\n\tG = nx.path_graph(4)\n\tpaths = nx.all_simple_paths(G, 0, [2, 3])\n\tassert {tuple(p) for p in paths} == {(0, 1, 2), (0, 1, 2, 3)}\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_ignores_cycle", "data": "def test_all_simple_paths_ignores_cycle():\n\tG = nx.cycle_graph(3, create_using=nx.DiGraph())\n\tG.add_edge(1, 3)\n\tpaths = nx.all_simple_paths(G, 0, 3)\n\tassert {tuple(p) for p in paths} == {(0, 1, 3)}\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_with_two_targets_inside_cycle_emits_two_paths", "data": "def test_all_simple_paths_with_two_targets_inside_cycle_emits_two_paths():\n\tG = nx.cycle_graph(3, create_using=nx.DiGraph())\n\tG.add_edge(1, 3)\n\tpaths = nx.all_simple_paths(G, 0, [2, 3])\n\tassert {tuple(p) for p in paths} == {(0, 1, 2), (0, 1, 3)}\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_source_target", "data": "def test_all_simple_paths_source_target():\n\tG = nx.path_graph(4)\n\tpaths = nx.all_simple_paths(G, 1, 1)\n\tassert list(paths) == []\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_cutoff", "data": "def test_all_simple_paths_cutoff():\n\tG = nx.complete_graph(4)\n\tpaths = nx.all_simple_paths(G, 0, 1, cutoff=1)\n\tassert {tuple(p) for p in paths} == {(0, 1)}\n\tpaths = nx.all_simple_paths(G, 0, 1, cutoff=2)\n\tassert {tuple(p) for p in paths} == {(0, 1), (0, 2, 1), (0, 3, 1)}\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_on_non_trivial_graph", "data": "def test_all_simple_paths_on_non_trivial_graph():\n\t\"\"\" you may need to draw this graph to make sure it is reasonable \"\"\"\n\tG = nx.path_graph(5, create_using=nx.DiGraph())\n\tG.add_edges_from([(0, 5), (1, 5), (1, 3), (5, 4), (4, 2), (4, 3)])\n\tpaths = nx.all_simple_paths(G, 1, [2, 3])\n\tassert {tuple(p) for p in paths} == {\n\t\t(1, 2),\n\t\t(1, 3, 4, 2),\n\t\t(1, 5, 4, 2),\n\t\t(1, 3),\n\t\t(1, 2, 3),\n\t\t(1, 5, 4, 3),\n\t\t(1, 5, 4, 2, 3),\n\t}\n\tpaths = nx.all_simple_paths(G, 1, [2, 3], cutoff=3)\n\tassert {tuple(p) for p in paths} == {\n\t\t(1, 2),\n\t\t(1, 3, 4, 2),\n\t\t(1, 5, 4, 2),\n\t\t(1, 3),\n\t\t(1, 2, 3),\n\t\t(1, 5, 4, 3),\n\t}\n\tpaths = nx.all_simple_paths(G, 1, [2, 3], cutoff=2)\n\tassert {tuple(p) for p in paths} == {(1, 2), (1, 3), (1, 2, 3)}\n\n", "description": " you may need to draw this graph to make sure it is reasonable ", "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_multigraph", "data": "def test_all_simple_paths_multigraph():\n\tG = nx.MultiGraph([(1, 2), (1, 2)])\n\tpaths = nx.all_simple_paths(G, 1, 1)\n\tassert list(paths) == []\n\tnx.add_path(G, [3, 1, 10, 2])\n\tpaths = list(nx.all_simple_paths(G, 1, 2))\n\tassert len(paths) == 3\n\tassert {tuple(p) for p in paths} == {(1, 2), (1, 2), (1, 10, 2)}\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_multigraph_with_cutoff", "data": "def test_all_simple_paths_multigraph_with_cutoff():\n\tG = nx.MultiGraph([(1, 2), (1, 2), (1, 10), (10, 2)])\n\tpaths = list(nx.all_simple_paths(G, 1, 2, cutoff=1))\n\tassert len(paths) == 2\n\tassert {tuple(p) for p in paths} == {(1, 2), (1, 2)}\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_directed", "data": "def test_all_simple_paths_directed():\n\tG = nx.DiGraph()\n\tnx.add_path(G, [1, 2, 3])\n\tnx.add_path(G, [3, 2, 1])\n\tpaths = nx.all_simple_paths(G, 1, 3)\n\tassert {tuple(p) for p in paths} == {(1, 2, 3)}\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_empty", "data": "def test_all_simple_paths_empty():\n\tG = nx.path_graph(4)\n\tpaths = nx.all_simple_paths(G, 0, 3, cutoff=2)\n\tassert list(paths) == []\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_corner_cases", "data": "def test_all_simple_paths_corner_cases():\n\tassert list(nx.all_simple_paths(nx.empty_graph(2), 0, 0)) == []\n\tassert list(nx.all_simple_paths(nx.empty_graph(2), 0, 1)) == []\n\tassert list(nx.all_simple_paths(nx.path_graph(9), 0, 8, 0)) == []\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "hamiltonian_path", "data": "def hamiltonian_path(G, source):\n\tsource = arbitrary_element(G)\n\tneighbors = set(G[source]) - {source}\n\tn = len(G)\n\tfor target in neighbors:\n\t\tfor path in nx.all_simple_paths(G, source, target):\n\t\t\tif len(path) == n:\n\t\t\t\tyield path\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_hamiltonian_path", "data": "def test_hamiltonian_path():\n\tfrom itertools import permutations\n\n\tG = nx.complete_graph(4)\n\tpaths = [list(p) for p in hamiltonian_path(G, 0)]\n\texact = [[0] + list(p) for p in permutations([1, 2, 3], 3)]\n\tassert sorted(paths) == sorted(exact)\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_cutoff_zero", "data": "def test_cutoff_zero():\n\tG = nx.complete_graph(4)\n\tpaths = nx.all_simple_paths(G, 0, 3, cutoff=0)\n\tassert list(list(p) for p in paths) == []\n\tpaths = nx.all_simple_paths(nx.MultiGraph(G), 0, 3, cutoff=0)\n\tassert list(list(p) for p in paths) == []\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_source_missing", "data": "def test_source_missing():\n\twith pytest.raises(nx.NodeNotFound):\n\t\tG = nx.Graph()\n\t\tnx.add_path(G, [1, 2, 3])\n\t\tlist(nx.all_simple_paths(nx.MultiGraph(G), 0, 3))\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_target_missing", "data": "def test_target_missing():\n\twith pytest.raises(nx.NodeNotFound):\n\t\tG = nx.Graph()\n\t\tnx.add_path(G, [1, 2, 3])\n\t\tlist(nx.all_simple_paths(nx.MultiGraph(G), 1, 4))\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_edge_paths", "data": "def test_all_simple_edge_paths():\n\tG = nx.path_graph(4)\n\tpaths = nx.all_simple_edge_paths(G, 0, 3)\n\tassert {tuple(p) for p in paths} == {((0, 1), (1, 2), (2, 3))}\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_edge_paths_with_two_targets_emits_two_paths", "data": "def test_all_simple_edge_paths_with_two_targets_emits_two_paths():\n\tG = nx.path_graph(4)\n\tG.add_edge(2, 4)\n\tpaths = nx.all_simple_edge_paths(G, 0, [3, 4])\n\tassert {tuple(p) for p in paths} == {\n\t\t((0, 1), (1, 2), (2, 3)),\n\t\t((0, 1), (1, 2), (2, 4)),\n\t}\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_digraph_all_simple_edge_paths_with_two_targets_emits_two_paths", "data": "def test_digraph_all_simple_edge_paths_with_two_targets_emits_two_paths():\n\tG = nx.path_graph(4, create_using=nx.DiGraph())\n\tG.add_edge(2, 4)\n\tpaths = nx.all_simple_edge_paths(G, 0, [3, 4])\n\tassert {tuple(p) for p in paths} == {\n\t\t((0, 1), (1, 2), (2, 3)),\n\t\t((0, 1), (1, 2), (2, 4)),\n\t}\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_edge_paths_with_two_targets_cutoff", "data": "def test_all_simple_edge_paths_with_two_targets_cutoff():\n\tG = nx.path_graph(4)\n\tG.add_edge(2, 4)\n\tpaths = nx.all_simple_edge_paths(G, 0, [3, 4], cutoff=3)\n\tassert {tuple(p) for p in paths} == {\n\t\t((0, 1), (1, 2), (2, 3)),\n\t\t((0, 1), (1, 2), (2, 4)),\n\t}\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_digraph_all_simple_edge_paths_with_two_targets_cutoff", "data": "def test_digraph_all_simple_edge_paths_with_two_targets_cutoff():\n\tG = nx.path_graph(4, create_using=nx.DiGraph())\n\tG.add_edge(2, 4)\n\tpaths = nx.all_simple_edge_paths(G, 0, [3, 4], cutoff=3)\n\tassert {tuple(p) for p in paths} == {\n\t\t((0, 1), (1, 2), (2, 3)),\n\t\t((0, 1), (1, 2), (2, 4)),\n\t}\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_edge_paths_with_two_targets_in_line_emits_two_paths", "data": "def test_all_simple_edge_paths_with_two_targets_in_line_emits_two_paths():\n\tG = nx.path_graph(4)\n\tpaths = nx.all_simple_edge_paths(G, 0, [2, 3])\n\tassert {tuple(p) for p in paths} == {((0, 1), (1, 2)), ((0, 1), (1, 2), (2, 3))}\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_edge_paths_ignores_cycle", "data": "def test_all_simple_edge_paths_ignores_cycle():\n\tG = nx.cycle_graph(3, create_using=nx.DiGraph())\n\tG.add_edge(1, 3)\n\tpaths = nx.all_simple_edge_paths(G, 0, 3)\n\tassert {tuple(p) for p in paths} == {((0, 1), (1, 3))}\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_edge_paths_with_two_targets_inside_cycle_emits_two_paths", "data": "def test_all_simple_edge_paths_with_two_targets_inside_cycle_emits_two_paths():\n\tG = nx.cycle_graph(3, create_using=nx.DiGraph())\n\tG.add_edge(1, 3)\n\tpaths = nx.all_simple_edge_paths(G, 0, [2, 3])\n\tassert {tuple(p) for p in paths} == {((0, 1), (1, 2)), ((0, 1), (1, 3))}\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_edge_paths_source_target", "data": "def test_all_simple_edge_paths_source_target():\n\tG = nx.path_graph(4)\n\tpaths = nx.all_simple_edge_paths(G, 1, 1)\n\tassert list(paths) == []\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_edge_paths_cutoff", "data": "def test_all_simple_edge_paths_cutoff():\n\tG = nx.complete_graph(4)\n\tpaths = nx.all_simple_edge_paths(G, 0, 1, cutoff=1)\n\tassert {tuple(p) for p in paths} == {((0, 1),)}\n\tpaths = nx.all_simple_edge_paths(G, 0, 1, cutoff=2)\n\tassert {tuple(p) for p in paths} == {((0, 1),), ((0, 2), (2, 1)), ((0, 3), (3, 1))}\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_edge_paths_on_non_trivial_graph", "data": "def test_all_simple_edge_paths_on_non_trivial_graph():\n\t\"\"\" you may need to draw this graph to make sure it is reasonable \"\"\"\n\tG = nx.path_graph(5, create_using=nx.DiGraph())\n\tG.add_edges_from([(0, 5), (1, 5), (1, 3), (5, 4), (4, 2), (4, 3)])\n\tpaths = nx.all_simple_edge_paths(G, 1, [2, 3])\n\tassert {tuple(p) for p in paths} == {\n\t\t((1, 2),),\n\t\t((1, 3), (3, 4), (4, 2)),\n\t\t((1, 5), (5, 4), (4, 2)),\n\t\t((1, 3),),\n\t\t((1, 2), (2, 3)),\n\t\t((1, 5), (5, 4), (4, 3)),\n\t\t((1, 5), (5, 4), (4, 2), (2, 3)),\n\t}\n\tpaths = nx.all_simple_edge_paths(G, 1, [2, 3], cutoff=3)\n\tassert {tuple(p) for p in paths} == {\n\t\t((1, 2),),\n\t\t((1, 3), (3, 4), (4, 2)),\n\t\t((1, 5), (5, 4), (4, 2)),\n\t\t((1, 3),),\n\t\t((1, 2), (2, 3)),\n\t\t((1, 5), (5, 4), (4, 3)),\n\t}\n\tpaths = nx.all_simple_edge_paths(G, 1, [2, 3], cutoff=2)\n\tassert {tuple(p) for p in paths} == {((1, 2),), ((1, 3),), ((1, 2), (2, 3))}\n\n", "description": " you may need to draw this graph to make sure it is reasonable ", "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_edge_paths_multigraph", "data": "def test_all_simple_edge_paths_multigraph():\n\tG = nx.MultiGraph([(1, 2), (1, 2)])\n\tpaths = nx.all_simple_edge_paths(G, 1, 1)\n\tassert list(paths) == []\n\tnx.add_path(G, [3, 1, 10, 2])\n\tpaths = list(nx.all_simple_edge_paths(G, 1, 2))\n\tassert len(paths) == 3\n\tassert {tuple(p) for p in paths} == {\n\t\t((1, 2, 0),),\n\t\t((1, 2, 1),),\n\t\t((1, 10, 0), (10, 2, 0)),\n\t}\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_edge_paths_multigraph_with_cutoff", "data": "def test_all_simple_edge_paths_multigraph_with_cutoff():\n\tG = nx.MultiGraph([(1, 2), (1, 2), (1, 10), (10, 2)])\n\tpaths = list(nx.all_simple_edge_paths(G, 1, 2, cutoff=1))\n\tassert len(paths) == 2\n\tassert {tuple(p) for p in paths} == {((1, 2, 0),), ((1, 2, 1),)}\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_edge_paths_directed", "data": "def test_all_simple_edge_paths_directed():\n\tG = nx.DiGraph()\n\tnx.add_path(G, [1, 2, 3])\n\tnx.add_path(G, [3, 2, 1])\n\tpaths = nx.all_simple_edge_paths(G, 1, 3)\n\tassert {tuple(p) for p in paths} == {((1, 2), (2, 3))}\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_edge_paths_empty", "data": "def test_all_simple_edge_paths_empty():\n\tG = nx.path_graph(4)\n\tpaths = nx.all_simple_edge_paths(G, 0, 3, cutoff=2)\n\tassert list(paths) == []\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_edge_paths_corner_cases", "data": "def test_all_simple_edge_paths_corner_cases():\n\tassert list(nx.all_simple_edge_paths(nx.empty_graph(2), 0, 0)) == []\n\tassert list(nx.all_simple_edge_paths(nx.empty_graph(2), 0, 1)) == []\n\tassert list(nx.all_simple_edge_paths(nx.path_graph(9), 0, 8, 0)) == []\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "hamiltonian_edge_path", "data": "def hamiltonian_edge_path(G, source):\n\tsource = arbitrary_element(G)\n\tneighbors = set(G[source]) - {source}\n\tn = len(G)\n\tfor target in neighbors:\n\t\tfor path in nx.all_simple_edge_paths(G, source, target):\n\t\t\tif len(path) == n - 1:\n\t\t\t\tyield path\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_hamiltonian__edge_path", "data": "def test_hamiltonian__edge_path():\n\tfrom itertools import permutations\n\n\tG = nx.complete_graph(4)\n\tpaths = hamiltonian_edge_path(G, 0)\n\texact = [list(pairwise([0] + list(p))) for p in permutations([1, 2, 3], 3)]\n\tassert sorted(exact) == [p for p in sorted(paths)]\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_edge_cutoff_zero", "data": "def test_edge_cutoff_zero():\n\tG = nx.complete_graph(4)\n\tpaths = nx.all_simple_edge_paths(G, 0, 3, cutoff=0)\n\tassert list(list(p) for p in paths) == []\n\tpaths = nx.all_simple_edge_paths(nx.MultiGraph(G), 0, 3, cutoff=0)\n\tassert list(list(p) for p in paths) == []\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_edge_source_missing", "data": "def test_edge_source_missing():\n\twith pytest.raises(nx.NodeNotFound):\n\t\tG = nx.Graph()\n\t\tnx.add_path(G, [1, 2, 3])\n\t\tlist(nx.all_simple_edge_paths(nx.MultiGraph(G), 0, 3))\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_edge_target_missing", "data": "def test_edge_target_missing():\n\twith pytest.raises(nx.NodeNotFound):\n\t\tG = nx.Graph()\n\t\tnx.add_path(G, [1, 2, 3])\n\t\tlist(nx.all_simple_edge_paths(nx.MultiGraph(G), 1, 4))\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_shortest_simple_paths", "data": "def test_shortest_simple_paths():\n\tG = cnlti(nx.grid_2d_graph(4, 4), first_label=1, ordering=\"sorted\")\n\tpaths = nx.shortest_simple_paths(G, 1, 12)\n\tassert next(paths) == [1, 2, 3, 4, 8, 12]\n\tassert next(paths) == [1, 5, 6, 7, 8, 12]\n\tassert [len(path) for path in nx.shortest_simple_paths(G, 1, 12)] == sorted(\n\t\t[len(path) for path in nx.all_simple_paths(G, 1, 12)]\n\t)\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_shortest_simple_paths_directed", "data": "def test_shortest_simple_paths_directed():\n\tG = nx.cycle_graph(7, create_using=nx.DiGraph())\n\tpaths = nx.shortest_simple_paths(G, 0, 3)\n\tassert [path for path in paths] == [[0, 1, 2, 3]]\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_shortest_simple_paths_directed_with_weight_fucntion", "data": "def test_shortest_simple_paths_directed_with_weight_fucntion():\n\tdef cost(u, v, x):\n\t\treturn 1\n\n\tG = cnlti(nx.grid_2d_graph(4, 4), first_label=1, ordering=\"sorted\")\n\tpaths = nx.shortest_simple_paths(G, 1, 12)\n\tassert next(paths) == [1, 2, 3, 4, 8, 12]\n\tassert next(paths) == [1, 5, 6, 7, 8, 12]\n\tassert [\n\t\tlen(path) for path in nx.shortest_simple_paths(G, 1, 12, weight=cost)\n\t] == sorted([len(path) for path in nx.all_simple_paths(G, 1, 12)])\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_shortest_simple_paths_with_weight_fucntion", "data": "def test_shortest_simple_paths_with_weight_fucntion():\n\tdef cost(u, v, x):\n\t\treturn 1\n\n\tG = nx.cycle_graph(7, create_using=nx.DiGraph())\n\tpaths = nx.shortest_simple_paths(G, 0, 3, weight=cost)\n\tassert [path for path in paths] == [[0, 1, 2, 3]]\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_Greg_Bernstein", "data": "def test_Greg_Bernstein():\n\tg1 = nx.Graph()\n\tg1.add_nodes_from([\"N0\", \"N1\", \"N2\", \"N3\", \"N4\"])\n\tg1.add_edge(\"N4\", \"N1\", weight=10.0, capacity=50, name=\"L5\")\n\tg1.add_edge(\"N4\", \"N0\", weight=7.0, capacity=40, name=\"L4\")\n\tg1.add_edge(\"N0\", \"N1\", weight=10.0, capacity=45, name=\"L1\")\n\tg1.add_edge(\"N3\", \"N0\", weight=10.0, capacity=50, name=\"L0\")\n\tg1.add_edge(\"N2\", \"N3\", weight=12.0, capacity=30, name=\"L2\")\n\tg1.add_edge(\"N1\", \"N2\", weight=15.0, capacity=42, name=\"L3\")\n\tsolution = [[\"N1\", \"N0\", \"N3\"], [\"N1\", \"N2\", \"N3\"], [\"N1\", \"N4\", \"N0\", \"N3\"]]\n\tresult = list(nx.shortest_simple_paths(g1, \"N1\", \"N3\", weight=\"weight\"))\n\tassert result == solution\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_weighted_shortest_simple_path", "data": "def test_weighted_shortest_simple_path():\n\tdef cost_func(path):\n\t\treturn sum(G.adj[u][v][\"weight\"] for (u, v) in zip(path, path[1:]))\n\n\tG = nx.complete_graph(5)\n\tweight = {(u, v): random.randint(1, 100) for (u, v) in G.edges()}\n\tnx.set_edge_attributes(G, weight, \"weight\")\n\tcost = 0\n\tfor path in nx.shortest_simple_paths(G, 0, 3, weight=\"weight\"):\n\t\tthis_cost = cost_func(path)\n\t\tassert cost <= this_cost\n\t\tcost = this_cost\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_directed_weighted_shortest_simple_path", "data": "def test_directed_weighted_shortest_simple_path():\n\tdef cost_func(path):\n\t\treturn sum(G.adj[u][v][\"weight\"] for (u, v) in zip(path, path[1:]))\n\n\tG = nx.complete_graph(5)\n\tG = G.to_directed()\n\tweight = {(u, v): random.randint(1, 100) for (u, v) in G.edges()}\n\tnx.set_edge_attributes(G, weight, \"weight\")\n\tcost = 0\n\tfor path in nx.shortest_simple_paths(G, 0, 3, weight=\"weight\"):\n\t\tthis_cost = cost_func(path)\n\t\tassert cost <= this_cost\n\t\tcost = this_cost\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_weighted_shortest_simple_path_issue2427", "data": "def test_weighted_shortest_simple_path_issue2427():\n\tG = nx.Graph()\n\tG.add_edge(\"IN\", \"OUT\", weight=2)\n\tG.add_edge(\"IN\", \"A\", weight=1)\n\tG.add_edge(\"IN\", \"B\", weight=2)\n\tG.add_edge(\"B\", \"OUT\", weight=2)\n\tassert list(nx.shortest_simple_paths(G, \"IN\", \"OUT\", weight=\"weight\")) == [\n\t\t[\"IN\", \"OUT\"],\n\t\t[\"IN\", \"B\", \"OUT\"],\n\t]\n\tG = nx.Graph()\n\tG.add_edge(\"IN\", \"OUT\", weight=10)\n\tG.add_edge(\"IN\", \"A\", weight=1)\n\tG.add_edge(\"IN\", \"B\", weight=1)\n\tG.add_edge(\"B\", \"OUT\", weight=1)\n\tassert list(nx.shortest_simple_paths(G, \"IN\", \"OUT\", weight=\"weight\")) == [\n\t\t[\"IN\", \"B\", \"OUT\"],\n\t\t[\"IN\", \"OUT\"],\n\t]\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_directed_weighted_shortest_simple_path_issue2427", "data": "def test_directed_weighted_shortest_simple_path_issue2427():\n\tG = nx.DiGraph()\n\tG.add_edge(\"IN\", \"OUT\", weight=2)\n\tG.add_edge(\"IN\", \"A\", weight=1)\n\tG.add_edge(\"IN\", \"B\", weight=2)\n\tG.add_edge(\"B\", \"OUT\", weight=2)\n\tassert list(nx.shortest_simple_paths(G, \"IN\", \"OUT\", weight=\"weight\")) == [\n\t\t[\"IN\", \"OUT\"],\n\t\t[\"IN\", \"B\", \"OUT\"],\n\t]\n\tG = nx.DiGraph()\n\tG.add_edge(\"IN\", \"OUT\", weight=10)\n\tG.add_edge(\"IN\", \"A\", weight=1)\n\tG.add_edge(\"IN\", \"B\", weight=1)\n\tG.add_edge(\"B\", \"OUT\", weight=1)\n\tassert list(nx.shortest_simple_paths(G, \"IN\", \"OUT\", weight=\"weight\")) == [\n\t\t[\"IN\", \"B\", \"OUT\"],\n\t\t[\"IN\", \"OUT\"],\n\t]\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_weight_name", "data": "def test_weight_name():\n\tG = nx.cycle_graph(7)\n\tnx.set_edge_attributes(G, 1, \"weight\")\n\tnx.set_edge_attributes(G, 1, \"foo\")\n\tG.adj[1][2][\"foo\"] = 7\n\tpaths = list(nx.shortest_simple_paths(G, 0, 3, weight=\"foo\"))\n\tsolution = [[0, 6, 5, 4, 3], [0, 1, 2, 3]]\n\tassert paths == solution\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_ssp_source_missing", "data": "def test_ssp_source_missing():\n\twith pytest.raises(nx.NodeNotFound):\n\t\tG = nx.Graph()\n\t\tnx.add_path(G, [1, 2, 3])\n\t\tlist(nx.shortest_simple_paths(G, 0, 3))\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_ssp_target_missing", "data": "def test_ssp_target_missing():\n\twith pytest.raises(nx.NodeNotFound):\n\t\tG = nx.Graph()\n\t\tnx.add_path(G, [1, 2, 3])\n\t\tlist(nx.shortest_simple_paths(G, 1, 4))\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_ssp_multigraph", "data": "def test_ssp_multigraph():\n\twith pytest.raises(nx.NetworkXNotImplemented):\n\t\tG = nx.MultiGraph()\n\t\tnx.add_path(G, [1, 2, 3])\n\t\tlist(nx.shortest_simple_paths(G, 1, 4))\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_ssp_source_missing2", "data": "def test_ssp_source_missing2():\n\twith pytest.raises(nx.NetworkXNoPath):\n\t\tG = nx.Graph()\n\t\tnx.add_path(G, [0, 1, 2])\n\t\tnx.add_path(G, [3, 4, 5])\n\t\tlist(nx.shortest_simple_paths(G, 0, 3))\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_bidirectional_shortest_path_restricted_cycle", "data": "def test_bidirectional_shortest_path_restricted_cycle():\n\tcycle = nx.cycle_graph(7)\n\tlength, path = _bidirectional_shortest_path(cycle, 0, 3)\n\tassert path == [0, 1, 2, 3]\n\tlength, path = _bidirectional_shortest_path(cycle, 0, 3, ignore_nodes=[1])\n\tassert path == [0, 6, 5, 4, 3]\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_bidirectional_shortest_path_restricted_wheel", "data": "def test_bidirectional_shortest_path_restricted_wheel():\n\twheel = nx.wheel_graph(6)\n\tlength, path = _bidirectional_shortest_path(wheel, 1, 3)\n\tassert path in [[1, 0, 3], [1, 2, 3]]\n\tlength, path = _bidirectional_shortest_path(wheel, 1, 3, ignore_nodes=[0])\n\tassert path == [1, 2, 3]\n\tlength, path = _bidirectional_shortest_path(wheel, 1, 3, ignore_nodes=[0, 2])\n\tassert path == [1, 5, 4, 3]\n\tlength, path = _bidirectional_shortest_path(\n\t\twheel, 1, 3, ignore_edges=[(1, 0), (5, 0), (2, 3)]\n\t)\n\tassert path in [[1, 2, 0, 3], [1, 5, 4, 3]]\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_bidirectional_shortest_path_restricted_directed_cycle", "data": "def test_bidirectional_shortest_path_restricted_directed_cycle():\n\tdirected_cycle = nx.cycle_graph(7, create_using=nx.DiGraph())\n\tlength, path = _bidirectional_shortest_path(directed_cycle, 0, 3)\n\tassert path == [0, 1, 2, 3]\n\tpytest.raises(\n\t\tnx.NetworkXNoPath,\n\t\t_bidirectional_shortest_path,\n\t\tdirected_cycle,\n\t\t0,\n\t\t3,\n\t\tignore_nodes=[1],\n\t)\n\tlength, path = _bidirectional_shortest_path(\n\t\tdirected_cycle, 0, 3, ignore_edges=[(2, 1)]\n\t)\n\tassert path == [0, 1, 2, 3]\n\tpytest.raises(\n\t\tnx.NetworkXNoPath,\n\t\t_bidirectional_shortest_path,\n\t\tdirected_cycle,\n\t\t0,\n\t\t3,\n\t\tignore_edges=[(1, 2)],\n\t)\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_bidirectional_shortest_path_ignore", "data": "def test_bidirectional_shortest_path_ignore():\n\tG = nx.Graph()\n\tnx.add_path(G, [1, 2])\n\tnx.add_path(G, [1, 3])\n\tnx.add_path(G, [1, 4])\n\tpytest.raises(\n\t\tnx.NetworkXNoPath, _bidirectional_shortest_path, G, 1, 2, ignore_nodes=[1]\n\t)\n\tpytest.raises(\n\t\tnx.NetworkXNoPath, _bidirectional_shortest_path, G, 1, 2, ignore_nodes=[2]\n\t)\n\tG = nx.Graph()\n\tnx.add_path(G, [1, 3])\n\tnx.add_path(G, [1, 4])\n\tnx.add_path(G, [3, 2])\n\tpytest.raises(\n\t\tnx.NetworkXNoPath, _bidirectional_shortest_path, G, 1, 2, ignore_nodes=[1, 2]\n\t)\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "validate_path", "data": "def validate_path(G, s, t, soln_len, path):\n\tassert path[0] == s\n\tassert path[-1] == t\n\tassert soln_len == sum(\n\t\tG[u][v].get(\"weight\", 1) for u, v in zip(path[:-1], path[1:])\n\t)\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "validate_length_path", "data": "def validate_length_path(G, s, t, soln_len, length, path):\n\tassert soln_len == length\n\tvalidate_path(G, s, t, length, path)\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_bidirectional_dijksta_restricted", "data": "def test_bidirectional_dijksta_restricted():\n\tXG = nx.DiGraph()\n\tXG.add_weighted_edges_from(\n\t\t[\n\t\t\t(\"s\", \"u\", 10),\n\t\t\t(\"s\", \"x\", 5),\n\t\t\t(\"u\", \"v\", 1),\n\t\t\t(\"u\", \"x\", 2),\n\t\t\t(\"v\", \"y\", 1),\n\t\t\t(\"x\", \"u\", 3),\n\t\t\t(\"x\", \"v\", 5),\n\t\t\t(\"x\", \"y\", 2),\n\t\t\t(\"y\", \"s\", 7),\n\t\t\t(\"y\", \"v\", 6),\n\t\t]\n\t)\n\n\tXG3 = nx.Graph()\n\tXG3.add_weighted_edges_from(\n\t\t[[0, 1, 2], [1, 2, 12], [2, 3, 1], [3, 4, 5], [4, 5, 1], [5, 0, 10]]\n\t)\n\tvalidate_length_path(XG, \"s\", \"v\", 9, *_bidirectional_dijkstra(XG, \"s\", \"v\"))\n\tvalidate_length_path(\n\t\tXG, \"s\", \"v\", 10, *_bidirectional_dijkstra(XG, \"s\", \"v\", ignore_nodes=[\"u\"])\n\t)\n\tvalidate_length_path(\n\t\tXG,\n\t\t\"s\",\n\t\t\"v\",\n\t\t11,\n\t\t*_bidirectional_dijkstra(XG, \"s\", \"v\", ignore_edges=[(\"s\", \"x\")])\n\t)\n\tpytest.raises(\n\t\tnx.NetworkXNoPath,\n\t\t_bidirectional_dijkstra,\n\t\tXG,\n\t\t\"s\",\n\t\t\"v\",\n\t\tignore_nodes=[\"u\"],\n\t\tignore_edges=[(\"s\", \"x\")],\n\t)\n\tvalidate_length_path(XG3, 0, 3, 15, *_bidirectional_dijkstra(XG3, 0, 3))\n\tvalidate_length_path(\n\t\tXG3, 0, 3, 16, *_bidirectional_dijkstra(XG3, 0, 3, ignore_nodes=[1])\n\t)\n\tvalidate_length_path(\n\t\tXG3, 0, 3, 16, *_bidirectional_dijkstra(XG3, 0, 3, ignore_edges=[(2, 3)])\n\t)\n\tpytest.raises(\n\t\tnx.NetworkXNoPath,\n\t\t_bidirectional_dijkstra,\n\t\tXG3,\n\t\t0,\n\t\t3,\n\t\tignore_nodes=[1],\n\t\tignore_edges=[(5, 4)],\n\t)\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_bidirectional_dijkstra_no_path", "data": "def test_bidirectional_dijkstra_no_path():\n\twith pytest.raises(nx.NetworkXNoPath):\n\t\tG = nx.Graph()\n\t\tnx.add_path(G, [1, 2, 3])\n\t\tnx.add_path(G, [4, 5, 6])\n\t\t_bidirectional_dijkstra(G, 1, 6)\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_bidirectional_dijkstra_ignore", "data": "def test_bidirectional_dijkstra_ignore():\n\tG = nx.Graph()\n\tnx.add_path(G, [1, 2, 10])\n\tnx.add_path(G, [1, 3, 10])\n\tpytest.raises(nx.NetworkXNoPath, _bidirectional_dijkstra, G, 1, 2, ignore_nodes=[1])\n\tpytest.raises(nx.NetworkXNoPath, _bidirectional_dijkstra, G, 1, 2, ignore_nodes=[2])\n\tpytest.raises(\n\t\tnx.NetworkXNoPath, _bidirectional_dijkstra, G, 1, 2, ignore_nodes=[1, 2]\n\t)\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "from networkx.utils import pairwise", "\tfrom itertools import permutations", "\tfrom itertools import permutations"]}], [{"term": "class", "name": "HTTPSitemapTests", "data": "class HTTPSitemapTests(SitemapTestsBase):\n\n\tdef test_simple_sitemap_index(self):\n\t\t\"A simple sitemap index can be rendered\"\n\t\tresponse = self.client.get('/simple/index.xml')\n\t\tself.assertEqual(response.content, \"\"\"\n", "description": "\n", "category": "simple", "imports": ["from datetime import date", "from django.conf import settings", "from django.contrib.auth.models import User", "from django.contrib.sitemaps import Sitemap, GenericSitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.utils.unittest import skipUnless", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "from .base import SitemapTestsBase"]}, {"term": "def", "name": "ftest_simple_sitemap_custom_index", "data": "\tdef test_simple_sitemap_custom_index(self):\n\t\t\"A simple sitemap index can be rendered with a custom template\"\n\t\tresponse = self.client.get('/simple/custom-index.xml')\n\t\tself.assertEqual(response.content, \"\"\"\n\n", "description": "\n\n", "category": "simple", "imports": ["from datetime import date", "from django.conf import settings", "from django.contrib.auth.models import User", "from django.contrib.sitemaps import Sitemap, GenericSitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.utils.unittest import skipUnless", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "from .base import SitemapTestsBase"]}, {"term": "def", "name": "ftest_simple_sitemap_section", "data": "\tdef test_simple_sitemap_section(self):\n\t\t\"A simple sitemap section can be rendered\"\n\t\tresponse = self.client.get('/simple/sitemap-simple.xml')\n\t\tself.assertEqual(response.content, \"\"\"\n", "description": "\n", "category": "simple", "imports": ["from datetime import date", "from django.conf import settings", "from django.contrib.auth.models import User", "from django.contrib.sitemaps import Sitemap, GenericSitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.utils.unittest import skipUnless", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "from .base import SitemapTestsBase"]}, {"term": "def", "name": "ftest_simple_sitemap", "data": "\tdef test_simple_sitemap(self):\n\t\t\"A simple sitemap can be rendered\"\n\t\tresponse = self.client.get('/simple/sitemap.xml')\n\t\tself.assertEqual(response.content, \"\"\"\n", "description": "\n", "category": "simple", "imports": ["from datetime import date", "from django.conf import settings", "from django.contrib.auth.models import User", "from django.contrib.sitemaps import Sitemap, GenericSitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.utils.unittest import skipUnless", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "from .base import SitemapTestsBase"]}, {"term": "def", "name": "ftest_simple_custom_sitemap", "data": "\tdef test_simple_custom_sitemap(self):\n\t\t\"A simple sitemap can be rendered with a custom template\"\n\t\tresponse = self.client.get('/simple/custom-sitemap.xml')\n\t\tself.assertEqual(response.content, \"\"\"\n\n", "description": "\n\n", "category": "simple", "imports": ["from datetime import date", "from django.conf import settings", "from django.contrib.auth.models import User", "from django.contrib.sitemaps import Sitemap, GenericSitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.utils.unittest import skipUnless", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "from .base import SitemapTestsBase"]}, {"term": "def", "name": "ftest_localized_priority", "data": "\tdef test_localized_priority(self):\n\t\t\"The priority value should not be localized (Refs #14164)\"\n\t\t# Localization should be active\n\t\tsettings.USE_L10N = True\n\t\tactivate('fr')\n\t\tself.assertEqual(u'0,3', localize(0.3))\n\n\t\t# Retrieve the sitemap. Check that priorities\n\t\t# haven't been rendered in localized format\n\t\tresponse = self.client.get('/simple/sitemap.xml')\n\t\tself.assertContains(response, '0.5')\n\t\tself.assertContains(response, '%s' % date.today())\n\t\tdeactivate()\n", "description": null, "category": "simple", "imports": ["from datetime import date", "from django.conf import settings", "from django.contrib.auth.models import User", "from django.contrib.sitemaps import Sitemap, GenericSitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.utils.unittest import skipUnless", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "from .base import SitemapTestsBase"]}, {"term": "def", "name": "ftest_requestsite_sitemap", "data": "\tdef test_requestsite_sitemap(self):\n\t\t# Make sure hitting the flatpages sitemap without the sites framework\n\t\t# installed doesn't raise an exception\n\t\tSite._meta.installed = False\n\t\tresponse = self.client.get('/simple/sitemap.xml')\n\t\tself.assertEqual(response.content, \"\"\"\n", "description": "\n", "category": "simple", "imports": ["from datetime import date", "from django.conf import settings", "from django.contrib.auth.models import User", "from django.contrib.sitemaps import Sitemap, GenericSitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.utils.unittest import skipUnless", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "from .base import SitemapTestsBase"]}, {"term": "def", "name": "ftest_sitemap_get_urls_no_site_1", "data": "\tdef test_sitemap_get_urls_no_site_1(self):\n\t\t\"\"\"\n\t\tCheck we get ImproperlyConfigured if we don't pass a site object to\n\t\tSitemap.get_urls and no Site objects exist\n\t\t\"\"\"\n\t\tSite.objects.all().delete()\n\t\tself.assertRaises(ImproperlyConfigured, Sitemap().get_urls)\n", "description": "\n\t\tCheck we get ImproperlyConfigured if we don't pass a site object to\n\t\tSitemap.get_urls and no Site objects exist\n\t\t", "category": "simple", "imports": ["from datetime import date", "from django.conf import settings", "from django.contrib.auth.models import User", "from django.contrib.sitemaps import Sitemap, GenericSitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.utils.unittest import skipUnless", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "from .base import SitemapTestsBase"]}, {"term": "def", "name": "ftest_sitemap_get_urls_no_site_2", "data": "\tdef test_sitemap_get_urls_no_site_2(self):\n\t\t\"\"\"\n\t\tCheck we get ImproperlyConfigured when we don't pass a site object to\n\t\tSitemap.get_urls if Site objects exists, but the sites framework is not\n\t\tactually installed.\n\t\t\"\"\"\n\t\tSite._meta.installed = False\n\t\tself.assertRaises(ImproperlyConfigured, Sitemap().get_urls)\n", "description": "\n\t\tCheck we get ImproperlyConfigured when we don't pass a site object to\n\t\tSitemap.get_urls if Site objects exists, but the sites framework is not\n\t\tactually installed.\n\t\t", "category": "simple", "imports": ["from datetime import date", "from django.conf import settings", "from django.contrib.auth.models import User", "from django.contrib.sitemaps import Sitemap, GenericSitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.utils.unittest import skipUnless", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "from .base import SitemapTestsBase"]}, {"term": "def", "name": "ftest_sitemap_item", "data": "\tdef test_sitemap_item(self):\n\t\t\"\"\"\n\t\tCheck to make sure that the raw item is included with each\n\t\tSitemap.get_url() url result.\n\t\t\"\"\"\n\t\tuser_sitemap = GenericSitemap({'queryset': User.objects.all()})\n\t\tdef is_user(url):\n\t\t\treturn isinstance(url['item'], User)\n\t\titem_in_url_info = all(map(is_user, user_sitemap.get_urls()))\n\t\tself.assertTrue(item_in_url_info)\n", "description": "\n\t\tCheck to make sure that the raw item is included with each\n\t\tSitemap.get_url() url result.\n\t\t", "category": "simple", "imports": ["from datetime import date", "from django.conf import settings", "from django.contrib.auth.models import User", "from django.contrib.sitemaps import Sitemap, GenericSitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.utils.unittest import skipUnless", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "from .base import SitemapTestsBase"]}, {"term": "def", "name": "ftest_cached_sitemap_index", "data": "\tdef test_cached_sitemap_index(self):\n\t\t\"\"\"\n\t\tCheck that a cached sitemap index can be rendered (#2713).\n\t\t\"\"\"\n\t\tresponse = self.client.get('/cached/index.xml')\n\t\tself.assertEqual(response.content, \"\"\"\n", "description": "\n\t\tCheck that a cached sitemap index can be rendered (#2713).\n\t\t", "category": "simple", "imports": ["from datetime import date", "from django.conf import settings", "from django.contrib.auth.models import User", "from django.contrib.sitemaps import Sitemap, GenericSitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.utils.unittest import skipUnless", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "from .base import SitemapTestsBase"]}], [{"term": "class", "name": "ScannerError", "data": "class ScannerError(MarkedYAMLError):\n\tpass\n", "description": null, "category": "simple", "imports": ["from error import MarkedYAMLError", "from tokens import *", "#\timport psyco"]}, {"term": "class", "name": "SimpleKey", "data": "class SimpleKey(object):\n\t# See below simple keys treatment.\n\n\tdef __init__(self, token_number, required, index, line, column, mark):\n\t\tself.token_number = token_number\n\t\tself.required = required\n\t\tself.index = index\n\t\tself.line = line\n\t\tself.column = column\n\t\tself.mark = mark\n", "description": null, "category": "simple", "imports": ["from error import MarkedYAMLError", "from tokens import *", "#\timport psyco"]}, {"term": "class", "name": "Scanner", "data": "class Scanner(object):\n\n\tdef __init__(self):\n\t\t\"\"\"Initialize the scanner.\"\"\"\n\t\t# It is assumed that Scanner and Reader will have a common descendant.\n\t\t# Reader do the dirty work of checking for BOM and converting the\n\t\t# input data to Unicode. It also adds NUL to the end.\n\t\t#\n\t\t# Reader supports the following methods\n\t\t#   self.peek(i=0)\t   # peek the next i-th character\n\t\t#   self.prefix(l=1)\t # peek the next l characters\n\t\t#   self.forward(l=1)\t# read the next l characters and move the pointer.\n\n\t\t# Had we reached the end of the stream?\n\t\tself.done = False\n\n\t\t# The number of unclosed '{' and '['. `flow_level == 0` means block\n\t\t# context.\n\t\tself.flow_level = 0\n\n\t\t# List of processed tokens that are not yet emitted.\n\t\tself.tokens = []\n\n\t\t# Add the STREAM-START token.\n\t\tself.fetch_stream_start()\n\n\t\t# Number of tokens that were emitted through the `get_token` method.\n\t\tself.tokens_taken = 0\n\n\t\t# The current indentation level.\n\t\tself.indent = -1\n\n\t\t# Past indentation levels.\n\t\tself.indents = []\n\n\t\t# Variables related to simple keys treatment.\n\n\t\t# A simple key is a key that is not denoted by the '?' indicator.\n\t\t# Example of simple keys:\n\t\t#   ---\n\t\t#   block simple key: value\n\t\t#   ? not a simple key:\n\t\t#   : { flow simple key: value }\n\t\t# We emit the KEY token before all keys, so when we find a potential\n\t\t# simple key, we try to locate the corresponding ':' indicator.\n\t\t# Simple keys should be limited to a single line and 1024 characters.\n\n\t\t# Can a simple key start at the current position? A simple key may\n\t\t# start:\n\t\t# - at the beginning of the line, not counting indentation spaces\n\t\t#\t   (in block context),\n\t\t# - after '{', '[', ',' (in the flow context),\n\t\t# - after '?', ':', '-' (in the block context).\n\t\t# In the block context, this flag also signifies if a block collection\n\t\t# may start at the current position.\n\t\tself.allow_simple_key = True\n\n\t\t# Keep track of possible simple keys. This is a dictionary. The key\n\t\t# is `flow_level`; there can be no more that one possible simple key\n\t\t# for each level. The value is a SimpleKey record:\n\t\t#   (token_number, required, index, line, column, mark)\n\t\t# A simple key may start with ALIAS, ANCHOR, TAG, SCALAR(flow),\n\t\t# '[', or '{' tokens.\n\t\tself.possible_simple_keys = {}\n\n\t# Public methods.\n\n\tdef check_token(self, *choices):\n\t\t# Check if the next token is one of the given types.\n\t\twhile self.need_more_tokens():\n\t\t\tself.fetch_more_tokens()\n\t\tif self.tokens:\n\t\t\tif not choices:\n\t\t\t\treturn True\n\t\t\tfor choice in choices:\n\t\t\t\tif isinstance(self.tokens[0], choice):\n\t\t\t\t\treturn True\n\t\treturn False\n\n\tdef peek_token(self):\n\t\t# Return the next token, but do not delete if from the queue.\n\t\twhile self.need_more_tokens():\n\t\t\tself.fetch_more_tokens()\n\t\tif self.tokens:\n\t\t\treturn self.tokens[0]\n\n\tdef get_token(self):\n\t\t# Return the next token.\n\t\twhile self.need_more_tokens():\n\t\t\tself.fetch_more_tokens()\n\t\tif self.tokens:\n\t\t\tself.tokens_taken += 1\n\t\t\treturn self.tokens.pop(0)\n\n\t# Private methods.\n\n\tdef need_more_tokens(self):\n\t\tif self.done:\n\t\t\treturn False\n\t\tif not self.tokens:\n\t\t\treturn True\n\t\t# The current token may be a potential simple key, so we\n\t\t# need to look further.\n\t\tself.stale_possible_simple_keys()\n\t\tif self.next_possible_simple_key() == self.tokens_taken:\n\t\t\treturn True\n\n\tdef fetch_more_tokens(self):\n\n\t\t# Eat whitespaces and comments until we reach the next token.\n\t\tself.scan_to_next_token()\n\n\t\t# Remove obsolete possible simple keys.\n\t\tself.stale_possible_simple_keys()\n\n\t\t# Compare the current indentation and column. It may add some tokens\n\t\t# and decrease the current indentation level.\n\t\tself.unwind_indent(self.column)\n\n\t\t# Peek the next character.\n\t\tch = self.peek()\n\n\t\t# Is it the end of stream?\n\t\tif ch == u'\\0':\n\t\t\treturn self.fetch_stream_end()\n\n\t\t# Is it a directive?\n\t\tif ch == u'%' and self.check_directive():\n\t\t\treturn self.fetch_directive()\n\n\t\t# Is it the document start?\n\t\tif ch == u'-' and self.check_document_start():\n\t\t\treturn self.fetch_document_start()\n\n\t\t# Is it the document end?\n\t\tif ch == u'.' and self.check_document_end():\n\t\t\treturn self.fetch_document_end()\n\n\t\t# TODO: support for BOM within a stream.\n\t\t#if ch == u'\\uFEFF':\n\t\t#\treturn self.fetch_bom()\t<-- issue BOMToken\n\n\t\t# Note: the order of the following checks is NOT significant.\n\n\t\t# Is it the flow sequence start indicator?\n\t\tif ch == u'[':\n\t\t\treturn self.fetch_flow_sequence_start()\n\n\t\t# Is it the flow mapping start indicator?\n\t\tif ch == u'{':\n\t\t\treturn self.fetch_flow_mapping_start()\n\n\t\t# Is it the flow sequence end indicator?\n\t\tif ch == u']':\n\t\t\treturn self.fetch_flow_sequence_end()\n\n\t\t# Is it the flow mapping end indicator?\n\t\tif ch == u'}':\n\t\t\treturn self.fetch_flow_mapping_end()\n\n\t\t# Is it the flow entry indicator?\n\t\tif ch == u',':\n\t\t\treturn self.fetch_flow_entry()\n\n\t\t# Is it the block entry indicator?\n\t\tif ch == u'-' and self.check_block_entry():\n\t\t\treturn self.fetch_block_entry()\n\n\t\t# Is it the key indicator?\n\t\tif ch == u'?' and self.check_key():\n\t\t\treturn self.fetch_key()\n\n\t\t# Is it the value indicator?\n\t\tif ch == u':' and self.check_value():\n\t\t\treturn self.fetch_value()\n\n\t\t# Is it an alias?\n\t\tif ch == u'*':\n\t\t\treturn self.fetch_alias()\n\n\t\t# Is it an anchor?\n\t\tif ch == u'&':\n\t\t\treturn self.fetch_anchor()\n\n\t\t# Is it a tag?\n\t\tif ch == u'!':\n\t\t\treturn self.fetch_tag()\n\n\t\t# Is it a literal scalar?\n\t\tif ch == u'|' and not self.flow_level:\n\t\t\treturn self.fetch_literal()\n\n\t\t# Is it a folded scalar?\n\t\tif ch == u'>' and not self.flow_level:\n\t\t\treturn self.fetch_folded()\n\n\t\t# Is it a single quoted scalar?\n\t\tif ch == u'\\'':\n\t\t\treturn self.fetch_single()\n\n\t\t# Is it a double quoted scalar?\n\t\tif ch == u'\\\"':\n\t\t\treturn self.fetch_double()\n\n\t\t# It must be a plain scalar then.\n\t\tif self.check_plain():\n\t\t\treturn self.fetch_plain()\n\n\t\t# No? It's an error. Let's produce a nice error message.\n\t\traise ScannerError(\"while scanning for the next token\", None,\n\t\t\t\t\"found character %r that cannot start any token\"\n\t\t\t\t% ch.encode('utf-8'), self.get_mark())\n\n\t# Simple keys treatment.\n\n\tdef next_possible_simple_key(self):\n\t\t# Return the number of the nearest possible simple key. Actually we\n\t\t# don't need to loop through the whole dictionary. We may replace it\n\t\t# with the following code:\n\t\t#   if not self.possible_simple_keys:\n\t\t#\t   return None\n\t\t#   return self.possible_simple_keys[\n\t\t#\t\t   min(self.possible_simple_keys.keys())].token_number\n\t\tmin_token_number = None\n\t\tfor level in self.possible_simple_keys:\n\t\t\tkey = self.possible_simple_keys[level]\n\t\t\tif min_token_number is None or key.token_number < min_token_number:\n\t\t\t\tmin_token_number = key.token_number\n\t\treturn min_token_number\n\n\tdef stale_possible_simple_keys(self):\n\t\t# Remove entries that are no longer possible simple keys. According to\n\t\t# the YAML specification, simple keys\n\t\t# - should be limited to a single line,\n\t\t# - should be no longer than 1024 characters.\n\t\t# Disabling this procedure will allow simple keys of any length and\n\t\t# height (may cause problems if indentation is broken though).\n\t\tfor level in self.possible_simple_keys.keys():\n\t\t\tkey = self.possible_simple_keys[level]\n\t\t\tif key.line != self.line  \\\n\t\t\t\t\tor self.index-key.index > 1024:\n\t\t\t\tif key.required:\n\t\t\t\t\traise ScannerError(\"while scanning a simple key\", key.mark,\n\t\t\t\t\t\t\t\"could not found expected ':'\", self.get_mark())\n\t\t\t\tdel self.possible_simple_keys[level]\n\n\tdef save_possible_simple_key(self):\n\t\t# The next token may start a simple key. We check if it's possible\n\t\t# and save its position. This function is called for\n\t\t#   ALIAS, ANCHOR, TAG, SCALAR(flow), '[', and '{'.\n\n\t\t# Check if a simple key is required at the current position.\n\t\trequired = not self.flow_level and self.indent == self.column\n\n\t\t# A simple key is required only if it is the first token in the current\n\t\t# line. Therefore it is always allowed.\n\t\tassert self.allow_simple_key or not required\n\n\t\t# The next token might be a simple key. Let's save it's number and\n\t\t# position.\n\t\tif self.allow_simple_key:\n\t\t\tself.remove_possible_simple_key()\n\t\t\ttoken_number = self.tokens_taken+len(self.tokens)\n\t\t\tkey = SimpleKey(token_number, required,\n\t\t\t\t\tself.index, self.line, self.column, self.get_mark())\n\t\t\tself.possible_simple_keys[self.flow_level] = key\n\n\tdef remove_possible_simple_key(self):\n\t\t# Remove the saved possible key position at the current flow level.\n\t\tif self.flow_level in self.possible_simple_keys:\n\t\t\tkey = self.possible_simple_keys[self.flow_level]\n\t\t\t\n\t\t\tif key.required:\n\t\t\t\traise ScannerError(\"while scanning a simple key\", key.mark,\n\t\t\t\t\t\t\"could not found expected ':'\", self.get_mark())\n\n\t\t\tdel self.possible_simple_keys[self.flow_level]\n\n\t# Indentation functions.\n\n\tdef unwind_indent(self, column):\n\n\t\t## In flow context, tokens should respect indentation.\n\t\t## Actually the condition should be `self.indent >= column` according to\n\t\t## the spec. But this condition will prohibit intuitively correct\n\t\t## constructions such as\n\t\t## key : {\n\t\t## }\n\t\t#if self.flow_level and self.indent > column:\n\t\t#\traise ScannerError(None, None,\n\t\t#\t\t\t\"invalid intendation or unclosed '[' or '{'\",\n\t\t#\t\t\tself.get_mark())\n\n\t\t# In the flow context, indentation is ignored. We make the scanner less\n\t\t# restrictive then specification requires.\n\t\tif self.flow_level:\n\t\t\treturn\n\n\t\t# In block context, we may need to issue the BLOCK-END tokens.\n\t\twhile self.indent > column:\n\t\t\tmark = self.get_mark()\n\t\t\tself.indent = self.indents.pop()\n\t\t\tself.tokens.append(BlockEndToken(mark, mark))\n\n\tdef add_indent(self, column):\n\t\t# Check if we need to increase indentation.\n\t\tif self.indent < column:\n\t\t\tself.indents.append(self.indent)\n\t\t\tself.indent = column\n\t\t\treturn True\n\t\treturn False\n\n\t# Fetchers.\n\n\tdef fetch_stream_start(self):\n\t\t# We always add STREAM-START as the first token and STREAM-END as the\n\t\t# last token.\n\n\t\t# Read the token.\n\t\tmark = self.get_mark()\n\t\t\n\t\t# Add STREAM-START.\n\t\tself.tokens.append(StreamStartToken(mark, mark,\n\t\t\tencoding=self.encoding))\n\t\t\n\n\tdef fetch_stream_end(self):\n\n\t\t# Set the current intendation to -1.\n\t\tself.unwind_indent(-1)\n\n\t\t# Reset everything (not really needed).\n\t\tself.allow_simple_key = False\n\t\tself.possible_simple_keys = {}\n\n\t\t# Read the token.\n\t\tmark = self.get_mark()\n\t\t\n\t\t# Add STREAM-END.\n\t\tself.tokens.append(StreamEndToken(mark, mark))\n\n\t\t# The steam is finished.\n\t\tself.done = True\n\n\tdef fetch_directive(self):\n\t\t\n\t\t# Set the current intendation to -1.\n\t\tself.unwind_indent(-1)\n\n\t\t# Reset simple keys.\n\t\tself.remove_possible_simple_key()\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add DIRECTIVE.\n\t\tself.tokens.append(self.scan_directive())\n\n\tdef fetch_document_start(self):\n\t\tself.fetch_document_indicator(DocumentStartToken)\n\n\tdef fetch_document_end(self):\n\t\tself.fetch_document_indicator(DocumentEndToken)\n\n\tdef fetch_document_indicator(self, TokenClass):\n\n\t\t# Set the current intendation to -1.\n\t\tself.unwind_indent(-1)\n\n\t\t# Reset simple keys. Note that there could not be a block collection\n\t\t# after '---'.\n\t\tself.remove_possible_simple_key()\n\t\tself.allow_simple_key = False\n\n\t\t# Add DOCUMENT-START or DOCUMENT-END.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward(3)\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(TokenClass(start_mark, end_mark))\n\n\tdef fetch_flow_sequence_start(self):\n\t\tself.fetch_flow_collection_start(FlowSequenceStartToken)\n\n\tdef fetch_flow_mapping_start(self):\n\t\tself.fetch_flow_collection_start(FlowMappingStartToken)\n\n\tdef fetch_flow_collection_start(self, TokenClass):\n\n\t\t# '[' and '{' may start a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# Increase the flow level.\n\t\tself.flow_level += 1\n\n\t\t# Simple keys are allowed after '[' and '{'.\n\t\tself.allow_simple_key = True\n\n\t\t# Add FLOW-SEQUENCE-START or FLOW-MAPPING-START.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(TokenClass(start_mark, end_mark))\n\n\tdef fetch_flow_sequence_end(self):\n\t\tself.fetch_flow_collection_end(FlowSequenceEndToken)\n\n\tdef fetch_flow_mapping_end(self):\n\t\tself.fetch_flow_collection_end(FlowMappingEndToken)\n\n\tdef fetch_flow_collection_end(self, TokenClass):\n\n\t\t# Reset possible simple key on the current level.\n\t\tself.remove_possible_simple_key()\n\n\t\t# Decrease the flow level.\n\t\tself.flow_level -= 1\n\n\t\t# No simple keys after ']' or '}'.\n\t\tself.allow_simple_key = False\n\n\t\t# Add FLOW-SEQUENCE-END or FLOW-MAPPING-END.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(TokenClass(start_mark, end_mark))\n\n\tdef fetch_flow_entry(self):\n\n\t\t# Simple keys are allowed after ','.\n\t\tself.allow_simple_key = True\n\n\t\t# Reset possible simple key on the current level.\n\t\tself.remove_possible_simple_key()\n\n\t\t# Add FLOW-ENTRY.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(FlowEntryToken(start_mark, end_mark))\n\n\tdef fetch_block_entry(self):\n\n\t\t# Block context needs additional checks.\n\t\tif not self.flow_level:\n\n\t\t\t# Are we allowed to start a new entry?\n\t\t\tif not self.allow_simple_key:\n\t\t\t\traise ScannerError(None, None,\n\t\t\t\t\t\t\"sequence entries are not allowed here\",\n\t\t\t\t\t\tself.get_mark())\n\n\t\t\t# We may need to add BLOCK-SEQUENCE-START.\n\t\t\tif self.add_indent(self.column):\n\t\t\t\tmark = self.get_mark()\n\t\t\t\tself.tokens.append(BlockSequenceStartToken(mark, mark))\n\n\t\t# It's an error for the block entry to occur in the flow context,\n\t\t# but we let the parser detect this.\n\t\telse:\n\t\t\tpass\n\n\t\t# Simple keys are allowed after '-'.\n\t\tself.allow_simple_key = True\n\n\t\t# Reset possible simple key on the current level.\n\t\tself.remove_possible_simple_key()\n\n\t\t# Add BLOCK-ENTRY.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(BlockEntryToken(start_mark, end_mark))\n\n\tdef fetch_key(self):\n\t\t\n\t\t# Block context needs additional checks.\n\t\tif not self.flow_level:\n\n\t\t\t# Are we allowed to start a key (not nessesary a simple)?\n\t\t\tif not self.allow_simple_key:\n\t\t\t\traise ScannerError(None, None,\n\t\t\t\t\t\t\"mapping keys are not allowed here\",\n\t\t\t\t\t\tself.get_mark())\n\n\t\t\t# We may need to add BLOCK-MAPPING-START.\n\t\t\tif self.add_indent(self.column):\n\t\t\t\tmark = self.get_mark()\n\t\t\t\tself.tokens.append(BlockMappingStartToken(mark, mark))\n\n\t\t# Simple keys are allowed after '?' in the block context.\n\t\tself.allow_simple_key = not self.flow_level\n\n\t\t# Reset possible simple key on the current level.\n\t\tself.remove_possible_simple_key()\n\n\t\t# Add KEY.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(KeyToken(start_mark, end_mark))\n\n\tdef fetch_value(self):\n\n\t\t# Do we determine a simple key?\n\t\tif self.flow_level in self.possible_simple_keys:\n\n\t\t\t# Add KEY.\n\t\t\tkey = self.possible_simple_keys[self.flow_level]\n\t\t\tdel self.possible_simple_keys[self.flow_level]\n\t\t\tself.tokens.insert(key.token_number-self.tokens_taken,\n\t\t\t\t\tKeyToken(key.mark, key.mark))\n\n\t\t\t# If this key starts a new block mapping, we need to add\n\t\t\t# BLOCK-MAPPING-START.\n\t\t\tif not self.flow_level:\n\t\t\t\tif self.add_indent(key.column):\n\t\t\t\t\tself.tokens.insert(key.token_number-self.tokens_taken,\n\t\t\t\t\t\t\tBlockMappingStartToken(key.mark, key.mark))\n\n\t\t\t# There cannot be two simple keys one after another.\n\t\t\tself.allow_simple_key = False\n\n\t\t# It must be a part of a complex key.\n\t\telse:\n\t\t\t\n\t\t\t# Block context needs additional checks.\n\t\t\t# (Do we really need them? They will be catched by the parser\n\t\t\t# anyway.)\n\t\t\tif not self.flow_level:\n\n\t\t\t\t# We are allowed to start a complex value if and only if\n\t\t\t\t# we can start a simple key.\n\t\t\t\tif not self.allow_simple_key:\n\t\t\t\t\traise ScannerError(None, None,\n\t\t\t\t\t\t\t\"mapping values are not allowed here\",\n\t\t\t\t\t\t\tself.get_mark())\n\n\t\t\t# If this value starts a new block mapping, we need to add\n\t\t\t# BLOCK-MAPPING-START.  It will be detected as an error later by\n\t\t\t# the parser.\n\t\t\tif not self.flow_level:\n\t\t\t\tif self.add_indent(self.column):\n\t\t\t\t\tmark = self.get_mark()\n\t\t\t\t\tself.tokens.append(BlockMappingStartToken(mark, mark))\n\n\t\t\t# Simple keys are allowed after ':' in the block context.\n\t\t\tself.allow_simple_key = not self.flow_level\n\n\t\t\t# Reset possible simple key on the current level.\n\t\t\tself.remove_possible_simple_key()\n\n\t\t# Add VALUE.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(ValueToken(start_mark, end_mark))\n\n\tdef fetch_alias(self):\n\n\t\t# ALIAS could be a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# No simple keys after ALIAS.\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add ALIAS.\n\t\tself.tokens.append(self.scan_anchor(AliasToken))\n\n\tdef fetch_anchor(self):\n\n\t\t# ANCHOR could start a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# No simple keys after ANCHOR.\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add ANCHOR.\n\t\tself.tokens.append(self.scan_anchor(AnchorToken))\n\n\tdef fetch_tag(self):\n\n\t\t# TAG could start a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# No simple keys after TAG.\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add TAG.\n\t\tself.tokens.append(self.scan_tag())\n\n\tdef fetch_literal(self):\n\t\tself.fetch_block_scalar(style='|')\n\n\tdef fetch_folded(self):\n\t\tself.fetch_block_scalar(style='>')\n\n\tdef fetch_block_scalar(self, style):\n\n\t\t# A simple key may follow a block scalar.\n\t\tself.allow_simple_key = True\n\n\t\t# Reset possible simple key on the current level.\n\t\tself.remove_possible_simple_key()\n\n\t\t# Scan and add SCALAR.\n\t\tself.tokens.append(self.scan_block_scalar(style))\n\n\tdef fetch_single(self):\n\t\tself.fetch_flow_scalar(style='\\'')\n\n\tdef fetch_double(self):\n\t\tself.fetch_flow_scalar(style='\"')\n\n\tdef fetch_flow_scalar(self, style):\n\n\t\t# A flow scalar could be a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# No simple keys after flow scalars.\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add SCALAR.\n\t\tself.tokens.append(self.scan_flow_scalar(style))\n\n\tdef fetch_plain(self):\n\n\t\t# A plain scalar could be a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# No simple keys after plain scalars. But note that `scan_plain` will\n\t\t# change this flag if the scan is finished at the beginning of the\n\t\t# line.\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add SCALAR. May change `allow_simple_key`.\n\t\tself.tokens.append(self.scan_plain())\n\n\t# Checkers.\n\n\tdef check_directive(self):\n\n\t\t# DIRECTIVE:\t\t^ '%' ...\n\t\t# The '%' indicator is already checked.\n\t\tif self.column == 0:\n\t\t\treturn True\n\n\tdef check_document_start(self):\n\n\t\t# DOCUMENT-START:   ^ '---' (' '|'\\n')\n\t\tif self.column == 0:\n\t\t\tif self.prefix(3) == u'---'  \\\n\t\t\t\t\tand self.peek(3) in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\treturn True\n\n\tdef check_document_end(self):\n\n\t\t# DOCUMENT-END:\t ^ '...' (' '|'\\n')\n\t\tif self.column == 0:\n\t\t\tif self.prefix(3) == u'...'  \\\n\t\t\t\t\tand self.peek(3) in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\treturn True\n\n\tdef check_block_entry(self):\n\n\t\t# BLOCK-ENTRY:\t  '-' (' '|'\\n')\n\t\treturn self.peek(1) in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029'\n\n\tdef check_key(self):\n\n\t\t# KEY(flow context):\t'?'\n\t\tif self.flow_level:\n\t\t\treturn True\n\n\t\t# KEY(block context):   '?' (' '|'\\n')\n\t\telse:\n\t\t\treturn self.peek(1) in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029'\n\n\tdef check_value(self):\n\n\t\t# VALUE(flow context):  ':'\n\t\tif self.flow_level:\n\t\t\treturn True\n\n\t\t# VALUE(block context): ':' (' '|'\\n')\n\t\telse:\n\t\t\treturn self.peek(1) in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029'\n\n\tdef check_plain(self):\n\n\t\t# A plain scalar may start with any non-space character except:\n\t\t#   '-', '?', ':', ',', '[', ']', '{', '}',\n\t\t#   '#', '&', '*', '!', '|', '>', '\\'', '\\\"',\n\t\t#   '%', '@', '`'.\n\t\t#\n\t\t# It may also start with\n\t\t#   '-', '?', ':'\n\t\t# if it is followed by a non-space character.\n\t\t#\n\t\t# Note that we limit the last rule to the block context (except the\n\t\t# '-' character) because we want the flow context to be space\n\t\t# independent.\n\t\tch = self.peek()\n\t\treturn ch not in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029-?:,[]{}#&*!|>\\'\\\"%@`'  \\\n\t\t\t\tor (self.peek(1) not in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029'\n\t\t\t\t\t\tand (ch == u'-' or (not self.flow_level and ch in u'?:')))\n\n\t# Scanners.\n\n\tdef scan_to_next_token(self):\n\t\t# We ignore spaces, line breaks and comments.\n\t\t# If we find a line break in the block context, we set the flag\n\t\t# `allow_simple_key` on.\n\t\t# The byte order mark is stripped if it's the first character in the\n\t\t# stream. We do not yet support BOM inside the stream as the\n\t\t# specification requires. Any such mark will be considered as a part\n\t\t# of the document.\n\t\t#\n\t\t# TODO: We need to make tab handling rules more sane. A good rule is\n\t\t#   Tabs cannot precede tokens\n\t\t#   BLOCK-SEQUENCE-START, BLOCK-MAPPING-START, BLOCK-END,\n\t\t#   KEY(block), VALUE(block), BLOCK-ENTRY\n\t\t# So the checking code is\n\t\t#   if :\n\t\t#\t   self.allow_simple_keys = False\n\t\t# We also need to add the check for `allow_simple_keys == True` to\n\t\t# `unwind_indent` before issuing BLOCK-END.\n\t\t# Scanners for block, flow, and plain scalars need to be modified.\n\n\t\tif self.index == 0 and self.peek() == u'\\uFEFF':\n\t\t\tself.forward()\n\t\tfound = False\n\t\twhile not found:\n\t\t\twhile self.peek() == u' ':\n\t\t\t\tself.forward()\n\t\t\tif self.peek() == u'#':\n\t\t\t\twhile self.peek() not in u'\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\t\tself.forward()\n\t\t\tif self.scan_line_break():\n\t\t\t\tif not self.flow_level:\n\t\t\t\t\tself.allow_simple_key = True\n\t\t\telse:\n\t\t\t\tfound = True\n\n\tdef scan_directive(self):\n\t\t# See the specification for details.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tname = self.scan_directive_name(start_mark)\n\t\tvalue = None\n\t\tif name == u'YAML':\n\t\t\tvalue = self.scan_yaml_directive_value(start_mark)\n\t\t\tend_mark = self.get_mark()\n\t\telif name == u'TAG':\n\t\t\tvalue = self.scan_tag_directive_value(start_mark)\n\t\t\tend_mark = self.get_mark()\n\t\telse:\n\t\t\tend_mark = self.get_mark()\n\t\t\twhile self.peek() not in u'\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tself.forward()\n\t\tself.scan_directive_ignored_line(start_mark)\n\t\treturn DirectiveToken(name, value, start_mark, end_mark)\n\n\tdef scan_directive_name(self, start_mark):\n\t\t# See the specification for details.\n\t\tlength = 0\n\t\tch = self.peek(length)\n\t\twhile u'0' <= ch <= u'9' or u'A' <= ch <= 'Z' or u'a' <= ch <= 'z'  \\\n\t\t\t\tor ch in u'-_':\n\t\t\tlength += 1\n\t\t\tch = self.peek(length)\n\t\tif not length:\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected alphabetic or numeric character, but found %r\"\n\t\t\t\t\t% ch.encode('utf-8'), self.get_mark())\n\t\tvalue = self.prefix(length)\n\t\tself.forward(length)\n\t\tch = self.peek()\n\t\tif ch not in u'\\0 \\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected alphabetic or numeric character, but found %r\"\n\t\t\t\t\t% ch.encode('utf-8'), self.get_mark())\n\t\treturn value\n\n\tdef scan_yaml_directive_value(self, start_mark):\n\t\t# See the specification for details.\n\t\twhile self.peek() == u' ':\n\t\t\tself.forward()\n\t\tmajor = self.scan_yaml_directive_number(start_mark)\n\t\tif self.peek() != '.':\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected a digit or '.', but found %r\"\n\t\t\t\t\t% self.peek().encode('utf-8'),\n\t\t\t\t\tself.get_mark())\n\t\tself.forward()\n\t\tminor = self.scan_yaml_directive_number(start_mark)\n\t\tif self.peek() not in u'\\0 \\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected a digit or ' ', but found %r\"\n\t\t\t\t\t% self.peek().encode('utf-8'),\n\t\t\t\t\tself.get_mark())\n\t\treturn (major, minor)\n\n\tdef scan_yaml_directive_number(self, start_mark):\n\t\t# See the specification for details.\n\t\tch = self.peek()\n\t\tif not (u'0' <= ch <= '9'):\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected a digit, but found %r\" % ch.encode('utf-8'),\n\t\t\t\t\tself.get_mark())\n\t\tlength = 0\n\t\twhile u'0' <= self.peek(length) <= u'9':\n\t\t\tlength += 1\n\t\tvalue = int(self.prefix(length))\n\t\tself.forward(length)\n\t\treturn value\n\n\tdef scan_tag_directive_value(self, start_mark):\n\t\t# See the specification for details.\n\t\twhile self.peek() == u' ':\n\t\t\tself.forward()\n\t\thandle = self.scan_tag_directive_handle(start_mark)\n\t\twhile self.peek() == u' ':\n\t\t\tself.forward()\n\t\tprefix = self.scan_tag_directive_prefix(start_mark)\n\t\treturn (handle, prefix)\n\n\tdef scan_tag_directive_handle(self, start_mark):\n\t\t# See the specification for details.\n\t\tvalue = self.scan_tag_handle('directive', start_mark)\n\t\tch = self.peek()\n\t\tif ch != u' ':\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected ' ', but found %r\" % ch.encode('utf-8'),\n\t\t\t\t\tself.get_mark())\n\t\treturn value\n\n\tdef scan_tag_directive_prefix(self, start_mark):\n\t\t# See the specification for details.\n\t\tvalue = self.scan_tag_uri('directive', start_mark)\n\t\tch = self.peek()\n\t\tif ch not in u'\\0 \\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected ' ', but found %r\" % ch.encode('utf-8'),\n\t\t\t\t\tself.get_mark())\n\t\treturn value\n\n\tdef scan_directive_ignored_line(self, start_mark):\n\t\t# See the specification for details.\n\t\twhile self.peek() == u' ':\n\t\t\tself.forward()\n\t\tif self.peek() == u'#':\n\t\t\twhile self.peek() not in u'\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tself.forward()\n\t\tch = self.peek()\n\t\tif ch not in u'\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected a comment or a line break, but found %r\"\n\t\t\t\t\t\t% ch.encode('utf-8'), self.get_mark())\n\t\tself.scan_line_break()\n\n\tdef scan_anchor(self, TokenClass):\n\t\t# The specification does not restrict characters for anchors and\n\t\t# aliases. This may lead to problems, for instance, the document:\n\t\t#   [ *alias, value ]\n\t\t# can be interpteted in two ways, as\n\t\t#   [ \"value\" ]\n\t\t# and\n\t\t#   [ *alias , \"value\" ]\n\t\t# Therefore we restrict aliases to numbers and ASCII letters.\n\t\tstart_mark = self.get_mark()\n\t\tindicator = self.peek()\n\t\tif indicator == '*':\n\t\t\tname = 'alias'\n\t\telse:\n\t\t\tname = 'anchor'\n\t\tself.forward()\n\t\tlength = 0\n\t\tch = self.peek(length)\n\t\twhile u'0' <= ch <= u'9' or u'A' <= ch <= 'Z' or u'a' <= ch <= 'z'  \\\n\t\t\t\tor ch in u'-_':\n\t\t\tlength += 1\n\t\t\tch = self.peek(length)\n\t\tif not length:\n\t\t\traise ScannerError(\"while scanning an %s\" % name, start_mark,\n\t\t\t\t\t\"expected alphabetic or numeric character, but found %r\"\n\t\t\t\t\t% ch.encode('utf-8'), self.get_mark())\n\t\tvalue = self.prefix(length)\n\t\tself.forward(length)\n\t\tch = self.peek()\n\t\tif ch not in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029?:,]}%@`':\n\t\t\traise ScannerError(\"while scanning an %s\" % name, start_mark,\n\t\t\t\t\t\"expected alphabetic or numeric character, but found %r\"\n\t\t\t\t\t% ch.encode('utf-8'), self.get_mark())\n\t\tend_mark = self.get_mark()\n\t\treturn TokenClass(value, start_mark, end_mark)\n\n\tdef scan_tag(self):\n\t\t# See the specification for details.\n\t\tstart_mark = self.get_mark()\n\t\tch = self.peek(1)\n\t\tif ch == u'<':\n\t\t\thandle = None\n\t\t\tself.forward(2)\n\t\t\tsuffix = self.scan_tag_uri('tag', start_mark)\n\t\t\tif self.peek() != u'>':\n\t\t\t\traise ScannerError(\"while parsing a tag\", start_mark,\n\t\t\t\t\t\t\"expected '>', but found %r\" % self.peek().encode('utf-8'),\n\t\t\t\t\t\tself.get_mark())\n\t\t\tself.forward()\n\t\telif ch in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\thandle = None\n\t\t\tsuffix = u'!'\n\t\t\tself.forward()\n\t\telse:\n\t\t\tlength = 1\n\t\t\tuse_handle = False\n\t\t\twhile ch not in u'\\0 \\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tif ch == u'!':\n\t\t\t\t\tuse_handle = True\n\t\t\t\t\tbreak\n\t\t\t\tlength += 1\n\t\t\t\tch = self.peek(length)\n\t\t\thandle = u'!'\n\t\t\tif use_handle:\n\t\t\t\thandle = self.scan_tag_handle('tag', start_mark)\n\t\t\telse:\n\t\t\t\thandle = u'!'\n\t\t\t\tself.forward()\n\t\t\tsuffix = self.scan_tag_uri('tag', start_mark)\n\t\tch = self.peek()\n\t\tif ch not in u'\\0 \\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a tag\", start_mark,\n\t\t\t\t\t\"expected ' ', but found %r\" % ch.encode('utf-8'),\n\t\t\t\t\tself.get_mark())\n\t\tvalue = (handle, suffix)\n\t\tend_mark = self.get_mark()\n\t\treturn TagToken(value, start_mark, end_mark)\n\n\tdef scan_block_scalar(self, style):\n\t\t# See the specification for details.\n\n\t\tif style == '>':\n\t\t\tfolded = True\n\t\telse:\n\t\t\tfolded = False\n\n\t\tchunks = []\n\t\tstart_mark = self.get_mark()\n\n\t\t# Scan the header.\n\t\tself.forward()\n\t\tchomping, increment = self.scan_block_scalar_indicators(start_mark)\n\t\tself.scan_block_scalar_ignored_line(start_mark)\n\n\t\t# Determine the indentation level and go to the first non-empty line.\n\t\tmin_indent = self.indent+1\n\t\tif min_indent < 1:\n\t\t\tmin_indent = 1\n\t\tif increment is None:\n\t\t\tbreaks, max_indent, end_mark = self.scan_block_scalar_indentation()\n\t\t\tindent = max(min_indent, max_indent)\n\t\telse:\n\t\t\tindent = min_indent+increment-1\n\t\t\tbreaks, end_mark = self.scan_block_scalar_breaks(indent)\n\t\tline_break = u''\n\n\t\t# Scan the inner part of the block scalar.\n\t\twhile self.column == indent and self.peek() != u'\\0':\n\t\t\tchunks.extend(breaks)\n\t\t\tleading_non_space = self.peek() not in u' \\t'\n\t\t\tlength = 0\n\t\t\twhile self.peek(length) not in u'\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tlength += 1\n\t\t\tchunks.append(self.prefix(length))\n\t\t\tself.forward(length)\n\t\t\tline_break = self.scan_line_break()\n\t\t\tbreaks, end_mark = self.scan_block_scalar_breaks(indent)\n\t\t\tif self.column == indent and self.peek() != u'\\0':\n\n\t\t\t\t# Unfortunately, folding rules are ambiguous.\n\t\t\t\t#\n\t\t\t\t# This is the folding according to the specification:\n\t\t\t\t\n\t\t\t\tif folded and line_break == u'\\n'   \\\n\t\t\t\t\t\tand leading_non_space and self.peek() not in u' \\t':\n\t\t\t\t\tif not breaks:\n\t\t\t\t\t\tchunks.append(u' ')\n\t\t\t\telse:\n\t\t\t\t\tchunks.append(line_break)\n\t\t\t\t\n\t\t\t\t# This is Clark Evans's interpretation (also in the spec\n\t\t\t\t# examples):\n\t\t\t\t#\n\t\t\t\t#if folded and line_break == u'\\n':\n\t\t\t\t#\tif not breaks:\n\t\t\t\t#\t\tif self.peek() not in ' \\t':\n\t\t\t\t#\t\t\tchunks.append(u' ')\n\t\t\t\t#\t\telse:\n\t\t\t\t#\t\t\tchunks.append(line_break)\n\t\t\t\t#else:\n\t\t\t\t#\tchunks.append(line_break)\n\t\t\telse:\n\t\t\t\tbreak\n\n\t\t# Chomp the tail.\n\t\tif chomping is not False:\n\t\t\tchunks.append(line_break)\n\t\tif chomping is True:\n\t\t\tchunks.extend(breaks)\n\n\t\t# We are done.\n\t\treturn ScalarToken(u''.join(chunks), False, start_mark, end_mark,\n\t\t\t\tstyle)\n\n\tdef scan_block_scalar_indicators(self, start_mark):\n\t\t# See the specification for details.\n\t\tchomping = None\n\t\tincrement = None\n\t\tch = self.peek()\n\t\tif ch in u'+-':\n\t\t\tif ch == '+':\n\t\t\t\tchomping = True\n\t\t\telse:\n\t\t\t\tchomping = False\n\t\t\tself.forward()\n\t\t\tch = self.peek()\n\t\t\tif ch in u'0123456789':\n\t\t\t\tincrement = int(ch)\n\t\t\t\tif increment == 0:\n\t\t\t\t\traise ScannerError(\"while scanning a block scalar\", start_mark,\n\t\t\t\t\t\t\t\"expected indentation indicator in the range 1-9, but found 0\",\n\t\t\t\t\t\t\tself.get_mark())\n\t\t\t\tself.forward()\n\t\telif ch in u'0123456789':\n\t\t\tincrement = int(ch)\n\t\t\tif increment == 0:\n\t\t\t\traise ScannerError(\"while scanning a block scalar\", start_mark,\n\t\t\t\t\t\t\"expected indentation indicator in the range 1-9, but found 0\",\n\t\t\t\t\t\tself.get_mark())\n\t\t\tself.forward()\n\t\t\tch = self.peek()\n\t\t\tif ch in u'+-':\n\t\t\t\tif ch == '+':\n\t\t\t\t\tchomping = True\n\t\t\t\telse:\n\t\t\t\t\tchomping = False\n\t\t\t\tself.forward()\n\t\tch = self.peek()\n\t\tif ch not in u'\\0 \\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a block scalar\", start_mark,\n\t\t\t\t\t\"expected chomping or indentation indicators, but found %r\"\n\t\t\t\t\t\t% ch.encode('utf-8'), self.get_mark())\n\t\treturn chomping, increment\n\n\tdef scan_block_scalar_ignored_line(self, start_mark):\n\t\t# See the specification for details.\n\t\twhile self.peek() == u' ':\n\t\t\tself.forward()\n\t\tif self.peek() == u'#':\n\t\t\twhile self.peek() not in u'\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tself.forward()\n\t\tch = self.peek()\n\t\tif ch not in u'\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a block scalar\", start_mark,\n\t\t\t\t\t\"expected a comment or a line break, but found %r\"\n\t\t\t\t\t\t% ch.encode('utf-8'), self.get_mark())\n\t\tself.scan_line_break()\n\n\tdef scan_block_scalar_indentation(self):\n\t\t# See the specification for details.\n\t\tchunks = []\n\t\tmax_indent = 0\n\t\tend_mark = self.get_mark()\n\t\twhile self.peek() in u' \\r\\n\\x85\\u2028\\u2029':\n\t\t\tif self.peek() != u' ':\n\t\t\t\tchunks.append(self.scan_line_break())\n\t\t\t\tend_mark = self.get_mark()\n\t\t\telse:\n\t\t\t\tself.forward()\n\t\t\t\tif self.column > max_indent:\n\t\t\t\t\tmax_indent = self.column\n\t\treturn chunks, max_indent, end_mark\n\n\tdef scan_block_scalar_breaks(self, indent):\n\t\t# See the specification for details.\n\t\tchunks = []\n\t\tend_mark = self.get_mark()\n\t\twhile self.column < indent and self.peek() == u' ':\n\t\t\tself.forward()\n\t\twhile self.peek() in u'\\r\\n\\x85\\u2028\\u2029':\n\t\t\tchunks.append(self.scan_line_break())\n\t\t\tend_mark = self.get_mark()\n\t\t\twhile self.column < indent and self.peek() == u' ':\n\t\t\t\tself.forward()\n\t\treturn chunks, end_mark\n\n\tdef scan_flow_scalar(self, style):\n\t\t# See the specification for details.\n\t\t# Note that we loose indentation rules for quoted scalars. Quoted\n\t\t# scalars don't need to adhere indentation because \" and ' clearly\n\t\t# mark the beginning and the end of them. Therefore we are less\n\t\t# restrictive then the specification requires. We only need to check\n\t\t# that document separators are not included in scalars.\n\t\tif style == '\"':\n\t\t\tdouble = True\n\t\telse:\n\t\t\tdouble = False\n\t\tchunks = []\n\t\tstart_mark = self.get_mark()\n\t\tquote = self.peek()\n\t\tself.forward()\n\t\tchunks.extend(self.scan_flow_scalar_non_spaces(double, start_mark))\n\t\twhile self.peek() != quote:\n\t\t\tchunks.extend(self.scan_flow_scalar_spaces(double, start_mark))\n\t\t\tchunks.extend(self.scan_flow_scalar_non_spaces(double, start_mark))\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\treturn ScalarToken(u''.join(chunks), False, start_mark, end_mark,\n\t\t\t\tstyle)\n\n\tESCAPE_REPLACEMENTS = {\n\t\tu'0':   u'\\0',\n\t\tu'a':   u'\\x07',\n\t\tu'b':   u'\\x08',\n\t\tu't':   u'\\x09',\n\t\tu'\\t':  u'\\x09',\n\t\tu'n':   u'\\x0A',\n\t\tu'v':   u'\\x0B',\n\t\tu'f':   u'\\x0C',\n\t\tu'r':   u'\\x0D',\n\t\tu'e':   u'\\x1B',\n\t\tu' ':   u'\\x20',\n\t\tu'\\\"':  u'\\\"',\n\t\tu'\\\\':  u'\\\\',\n\t\tu'N':   u'\\x85',\n\t\tu'_':   u'\\xA0',\n\t\tu'L':   u'\\u2028',\n\t\tu'P':   u'\\u2029',\n\t}\n\n\tESCAPE_CODES = {\n\t\tu'x':   2,\n\t\tu'u':   4,\n\t\tu'U':   8,\n\t}\n\n\tdef scan_flow_scalar_non_spaces(self, double, start_mark):\n\t\t# See the specification for details.\n\t\tchunks = []\n\t\twhile True:\n\t\t\tlength = 0\n\t\t\twhile self.peek(length) not in u'\\'\\\"\\\\\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tlength += 1\n\t\t\tif length:\n\t\t\t\tchunks.append(self.prefix(length))\n\t\t\t\tself.forward(length)\n\t\t\tch = self.peek()\n\t\t\tif not double and ch == u'\\'' and self.peek(1) == u'\\'':\n\t\t\t\tchunks.append(u'\\'')\n\t\t\t\tself.forward(2)\n\t\t\telif (double and ch == u'\\'') or (not double and ch in u'\\\"\\\\'):\n\t\t\t\tchunks.append(ch)\n\t\t\t\tself.forward()\n\t\t\telif double and ch == u'\\\\':\n\t\t\t\tself.forward()\n\t\t\t\tch = self.peek()\n\t\t\t\tif ch in self.ESCAPE_REPLACEMENTS:\n\t\t\t\t\tchunks.append(self.ESCAPE_REPLACEMENTS[ch])\n\t\t\t\t\tself.forward()\n\t\t\t\telif ch in self.ESCAPE_CODES:\n\t\t\t\t\tlength = self.ESCAPE_CODES[ch]\n\t\t\t\t\tself.forward()\n\t\t\t\t\tfor k in range(length):\n\t\t\t\t\t\tif self.peek(k) not in u'0123456789ABCDEFabcdef':\n\t\t\t\t\t\t\traise ScannerError(\"while scanning a double-quoted scalar\", start_mark,\n\t\t\t\t\t\t\t\t\t\"expected escape sequence of %d hexdecimal numbers, but found %r\" %\n\t\t\t\t\t\t\t\t\t\t(length, self.peek(k).encode('utf-8')), self.get_mark())\n\t\t\t\t\tcode = int(self.prefix(length), 16)\n\t\t\t\t\tchunks.append(unichr(code))\n\t\t\t\t\tself.forward(length)\n\t\t\t\telif ch in u'\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\t\tself.scan_line_break()\n\t\t\t\t\tchunks.extend(self.scan_flow_scalar_breaks(double, start_mark))\n\t\t\t\telse:\n\t\t\t\t\traise ScannerError(\"while scanning a double-quoted scalar\", start_mark,\n\t\t\t\t\t\t\t\"found unknown escape character %r\" % ch.encode('utf-8'), self.get_mark())\n\t\t\telse:\n\t\t\t\treturn chunks\n\n\tdef scan_flow_scalar_spaces(self, double, start_mark):\n\t\t# See the specification for details.\n\t\tchunks = []\n\t\tlength = 0\n\t\twhile self.peek(length) in u' \\t':\n\t\t\tlength += 1\n\t\twhitespaces = self.prefix(length)\n\t\tself.forward(length)\n\t\tch = self.peek()\n\t\tif ch == u'\\0':\n\t\t\traise ScannerError(\"while scanning a quoted scalar\", start_mark,\n\t\t\t\t\t\"found unexpected end of stream\", self.get_mark())\n\t\telif ch in u'\\r\\n\\x85\\u2028\\u2029':\n\t\t\tline_break = self.scan_line_break()\n\t\t\tbreaks = self.scan_flow_scalar_breaks(double, start_mark)\n\t\t\tif line_break != u'\\n':\n\t\t\t\tchunks.append(line_break)\n\t\t\telif not breaks:\n\t\t\t\tchunks.append(u' ')\n\t\t\tchunks.extend(breaks)\n\t\telse:\n\t\t\tchunks.append(whitespaces)\n\t\treturn chunks\n\n\tdef scan_flow_scalar_breaks(self, double, start_mark):\n\t\t# See the specification for details.\n\t\tchunks = []\n\t\twhile True:\n\t\t\t# Instead of checking indentation, we check for document\n\t\t\t# separators.\n\t\t\tprefix = self.prefix(3)\n\t\t\tif (prefix == u'---' or prefix == u'...')   \\\n\t\t\t\t\tand self.peek(3) in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\traise ScannerError(\"while scanning a quoted scalar\", start_mark,\n\t\t\t\t\t\t\"found unexpected document separator\", self.get_mark())\n\t\t\twhile self.peek() in u' \\t':\n\t\t\t\tself.forward()\n\t\t\tif self.peek() in u'\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tchunks.append(self.scan_line_break())\n\t\t\telse:\n\t\t\t\treturn chunks\n\n\tdef scan_plain(self):\n\t\t# See the specification for details.\n\t\t# We add an additional restriction for the flow context:\n\t\t#   plain scalars in the flow context cannot contain ',', ':' and '?'.\n\t\t# We also keep track of the `allow_simple_key` flag here.\n\t\t# Indentation rules are loosed for the flow context.\n\t\tchunks = []\n\t\tstart_mark = self.get_mark()\n\t\tend_mark = start_mark\n\t\tindent = self.indent+1\n\t\t# We allow zero indentation for scalars, but then we need to check for\n\t\t# document separators at the beginning of the line.\n\t\t#if indent == 0:\n\t\t#\tindent = 1\n\t\tspaces = []\n\t\twhile True:\n\t\t\tlength = 0\n\t\t\tif self.peek() == u'#':\n\t\t\t\tbreak\n\t\t\twhile True:\n\t\t\t\tch = self.peek(length)\n\t\t\t\tif ch in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029'   \\\n\t\t\t\t\t\tor (not self.flow_level and ch == u':' and\n\t\t\t\t\t\t\t\tself.peek(length+1) in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029') \\\n\t\t\t\t\t\tor (self.flow_level and ch in u',:?[]{}'):\n\t\t\t\t\tbreak\n\t\t\t\tlength += 1\n\t\t\t# It's not clear what we should do with ':' in the flow context.\n\t\t\tif (self.flow_level and ch == u':'\n\t\t\t\t\tand self.peek(length+1) not in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029,[]{}'):\n\t\t\t\tself.forward(length)\n\t\t\t\traise ScannerError(\"while scanning a plain scalar\", start_mark,\n\t\t\t\t\t\"found unexpected ':'\", self.get_mark(),\n\t\t\t\t\t\"Please check http://pyyaml.org/wiki/YAMLColonInFlowContext for details.\")\n\t\t\tif length == 0:\n\t\t\t\tbreak\n\t\t\tself.allow_simple_key = False\n\t\t\tchunks.extend(spaces)\n\t\t\tchunks.append(self.prefix(length))\n\t\t\tself.forward(length)\n\t\t\tend_mark = self.get_mark()\n\t\t\tspaces = self.scan_plain_spaces(indent, start_mark)\n\t\t\tif not spaces or self.peek() == u'#' \\\n\t\t\t\t\tor (not self.flow_level and self.column < indent):\n\t\t\t\tbreak\n\t\treturn ScalarToken(u''.join(chunks), True, start_mark, end_mark)\n\n\tdef scan_plain_spaces(self, indent, start_mark):\n\t\t# See the specification for details.\n\t\t# The specification is really confusing about tabs in plain scalars.\n\t\t# We just forbid them completely. Do not use tabs in YAML!\n\t\tchunks = []\n\t\tlength = 0\n\t\twhile self.peek(length) in u' ':\n\t\t\tlength += 1\n\t\twhitespaces = self.prefix(length)\n\t\tself.forward(length)\n\t\tch = self.peek()\n\t\tif ch in u'\\r\\n\\x85\\u2028\\u2029':\n\t\t\tline_break = self.scan_line_break()\n\t\t\tself.allow_simple_key = True\n\t\t\tprefix = self.prefix(3)\n\t\t\tif (prefix == u'---' or prefix == u'...')   \\\n\t\t\t\t\tand self.peek(3) in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\treturn\n\t\t\tbreaks = []\n\t\t\twhile self.peek() in u' \\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tif self.peek() == ' ':\n\t\t\t\t\tself.forward()\n\t\t\t\telse:\n\t\t\t\t\tbreaks.append(self.scan_line_break())\n\t\t\t\t\tprefix = self.prefix(3)\n\t\t\t\t\tif (prefix == u'---' or prefix == u'...')   \\\n\t\t\t\t\t\t\tand self.peek(3) in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\t\t\treturn\n\t\t\tif line_break != u'\\n':\n\t\t\t\tchunks.append(line_break)\n\t\t\telif not breaks:\n\t\t\t\tchunks.append(u' ')\n\t\t\tchunks.extend(breaks)\n\t\telif whitespaces:\n\t\t\tchunks.append(whitespaces)\n\t\treturn chunks\n\n\tdef scan_tag_handle(self, name, start_mark):\n\t\t# See the specification for details.\n\t\t# For some strange reasons, the specification does not allow '_' in\n\t\t# tag handles. I have allowed it anyway.\n\t\tch = self.peek()\n\t\tif ch != u'!':\n\t\t\traise ScannerError(\"while scanning a %s\" % name, start_mark,\n\t\t\t\t\t\"expected '!', but found %r\" % ch.encode('utf-8'),\n\t\t\t\t\tself.get_mark())\n\t\tlength = 1\n\t\tch = self.peek(length)\n\t\tif ch != u' ':\n\t\t\twhile u'0' <= ch <= u'9' or u'A' <= ch <= 'Z' or u'a' <= ch <= 'z'  \\\n\t\t\t\t\tor ch in u'-_':\n\t\t\t\tlength += 1\n\t\t\t\tch = self.peek(length)\n\t\t\tif ch != u'!':\n\t\t\t\tself.forward(length)\n\t\t\t\traise ScannerError(\"while scanning a %s\" % name, start_mark,\n\t\t\t\t\t\t\"expected '!', but found %r\" % ch.encode('utf-8'),\n\t\t\t\t\t\tself.get_mark())\n\t\t\tlength += 1\n\t\tvalue = self.prefix(length)\n\t\tself.forward(length)\n\t\treturn value\n\n\tdef scan_tag_uri(self, name, start_mark):\n\t\t# See the specification for details.\n\t\t# Note: we do not check if URI is well-formed.\n\t\tchunks = []\n\t\tlength = 0\n\t\tch = self.peek(length)\n\t\twhile u'0' <= ch <= u'9' or u'A' <= ch <= 'Z' or u'a' <= ch <= 'z'  \\\n\t\t\t\tor ch in u'-;/?:@&=+$,_.!~*\\'()[]%':\n\t\t\tif ch == u'%':\n\t\t\t\tchunks.append(self.prefix(length))\n\t\t\t\tself.forward(length)\n\t\t\t\tlength = 0\n\t\t\t\tchunks.append(self.scan_uri_escapes(name, start_mark))\n\t\t\telse:\n\t\t\t\tlength += 1\n\t\t\tch = self.peek(length)\n\t\tif length:\n\t\t\tchunks.append(self.prefix(length))\n\t\t\tself.forward(length)\n\t\t\tlength = 0\n\t\tif not chunks:\n\t\t\traise ScannerError(\"while parsing a %s\" % name, start_mark,\n\t\t\t\t\t\"expected URI, but found %r\" % ch.encode('utf-8'),\n\t\t\t\t\tself.get_mark())\n\t\treturn u''.join(chunks)\n\n\tdef scan_uri_escapes(self, name, start_mark):\n\t\t# See the specification for details.\n\t\tbytes = []\n\t\tmark = self.get_mark()\n\t\twhile self.peek() == u'%':\n\t\t\tself.forward()\n\t\t\tfor k in range(2):\n\t\t\t\tif self.peek(k) not in u'0123456789ABCDEFabcdef':\n\t\t\t\t\traise ScannerError(\"while scanning a %s\" % name, start_mark,\n\t\t\t\t\t\t\t\"expected URI escape sequence of 2 hexdecimal numbers, but found %r\" %\n\t\t\t\t\t\t\t\t(self.peek(k).encode('utf-8')), self.get_mark())\n\t\t\tbytes.append(chr(int(self.prefix(2), 16)))\n\t\t\tself.forward(2)\n\t\ttry:\n\t\t\tvalue = unicode(''.join(bytes), 'utf-8')\n\t\texcept UnicodeDecodeError, exc:\n\t\t\traise ScannerError(\"while scanning a %s\" % name, start_mark, str(exc), mark)\n\t\treturn value\n\n\tdef scan_line_break(self):\n\t\t# Transforms:\n\t\t#   '\\r\\n'\t  :   '\\n'\n\t\t#   '\\r'\t\t:   '\\n'\n\t\t#   '\\n'\t\t:   '\\n'\n\t\t#   '\\x85'\t  :   '\\n'\n\t\t#   '\\u2028'\t:   '\\u2028'\n\t\t#   '\\u2029\t :   '\\u2029'\n\t\t#   default\t :   ''\n\t\tch = self.peek()\n\t\tif ch in u'\\r\\n\\x85':\n\t\t\tif self.prefix(2) == u'\\r\\n':\n\t\t\t\tself.forward(2)\n\t\t\telse:\n\t\t\t\tself.forward()\n\t\t\treturn u'\\n'\n\t\telif ch in u'\\u2028\\u2029':\n\t\t\tself.forward()\n\t\t\treturn ch\n\t\treturn u''\n", "description": "Initialize the scanner.", "category": "simple", "imports": ["from error import MarkedYAMLError", "from tokens import *", "#\timport psyco"]}], [{"term": "def", "name": "trim", "data": "def trim(value, num):\n\treturn value[:num]\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "make_data_div", "data": "def make_data_div(value):\n\t\"\"\"A filter that uses a decorator (@mark_safe).\"\"\"\n\treturn '' % value\n\n", "description": "A filter that uses a decorator (@mark_safe).", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "noop", "data": "def noop(value, param=None):\n\t\"\"\"A noop filter that always return its first argument and does nothing with\n\tits second (optional) one.\n\tUseful for testing out whitespace in filter arguments (see #19882).\"\"\"\n\treturn value\n\n", "description": "A noop filter that always return its first argument and does nothing with\n\tits second (optional) one.\n\tUseful for testing out whitespace in filter arguments (see #19882).", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "context_stack_length", "data": "def context_stack_length(context):\n\treturn len(context.dicts)\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "no_params", "data": "def no_params():\n\t\"\"\"Expected no_params __doc__\"\"\"\n\treturn \"no_params - Expected result\"\n\n", "description": "Expected no_params __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "one_param", "data": "def one_param(arg):\n\t\"\"\"Expected one_param __doc__\"\"\"\n\treturn \"one_param - Expected result: %s\" % arg\n\n", "description": "Expected one_param __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "explicit_no_context", "data": "def explicit_no_context(arg):\n\t\"\"\"Expected explicit_no_context __doc__\"\"\"\n\treturn \"explicit_no_context - Expected result: %s\" % arg\n\n", "description": "Expected explicit_no_context __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "no_params_with_context", "data": "def no_params_with_context(context):\n\t\"\"\"Expected no_params_with_context __doc__\"\"\"\n\treturn \"no_params_with_context - Expected result (context value: %s)\" % context['value']\n\n", "description": "Expected no_params_with_context __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "params_and_context", "data": "def params_and_context(context, arg):\n\t\"\"\"Expected params_and_context __doc__\"\"\"\n\treturn \"params_and_context - Expected result (context value: %s): %s\" % (context['value'], arg)\n\n", "description": "Expected params_and_context __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_two_params", "data": "def simple_two_params(one, two):\n\t\"\"\"Expected simple_two_params __doc__\"\"\"\n\treturn \"simple_two_params - Expected result: %s, %s\" % (one, two)\n\n", "description": "Expected simple_two_params __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_keyword_only_param", "data": "def simple_keyword_only_param(*, kwarg):\n\treturn \"simple_keyword_only_param - Expected result: %s\" % kwarg\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_keyword_only_default", "data": "def simple_keyword_only_default(*, kwarg=42):\n\treturn \"simple_keyword_only_default - Expected result: %s\" % kwarg\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_one_default", "data": "def simple_one_default(one, two='hi'):\n\t\"\"\"Expected simple_one_default __doc__\"\"\"\n\treturn \"simple_one_default - Expected result: %s, %s\" % (one, two)\n\n", "description": "Expected simple_one_default __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_unlimited_args", "data": "def simple_unlimited_args(one, two='hi', *args):\n\t\"\"\"Expected simple_unlimited_args __doc__\"\"\"\n\treturn \"simple_unlimited_args - Expected result: %s\" % (\n\t\t', '.join(str(arg) for arg in [one, two, *args])\n\t)\n\n", "description": "Expected simple_unlimited_args __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_only_unlimited_args", "data": "def simple_only_unlimited_args(*args):\n\t\"\"\"Expected simple_only_unlimited_args __doc__\"\"\"\n\treturn \"simple_only_unlimited_args - Expected result: %s\" % ', '.join(str(arg) for arg in args)\n\n", "description": "Expected simple_only_unlimited_args __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_unlimited_args_kwargs", "data": "def simple_unlimited_args_kwargs(one, two='hi', *args, **kwargs):\n\t\"\"\"Expected simple_unlimited_args_kwargs __doc__\"\"\"\n\t# Sort the dictionary by key to guarantee the order for testing.\n\tsorted_kwarg = sorted(kwargs.items(), key=operator.itemgetter(0))\n\treturn \"simple_unlimited_args_kwargs - Expected result: %s / %s\" % (\n\t\t', '.join(str(arg) for arg in [one, two, *args]),\n\t\t', '.join('%s=%s' % (k, v) for (k, v) in sorted_kwarg)\n\t)\n\n", "description": "Expected simple_unlimited_args_kwargs __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_tag_without_context_parameter", "data": "def simple_tag_without_context_parameter(arg):\n\t\"\"\"Expected simple_tag_without_context_parameter __doc__\"\"\"\n\treturn \"Expected result\"\n\n", "description": "Expected simple_tag_without_context_parameter __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "escape_naive", "data": "def escape_naive(context):\n\t\"\"\"A tag that doesn't even think about escaping issues\"\"\"\n\treturn \"Hello {0}!\".format(context['name'])\n\n", "description": "A tag that doesn't even think about escaping issues", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "escape_explicit", "data": "def escape_explicit(context):\n\t\"\"\"A tag that uses escape explicitly\"\"\"\n\treturn escape(\"Hello {0}!\".format(context['name']))\n\n", "description": "A tag that uses escape explicitly", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "escape_format_html", "data": "def escape_format_html(context):\n\t\"\"\"A tag that uses format_html\"\"\"\n\treturn format_html(\"Hello {0}!\", context['name'])\n\n", "description": "A tag that uses format_html", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "current_app", "data": "def current_app(context):\n\treturn \"%s\" % context.current_app\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "use_l10n", "data": "def use_l10n(context):\n\treturn \"%s\" % context.use_l10n\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "minustwo_overridden_name", "data": "def minustwo_overridden_name(value):\n\treturn value - 2\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "counter", "data": "def counter(parser, token):\n\treturn CounterNode()\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "class", "name": "CounterNode", "data": "class CounterNode(template.Node):\n\tdef __init__(self):\n\t\tself.count = 0\n\n\tdef render(self, context):\n\t\tcount = self.count\n\t\tself.count = count + 1\n\t\treturn count\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}], [{"term": "class", "name": "MockBaseClusterResolver", "data": "class MockBaseClusterResolver(ClusterResolver):\n", "description": null, "category": "simple", "imports": ["from __future__ import absolute_import", "from __future__ import division", "from __future__ import print_function", "from tensorflow.python import framework", "from tensorflow.python.client import session", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import ClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import SimpleClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import UnionClusterResolver", "from tensorflow.python.eager.context import LogicalDevice", "from tensorflow.python.framework import test_util", "from tensorflow.python.platform import test", "from tensorflow.python.training import server_lib"]}, {"term": "def", "name": "cluster_spec", "data": "  def cluster_spec(self):\n\treturn None\n", "description": null, "category": "simple", "imports": ["from __future__ import absolute_import", "from __future__ import division", "from __future__ import print_function", "from tensorflow.python import framework", "from tensorflow.python.client import session", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import ClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import SimpleClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import UnionClusterResolver", "from tensorflow.python.eager.context import LogicalDevice", "from tensorflow.python.framework import test_util", "from tensorflow.python.platform import test", "from tensorflow.python.training import server_lib"]}, {"term": "def", "name": "master", "data": "  def master(self, task_type=None, task_id=None, rpc_layer=None):\n\treturn \"\"\n", "description": null, "category": "simple", "imports": ["from __future__ import absolute_import", "from __future__ import division", "from __future__ import print_function", "from tensorflow.python import framework", "from tensorflow.python.client import session", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import ClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import SimpleClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import UnionClusterResolver", "from tensorflow.python.eager.context import LogicalDevice", "from tensorflow.python.framework import test_util", "from tensorflow.python.platform import test", "from tensorflow.python.training import server_lib"]}, {"term": "def", "name": "environment", "data": "  def environment(self):\n\treturn \"\"\n\n", "description": null, "category": "simple", "imports": ["from __future__ import absolute_import", "from __future__ import division", "from __future__ import print_function", "from tensorflow.python import framework", "from tensorflow.python.client import session", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import ClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import SimpleClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import UnionClusterResolver", "from tensorflow.python.eager.context import LogicalDevice", "from tensorflow.python.framework import test_util", "from tensorflow.python.platform import test", "from tensorflow.python.training import server_lib"]}, {"term": "class", "name": "BaseClusterResolverTest", "data": "class BaseClusterResolverTest(test.TestCase):\n", "description": null, "category": "simple", "imports": ["from __future__ import absolute_import", "from __future__ import division", "from __future__ import print_function", "from tensorflow.python import framework", "from tensorflow.python.client import session", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import ClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import SimpleClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import UnionClusterResolver", "from tensorflow.python.eager.context import LogicalDevice", "from tensorflow.python.framework import test_util", "from tensorflow.python.platform import test", "from tensorflow.python.training import server_lib"]}, {"term": "def", "name": "testNumAcceleratorsSuccess", "data": "  def testNumAcceleratorsSuccess(self, mock_list_devices,\n\t\t\t\t\t\t\t\t mock_eager_list_devices):\n\tdevices = [\n\t\tLogicalDevice(\"/job:worker/task:0/device:GPU:0\", \"GPU\"),\n\t\tLogicalDevice(\"/job:worker/task:0/device:GPU:1\", \"GPU\"),\n\t\tLogicalDevice(\"/job:worker/task:0/device:GPU:2\", \"GPU\"),\n\t\tLogicalDevice(\"/job:worker/task:0/device:GPU:3\", \"GPU\"),\n\t]\n\tdevice_list = [\n\t\tsession._DeviceAttributes(d.name, d.device_type, 1024, 0)\n\t\tfor d in devices\n\t]\n\tmock_eager_list_devices.return_value = devices\n\tmock_list_devices.return_value = device_list\n\n\tresolver = MockBaseClusterResolver()\n\tself.assertEqual(resolver.num_accelerators(), {\"GPU\": 4})\n", "description": null, "category": "simple", "imports": ["from __future__ import absolute_import", "from __future__ import division", "from __future__ import print_function", "from tensorflow.python import framework", "from tensorflow.python.client import session", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import ClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import SimpleClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import UnionClusterResolver", "from tensorflow.python.eager.context import LogicalDevice", "from tensorflow.python.framework import test_util", "from tensorflow.python.platform import test", "from tensorflow.python.training import server_lib"]}, {"term": "def", "name": "testNumAcceleratorsMultiDeviceSuccess", "data": "  def testNumAcceleratorsMultiDeviceSuccess(self, mock_list_devices,\n\t\t\t\t\t\t\t\t\t\t\tmock_eager_list_devices):\n\tdevices = [\n\t\tLogicalDevice(\"/job:worker/task:0/device:TPU:0\", \"TPU\"),\n\t\tLogicalDevice(\"/job:worker/task:0/device:TPU:1\", \"TPU\"),\n\t\tLogicalDevice(\"/job:worker/task:0/device:TPU:2\", \"TPU\"),\n\t\tLogicalDevice(\"/job:worker/task:0/device:TPU:3\", \"TPU\"),\n\t\tLogicalDevice(\"/job:worker/task:0/device:GPU:0\", \"GPU\"),\n\t\tLogicalDevice(\"/job:worker/task:0/device:GPU:1\", \"GPU\"),\n\t\tLogicalDevice(\"/job:worker/task:0/device:GPU:2\", \"GPU\"),\n\t\tLogicalDevice(\"/job:worker/task:0/device:GPU:3\", \"GPU\"),\n\t]\n\tdevice_list = [\n\t\tsession._DeviceAttributes(d.name, d.device_type, 1024, 0)\n\t\tfor d in devices\n\t]\n\tmock_eager_list_devices.return_value = devices\n\tmock_list_devices.return_value = device_list\n\n\tresolver = MockBaseClusterResolver()\n\tself.assertEqual(resolver.num_accelerators(), {\"TPU\": 4, \"GPU\": 4})\n", "description": null, "category": "simple", "imports": ["from __future__ import absolute_import", "from __future__ import division", "from __future__ import print_function", "from tensorflow.python import framework", "from tensorflow.python.client import session", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import ClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import SimpleClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import UnionClusterResolver", "from tensorflow.python.eager.context import LogicalDevice", "from tensorflow.python.framework import test_util", "from tensorflow.python.platform import test", "from tensorflow.python.training import server_lib"]}, {"term": "def", "name": "testNumAcceleratorsFilterTasks", "data": "  def testNumAcceleratorsFilterTasks(self, mock_list_devices,\n\t\t\t\t\t\t\t\t\t mock_eager_list_devices):\n\tdevices = [\n\t\tLogicalDevice(\"/job:worker1/task:0/device:TPU:0\", \"TPU\"),\n\t\tLogicalDevice(\"/job:worker1/task:0/device:TPU:1\", \"TPU\"),\n\t\tLogicalDevice(\"/job:worker1/task:0/device:GPU:0\", \"GPU\"),\n\t\tLogicalDevice(\"/job:worker1/task:0/device:GPU:1\", \"GPU\"),\n\t\tLogicalDevice(\"/job:worker2/task:1/device:TPU:2\", \"TPU\"),\n\t\tLogicalDevice(\"/job:worker2/task:2/device:TPU:3\", \"TPU\"),\n\t\tLogicalDevice(\"/job:worker2/task:3/device:GPU:2\", \"GPU\"),\n\t\tLogicalDevice(\"/job:worker2/task:4/device:GPU:3\", \"GPU\"),\n\t]\n\tdevice_list = [\n\t\tsession._DeviceAttributes(d.name, d.device_type, 1024, 0)\n\t\tfor d in devices\n\t]\n\tmock_eager_list_devices.return_value = devices\n\tmock_list_devices.return_value = device_list\n\n\tresolver = MockBaseClusterResolver()\n\tself.assertEqual(resolver.num_accelerators(task_type=\"worker1\", task_id=0),\n\t\t\t\t\t {\"TPU\": 2, \"GPU\": 2})\n\tself.assertEqual(resolver.num_accelerators(task_type=\"worker2\", task_id=3),\n\t\t\t\t\t {\"GPU\": 1})\n\tself.assertEqual(resolver.num_accelerators(task_type=\"worker2\", task_id=4),\n\t\t\t\t\t {\"GPU\": 1})\n\n", "description": null, "category": "simple", "imports": ["from __future__ import absolute_import", "from __future__ import division", "from __future__ import print_function", "from tensorflow.python import framework", "from tensorflow.python.client import session", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import ClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import SimpleClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import UnionClusterResolver", "from tensorflow.python.eager.context import LogicalDevice", "from tensorflow.python.framework import test_util", "from tensorflow.python.platform import test", "from tensorflow.python.training import server_lib"]}, {"term": "def", "name": "_verifyClusterSpecEquality", "data": "  def _verifyClusterSpecEquality(self, cluster_spec, expected_proto):\n\tself.assertProtoEquals(expected_proto, cluster_spec.as_cluster_def())\n\tself.assertProtoEquals(\n\t\texpected_proto, server_lib.ClusterSpec(cluster_spec).as_cluster_def())\n\tself.assertProtoEquals(\n\t\texpected_proto,\n\t\tserver_lib.ClusterSpec(cluster_spec.as_cluster_def()).as_cluster_def())\n\tself.assertProtoEquals(\n\t\texpected_proto,\n\t\tserver_lib.ClusterSpec(cluster_spec.as_dict()).as_cluster_def())\n", "description": null, "category": "simple", "imports": ["from __future__ import absolute_import", "from __future__ import division", "from __future__ import print_function", "from tensorflow.python import framework", "from tensorflow.python.client import session", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import ClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import SimpleClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import UnionClusterResolver", "from tensorflow.python.eager.context import LogicalDevice", "from tensorflow.python.framework import test_util", "from tensorflow.python.platform import test", "from tensorflow.python.training import server_lib"]}, {"term": "def", "name": "testSingleClusterResolver", "data": "  def testSingleClusterResolver(self):\n\tbase_cluster_spec = server_lib.ClusterSpec({\n\t\t\"ps\": [\"ps0:2222\", \"ps1:2222\"],\n\t\t\"worker\": [\"worker0:2222\", \"worker1:2222\", \"worker2:2222\"]\n\t})\n\tsimple_resolver = SimpleClusterResolver(base_cluster_spec)\n\tunion_resolver = UnionClusterResolver(simple_resolver)\n\n\texpected_proto = \"\"\"\n\tjob { name: 'ps' tasks { key: 0 value: 'ps0:2222' }\n\t\t\t\t\t tasks { key: 1 value: 'ps1:2222' } }\n\tjob { name: 'worker' tasks { key: 0 value: 'worker0:2222' }\n\t\t\t\t\t\t tasks { key: 1 value: 'worker1:2222' }\n\t\t\t\t\t\t tasks { key: 2 value: 'worker2:2222' } }\n\t\"\"\"\n\tactual_cluster_spec = union_resolver.cluster_spec()\n\tself._verifyClusterSpecEquality(actual_cluster_spec, expected_proto)\n", "description": "\n\tjob { name: 'ps' tasks { key: 0 value: 'ps0:2222' }\n\t\t\t\t\t tasks { key: 1 value: 'ps1:2222' } }\n\tjob { name: 'worker' tasks { key: 0 value: 'worker0:2222' }\n\t\t\t\t\t\t tasks { key: 1 value: 'worker1:2222' }\n\t\t\t\t\t\t tasks { key: 2 value: 'worker2:2222' } }\n\t", "category": "simple", "imports": ["from __future__ import absolute_import", "from __future__ import division", "from __future__ import print_function", "from tensorflow.python import framework", "from tensorflow.python.client import session", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import ClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import SimpleClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import UnionClusterResolver", "from tensorflow.python.eager.context import LogicalDevice", "from tensorflow.python.framework import test_util", "from tensorflow.python.platform import test", "from tensorflow.python.training import server_lib"]}, {"term": "def", "name": "testInitSimpleClusterResolver", "data": "  def testInitSimpleClusterResolver(self):\n\tbase_cluster_spec = server_lib.ClusterSpec({\n\t\t\"ps\": [\"ps0:2222\", \"ps1:2222\"],\n\t\t\"worker\": [\"worker0:2222\", \"worker1:2222\", \"worker2:2222\"]\n\t})\n\n\tsimple_resolver = SimpleClusterResolver(base_cluster_spec, task_type=\"ps\",\n\t\t\t\t\t\t\t\t\t\t\ttask_id=1, environment=\"cloud\",\n\t\t\t\t\t\t\t\t\t\t\tnum_accelerators={\"GPU\": 8},\n\t\t\t\t\t\t\t\t\t\t\trpc_layer=\"grpc\")\n\n\tself.assertEqual(simple_resolver.task_type, \"ps\")\n\tself.assertEqual(simple_resolver.task_id, 1)\n\tself.assertEqual(simple_resolver.environment, \"cloud\")\n\tself.assertEqual(simple_resolver.num_accelerators(), {\"GPU\": 8})\n\tself.assertEqual(simple_resolver.rpc_layer, \"grpc\")\n", "description": null, "category": "simple", "imports": ["from __future__ import absolute_import", "from __future__ import division", "from __future__ import print_function", "from tensorflow.python import framework", "from tensorflow.python.client import session", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import ClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import SimpleClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import UnionClusterResolver", "from tensorflow.python.eager.context import LogicalDevice", "from tensorflow.python.framework import test_util", "from tensorflow.python.platform import test", "from tensorflow.python.training import server_lib"]}, {"term": "def", "name": "testOverrideSimpleClusterResolver", "data": "  def testOverrideSimpleClusterResolver(self):\n\tbase_cluster_spec = server_lib.ClusterSpec({\n\t\t\"ps\": [\"ps0:2222\", \"ps1:2222\"],\n\t\t\"worker\": [\"worker0:2222\", \"worker1:2222\", \"worker2:2222\"]\n\t})\n\n\tsimple_resolver = SimpleClusterResolver(base_cluster_spec, task_type=\"ps\",\n\t\t\t\t\t\t\t\t\t\t\ttask_id=1, environment=\"cloud\",\n\t\t\t\t\t\t\t\t\t\t\tnum_accelerators={\"GPU\": 8},\n\t\t\t\t\t\t\t\t\t\t\trpc_layer=\"grpc\")\n\n\tsimple_resolver.task_type = \"worker\"\n\tsimple_resolver.task_id = 2\n\tsimple_resolver.rpc_layer = \"http\"\n\n\tself.assertEqual(simple_resolver.task_type, \"worker\")\n\tself.assertEqual(simple_resolver.task_id, 2)\n\tself.assertEqual(simple_resolver.rpc_layer, \"http\")\n", "description": null, "category": "simple", "imports": ["from __future__ import absolute_import", "from __future__ import division", "from __future__ import print_function", "from tensorflow.python import framework", "from tensorflow.python.client import session", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import ClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import SimpleClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import UnionClusterResolver", "from tensorflow.python.eager.context import LogicalDevice", "from tensorflow.python.framework import test_util", "from tensorflow.python.platform import test", "from tensorflow.python.training import server_lib"]}, {"term": "def", "name": "testSimpleOverrideMasterWithTaskIndexZero", "data": "  def testSimpleOverrideMasterWithTaskIndexZero(self):\n\tbase_cluster_spec = server_lib.ClusterSpec({\n\t\t\"ps\": [\"ps0:2222\", \"ps1:2222\"],\n\t\t\"worker\": [\"worker0:2222\", \"worker1:2222\", \"worker2:2222\"]\n\t})\n\n\tsimple_resolver = SimpleClusterResolver(base_cluster_spec)\n\tactual_master = simple_resolver.master(\"worker\", 0, rpc_layer=\"grpc\")\n\tself.assertEqual(actual_master, \"grpc://worker0:2222\")\n", "description": null, "category": "simple", "imports": ["from __future__ import absolute_import", "from __future__ import division", "from __future__ import print_function", "from tensorflow.python import framework", "from tensorflow.python.client import session", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import ClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import SimpleClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import UnionClusterResolver", "from tensorflow.python.eager.context import LogicalDevice", "from tensorflow.python.framework import test_util", "from tensorflow.python.platform import test", "from tensorflow.python.training import server_lib"]}, {"term": "def", "name": "testSimpleOverrideMasterWithRpcLayer", "data": "  def testSimpleOverrideMasterWithRpcLayer(self):\n\tbase_cluster_spec = server_lib.ClusterSpec({\n\t\t\"ps\": [\"ps0:2222\", \"ps1:2222\"],\n\t\t\"worker\": [\"worker0:2222\", \"worker1:2222\", \"worker2:2222\"]\n\t})\n\n\tsimple_resolver = SimpleClusterResolver(base_cluster_spec)\n\tactual_master = simple_resolver.master(\"worker\", 2, rpc_layer=\"grpc\")\n\tself.assertEqual(actual_master, \"grpc://worker2:2222\")\n", "description": null, "category": "simple", "imports": ["from __future__ import absolute_import", "from __future__ import division", "from __future__ import print_function", "from tensorflow.python import framework", "from tensorflow.python.client import session", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import ClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import SimpleClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import UnionClusterResolver", "from tensorflow.python.eager.context import LogicalDevice", "from tensorflow.python.framework import test_util", "from tensorflow.python.platform import test", "from tensorflow.python.training import server_lib"]}, {"term": "def", "name": "testSimpleOverrideMaster", "data": "  def testSimpleOverrideMaster(self):\n\tbase_cluster_spec = server_lib.ClusterSpec({\n\t\t\"ps\": [\"ps0:2222\", \"ps1:2222\"],\n\t\t\"worker\": [\"worker0:2222\", \"worker1:2222\", \"worker2:2222\"]\n\t})\n\n\tsimple_resolver = SimpleClusterResolver(base_cluster_spec)\n\tactual_master = simple_resolver.master(\"worker\", 2)\n\tself.assertEqual(actual_master, \"worker2:2222\")\n", "description": null, "category": "simple", "imports": ["from __future__ import absolute_import", "from __future__ import division", "from __future__ import print_function", "from tensorflow.python import framework", "from tensorflow.python.client import session", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import ClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import SimpleClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import UnionClusterResolver", "from tensorflow.python.eager.context import LogicalDevice", "from tensorflow.python.framework import test_util", "from tensorflow.python.platform import test", "from tensorflow.python.training import server_lib"]}, {"term": "def", "name": "testUnionClusterResolverGetProperties", "data": "  def testUnionClusterResolverGetProperties(self):\n\tcluster_spec_1 = server_lib.ClusterSpec({\n\t\t\"ps\": [\"ps0:2222\", \"ps1:2222\"],\n\t\t\"worker\": [\"worker0:2222\", \"worker1:2222\", \"worker2:2222\"]\n\t})\n\tresolver1 = SimpleClusterResolver(cluster_spec_1, task_type=\"ps\",\n\t\t\t\t\t\t\t\t\t  task_id=1, environment=\"cloud\",\n\t\t\t\t\t\t\t\t\t  num_accelerators={\"GPU\": 8},\n\t\t\t\t\t\t\t\t\t  rpc_layer=\"grpc\")\n\n\tcluster_spec_2 = server_lib.ClusterSpec({\n\t\t\"ps\": [\"ps2:2222\", \"ps3:2222\"],\n\t\t\"worker\": [\"worker3:2222\", \"worker4:2222\", \"worker5:2222\"]\n\t})\n\tresolver2 = SimpleClusterResolver(cluster_spec_2, task_type=\"worker\",\n\t\t\t\t\t\t\t\t\t  task_id=2, environment=\"local\",\n\t\t\t\t\t\t\t\t\t  num_accelerators={\"GPU\": 16},\n\t\t\t\t\t\t\t\t\t  rpc_layer=\"http\")\n\n\tunion_resolver = UnionClusterResolver(resolver1, resolver2)\n\n\tself.assertEqual(union_resolver.task_type, \"ps\")\n\tself.assertEqual(union_resolver.task_id, 1)\n\tself.assertEqual(union_resolver.environment, \"cloud\")\n\tself.assertEqual(union_resolver.num_accelerators(), {\"GPU\": 8})\n\tself.assertEqual(union_resolver.rpc_layer, \"grpc\")\n\n\tunion_resolver.task_type = \"worker\"\n\tunion_resolver.task_id = 2\n\tunion_resolver.rpc_layer = \"http\"\n\n\tself.assertEqual(union_resolver.task_type, \"worker\")\n\tself.assertEqual(union_resolver.task_id, 2)\n\tself.assertEqual(union_resolver.rpc_layer, \"http\")\n", "description": null, "category": "simple", "imports": ["from __future__ import absolute_import", "from __future__ import division", "from __future__ import print_function", "from tensorflow.python import framework", "from tensorflow.python.client import session", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import ClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import SimpleClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import UnionClusterResolver", "from tensorflow.python.eager.context import LogicalDevice", "from tensorflow.python.framework import test_util", "from tensorflow.python.platform import test", "from tensorflow.python.training import server_lib"]}, {"term": "def", "name": "testTwoNonOverlappingJobMergedClusterResolver", "data": "  def testTwoNonOverlappingJobMergedClusterResolver(self):\n\tcluster_spec_1 = server_lib.ClusterSpec({\n\t\t\"ps\": [\n\t\t\t\"ps0:2222\",\n\t\t\t\"ps1:2222\"\n\t\t]\n\t})\n\tcluster_spec_2 = server_lib.ClusterSpec({\n\t\t\"worker\": [\n\t\t\t\"worker0:2222\",\n\t\t\t\"worker1:2222\",\n\t\t\t\"worker2:2222\"\n\t\t]\n\t})\n\tcluster_resolver_1 = SimpleClusterResolver(cluster_spec_1)\n\tcluster_resolver_2 = SimpleClusterResolver(cluster_spec_2)\n\n\tunion_cluster = UnionClusterResolver(cluster_resolver_1, cluster_resolver_2)\n\tcluster_spec = union_cluster.cluster_spec()\n\n\texpected_proto = \"\"\"\n\tjob { name: 'ps' tasks { key: 0 value: 'ps0:2222' }\n\t\t\t\t\t tasks { key: 1 value: 'ps1:2222' } }\n\tjob { name: 'worker' tasks { key: 0 value: 'worker0:2222' }\n\t\t\t\t\t\t tasks { key: 1 value: 'worker1:2222' }\n\t\t\t\t\t\t tasks { key: 2 value: 'worker2:2222' } }\n\t\"\"\"\n\tself._verifyClusterSpecEquality(cluster_spec, expected_proto)\n", "description": "\n\tjob { name: 'ps' tasks { key: 0 value: 'ps0:2222' }\n\t\t\t\t\t tasks { key: 1 value: 'ps1:2222' } }\n\tjob { name: 'worker' tasks { key: 0 value: 'worker0:2222' }\n\t\t\t\t\t\t tasks { key: 1 value: 'worker1:2222' }\n\t\t\t\t\t\t tasks { key: 2 value: 'worker2:2222' } }\n\t", "category": "simple", "imports": ["from __future__ import absolute_import", "from __future__ import division", "from __future__ import print_function", "from tensorflow.python import framework", "from tensorflow.python.client import session", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import ClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import SimpleClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import UnionClusterResolver", "from tensorflow.python.eager.context import LogicalDevice", "from tensorflow.python.framework import test_util", "from tensorflow.python.platform import test", "from tensorflow.python.training import server_lib"]}, {"term": "def", "name": "testMergedClusterResolverMaster", "data": "  def testMergedClusterResolverMaster(self):\n\tcluster_spec_1 = server_lib.ClusterSpec({\n\t\t\"ps\": [\n\t\t\t\"ps0:2222\",\n\t\t\t\"ps1:2222\"\n\t\t]\n\t})\n\tcluster_spec_2 = server_lib.ClusterSpec({\n\t\t\"worker\": [\n\t\t\t\"worker0:2222\",\n\t\t\t\"worker1:2222\",\n\t\t\t\"worker2:2222\"\n\t\t]\n\t})\n\tcluster_resolver_1 = SimpleClusterResolver(cluster_spec_1)\n\tcluster_resolver_2 = SimpleClusterResolver(cluster_spec_2)\n\n\tunion_cluster = UnionClusterResolver(cluster_resolver_1, cluster_resolver_2)\n\n\tunspecified_master = union_cluster.master()\n\tself.assertEqual(unspecified_master, \"\")\n\n\tspecified_master = union_cluster.master(\"worker\", 1)\n\tself.assertEqual(specified_master, \"worker1:2222\")\n\n\trpc_master = union_cluster.master(\"worker\", 1, rpc_layer=\"grpc\")\n\tself.assertEqual(rpc_master, \"grpc://worker1:2222\")\n", "description": null, "category": "simple", "imports": ["from __future__ import absolute_import", "from __future__ import division", "from __future__ import print_function", "from tensorflow.python import framework", "from tensorflow.python.client import session", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import ClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import SimpleClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import UnionClusterResolver", "from tensorflow.python.eager.context import LogicalDevice", "from tensorflow.python.framework import test_util", "from tensorflow.python.platform import test", "from tensorflow.python.training import server_lib"]}, {"term": "def", "name": "testOverlappingJobMergedClusterResolver", "data": "  def testOverlappingJobMergedClusterResolver(self):\n\tcluster_spec_1 = server_lib.ClusterSpec({\n\t\t\"worker\": [\n\t\t\t\"worker4:2222\",\n\t\t\t\"worker5:2222\"\n\t\t]\n\t})\n\tcluster_spec_2 = server_lib.ClusterSpec({\n\t\t\"worker\": [\n\t\t\t\"worker0:2222\",\n\t\t\t\"worker1:2222\",\n\t\t\t\"worker2:2222\"\n\t\t]\n\t})\n\tcluster_resolver_1 = SimpleClusterResolver(cluster_spec_1)\n\tcluster_resolver_2 = SimpleClusterResolver(cluster_spec_2)\n\n\tunion_cluster = UnionClusterResolver(cluster_resolver_1, cluster_resolver_2)\n\tcluster_spec = union_cluster.cluster_spec()\n\n\texpected_proto = \"\"\"\n\tjob { name: 'worker' tasks { key: 0 value: 'worker4:2222' }\n\t\t\t\t\t\t tasks { key: 1 value: 'worker5:2222' }\n\t\t\t\t\t\t tasks { key: 2 value: 'worker0:2222' }\n\t\t\t\t\t\t tasks { key: 3 value: 'worker1:2222' }\n\t\t\t\t\t\t tasks { key: 4 value: 'worker2:2222' } }\n\t\"\"\"\n\tself._verifyClusterSpecEquality(cluster_spec, expected_proto)\n", "description": "\n\tjob { name: 'worker' tasks { key: 0 value: 'worker4:2222' }\n\t\t\t\t\t\t tasks { key: 1 value: 'worker5:2222' }\n\t\t\t\t\t\t tasks { key: 2 value: 'worker0:2222' }\n\t\t\t\t\t\t tasks { key: 3 value: 'worker1:2222' }\n\t\t\t\t\t\t tasks { key: 4 value: 'worker2:2222' } }\n\t", "category": "simple", "imports": ["from __future__ import absolute_import", "from __future__ import division", "from __future__ import print_function", "from tensorflow.python import framework", "from tensorflow.python.client import session", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import ClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import SimpleClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import UnionClusterResolver", "from tensorflow.python.eager.context import LogicalDevice", "from tensorflow.python.framework import test_util", "from tensorflow.python.platform import test", "from tensorflow.python.training import server_lib"]}, {"term": "def", "name": "testOverlappingSparseJobMergedClusterResolverThrowError", "data": "  def testOverlappingSparseJobMergedClusterResolverThrowError(self):\n\tcluster_spec_1 = server_lib.ClusterSpec({\n\t\t\"worker\": {\n\t\t\t7: \"worker4:2222\",\n\t\t\t9: \"worker5:2222\"\n\t\t}\n\t})\n\tcluster_spec_2 = server_lib.ClusterSpec({\n\t\t\"worker\": {\n\t\t\t3: \"worker0:2222\",\n\t\t\t6: \"worker1:2222\",\n\t\t\t7: \"worker2:2222\"\n\t\t}\n\t})\n\tcluster_resolver_1 = SimpleClusterResolver(cluster_spec_1)\n\tcluster_resolver_2 = SimpleClusterResolver(cluster_spec_2)\n\n\tunion_cluster = UnionClusterResolver(cluster_resolver_1, cluster_resolver_2)\n\tself.assertRaises(KeyError, union_cluster.cluster_spec)\n", "description": null, "category": "simple", "imports": ["from __future__ import absolute_import", "from __future__ import division", "from __future__ import print_function", "from tensorflow.python import framework", "from tensorflow.python.client import session", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import ClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import SimpleClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import UnionClusterResolver", "from tensorflow.python.eager.context import LogicalDevice", "from tensorflow.python.framework import test_util", "from tensorflow.python.platform import test", "from tensorflow.python.training import server_lib"]}, {"term": "def", "name": "testOverlappingDictAndListThrowError", "data": "  def testOverlappingDictAndListThrowError(self):\n\tcluster_spec_1 = server_lib.ClusterSpec({\n\t\t\"worker\": [\n\t\t\t\"worker4:2222\",\n\t\t\t\"worker5:2222\"\n\t\t]\n\t})\n\tcluster_spec_2 = server_lib.ClusterSpec({\n\t\t\"worker\": {\n\t\t\t1: \"worker0:2222\",\n\t\t\t2: \"worker1:2222\",\n\t\t\t3: \"worker2:2222\"\n\t\t}\n\t})\n\tcluster_resolver_1 = SimpleClusterResolver(cluster_spec_1)\n\tcluster_resolver_2 = SimpleClusterResolver(cluster_spec_2)\n\n\tunion_cluster = UnionClusterResolver(cluster_resolver_1, cluster_resolver_2)\n\tself.assertRaises(KeyError, union_cluster.cluster_spec)\n", "description": null, "category": "simple", "imports": ["from __future__ import absolute_import", "from __future__ import division", "from __future__ import print_function", "from tensorflow.python import framework", "from tensorflow.python.client import session", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import ClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import SimpleClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import UnionClusterResolver", "from tensorflow.python.eager.context import LogicalDevice", "from tensorflow.python.framework import test_util", "from tensorflow.python.platform import test", "from tensorflow.python.training import server_lib"]}, {"term": "def", "name": "testOverlappingJobNonOverlappingKey", "data": "  def testOverlappingJobNonOverlappingKey(self):\n\tcluster_spec_1 = server_lib.ClusterSpec({\n\t\t\"worker\": {\n\t\t\t5: \"worker4:2222\",\n\t\t\t9: \"worker5:2222\"\n\t\t}\n\t})\n\tcluster_spec_2 = server_lib.ClusterSpec({\n\t\t\"worker\": {\n\t\t\t3: \"worker0:2222\",\n\t\t\t6: \"worker1:2222\",\n\t\t\t7: \"worker2:2222\"\n\t\t}\n\t})\n\tcluster_resolver_1 = SimpleClusterResolver(cluster_spec_1)\n\tcluster_resolver_2 = SimpleClusterResolver(cluster_spec_2)\n\n\tunion_cluster = UnionClusterResolver(cluster_resolver_1, cluster_resolver_2)\n\tcluster_spec = union_cluster.cluster_spec()\n\n\texpected_proto = \"\"\"\n\tjob { name: 'worker' tasks { key: 3 value: 'worker0:2222' }\n\t\t\t\t\t\t tasks { key: 5 value: 'worker4:2222' }\n\t\t\t\t\t\t tasks { key: 6 value: 'worker1:2222' }\n\t\t\t\t\t\t tasks { key: 7 value: 'worker2:2222' }\n\t\t\t\t\t\t tasks { key: 9 value: 'worker5:2222' }}\n\t\"\"\"\n\tself._verifyClusterSpecEquality(cluster_spec, expected_proto)\n", "description": "\n\tjob { name: 'worker' tasks { key: 3 value: 'worker0:2222' }\n\t\t\t\t\t\t tasks { key: 5 value: 'worker4:2222' }\n\t\t\t\t\t\t tasks { key: 6 value: 'worker1:2222' }\n\t\t\t\t\t\t tasks { key: 7 value: 'worker2:2222' }\n\t\t\t\t\t\t tasks { key: 9 value: 'worker5:2222' }}\n\t", "category": "simple", "imports": ["from __future__ import absolute_import", "from __future__ import division", "from __future__ import print_function", "from tensorflow.python import framework", "from tensorflow.python.client import session", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import ClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import SimpleClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import UnionClusterResolver", "from tensorflow.python.eager.context import LogicalDevice", "from tensorflow.python.framework import test_util", "from tensorflow.python.platform import test", "from tensorflow.python.training import server_lib"]}, {"term": "def", "name": "testMixedModeNonOverlappingKey", "data": "  def testMixedModeNonOverlappingKey(self):\n\tcluster_spec_1 = server_lib.ClusterSpec({\n\t\t\"worker\": [\n\t\t\t\"worker4:2222\",\n\t\t\t\"worker5:2222\"\n\t\t]\n\t})\n\tcluster_spec_2 = server_lib.ClusterSpec({\n\t\t\"worker\": {\n\t\t\t3: \"worker0:2222\",\n\t\t\t6: \"worker1:2222\",\n\t\t\t7: \"worker2:2222\"\n\t\t}\n\t})\n\tcluster_resolver_1 = SimpleClusterResolver(cluster_spec_1)\n\tcluster_resolver_2 = SimpleClusterResolver(cluster_spec_2)\n\n\tunion_cluster = UnionClusterResolver(cluster_resolver_1, cluster_resolver_2)\n\tcluster_spec = union_cluster.cluster_spec()\n\n\texpected_proto = \"\"\"\n\tjob { name: 'worker' tasks { key: 0 value: 'worker4:2222' }\n\t\t\t\t\t\t tasks { key: 1 value: 'worker5:2222' }\n\t\t\t\t\t\t tasks { key: 3 value: 'worker0:2222' }\n\t\t\t\t\t\t tasks { key: 6 value: 'worker1:2222' }\n\t\t\t\t\t\t tasks { key: 7 value: 'worker2:2222' }}\n\t\"\"\"\n\tself._verifyClusterSpecEquality(cluster_spec, expected_proto)\n", "description": "\n\tjob { name: 'worker' tasks { key: 0 value: 'worker4:2222' }\n\t\t\t\t\t\t tasks { key: 1 value: 'worker5:2222' }\n\t\t\t\t\t\t tasks { key: 3 value: 'worker0:2222' }\n\t\t\t\t\t\t tasks { key: 6 value: 'worker1:2222' }\n\t\t\t\t\t\t tasks { key: 7 value: 'worker2:2222' }}\n\t", "category": "simple", "imports": ["from __future__ import absolute_import", "from __future__ import division", "from __future__ import print_function", "from tensorflow.python import framework", "from tensorflow.python.client import session", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import ClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import SimpleClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import UnionClusterResolver", "from tensorflow.python.eager.context import LogicalDevice", "from tensorflow.python.framework import test_util", "from tensorflow.python.platform import test", "from tensorflow.python.training import server_lib"]}, {"term": "def", "name": "testRetainSparseJobWithNoMerging", "data": "  def testRetainSparseJobWithNoMerging(self):\n\tbase_cluster_spec = server_lib.ClusterSpec({\n\t\t\"worker\": {\n\t\t\t1: \"worker0:2222\",\n\t\t\t3: \"worker1:2222\",\n\t\t\t5: \"worker2:2222\"\n\t\t}\n\t})\n\n\tbase_cluster_resolver = SimpleClusterResolver(base_cluster_spec)\n\tunion_cluster = UnionClusterResolver(base_cluster_resolver)\n\tcluster_spec = union_cluster.cluster_spec()\n\n\texpected_proto = \"\"\"\n\tjob { name: 'worker' tasks { key: 1 value: 'worker0:2222' }\n\t\t\t\t\t\t tasks { key: 3 value: 'worker1:2222' }\n\t\t\t\t\t\t tasks { key: 5 value: 'worker2:2222' } }\n\t\"\"\"\n\tself._verifyClusterSpecEquality(cluster_spec, expected_proto)\n\n", "description": "\n\tjob { name: 'worker' tasks { key: 1 value: 'worker0:2222' }\n\t\t\t\t\t\t tasks { key: 3 value: 'worker1:2222' }\n\t\t\t\t\t\t tasks { key: 5 value: 'worker2:2222' } }\n\t", "category": "simple", "imports": ["from __future__ import absolute_import", "from __future__ import division", "from __future__ import print_function", "from tensorflow.python import framework", "from tensorflow.python.client import session", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import ClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import SimpleClusterResolver", "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import UnionClusterResolver", "from tensorflow.python.eager.context import LogicalDevice", "from tensorflow.python.framework import test_util", "from tensorflow.python.platform import test", "from tensorflow.python.training import server_lib"]}], [{"term": "def", "name": "simple", "data": "def simple(e):\n\tcode = e.code\n\n\tif code.endswith('Exception'):\n\t\tcode = code.rstrip('Exception')\n\n\ttry:\n\t\t# Dynamically get the error class.\n\t\tsimple_e = getattr(sys.modules[__name__], code)(e)\n\texcept AttributeError:\n\t\t# Return original exception on failure.\n\t\treturn e\n\n\treturn simple_e\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "SimpleException", "data": "class SimpleException(BotoServerError):\n\tdef __init__(self, e):\n\t\tsuper(SimpleException, self).__init__(e.status, e.reason, e.body)\n\t\tself.error_message = self.message\n\n\tdef __repr__(self):\n\t\treturn self.__class__.__name__ + ': ' + self.error_message\n\tdef __str__(self):\n\t\treturn self.__class__.__name__ + ': ' + self.error_message\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "ValidationError", "data": "class ValidationError(SimpleException): pass\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "Throttling", "data": "class Throttling(SimpleException): pass\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "SourceBundleDeletion", "data": "class SourceBundleDeletion(SimpleException): pass\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}], [], [], [], [], [], [], [], [{"term": "class", "name": "TestIsSimplePath", "data": "class TestIsSimplePath(object):\n\t\"\"\"Unit tests for the\n\t:func:`networkx.algorithms.simple_paths.is_simple_path` function.\n\n\t\"\"\"\n\n\tdef test_empty_list(self):\n\t\t\"\"\"Tests that the empty list is not a valid path, since there\n\t\tshould be a one-to-one correspondence between paths as lists of\n\t\tnodes and paths as lists of edges.\n\n\t\t\"\"\"\n\t\tG = nx.trivial_graph()\n\t\tassert not nx.is_simple_path(G, [])\n\n\tdef test_trivial_path(self):\n\t\t\"\"\"Tests that the trivial path, a path of length one, is\n\t\tconsidered a simple path in a graph.\n\n\t\t\"\"\"\n\t\tG = nx.trivial_graph()\n\t\tassert nx.is_simple_path(G, [0])\n\n\tdef test_trivial_nonpath(self):\n\t\t\"\"\"Tests that a list whose sole element is an object not in the\n\t\tgraph is not considered a simple path.\n\n\t\t\"\"\"\n\t\tG = nx.trivial_graph()\n\t\tassert not nx.is_simple_path(G, ['not a node'])\n\n\tdef test_simple_path(self):\n\t\tG = nx.path_graph(2)\n\t\tassert nx.is_simple_path(G, [0, 1])\n\n\tdef test_non_simple_path(self):\n\t\tG = nx.path_graph(2)\n\t\tassert not nx.is_simple_path(G, [0, 1, 0])\n\n\tdef test_cycle(self):\n\t\tG = nx.cycle_graph(3)\n\t\tassert not nx.is_simple_path(G, [0, 1, 2, 0])\n\n\tdef test_missing_node(self):\n\t\tG = nx.path_graph(2)\n\t\tassert not nx.is_simple_path(G, [0, 2])\n\n\tdef test_directed_path(self):\n\t\tG = nx.DiGraph([(0, 1), (1, 2)])\n\t\tassert nx.is_simple_path(G, [0, 1, 2])\n\n\tdef test_directed_non_path(self):\n\t\tG = nx.DiGraph([(0, 1), (1, 2)])\n\t\tassert not nx.is_simple_path(G, [2, 1, 0])\n\n\tdef test_directed_cycle(self):\n\t\tG = nx.DiGraph([(0, 1), (1, 2), (2, 0)])\n\t\tassert not nx.is_simple_path(G, [0, 1, 2, 0])\n\n\tdef test_multigraph(self):\n\t\tG = nx.MultiGraph([(0, 1), (0, 1)])\n\t\tassert nx.is_simple_path(G, [0, 1])\n\n\tdef test_multidigraph(self):\n\t\tG = nx.MultiDiGraph([(0, 1), (0, 1), (1, 0), (1, 0)])\n\t\tassert nx.is_simple_path(G, [0, 1])\n\n", "description": "Unit tests for the\n\t:func:`networkx.algorithms.simple_paths.is_simple_path` function.\n\n\t", "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths", "data": "def test_all_simple_paths():\n\tG = nx.path_graph(4)\n\tpaths = nx.all_simple_paths(G, 0, 3)\n\tassert set(tuple(p) for p in paths) == {(0, 1, 2, 3)}\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_with_two_targets_emits_two_paths", "data": "def test_all_simple_paths_with_two_targets_emits_two_paths():\n\tG = nx.path_graph(4)\n\tG.add_edge(2, 4)\n\tpaths = nx.all_simple_paths(G, 0, [3, 4])\n\tassert set(tuple(p) for p in paths) == {(0, 1, 2, 3), (0, 1, 2, 4)}\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_digraph_all_simple_paths_with_two_targets_emits_two_paths", "data": "def test_digraph_all_simple_paths_with_two_targets_emits_two_paths():\n\tG = nx.path_graph(4, create_using=nx.DiGraph())\n\tG.add_edge(2, 4)\n\tpaths = nx.all_simple_paths(G, 0, [3, 4])\n\tassert set(tuple(p) for p in paths) == {(0, 1, 2, 3), (0, 1, 2, 4)}\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_with_two_targets_cutoff", "data": "def test_all_simple_paths_with_two_targets_cutoff():\n\tG = nx.path_graph(4)\n\tG.add_edge(2, 4)\n\tpaths = nx.all_simple_paths(G, 0, [3, 4], cutoff=3)\n\tassert set(tuple(p) for p in paths) == {(0, 1, 2, 3), (0, 1, 2, 4)}\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_digraph_all_simple_paths_with_two_targets_cutoff", "data": "def test_digraph_all_simple_paths_with_two_targets_cutoff():\n\tG = nx.path_graph(4, create_using=nx.DiGraph())\n\tG.add_edge(2, 4)\n\tpaths = nx.all_simple_paths(G, 0, [3, 4], cutoff=3)\n\tassert set(tuple(p) for p in paths) == {(0, 1, 2, 3), (0, 1, 2, 4)}\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_with_two_targets_in_line_emits_two_paths", "data": "def test_all_simple_paths_with_two_targets_in_line_emits_two_paths():\n\tG = nx.path_graph(4)\n\tpaths = nx.all_simple_paths(G, 0, [2, 3])\n\tassert set(tuple(p) for p in paths) == {(0, 1, 2), (0, 1, 2, 3)}\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_ignores_cycle", "data": "def test_all_simple_paths_ignores_cycle():\n\tG = nx.cycle_graph(3, create_using=nx.DiGraph())\n\tG.add_edge(1, 3)\n\tpaths = nx.all_simple_paths(G, 0, 3)\n\tassert set(tuple(p) for p in paths) == {(0, 1, 3)}\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_with_two_targets_inside_cycle_emits_two_paths", "data": "def test_all_simple_paths_with_two_targets_inside_cycle_emits_two_paths():\n\tG = nx.cycle_graph(3, create_using=nx.DiGraph())\n\tG.add_edge(1, 3)\n\tpaths = nx.all_simple_paths(G, 0, [2, 3])\n\tassert set(tuple(p) for p in paths) == {(0, 1, 2), (0, 1, 3)}\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_source_target", "data": "def test_all_simple_paths_source_target():\n\tG = nx.path_graph(4)\n\tpaths = nx.all_simple_paths(G, 1, 1)\n\tassert paths == []\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_cutoff", "data": "def test_all_simple_paths_cutoff():\n\tG = nx.complete_graph(4)\n\tpaths = nx.all_simple_paths(G, 0, 1, cutoff=1)\n\tassert set(tuple(p) for p in paths) == {(0, 1)}\n\tpaths = nx.all_simple_paths(G, 0, 1, cutoff=2)\n\tassert set(tuple(p) for p in paths) == {(0, 1), (0, 2, 1), (0, 3, 1)}\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_on_non_trivial_graph", "data": "def test_all_simple_paths_on_non_trivial_graph():\n\t''' you may need to draw this graph to make sure it is reasonable '''\n\tG = nx.path_graph(5, create_using=nx.DiGraph())\n\tG.add_edges_from([(0, 5), (1, 5), (1, 3), (5, 4), (4, 2), (4, 3)])\n\tpaths = nx.all_simple_paths(G, 1, [2, 3])\n\tassert set(tuple(p) for p in paths) == {\n\t\t(1, 2), (1, 3, 4, 2), (1, 5, 4, 2), (1, 3), (1, 2, 3), (1, 5, 4, 3),\n\t\t(1, 5, 4, 2, 3)}\n\tpaths = nx.all_simple_paths(G, 1, [2, 3], cutoff=3)\n\tassert set(tuple(p) for p in paths) == {\n\t\t(1, 2), (1, 3, 4, 2), (1, 5, 4, 2), (1, 3), (1, 2, 3), (1, 5, 4, 3)}\n\tpaths = nx.all_simple_paths(G, 1, [2, 3], cutoff=2)\n\tassert set(tuple(p) for p in paths) == {(1, 2), (1, 3), (1, 2, 3)}\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_multigraph", "data": "def test_all_simple_paths_multigraph():\n\tG = nx.MultiGraph([(1, 2), (1, 2)])\n\tpaths = nx.all_simple_paths(G, 1, 1)\n\tassert paths == []\n\tnx.add_path(G, [3, 1, 10, 2])\n\tpaths = list(nx.all_simple_paths(G, 1, 2))\n\tassert len(paths) == 3\n\tassert set(tuple(p) for p in paths) == {(1, 2), (1, 2), (1, 10, 2)}\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_multigraph_with_cutoff", "data": "def test_all_simple_paths_multigraph_with_cutoff():\n\tG = nx.MultiGraph([(1, 2), (1, 2), (1, 10), (10, 2)])\n\tpaths = list(nx.all_simple_paths(G, 1, 2, cutoff=1))\n\tassert len(paths) == 2\n\tassert set(tuple(p) for p in paths) == {(1, 2), (1, 2)}\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_directed", "data": "def test_all_simple_paths_directed():\n\tG = nx.DiGraph()\n\tnx.add_path(G, [1, 2, 3])\n\tnx.add_path(G, [3, 2, 1])\n\tpaths = nx.all_simple_paths(G, 1, 3)\n\tassert set(tuple(p) for p in paths) == {(1, 2, 3)}\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_empty", "data": "def test_all_simple_paths_empty():\n\tG = nx.path_graph(4)\n\tpaths = nx.all_simple_paths(G, 0, 3, cutoff=2)\n\tassert list(paths) == []\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_corner_cases", "data": "def test_all_simple_paths_corner_cases():\n\tassert list(nx.all_simple_paths(nx.empty_graph(2), 0, 0)) == []\n\tassert list(nx.all_simple_paths(nx.empty_graph(2), 0, 1)) == []\n\tassert list(nx.all_simple_paths(nx.path_graph(9), 0, 8, 0)) == []\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "hamiltonian_path", "data": "def hamiltonian_path(G, source):\n\tsource = arbitrary_element(G)\n\tneighbors = set(G[source]) - set([source])\n\tn = len(G)\n\tfor target in neighbors:\n\t\tfor path in nx.all_simple_paths(G, source, target):\n\t\t\tif len(path) == n:\n\t\t\t\tyield path\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_hamiltonian_path", "data": "def test_hamiltonian_path():\n\tfrom itertools import permutations\n\tG = nx.complete_graph(4)\n\tpaths = [list(p) for p in hamiltonian_path(G, 0)]\n\texact = [[0] + list(p) for p in permutations([1, 2, 3], 3)]\n\tassert sorted(paths) == sorted(exact)\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_cutoff_zero", "data": "def test_cutoff_zero():\n\tG = nx.complete_graph(4)\n\tpaths = nx.all_simple_paths(G, 0, 3, cutoff=0)\n\tassert list(list(p) for p in paths) == []\n\tpaths = nx.all_simple_paths(nx.MultiGraph(G), 0, 3, cutoff=0)\n\tassert list(list(p) for p in paths) == []\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_source_missing", "data": "def test_source_missing():\n\twith pytest.raises(nx.NodeNotFound):\n\t\tG = nx.Graph()\n\t\tnx.add_path(G, [1, 2, 3])\n\t\tpaths = list(nx.all_simple_paths(nx.MultiGraph(G), 0, 3))\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_target_missing", "data": "def test_target_missing():\n\twith pytest.raises(nx.NodeNotFound):\n\t\tG = nx.Graph()\n\t\tnx.add_path(G, [1, 2, 3])\n\t\tpaths = list(nx.all_simple_paths(nx.MultiGraph(G), 1, 4))\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_shortest_simple_paths", "data": "def test_shortest_simple_paths():\n\tG = cnlti(nx.grid_2d_graph(4, 4), first_label=1, ordering=\"sorted\")\n\tpaths = nx.shortest_simple_paths(G, 1, 12)\n\tassert next(paths) == [1, 2, 3, 4, 8, 12]\n\tassert next(paths) == [1, 5, 6, 7, 8, 12]\n\tassert ([len(path) for path in nx.shortest_simple_paths(G, 1, 12)] ==\n\t\t\t\t sorted([len(path) for path in nx.all_simple_paths(G, 1, 12)]))\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_shortest_simple_paths_directed", "data": "def test_shortest_simple_paths_directed():\n\tG = nx.cycle_graph(7, create_using=nx.DiGraph())\n\tpaths = nx.shortest_simple_paths(G, 0, 3)\n\tassert [path for path in paths] == [[0, 1, 2, 3]]\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_Greg_Bernstein", "data": "def test_Greg_Bernstein():\n\tg1 = nx.Graph()\n\tg1.add_nodes_from([\"N0\", \"N1\", \"N2\", \"N3\", \"N4\"])\n\tg1.add_edge(\"N4\", \"N1\", weight=10.0, capacity=50, name=\"L5\")\n\tg1.add_edge(\"N4\", \"N0\", weight=7.0, capacity=40, name=\"L4\")\n\tg1.add_edge(\"N0\", \"N1\", weight=10.0, capacity=45, name=\"L1\")\n\tg1.add_edge(\"N3\", \"N0\", weight=10.0, capacity=50, name=\"L0\")\n\tg1.add_edge(\"N2\", \"N3\", weight=12.0, capacity=30, name=\"L2\")\n\tg1.add_edge(\"N1\", \"N2\", weight=15.0, capacity=42, name=\"L3\")\n\tsolution = [['N1', 'N0', 'N3'], ['N1', 'N2', 'N3'], ['N1', 'N4', 'N0', 'N3']]\n\tresult = list(nx.shortest_simple_paths(g1, 'N1', 'N3', weight='weight'))\n\tassert result == solution\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_weighted_shortest_simple_path", "data": "def test_weighted_shortest_simple_path():\n\tdef cost_func(path):\n\t\treturn sum(G.adj[u][v]['weight'] for (u, v) in zip(path, path[1:]))\n\n\tG = nx.complete_graph(5)\n\tweight = {(u, v): random.randint(1, 100) for (u, v) in G.edges()}\n\tnx.set_edge_attributes(G, weight, 'weight')\n\tcost = 0\n\tfor path in nx.shortest_simple_paths(G, 0, 3, weight='weight'):\n\t\tthis_cost = cost_func(path)\n\t\tassert cost <= this_cost\n\t\tcost = this_cost\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_directed_weighted_shortest_simple_path", "data": "def test_directed_weighted_shortest_simple_path():\n\tdef cost_func(path):\n\t\treturn sum(G.adj[u][v]['weight'] for (u, v) in zip(path, path[1:]))\n\n\tG = nx.complete_graph(5)\n\tG = G.to_directed()\n\tweight = {(u, v): random.randint(1, 100) for (u, v) in G.edges()}\n\tnx.set_edge_attributes(G, weight, 'weight')\n\tcost = 0\n\tfor path in nx.shortest_simple_paths(G, 0, 3, weight='weight'):\n\t\tthis_cost = cost_func(path)\n\t\tassert cost <= this_cost\n\t\tcost = this_cost\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_weighted_shortest_simple_path_issue2427", "data": "def test_weighted_shortest_simple_path_issue2427():\n\tG = nx.Graph()\n\tG.add_edge('IN', 'OUT', weight=2)\n\tG.add_edge('IN', 'A', weight=1)\n\tG.add_edge('IN', 'B', weight=2)\n\tG.add_edge('B', 'OUT', weight=2)\n\tassert (list(nx.shortest_simple_paths(G, 'IN', 'OUT', weight=\"weight\")) ==\n\t\t\t\t [['IN', 'OUT'], ['IN', 'B', 'OUT']])\n\tG = nx.Graph()\n\tG.add_edge('IN', 'OUT', weight=10)\n\tG.add_edge('IN', 'A', weight=1)\n\tG.add_edge('IN', 'B', weight=1)\n\tG.add_edge('B', 'OUT', weight=1)\n\tassert (list(nx.shortest_simple_paths(G, 'IN', 'OUT', weight=\"weight\")) ==\n\t\t\t\t [['IN', 'B', 'OUT'], ['IN', 'OUT']])\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_directed_weighted_shortest_simple_path_issue2427", "data": "def test_directed_weighted_shortest_simple_path_issue2427():\n\tG = nx.DiGraph()\n\tG.add_edge('IN', 'OUT', weight=2)\n\tG.add_edge('IN', 'A', weight=1)\n\tG.add_edge('IN', 'B', weight=2)\n\tG.add_edge('B', 'OUT', weight=2)\n\tassert (list(nx.shortest_simple_paths(G, 'IN', 'OUT', weight=\"weight\")) ==\n\t\t\t\t [['IN', 'OUT'], ['IN', 'B', 'OUT']])\n\tG = nx.DiGraph()\n\tG.add_edge('IN', 'OUT', weight=10)\n\tG.add_edge('IN', 'A', weight=1)\n\tG.add_edge('IN', 'B', weight=1)\n\tG.add_edge('B', 'OUT', weight=1)\n\tassert (list(nx.shortest_simple_paths(G, 'IN', 'OUT', weight=\"weight\")) ==\n\t\t\t\t [['IN', 'B', 'OUT'], ['IN', 'OUT']])\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_weight_name", "data": "def test_weight_name():\n\tG = nx.cycle_graph(7)\n\tnx.set_edge_attributes(G, 1, 'weight')\n\tnx.set_edge_attributes(G, 1, 'foo')\n\tG.adj[1][2]['foo'] = 7\n\tpaths = list(nx.shortest_simple_paths(G, 0, 3, weight='foo'))\n\tsolution = [[0, 6, 5, 4, 3], [0, 1, 2, 3]]\n\tassert paths == solution\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_ssp_source_missing", "data": "def test_ssp_source_missing():\n\twith pytest.raises(nx.NodeNotFound):\n\t\tG = nx.Graph()\n\t\tnx.add_path(G, [1, 2, 3])\n\t\tpaths = list(nx.shortest_simple_paths(G, 0, 3))\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_ssp_target_missing", "data": "def test_ssp_target_missing():\n\twith pytest.raises(nx.NodeNotFound):\n\t\tG = nx.Graph()\n\t\tnx.add_path(G, [1, 2, 3])\n\t\tpaths = list(nx.shortest_simple_paths(G, 1, 4))\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_ssp_multigraph", "data": "def test_ssp_multigraph():\n\twith pytest.raises(nx.NetworkXNotImplemented):\n\t\tG = nx.MultiGraph()\n\t\tnx.add_path(G, [1, 2, 3])\n\t\tpaths = list(nx.shortest_simple_paths(G, 1, 4))\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_ssp_source_missing", "data": "def test_ssp_source_missing():\n\twith pytest.raises(nx.NetworkXNoPath):\n\t\tG = nx.Graph()\n\t\tnx.add_path(G, [0, 1, 2])\n\t\tnx.add_path(G, [3, 4, 5])\n\t\tpaths = list(nx.shortest_simple_paths(G, 0, 3))\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_bidirectional_shortest_path_restricted_cycle", "data": "def test_bidirectional_shortest_path_restricted_cycle():\n\tcycle = nx.cycle_graph(7)\n\tlength, path = _bidirectional_shortest_path(cycle, 0, 3)\n\tassert path == [0, 1, 2, 3]\n\tlength, path = _bidirectional_shortest_path(cycle, 0, 3, ignore_nodes=[1])\n\tassert path == [0, 6, 5, 4, 3]\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_bidirectional_shortest_path_restricted_wheel", "data": "def test_bidirectional_shortest_path_restricted_wheel():\n\twheel = nx.wheel_graph(6)\n\tlength, path = _bidirectional_shortest_path(wheel, 1, 3)\n\tassert path in [[1, 0, 3], [1, 2, 3]]\n\tlength, path = _bidirectional_shortest_path(wheel, 1, 3, ignore_nodes=[0])\n\tassert path == [1, 2, 3]\n\tlength, path = _bidirectional_shortest_path(wheel, 1, 3, ignore_nodes=[0, 2])\n\tassert path == [1, 5, 4, 3]\n\tlength, path = _bidirectional_shortest_path(wheel, 1, 3,\n\t\t\t\t\t\t\t\t\t\t\t\tignore_edges=[(1, 0), (5, 0), (2, 3)])\n\tassert path in [[1, 2, 0, 3], [1, 5, 4, 3]]\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_bidirectional_shortest_path_restricted_directed_cycle", "data": "def test_bidirectional_shortest_path_restricted_directed_cycle():\n\tdirected_cycle = nx.cycle_graph(7, create_using=nx.DiGraph())\n\tlength, path = _bidirectional_shortest_path(directed_cycle, 0, 3)\n\tassert path == [0, 1, 2, 3]\n\tpytest.raises(\n\t\tnx.NetworkXNoPath,\n\t\t_bidirectional_shortest_path,\n\t\tdirected_cycle,\n\t\t0, 3,\n\t\tignore_nodes=[1],\n\t)\n\tlength, path = _bidirectional_shortest_path(directed_cycle, 0, 3,\n\t\t\t\t\t\t\t\t\t\t\t\tignore_edges=[(2, 1)])\n\tassert path == [0, 1, 2, 3]\n\tpytest.raises(\n\t\tnx.NetworkXNoPath,\n\t\t_bidirectional_shortest_path,\n\t\tdirected_cycle,\n\t\t0, 3,\n\t\tignore_edges=[(1, 2)],\n\t)\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_bidirectional_shortest_path_ignore", "data": "def test_bidirectional_shortest_path_ignore():\n\tG = nx.Graph()\n\tnx.add_path(G, [1, 2])\n\tnx.add_path(G, [1, 3])\n\tnx.add_path(G, [1, 4])\n\tpytest.raises(\n\t\tnx.NetworkXNoPath,\n\t\t_bidirectional_shortest_path,\n\t\tG,\n\t\t1, 2,\n\t\tignore_nodes=[1],\n\t)\n\tpytest.raises(\n\t\tnx.NetworkXNoPath,\n\t\t_bidirectional_shortest_path,\n\t\tG,\n\t\t1, 2,\n\t\tignore_nodes=[2],\n\t)\n\tG = nx.Graph()\n\tnx.add_path(G, [1, 3])\n\tnx.add_path(G, [1, 4])\n\tnx.add_path(G, [3, 2])\n\tpytest.raises(\n\t\tnx.NetworkXNoPath,\n\t\t_bidirectional_shortest_path,\n\t\tG,\n\t\t1, 2,\n\t\tignore_nodes=[1, 2],\n\t)\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "validate_path", "data": "def validate_path(G, s, t, soln_len, path):\n\tassert path[0] == s\n\tassert path[-1] == t\n\tassert soln_len == sum(G[u][v].get('weight', 1)\n\t\t\t\t\t\t\t   for u, v in zip(path[:-1], path[1:]))\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "validate_length_path", "data": "def validate_length_path(G, s, t, soln_len, length, path):\n\tassert soln_len == length\n\tvalidate_path(G, s, t, length, path)\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_bidirectional_dijksta_restricted", "data": "def test_bidirectional_dijksta_restricted():\n\tXG = nx.DiGraph()\n\tXG.add_weighted_edges_from([('s', 'u', 10), ('s', 'x', 5),\n\t\t\t\t\t\t\t\t('u', 'v', 1), ('u', 'x', 2),\n\t\t\t\t\t\t\t\t('v', 'y', 1), ('x', 'u', 3),\n\t\t\t\t\t\t\t\t('x', 'v', 5), ('x', 'y', 2),\n\t\t\t\t\t\t\t\t('y', 's', 7), ('y', 'v', 6)])\n\n\tXG3 = nx.Graph()\n\tXG3.add_weighted_edges_from([[0, 1, 2], [1, 2, 12],\n\t\t\t\t\t\t\t\t [2, 3, 1], [3, 4, 5],\n\t\t\t\t\t\t\t\t [4, 5, 1], [5, 0, 10]])\n\tvalidate_length_path(XG, 's', 'v', 9,\n\t\t\t\t\t\t *_bidirectional_dijkstra(XG, 's', 'v'))\n\tvalidate_length_path(XG, 's', 'v', 10,\n\t\t\t\t\t\t *_bidirectional_dijkstra(XG, 's', 'v', ignore_nodes=['u']))\n\tvalidate_length_path(XG, 's', 'v', 11,\n\t\t\t\t\t\t *_bidirectional_dijkstra(XG, 's', 'v', ignore_edges=[('s', 'x')]))\n\tpytest.raises(\n\t\tnx.NetworkXNoPath,\n\t\t_bidirectional_dijkstra,\n\t\tXG,\n\t\t's', 'v',\n\t\tignore_nodes=['u'],\n\t\tignore_edges=[('s', 'x')],\n\t)\n\tvalidate_length_path(XG3, 0, 3, 15, *_bidirectional_dijkstra(XG3, 0, 3))\n\tvalidate_length_path(XG3, 0, 3, 16,\n\t\t\t\t\t\t *_bidirectional_dijkstra(XG3, 0, 3, ignore_nodes=[1]))\n\tvalidate_length_path(XG3, 0, 3, 16,\n\t\t\t\t\t\t *_bidirectional_dijkstra(XG3, 0, 3, ignore_edges=[(2, 3)]))\n\tpytest.raises(\n\t\tnx.NetworkXNoPath,\n\t\t_bidirectional_dijkstra,\n\t\tXG3,\n\t\t0, 3,\n\t\tignore_nodes=[1],\n\t\tignore_edges=[(5, 4)],\n\t)\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_bidirectional_dijkstra_no_path", "data": "def test_bidirectional_dijkstra_no_path():\n\twith pytest.raises(nx.NetworkXNoPath):\n\t\tG = nx.Graph()\n\t\tnx.add_path(G, [1, 2, 3])\n\t\tnx.add_path(G, [4, 5, 6])\n\t\tpath = _bidirectional_dijkstra(G, 1, 6)\n\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_bidirectional_dijkstra_ignore", "data": "def test_bidirectional_dijkstra_ignore():\n\tG = nx.Graph()\n\tnx.add_path(G, [1, 2, 10])\n\tnx.add_path(G, [1, 3, 10])\n\tpytest.raises(\n\t\tnx.NetworkXNoPath,\n\t\t_bidirectional_dijkstra,\n\t\tG,\n\t\t1, 2,\n\t\tignore_nodes=[1],\n\t)\n\tpytest.raises(\n\t\tnx.NetworkXNoPath,\n\t\t_bidirectional_dijkstra,\n\t\tG,\n\t\t1, 2,\n\t\tignore_nodes=[2],\n\t)\n\tpytest.raises(\n\t\tnx.NetworkXNoPath,\n\t\t_bidirectional_dijkstra,\n\t\tG,\n\t\t1, 2,\n\t\tignore_nodes=[1, 2],\n\t)\n", "description": null, "category": "simple", "imports": ["import random", "import pytest", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}], [{"term": "def", "name": "trim", "data": "def trim(value, num):\n\treturn value[:num]\n\n", "description": null, "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "noop", "data": "def noop(value, param=None):\n\t\"\"\"A noop filter that always return its first argument and does nothing with\n\tits second (optional) one.\n\tUseful for testing out whitespace in filter arguments (see #19882).\"\"\"\n\treturn value\n\n", "description": "A noop filter that always return its first argument and does nothing with\n\tits second (optional) one.\n\tUseful for testing out whitespace in filter arguments (see #19882).", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "context_stack_length", "data": "def context_stack_length(context):\n\treturn len(context.dicts)\n\n", "description": null, "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "no_params", "data": "def no_params():\n\t\"\"\"Expected no_params __doc__\"\"\"\n", "description": "Expected no_params __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "one_param", "data": "def one_param(arg):\n\t\"\"\"Expected one_param __doc__\"\"\"\n", "description": "Expected one_param __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "explicit_no_context", "data": "def explicit_no_context(arg):\n\t\"\"\"Expected explicit_no_context __doc__\"\"\"\n", "description": "Expected explicit_no_context __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "no_params_with_context", "data": "def no_params_with_context(context):\n\t\"\"\"Expected no_params_with_context __doc__\"\"\"\n", "description": "Expected no_params_with_context __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "params_and_context", "data": "def params_and_context(context, arg):\n\t\"\"\"Expected params_and_context __doc__\"\"\"\n", "description": "Expected params_and_context __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "simple_two_params", "data": "def simple_two_params(one, two):\n\t\"\"\"Expected simple_two_params __doc__\"\"\"\n", "description": "Expected simple_two_params __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "simple_one_default", "data": "def simple_one_default(one, two='hi'):\n\t\"\"\"Expected simple_one_default __doc__\"\"\"\n", "description": "Expected simple_one_default __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "simple_unlimited_args", "data": "def simple_unlimited_args(one, two='hi', *args):\n\t\"\"\"Expected simple_unlimited_args __doc__\"\"\"\n\treturn \"simple_unlimited_args - Expected result: %s\" % (\n\t\t', '.join(six.text_type(arg) for arg in [one, two] + list(args))\n", "description": "Expected simple_unlimited_args __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "simple_only_unlimited_args", "data": "def simple_only_unlimited_args(*args):\n\t\"\"\"Expected simple_only_unlimited_args __doc__\"\"\"\n", "description": "Expected simple_only_unlimited_args __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "simple_unlimited_args_kwargs", "data": "def simple_unlimited_args_kwargs(one, two='hi', *args, **kwargs):\n\t\"\"\"Expected simple_unlimited_args_kwargs __doc__\"\"\"\n\t# Sort the dictionary by key to guarantee the order for testing.\n\tsorted_kwarg = sorted(six.iteritems(kwargs), key=operator.itemgetter(0))\n\treturn \"simple_unlimited_args_kwargs - Expected result: %s / %s\" % (\n\t\t', '.join(six.text_type(arg) for arg in [one, two] + list(args)),\n\t\t', '.join('%s=%s' % (k, v) for (k, v) in sorted_kwarg)\n", "description": "Expected simple_unlimited_args_kwargs __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "simple_tag_without_context_parameter", "data": "def simple_tag_without_context_parameter(arg):\n\t\"\"\"Expected simple_tag_without_context_parameter __doc__\"\"\"\n", "description": "Expected simple_tag_without_context_parameter __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "escape_naive", "data": "def escape_naive(context):\n\t\"\"\"A tag that doesn't even think about escaping issues\"\"\"\n\treturn \"Hello {0}!\".format(context['name'])\n\n", "description": "A tag that doesn't even think about escaping issues", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "escape_explicit", "data": "def escape_explicit(context):\n\t\"\"\"A tag that uses escape explicitly\"\"\"\n\treturn escape(\"Hello {0}!\".format(context['name']))\n\n", "description": "A tag that uses escape explicitly", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "escape_format_html", "data": "def escape_format_html(context):\n\t\"\"\"A tag that uses format_html\"\"\"\n\treturn format_html(\"Hello {0}!\", context['name'])\n\n", "description": "A tag that uses format_html", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "current_app", "data": "def current_app(context):\n\treturn \"%s\" % context.current_app\n\n", "description": null, "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "use_l10n", "data": "def use_l10n(context):\n\treturn \"%s\" % context.use_l10n\n\n", "description": null, "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "minustwo_overridden_name", "data": "def minustwo_overridden_name(value):\n\treturn value - 2\n", "description": null, "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "fassignment_no_params", "data": "\tdef assignment_no_params():\n\t\t\"\"\"Expected assignment_no_params __doc__\"\"\"\n", "description": "Expected assignment_no_params __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "fassignment_tag_without_context_parameter", "data": "\tdef assignment_tag_without_context_parameter(arg):\n\t\t\"\"\"Expected assignment_tag_without_context_parameter __doc__\"\"\"\n", "description": "Expected assignment_tag_without_context_parameter __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}], [], [{"term": "def", "name": "simple", "data": "def simple(e):\n\tcode = e.code\n\n\tif code.endswith('Exception'):\n\t\tcode = code.rstrip('Exception')\n\n\ttry:\n\t\t# Dynamically get the error class.\n\t\tsimple_e = getattr(sys.modules[__name__], code)(e)\n\texcept AttributeError:\n\t\t# Return original exception on failure.\n\t\treturn e\n\n\treturn simple_e\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "SimpleException", "data": "class SimpleException(BotoServerError):\n\tdef __init__(self, e):\n\t\tsuper(SimpleException, self).__init__(e.status, e.reason, e.body)\n\t\tself.error_message = self.message\n\n\tdef __repr__(self):\n\t\treturn self.__class__.__name__ + ': ' + self.error_message\n\tdef __str__(self):\n\t\treturn self.__class__.__name__ + ': ' + self.error_message\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "ValidationError", "data": "class ValidationError(SimpleException): pass\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "Throttling", "data": "class Throttling(SimpleException): pass\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "SourceBundleDeletion", "data": "class SourceBundleDeletion(SimpleException): pass\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}], [], [], [], [], [], [], [], [{"term": "class", "name": "SimpleTree", "data": "class SimpleTree(object):\n\tdef __init__(self, value=None, rightSubTree=None, leftSubTree=None, parent=None):\n\t\tself.value = value\n\t\tself.rightSubTree = rightSubTree\n\t\tself.leftSubTree = leftSubTree\n\t\tself.parent = parent\n\n\tdef __repr__(self):\n\t\treturn \"Tree({0}, left = {1}, right = {2})\".format(self.value, self.leftSubTree, self.rightSubTree)\n\n\tdef withLeftChild(self, leftSubTree):\n\t\tself.leftSubTree = leftSubTree\n\n\tdef withRightChild(self, rightSubTree):\n\t\tself.rightSubTree = rightSubTree\n\n\tdef assignValue(self, value):\n\t\tself.value = value\n\n\tdef hasRightChild(self):\n\t\treturn self.rightSubTree is not None\n\n\tdef hasLeftChild(self):\n\t\treturn self.leftSubTree is not None\n\n\tdef hasParent(self):\n\t\treturn self.parent is not None\n\n\tdef getParent(self):\n\t\treturn self.parent\n\n\tdef isEmpty(self):\n\t\treturn not self.hasRightChild() and not self.hasLeftChild()\n\n", "description": null, "category": "simple", "imports": []}, {"term": "def", "name": "createChildOrGet", "data": "def createChildOrGet(simpleTree, isRight):\n\tif isRight:\n\t\tif simpleTree.hasRightChild():\n\t\t\treturn simpleTree.rightSubTree\n\t\telse:\n\t\t\treturn SimpleTree(parent=simpleTree)\n\telse:\n\t\tif simpleTree.hasLeftChild():\n\t\t\treturn simpleTree.leftSubTree\n\t\telse:\n\t\t\treturn SimpleTree(parent=simpleTree)\n\n", "description": null, "category": "simple", "imports": []}, {"term": "def", "name": "goToRoot", "data": "def goToRoot(simpleTree):\n\twhile simpleTree.hasParent():\n\t\tsimpleTree = simpleTree.getParent()\n\treturn simpleTree\n\n", "description": null, "category": "simple", "imports": []}, {"term": "def", "name": "createTree", "data": "def createTree(codes):\n\tcurrentTree = SimpleTree()\n\n\tfor pair in codes:\n\t\tfor char in pair[1]:\n\t\t\tif char == '0':\n\t\t\t\tchild = createChildOrGet(currentTree, False)\n\t\t\t\tcurrentTree.withLeftChild(child)\n\t\t\t\tcurrentTree = child\n\t\t\telse:\n\t\t\t\tchild = createChildOrGet(currentTree, True)\n\t\t\t\tcurrentTree.withRightChild(child)\n\t\t\t\tcurrentTree = child\n\t\tcurrentTree.assignValue(pair[0])\n\t\tcurrentTree = goToRoot(currentTree)\n\treturn currentTree\n\n", "description": null, "category": "simple", "imports": []}, {"term": "def", "name": "decode", "data": "def decode(simpleTree, bin):\n\ttempTree = simpleTree\n\tstr = \"\"\n\tfor b in bin:\n\t\tif b == '1':\n\t\t\ttempTree = tempTree.rightSubTree\n\t\t\tif tempTree.isEmpty():\n\t\t\t\tstr += tempTree.value\n\t\t\t\ttempTree = tree\n\t\telse:\n\t\t\ttempTree = tempTree.leftSubTree\n\t\t\tif tempTree.isEmpty():\n\t\t\t\tstr += tempTree.value\n\t\t\t\ttempTree = tree\n\treturn str\n\n", "description": null, "category": "simple", "imports": []}], [{"term": "def", "name": "fswig_import_helper", "data": "\tdef swig_import_helper():\n\t\timport importlib\n\t\tpkg = __name__.rpartition('.')[0]\n\t\tmname = '.'.join((pkg, '_param_AtomicSimpleCPU')).lstrip('.')\n\t\ttry:\n\t\t\treturn importlib.import_module(mname)\n\t\texcept ImportError:\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_AtomicSimpleCPU')", "\t_param_AtomicSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_AtomicSimpleCPU", "\t_param_AtomicSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_AtomicSimpleCPU", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BaseSimpleCPU", "import m5.internal.param_BranchPredictor", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_BaseCPU", "import m5.internal.param_X86TLB", "import m5.internal.param_X86PagetableWalker", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BaseTLB", "import m5.internal.X86LocalApic_vector", "import m5.internal.param_X86LocalApic", "import m5.internal.param_BasicPioDevice", "import m5.internal.param_PioDevice", "import m5.internal.X86ISA_vector", "import m5.internal.param_X86ISA", "import m5.internal.Counter_vector", "import m5.internal.param_InstTracer", "import m5.internal.Process_vector", "import m5.internal.param_Process"]}, {"term": "def", "name": "fswig_import_helper", "data": "\tdef swig_import_helper():\n\t\tfrom os.path import dirname\n\t\timport imp\n\t\tfp = None\n\t\ttry:\n\t\t\tfp, pathname, description = imp.find_module('_param_AtomicSimpleCPU', [dirname(__file__)])\n\t\texcept ImportError:\n\t\t\timport _param_AtomicSimpleCPU\n\t\t\treturn _param_AtomicSimpleCPU\n\t\ttry:\n\t\t\t_mod = imp.load_module('_param_AtomicSimpleCPU', fp, pathname, description)\n\t\tfinally:\n\t\t\tif fp is not None:\n\t\t\t\tfp.close()\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_AtomicSimpleCPU')", "\t_param_AtomicSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_AtomicSimpleCPU", "\t_param_AtomicSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_AtomicSimpleCPU", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BaseSimpleCPU", "import m5.internal.param_BranchPredictor", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_BaseCPU", "import m5.internal.param_X86TLB", "import m5.internal.param_X86PagetableWalker", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BaseTLB", "import m5.internal.X86LocalApic_vector", "import m5.internal.param_X86LocalApic", "import m5.internal.param_BasicPioDevice", "import m5.internal.param_PioDevice", "import m5.internal.X86ISA_vector", "import m5.internal.param_X86ISA", "import m5.internal.Counter_vector", "import m5.internal.param_InstTracer", "import m5.internal.Process_vector", "import m5.internal.param_Process"]}, {"term": "def", "name": "_swig_setattr_nondynamic", "data": "def _swig_setattr_nondynamic(self, class_type, name, value, static=1):\n\tif (name == \"thisown\"):\n\t\treturn self.this.own(value)\n\tif (name == \"this\"):\n\t\tif type(value).__name__ == 'SwigPyObject':\n\t\t\tself.__dict__[name] = value\n\t\t\treturn\n\tmethod = class_type.__swig_setmethods__.get(name, None)\n\tif method:\n\t\treturn method(self, value)\n\tif (not static):\n\t\tobject.__setattr__(self, name, value)\n\telse:\n\t\traise AttributeError(\"You cannot add attributes to %s\" % self)\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_AtomicSimpleCPU')", "\t_param_AtomicSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_AtomicSimpleCPU", "\t_param_AtomicSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_AtomicSimpleCPU", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BaseSimpleCPU", "import m5.internal.param_BranchPredictor", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_BaseCPU", "import m5.internal.param_X86TLB", "import m5.internal.param_X86PagetableWalker", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BaseTLB", "import m5.internal.X86LocalApic_vector", "import m5.internal.param_X86LocalApic", "import m5.internal.param_BasicPioDevice", "import m5.internal.param_PioDevice", "import m5.internal.X86ISA_vector", "import m5.internal.param_X86ISA", "import m5.internal.Counter_vector", "import m5.internal.param_InstTracer", "import m5.internal.Process_vector", "import m5.internal.param_Process"]}, {"term": "def", "name": "_swig_setattr", "data": "def _swig_setattr(self, class_type, name, value):\n\treturn _swig_setattr_nondynamic(self, class_type, name, value, 0)\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_AtomicSimpleCPU')", "\t_param_AtomicSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_AtomicSimpleCPU", "\t_param_AtomicSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_AtomicSimpleCPU", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BaseSimpleCPU", "import m5.internal.param_BranchPredictor", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_BaseCPU", "import m5.internal.param_X86TLB", "import m5.internal.param_X86PagetableWalker", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BaseTLB", "import m5.internal.X86LocalApic_vector", "import m5.internal.param_X86LocalApic", "import m5.internal.param_BasicPioDevice", "import m5.internal.param_PioDevice", "import m5.internal.X86ISA_vector", "import m5.internal.param_X86ISA", "import m5.internal.Counter_vector", "import m5.internal.param_InstTracer", "import m5.internal.Process_vector", "import m5.internal.param_Process"]}, {"term": "def", "name": "_swig_getattr", "data": "def _swig_getattr(self, class_type, name):\n\tif (name == \"thisown\"):\n\t\treturn self.this.own()\n\tmethod = class_type.__swig_getmethods__.get(name, None)\n\tif method:\n\t\treturn method(self)\n\traise AttributeError(\"'%s' object has no attribute '%s'\" % (class_type.__name__, name))\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_AtomicSimpleCPU')", "\t_param_AtomicSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_AtomicSimpleCPU", "\t_param_AtomicSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_AtomicSimpleCPU", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BaseSimpleCPU", "import m5.internal.param_BranchPredictor", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_BaseCPU", "import m5.internal.param_X86TLB", "import m5.internal.param_X86PagetableWalker", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BaseTLB", "import m5.internal.X86LocalApic_vector", "import m5.internal.param_X86LocalApic", "import m5.internal.param_BasicPioDevice", "import m5.internal.param_PioDevice", "import m5.internal.X86ISA_vector", "import m5.internal.param_X86ISA", "import m5.internal.Counter_vector", "import m5.internal.param_InstTracer", "import m5.internal.Process_vector", "import m5.internal.param_Process"]}, {"term": "def", "name": "_swig_repr", "data": "def _swig_repr(self):\n\ttry:\n\t\tstrthis = \"proxy of \" + self.this.__repr__()\n\texcept __builtin__.Exception:\n\t\tstrthis = \"\"\n\treturn \"<%s.%s; %s >\" % (self.__class__.__module__, self.__class__.__name__, strthis,)\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_AtomicSimpleCPU')", "\t_param_AtomicSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_AtomicSimpleCPU", "\t_param_AtomicSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_AtomicSimpleCPU", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BaseSimpleCPU", "import m5.internal.param_BranchPredictor", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_BaseCPU", "import m5.internal.param_X86TLB", "import m5.internal.param_X86PagetableWalker", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BaseTLB", "import m5.internal.X86LocalApic_vector", "import m5.internal.param_X86LocalApic", "import m5.internal.param_BasicPioDevice", "import m5.internal.param_PioDevice", "import m5.internal.X86ISA_vector", "import m5.internal.param_X86ISA", "import m5.internal.Counter_vector", "import m5.internal.param_InstTracer", "import m5.internal.Process_vector", "import m5.internal.param_Process"]}, {"term": "def", "name": "_swig_setattr_nondynamic_method", "data": "def _swig_setattr_nondynamic_method(set):\n\tdef set_attr(self, name, value):\n\t\tif (name == \"thisown\"):\n\t\t\treturn self.this.own(value)\n\t\tif hasattr(self, name) or (name == \"this\"):\n\t\t\tset(self, name, value)\n\t\telse:\n\t\t\traise AttributeError(\"You cannot add attributes to %s\" % self)\n\treturn set_attr\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_AtomicSimpleCPU')", "\t_param_AtomicSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_AtomicSimpleCPU", "\t_param_AtomicSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_AtomicSimpleCPU", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BaseSimpleCPU", "import m5.internal.param_BranchPredictor", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_BaseCPU", "import m5.internal.param_X86TLB", "import m5.internal.param_X86PagetableWalker", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BaseTLB", "import m5.internal.X86LocalApic_vector", "import m5.internal.param_X86LocalApic", "import m5.internal.param_BasicPioDevice", "import m5.internal.param_PioDevice", "import m5.internal.X86ISA_vector", "import m5.internal.param_X86ISA", "import m5.internal.Counter_vector", "import m5.internal.param_InstTracer", "import m5.internal.Process_vector", "import m5.internal.param_Process"]}, {"term": "class", "name": "AtomicSimpleCPU", "data": "class AtomicSimpleCPU(m5.internal.param_BaseSimpleCPU.BaseSimpleCPU):\n\tthisown = _swig_property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc='The membership flag')\n\n\tdef __init__(self, *args, **kwargs):\n\t\traise AttributeError(\"No constructor defined - class is abstract\")\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_AtomicSimpleCPU')", "\t_param_AtomicSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_AtomicSimpleCPU", "\t_param_AtomicSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_AtomicSimpleCPU", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BaseSimpleCPU", "import m5.internal.param_BranchPredictor", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_BaseCPU", "import m5.internal.param_X86TLB", "import m5.internal.param_X86PagetableWalker", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BaseTLB", "import m5.internal.X86LocalApic_vector", "import m5.internal.param_X86LocalApic", "import m5.internal.param_BasicPioDevice", "import m5.internal.param_PioDevice", "import m5.internal.X86ISA_vector", "import m5.internal.param_X86ISA", "import m5.internal.Counter_vector", "import m5.internal.param_InstTracer", "import m5.internal.Process_vector", "import m5.internal.param_Process"]}, {"term": "class", "name": "AtomicSimpleCPUParams", "data": "class AtomicSimpleCPUParams(m5.internal.param_BaseSimpleCPU.BaseSimpleCPUParams):\n\tthisown = _swig_property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc='The membership flag')\n\t__repr__ = _swig_repr\n\n\tdef create(self):\n\t\treturn _param_AtomicSimpleCPU.AtomicSimpleCPUParams_create(self)\n\tfastmem = _swig_property(_param_AtomicSimpleCPU.AtomicSimpleCPUParams_fastmem_get, _param_AtomicSimpleCPU.AtomicSimpleCPUParams_fastmem_set)\n\tsimulate_data_stalls = _swig_property(_param_AtomicSimpleCPU.AtomicSimpleCPUParams_simulate_data_stalls_get, _param_AtomicSimpleCPU.AtomicSimpleCPUParams_simulate_data_stalls_set)\n\tsimulate_inst_stalls = _swig_property(_param_AtomicSimpleCPU.AtomicSimpleCPUParams_simulate_inst_stalls_get, _param_AtomicSimpleCPU.AtomicSimpleCPUParams_simulate_inst_stalls_set)\n\twidth = _swig_property(_param_AtomicSimpleCPU.AtomicSimpleCPUParams_width_get, _param_AtomicSimpleCPU.AtomicSimpleCPUParams_width_set)\n\n\tdef __init__(self):\n\t\tthis = _param_AtomicSimpleCPU.new_AtomicSimpleCPUParams()\n\t\ttry:\n\t\t\tself.this.append(this)\n\t\texcept __builtin__.Exception:\n\t\t\tself.this = this\n\t__swig_destroy__ = _param_AtomicSimpleCPU.delete_AtomicSimpleCPUParams\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_AtomicSimpleCPU')", "\t_param_AtomicSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_AtomicSimpleCPU", "\t_param_AtomicSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_AtomicSimpleCPU", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BaseSimpleCPU", "import m5.internal.param_BranchPredictor", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_BaseCPU", "import m5.internal.param_X86TLB", "import m5.internal.param_X86PagetableWalker", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BaseTLB", "import m5.internal.X86LocalApic_vector", "import m5.internal.param_X86LocalApic", "import m5.internal.param_BasicPioDevice", "import m5.internal.param_PioDevice", "import m5.internal.X86ISA_vector", "import m5.internal.param_X86ISA", "import m5.internal.Counter_vector", "import m5.internal.param_InstTracer", "import m5.internal.Process_vector", "import m5.internal.param_Process"]}], [{"term": "def", "name": "readData", "data": "def readData(path_patient = r'.\\Patient', path_atlas = r'.\\Atlas'):\r\n\t\"\"\"\r\n\tRead in all the data in the folder\r\n\tReturns the path of each file.\r\n\t\"\"\"\r\n\t#  List of path\r\n\tatlas_path = []\r\n\tatlas_manual_path = []\r\n\tpatient_path = []\r\n\tpatient_manual_path = []\r\n\t#  List of images\r\n\tatlas = []\r\n\tatlas_manual = []\r\n\tpatient = []\r\n\tpatienr_manual = []\r\n\t#  Read in all the atlas\r\n\tfor file in os.listdir(path_atlas):\r\n\t\tfile_name = path_atlas + '\\\\' + file\t\r\n\t\tatlas_path.append(file_name + '\\\\' + 'mr_bffe.mhd')\r\n\t\tatlas_manual_path.append(file_name + '\\\\' + 'prostaat.mhd')\r\n\t\tatlas.append(SimpleITK.ReadImage(file_name + '\\\\' + 'mr_bffe.mhd'))\r\n\t\tatlas_manual.append(SimpleITK.ReadImage(file_name + '\\\\' + 'prostaat.mhd'))\r\n\t#  Read in all the patients\r\n\tfor file in os.listdir(path_patient):\r\n\t\tfile_name = path_patient + '\\\\' + file\r\n\t\tpatient_path.append(file_name + '\\\\' + 'mr_bffe.mhd')\r\n\t\tpatient_manual_path.append(file_name + '\\\\' + 'prostaat.mhd')\r\n\t\tpatient.append(SimpleITK.ReadImage(file_name + '\\\\' + 'mr_bffe.mhd'))\r\n\t\tpatienr_manual.append(SimpleITK.ReadImage(file_name + '\\\\' + 'prostaat.mhd'))\r\n\tprint('There are %d atlases data and %d patient' %(len(atlas_path), len(patient_path)))\r\n\t\r\n\treturn [atlas, atlas_manual], [patient, patienr_manual]\r\n", "description": "\r\n\tRead in all the data in the folder\r\n\tReturns the path of each file.\r\n\t", "category": "simple", "imports": ["import SimpleITK\r", "import os\r", "import numpy as np\r", "from skimage.morphology import dilation\r"]}, {"term": "def", "name": "register", "data": "def register(atlas, patient, ifPrint = 0):\r\n\t\"\"\"\r\n\tDo the registeration.\r\n\tFirst it searches all the data from the altas floder. Then all the altas are \r\n\tregistered with the files in the patient floder.\r\n\tIt also records the scores in a scoreList.\r\n\tThe best registratons are saved.\r\n\tatlas0 = image, atlas1 = maunal\r\n\tpatient0 = image, patienr1 = manual\r\n\t\"\"\"\r\n\t#  Set the parameterMap\r\n\tparameterVec = setParameters()\r\n\t#  Initilize a SimpleElastix instance\r\n\tSimpleElastix = SimpleITK.SimpleElastix()\r\n\tSimpleElastix.SetLogToFile(True)\r\n\tif ifPrint == 1:\r\n\t\tSimpleElastix.LogToConsoleOn()\r\n\t#  Set the parameterMap\r\n\tSimpleElastix.SetParameterMap(parameterVec)\r\n\t#  ifPrint\r\n\tif ifPrint == 1:\r\n\t\tSimpleElastix.PrintParameterMap()\r\n\t# A list to store results of patient image\r\n\tresultPatientImage = []\r\n\t# A list to store results of patient Manuals\r\n\tresultPatientManual = []\r\n\t# A list to store results of patient score\r\n\treslutPatientScore = []\r\n\t#  Lood through the patient folder\r\n\tfor patientImage, patientManual in zip(patient[0], patient[1]):\r\n\t\t#  A list to store all the reslut image\r\n\t\tresultImage = []\r\n\t\t#  A list to store all the reversed manuals\r\n\t\tresultManuals = []\r\n\t\t#  A list to store all the dice scores\r\n\t\tresultScore = []\r\n\t\t#  Set the fixed image\r\n\t\tSimpleElastix.SetFixedImage(patientImage)\r\n\t\t#  Get the origin of the fixed image\r\n\t\timageOrigin = patientImage.GetOrigin()\r\n\t\tmanualOrigin = patientManual.GetOrigin()\r\n\t\t#  Loop through the patient folder\r\n\t\tfor atlasImage, atlasManual in zip(atlas[0], atlas[1]):\r\n\t\t\t#  Set the origin of moving image\r\n\t\t\tatlasImage.SetOrigin(imageOrigin)\r\n\t\t\t#  Set the moving image\r\n\t\t\tSimpleElastix.SetMovingImage(atlasImage)\r\n\t\t\t#  Do the registration\r\n\t\t\tSimpleElastix.Execute()\r\n\t\t\tprint('\\nOne registration done!')\r\n\t\t\tresultImage.append(SimpleElastix.GetResultImage())\r\n\t\t\t#  Get the transform Matrix\r\n\t\t\ttransforMartix = SimpleElastix.GetTransformParameterMap()\r\n\t\t\t#  Apply the transform Matrix to the atlasManual\r\n\t\t\treversedManual = SimpleITK.Transformix(atlasManual, transforMartix)\r\n\t\t\t#  Label voting\r\n\t\t\treversedManual = SimpleITK.LabelVoting(reversedManual,1) \r\n\t\t\tprint('Label voting done!')\r\n\t\t\t#  Set the origin of reversed maunal\r\n\t\t\treversedManual.SetOrigin(manualOrigin)\r\n\t\t\tresultManuals.append(reversedManual)   \r\n\t\t\t#  Calculate the dice score\r\n\t\t\tmeasureFilter = SimpleITK.LabelOverlapMeasuresImageFilter()\r\n\t\t\t#  Have to change the tolerance to make the code work\r\n\t\t\tmeasureFilter.SetGlobalDefaultCoordinateTolerance(1e3)\r\n\t\t\treversedOrigin = reversedManual.GetOrigin()\r\n\t\t\tatlasManual.SetOrigin(reversedOrigin)\r\n\t\t\tmeasureFilter.Execute(reversedManual, atlasManual)\r\n\t\t\tprint('Dice scores done!')\r\n\t\t\tdiceScore = measureFilter.GetDiceCoefficient()\r\n\t\t\tresultScore.append(diceScore)\r\n\t\t\tprint('The dice score is %f' %diceScore)\r\n\t\tresultPatientImage.append(resultImage)\r\n\t\tresultPatientManual.append(resultManuals)\r\n\t\treslutPatientScore.append(resultScore)\r\n\treturn resultPatientImage, resultPatientManual, reslutPatientScore\r\n", "description": "\r\n\tDo the registeration.\r\n\tFirst it searches all the data from the altas floder. Then all the altas are \r\n\tregistered with the files in the patient floder.\r\n\tIt also records the scores in a scoreList.\r\n\tThe best registratons are saved.\r\n\tatlas0 = image, atlas1 = maunal\r\n\tpatient0 = image, patienr1 = manual\r\n\t", "category": "simple", "imports": ["import SimpleITK\r", "import os\r", "import numpy as np\r", "from skimage.morphology import dilation\r"]}, {"term": "def", "name": "setParameters", "data": "def setParameters():\r\n\tparameterVec = SimpleITK.VectorOfParameterMap()\r\n\r\n\t#rigid = SimpleITK.GetDefaultParameterMap('rigid')\r\n\ttraslation = SimpleITK.GetDefaultParameterMap('translation')\r\n\taffine = SimpleITK.GetDefaultParameterMap('affine')\r\n\tbspline = SimpleITK.GetDefaultParameterMap('bspline')\r\n\r\n\ttraslation['FinalBSplineInterpolationOrder'] = '0'\r\n\taffine['FinalBSplineInterpolationOrder'] = '0'\r\n\tbspline['FinalBSplineInterpolationOrder'] = '0'\r\n\r\n\ttraslation['Registration'] = ['MultiMetricMultiResolutionRegistration']\r\n\taffine['Registration'] = ['MultiMetricMultiResolutionRegistration']\r\n\tbspline['Registration'] = ['MultiMetricMultiResolutionRegistration']\r\n\r\n\ttraslation['Metric'] = ['AdvancedMattesMutualInformation','AdvancedNormalizedCorrelation']\r\n\taffine['Metric'] = ['AdvancedMattesMutualInformation','AdvancedNormalizedCorrelation']\r\n\tbspline['Metric'] = ['AdvancedMattesMutualInformation','AdvancedNormalizedCorrelation']\r\n\r\n\t#parameterVec.append(rigid)\r\n\tparameterVec.append(traslation)\r\n\tparameterVec.append(affine)\r\n\tparameterVec.append(bspline)\r\n\treturn parameterVec\r\n", "description": null, "category": "simple", "imports": ["import SimpleITK\r", "import os\r", "import numpy as np\r", "from skimage.morphology import dilation\r"]}, {"term": "def", "name": "selectResults", "data": "def selectResults(resultImage, resultManuals, resultScore):\r\n\t\"\"\"\r\n\tSelect the best results and save\r\n\t\"\"\"\r\n\tresultIm = []\r\n\tresultMn = []\r\n\tresultSc = []\r\n\tfor i in range(len(resultScore)):\r\n\t\tresult = resultScore[i]\r\n\t\tmaxPos = result.index(max(result))\r\n\t\tresultIm.append(resultImage[i][maxPos])\r\n\t\tresultMn.append(resultManuals[i][maxPos])\r\n\t\tresultSc.append(resultScore[i][maxPos])\r\n\tfor i in range(len(resultScore)):\r\n\t\tresult = resultScore[i]\r\n\t\tSimpleITK.WriteImage(resultIm[i],r'.\\result\\resultImage' + '%f.mhd' %max(result))\r\n\t\tSimpleITK.WriteImage(resultMn[i],r'.\\result\\resultManual'+'%f.mhd' %max(result))\r\n\treturn resultSc, resultIm, resultMn\r\n\t\r\n", "description": "\r\n\tSelect the best results and save\r\n\t", "category": "simple", "imports": ["import SimpleITK\r", "import os\r", "import numpy as np\r", "from skimage.morphology import dilation\r"]}, {"term": "def", "name": "zooming", "data": "def zooming(MRImage_Atlas):\r\n\tfor MRImage, atlasManual in zip(MRImage_Atlas[0], MRImage_Atlas[1]):\r\n\t\t# Get mask by dilation\r\n\t\tprint(\"Dilating....\")\r\n\t\r\n\t\tlabel_vote = SimpleITK.LabelVoting(atlasManual)\r\n\t\r\n\t\t# Volume\r\n\t\troi = SimpleITK.GetArrayFromImage(label_vote)\r\n\t\r\n\t\t# Desired volume\r\n\t\ttarget_size = np.sum(roi) * 1.5\r\n\r\n\r\n\t\twhile np.sum(roi) < target_size:\r\n\t\t\troi = dilation(roi)\r\n\t\t\tprint(np.sum(roi), target_size, end=\"\\r\")\r\n\t\t\r\n\t\tprint(\"Dilation complete\")\r\n\t\r\n\t\troi = SimpleITK.GetImageFromArray(roi)\r\n\t\t\r\n\t\tZoomedImage = MRImage*roi\r\n\t\t\r\n\treturn [ZoomedImage, atlasManual]\r\n\r\n", "description": null, "category": "simple", "imports": ["import SimpleITK\r", "import os\r", "import numpy as np\r", "from skimage.morphology import dilation\r"]}], [{"term": "def", "name": "simple_tree", "data": "def simple_tree():\n\tt = BinaryTree()\n\tt.insert(5)\n\tt.insert(10)\n\tt.insert(2)\n\tt.insert(17)\n\treturn t\n\n", "description": null, "category": "simple", "imports": ["from bst import BinaryTree", "import pytest"]}, {"term": "def", "name": "empty_tree", "data": "def empty_tree():\n\tt = BinaryTree()\n\treturn t\n\n", "description": null, "category": "simple", "imports": ["from bst import BinaryTree", "import pytest"]}, {"term": "def", "name": "test_binarytree", "data": "def test_binarytree():\n\tt = BinaryTree()\n\tassert t.root is None\n\n", "description": null, "category": "simple", "imports": ["from bst import BinaryTree", "import pytest"]}, {"term": "def", "name": "test_insert_into_empty_tree", "data": "def test_insert_into_empty_tree(empty_tree):\n\tempty_tree.insert(5)\n\tassert empty_tree.root.val == 5\n\n", "description": null, "category": "simple", "imports": ["from bst import BinaryTree", "import pytest"]}, {"term": "def", "name": "test_insert_into_simple_tree", "data": "def test_insert_into_simple_tree(simple_tree):\n\tsimple_tree.insert(1)\n\tassert simple_tree.root.left_child.left_child.val == 1\n\n", "description": null, "category": "simple", "imports": ["from bst import BinaryTree", "import pytest"]}, {"term": "def", "name": "test_insert_duplicate", "data": "def test_insert_duplicate(simple_tree):\n\tassert simple_tree.size == 4\n\tsimple_tree.insert(17)\n\tassert simple_tree.size == 4\n\n", "description": null, "category": "simple", "imports": ["from bst import BinaryTree", "import pytest"]}, {"term": "def", "name": "test_contains", "data": "def test_contains(simple_tree):\n\tassert simple_tree.contains(5)\n\tassert simple_tree.contains(17)\n\tassert simple_tree.contains(10)\n\n", "description": null, "category": "simple", "imports": ["from bst import BinaryTree", "import pytest"]}, {"term": "def", "name": "test_size_on_empty_tree", "data": "def test_size_on_empty_tree(empty_tree):\n\tassert empty_tree.size == 0\n\n", "description": null, "category": "simple", "imports": ["from bst import BinaryTree", "import pytest"]}, {"term": "def", "name": "test_size_on_simple_tree", "data": "def test_size_on_simple_tree(simple_tree):\n\tassert simple_tree.size == 4\n\n", "description": null, "category": "simple", "imports": ["from bst import BinaryTree", "import pytest"]}, {"term": "def", "name": "test_depth_on_empty_tree", "data": "def test_depth_on_empty_tree(empty_tree):\n\tassert empty_tree.depth() == 0\n\n", "description": null, "category": "simple", "imports": ["from bst import BinaryTree", "import pytest"]}, {"term": "def", "name": "test_depth_on_simple_tree", "data": "def test_depth_on_simple_tree(simple_tree):\n\tassert simple_tree.depth() == 3\n\n", "description": null, "category": "simple", "imports": ["from bst import BinaryTree", "import pytest"]}, {"term": "def", "name": "test_balance", "data": "def test_balance(simple_tree):\n\tassert simple_tree.balance() == -1\n\n", "description": null, "category": "simple", "imports": ["from bst import BinaryTree", "import pytest"]}, {"term": "def", "name": "test_balance_empty_tree", "data": "def test_balance_empty_tree(empty_tree):\n\tassert empty_tree.balance() == 0\n\n", "description": null, "category": "simple", "imports": ["from bst import BinaryTree", "import pytest"]}, {"term": "def", "name": "test_balance_one_node_tree_returns_1", "data": "def test_balance_one_node_tree_returns_1():\n\tt = BinaryTree()\n\tt.insert(1)\n\tassert t.balance() == 0\n\n", "description": null, "category": "simple", "imports": ["from bst import BinaryTree", "import pytest"]}, {"term": "def", "name": "test_in_order_traversal_empty", "data": "def test_in_order_traversal_empty(empty_tree):\n\tiogen = empty_tree.in_order()\n\tgenlist = []\n\tfor n in iogen:\n\t\tgenlist.append(n)\n\tassert genlist == []\n\n", "description": null, "category": "simple", "imports": ["from bst import BinaryTree", "import pytest"]}, {"term": "def", "name": "test_in_order_traversal_simple_tree", "data": "def test_in_order_traversal_simple_tree(simple_tree):\n\tiogen = simple_tree.in_order()\n\tgenlist = []\n\tfor n in iogen:\n\t\tgenlist.append(n)\n\tassert genlist == [2, 5, 10, 17]\n\n", "description": null, "category": "simple", "imports": ["from bst import BinaryTree", "import pytest"]}, {"term": "def", "name": "test_post_order_traversal_empty", "data": "def test_post_order_traversal_empty(empty_tree):\n\tiogen = empty_tree.post_order()\n\tgenlist = []\n\tfor n in iogen:\n\t\tgenlist.append(n)\n\tassert genlist == []\n\n", "description": null, "category": "simple", "imports": ["from bst import BinaryTree", "import pytest"]}, {"term": "def", "name": "test_post_order_traversal_simple_tree", "data": "def test_post_order_traversal_simple_tree(simple_tree):\n\tiogen = simple_tree.post_order()\n\tgenlist = []\n\tfor n in iogen:\n\t\tgenlist.append(n)\n\tassert genlist == [2, 17, 10, 5]\n\n", "description": null, "category": "simple", "imports": ["from bst import BinaryTree", "import pytest"]}, {"term": "def", "name": "test_pre_order_traversal_empty", "data": "def test_pre_order_traversal_empty(empty_tree):\n\tgenlist = []\n\tfor n in empty_tree.pre_order():\n\t\tgenlist.append(n)\n\tassert genlist == []\n\n", "description": null, "category": "simple", "imports": ["from bst import BinaryTree", "import pytest"]}, {"term": "def", "name": "test_pre_order_traversal_simple_tree", "data": "def test_pre_order_traversal_simple_tree(simple_tree):\n\tiogen = simple_tree.pre_order()\n\tgenlist = []\n\tfor n in iogen:\n\t\tgenlist.append(n)\n\tassert genlist == [5, 2, 10, 17]\n\n", "description": null, "category": "simple", "imports": ["from bst import BinaryTree", "import pytest"]}, {"term": "def", "name": "test_breadth_first_traversal_empty", "data": "def test_breadth_first_traversal_empty(empty_tree):\n\tiogen = empty_tree.breadth_first()\n\tgenlist = []\n\tfor n in iogen:\n\t\tgenlist.append(n)\n\tassert genlist == []\n\n", "description": null, "category": "simple", "imports": ["from bst import BinaryTree", "import pytest"]}, {"term": "def", "name": "test_breadth_first_traversal_simple_tree", "data": "def test_breadth_first_traversal_simple_tree(simple_tree):\n\tiogen = simple_tree.breadth_first()\n\tgenlist = []\n\tfor n in iogen:\n\t\tgenlist.append(n)\n\tassert genlist == [5, 2, 10, 17]\n\n", "description": null, "category": "simple", "imports": ["from bst import BinaryTree", "import pytest"]}], [{"term": "class", "name": "Punctuation", "data": "class Punctuation(object):\n\t\"\"\"A class reprensenting a punctuation model.\n\t\"\"\"\n\tlogger = logging.getLogger(\"Asrt.Punctuation\")\n\n\tdefault_puncutation = [\n\t\t(r\"\\.\" , SIMPLE_t, \"point\"),\n\t\t(r\"\\,\" , SIMPLE_t, \"virgule\"),\n\t\t(r\"\\;\" , SIMPLE_t, \"point virgule\"),\n\t\t(r\"\\:\" , SIMPLE_t, \"deux points\"),\n\t\t(r\"\\n\" , SIMPLE_t, \"\u00e0 la ligne\"),\n\t\t(r\"\\r\\n\" , SIMPLE_t, \"\u00e0 la ligne\"),\n\t\t(r\"\\((\\S+)\\)\" , PREFIX_t, \"entre parenth\u00e8ses\"),\n\t\t(r\"\\\"(\\S+)\\\"\" , PREFIX_t, \"entre guillemets\"),\n\t\t(r\"\\?\" , SIMPLE_t, \"point d'interrogation\"),\n\t\t(r\"\\!\" , SIMPLE_t, \"point d'exclamation\"),\n\t\t(r\"\\((\\S+)\\s\" , PREFIX_t, \"ouvrez la parenth\u00e8se\"),\n\t\t(r\"\\\"(\\S+)\\s\" , PREFIX_t, \"ouvrez les guillemets\"),\n\t\t(r\"\\s(\\S+)\\)\" , POSTFIX_t, \"fermez la parenth\u00e8se\"),\n\t\t(r\"\\s(\\S+)\\\"\" , POSTFIX_t, \"fermez les guillemets\"),\n\t\t(r\"(?:\\s|^)-(?:\\s|)\" , SIMPLE_t, \"tiret\") ]\n\n\tdefault_reverse = [\n\t\t(r\"(?:\\s|^)point\\svirgule(?:\\s|)\" , SIMPLE_t, \";\"),\n\t\t(r\"(?:\\s|^)deux\\spoints(?:\\s|)\" , SIMPLE_t, \":\"),\n\t\t(r\"(?:\\s|^)double\\spoints(?:\\s|)\", SIMPLE_t, \":\"),\n\t\t(r\"(?:\\s|^)retour\\s\u00e0\\sla\\sligne(?:\\s|)\", SIMPLE_t, \"\\n\"),\n\t\t(r\"(?:\\s|^)\u00e0\\sla\\sligne(?:\\s|)\" , SIMPLE_t, \"\\n\"),\n\t\t(r\"(?:\\s|^)entre\\sparenth\u00e8ses\\s(\\S+)(?:\\s|)\" , MIDDLE_t, \"()\"),\n\t\t(r\"(?:\\s|^)entre\\sguillemets\\s(\\S+)(?:\\s|)\" , MIDDLE_t, \"\\\"\\\"\"),\n\t\t(r\"(?:\\s|^)point\\sd'interrogation(?:\\s|)\" , SIMPLE_t, \"?\"),\n\t\t(r\"(?:\\s|^)point\\sd'exclamation(?:\\s|)\" , SIMPLE_t, \"!\"),\n\t\t(r\"(?:\\s|^)ouvrez\\sla\\sparenth\u00e8se(?:\\s|)\" , SIMPLE_NSR_t, \"(\"),\n\t\t(r\"(?:\\s|^)ouvrez\\sles\\sguillemets(?:\\s|)\" , SIMPLE_NSR_t, \"\\\"\"),\n\t\t(r\"(?:\\s|^)fermez\\sla\\sparenth\u00e8se(?:\\s|)\" , SIMPLE_NSL_t, \")\"),\n\t\t(r\"(?:\\s|^)fermez\\sles\\sguillemets(?:\\s|)\" , SIMPLE_NSL_t, \"\\\"\"),\n\t\t(r\"(?:\\s|^)point(?:\\s|)\" , SIMPLE_t, \".\"),\n\t\t(r\"(?:\\s|^)virgule(?:\\s|)\" , SIMPLE_t, \",\"),\n\t\t(r\"(?:\\s|^)tiret(?:\\s|)\" , SIMPLE_t, \"-\") ]\n\n\tdefault_remove = [\n\t\t(r\"(?:\\s|^)point\\svirgule(?:\\s|)\" , SIMPLE_t, \" \"),\n\t\t(r\"(?:\\s|^)deux\\spoints(?:\\s|)\" , SIMPLE_t, \" \"),\n\t\t(r\"(?:\\s|^)double\\spoints(?:\\s|)\", SIMPLE_t, \" \"),\n\t\t(r\"(?:\\s|^)retour\\s\u00e0\\sla\\sligne(?:\\s|)\", SIMPLE_t, \" \"),\n\t\t(r\"(?:\\s|^)\u00e0\\sla\\sligne(?:\\s|)\" , SIMPLE_t, \" \"),\n\t\t(r\"(?:\\s|^)entre\\sparenth\u00e8ses\\s(\\S+)(?:\\s|)\" , MIDDLE_t, \"  \"),\n\t\t(r\"(?:\\s|^)entre\\sguillemets\\s(\\S+)(?:\\s|)\" , MIDDLE_t, \"  \"),\n\t\t(r\"(?:\\s|^)point\\sd'interrogation(?:\\s|)\" , SIMPLE_t, \" \"),\n\t\t(r\"(?:\\s|^)point\\sd'exclamation(?:\\s|)\" , SIMPLE_t, \" \"),\n\t\t(r\"(?:\\s|^)ouvrez\\sla\\sparenth\u00e8se(?:\\s|)\" , SIMPLE_NSR_t, \" \"),\n\t\t(r\"(?:\\s|^)ouvrez\\sles\\sguillemets(?:\\s|)\" , SIMPLE_NSR_t, \" \"),\n\t\t(r\"(?:\\s|^)fermez\\sla\\sparenth\u00e8se(?:\\s|)\" , SIMPLE_NSL_t, \" \"),\n\t\t(r\"(?:\\s|^)fermez\\sles\\sguillemets(?:\\s|)\" , SIMPLE_NSL_t, \" \"),\n\t\t(r\"(?:\\s|^)point(?:\\s|)\" , SIMPLE_t, \" \"),\n\t\t(r\"(?:\\s|^)virgule(?:\\s|)\" , SIMPLE_t, \" \"),\n\t\t(r\"(?:\\s|^)tiret(?:\\s|)\" , SIMPLE_t, \" \") ]\n\n\tdef __init__(self, punctuation_model = None, reverse_model = None):\n\t\t\"\"\"Constructor\n\t\t\t\tpunctuation_model\t   take a list containing the\n\t\t\t\t\t\t\t\t\t\t\tpunctuation if not provided will take\n\t\t\t\t\t\t\t\t\t\t\tthe default (default_punctuation)\n\t\t\"\"\"\n\t\tif punctuation_model :\n\t\t\tself.punctuation = punctuation_model\n\t\telse:\n\t\t\tself.punctuation = self.default_puncutation\n\t\tif reverse_model :\n\t\t\tself.reverse = reverse_model\n\t\telse:\n\t\t\tself.reverse = self.default_reverse\n\n\t########################\n\t# Private interface\n\t#\n\tdef __simpleRepl(self, match):\n\t\t\"\"\" just replace with the text no word associated with it\n\t\t\"\"\"\n\t\treturn ' ' + self.replace_temp + ' '\n\n\tdef __simpleNSRepl(self, match):\n\t\t\"\"\" replace with the text and remove all space\n\t\t\"\"\"\n\t\treturn self.replace_temp\n\n\tdef __simpleNSRRepl(self, match):\n\t\t\"\"\" replace with no space on the right\n\t\t\"\"\"\n\t\treturn ' ' + self.replace_temp\n\n\tdef __simpleNSLRepl(self, match):\n\t\t\"\"\" replace with no space on the left\n\t\t\"\"\"\n\t\treturn self.replace_temp + ' '\n\n\tdef __prefixRepl(self, match):\n\t\t\"\"\" replace a value prefixed with some text\n\t\t\"\"\"\n\t\treturn ' ' + self.replace_temp + ' ' + match.group(1) + ' '\n\n\tdef __postfixRepl(self, match):\n\t\t\"\"\" replace a valus postfixed with some text\n\t\t\"\"\"\n\t\treturn ' ' + match.group(1) + ' ' + self.replace_temp + ' '\n\n\tdef __middleRepl(self, match):\n\t\t\"\"\" replace a value in the middle of a text\n\t\t\"\"\"\n\t\treturn ' ' + self.replace_temp[0] + match.group(1).strip() + self.replace_temp[1] + ' '\n\n\tdef __replaceList(self, list_word, input_text):\n\t\t\"\"\" replace a list of word by another using regexp\n\t\t\"\"\"\n\t\toutput_text = input_text\n\t\tfor elem in list_word :\n\t\t\tkey = elem[0]\n\t\t\tkind = elem[1]\n\t\t\tvalue = elem[2]\n\t\t\t# cheat to pass value to the repl\n\t\t\tself.replace_temp = value\n\t\t\tif kind == SIMPLE_t :\n\t\t\t\toutput_text = re.sub(key, self.__simpleRepl, output_text)\n\t\t\telif kind == SIMPLE_NS_t :\n\t\t\t\toutput_text = re.sub(key, self.__simpleNSRepl, output_text)\n\t\t\telif kind == SIMPLE_NSR_t :\n\t\t\t\toutput_text = re.sub(key, self.__simpleNSRRepl, output_text)\n\t\t\telif kind == SIMPLE_NSL_t :\n\t\t\t\toutput_text = re.sub(key, self.__simpleNSLRepl, output_text)\n\t\t\telif kind == MIDDLE_t :\n\t\t\t\toutput_text = re.sub(key, self.__middleRepl, output_text)\n\t\t\telif kind == PREFIX_t :\n\t\t\t\toutput_text = re.sub(key, self.__prefixRepl, output_text)\n\t\t\telif kind == POSTFIX_t :\n\t\t\t\toutput_text = re.sub(key, self.__postfixRepl, output_text)\n\t\tsplit_text = output_text.split()\n\t\treturn \" \".join(split_text)\n\n\t########################\n\t# Public interface\n\t#\n\tdef countPresenceText(self, input_text):\n\t\t\"\"\"Count the presence of all the punctuation in the punctuation model\n\t\t\tpresent in the [input_text]\n\t\t\t\treturn\t\t\t\t  dictionary containing key and count\n\t\t\"\"\"\n\t\tcount_dict = {}\n\t\tfor elem in self.punctuation :\n\t\t\tkey = elem[0]\n\t\t\tvalue = elem[2]\n\t\t\tcount = len(re.findall(key, input_text))\n\t\t\tif count :\n\t\t\t\tcount_dict[value] = count\n\t\treturn count_dict\n\n\tdef countPresentFile(self, input_file):\n\t\t\"\"\"Count the presence of all the punctuation in the punctuation model\n\t\t\tpresent in the file named [input_file]\n\t\t\t\tinput_file\t\t\t  Input file to be used as source\n\t\t\t\treturn\t\t\t\t  dictionary containing key and count\n\t\t\"\"\"\n\t\ttry:\n\t\t\tio = Ioread()\n\t\t\tfile_content = io.readFileContent(input_file)\n\t\t\treturn self.countPresenceText(file_content)\n\t\texcept Exception as e :\n\t\t\tprint((\"exception<\" + input_file + \"> : \" + str(e)))\n\t\t\treturn {}\n\n\tdef symbolText(self, input_text):\n\t\t\"\"\"check for verbalisation of punctuation and replace it with apropriate\n\t\t\tsymbol.\n\t\t\t\treturn\t\t\t\t  the modified text.\n\t\t\"\"\"\n\t\treturn self.__replaceList(self.reverse, input_text)\n\n\tdef replaceText(self, input_text):\n\t\t\"\"\"Replace the punctuation in the text by the one in the punctuation\n\t\t\tmodel\n\t\t\t\treturn\t\t\t\t  the modified text.\n\t\t\"\"\"\n\t\treturn self.__replaceList(self.punctuation, input_text)\n\n\tdef removeVerbalized(self, input_text):\n\t\t\"\"\"Remove verbalized punctuation.\n\n\t\t   return the text without punctuation\n\t\t\"\"\"\n\t\toutput_text = self.__replaceList(self.default_remove, input_text)\n\t\treturn \" \".join(output_text.split())\n\n\tdef replaceFile(self, input_file, output_file = None):\n\t\t\"\"\"Replace the punctuation in the file named [input_file] and return the\n\t\t\tresult in the file named [output_file]\n\t\t\t\tinput_file\t\t\t  Input file to be used as source\n\t\t\t\toutput_file\t\t\t Output file (if None return Text\n\t\t\t\treturn\t\t\t\t  True if success False is failure in case\n\t\t\t\t\t\t\t\t\t\t\toutput_file is present output_text if\n\t\t\t\t\t\t\t\t\t\t\tnot present\n\t\t\"\"\"\n\t\ttry:\n\t\t\tio = Ioread()\n\t\t\tinput_text = io.readFileContent(input_file)\n\t\t\tif output_file :\n\t\t\t\tf = open(output_file, \"w\")\n\t\t\t\tf.write(self.replaceText(input_text))\n\t\t\t\treturn True\n\t\t\telse:\n\t\t\t\treturn self.replaceText(input_text)\n\t\texcept Exception as e :\n\t\t\tprint((\"exception<\" + input_file + \"> : \" + str(e)))\n\t\t\tif output_file :\n\t\t\t\treturn False\n\t\t\telse :\n\t\t\t\treturn None\n", "description": "A class reprensenting a punctuation model.\n\t", "category": "simple", "imports": ["import sys", "import re, logging", "from asrt.common.ioread import Ioread"]}], [{"term": "def", "name": "write", "data": "def write():\n\tprint('Creating new text file') \n\n\tfo = open('simple_survey.input', 'w+', 0)\n\tfo.write('question' + '\\t' + 'choice1' + '\\t' + 'choice2' + '\\n' + question + '\\t' + a + '\\t' + b)\n\tfo.close()\n", "description": null, "category": "simple", "imports": ["import sys", "import os", "import subprocess", "import time", "from shutil import copyfile"]}, {"term": "def", "name": "mkNewDirs", "data": "def mkNewDirs(): \n\tos.system(\"rm -rf \" + newPath)\n\tos.mkdir(newPath)\n\tcopyfile(path + 'simple_survey.properties', \n\t\tnewPath + 'simple_survey.properties')\n\tcopyfile(path + 'simple_survey.input', \n\t\tnewPath + 'simple_survey.input')\n\tcopyfile(path + 'simple_survey.question', \n\t\tnewPath + 'simple_survey.question')\n\tcopyfile(path + 'getResults.sh', \n\t\tnewPath + 'getResults.sh')\n", "description": null, "category": "simple", "imports": ["import sys", "import os", "import subprocess", "import time", "from shutil import copyfile"]}, {"term": "def", "name": "run", "data": "def run(): \n\tprint binPath\n\tos.chdir(binPath)\n\texecutable = \"./loadHITs.sh $1 $2 $3 $4 $5 $6 $7 $8 $9 -label ../samples/simple_survey/simple_survey -input ../samples/simple_survey/newDir\" + str(t) + '/' + \"simple_survey.input -question ../samples/simple_survey/newDir\" + str(t) + '/' + \"simple_survey.question -properties ../samples/simple_survey/newDir\" + str(t) + '/' + \"simple_survey.properties\"\n\tos.system(executable)\n\tos.chdir(path)\n", "description": null, "category": "simple", "imports": ["import sys", "import os", "import subprocess", "import time", "from shutil import copyfile"]}, {"term": "def", "name": "checkIfFinished", "data": "def checkIfFinished():\n\tos.chdir(newPath)\n\tfo = open('simple_survey.results')\n\tlines = len(fo.readlines())\n\tprint \"lines: \" + str(lines)\n\treturn lines == n+1\n", "description": null, "category": "simple", "imports": ["import sys", "import os", "import subprocess", "import time", "from shutil import copyfile"]}, {"term": "def", "name": "getResults", "data": "def getResults(): \n\tos.chdir(binPath)\n\texecutable = \"./getResults.sh $1 $2 $3 $4 $5 $6 $7 $8 $9 -successfile ../samples/simple_survey/newDir\" + str(t) + '/' + \"simple_survey.success -outputfile ../samples/simple_survey/newDir\" + str(t) + '/' + \"simple_survey.results\"\n\tprint (executable)\n\tos.system(executable)\n\tos.chdir(path)\n", "description": null, "category": "simple", "imports": ["import sys", "import os", "import subprocess", "import time", "from shutil import copyfile"]}, {"term": "def", "name": "moveSuccess", "data": "def moveSuccess():\n\tcopyfile(path + 'simple_survey.success', \n\t\tnewPath + 'simple_survey.success')\n", "description": null, "category": "simple", "imports": ["import sys", "import os", "import subprocess", "import time", "from shutil import copyfile"]}, {"term": "def", "name": "getDataStructure", "data": "def getDataStructure():\n\tarray_of_tuples = []\n\t#for i in range(n-1):\n\t#\tarray_of_tuples.append((0, \"not submitted yet\"))\n\n\tos.chdir(newPath)\n\tfo = open('simple_survey.results')\n\tcontent = fo.readlines()\n\tcells = str(content[0]).split(\"\\t\")\n\tcolumn1 = 0;\n\tcolumn2 = 0;\n\ti = 0;\n\twhile (column1 == 0 or column2 == 0):\n\t\tprint cells[i]\n\t\tif (str(cells[i]).find(\"Answer.1\") != -1):\n\t\t\tcolumn1 = i\n\t\t\tprint \"1\"\n\t\tif (str(cells[i]).find(\"Answer.2\") != -1):\n\t\t\tcolumn2 = i\n\t\t\tprint \"2\"\n\t\ti = i + 1\n\tprint \"column1:\" + str(column1)\n\tprint \"column2:\" + str(column2)\n\tj = 0\n\twhile (j < n):\n\t\tline = content[j+1].split(\"\\t\")\n\t\titem1 = line[column1].rstrip('\\n')\n\t\titem2 = line[column2].rstrip('\\n')\n\t\tif (item1 == \"\"):\n\t\t\titem1 = \"testResponse\"\n\t\tif (item2 == \"\"):\n\t\t\titem2 = \"testResponse\"\n\t\tarray_of_tuples.append((item1,item2))\n\t\tprint array_of_tuples[j]\n\t\tj = j + 1\n\tprint array_of_tuples\n\treturn array_of_tuples\n", "description": null, "category": "simple", "imports": ["import sys", "import os", "import subprocess", "import time", "from shutil import copyfile"]}, {"term": "def", "name": "initialMain", "data": "def initialMain():\n\tos.chdir(path)\n\twrite()\n\tmkNewDirs()\n\trun()\n", "description": null, "category": "simple", "imports": ["import sys", "import os", "import subprocess", "import time", "from shutil import copyfile"]}, {"term": "def", "name": "main", "data": "def main():\n\tinitialMain()\n\tmoveSuccess()\n\tgetResults()\n\twhile (not checkIfFinished()):\n\t\ttime.sleep(600)\n\t\tprint \"waiting\"\n\t\tgetResults()\n\tprint \"results returned\"\n\tdataStructure = getDataStructure()\n\treturn dataStructure\n", "description": null, "category": "simple", "imports": ["import sys", "import os", "import subprocess", "import time", "from shutil import copyfile"]}], [{"term": "def", "name": "write", "data": "def write():\n\tprint('Creating new text file') \n\n\tfo = open('simple_survey.input', 'w+', 0)\n\tfo.write('question' + '\\t' + 'choice1' + '\\t' + 'choice2' + '\\n' + question + '\\t' + a + '\\t' + b)\n\tfo.close()\n", "description": null, "category": "simple", "imports": ["import sys", "import os", "import subprocess", "import time", "from shutil import copyfile"]}, {"term": "def", "name": "mkNewDirs", "data": "def mkNewDirs(): \n\tos.system(\"rm -rf \" + newPath)\n\tos.mkdir(newPath)\n\tcopyfile(path + 'simple_survey.properties', \n\t\tnewPath + 'simple_survey.properties')\n\tcopyfile(path + 'simple_survey.input', \n\t\tnewPath + 'simple_survey.input')\n\tcopyfile(path + 'simple_survey.question', \n\t\tnewPath + 'simple_survey.question')\n\tcopyfile(path + 'getResults.sh', \n\t\tnewPath + 'getResults.sh')\n", "description": null, "category": "simple", "imports": ["import sys", "import os", "import subprocess", "import time", "from shutil import copyfile"]}, {"term": "def", "name": "run", "data": "def run(): \n\tprint binPath\n\tos.chdir(binPath)\n\texecutable = \"./loadHITs.sh $1 $2 $3 $4 $5 $6 $7 $8 $9 -label ../samples/simple_survey/simple_survey -input ../samples/simple_survey/newDir\" + str(t) + '/' + \"simple_survey.input -question ../samples/simple_survey/newDir\" + str(t) + '/' + \"simple_survey.question -properties ../samples/simple_survey/newDir\" + str(t) + '/' + \"simple_survey.properties\"\n\tos.system(executable)\n\tos.chdir(path)\n", "description": null, "category": "simple", "imports": ["import sys", "import os", "import subprocess", "import time", "from shutil import copyfile"]}, {"term": "def", "name": "checkIfFinished", "data": "def checkIfFinished():\n\tos.chdir(newPath)\n\tfo = open('simple_survey.results')\n\tlines = len(fo.readlines())\n\tprint \"lines: \" + str(lines)\n\treturn lines == n+1\n", "description": null, "category": "simple", "imports": ["import sys", "import os", "import subprocess", "import time", "from shutil import copyfile"]}, {"term": "def", "name": "getResults", "data": "def getResults(): \n\tos.chdir(binPath)\n\texecutable = \"./getResults.sh $1 $2 $3 $4 $5 $6 $7 $8 $9 -successfile ../samples/simple_survey/newDir\" + str(t) + '/' + \"simple_survey.success -outputfile ../samples/simple_survey/newDir\" + str(t) + '/' + \"simple_survey.results\"\n\tprint (executable)\n\tos.system(executable)\n\tos.chdir(path)\n", "description": null, "category": "simple", "imports": ["import sys", "import os", "import subprocess", "import time", "from shutil import copyfile"]}, {"term": "def", "name": "moveSuccess", "data": "def moveSuccess():\n\tcopyfile(path + 'simple_survey.success', \n\t\tnewPath + 'simple_survey.success')\n", "description": null, "category": "simple", "imports": ["import sys", "import os", "import subprocess", "import time", "from shutil import copyfile"]}, {"term": "def", "name": "getDataStructure", "data": "def getDataStructure():\n\tarray_of_tuples = []\n\t#for i in range(n-1):\n\t#\tarray_of_tuples.append((0, \"not submitted yet\"))\n\n\tos.chdir(newPath)\n\tfo = open('simple_survey.results')\n\tcontent = fo.readlines()\n\tcells = str(content[0]).split(\"\\t\")\n\tcolumn1 = 0;\n\tcolumn2 = 0;\n\ti = 0;\n\twhile (column1 == 0 or column2 == 0):\n\t\tprint cells[i]\n\t\tif (str(cells[i]).find(\"Answer.1\") != -1):\n\t\t\tcolumn1 = i\n\t\t\tprint \"1\"\n\t\tif (str(cells[i]).find(\"Answer.2\") != -1):\n\t\t\tcolumn2 = i\n\t\t\tprint \"2\"\n\t\ti = i + 1\n\tprint \"column1:\" + str(column1)\n\tprint \"column2:\" + str(column2)\n\tj = 0\n\twhile (j < n):\n\t\tline = content[j+1].split(\"\\t\")\n\t\titem1 = line[column1].rstrip('\\n')\n\t\titem2 = line[column2].rstrip('\\n')\n\t\tif (item1 == \"\"):\n\t\t\titem1 = \"testResponse\"\n\t\tif (item2 == \"\"):\n\t\t\titem2 = \"testResponse\"\n\t\tarray_of_tuples.append((item1,item2))\n\t\tprint array_of_tuples[j]\n\t\tj = j + 1\n\tprint array_of_tuples\n\treturn array_of_tuples\n", "description": null, "category": "simple", "imports": ["import sys", "import os", "import subprocess", "import time", "from shutil import copyfile"]}, {"term": "def", "name": "initialMain", "data": "def initialMain():\n\tos.chdir(path)\n\twrite()\n\tmkNewDirs()\n\trun()\n", "description": null, "category": "simple", "imports": ["import sys", "import os", "import subprocess", "import time", "from shutil import copyfile"]}, {"term": "def", "name": "main", "data": "def main():\n\tinitialMain()\n\tmoveSuccess()\n\tgetResults()\n\twhile (not checkIfFinished()):\n\t\ttime.sleep(600)\n\t\tprint \"waiting\"\n\t\tgetResults()\n\tprint \"results returned\"\n\tdataStructure = getDataStructure()\n\treturn dataStructure\n", "description": null, "category": "simple", "imports": ["import sys", "import os", "import subprocess", "import time", "from shutil import copyfile"]}], [], [{"term": "class", "name": "CustomFilterTests", "data": "class CustomFilterTests(SimpleTestCase):\n\n\tdef test_filter(self):\n\t\tengine = Engine(libraries=LIBRARIES)\n\t\tt = engine.from_string(\"{% load custom %}{{ string|trim:5 }}\")\n\t\tself.assertEqual(\n\t\t\tt.render(Context({\"string\": \"abcdefghijklmnopqrstuvwxyz\"})),\n\t\t\t\"abcde\"\n\t\t)\n\n\tdef test_decorated_filter(self):\n\t\tengine = Engine(libraries=LIBRARIES)\n\t\tt = engine.from_string('{% load custom %}{{ name|make_data_div }}')\n\t\tself.assertEqual(t.render(Context({'name': 'foo'})), '')\n\n", "description": null, "category": "simple", "imports": ["import os", "from django.template import Context, Engine, TemplateSyntaxError", "from django.template.base import Node", "from django.template.library import InvalidTemplateLibrary", "from django.test import SimpleTestCase", "from django.test.utils import extend_sys_path", "from .templatetags import custom, inclusion", "from .utils import ROOT", "\t\t\t\"trying to load 'template_tests.broken_tag': cannot import name \"", "\t\t\t\"import name 'Xtemplate'\""]}, {"term": "class", "name": "TagTestCase", "data": "class TagTestCase(SimpleTestCase):\n\n\t@classmethod\n\tdef setUpClass(cls):\n\t\tcls.engine = Engine(app_dirs=True, libraries=LIBRARIES)\n\t\tsuper().setUpClass()\n\n\tdef verify_tag(self, tag, name):\n\t\tself.assertEqual(tag.__name__, name)\n\t\tself.assertEqual(tag.__doc__, 'Expected %s __doc__' % name)\n\t\tself.assertEqual(tag.__dict__['anything'], 'Expected %s __dict__' % name)\n\n", "description": null, "category": "simple", "imports": ["import os", "from django.template import Context, Engine, TemplateSyntaxError", "from django.template.base import Node", "from django.template.library import InvalidTemplateLibrary", "from django.test import SimpleTestCase", "from django.test.utils import extend_sys_path", "from .templatetags import custom, inclusion", "from .utils import ROOT", "\t\t\t\"trying to load 'template_tests.broken_tag': cannot import name \"", "\t\t\t\"import name 'Xtemplate'\""]}, {"term": "class", "name": "SimpleTagTests", "data": "class SimpleTagTests(TagTestCase):\n\n\tdef test_simple_tags(self):\n\t\tc = Context({'value': 42})\n\n\t\ttemplates = [\n\t\t\t('{% load custom %}{% no_params %}', 'no_params - Expected result'),\n\t\t\t('{% load custom %}{% one_param 37 %}', 'one_param - Expected result: 37'),\n\t\t\t('{% load custom %}{% explicit_no_context 37 %}', 'explicit_no_context - Expected result: 37'),\n\t\t\t('{% load custom %}{% no_params_with_context %}',\n\t\t\t\t'no_params_with_context - Expected result (context value: 42)'),\n\t\t\t('{% load custom %}{% params_and_context 37 %}',\n\t\t\t\t'params_and_context - Expected result (context value: 42): 37'),\n\t\t\t('{% load custom %}{% simple_two_params 37 42 %}', 'simple_two_params - Expected result: 37, 42'),\n\t\t\t('{% load custom %}{% simple_keyword_only_param kwarg=37 %}',\n\t\t\t\t'simple_keyword_only_param - Expected result: 37'),\n\t\t\t('{% load custom %}{% simple_keyword_only_default %}',\n\t\t\t\t'simple_keyword_only_default - Expected result: 42'),\n\t\t\t(\n\t\t\t\t'{% load custom %}{% simple_keyword_only_default kwarg=37 %}',\n\t\t\t\t'simple_keyword_only_default - Expected result: 37',\n\t\t\t),\n\t\t\t('{% load custom %}{% simple_one_default 37 %}', 'simple_one_default - Expected result: 37, hi'),\n\t\t\t('{% load custom %}{% simple_one_default 37 two=\"hello\" %}',\n\t\t\t\t'simple_one_default - Expected result: 37, hello'),\n\t\t\t('{% load custom %}{% simple_one_default one=99 two=\"hello\" %}',\n\t\t\t\t'simple_one_default - Expected result: 99, hello'),\n\t\t\t('{% load custom %}{% simple_one_default 37 42 %}',\n\t\t\t\t'simple_one_default - Expected result: 37, 42'),\n\t\t\t('{% load custom %}{% simple_unlimited_args 37 %}', 'simple_unlimited_args - Expected result: 37, hi'),\n\t\t\t('{% load custom %}{% simple_unlimited_args 37 42 56 89 %}',\n\t\t\t\t'simple_unlimited_args - Expected result: 37, 42, 56, 89'),\n\t\t\t('{% load custom %}{% simple_only_unlimited_args %}', 'simple_only_unlimited_args - Expected result: '),\n\t\t\t('{% load custom %}{% simple_only_unlimited_args 37 42 56 89 %}',\n\t\t\t\t'simple_only_unlimited_args - Expected result: 37, 42, 56, 89'),\n\t\t\t('{% load custom %}{% simple_unlimited_args_kwargs 37 40|add:2 56 eggs=\"scrambled\" four=1|add:3 %}',\n\t\t\t\t'simple_unlimited_args_kwargs - Expected result: 37, 42, 56 / eggs=scrambled, four=4'),\n\t\t]\n\n\t\tfor entry in templates:\n\t\t\tt = self.engine.from_string(entry[0])\n\t\t\tself.assertEqual(t.render(c), entry[1])\n\n\t\tfor entry in templates:\n\t\t\tt = self.engine.from_string(\"%s as var %%}Result: {{ var }}\" % entry[0][0:-2])\n\t\t\tself.assertEqual(t.render(c), \"Result: %s\" % entry[1])\n\n\tdef test_simple_tag_errors(self):\n\t\terrors = [\n\t\t\t(\"'simple_one_default' received unexpected keyword argument 'three'\",\n\t\t\t\t'{% load custom %}{% simple_one_default 99 two=\"hello\" three=\"foo\" %}'),\n\t\t\t(\"'simple_two_params' received too many positional arguments\",\n\t\t\t\t'{% load custom %}{% simple_two_params 37 42 56 %}'),\n\t\t\t(\"'simple_one_default' received too many positional arguments\",\n\t\t\t\t'{% load custom %}{% simple_one_default 37 42 56 %}'),\n\t\t\t(\"'simple_keyword_only_param' did not receive value(s) for the argument(s): 'kwarg'\",\n\t\t\t\t'{% load custom %}{% simple_keyword_only_param %}'),\n\t\t\t(\n\t\t\t\t\"'simple_keyword_only_param' received multiple values for \"\n\t\t\t\t\"keyword argument 'kwarg'\",\n\t\t\t\t'{% load custom %}{% simple_keyword_only_param kwarg=42 '\n\t\t\t\t'kwarg=37 %}',\n\t\t\t),\n\t\t\t(\n\t\t\t\t\"'simple_keyword_only_default' received multiple values for \"\n\t\t\t\t\"keyword argument 'kwarg'\",\n\t\t\t\t'{% load custom %}{% simple_keyword_only_default kwarg=42 '\n\t\t\t\t'kwarg=37 %}',\n\t\t\t),\n\t\t\t(\"'simple_unlimited_args_kwargs' received some positional argument(s) after some keyword argument(s)\",\n\t\t\t\t'{% load custom %}{% simple_unlimited_args_kwargs 37 40|add:2 eggs=\"scrambled\" 56 four=1|add:3 %}'),\n\t\t\t(\"'simple_unlimited_args_kwargs' received multiple values for keyword argument 'eggs'\",\n\t\t\t\t'{% load custom %}{% simple_unlimited_args_kwargs 37 eggs=\"scrambled\" eggs=\"scrambled\" %}'),\n\t\t]\n\n\t\tfor entry in errors:\n\t\t\twith self.assertRaisesMessage(TemplateSyntaxError, entry[0]):\n\t\t\t\tself.engine.from_string(entry[1])\n\n\t\tfor entry in errors:\n\t\t\twith self.assertRaisesMessage(TemplateSyntaxError, entry[0]):\n\t\t\t\tself.engine.from_string(\"%s as var %%}\" % entry[1][0:-2])\n\n\tdef test_simple_tag_escaping_autoescape_off(self):\n\t\tc = Context({'name': \"Jack & Jill\"}, autoescape=False)\n\t\tt = self.engine.from_string(\"{% load custom %}{% escape_naive %}\")\n\t\tself.assertEqual(t.render(c), \"Hello Jack & Jill!\")\n\n\tdef test_simple_tag_naive_escaping(self):\n\t\tc = Context({'name': \"Jack & Jill\"})\n\t\tt = self.engine.from_string(\"{% load custom %}{% escape_naive %}\")\n\t\tself.assertEqual(t.render(c), \"Hello Jack & Jill!\")\n\n\tdef test_simple_tag_explicit_escaping(self):\n\t\t# Check we don't double escape\n\t\tc = Context({'name': \"Jack & Jill\"})\n\t\tt = self.engine.from_string(\"{% load custom %}{% escape_explicit %}\")\n\t\tself.assertEqual(t.render(c), \"Hello Jack & Jill!\")\n\n\tdef test_simple_tag_format_html_escaping(self):\n\t\t# Check we don't double escape\n\t\tc = Context({'name': \"Jack & Jill\"})\n\t\tt = self.engine.from_string(\"{% load custom %}{% escape_format_html %}\")\n\t\tself.assertEqual(t.render(c), \"Hello Jack & Jill!\")\n\n\tdef test_simple_tag_registration(self):\n\t\t# The decorators preserve the decorated function's docstring, name,\n\t\t# and attributes.\n\t\tself.verify_tag(custom.no_params, 'no_params')\n\t\tself.verify_tag(custom.one_param, 'one_param')\n\t\tself.verify_tag(custom.explicit_no_context, 'explicit_no_context')\n\t\tself.verify_tag(custom.no_params_with_context, 'no_params_with_context')\n\t\tself.verify_tag(custom.params_and_context, 'params_and_context')\n\t\tself.verify_tag(custom.simple_unlimited_args_kwargs, 'simple_unlimited_args_kwargs')\n\t\tself.verify_tag(custom.simple_tag_without_context_parameter, 'simple_tag_without_context_parameter')\n\n\tdef test_simple_tag_missing_context(self):\n\t\t# The 'context' parameter must be present when takes_context is True\n\t\tmsg = (\n\t\t\t\"'simple_tag_without_context_parameter' is decorated with \"\n\t\t\t\"takes_context=True so it must have a first argument of 'context'\"\n\t\t)\n\t\twith self.assertRaisesMessage(TemplateSyntaxError, msg):\n\t\t\tself.engine.from_string('{% load custom %}{% simple_tag_without_context_parameter 123 %}')\n\n", "description": null, "category": "simple", "imports": ["import os", "from django.template import Context, Engine, TemplateSyntaxError", "from django.template.base import Node", "from django.template.library import InvalidTemplateLibrary", "from django.test import SimpleTestCase", "from django.test.utils import extend_sys_path", "from .templatetags import custom, inclusion", "from .utils import ROOT", "\t\t\t\"trying to load 'template_tests.broken_tag': cannot import name \"", "\t\t\t\"import name 'Xtemplate'\""]}, {"term": "class", "name": "InclusionTagTests", "data": "class InclusionTagTests(TagTestCase):\n\n\tdef test_inclusion_tags(self):\n\t\tc = Context({'value': 42})\n\n\t\ttemplates = [\n\t\t\t('{% load inclusion %}{% inclusion_no_params %}', 'inclusion_no_params - Expected result\\n'),\n\t\t\t('{% load inclusion %}{% inclusion_one_param 37 %}', 'inclusion_one_param - Expected result: 37\\n'),\n\t\t\t('{% load inclusion %}{% inclusion_explicit_no_context 37 %}',\n\t\t\t\t'inclusion_explicit_no_context - Expected result: 37\\n'),\n\t\t\t('{% load inclusion %}{% inclusion_no_params_with_context %}',\n\t\t\t\t'inclusion_no_params_with_context - Expected result (context value: 42)\\n'),\n\t\t\t('{% load inclusion %}{% inclusion_params_and_context 37 %}',\n\t\t\t\t'inclusion_params_and_context - Expected result (context value: 42): 37\\n'),\n\t\t\t('{% load inclusion %}{% inclusion_two_params 37 42 %}',\n\t\t\t\t'inclusion_two_params - Expected result: 37, 42\\n'),\n\t\t\t(\n\t\t\t\t'{% load inclusion %}{% inclusion_one_default 37 %}',\n\t\t\t\t'inclusion_one_default - Expected result: 37, hi\\n'\n\t\t\t),\n\t\t\t('{% load inclusion %}{% inclusion_one_default 37 two=\"hello\" %}',\n\t\t\t\t'inclusion_one_default - Expected result: 37, hello\\n'),\n\t\t\t('{% load inclusion %}{% inclusion_one_default one=99 two=\"hello\" %}',\n\t\t\t\t'inclusion_one_default - Expected result: 99, hello\\n'),\n\t\t\t('{% load inclusion %}{% inclusion_one_default 37 42 %}',\n\t\t\t\t'inclusion_one_default - Expected result: 37, 42\\n'),\n\t\t\t(\n\t\t\t\t'{% load inclusion %}{% inclusion_keyword_only_default kwarg=37 %}',\n\t\t\t\t'inclusion_keyword_only_default - Expected result: 37\\n',\n\t\t\t),\n\t\t\t('{% load inclusion %}{% inclusion_unlimited_args 37 %}',\n\t\t\t\t'inclusion_unlimited_args - Expected result: 37, hi\\n'),\n\t\t\t('{% load inclusion %}{% inclusion_unlimited_args 37 42 56 89 %}',\n\t\t\t\t'inclusion_unlimited_args - Expected result: 37, 42, 56, 89\\n'),\n\t\t\t('{% load inclusion %}{% inclusion_only_unlimited_args %}',\n\t\t\t\t'inclusion_only_unlimited_args - Expected result: \\n'),\n\t\t\t('{% load inclusion %}{% inclusion_only_unlimited_args 37 42 56 89 %}',\n\t\t\t\t'inclusion_only_unlimited_args - Expected result: 37, 42, 56, 89\\n'),\n\t\t\t('{% load inclusion %}{% inclusion_unlimited_args_kwargs 37 40|add:2 56 eggs=\"scrambled\" four=1|add:3 %}',\n\t\t\t\t'inclusion_unlimited_args_kwargs - Expected result: 37, 42, 56 / eggs=scrambled, four=4\\n'),\n\t\t]\n\n\t\tfor entry in templates:\n\t\t\tt = self.engine.from_string(entry[0])\n\t\t\tself.assertEqual(t.render(c), entry[1])\n\n\tdef test_inclusion_tag_errors(self):\n\t\terrors = [\n\t\t\t(\"'inclusion_one_default' received unexpected keyword argument 'three'\",\n\t\t\t\t'{% load inclusion %}{% inclusion_one_default 99 two=\"hello\" three=\"foo\" %}'),\n\t\t\t(\"'inclusion_two_params' received too many positional arguments\",\n\t\t\t\t'{% load inclusion %}{% inclusion_two_params 37 42 56 %}'),\n\t\t\t(\"'inclusion_one_default' received too many positional arguments\",\n\t\t\t\t'{% load inclusion %}{% inclusion_one_default 37 42 56 %}'),\n\t\t\t(\"'inclusion_one_default' did not receive value(s) for the argument(s): 'one'\",\n\t\t\t\t'{% load inclusion %}{% inclusion_one_default %}'),\n\t\t\t(\n\t\t\t\t\"'inclusion_keyword_only_default' received multiple values \"\n\t\t\t\t\"for keyword argument 'kwarg'\",\n\t\t\t\t'{% load inclusion %}{% inclusion_keyword_only_default '\n\t\t\t\t'kwarg=37 kwarg=42 %}',\n\t\t\t),\n\t\t\t(\"'inclusion_unlimited_args' did not receive value(s) for the argument(s): 'one'\",\n\t\t\t\t'{% load inclusion %}{% inclusion_unlimited_args %}'),\n\t\t\t(\n\t\t\t\t\"'inclusion_unlimited_args_kwargs' received some positional argument(s) \"\n\t\t\t\t\"after some keyword argument(s)\",\n\t\t\t\t'{% load inclusion %}{% inclusion_unlimited_args_kwargs 37 40|add:2 eggs=\"boiled\" 56 four=1|add:3 %}',\n\t\t\t),\n\t\t\t(\"'inclusion_unlimited_args_kwargs' received multiple values for keyword argument 'eggs'\",\n\t\t\t\t'{% load inclusion %}{% inclusion_unlimited_args_kwargs 37 eggs=\"scrambled\" eggs=\"scrambled\" %}'),\n\t\t]\n\n\t\tfor entry in errors:\n\t\t\twith self.assertRaisesMessage(TemplateSyntaxError, entry[0]):\n\t\t\t\tself.engine.from_string(entry[1])\n\n\tdef test_include_tag_missing_context(self):\n\t\t# The 'context' parameter must be present when takes_context is True\n\t\tmsg = (\n\t\t\t\"'inclusion_tag_without_context_parameter' is decorated with \"\n\t\t\t\"takes_context=True so it must have a first argument of 'context'\"\n\t\t)\n\t\twith self.assertRaisesMessage(TemplateSyntaxError, msg):\n\t\t\tself.engine.from_string('{% load inclusion %}{% inclusion_tag_without_context_parameter 123 %}')\n\n\tdef test_inclusion_tags_from_template(self):\n\t\tc = Context({'value': 42})\n\n\t\ttemplates = [\n\t\t\t('{% load inclusion %}{% inclusion_no_params_from_template %}',\n\t\t\t\t'inclusion_no_params_from_template - Expected result\\n'),\n\t\t\t('{% load inclusion %}{% inclusion_one_param_from_template 37 %}',\n\t\t\t\t'inclusion_one_param_from_template - Expected result: 37\\n'),\n\t\t\t('{% load inclusion %}{% inclusion_explicit_no_context_from_template 37 %}',\n\t\t\t\t'inclusion_explicit_no_context_from_template - Expected result: 37\\n'),\n\t\t\t('{% load inclusion %}{% inclusion_no_params_with_context_from_template %}',\n\t\t\t\t'inclusion_no_params_with_context_from_template - Expected result (context value: 42)\\n'),\n\t\t\t('{% load inclusion %}{% inclusion_params_and_context_from_template 37 %}',\n\t\t\t\t'inclusion_params_and_context_from_template - Expected result (context value: 42): 37\\n'),\n\t\t\t('{% load inclusion %}{% inclusion_two_params_from_template 37 42 %}',\n\t\t\t\t'inclusion_two_params_from_template - Expected result: 37, 42\\n'),\n\t\t\t('{% load inclusion %}{% inclusion_one_default_from_template 37 %}',\n\t\t\t\t'inclusion_one_default_from_template - Expected result: 37, hi\\n'),\n\t\t\t('{% load inclusion %}{% inclusion_one_default_from_template 37 42 %}',\n\t\t\t\t'inclusion_one_default_from_template - Expected result: 37, 42\\n'),\n\t\t\t('{% load inclusion %}{% inclusion_unlimited_args_from_template 37 %}',\n\t\t\t\t'inclusion_unlimited_args_from_template - Expected result: 37, hi\\n'),\n\t\t\t('{% load inclusion %}{% inclusion_unlimited_args_from_template 37 42 56 89 %}',\n\t\t\t\t'inclusion_unlimited_args_from_template - Expected result: 37, 42, 56, 89\\n'),\n\t\t\t('{% load inclusion %}{% inclusion_only_unlimited_args_from_template %}',\n\t\t\t\t'inclusion_only_unlimited_args_from_template - Expected result: \\n'),\n\t\t\t('{% load inclusion %}{% inclusion_only_unlimited_args_from_template 37 42 56 89 %}',\n\t\t\t\t'inclusion_only_unlimited_args_from_template - Expected result: 37, 42, 56, 89\\n'),\n\t\t]\n\n\t\tfor entry in templates:\n\t\t\tt = self.engine.from_string(entry[0])\n\t\t\tself.assertEqual(t.render(c), entry[1])\n\n\tdef test_inclusion_tag_registration(self):\n\t\t# The decorators preserve the decorated function's docstring, name,\n\t\t# and attributes.\n\t\tself.verify_tag(inclusion.inclusion_no_params, 'inclusion_no_params')\n\t\tself.verify_tag(inclusion.inclusion_one_param, 'inclusion_one_param')\n\t\tself.verify_tag(inclusion.inclusion_explicit_no_context, 'inclusion_explicit_no_context')\n\t\tself.verify_tag(inclusion.inclusion_no_params_with_context, 'inclusion_no_params_with_context')\n\t\tself.verify_tag(inclusion.inclusion_params_and_context, 'inclusion_params_and_context')\n\t\tself.verify_tag(inclusion.inclusion_two_params, 'inclusion_two_params')\n\t\tself.verify_tag(inclusion.inclusion_one_default, 'inclusion_one_default')\n\t\tself.verify_tag(inclusion.inclusion_unlimited_args, 'inclusion_unlimited_args')\n\t\tself.verify_tag(inclusion.inclusion_only_unlimited_args, 'inclusion_only_unlimited_args')\n\t\tself.verify_tag(inclusion.inclusion_tag_without_context_parameter, 'inclusion_tag_without_context_parameter')\n\t\tself.verify_tag(inclusion.inclusion_tag_use_l10n, 'inclusion_tag_use_l10n')\n\t\tself.verify_tag(inclusion.inclusion_unlimited_args_kwargs, 'inclusion_unlimited_args_kwargs')\n\n\tdef test_15070_use_l10n(self):\n\t\t\"\"\"\n\t\tInclusion tag passes down `use_l10n` of context to the\n\t\tContext of the included/rendered template as well.\n\t\t\"\"\"\n\t\tc = Context({})\n\t\tt = self.engine.from_string('{% load inclusion %}{% inclusion_tag_use_l10n %}')\n\t\tself.assertEqual(t.render(c).strip(), 'None')\n\n\t\tc.use_l10n = True\n\t\tself.assertEqual(t.render(c).strip(), 'True')\n\n\tdef test_no_render_side_effect(self):\n\t\t\"\"\"\n\t\t#23441 -- InclusionNode shouldn't modify its nodelist at render time.\n\t\t\"\"\"\n\t\tengine = Engine(app_dirs=True, libraries=LIBRARIES)\n\t\ttemplate = engine.from_string('{% load inclusion %}{% inclusion_no_params %}')\n\t\tcount = template.nodelist.get_nodes_by_type(Node)\n\t\ttemplate.render(Context({}))\n\t\tself.assertEqual(template.nodelist.get_nodes_by_type(Node), count)\n\n\tdef test_render_context_is_cleared(self):\n\t\t\"\"\"\n\t\t#24555 -- InclusionNode should push and pop the render_context stack\n\t\twhen rendering. Otherwise, leftover values such as blocks from\n\t\textending can interfere with subsequent rendering.\n\t\t\"\"\"\n\t\tengine = Engine(app_dirs=True, libraries=LIBRARIES)\n\t\ttemplate = engine.from_string('{% load inclusion %}{% inclusion_extends1 %}{% inclusion_extends2 %}')\n\t\tself.assertEqual(template.render(Context({})).strip(), 'one\\ntwo')\n\n", "description": "\n\t\tInclusion tag passes down `use_l10n` of context to the\n\t\tContext of the included/rendered template as well.\n\t\t", "category": "simple", "imports": ["import os", "from django.template import Context, Engine, TemplateSyntaxError", "from django.template.base import Node", "from django.template.library import InvalidTemplateLibrary", "from django.test import SimpleTestCase", "from django.test.utils import extend_sys_path", "from .templatetags import custom, inclusion", "from .utils import ROOT", "\t\t\t\"trying to load 'template_tests.broken_tag': cannot import name \"", "\t\t\t\"import name 'Xtemplate'\""]}, {"term": "class", "name": "TemplateTagLoadingTests", "data": "class TemplateTagLoadingTests(SimpleTestCase):\n\n\t@classmethod\n\tdef setUpClass(cls):\n\t\tcls.egg_dir = os.path.join(ROOT, 'eggs')\n\t\tsuper().setUpClass()\n\n\tdef test_load_error(self):\n\t\tmsg = (\n\t\t\t\"Invalid template library specified. ImportError raised when \"\n\t\t\t\"trying to load 'template_tests.broken_tag': cannot import name \"\n\t\t\t\"'Xtemplate'\"\n\t\t)\n\t\twith self.assertRaisesMessage(InvalidTemplateLibrary, msg):\n\t\t\tEngine(libraries={'broken_tag': 'template_tests.broken_tag'})\n\n\tdef test_load_error_egg(self):\n\t\tegg_name = '%s/tagsegg.egg' % self.egg_dir\n\t\tmsg = (\n\t\t\t\"Invalid template library specified. ImportError raised when \"\n\t\t\t\"trying to load 'tagsegg.templatetags.broken_egg': cannot \"\n\t\t\t\"import name 'Xtemplate'\"\n\t\t)\n\t\twith extend_sys_path(egg_name):\n\t\t\twith self.assertRaisesMessage(InvalidTemplateLibrary, msg):\n\t\t\t\tEngine(libraries={'broken_egg': 'tagsegg.templatetags.broken_egg'})\n\n\tdef test_load_working_egg(self):\n\t\tttext = \"{% load working_egg %}\"\n\t\tegg_name = '%s/tagsegg.egg' % self.egg_dir\n\t\twith extend_sys_path(egg_name):\n\t\t\tengine = Engine(libraries={\n\t\t\t\t'working_egg': 'tagsegg.templatetags.working_egg',\n\t\t\t})\n\t\t\tengine.from_string(ttext)\n\n\tdef test_load_annotated_function(self):\n\t\tEngine(libraries={\n\t\t\t'annotated_tag_function': 'template_tests.annotated_tag_function',\n\t\t})\n", "description": null, "category": "simple", "imports": ["import os", "from django.template import Context, Engine, TemplateSyntaxError", "from django.template.base import Node", "from django.template.library import InvalidTemplateLibrary", "from django.test import SimpleTestCase", "from django.test.utils import extend_sys_path", "from .templatetags import custom, inclusion", "from .utils import ROOT", "\t\t\t\"trying to load 'template_tests.broken_tag': cannot import name \"", "\t\t\t\"import name 'Xtemplate'\""]}], [{"term": "def", "name": "test_simple_producer_redirect", "data": "def test_simple_producer_redirect(app):\n\n\tt = GlobalTestData()\n\n\t@app.pipeline()\n\tdef callback_func(pipeline, x):\n\t\treturn x.subscribe_func(t.save_multiple_items)\n\n\t@app.producer(callback_func)\n\tdef simple_producer():\n\t\tfor i in range(100):\n\t\t\tyield dict(x=1)\n\n\t@app.producer_redirect(simple_producer, callback_func)\n\tdef simple_producer2(data):\n\t\treturn data\n\n\tcallback_func.compile()\n\tsimple_producer2.flush()\n\tsimple_producer2.run()\n\trun_pipelines(app)\n\n\tassert len(t.get_result()) == 100\n\n", "description": null, "category": "simple", "imports": ["from stairs import producer_signals", "from utils import function_as_step, run_pipelines, GlobalTestData", "from stairs.core.producer import run_jobs_processor"]}, {"term": "def", "name": "test_batch_producer_redirect", "data": "def test_batch_producer_redirect(app):\n\tt = GlobalTestData()\n\n\t@app.pipeline()\n\tdef simple_pipeline(pipeline, x):\n\t\treturn x.subscribe_func(t.save_multiple_items)\n\n\t@app.producer(simple_pipeline)\n\tdef batch_handler(x):\n\t\tyield dict(x=x)\n\n\t@app.producer_redirect(batch_handler, simple_pipeline)\n\tdef simple_producer2(data):\n\t\treturn data\n\n\t@app.batch_producer(simple_producer2)\n\tdef worker_producer():\n\t\tfor i in range(10):\n\t\t\t# here we should yield batch of data\n\t\t\tyield dict(x=1)\n\n\tsimple_pipeline.compile()\n\tworker_producer()\n\ttry:\n\t\tworker_producer()\n\t\trun_jobs_processor(app.project,\n\t\t\t\t\t\t   [simple_producer2],\n\t\t\t\t\t\t   die_when_empty=True)\n\texcept SystemExit:\n\t\tpass\n\n\trun_pipelines(app)\n\n", "description": null, "category": "simple", "imports": ["from stairs import producer_signals", "from utils import function_as_step, run_pipelines, GlobalTestData", "from stairs.core.producer import run_jobs_processor"]}], [{"term": "def", "name": "fswig_import_helper", "data": "\tdef swig_import_helper():\n\t\timport importlib\n\t\tpkg = __name__.rpartition('.')[0]\n\t\tmname = '.'.join((pkg, '_param_SimpleNetwork')).lstrip('.')\n\t\ttry:\n\t\t\treturn importlib.import_module(mname)\n\t\texcept ImportError:\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleNetwork')", "\t_param_SimpleNetwork = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleNetwork", "\t_param_SimpleNetwork = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleNetwork", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.MessageBuffer_vector", "import m5.internal.param_MessageBuffer", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_RubyNetwork", "import m5.internal.BasicExtLink_vector", "import m5.internal.param_BasicExtLink", "import m5.internal.param_RubyController", "import m5.internal.param_RubySystem", "import m5.internal.param_SimpleMemory", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BasicRouter", "import m5.internal.param_BasicLink", "import m5.internal.BasicIntLink_vector", "import m5.internal.param_BasicIntLink", "import m5.internal.ClockedObject_vector", "import m5.internal.BasicRouter_vector"]}, {"term": "def", "name": "fswig_import_helper", "data": "\tdef swig_import_helper():\n\t\tfrom os.path import dirname\n\t\timport imp\n\t\tfp = None\n\t\ttry:\n\t\t\tfp, pathname, description = imp.find_module('_param_SimpleNetwork', [dirname(__file__)])\n\t\texcept ImportError:\n\t\t\timport _param_SimpleNetwork\n\t\t\treturn _param_SimpleNetwork\n\t\ttry:\n\t\t\t_mod = imp.load_module('_param_SimpleNetwork', fp, pathname, description)\n\t\tfinally:\n\t\t\tif fp is not None:\n\t\t\t\tfp.close()\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleNetwork')", "\t_param_SimpleNetwork = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleNetwork", "\t_param_SimpleNetwork = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleNetwork", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.MessageBuffer_vector", "import m5.internal.param_MessageBuffer", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_RubyNetwork", "import m5.internal.BasicExtLink_vector", "import m5.internal.param_BasicExtLink", "import m5.internal.param_RubyController", "import m5.internal.param_RubySystem", "import m5.internal.param_SimpleMemory", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BasicRouter", "import m5.internal.param_BasicLink", "import m5.internal.BasicIntLink_vector", "import m5.internal.param_BasicIntLink", "import m5.internal.ClockedObject_vector", "import m5.internal.BasicRouter_vector"]}, {"term": "def", "name": "_swig_setattr_nondynamic", "data": "def _swig_setattr_nondynamic(self, class_type, name, value, static=1):\n\tif (name == \"thisown\"):\n\t\treturn self.this.own(value)\n\tif (name == \"this\"):\n\t\tif type(value).__name__ == 'SwigPyObject':\n\t\t\tself.__dict__[name] = value\n\t\t\treturn\n\tmethod = class_type.__swig_setmethods__.get(name, None)\n\tif method:\n\t\treturn method(self, value)\n\tif (not static):\n\t\tobject.__setattr__(self, name, value)\n\telse:\n\t\traise AttributeError(\"You cannot add attributes to %s\" % self)\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleNetwork')", "\t_param_SimpleNetwork = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleNetwork", "\t_param_SimpleNetwork = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleNetwork", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.MessageBuffer_vector", "import m5.internal.param_MessageBuffer", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_RubyNetwork", "import m5.internal.BasicExtLink_vector", "import m5.internal.param_BasicExtLink", "import m5.internal.param_RubyController", "import m5.internal.param_RubySystem", "import m5.internal.param_SimpleMemory", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BasicRouter", "import m5.internal.param_BasicLink", "import m5.internal.BasicIntLink_vector", "import m5.internal.param_BasicIntLink", "import m5.internal.ClockedObject_vector", "import m5.internal.BasicRouter_vector"]}, {"term": "def", "name": "_swig_setattr", "data": "def _swig_setattr(self, class_type, name, value):\n\treturn _swig_setattr_nondynamic(self, class_type, name, value, 0)\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleNetwork')", "\t_param_SimpleNetwork = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleNetwork", "\t_param_SimpleNetwork = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleNetwork", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.MessageBuffer_vector", "import m5.internal.param_MessageBuffer", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_RubyNetwork", "import m5.internal.BasicExtLink_vector", "import m5.internal.param_BasicExtLink", "import m5.internal.param_RubyController", "import m5.internal.param_RubySystem", "import m5.internal.param_SimpleMemory", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BasicRouter", "import m5.internal.param_BasicLink", "import m5.internal.BasicIntLink_vector", "import m5.internal.param_BasicIntLink", "import m5.internal.ClockedObject_vector", "import m5.internal.BasicRouter_vector"]}, {"term": "def", "name": "_swig_getattr", "data": "def _swig_getattr(self, class_type, name):\n\tif (name == \"thisown\"):\n\t\treturn self.this.own()\n\tmethod = class_type.__swig_getmethods__.get(name, None)\n\tif method:\n\t\treturn method(self)\n\traise AttributeError(\"'%s' object has no attribute '%s'\" % (class_type.__name__, name))\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleNetwork')", "\t_param_SimpleNetwork = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleNetwork", "\t_param_SimpleNetwork = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleNetwork", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.MessageBuffer_vector", "import m5.internal.param_MessageBuffer", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_RubyNetwork", "import m5.internal.BasicExtLink_vector", "import m5.internal.param_BasicExtLink", "import m5.internal.param_RubyController", "import m5.internal.param_RubySystem", "import m5.internal.param_SimpleMemory", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BasicRouter", "import m5.internal.param_BasicLink", "import m5.internal.BasicIntLink_vector", "import m5.internal.param_BasicIntLink", "import m5.internal.ClockedObject_vector", "import m5.internal.BasicRouter_vector"]}, {"term": "def", "name": "_swig_repr", "data": "def _swig_repr(self):\n\ttry:\n\t\tstrthis = \"proxy of \" + self.this.__repr__()\n\texcept __builtin__.Exception:\n\t\tstrthis = \"\"\n\treturn \"<%s.%s; %s >\" % (self.__class__.__module__, self.__class__.__name__, strthis,)\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleNetwork')", "\t_param_SimpleNetwork = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleNetwork", "\t_param_SimpleNetwork = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleNetwork", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.MessageBuffer_vector", "import m5.internal.param_MessageBuffer", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_RubyNetwork", "import m5.internal.BasicExtLink_vector", "import m5.internal.param_BasicExtLink", "import m5.internal.param_RubyController", "import m5.internal.param_RubySystem", "import m5.internal.param_SimpleMemory", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BasicRouter", "import m5.internal.param_BasicLink", "import m5.internal.BasicIntLink_vector", "import m5.internal.param_BasicIntLink", "import m5.internal.ClockedObject_vector", "import m5.internal.BasicRouter_vector"]}, {"term": "def", "name": "_swig_setattr_nondynamic_method", "data": "def _swig_setattr_nondynamic_method(set):\n\tdef set_attr(self, name, value):\n\t\tif (name == \"thisown\"):\n\t\t\treturn self.this.own(value)\n\t\tif hasattr(self, name) or (name == \"this\"):\n\t\t\tset(self, name, value)\n\t\telse:\n\t\t\traise AttributeError(\"You cannot add attributes to %s\" % self)\n\treturn set_attr\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleNetwork')", "\t_param_SimpleNetwork = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleNetwork", "\t_param_SimpleNetwork = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleNetwork", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.MessageBuffer_vector", "import m5.internal.param_MessageBuffer", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_RubyNetwork", "import m5.internal.BasicExtLink_vector", "import m5.internal.param_BasicExtLink", "import m5.internal.param_RubyController", "import m5.internal.param_RubySystem", "import m5.internal.param_SimpleMemory", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BasicRouter", "import m5.internal.param_BasicLink", "import m5.internal.BasicIntLink_vector", "import m5.internal.param_BasicIntLink", "import m5.internal.ClockedObject_vector", "import m5.internal.BasicRouter_vector"]}, {"term": "class", "name": "SimpleNetwork", "data": "class SimpleNetwork(m5.internal.param_RubyNetwork.Network):\n\tthisown = _swig_property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc='The membership flag')\n\n\tdef __init__(self, *args, **kwargs):\n\t\traise AttributeError(\"No constructor defined - class is abstract\")\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleNetwork')", "\t_param_SimpleNetwork = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleNetwork", "\t_param_SimpleNetwork = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleNetwork", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.MessageBuffer_vector", "import m5.internal.param_MessageBuffer", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_RubyNetwork", "import m5.internal.BasicExtLink_vector", "import m5.internal.param_BasicExtLink", "import m5.internal.param_RubyController", "import m5.internal.param_RubySystem", "import m5.internal.param_SimpleMemory", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BasicRouter", "import m5.internal.param_BasicLink", "import m5.internal.BasicIntLink_vector", "import m5.internal.param_BasicIntLink", "import m5.internal.ClockedObject_vector", "import m5.internal.BasicRouter_vector"]}, {"term": "class", "name": "SimpleNetworkParams", "data": "class SimpleNetworkParams(m5.internal.param_RubyNetwork.RubyNetworkParams):\n\tthisown = _swig_property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc='The membership flag')\n\t__repr__ = _swig_repr\n\n\tdef create(self):\n\t\treturn _param_SimpleNetwork.SimpleNetworkParams_create(self)\n\tadaptive_routing = _swig_property(_param_SimpleNetwork.SimpleNetworkParams_adaptive_routing_get, _param_SimpleNetwork.SimpleNetworkParams_adaptive_routing_set)\n\tbuffer_size = _swig_property(_param_SimpleNetwork.SimpleNetworkParams_buffer_size_get, _param_SimpleNetwork.SimpleNetworkParams_buffer_size_set)\n\tendpoint_bandwidth = _swig_property(_param_SimpleNetwork.SimpleNetworkParams_endpoint_bandwidth_get, _param_SimpleNetwork.SimpleNetworkParams_endpoint_bandwidth_set)\n\tint_link_buffers = _swig_property(_param_SimpleNetwork.SimpleNetworkParams_int_link_buffers_get, _param_SimpleNetwork.SimpleNetworkParams_int_link_buffers_set)\n\n\tdef __init__(self):\n\t\tthis = _param_SimpleNetwork.new_SimpleNetworkParams()\n\t\ttry:\n\t\t\tself.this.append(this)\n\t\texcept __builtin__.Exception:\n\t\t\tself.this = this\n\t__swig_destroy__ = _param_SimpleNetwork.delete_SimpleNetworkParams\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleNetwork')", "\t_param_SimpleNetwork = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleNetwork", "\t_param_SimpleNetwork = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleNetwork", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.MessageBuffer_vector", "import m5.internal.param_MessageBuffer", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_RubyNetwork", "import m5.internal.BasicExtLink_vector", "import m5.internal.param_BasicExtLink", "import m5.internal.param_RubyController", "import m5.internal.param_RubySystem", "import m5.internal.param_SimpleMemory", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BasicRouter", "import m5.internal.param_BasicLink", "import m5.internal.BasicIntLink_vector", "import m5.internal.param_BasicIntLink", "import m5.internal.ClockedObject_vector", "import m5.internal.BasicRouter_vector"]}], [{"term": "class", "name": "SimpleOperationWriteHandler", "data": "class SimpleOperationWriteHandler(AbstractWriteHandler):\n\t\"\"\"Handles writing regular operations and a few special cases.\"\"\"\n\n\t_ssb_operations_special_cases_handlers: Dict[Optional[str], Type[AbstractWriteHandler]] = {\n\t\tNone: SimpleSimpleOpWriteHandler\n\t}\n\tfor x in [OP_JUMP, OP_CALL, OP_RETURN, OP_END, OP_HOLD]:\n\t\t_ssb_operations_special_cases_handlers[x] = KeywordSimpleOpWriteHandler\n\tfor x in OPS_CTX:\n\t\t_ssb_operations_special_cases_handlers[x] = CtxSimpleOpWriteHandler\n\tfor x in OPS_SWITCH_TEXT_CASE_MAP:\n\t\t_ssb_operations_special_cases_handlers[x] = MesageSwitchSimpleOpWriteHandler\n\tfor x in OPS_SWITCH_TEXT_CASE_CASES_LIST:\n\t\t_ssb_operations_special_cases_handlers[x] = MesageSwitchCasesSimpleOpWriteHandler\n\tfor x in OPS_FLAG_ALL:\n\t\t_ssb_operations_special_cases_handlers[x] = FlagSimpleOpWriteHandler\n\n\tdef __init__(self, start_vertex: Vertex, decompiler, parent):\n\t\tsuper().__init__(start_vertex, decompiler, parent)\n\n\tdef write_content(self):\n\t\t\"\"\"Delegate to specific simple op handler\"\"\"\n\t\treturn self.get_real_handler()(self.start_vertex, self.decompiler, self).write_content()\n\n\tdef get_real_handler(self) -> Type[AbstractWriteHandler]:\n\t\top: SsbOperation = self.start_vertex['op']\n\t\tlogger.debug(\"Writing a simple operation (%s)...\", op)\n\t\thandler = self._ssb_operations_special_cases_handlers[None]\n\t\tfor h_types, h in self._ssb_operations_special_cases_handlers.items():\n\t\t\tif op.op_code.name == h_types:\n\t\t\t\thandler = h\n\t\treturn handler\n", "description": "Handles writing regular operations and a few special cases.", "category": "simple", "imports": ["import logging", "from typing import Optional, Dict, Type", "from igraph import Vertex", "from explorerscript.ssb_converting.decompiler.write_handlers.abstract import AbstractWriteHandler", "from explorerscript.ssb_converting.decompiler.write_handlers.simple_ops.ctx import CtxSimpleOpWriteHandler", "from explorerscript.ssb_converting.decompiler.write_handlers.simple_ops.flag import FlagSimpleOpWriteHandler", "from explorerscript.ssb_converting.decompiler.write_handlers.simple_ops.keyword import KeywordSimpleOpWriteHandler", "from explorerscript.ssb_converting.decompiler.write_handlers.simple_ops.message_switches import \\", "from explorerscript.ssb_converting.decompiler.write_handlers.simple_ops.message_switches_cases import \\", "from explorerscript.ssb_converting.decompiler.write_handlers.simple_ops.simple import SimpleSimpleOpWriteHandler", "from explorerscript.ssb_converting.ssb_data_types import SsbOperation", "from explorerscript.ssb_converting.ssb_special_ops import OPS_THAT_END_CONTROL_FLOW, OPS_CTX, OP_JUMP, OP_RETURN, \\"]}], [{"term": "def", "name": "write", "data": "def write():\n\tprint('Creating new text file') \n\tos.chdir(path)\n\tfo = open('simple_survey.input', 'w+', 0)\n\tglobal quesiton\n\tfo.write('question' + '\\t' + 'assignments' + '\\n' + question + '\\t' + str(n))\n\tfo.close() \n", "description": null, "category": "simple", "imports": ["import sys", "import os", "import subprocess", "import time", "import random", "from shutil import copyfile"]}, {"term": "def", "name": "mkNewDirs", "data": "def mkNewDirs(): \n\tos.system(\"rm -rf \" + newPath)\n\tos.mkdir(newPath)\n\tcopyfile(path + 'simple_survey.properties', \n\t\tnewPath + 'simple_survey.properties')\n\tcopyfile(path + 'simple_survey.input', \n\t\tnewPath + 'simple_survey.input')\n\tcopyfile(path + 'simple_survey.question', \n\t\tnewPath + 'simple_survey.question')\n\tcopyfile(path + 'getResults.sh', \n\t\tnewPath + 'getResults.sh')\n", "description": null, "category": "simple", "imports": ["import sys", "import os", "import subprocess", "import time", "import random", "from shutil import copyfile"]}, {"term": "def", "name": "run", "data": "def run(): \n\tprint binPath\n\tos.chdir(binPath)\n\texecutable = \"./loadHITs.sh $1 $2 $3 $4 $5 $6 $7 $8 $9 -label ../samples/simple_survey/simple_survey -input ../samples/simple_survey/newDir\" + str(t) + '/' + \"simple_survey.input -question ../samples/simple_survey/newDir\" + str(t) + '/' + \"simple_survey.question -properties ../samples/simple_survey/newDir\" + str(t) + '/' + \"simple_survey.properties\"\n\tos.system(executable)\n\tos.chdir(path)\n", "description": null, "category": "simple", "imports": ["import sys", "import os", "import subprocess", "import time", "import random", "from shutil import copyfile"]}, {"term": "def", "name": "moveSuccess", "data": "def moveSuccess():\n\tcopyfile(path + 'simple_survey.success', \n\t\tnewPath + 'simple_survey.success')\n\n", "description": null, "category": "simple", "imports": ["import sys", "import os", "import subprocess", "import time", "import random", "from shutil import copyfile"]}, {"term": "def", "name": "runComponents", "data": "def runComponents(qI,tI): \n\tglobal question\n\tquestion = qI\n\tglobal t\n\tt = tI\n\tglobal newPath\n\tnewPath = path + \"newDir\" + str(t) +'/'\n\twrite()\n\tmkNewDirs()\n\trun()\n\tmoveSuccess()\n\n", "description": null, "category": "simple", "imports": ["import sys", "import os", "import subprocess", "import time", "import random", "from shutil import copyfile"]}], [{"term": "def", "name": "simple", "data": "def simple(e):\n\tcode = e.code\n\n\tif code.endswith('Exception'):\n\t\tcode = code.rstrip('Exception')\n\n\ttry:\n\t\t# Dynamically get the error class.\n\t\tsimple_e = getattr(sys.modules[__name__], code)(e)\n\texcept AttributeError:\n\t\t# Return original exception on failure.\n\t\treturn e\n\n\treturn simple_e\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "SimpleException", "data": "class SimpleException(BotoServerError):\n\tdef __init__(self, e):\n\t\tsuper(SimpleException, self).__init__(e.status, e.reason, e.body)\n\t\tself.error_message = self.message\n\n\tdef __repr__(self):\n\t\treturn self.__class__.__name__ + ': ' + self.error_message\n\tdef __str__(self):\n\t\treturn self.__class__.__name__ + ': ' + self.error_message\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "ValidationError", "data": "class ValidationError(SimpleException): pass\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "Throttling", "data": "class Throttling(SimpleException): pass\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "SourceBundleDeletion", "data": "class SourceBundleDeletion(SimpleException): pass\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}], [{"term": "def", "name": "simple", "data": "def simple(e):\n\tcode = e.code\n\n\tif code.endswith('Exception'):\n\t\tcode = code.rstrip('Exception')\n\n\ttry:\n\t\t# Dynamically get the error class.\n\t\tsimple_e = getattr(sys.modules[__name__], code)(e)\n\texcept AttributeError:\n\t\t# Return original exception on failure.\n\t\treturn e\n\n\treturn simple_e\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "SimpleException", "data": "class SimpleException(BotoServerError):\n\tdef __init__(self, e):\n\t\tsuper(SimpleException, self).__init__(e.status, e.reason, e.body)\n\t\tself.error_message = self.message\n\n\tdef __repr__(self):\n\t\treturn self.__class__.__name__ + ': ' + self.error_message\n\tdef __str__(self):\n\t\treturn self.__class__.__name__ + ': ' + self.error_message\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "ValidationError", "data": "class ValidationError(SimpleException): pass\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "Throttling", "data": "class Throttling(SimpleException): pass\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "SourceBundleDeletion", "data": "class SourceBundleDeletion(SimpleException): pass\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}], [{"term": "class", "name": "snackmonitors", "data": "class snackmonitors(Component):\n\n\tdef __init__(self, ctxt):\n\t\tComponent.__init__(self, ctxt)\n\t\tself.monitorsui = self.resolve(str(monitorsui))\n\n\tdef bootstrap_complete_callback(self, *args):\n\t\tself.monitorsui.uisection.set_default_subpath(\"NetworkOverview\")\n\t\treturn CONTINUE\n\n\tdef install(self):\n\t\tself.register_for_bootstrap_complete(self.bootstrap_complete_callback)\n\t\tmonitors = self.monitorsui.monitors\n\t\tr = monitors.register\n\t\tr(SimpleTemplateMonitor(\"NetworkOverview\", \"Network Overview\",\n\t\t\t\t\t\t\t\t100, self,\n\t\t\t\t\t\t\t\tset([\"viewmonitors\"]),\n\t\t\t\t\t\t\t\t\"NetworkOverview.mako\"));\n\t\tr(SimpleTemplateMonitor(\"Hosts\", \"Hosts\", 300,\n\t\t\t\t\t\t\t\tself, set([\"viewmonitors\"]),\n\t\t\t\t\t\t\t\t\"principallist_wrapper.mako\", \n\t\t\t\t\t\t\t\tptype=\"Hosts\"))\t\t\n\t\tr(SimpleResourceMonitor(\"HostslistOnly\", None, sys.maxint, \n\t\t\t\t\t\t\t\tself, set([\"viewmonitors\"]),\n\t\t\t\t\t\t\t\tHostListRes(self,set([\"viewmonitors\"]))))\n\t\tr(SimpleTemplateMonitor(\"Switches\", \"Switches\", 200, \n\t\t\t\t\t\t\t\tself, set([\"viewmonitors\"]),\n\t\t\t\t\t\t\t\t\"principallist_wrapper.mako\", \n\t\t\t\t\t\t\t\tptype=\"Switches\"))\t\t\n\t\tr(SimpleResourceMonitor(\"SwitcheslistOnly\", None, sys.maxint, \n\t\t\t\t\t\t\t\tself, set([\"viewmonitors\"]),\n\t\t\t\t\t\t\t\tSwitchListRes(self,set([\"viewmonitors\"]))))\n\t\tr(SimpleTemplateMonitor(\"SwitchInfo\", None, sys.maxint,\n\t\t\t\t\t\t\t\tself, set([\"viewmonitors\"]),\n\t\t\t\t\t\t\t\t\"SwitchInfoMon.mako\",\n\t\t\t\t\t\t\t\tmonitors.get(\"Switches\")))\n\t\tr(SimpleTemplateMonitor(\"SwitchPortInfo\", None, sys.maxint,\n\t\t\t\t\t\t\t\tself, set([\"viewmonitors\"]),\n\t\t\t\t\t\t\t\t\"SwitchPortInfoMon.mako\",\n\t\t\t\t\t\t\t\tmonitors.get(\"Switches\")))\t\t\n\t\tr(SimpleTemplateMonitor(\"HostInfo\", None,\n\t\t\t\t\t\t\t\tsys.maxint, self,\n\t\t\t\t\t\t\t\tset([\"viewmonitors\"]),\n\t\t\t\t\t\t\t\t\"HostInfo.mako\",\n\t\t\t\t\t\t\t\tmonitors.get(\"Hosts\")));\n\t\tr(SimpleTemplateMonitor(\"Users\", \"Users\", 400, \n\t\t\t\t\t\t\t\tself, set([\"viewmonitors\"]),\n\t\t\t\t\t\t\t\t\"principallist_wrapper.mako\", \n\t\t\t\t\t\t\t\tptype=\"Users\"))\t\t\n\t\tr(SimpleResourceMonitor(\"UserslistOnly\", None, sys.maxint, \n\t\t\t\t\t\t\t\tself, set([\"viewmonitors\"]),\n\t\t\t\t\t\t\t\tPrincipalListRes(\"user\", self, \n\t\t\t\t\t\t\t\t\tset([\"viewmonitors\"]))));\n\t\tr(SimpleTemplateMonitor(\"UserInfo\", None,\n\t\t\t\t\t\t\t\tsys.maxint, self,\n\t\t\t\t\t\t\t\tset([\"viewmonitors\"]),\n\t\t\t\t\t\t\t\t\"UserInfo.mako\",\n\t\t\t\t\t\t\t\tmonitors.get(\"Users\")));\n\t\tr(SimpleTemplateMonitor(\"Locations\", \"Locations\", 500, \n\t\t\t\t\t\t\t\tself, set([\"viewmonitors\"]),\n\t\t\t\t\t\t\t\t\"principallist_wrapper.mako\", \n\t\t\t\t\t\t\t\tptype=\"Locations\"))\t\t\n\t\tr(SimpleResourceMonitor(\"LocationslistOnly\", None, sys.maxint, \n\t\t\t\t\t\t\t\tself, set([\"viewmonitors\"]),\n\t\t\t\t\t\t\t\tLocationListRes(self,set([\"viewmonitors\"]))))\n\t\tr(SimpleTemplateMonitor(\"Groups\", \"Groups\",\n\t\t\t\t\t\t\t\t600, self,\n\t\t\t\t\t\t\t\tset([\"viewmonitors\"]),\n\t\t\t\t\t\t\t\t\"Groups.mako\"));\n\t\tr(SimpleTemplateMonitor(\"HostGroups\", None,\n\t\t\t\t\t\t\t\tsys.maxint, self,\n\t\t\t\t\t\t\t\tset([\"viewmonitors\"]),\n\t\t\t\t\t\t\t\t\"HostGroups.mako\",\n\t\t\t\t\t\t\t\tmonitors.get(\"Groups\")));\n\t\tr(SimpleTemplateMonitor(\"HostGroupInfo\", None,\n\t\t\t\t\t\t\t\tsys.maxint, self,\n\t\t\t\t\t\t\t\tset([\"viewmonitors\"]),\n\t\t\t\t\t\t\t\t\"HostGroupInfo.mako\",\n\t\t\t\t\t\t\t\tmonitors.get(\"Groups\")));\n\t\tr(SimpleTemplateMonitor(\"UserGroups\", None,\n\t\t\t\t\t\t\t\tsys.maxint, self,\n\t\t\t\t\t\t\t\tset([\"viewmonitors\"]),\n\t\t\t\t\t\t\t\t\"UserGroups.mako\",\n\t\t\t\t\t\t\t\tmonitors.get(\"Groups\")));\n\t\tr(SimpleTemplateMonitor(\"UserGroupInfo\", None,\n\t\t\t\t\t\t\t\tsys.maxint, self,\n\t\t\t\t\t\t\t\tset([\"viewmonitors\"]),\n\t\t\t\t\t\t\t\t\"UserGroupInfo.mako\",\n\t\t\t\t\t\t\t\tmonitors.get(\"Groups\")));\n\t\tr(SimpleTemplateMonitor(\"SwitchGroups\", None,\n\t\t\t\t\t\t\t\tsys.maxint, self,\n\t\t\t\t\t\t\t\tset([\"viewmonitors\"]),\n\t\t\t\t\t\t\t\t\"SwitchGroups.mako\",\n\t\t\t\t\t\t\t\tmonitors.get(\"Groups\")));\n\t\tr(SimpleTemplateMonitor(\"SwitchGroupInfo\", None,\n\t\t\t\t\t\t\t\tsys.maxint, self,\n\t\t\t\t\t\t\t\tset([\"viewmonitors\"]),\n\t\t\t\t\t\t\t\t\"SwitchGroupInfo.mako\",\n\t\t\t\t\t\t\t\tmonitors.get(\"Groups\")));\n\t\tr(SimpleTemplateMonitor(\"LocationGroups\", None,\n\t\t\t\t\t\t\t\tsys.maxint, self,\n\t\t\t\t\t\t\t\tset([\"viewmonitors\"]),\n\t\t\t\t\t\t\t\t\"LocationGroups.mako\",\n\t\t\t\t\t\t\t\tmonitors.get(\"Groups\")));\n\t\tr(SimpleTemplateMonitor(\"LocationGroupInfo\", None,\n\t\t\t\t\t\t\t\tsys.maxint, self,\n\t\t\t\t\t\t\t\tset([\"viewmonitors\"]),\n\t\t\t\t\t\t\t\t\"LocationGroupInfo.mako\",\n\t\t\t\t\t\t\t\tmonitors.get(\"Groups\")));\n\t\tr(SimpleTemplateMonitor(\"NWAddrGroups\", None,\n\t\t\t\t\t\t\t\tsys.maxint, self,\n\t\t\t\t\t\t\t\tset([\"viewmonitors\"]),\n\t\t\t\t\t\t\t\t\"NWAddrGroups.mako\",\n\t\t\t\t\t\t\t\tmonitors.get(\"Groups\")));\n\t\tr(SimpleTemplateMonitor(\"NWAddrGroupInfo\", None,\n\t\t\t\t\t\t\t\tsys.maxint, self,\n\t\t\t\t\t\t\t\tset([\"viewmonitors\"]),\n\t\t\t\t\t\t\t\t\"NWAddrGroupInfo.mako\",\n\t\t\t\t\t\t\t\tmonitors.get(\"Groups\")));\n\t\tr(SimpleTemplateMonitor(\"NetworkEventsLog\", \"Network Events Log\",\n\t\t\t\t\t\t\t\t700, self,\n\t\t\t\t\t\t\t\tset([\"viewmonitors\"]),\n\t\t\t\t\t\t\t\t\"NetEventsMon.mako\"));\n\t\tr(SimpleResourceMonitor(\"Search\", None, sys.maxint, \n\t\t\t\t\t\t\t\tself, set([\"viewmonitors\"]),\n\t\t\t\t\t\t\t\tSearchRes(self,set([\"viewmonitors\"]))))\n\t\tr(SimpleResourceMonitor(\"FlowHistory\", None, sys.maxint, \n\t\t\t\t\t\t\t\tself, set([\"viewmonitors\"]),\n\t\t\t\t\t\t\t\tFlowTableRes(self,set([\"viewmonitors\"]))))\n\t\tr(SimpleResourceMonitor(\"HostFlowSummary\", None, sys.maxint, \n\t\t\t\t\t\t\t\tself, set([\"viewmonitors\"]),\n\t\t\t\t\t\t\t\tHostFlowSummaryRes(self,set([\"viewmonitors\"]))))\n\n\n\tdef getInterface(self):\n\t\treturn str(snackmonitors)\n", "description": null, "category": "simple", "imports": ["import sys", "from nox.apps.pyrt.pycomponent import *", "from nox.lib.core import *", "from nox.apps.coreui.authui import UISection, UIResource, Capabilities", "from nox.apps.user_event_log.UI_user_event_log import UI_user_event_log", "from nox.apps.coreui import coreui", "from nox.apps.coreui.monitorsui import monitorsui, SimpleTemplateMonitor", "from nox.ext.apps.snackui.principal_list_pages import *", "from nox.ext.apps.snackui.search import SearchRes", "from nox.ext.apps.snackui.flow_table_page import FlowTableRes,HostFlowSummaryRes"]}, {"term": "def", "name": "getFactory", "data": "def getFactory():\n\tclass Factory:\n\t\tdef instance(self, ctxt):\n\t\t\treturn snackmonitors(ctxt)\n\n\treturn Factory()\n", "description": null, "category": "simple", "imports": ["import sys", "from nox.apps.pyrt.pycomponent import *", "from nox.lib.core import *", "from nox.apps.coreui.authui import UISection, UIResource, Capabilities", "from nox.apps.user_event_log.UI_user_event_log import UI_user_event_log", "from nox.apps.coreui import coreui", "from nox.apps.coreui.monitorsui import monitorsui, SimpleTemplateMonitor", "from nox.ext.apps.snackui.principal_list_pages import *", "from nox.ext.apps.snackui.search import SearchRes", "from nox.ext.apps.snackui.flow_table_page import FlowTableRes,HostFlowSummaryRes"]}], [{"term": "def", "name": "nonnegative_weights_init", "data": "def nonnegative_weights_init(m):\n\t\"\"\"Non-negative initialization of weights.\"\"\"\n\tif isinstance(m, nn.Conv2d):\n\t\tnn.init.uniform_(m.weight)\n\telse:\n\t\tm.data.fill_(0.1)\n", "description": "Non-negative initialization of weights.", "category": "simple", "imports": ["from numpy.core.numeric import True_", "import torch  # pylint: disable=import-error", "import torch.nn as nn  # pylint: disable=import-error", "import torch.nn.functional as F  # pylint: disable=import-error"]}, {"term": "def", "name": "orthogonal_weights_init", "data": "def orthogonal_weights_init(m):\n\t\"\"\"Orthogonal initialization of weights.\"\"\"\n\tif isinstance(m, nn.Conv2d):\n\t\tnn.init.orthogonal_(m.weight)\n\t\tm.weight.data.clamp_(0)\n\t\tm.bias.data.fill_(0.)\n\telse:\n\t\tm.data.fill_(0.)\n\n", "description": "Orthogonal initialization of weights.", "category": "simple", "imports": ["from numpy.core.numeric import True_", "import torch  # pylint: disable=import-error", "import torch.nn as nn  # pylint: disable=import-error", "import torch.nn.functional as F  # pylint: disable=import-error"]}, {"term": "class", "name": "ExcInhDivNorm", "data": "class ExcInhDivNorm(nn.Module):\n\t\"\"\"\n\tImplements Schwartz and Simoncelli 2001 style divisive normalization w/ lateral E/I connections.\n\tparams:\n\t  input_dim: Number of channels in input\n\t  hidden_dim: Number of hidden channels\n\t  kernel_size: Size of kernel in convolutions\n\tExample:\n\t  x = torch.zeros(1, 1, 100, 100)\n\t  net = ExcInhDivNorm(1, 16, 15)\n\t  out = net(x)\n\t\"\"\"\n\n\tdef __init__(self,\n\t\t\t\t in_channels,\n\t\t\t\t l_filter_size,\n\t\t\t\t l_theta, \n\t\t\t\t l_sfs,\n\t\t\t\t l_phase,\n\t\t\t\t divnorm_fsize=5,\n\t\t\t\t exc_fsize=7,\n\t\t\t\t inh_fsize=5,\n\t\t\t\t stride=4,\n\t\t\t\t padding_mode='zeros',\n\t\t\t\t groups=1,\n\t\t\t\t device='cuda',\n\t\t\t\t ):\n\t\tsuper(ExcInhDivNorm, self).__init__()\n\t\tself.in_channels = in_channels\n\t\tself.hidden_dim = in_channels\n\n\t\tself.div = nn.Conv2d(\n\t\t\tself.hidden_dim,\n\t\t\tself.hidden_dim,\n\t\t\tdivnorm_fsize,\n\t\t\tpadding=(divnorm_fsize - 1) // 2,\n\t\t\tpadding_mode=padding_mode,\n\t\t\tgroups=groups,\n\t\t\tbias=False)\n\t\tself.e_e = nn.Conv2d(\n\t\t\tself.hidden_dim, self.hidden_dim, \n\t\t\texc_fsize, bias=True, padding=(exc_fsize - 1) // 2,\n\t\t\t)\n\t\tself.i_e = nn.Conv2d(\n\t\t\tself.hidden_dim, self.hidden_dim, inh_fsize, \n\t\t\tpadding=(inh_fsize - 1) // 2,\n\t\t\tbias=True)\n\t\tself.sigma = nn.Parameter(torch.ones([1, self.hidden_dim, 1, 1]))\n\t\tself.output_bn = nn.BatchNorm2d(in_channels)\n\t\tself.output_relu = nn.ReLU(inplace=True)\n\t\t\n\tdef forward(self, x, residual=False, square_act=True, hor_conn=True):\n\t\t\"\"\"\n\t\tparams:\n\t\t  x: Input grayscale image tensor\n\t\tReturns:\n\t\t  output: Output post divisive normalization\n\t\t\"\"\"\n\t\tidentity = x\n\t\t# Gabor filter bank]\n\t\tsimple_cells = nn.Identity()(x)\n\t\tif hor_conn:\n\t\t\tinhibition = self.i_e(simple_cells)  # + self.i_ff(x)\n\t\t\t# Excitatory lateral connections (Center corresponds to self-excitation)\n\t\t\texcitation = self.e_e(simple_cells)\n\t\t\tsimple_cells = simple_cells + excitation - inhibition\n\t\tif square_act:\n\t\t\tsimple_cells = simple_cells ** 2\n\t\t\tnorm = self.div(simple_cells) + self.sigma ** 2 + 1e-5\n\t\t\tsimple_cells = simple_cells / norm\n\t\telse:\n\t\t\tnorm = 1 + F.relu(self.div(simple_cells))\n\t\t\tsimple_cells = simple_cells / norm\n\t\toutput = self.output_bn(simple_cells)\n\t\tif residual:\n\t\t\toutput += identity\n\t\toutput = self.output_relu(output)\n", "description": "\n\tImplements Schwartz and Simoncelli 2001 style divisive normalization w/ lateral E/I connections.\n\tparams:\n\t  input_dim: Number of channels in input\n\t  hidden_dim: Number of hidden channels\n\t  kernel_size: Size of kernel in convolutions\n\tExample:\n\t  x = torch.zeros(1, 1, 100, 100)\n\t  net = ExcInhDivNorm(1, 16, 15)\n\t  out = net(x)\n\t", "category": "simple", "imports": ["from numpy.core.numeric import True_", "import torch  # pylint: disable=import-error", "import torch.nn as nn  # pylint: disable=import-error", "import torch.nn.functional as F  # pylint: disable=import-error"]}], [{"term": "def", "name": "asInt", "data": "def asInt( value ):\n\tif isinstance( value, float ):\n\t\treturn int(round(value,0))\n\treturn value\n", "description": null, "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "def", "name": "fglReadPixels", "data": "\tdef glReadPixels( x,y,width,height,format,type=type, array=None ):\n\t\t\"\"\"Read specified pixels from the current display buffer\n\t\t\n\t\tThis typed version returns data in your specified default \n\t\tarray data-type format, or in the passed array, which will \n\t\tbe converted to the array-type required by the format.\n\t\t\"\"\"\n\t\tx,y,width,height = asInt(x),asInt(y),asInt(width),asInt(height)\n\t\tarrayType = arrays.GL_CONSTANT_TO_ARRAY_TYPE[ images.TYPE_TO_ARRAYTYPE.get(type,type) ]\n\t\tif array is None:\n\t\t\tarray = images.SetupPixelRead( format, (width,height), type )\n\t\telse:\n\t\t\tarray = arrayType.asArray( array )\n\t\timageData = arrayType.voidDataPointer( array )\n\t\tsimple.glReadPixels( \n\t\t\tint(x),int(y),\n\t\t\tint(width), int(height),\n\t\t\tformat,type, \n\t\t\timageData\n\t\t)\n", "description": "Read specified pixels from the current display buffer\n\t\t\n\t\tThis typed version returns data in your specified default \n\t\tarray data-type format, or in the passed array, which will \n\t\tbe converted to the array-type required by the format.\n\t\t", "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "def", "name": "fglGetTexImage", "data": "\tdef glGetTexImage( target, level,format,type=type ):\n\t\t\"\"\"Get a texture-level as an image\"\"\"\n\t\tfrom OpenGL.GL import glget\n\t\tdims = [glget.glGetTexLevelParameteriv( target, level, simple.GL_TEXTURE_WIDTH )]\n\t\tif target != simple.GL_TEXTURE_1D:\n\t\t\tdims.append( glget.glGetTexLevelParameteriv( target, level, simple.GL_TEXTURE_HEIGHT ) )\n\t\t\tif target != simple.GL_TEXTURE_2D:\n\t\t\t\tdims.append( glget.glGetTexLevelParameteriv( target, level, simple.GL_TEXTURE_DEPTH ) )\n\t\tarray = images.SetupPixelRead( format, tuple(dims), type )\n\t\tarrayType = arrays.GL_CONSTANT_TO_ARRAY_TYPE[ images.TYPE_TO_ARRAYTYPE.get(type,type) ]\n\t\tsimple.glGetTexImage( \n\t\t\ttarget, level, format, type, ctypes.c_void_p( arrayType.dataPointer(array)) \n\t\t)\n", "description": "Get a texture-level as an image", "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "def", "name": "glReadPixels", "data": "def glReadPixels( x,y,width,height,format,type, array=None, outputType=str ):\n\t\"\"\"Read specified pixels from the current display buffer\n\t\n\tx,y,width,height -- location and dimensions of the image to read \n\t\tfrom the buffer\n\tformat -- pixel format for the resulting data\n\ttype -- data-format for the resulting data\n\tarray -- optional array/offset into which to store the value\n\toutputType -- default (str) provides string output of the \n\t\tresults iff OpenGL.UNSIGNED_BYTE_IMAGES_AS_STRING is True \n\t\tand type == GL_UNSIGNED_BYTE.  Any other value will cause \n\t\toutput in the default array output format.\n\t\n\treturns the pixel data array in the format defined by the \n\tformat, type and outputType\n\t\"\"\"\n\tx,y,width,height = asInt(x),asInt(y),asInt(width),asInt(height)\n\t\n\tarrayType = arrays.GL_CONSTANT_TO_ARRAY_TYPE[ images.TYPE_TO_ARRAYTYPE.get(type,type) ]\n\tif array is None:\n\t\tarray = images.SetupPixelRead( format, (width,height), type )\n\telse:\n\t\tarray = arrayType.asArray( array )\n\timageData = arrayType.voidDataPointer( array )\n\tsimple.glReadPixels( \n\t\tx,y,width,height,\n\t\tformat,type, \n\t\timageData\n\t)\n\tif outputType is str:\n\t\treturn images.returnFormat( array, type )\n\telse:\n\t\treturn array\n", "description": "Read specified pixels from the current display buffer\n\t\n\tx,y,width,height -- location and dimensions of the image to read \n\t\tfrom the buffer\n\tformat -- pixel format for the resulting data\n\ttype -- data-format for the resulting data\n\tarray -- optional array/offset into which to store the value\n\toutputType -- default (str) provides string output of the \n\t\tresults iff OpenGL.UNSIGNED_BYTE_IMAGES_AS_STRING is True \n\t\tand type == GL_UNSIGNED_BYTE.  Any other value will cause \n\t\toutput in the default array output format.\n\t\n\treturns the pixel data array in the format defined by the \n\tformat, type and outputType\n\t", "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "def", "name": "glGetTexImage", "data": "def glGetTexImage( target, level,format,type, outputType=str ):\n\t\"\"\"Get a texture-level as an image\n\t\n\ttarget -- enum constant for the texture engine to be read \n\tlevel -- the mip-map level to read \n\tformat -- image format to read out the data \n\ttype -- data-type into which to read the data\n\t\n\toutputType -- default (str) provides string output of the \n\t\tresults iff OpenGL.UNSIGNED_BYTE_IMAGES_AS_STRING is True \n\t\tand type == GL_UNSIGNED_BYTE.  Any other value will cause \n\t\toutput in the default array output format.\n\t\n\treturns the pixel data array in the format defined by the \n\tformat, type and outputType\n\t\"\"\"\n\tfrom OpenGL.GL import glget\n\tdims = [glget.glGetTexLevelParameteriv( target, level, simple.GL_TEXTURE_WIDTH )]\n\tif target != simple.GL_TEXTURE_1D:\n\t\tdims.append( glget.glGetTexLevelParameteriv( target, level, simple.GL_TEXTURE_HEIGHT ) )\n\t\tif target != simple.GL_TEXTURE_2D:\n\t\t\tdims.append( glget.glGetTexLevelParameteriv( target, level, simple.GL_TEXTURE_DEPTH ) )\n\tarray = images.SetupPixelRead( format, tuple(dims), type )\n\tarrayType = arrays.GL_CONSTANT_TO_ARRAY_TYPE[ images.TYPE_TO_ARRAYTYPE.get(type,type) ]\n\tsimple.glGetTexImage( \n\t\ttarget, level, format, type, ctypes.c_void_p( arrayType.dataPointer(array)) \n\t)\n\tif outputType is str:\n\t\treturn images.returnFormat( array, type )\n\telse:\n\t\treturn array\n\n", "description": "Get a texture-level as an image\n\t\n\ttarget -- enum constant for the texture engine to be read \n\tlevel -- the mip-map level to read \n\tformat -- image format to read out the data \n\ttype -- data-type into which to read the data\n\t\n\toutputType -- default (str) provides string output of the \n\t\tresults iff OpenGL.UNSIGNED_BYTE_IMAGES_AS_STRING is True \n\t\tand type == GL_UNSIGNED_BYTE.  Any other value will cause \n\t\toutput in the default array output format.\n\t\n\treturns the pixel data array in the format defined by the \n\tformat, type and outputType\n\t", "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "def", "name": "asWrapper", "data": "def asWrapper( value ):\n\tif not isinstance( value, wrapper.Wrapper ):\n\t\treturn wrapper.wrapper( value )\n\treturn value\n", "description": null, "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "def", "name": "asIntConverter", "data": "def asIntConverter( value, *args ):\n\tif isinstance( value, float ):\n\t\treturn int(round(value,0))\n\treturn value\n", "description": null, "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "def", "name": "setDimensionsAsInts", "data": "def setDimensionsAsInts( baseOperation ):\n\t\"\"\"Set arguments with names in INT_DIMENSION_NAMES to asInt processing\"\"\"\n\tbaseOperation = asWrapper( baseOperation )\n\targNames = getattr( baseOperation, 'pyConverterNames', baseOperation.argNames )\n\tfor i,argName in enumerate(argNames):\n\t\tif argName in INT_DIMENSION_NAMES:\n\t\t\tbaseOperation.setPyConverter( argName, asIntConverter )\n\treturn baseOperation\n\n\t\n", "description": "Set arguments with names in INT_DIMENSION_NAMES to asInt processing", "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "class", "name": "ImageInputConverter", "data": "class ImageInputConverter( object ):\n\tdef __init__( self, rank, pixelsName=None, typeName='type' ):\n\t\tself.rank = rank\n\t\tself.typeName = typeName\n\t\tself.pixelsName = pixelsName\n\tdef finalise( self, wrapper ):\n\t\t\"\"\"Get our pixel index from the wrapper\"\"\"\n\t\tself.typeIndex = wrapper.pyArgIndex( self.typeName )\n\t\tself.pixelsIndex = wrapper.pyArgIndex( self.pixelsName )\n\tdef __call__( self, arg, baseOperation, pyArgs ):\n\t\t\"\"\"pyConverter for the pixels argument\"\"\"\n\t\timages.setupDefaultTransferMode()\n\t\timages.rankPacking( self.rank )\n\t\ttype = pyArgs[ self.typeIndex ]\n\t\tarrayType = arrays.GL_CONSTANT_TO_ARRAY_TYPE[ images.TYPE_TO_ARRAYTYPE[ type ] ]\n", "description": "Get our pixel index from the wrapper", "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "class", "name": "TypedImageInputConverter", "data": "class TypedImageInputConverter( ImageInputConverter ):\n\tdef __init__( self, rank, pixelsName, arrayType, typeName=None ):\n\t\tself.rank = rank\n\t\tself.arrayType = arrayType\n\t\tself.pixelsName = pixelsName\n\t\tself.typeName = typeName\n\tdef __call__( self, arg, baseOperation, pyArgs ):\n\t\t\"\"\"The pyConverter for the pixels\"\"\"\n\t\timages.setupDefaultTransferMode()\n\t\timages.rankPacking( self.rank )\n\t\treturn self.arrayType.asArray( arg )\n\tdef finalise( self, wrapper ):\n\t\t\"\"\"Get our pixel index from the wrapper\"\"\"\n\t\tself.pixelsIndex = wrapper.pyArgIndex( self.pixelsName )\n\tdef width( self, pyArgs, index, wrappedOperation ):\n\t\t\"\"\"Extract the width from the pixels argument\"\"\"\n\t\treturn self.arrayType.dimensions( pyArgs[self.pixelsIndex] )[0]\n\tdef height( self, pyArgs, index, wrappedOperation ):\n\t\t\"\"\"Extract the height from the pixels argument\"\"\"\n\t\treturn self.arrayType.dimensions( pyArgs[self.pixelsIndex] )[1]\n\tdef depth( self, pyArgs, index, wrappedOperation ):\n\t\t\"\"\"Extract the depth from the pixels argument\"\"\"\n\t\treturn self.arrayType.dimensions( pyArgs[self.pixelsIndex] )[2]\n\tdef type( self, pyArgs, index, wrappedOperation ):\n\t\t\"\"\"Provide the item-type argument from our stored value\n\t\t\n\t\tThis is used for pre-bound processing where we want to provide \n\t\tthe type by implication...\n\t\t\"\"\"\n\t\treturn self.typeName\n", "description": "The pyConverter for the pixels", "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "class", "name": "CompressedImageConverter", "data": "class CompressedImageConverter( object ):\n\tdef finalise( self, wrapper ):\n\t\t\"\"\"Get our pixel index from the wrapper\"\"\"\n\t\tself.dataIndex = wrapper.pyArgIndex( 'data' )\n\tdef __call__( self, pyArgs, index, wrappedOperation ):\n\t\t\"\"\"Create a data-size measurement for our image\"\"\"\n\t\targ = pyArgs[ self.dataIndex ]\n\t\treturn arrays.ArrayType.arrayByteCount( arg )\n\n\n", "description": "Get our pixel index from the wrapper", "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "def", "name": "setImageInput", "data": "def setImageInput( \n\tbaseOperation, arrayType=None, dimNames=DIMENSION_NAMES, \n", "description": null, "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "def", "name": "typedImageFunction", "data": "def typedImageFunction( suffix, arrayConstant,  baseFunction ):\n\t\"\"\"Produce a typed version of the given image function\"\"\"\n\tfunctionName = baseFunction.__name__\n\tfunctionName = '%(functionName)s%(suffix)s'%locals()\n\tif baseFunction:\n\t\tarrayType = arrays.GL_CONSTANT_TO_ARRAY_TYPE[ arrayConstant ]\n\t\tfunction = setDimensionsAsInts(\n\t\t\tsetImageInput(\n\t\t\t\tbaseFunction, \n\t\t\t\tarrayType,\n\t\t\t\ttypeName = arrayConstant,\n\t\t\t)\n\t\t)\n\t\treturn functionName, function\n\telse:\n\t\treturn functionName, baseFunction\n", "description": "Produce a typed version of the given image function", "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "def", "name": "_setDataSize", "data": "def _setDataSize( baseFunction, argument='imageSize' ):\n\t\"\"\"Set the data-size value to come from the data field\"\"\"\n\tif baseFunction:\n\t\tconverter = CompressedImageConverter()\n\t\treturn asWrapper( baseFunction ).setPyConverter(\n\t\t\targument\n\t\t).setCConverter( argument, converter )\n\telse:\n\t\treturn baseFunction\n", "description": "Set the data-size value to come from the data field", "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "def", "name": "compressedImageFunction", "data": "def compressedImageFunction( baseFunction ):\n\t\"\"\"Set the imageSize and dimensions-as-ints converters for baseFunction\"\"\"\n\tif baseFunction:\n\t\treturn setDimensionsAsInts(\n\t\t\t_setDataSize( \n\t\t\t\tbaseFunction, argument='imageSize'\n\t\t\t)\n\t\t)\n\telse:\n\t\treturn baseFunction\n", "description": "Set the imageSize and dimensions-as-ints converters for baseFunction", "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [{"term": "class", "name": "SimpleStorage", "data": "class SimpleStorage(Resource):\n\t\"\"\"Defines API behaviors for SimpleStorage instances.\n\n\tDefined: GET, PUT, PATCH, DELETE.\n\n\tflask_restful provides default support for HEAD and OPTIONS.\n\tIt also provides a default 405 (Method Not Allowed) response\n\tfor any RESTful service requests that are not defined.\n\t\"\"\"\n\n\tdef __init__(self):\n\t\t\"\"\"Handles class setup. Called by flask_restful prior to\n\t\teach and every REST operation handled by this class.\"\"\"\n\t\t# End of __init__()\n\n\tdef get(\n\t\t\tself,\n\t\t\tComputerSystemId = \"\",\n\t\t\tSimpleStorageId = \"\",\n\t\t\tResourceBlockId = \"\"\n\t\t\t):\n\t\t\"\"\"Defines GET behavior. Called by flask_restful.\"\"\"\n\t\t# When not empty, arguments hold values from the URI\n\t\t# TODO: Add privilege check\n\t\t# TODO: Add ETag support\n\t\t#\n\t\t# Handle GET request\n\t\tinst_key = request.path\n\t\t# fish keys do not have trailing slashes\n\t\tif inst_key.endswith('/'):\n\t\t\tinst_key += '/'\n\t\t\tinst_key = inst_key.replace('//', '')\n\t\t# Ensure object is in the fish object dictionary\n\t\tif inst_key not in fish:\n\t\t\treturn 'Object not found', HTTP.NOT_FOUND\n\t\t# Return the requested object\n\t\treturn fish[inst_key], HTTP.OK\n\t\t# End of get()\n\n\tdef put(\n\t\t\tself,\n\t\t\tComputerSystemId = \"\",\n\t\t\tSimpleStorageId = \"\",\n\t\t\tResourceBlockId = \"\"\n\t\t\t):\n\t\t\"\"\"Defines PUT behavior. Called by flask_restful.\"\"\"\n\t\t# When not empty, arguments hold values from the URI\n\t\t# TODO: Add privilege check\n\t\t# TODO: Add ETag support\n\t\t#\n\t\t# Handle Resource Capability restriction\n\t\tif not res_cap_updatable:\n\t\t\tresp = make_response('', HTTP.METHOD_NOT_ALLOWED)\n\t\t\tresp.headers.extend({'Allow': allow_http_verbs})\n\t\t\treturn resp\n\t\t#\n\t\t# Handle PUT request\n\t\tinst_key = request.path\n\t\t# fish keys do not have trailing slashes\n\t\tif inst_key.endswith('/'):\n\t\t\tinst_key += '/'\n\t\t\tinst_key = inst_key.replace('//', '')\n\t\t# Ensure object is in the fish object dictionary\n\t\tif inst_key not in fish:\n\t\t\treturn 'Object not found', HTTP.NOT_FOUND\n\t\t# Get JSON input, with minimal JSON checking\n\t\tjson_input = request.get_json(force = True, silent = True)\n\t\tif json_input == None:\n\t\t\treturn 'Bad JSON input', HTTP.BAD_REQUEST\n\t\t# Ensure @odata.id is in the new object\n\t\tif '@odata.id' not in json_input:\n\t\t\treturn '@odata.id not in input', HTTP.BAD_REQUEST\n\t\t# Ensure @odata.id is not being changed\n\t\tif fish[inst_key]['@odata.id'] != json_input['@odata.id']:\n\t\t\treturn 'Bad @odata.id input', HTTP.BAD_REQUEST\n\t\t# TODO: Add more checking of JSON input\n\t\t# Replace the old object with the new object\n\t\tfish[inst_key] = json_input\n\t\t# Return a copy of the new object\n\t\treturn fish[inst_key], HTTP.OK\n\t\t# End of put()\n\n\tdef patch(\n\t\t\tself,\n\t\t\tComputerSystemId = \"\",\n\t\t\tSimpleStorageId = \"\",\n\t\t\tResourceBlockId = \"\"\n\t\t\t):\n\t\t\"\"\"Defines PATCH behavior. Called by flask_restful.\"\"\"\n\t\t# When not empty, arguments hold values from the URI\n\t\t# TODO: Add privilege check\n\t\t# TODO: Add ETag support\n\t\t#\n\t\t# Handle Resource Capability restriction\n\t\tif not res_cap_updatable:\n\t\t\tresp = make_response('', HTTP.METHOD_NOT_ALLOWED)\n\t\t\tresp.headers.extend({'Allow': allow_http_verbs})\n\t\t\treturn resp\n\t\t#\n\t\t# Handle PATCH request\n\t\tinst_key = request.path\n\t\t# fish keys do not have trailing slashes\n\t\tif inst_key.endswith('/'):\n\t\t\tinst_key += '/'\n\t\t\tinst_key = inst_key.replace('//', '')\n\t\t# Ensure object is in the fish object dictionary\n\t\tif inst_key not in fish:\n\t\t\treturn 'Object not found', HTTP.NOT_FOUND\n\t\t# Get JSON input, with minimal JSON checking\n\t\tjson_input = request.get_json(force = True, silent = True)\n\t\tif json_input == None:\n\t\t\treturn 'Bad JSON input', HTTP.BAD_REQUEST\n\t\t# Ensure @odata.id is not a PATCH target\n\t\tif '@odata.id' in json_input:\n\t\t\treturn 'Attempted to PATCH @odata.id', HTTP.BAD_REQUEST\n\t\t# TODO: Add more checking of JSON input\n\t\t# Update patch_key items in the object\n\t\tfor patch_key, patch_value in json_input.items():\n\t\t\t# TODO: Add Writeability check for each patch_key item\n\t\t\tfish[inst_key][patch_key] = patch_value\n\t\t# Return a copy of the updated object\n\t\treturn fish[inst_key], HTTP.OK\n\t\t# End of patch()\n\n\tdef post(\n\t\t\tself,\n\t\t\tComputerSystemId = \"\",\n\t\t\tSimpleStorageId = \"\",\n\t\t\tResourceBlockId = \"\"\n\t\t\t):\n\t\t\"\"\"Defines POST behavior. Called by flask_restful.\"\"\"\n\t\t# When not empty, arguments hold values from the URI\n\t\t#\n\t\t# Handle POST request\n\t\t# POST is not allowed as a CRUD operation on a singleton\n\t\t# resource (except for Actions, which are handled in a\n\t\t# separate class), but is defined here so a proper Allow\n\t\t# header will be returned if a POST request is received.\n\t\tresp = make_response('', HTTP.METHOD_NOT_ALLOWED)\n\t\tresp.headers.extend({'Allow': allow_http_verbs})\n\t\treturn resp\n\t\t# End of post()\n\n\tdef delete(\n\t\t\tself,\n\t\t\tComputerSystemId = \"\",\n\t\t\tSimpleStorageId = \"\",\n\t\t\tResourceBlockId = \"\"\n\t\t\t):\n\t\t\"\"\"Defines DELETE behavior. Called by flask_restful.\"\"\"\n\t\t# When not empty, arguments hold values from the URI\n\t\t# TODO: Add privilege check\n\t\t# TODO: Add ETag support\n\t\t# TODO: Check for (and handle?) @Redfish.OperationApplyTime\n\t\t#\n\t\t# Handle Resource Capability restriction\n\t\tif not res_cap_deletable:\n\t\t\tresp = make_response('', HTTP.METHOD_NOT_ALLOWED)\n\t\t\tresp.headers.extend({'Allow': allow_http_verbs})\n\t\t\treturn resp\n\t\t#\n\t\t# Handle DELETE request\n\t\tinst_key = request.path\n\t\t# fish keys do not have trailing slashes\n\t\tif inst_key.endswith('/'):\n\t\t\tinst_key += '/'\n\t\t\tinst_key = inst_key.replace('//', '')\n\t\t# Ensure the object is in the fish object dictionary\n\t\tif inst_key not in fish:\n\t\t\treturn 'Object not found', HTTP.NOT_FOUND\n\t\t# Find the coll_key (assumes object is a collection member)\n\t\tinst_key_parts = inst_key.split('/')\n\t\tcoll_member_id = inst_key_parts[len(inst_key_parts) - 1]\n\t\tcoll_key = inst_key + '//'\n\t\tcoll_key = coll_key.replace('/' + coll_member_id + '//', '')\n\t\t# Ensure the collection is in the fish object dictionary\n\t\tif coll_key not in fish:\n\t\t\treturn 'Collection not found', HTTP.NOT_FOUND\n\t\t# Ensure the object is in the Collection's Members\n\t\tif {'@odata.id': inst_key} not in fish[coll_key]['Members']:\n\t\t\treturn 'Object not in Collection', HTTP.NOT_FOUND\n\t\t# Get a copy of the object\n\t\tdeleted_object = fish[inst_key]\n\t\t# Delete the object and its subordinate resources\n\t\tdel_keys = []\n\t\tfor fish_key in fish:\n\t\t\tif fish_key.startswith(inst_key):\n\t\t\t\tdel_keys.append(fish_key)\n\t\tfor del_key in del_keys:\n\t\t\t\tdel fish[del_key]\n\t\t# Remove link from Collection Members\n\t\tfish[coll_key]['Members'].remove(\n\t\t\t{'@odata.id': inst_key})\n\t\t# Re-evaluate collection Members count\n\t\tfish[coll_key]['Members@odata.count'] = \\\n\t\t\tlen(fish[coll_key]['Members'])\n\t\t# Return a copy of the deleted object\n\t\treturn deleted_object, HTTP.OK\n\t\t# End of delete()\n\n", "description": "Defines API behaviors for SimpleStorage instances.\n\n\tDefined: GET, PUT, PATCH, DELETE.\n\n\tflask_restful provides default support for HEAD and OPTIONS.\n\tIt also provides a default 405 (Method Not Allowed) response\n\tfor any RESTful service requests that are not defined.\n\t", "category": "simple", "imports": ["# Standard library module imports", "# Third party module imports", "from flask_restful import Resource\t  # REST operations", "from flask import request\t\t\t   # JSON input from REST", "from flask import make_response\t\t # Allow header handling", "# Local module imports", "from fish_data import fish\t\t\t  # Fish data", "import fishem_httpcodes as HTTP\t\t # HTTP status codes"]}, {"term": "class", "name": "SimpleStorageActions", "data": "class SimpleStorageActions(Resource):\n\t\"\"\"Defines API behaviors for SimpleStorage Actions.\n\n\tDefined: POST.\n\n\tflask_restful provides default support for HEAD and OPTIONS.\n\tIt also provides a 405 (Method Not Allowed) response for any\n\tRESTful service requests that are not defined.\n\n\tThis class is only needed for Resource Singletons that support\n\tActions or OEM Actions.\n\n\tNote: This class is included for all Singleton objects, even\n\twhen there are no Actions currently defined for the object.\n\tThis is to allow new Actions and OEM Actions to be created\n\tfor experimental purposes.\n\t\"\"\"\n\n\tdef __init__(self):\n\t\t\"\"\"Handles class setup. Called by flask_restful prior to\n\t\teach and every REST operation handled by this class.\"\"\"\n\t\t# End of __init__()\n\n\tdef post(\n\t\t\tself,\n\t\t\tComputerSystemId = \"\",\n\t\t\tSimpleStorageId = \"\",\n\t\t\tResourceBlockId = \"\",\n\t\t\tUriAction = \"\",\n\t\t\tUriOemAction = \"\"\n\t\t\t):\n\t\t\"\"\"Defines POST behavior. Called by flask_restful.\"\"\"\n\t\t# When not empty, arguments hold values from the URI\n\t\t# TODO: Add privilege check\n\t\t# TODO: Add ETag support (?)\n\t\t#\n\t\t# Handle POST request\n\t\taction_uri_parts = request.path.split('/Actions/')\n\t\tif len(action_uri_parts) != 2:\n\t\t\treturn 'Bad input', HTTP.BAD_REQUEST\n\t\tinst_key = action_uri_parts[0]\n\t\taction_name = action_uri_parts[1]\n\t\t# Action names do not have trailing slashes\n\t\tif action_name.endswith('/'):\n\t\t\taction_name += '/'\n\t\t\taction_name = action_name.replace('//', '')\n\t\t# Ensure object is in the fish object dictionary\n\t\tif inst_key not in fish:\n\t\t\treturn 'Object not found', HTTP.NOT_FOUND\n\t\t# Scan for the requested Action with an elif chain that\n\t\t# follows the initial 'if' statement below; OEM Actions\n\t\t# will have action_name = 'Oem/.'\n\t\tif action_name == '':\n\t\t\treturn 'Unknown Action for ' + inst_key, HTTP.BAD_REQUEST\n\t\telse:\n\t\t\t# Did not find a defined Action or OEM Action\n\t\t\treturn 'Unknown Action for ' + inst_key, HTTP.BAD_REQUEST\n\t\t# End of post()\n\n", "description": "Defines API behaviors for SimpleStorage Actions.\n\n\tDefined: POST.\n\n\tflask_restful provides default support for HEAD and OPTIONS.\n\tIt also provides a 405 (Method Not Allowed) response for any\n\tRESTful service requests that are not defined.\n\n\tThis class is only needed for Resource Singletons that support\n\tActions or OEM Actions.\n\n\tNote: This class is included for all Singleton objects, even\n\twhen there are no Actions currently defined for the object.\n\tThis is to allow new Actions and OEM Actions to be created\n\tfor experimental purposes.\n\t", "category": "simple", "imports": ["# Standard library module imports", "# Third party module imports", "from flask_restful import Resource\t  # REST operations", "from flask import request\t\t\t   # JSON input from REST", "from flask import make_response\t\t # Allow header handling", "# Local module imports", "from fish_data import fish\t\t\t  # Fish data", "import fishem_httpcodes as HTTP\t\t # HTTP status codes"]}, {"term": "def", "name": "activate", "data": "def activate(rest_api):\n\t\"\"\"Registers URIs for this API module with flask_restful.\"\"\"\n\n\t# Register the URIs this API module responds to:\n\trest_api.add_resource(\n\t\tSimpleStorage,\n\t\t'/redfish/v1/Systems//SimpleStorage/',\n\t\t'/redfish/v1/Systems//SimpleStorage//',\n\t\t'/redfish/v1/CompositionService/ResourceBlocks//SimpleStorage/',\n\t\t'/redfish/v1/CompositionService/ResourceBlocks//SimpleStorage//',\n\t\t'/redfish/v1/CompositionService/ResourceBlocks//Systems//SimpleStorage/',\n\t\t'/redfish/v1/CompositionService/ResourceBlocks//Systems//SimpleStorage//',\n\t\t'/redfish/v1/ResourceBlocks//SimpleStorage/',\n\t\t'/redfish/v1/ResourceBlocks//SimpleStorage//',\n\t\t'/redfish/v1/ResourceBlocks//Systems//SimpleStorage/',\n\t\t'/redfish/v1/ResourceBlocks//Systems//SimpleStorage//'\n\t\t)\n\n\t# Register the Action URIs this API module responds to:\n\trest_api.add_resource(\n\t\tSimpleStorageActions,\n\t\t'/redfish/v1/Systems//SimpleStorage//Actions/',\n\t\t'/redfish/v1/Systems//SimpleStorage//Actions/Oem/',\n\t\t'/redfish/v1/Systems//SimpleStorage//Actions//',\n\t\t'/redfish/v1/Systems//SimpleStorage//Actions/Oem//',\n\t\t'/redfish/v1/CompositionService/ResourceBlocks//SimpleStorage//Actions/',\n\t\t'/redfish/v1/CompositionService/ResourceBlocks//SimpleStorage//Actions/Oem/',\n\t\t'/redfish/v1/CompositionService/ResourceBlocks//SimpleStorage//Actions//',\n\t\t'/redfish/v1/CompositionService/ResourceBlocks//SimpleStorage//Actions/Oem//',\n\t\t'/redfish/v1/CompositionService/ResourceBlocks//Systems//SimpleStorage//Actions/',\n\t\t'/redfish/v1/CompositionService/ResourceBlocks//Systems//SimpleStorage//Actions/Oem/',\n\t\t'/redfish/v1/CompositionService/ResourceBlocks//Systems//SimpleStorage//Actions//',\n\t\t'/redfish/v1/CompositionService/ResourceBlocks//Systems//SimpleStorage//Actions/Oem//',\n\t\t'/redfish/v1/ResourceBlocks//SimpleStorage//Actions/',\n\t\t'/redfish/v1/ResourceBlocks//SimpleStorage//Actions/Oem/',\n\t\t'/redfish/v1/ResourceBlocks//SimpleStorage//Actions//',\n\t\t'/redfish/v1/ResourceBlocks//SimpleStorage//Actions/Oem//',\n\t\t'/redfish/v1/ResourceBlocks//Systems//SimpleStorage//Actions/',\n\t\t'/redfish/v1/ResourceBlocks//Systems//SimpleStorage//Actions/Oem/',\n\t\t'/redfish/v1/ResourceBlocks//Systems//SimpleStorage//Actions//',\n\t\t'/redfish/v1/ResourceBlocks//Systems//SimpleStorage//Actions/Oem//'\n\t\t)\n\n\treturn\n\t# End of activate()\n", "description": "Registers URIs for this API module with flask_restful.", "category": "simple", "imports": ["# Standard library module imports", "# Third party module imports", "from flask_restful import Resource\t  # REST operations", "from flask import request\t\t\t   # JSON input from REST", "from flask import make_response\t\t # Allow header handling", "# Local module imports", "from fish_data import fish\t\t\t  # Fish data", "import fishem_httpcodes as HTTP\t\t # HTTP status codes"]}], [], [{"term": "def", "name": "glVertexPointerd", "data": "def glVertexPointerd( array ):\n\t\"Natural writing of glVertexPointerd using standard ctypes\"\n\targ2 = GL_DOUBLE\n\targ3 = 0 # stride\n\targ4 = arrays.asArray(array, GL_DOUBLE)\n\targ1 = arrays.arraySize( arg4, 'd' )\n\tplatform.OpenGL.glVertexPointer( arg1, arg2, arg3, arrays.ArrayDatatype.dataPointer(arg4) )\n\tglCheckError()\n\t# only store if we successfully set the value...\n\tstoredPointers[ GL_VERTEX_ARRAY ] = arg4\n", "description": null, "category": "simple", "imports": ["from OpenGL import platform, arrays, error, wrapper, contextdata, converters, constant, ERROR_ON_COPY", "from OpenGL.raw import GL as simple", "from OpenGL.raw.GL import annotations", "import ctypes", "import weakref", "\tfrom OpenGL.GL import glGetIntegerv", "\tfrom OpenGL.GL import selection, feedback"]}, {"term": "def", "name": "wrapPointerFunction", "data": "def wrapPointerFunction( name, baseFunction, glType, arrayType,startArgs, defaultSize ):\n\t\"\"\"Wrap the given pointer-setting function\"\"\"\n\tfunction= wrapper.wrapper( baseFunction )\n\tassert not getattr( function, 'pyConverters', None ), \"\"\"Reusing wrappers?\"\"\"\n\tif arrayType:\n\t\tarrayModuleType = arrays.GL_CONSTANT_TO_ARRAY_TYPE[ glType ]\n\t\tfunction.setPyConverter( 'pointer', arrays.asArrayType(arrayModuleType) )\n\telse:\n\t\tfunction.setPyConverter( 'pointer', arrays.AsArrayOfType('pointer','type') )\n\tfunction.setCConverter( 'pointer', converters.getPyArgsName( 'pointer' ) )\n\tif 'size' in function.argNames:\n\t\tfunction.setPyConverter( 'size' )\n\t\tfunction.setCConverter( 'size', arrays.arraySizeOfFirstType(arrayModuleType,defaultSize) )\n\tif 'type' in function.argNames:\n\t\tfunction.setPyConverter( 'type' )\n\t\tfunction.setCConverter( 'type', glType )\n\tif 'stride' in function.argNames:\n\t\tfunction.setPyConverter( 'stride' )\n\t\tfunction.setCConverter( 'stride', 0 )\n\tfunction.setStoreValues( arrays.storePointerType( 'pointer', arrayType ) )\n\tfunction.setReturnValues( wrapper.returnPyArgument( 'pointer' ) )\n\treturn name,function\n\n\n", "description": "Wrap the given pointer-setting function", "category": "simple", "imports": ["from OpenGL import platform, arrays, error, wrapper, contextdata, converters, constant, ERROR_ON_COPY", "from OpenGL.raw import GL as simple", "from OpenGL.raw.GL import annotations", "import ctypes", "import weakref", "\tfrom OpenGL.GL import glGetIntegerv", "\tfrom OpenGL.GL import selection, feedback"]}, {"term": "def", "name": "glDrawElementsTyped", "data": "def glDrawElementsTyped( type, suffix ):\n\tarrayType = arrays.GL_CONSTANT_TO_ARRAY_TYPE[ type ]\n\tfunction = wrapper.wrapper( \n\t\tsimple.glDrawElements \n\t).setPyConverter('type').setCConverter(\n\t\t'type', type\n\t).setPyConverter('count').setCConverter(\n\t\t'count', arrays.AsArrayTypedSize( 'indices', arrayType ),\n\t).setPyConverter(\n\t\t'indices', arrays.AsArrayTyped( 'indices', arrayType ),\n\t).setReturnValues(\n\t\twrapper.returnPyArgument( 'indices' )\n\t)\n", "description": null, "category": "simple", "imports": ["from OpenGL import platform, arrays, error, wrapper, contextdata, converters, constant, ERROR_ON_COPY", "from OpenGL.raw import GL as simple", "from OpenGL.raw.GL import annotations", "import ctypes", "import weakref", "\tfrom OpenGL.GL import glGetIntegerv", "\tfrom OpenGL.GL import selection, feedback"]}, {"term": "def", "name": "glSelectBuffer", "data": "def glSelectBuffer( size, buffer = None ):\n\t\"\"\"Create a selection buffer of the given size\n\t\"\"\"\n\tif buffer is None:\n\t\tbuffer = arrays.GLuintArray.zeros( (size,) )\n\tsimple.glSelectBuffer( size, buffer )\n\tcontextdata.setValue( simple.GL_SELECTION_BUFFER_POINTER, buffer )\n", "description": "Create a selection buffer of the given size\n\t", "category": "simple", "imports": ["from OpenGL import platform, arrays, error, wrapper, contextdata, converters, constant, ERROR_ON_COPY", "from OpenGL.raw import GL as simple", "from OpenGL.raw.GL import annotations", "import ctypes", "import weakref", "\tfrom OpenGL.GL import glGetIntegerv", "\tfrom OpenGL.GL import selection, feedback"]}, {"term": "def", "name": "glFeedbackBuffer", "data": "def glFeedbackBuffer( size, type, buffer = None ):\n\t\"\"\"Create a selection buffer of the given size\n\t\"\"\"\n\tif buffer is None:\n\t\tbuffer = arrays.GLfloatArray.zeros( (size,) )\n\tsimple.glFeedbackBuffer( size, type, buffer )\n\tcontextdata.setValue( simple.GL_FEEDBACK_BUFFER_POINTER, buffer )\n\tcontextdata.setValue( \"GL_FEEDBACK_BUFFER_TYPE\", type )\n\treturn buffer\n", "description": "Create a selection buffer of the given size\n\t", "category": "simple", "imports": ["from OpenGL import platform, arrays, error, wrapper, contextdata, converters, constant, ERROR_ON_COPY", "from OpenGL.raw import GL as simple", "from OpenGL.raw.GL import annotations", "import ctypes", "import weakref", "\tfrom OpenGL.GL import glGetIntegerv", "\tfrom OpenGL.GL import selection, feedback"]}, {"term": "def", "name": "glRenderMode", "data": "def glRenderMode( newMode ):\n\t\"\"\"Change to the given rendering mode\n\t\n\tIf the current mode is GL_FEEDBACK or GL_SELECT, return\n\tthe current buffer appropriate to the mode\n\t\"\"\"\n\t# must get the current mode to determine operation...\n\tfrom OpenGL.GL import glGetIntegerv\n\tfrom OpenGL.GL import selection, feedback\n\tcurrentMode = glGetIntegerv( simple.GL_RENDER_MODE )\n\ttry:\n\t\tcurrentMode = currentMode[0]\n\texcept (TypeError,ValueError,IndexError), err:\n\t\tpass\n\tif currentMode in (simple.GL_RENDER,0):\n\t\t# no array needs to be returned...\n\t\treturn simple.glRenderMode( newMode )\n\tresult = simple.glRenderMode( newMode )\n\t# result is now an integer telling us how many elements were copied...\n\t\n\tif result < 0:\n\t\tif currentMode == simple.GL_SELECT:\n\t\t\traise error.GLError(\n\t\t\t\tsimple.GL_STACK_OVERFLOW,\n\t\t\t\t\"glSelectBuffer too small to hold selection results\",\n\t\t\t)\n\t\telif currentMode == simple.GL_FEEDBACK:\n\t\t\traise error.GLError(\n\t\t\t\tsimple.GL_STACK_OVERFLOW,\n\t\t\t\t\"glFeedbackBuffer too small to hold selection results\",\n\t\t\t)\n\t\telse:\n\t\t\traise error.GLError(\n\t\t\t\tsimple.GL_STACK_OVERFLOW,\n\t\t\t\t\"Unknown glRenderMode buffer (%s) too small to hold selection results\"%(\n\t\t\t\t\tcurrentMode,\n\t\t\t\t),\n\t\t\t)\n\t# Okay, now that the easy cases are out of the way...\n\t#  Do we have a pre-stored pointer about which the user already knows?\n\tcontext = platform.GetCurrentContext()\n\tif context == 0:\n\t\traise error.Error(\n\t\t\t\"\"\"Returning from glRenderMode without a valid context!\"\"\"\n\t\t)\n\tarrayConstant, wrapperFunction = {\n\t\tsimple.GL_FEEDBACK: (simple.GL_FEEDBACK_BUFFER_POINTER,feedback.parseFeedback),\n\t\tsimple.GL_SELECT: (simple.GL_SELECTION_BUFFER_POINTER, selection.GLSelectRecord.fromArray),\n\t}[ currentMode ]\n\tcurrent = contextdata.getValue( arrayConstant )\n\t# XXX check to see if it's the *same* array we set currently!\n\tif current is None:\n\t\tcurrent = glGetPointerv( arrayConstant )\n\t# XXX now, can turn the array into the appropriate wrapper type...\n\tif wrapperFunction:\n\t\tcurrent = wrapperFunction( current, result )\n\treturn current\n", "description": "Change to the given rendering mode\n\t\n\tIf the current mode is GL_FEEDBACK or GL_SELECT, return\n\tthe current buffer appropriate to the mode\n\t", "category": "simple", "imports": ["from OpenGL import platform, arrays, error, wrapper, contextdata, converters, constant, ERROR_ON_COPY", "from OpenGL.raw import GL as simple", "from OpenGL.raw.GL import annotations", "import ctypes", "import weakref", "\tfrom OpenGL.GL import glGetIntegerv", "\tfrom OpenGL.GL import selection, feedback"]}, {"term": "def", "name": "glGetPointerv", "data": "def glGetPointerv( constant ):\n\t\"\"\"Retrieve a stored pointer constant\"\"\"\n\t# do we have a cached version of the pointer?\n\t# get the base pointer from the underlying operation\n\tvp = ctypes.voidp()\n\tsimple.glGetPointerv( constant, ctypes.byref(vp) )\n\tcurrent = contextdata.getValue( constant )\n\tif current is not None:\n\t\tif arrays.ArrayDatatype.dataPointer( current ) == vp.value:\n\t\t\treturn current\n\t# XXX should be coercing to the proper type and converting to an array\n", "description": "Retrieve a stored pointer constant", "category": "simple", "imports": ["from OpenGL import platform, arrays, error, wrapper, contextdata, converters, constant, ERROR_ON_COPY", "from OpenGL.raw import GL as simple", "from OpenGL.raw.GL import annotations", "import ctypes", "import weakref", "\tfrom OpenGL.GL import glGetIntegerv", "\tfrom OpenGL.GL import selection, feedback"]}], [{"term": "def", "name": "test_simple_producer", "data": "def test_simple_producer(app):\n\n\tt = GlobalTestData()\n\n\t@app.pipeline()\n\tdef callback_func(pipeline, x):\n\t\treturn x.subscribe_func(t.save_multiple_items)\n\n\t@app.producer(callback_func)\n\tdef simple_producer():\n\t\tfor i in range(100):\n\t\t\tyield dict(x=1)\n\n\tcallback_func.compile()\n\tsimple_producer.flush()\n\tsimple_producer.run()\n\trun_pipelines(app)\n\n\tassert len(t.get_result()) == 100\n\n", "description": null, "category": "simple", "imports": ["from stairs import producer_signals", "from utils import run_pipelines, run_pipelines_process, GlobalTestData"]}, {"term": "def", "name": "test_multiple_pipelines", "data": "def test_multiple_pipelines(app):\n\tt = GlobalTestData()\n\n\t@app.pipeline()\n\tdef callback_func(pipeline, x):\n\t\treturn x.subscribe_func(t.save_multiple_items)\n\n\t@app.pipeline()\n\tdef callback_func2(pipeline, x):\n\t\treturn x.subscribe_func(t.save_multiple_items)\n\n\t@app.producer(callback_func, callback_func2)\n\tdef simple_producer():\n\t\tfor i in range(100):\n\t\t\tyield dict(x=1)\n\n\tcallback_func.compile()\n\tcallback_func2.compile()\n\n\tsimple_producer.flush()\n\tsimple_producer.run()\n\n\trun_pipelines(app)\n\n\tassert len(t.get_result()) == 200\n\n", "description": null, "category": "simple", "imports": ["from stairs import producer_signals", "from utils import run_pipelines, run_pipelines_process, GlobalTestData"]}, {"term": "def", "name": "test_repeat_producer", "data": "def test_repeat_producer(app):\n\n\tt = GlobalTestData()\n\n\t@app.pipeline()\n\tdef callback_func(pipeline, x):\n\t\treturn x.subscribe_func(t.save_multiple_items)\n\n\t@app.producer(callback_func,\n\t\t\t\t  repeat_on_signal=producer_signals.on_pipeline_empty,\n\t\t\t\t  repeat_times=2)\n\tdef simple_producer():\n\t\tfor i in range(100):\n\t\t\tyield dict(x=1)\n\n\tcallback_func.compile()\n\n\tprocess = run_pipelines_process(app)\n\n\tsimple_producer.flush()\n\tsimple_producer()\n\n\tprocess.terminate()\n\n\t# 200 because we repeat simple_producer two times + first initial run\n\tassert len(t.get_result()) == 300\n", "description": null, "category": "simple", "imports": ["from stairs import producer_signals", "from utils import run_pipelines, run_pipelines_process, GlobalTestData"]}], [{"term": "class", "name": "TLSXMLRPCRequestHandler", "data": "class TLSXMLRPCRequestHandler(SimpleXMLRPCRequestHandler):\n\t\"\"\"XMLRPCRequestHandler using TLS\"\"\"\n\t\n\t# Redefine the setup method (see SocketServer.StreamRequestHandler)\n\tdef setup(self):\n\t\tself.connection = self.request\n\t\tif getattr(self, 'timeout', None) is not None:\n\t\t\t# Python 2.7\n\t\t\tself.connection.settimeout(self.timeout)\n\t\tself.rfile = self.connection.makefile('rb', self.rbufsize)\n\t\tself.wfile = self.connection.makefile('wb', self.wbufsize)\n\t\t\n\tdef do_POST(self):\n\t\t\"\"\"Handles the HTTPS POST request.\"\"\"\n\t\tSimpleXMLRPCRequestHandler.do_POST(self)\n\t\ttry:\n\t\t\t# shut down the connection\n\t\t\tself.connection.shutdown()\n\t\texcept:\n\t\t\tpass\n\n", "description": "XMLRPCRequestHandler using TLS", "category": "simple", "imports": ["\tfrom SimpleXMLRPCServer import SimpleXMLRPCServer, SimpleXMLRPCRequestHandler", "\tfrom xmlrpc.server import SimpleXMLRPCServer, SimpleXMLRPCRequestHandler", "from .tlssocketservermixin import TLSSocketServerMixIn"]}, {"term": "class", "name": "TLSXMLRPCServer", "data": "class TLSXMLRPCServer(TLSSocketServerMixIn,\n\t\t\t\t\t  SimpleXMLRPCServer):\n\t\"\"\"Simple XML-RPC server using TLS\"\"\" \n\n\tdef __init__(self, addr, *args, **kwargs):\n\t\tif not args and not 'requestHandler' in kwargs:\n\t\t\tkwargs['requestHandler'] = TLSXMLRPCRequestHandler\n\t\tSimpleXMLRPCServer.__init__(self, addr, *args, **kwargs)\n\n", "description": "Simple XML-RPC server using TLS", "category": "simple", "imports": ["\tfrom SimpleXMLRPCServer import SimpleXMLRPCServer, SimpleXMLRPCRequestHandler", "\tfrom xmlrpc.server import SimpleXMLRPCServer, SimpleXMLRPCRequestHandler", "from .tlssocketservermixin import TLSSocketServerMixIn"]}, {"term": "class", "name": "MultiPathTLSXMLRPCServer", "data": "class MultiPathTLSXMLRPCServer(TLSXMLRPCServer):\n\t\"\"\"Multipath XML-RPC Server using TLS\"\"\"\n\n\tdef __init__(self, addr, *args, **kwargs):\n\t\tTLSXMLRPCServer.__init__(addr, *args, **kwargs)\n\t\tself.dispatchers = {}\n\t\tself.allow_none = allow_none\n\t\tself.encoding = encoding\n", "description": "Multipath XML-RPC Server using TLS", "category": "simple", "imports": ["\tfrom SimpleXMLRPCServer import SimpleXMLRPCServer, SimpleXMLRPCRequestHandler", "\tfrom xmlrpc.server import SimpleXMLRPCServer, SimpleXMLRPCRequestHandler", "from .tlssocketservermixin import TLSSocketServerMixIn"]}], [], [], [{"term": "class", "name": "classDocumentStore:", "data": "class DocumentStore:\n\t\"\"\"\n\tThe I{suds} document store provides a local repository for XML documents.\n\n\t@cvar protocol: The URL protocol for the store.\n\t@type protocol: str\n\t@cvar store: The mapping of URL location to documents.\n\t@type store: dict\n\t\"\"\"\n\n\tdef __init__(self, *args, **kwargs):\n\t\tself.__store = {\n\t\t\t'schemas.xmlsoap.org/soap/encoding/':soap5_encoding_schema}\n\t\tself.update = self.__store.update\n\t\tself.update(*args, **kwargs)\n\n\tdef __len__(self):\n\t\t# Implementation note:\n\t\t#   We can not implement '__len__' as simply self.__store.__len__, as\n\t\t# we do for 'update' because that causes py2to3 conversion to fail.\n\t\t#\t\t\t\t\t\t\t\t\t\t\t(08.05.2013.) (Jurko)\n\t\treturn len(self.__store)\n\n\tdef open(self, url):\n\t\t\"\"\"\n\t\tOpen a document at the specified URL.\n\n\t\tMissing documents referenced using the internal 'suds' protocol are\n\t\treported by raising an exception. For other protocols, None is returned\n\t\tinstead.\n\n\t\t@param url: A document URL.\n\t\t@type url: str\n\t\t@return: Document content or None if not found.\n\t\t@rtype: bytes\n\t\t\"\"\"\n\t\tprotocol, location = self.__split(url)\n\t\tcontent = self.__find(location)\n\t\tif protocol == 'suds' and content is None:\n\t\t\traise Exception, 'location \"%s\" not in document store' % location\n\t\treturn content\n\n\tdef __find(self, location):\n\t\t\"\"\"\n\t\tFind the specified location in the store.\n\t\t@param location: The I{location} part of a URL.\n\t\t@type location: str\n\t\t@return: Document content or None if not found.\n\t\t@rtype: bytes\n\t\t\"\"\"\n\t\treturn self.__store.get(location)\n\n\tdef __split(self, url):\n\t\t\"\"\"\n\t\tSplit the URL into I{protocol} and I{location}\n\t\t@param url: A URL.\n\t\t@param url: str\n\t\t@return: (I{url}, I{location})\n\t\t@rtype: tuple\n\t\t\"\"\"\n\t\tparts = url.split('://', 1)\n\t\tif len(parts) == 2:\n\t\t\treturn parts\n\t\treturn None, url\n\n", "description": "\n\tThe I{suds} document store provides a local repository for XML documents.\n\n\t@cvar protocol: The URL protocol for the store.\n\t@type protocol: str\n\t@cvar store: The mapping of URL location to documents.\n\t@type store: dict\n\t", "category": "simple", "imports": ["import suds", "from logging import getLogger"]}], [{"term": "class", "name": "TestAllPropTypes_i", "data": "class TestAllPropTypes_i(TestAllPropTypes_base):\n\t\"\"\"\"\"\"\n\tdef initialize(self):\n\t\t\"\"\"\n\t\tThis is called by the framework immediately after your component registers with the NameService.\n\t\t\n\t\tIn general, you should add customization here and not in the __init__ constructor.  If you have \n\t\ta custom port implementation you can override the specific implementation here with a statement\n\t\tsimilar to the following:\n\t\t  self.some_port = MyPortImplementation()\n\t\t\"\"\"\n\t\tTestAllPropTypes_base.initialize(self)\n\t\t# TODO add customization here.\n\t\n\t# Call back functions\t\n\tdef onconfigure_prop_simple_string(self, old, new):\n\t\tself.simple_string = '42'\n\t\t\n\tdef onconfigure_prop_simple_boolean(self, old, new):\n\t\tself.simple_boolean = True\n\t\t\n\tdef onconfigure_prop_simple_ulong(self, old, new):\n\t\tself.simple_ulong = 43\n\t\t\n\tdef onconfigure_prop_simple_objref(self, old, new):\n\t\tself.simple_objref = '44'\n\t\t\n\tdef onconfigure_prop_simple_short(self, old, new):\n\t\tself.simple_short = 45\n\t\t\n\tdef onconfigure_prop_simple_float(self, old, new):\n\t\tself.simple_float = 46.0\n\t\t\n\tdef onconfigure_prop_simple_octet(self, old, new):\n\t\tself.simple_octet = 47\n\t\t\n\tdef onconfigure_prop_simple_char(self, old, new):\n\t\tself.simple_char = struct.pack('b', 48)\n\t\t\n\tdef onconfigure_prop_simple_ushort(self, old, new):\n\t\tself.simple_ushort = 49\n\t\t\n\tdef onconfigure_prop_simple_double(self, old, new):\n\t\tself.simple_double = 50.0\n\t\t\n\tdef onconfigure_prop_simple_long(self, old, new):\n\t\tself.simple_long = 51\n\t\t\n\tdef onconfigure_prop_simple_longlong(self, old, new):\n\t\tself.simple_longlong = 52\n\t\t\n\tdef onconfigure_prop_simple_ulonglong(self, old, new):\n\t\tself.simple_ulonglong = 53\n\t\t\n\tdef onconfigure_prop_simple_sequence_string(self, old, new):\n\t\tself.simple_sequence_string = []\n\t\tself.simple_sequence_string.append('54')\n\t\t\n\tdef onconfigure_prop_simple_sequence_boolean(self, old, new):\n\t\tself.simple_sequence_boolean = []\n\t\tself.simple_sequence_boolean.append(True)\n\t\t\n\tdef onconfigure_prop_simple_sequence_ulong(self, old, new):\n\t\tself.simple_sequence_ulong = []\n\t\tself.simple_sequence_ulong.append(55)\n", "description": "", "category": "simple", "imports": ["from ossie.resource import Resource, start_component", "import logging", "import struct", "from TestAllPropTypes_base import * "]}, {"term": "def", "name": "fonconfigure_prop_simple_sequence_short", "data": "\tdef onconfigure_prop_simple_sequence_short(self, old, new):\n\t\tself.simple_sequence_short = []\n\t\tself.simple_sequence_short.append(57)\n", "description": null, "category": "simple", "imports": ["from ossie.resource import Resource, start_component", "import logging", "import struct", "from TestAllPropTypes_base import * "]}, {"term": "def", "name": "fonconfigure_prop_simple_sequence_float", "data": "\tdef onconfigure_prop_simple_sequence_float(self, old, new):\n\t\tself.simple_sequence_float = []\n\t\tself.simple_sequence_float.append(58.0)\n", "description": null, "category": "simple", "imports": ["from ossie.resource import Resource, start_component", "import logging", "import struct", "from TestAllPropTypes_base import * "]}, {"term": "def", "name": "fonconfigure_prop_simple_sequence_octet", "data": "\tdef onconfigure_prop_simple_sequence_octet(self, old, new):\n\t\tself.simple_sequence_octet = []\n\t\tself.simple_sequence_octet.append(59)\n", "description": null, "category": "simple", "imports": ["from ossie.resource import Resource, start_component", "import logging", "import struct", "from TestAllPropTypes_base import * "]}, {"term": "def", "name": "fonconfigure_prop_simple_sequence_char", "data": "\tdef onconfigure_prop_simple_sequence_char(self, old, new):\n\t\tself.simple_sequence_char = []\n\t\tself.simple_sequence_char.append(struct.pack('b', 60))\n", "description": null, "category": "simple", "imports": ["from ossie.resource import Resource, start_component", "import logging", "import struct", "from TestAllPropTypes_base import * "]}, {"term": "def", "name": "fonconfigure_prop_simple_sequence_ushort", "data": "\tdef onconfigure_prop_simple_sequence_ushort(self, old, new):\n\t\tself.simple_sequence_ushort = []\n\t\tself.simple_sequence_ushort.append(61)\n", "description": null, "category": "simple", "imports": ["from ossie.resource import Resource, start_component", "import logging", "import struct", "from TestAllPropTypes_base import * "]}, {"term": "def", "name": "fonconfigure_prop_simple_sequence_double", "data": "\tdef onconfigure_prop_simple_sequence_double(self, old, new):\n\t\tself.simple_sequence_double = []\n\t\tself.simple_sequence_double.append(62.0)\n", "description": null, "category": "simple", "imports": ["from ossie.resource import Resource, start_component", "import logging", "import struct", "from TestAllPropTypes_base import * "]}, {"term": "def", "name": "fonconfigure_prop_simple_sequence_long", "data": "\tdef onconfigure_prop_simple_sequence_long(self, old, new):\n\t\tself.simple_sequence_long = []\n\t\tself.simple_sequence_long.append(63)\n", "description": null, "category": "simple", "imports": ["from ossie.resource import Resource, start_component", "import logging", "import struct", "from TestAllPropTypes_base import * "]}, {"term": "def", "name": "fonconfigure_prop_simple_sequence_longlong", "data": "\tdef onconfigure_prop_simple_sequence_longlong(self, old, new):\n\t\tself.simple_sequence_longlong = []\n\t\tself.simple_sequence_longlong.append(64)\n", "description": null, "category": "simple", "imports": ["from ossie.resource import Resource, start_component", "import logging", "import struct", "from TestAllPropTypes_base import * "]}, {"term": "def", "name": "fonconfigure_prop_simple_sequence_ulonglong", "data": "\tdef onconfigure_prop_simple_sequence_ulonglong(self, old, new):\n\t\tself.simple_sequence_ulonglong = []\n\t\tself.simple_sequence_ulonglong.append(65)\n", "description": null, "category": "simple", "imports": ["from ossie.resource import Resource, start_component", "import logging", "import struct", "from TestAllPropTypes_base import * "]}, {"term": "def", "name": "fonconfigure_prop_struct_vars", "data": "\tdef onconfigure_prop_struct_vars(self, old, new):\n\t\tself.struct_vars.struct_string = '66'\n", "description": null, "category": "simple", "imports": ["from ossie.resource import Resource, start_component", "import logging", "import struct", "from TestAllPropTypes_base import * "]}, {"term": "def", "name": "fonconfigure_prop_struct_seq", "data": "\tdef onconfigure_prop_struct_seq(self, old, new):\n\t\ttemp = self.StructSeqVars('67',False,0,'',0,0,0,0,0,0,0,0,0)\n\t\tself.struct_seq.append(temp)\n", "description": null, "category": "simple", "imports": ["from ossie.resource import Resource, start_component", "import logging", "import struct", "from TestAllPropTypes_base import * "]}, {"term": "def", "name": "fprocess", "data": "\tdef process(self):\n\t\t\"\"\"\n\t\tBasic functionality:\n\t\t\n\t\t\tThe process method should process a single \"chunk\" of data and then return. This method\n\t\t\twill be called from the processing thread again, and again, and again until it returns\n\t\t\tFINISH or stop() is called on the component.  If no work is performed, then return NOOP.\n\t\t\t\n\t\tStreamSRI:\n\t\t\tTo create a StreamSRI object, use the following code (this generates a normalized SRI that does not flush the queue when full):\n\t\t\t\tself.sri = BULKIO.StreamSRI(1, 0.0, 0.0, BULKIO.UNITS_TIME, 0, 0.0, 0.0, BULKIO.UNITS_NONE, 0, self.stream_id, True, [])\n\n\t\tPrecisionUTCTime:\n\t\t\tTo create a PrecisionUTCTime object, use the following code:\n\t\t\t\ttmp_time = time.time()\n\t\t\t\twsec = math.modf(tmp_time)[1]\n\t\t\t\tfsec = math.modf(tmp_time)[0]\n\t\t\t\ttstamp = BULKIO.PrecisionUTCTime(BULKIO.TCM_CPU, BULKIO.TCS_VALID, 0, wsec, fsec)\n  \n\t\tPorts:\n\n\t\t\tEach port instance is accessed through members of the following form: self.port_\n\t\t\t\n\t\t\tData is obtained in the process function through the getPacket call (BULKIO only) on a\n\t\t\tprovides port member instance. The getPacket function call is non-blocking - if no data\n\t\t\tis available, it will return immediately with all values == None.\n\t\t\t\n\t\t\tTo send data, call the appropriate function in the port directly. In the case of BULKIO,\n\t\t\tconvenience functions have been added in the port classes that aid in output.\n\t\t\t\n\t\t\tInteractions with non-BULKIO ports are left up to the component developer's discretion.\n\t\t\t\n\t\tProperties:\n\t\t\n\t\t\tProperties are accessed directly as member variables. If the property name is baudRate,\n\t\t\tthen accessing it (for reading or writing) is achieved in the following way: self.baudRate.\n\t\t\t\n\t\tExample:\n\t\t\n\t\t\t# This example assumes that the component has two ports:\n\t\t\t#   - A provides (input) port of type BULKIO.dataShort called dataShort_in\n\t\t\t#   - A uses (output) port of type BULKIO.dataFloat called dataFloat_out\n\t\t\t# The mapping between the port and the class if found in the component\n\t\t\t# base class.\n\t\t\t# This example also makes use of the following Properties:\n\t\t\t#   - A float value called amplitude\n\t\t\t#   - A boolean called increaseAmplitude\n\t\t\t\n\t\t\tdata, T, EOS, streamID, sri, sriChanged, inputQueueFlushed = self.port_dataShort_in.getPacket()\n\t\t\t\n\t\t\tif data == None:\n\t\t\t\treturn NOOP\n\t\t\t\t\n\t\t\toutData = range(len(data))\n\t\t\tfor i in range(len(data)):\n\t\t\t\tif self.increaseAmplitude:\n\t\t\t\t\toutData[i] = float(data[i]) * self.amplitude\n\t\t\t\telse:\n\t\t\t\t\toutData[i] = float(data[i])\n\t\t\t\t\n\t\t\t# NOTE: You must make at least one valid pushSRI call\n\t\t\tif sriChanged:\n\t\t\t\tself.port_dataFloat_out.pushSRI(sri);\n\n\t\t\tself.port_dataFloat_out.pushPacket(outData, T, EOS, streamID)\n\t\t\treturn NORMAL\n\t\t\t\n\t\t\"\"\"\n\n\t\t# TODO fill in your code here\n\t\tself._log.debug(\"process() example log message\")\n\t\treturn NOOP\n\t\t\n", "description": "\n\t\tBasic functionality:\n\t\t\n\t\t\tThe process method should process a single \"chunk\" of data and then return. This method\n\t\t\twill be called from the processing thread again, and again, and again until it returns\n\t\t\tFINISH or stop() is called on the component.  If no work is performed, then return NOOP.\n\t\t\t\n\t\tStreamSRI:\n\t\t\tTo create a StreamSRI object, use the following code (this generates a normalized SRI that does not flush the queue when full):\n\t\t\t\tself.sri = BULKIO.StreamSRI(1, 0.0, 0.0, BULKIO.UNITS_TIME, 0, 0.0, 0.0, BULKIO.UNITS_NONE, 0, self.stream_id, True, [])\n\n\t\tPrecisionUTCTime:\n\t\t\tTo create a PrecisionUTCTime object, use the following code:\n\t\t\t\ttmp_time = time.time()\n\t\t\t\twsec = math.modf(tmp_time)[1]\n\t\t\t\tfsec = math.modf(tmp_time)[0]\n\t\t\t\ttstamp = BULKIO.PrecisionUTCTime(BULKIO.TCM_CPU, BULKIO.TCS_VALID, 0, wsec, fsec)\n  \n\t\tPorts:\n\n\t\t\tEach port instance is accessed through members of the following form: self.port_\n\t\t\t\n\t\t\tData is obtained in the process function through the getPacket call (BULKIO only) on a\n\t\t\tprovides port member instance. The getPacket function call is non-blocking - if no data\n\t\t\tis available, it will return immediately with all values == None.\n\t\t\t\n\t\t\tTo send data, call the appropriate function in the port directly. In the case of BULKIO,\n\t\t\tconvenience functions have been added in the port classes that aid in output.\n\t\t\t\n\t\t\tInteractions with non-BULKIO ports are left up to the component developer's discretion.\n\t\t\t\n\t\tProperties:\n\t\t\n\t\t\tProperties are accessed directly as member variables. If the property name is baudRate,\n\t\t\tthen accessing it (for reading or writing) is achieved in the following way: self.baudRate.\n\t\t\t\n\t\tExample:\n\t\t\n\t\t\t# This example assumes that the component has two ports:\n\t\t\t#   - A provides (input) port of type BULKIO.dataShort called dataShort_in\n\t\t\t#   - A uses (output) port of type BULKIO.dataFloat called dataFloat_out\n\t\t\t# The mapping between the port and the class if found in the component\n\t\t\t# base class.\n\t\t\t# This example also makes use of the following Properties:\n\t\t\t#   - A float value called amplitude\n\t\t\t#   - A boolean called increaseAmplitude\n\t\t\t\n\t\t\tdata, T, EOS, streamID, sri, sriChanged, inputQueueFlushed = self.port_dataShort_in.getPacket()\n\t\t\t\n\t\t\tif data == None:\n\t\t\t\treturn NOOP\n\t\t\t\t\n\t\t\toutData = range(len(data))\n\t\t\tfor i in range(len(data)):\n\t\t\t\tif self.increaseAmplitude:\n\t\t\t\t\toutData[i] = float(data[i]) * self.amplitude\n\t\t\t\telse:\n\t\t\t\t\toutData[i] = float(data[i])\n\t\t\t\t\n\t\t\t# NOTE: You must make at least one valid pushSRI call\n\t\t\tif sriChanged:\n\t\t\t\tself.port_dataFloat_out.pushSRI(sri);\n\n\t\t\tself.port_dataFloat_out.pushPacket(outData, T, EOS, streamID)\n\t\t\treturn NORMAL\n\t\t\t\n\t\t", "category": "simple", "imports": ["from ossie.resource import Resource, start_component", "import logging", "import struct", "from TestAllPropTypes_base import * "]}], [{"term": "def", "name": "in_tree", "data": "def in_tree(response, name, uclass, drv, depth, last_child):\n\tlines = [x.strip() for x in response.splitlines()]\n\tleaf = ''\n\tif depth != 0:\n\t\tleaf = '   ' + '\t' * (depth - 1) ;\n\t\tif not last_child:\n\t\t\tleaf = leaf + r'\\|'\n\t\telse:\n\t\t\t\t\t\tleaf = leaf + '`'\n\n\tleaf = leaf + '-- ' + name\n\tline = (r' *{:10.10} *[0-9]*  \\[ [ +] \\]   {:20.20}  [` |]{}$'\n\t\t\t.format(uclass, drv, leaf))\n\tprog = re.compile(line)\n\tfor l in lines:\n\t\tif prog.match(l):\n\t\t\treturn True\n\treturn False\n\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}, {"term": "def", "name": "test_bind_unbind_with_node", "data": "def test_bind_unbind_with_node(u_boot_console):\n\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, False)\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'simple_bus', 1, True)\n\n\t#Unbind child #1. No error expected and all devices should be there except for bind-test-child1\n\tresponse = u_boot_console.run_command('unbind  /bind-test/bind-test-child1')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'simple_bus', 0, True)\n\tassert 'bind-test-child1' not in tree\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'simple_bus', 1, True)\n\n\t#bind child #1. No error expected and all devices should be there\n\tresponse = u_boot_console.run_command('bind  /bind-test/bind-test-child1 phy_sandbox')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, True)\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'simple_bus', 1, False)\n\n\t#Unbind child #2. No error expected and all devices should be there except for bind-test-child2\n\tresponse = u_boot_console.run_command('unbind  /bind-test/bind-test-child2')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, True)\n\tassert 'bind-test-child2' not in tree\n\n\n\t#Bind child #2. No error expected and all devices should be there\n\tresponse = u_boot_console.run_command('bind /bind-test/bind-test-child2 simple_bus')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, False)\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'simple_bus', 1, True)\n\n\t#Unbind parent. No error expected. All devices should be removed and unbound\n\tresponse = u_boot_console.run_command('unbind  /bind-test')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert 'bind-test' not in tree\n\tassert 'bind-test-child1' not in tree\n\tassert 'bind-test-child2' not in tree\n\n\t#try binding invalid node with valid driver\n\tresponse = u_boot_console.run_command('bind  /not-a-valid-node simple_bus')\n\tassert response != ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert 'not-a-valid-node' not in tree\n\n\t#try binding valid node with invalid driver\n\tresponse = u_boot_console.run_command('bind  /bind-test not_a_driver')\n\tassert response != ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert 'bind-test' not in tree\n\n\t#bind /bind-test. Device should come up as well as its children\n\tresponse = u_boot_console.run_command('bind  /bind-test simple_bus')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, False)\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'simple_bus', 1, True)\n\n\tresponse = u_boot_console.run_command('unbind  /bind-test')\n\tassert response == ''\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}, {"term": "def", "name": "get_next_line", "data": "def get_next_line(tree, name):\n\ttreelines = [x.strip() for x in tree.splitlines() if x.strip()]\n\tchild_line = ''\n\tfor idx, line in enumerate(treelines):\n\t\tif ('-- ' + name) in line:\n\t\t\ttry:\n\t\t\t\tchild_line = treelines[idx+1]\n\t\t\texcept:\n\t\t\t\tpass\n\t\t\tbreak\n\treturn child_line\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}, {"term": "def", "name": "test_bind_unbind_with_uclass", "data": "def test_bind_unbind_with_uclass(u_boot_console):\n\t#bind /bind-test\n\tresponse = u_boot_console.run_command('bind  /bind-test simple_bus')\n\tassert response == ''\n\n\t#make sure bind-test-child2 is there and get its uclass/index pair\n\ttree = u_boot_console.run_command('dm tree')\n\tchild2_line = [x.strip() for x in tree.splitlines() if '-- bind-test-child2' in x]\n\tassert len(child2_line) == 1\n\n\tchild2_uclass = child2_line[0].split()[0]\n\tchild2_index = int(child2_line[0].split()[1])\n\n\t#bind simple_bus as a child of bind-test-child2\n\tresponse = u_boot_console.run_command('bind  {} {} simple_bus'.format(child2_uclass, child2_index, 'simple_bus'))\n\n\t#check that the child is there and its uclass/index pair is right\n\ttree = u_boot_console.run_command('dm tree')\n\n\tchild_of_child2_line = get_next_line(tree, 'bind-test-child2')\n\tassert child_of_child2_line\n\tchild_of_child2_index = int(child_of_child2_line.split()[1])\n\tassert in_tree(tree, 'simple_bus', 'simple_bus', 'simple_bus', 2, True)\n\tassert child_of_child2_index == child2_index + 1\n\n\t#unbind the child and check it has been removed\n\tresponse = u_boot_console.run_command('unbind  simple_bus {}'.format(child_of_child2_index))\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'simple_bus', 1, True)\n\tassert not in_tree(tree, 'simple_bus', 'simple_bus', 'simple_bus', 2, True)\n\tchild_of_child2_line = get_next_line(tree, 'bind-test-child2')\n\tassert child_of_child2_line == ''\n\n\t#bind simple_bus as a child of bind-test-child2\n\tresponse = u_boot_console.run_command('bind  {} {} simple_bus'.format(child2_uclass, child2_index, 'simple_bus'))\n\n\t#check that the child is there and its uclass/index pair is right\n\ttree = u_boot_console.run_command('dm tree')\n\ttreelines = [x.strip() for x in tree.splitlines() if x.strip()]\n\n\tchild_of_child2_line = get_next_line(tree, 'bind-test-child2')\n\tassert child_of_child2_line\n\tchild_of_child2_index = int(child_of_child2_line.split()[1])\n\tassert in_tree(tree, 'simple_bus', 'simple_bus', 'simple_bus', 2, True)\n\tassert child_of_child2_index == child2_index + 1\n\n\t#unbind the child and check it has been removed\n\tresponse = u_boot_console.run_command('unbind  {} {} simple_bus'.format(child2_uclass, child2_index, 'simple_bus'))\n\tassert response == ''\n\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'simple_bus', 1, True)\n\n\tchild_of_child2_line = get_next_line(tree, 'bind-test-child2')\n\tassert child_of_child2_line == ''\n\n\t#unbind the child again and check it doesn't change the tree\n\ttree_old = u_boot_console.run_command('dm tree')\n\tresponse = u_boot_console.run_command('unbind  {} {} simple_bus'.format(child2_uclass, child2_index, 'simple_bus'))\n\ttree_new = u_boot_console.run_command('dm tree')\n\n\tassert response == ''\n\tassert tree_old == tree_new\n\n\tresponse = u_boot_console.run_command('unbind  /bind-test')\n\tassert response == ''\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}], [{"term": "def", "name": "in_tree", "data": "def in_tree(response, name, uclass, drv, depth, last_child):\n\tlines = [x.strip() for x in response.splitlines()]\n\tleaf = ' ' * 4 * depth;\n\tif not last_child:\n\t\tleaf = leaf + '\\|'\n\telse:\n\t\tleaf = leaf + '`'\n\tleaf = leaf + '-- ' + name\n\tline = (' *{:10.10}   [0-9]*  \\[ [ +] \\]   {:20.20}  {}$'\n\t\t\t.format(uclass, drv, leaf))\n\tprog = re.compile(line)\n\tfor l in lines:\n\t\tif prog.match(l):\n\t\t\treturn True\n\treturn False\n\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}, {"term": "def", "name": "test_bind_unbind_with_node", "data": "def test_bind_unbind_with_node(u_boot_console):\n\n\t#bind /bind-test. Device should come up as well as its children\n\tresponse = u_boot_console.run_command('bind  /bind-test generic_simple_bus')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'generic_simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, False)\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'generic_simple_bus', 1, True)\n\n\t#Unbind child #1. No error expected and all devices should be there except for bind-test-child1\n\tresponse = u_boot_console.run_command('unbind  /bind-test/bind-test-child1')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'generic_simple_bus', 0, True)\n\tassert 'bind-test-child1' not in tree\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'generic_simple_bus', 1, True)\n\n\t#bind child #1. No error expected and all devices should be there\n\tresponse = u_boot_console.run_command('bind  /bind-test/bind-test-child1 phy_sandbox')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'generic_simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, True)\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'generic_simple_bus', 1, False)\n\n\t#Unbind child #2. No error expected and all devices should be there except for bind-test-child2\n\tresponse = u_boot_console.run_command('unbind  /bind-test/bind-test-child2')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'generic_simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, True)\n\tassert 'bind-test-child2' not in tree\n\n\n\t#Bind child #2. No error expected and all devices should be there\n\tresponse = u_boot_console.run_command('bind /bind-test/bind-test-child2 generic_simple_bus')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'generic_simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, False)\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'generic_simple_bus', 1, True)\n\n\t#Unbind parent. No error expected. All devices should be removed and unbound\n\tresponse = u_boot_console.run_command('unbind  /bind-test')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert 'bind-test' not in tree\n\tassert 'bind-test-child1' not in tree\n\tassert 'bind-test-child2' not in tree\n\n\t#try binding invalid node with valid driver\n\tresponse = u_boot_console.run_command('bind  /not-a-valid-node generic_simple_bus')\n\tassert response != ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert 'not-a-valid-node' not in tree\n\n\t#try binding valid node with invalid driver\n\tresponse = u_boot_console.run_command('bind  /bind-test not_a_driver')\n\tassert response != ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert 'bind-test' not in tree\n\n\t#bind /bind-test. Device should come up as well as its children\n\tresponse = u_boot_console.run_command('bind  /bind-test generic_simple_bus')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'generic_simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, False)\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'generic_simple_bus', 1, True)\n\n\tresponse = u_boot_console.run_command('unbind  /bind-test')\n\tassert response == ''\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}, {"term": "def", "name": "get_next_line", "data": "def get_next_line(tree, name):\n\ttreelines = [x.strip() for x in tree.splitlines() if x.strip()]\n\tchild_line = ''\n\tfor idx, line in enumerate(treelines):\n\t\tif ('-- ' + name) in line:\n\t\t\ttry:\n\t\t\t\tchild_line = treelines[idx+1]\n\t\t\texcept:\n\t\t\t\tpass\n\t\t\tbreak\n\treturn child_line\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}, {"term": "def", "name": "test_bind_unbind_with_uclass", "data": "def test_bind_unbind_with_uclass(u_boot_console):\n\t#bind /bind-test\n\tresponse = u_boot_console.run_command('bind  /bind-test generic_simple_bus')\n\tassert response == ''\n\n\t#make sure bind-test-child2 is there and get its uclass/index pair\n\ttree = u_boot_console.run_command('dm tree')\n\tchild2_line = [x.strip() for x in tree.splitlines() if '-- bind-test-child2' in x]\n\tassert len(child2_line) == 1\n\n\tchild2_uclass = child2_line[0].split()[0]\n\tchild2_index = int(child2_line[0].split()[1])\n\n\t#bind generic_simple_bus as a child of bind-test-child2\n\tresponse = u_boot_console.run_command('bind  {} {} generic_simple_bus'.format(child2_uclass, child2_index, 'generic_simple_bus'))\n\n\t#check that the child is there and its uclass/index pair is right\n\ttree = u_boot_console.run_command('dm tree')\n\n\tchild_of_child2_line = get_next_line(tree, 'bind-test-child2')\n\tassert child_of_child2_line\n\tchild_of_child2_index = int(child_of_child2_line.split()[1])\n\tassert in_tree(tree, 'generic_simple_bus', 'simple_bus', 'generic_simple_bus', 2, True)\n\tassert child_of_child2_index == child2_index + 1\n\n\t#unbind the child and check it has been removed\n\tresponse = u_boot_console.run_command('unbind  simple_bus {}'.format(child_of_child2_index))\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'generic_simple_bus', 1, True)\n\tassert not in_tree(tree, 'generic_simple_bus', 'simple_bus', 'generic_simple_bus', 2, True)\n\tchild_of_child2_line = get_next_line(tree, 'bind-test-child2')\n\tassert child_of_child2_line == ''\n\n\t#bind generic_simple_bus as a child of bind-test-child2\n\tresponse = u_boot_console.run_command('bind  {} {} generic_simple_bus'.format(child2_uclass, child2_index, 'generic_simple_bus'))\n\n\t#check that the child is there and its uclass/index pair is right\n\ttree = u_boot_console.run_command('dm tree')\n\ttreelines = [x.strip() for x in tree.splitlines() if x.strip()]\n\n\tchild_of_child2_line = get_next_line(tree, 'bind-test-child2')\n\tassert child_of_child2_line\n\tchild_of_child2_index = int(child_of_child2_line.split()[1])\n\tassert in_tree(tree, 'generic_simple_bus', 'simple_bus', 'generic_simple_bus', 2, True)\n\tassert child_of_child2_index == child2_index + 1\n\n\t#unbind the child and check it has been removed\n\tresponse = u_boot_console.run_command('unbind  {} {} generic_simple_bus'.format(child2_uclass, child2_index, 'generic_simple_bus'))\n\tassert response == ''\n\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'generic_simple_bus', 1, True)\n\n\tchild_of_child2_line = get_next_line(tree, 'bind-test-child2')\n\tassert child_of_child2_line == ''\n\n\t#unbind the child again and check it doesn't change the tree\n\ttree_old = u_boot_console.run_command('dm tree')\n\tresponse = u_boot_console.run_command('unbind  {} {} generic_simple_bus'.format(child2_uclass, child2_index, 'generic_simple_bus'))\n\ttree_new = u_boot_console.run_command('dm tree')\n\n\tassert response == ''\n\tassert tree_old == tree_new\n\n\tresponse = u_boot_console.run_command('unbind  /bind-test')\n\tassert response == ''\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}], [{"term": "def", "name": "fswig_import_helper", "data": "\tdef swig_import_helper():\n\t\timport importlib\n\t\tpkg = __name__.rpartition('.')[0]\n\t\tmname = '.'.join((pkg, '_param_SimpleDisk')).lstrip('.')\n\t\ttry:\n\t\t\treturn importlib.import_module(mname)\n\t\texcept ImportError:\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleDisk')", "\t_param_SimpleDisk = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleDisk", "\t_param_SimpleDisk = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleDisk", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_DiskImage", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel"]}, {"term": "def", "name": "fswig_import_helper", "data": "\tdef swig_import_helper():\n\t\tfrom os.path import dirname\n\t\timport imp\n\t\tfp = None\n\t\ttry:\n\t\t\tfp, pathname, description = imp.find_module('_param_SimpleDisk', [dirname(__file__)])\n\t\texcept ImportError:\n\t\t\timport _param_SimpleDisk\n\t\t\treturn _param_SimpleDisk\n\t\ttry:\n\t\t\t_mod = imp.load_module('_param_SimpleDisk', fp, pathname, description)\n\t\tfinally:\n\t\t\tif fp is not None:\n\t\t\t\tfp.close()\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleDisk')", "\t_param_SimpleDisk = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleDisk", "\t_param_SimpleDisk = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleDisk", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_DiskImage", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel"]}, {"term": "def", "name": "_swig_setattr_nondynamic", "data": "def _swig_setattr_nondynamic(self, class_type, name, value, static=1):\n\tif (name == \"thisown\"):\n\t\treturn self.this.own(value)\n\tif (name == \"this\"):\n\t\tif type(value).__name__ == 'SwigPyObject':\n\t\t\tself.__dict__[name] = value\n\t\t\treturn\n\tmethod = class_type.__swig_setmethods__.get(name, None)\n\tif method:\n\t\treturn method(self, value)\n\tif (not static):\n\t\tobject.__setattr__(self, name, value)\n\telse:\n\t\traise AttributeError(\"You cannot add attributes to %s\" % self)\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleDisk')", "\t_param_SimpleDisk = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleDisk", "\t_param_SimpleDisk = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleDisk", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_DiskImage", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel"]}, {"term": "def", "name": "_swig_setattr", "data": "def _swig_setattr(self, class_type, name, value):\n\treturn _swig_setattr_nondynamic(self, class_type, name, value, 0)\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleDisk')", "\t_param_SimpleDisk = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleDisk", "\t_param_SimpleDisk = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleDisk", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_DiskImage", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel"]}, {"term": "def", "name": "_swig_getattr", "data": "def _swig_getattr(self, class_type, name):\n\tif (name == \"thisown\"):\n\t\treturn self.this.own()\n\tmethod = class_type.__swig_getmethods__.get(name, None)\n\tif method:\n\t\treturn method(self)\n\traise AttributeError(\"'%s' object has no attribute '%s'\" % (class_type.__name__, name))\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleDisk')", "\t_param_SimpleDisk = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleDisk", "\t_param_SimpleDisk = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleDisk", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_DiskImage", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel"]}, {"term": "def", "name": "_swig_repr", "data": "def _swig_repr(self):\n\ttry:\n\t\tstrthis = \"proxy of \" + self.this.__repr__()\n\texcept __builtin__.Exception:\n\t\tstrthis = \"\"\n\treturn \"<%s.%s; %s >\" % (self.__class__.__module__, self.__class__.__name__, strthis,)\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleDisk')", "\t_param_SimpleDisk = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleDisk", "\t_param_SimpleDisk = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleDisk", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_DiskImage", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel"]}, {"term": "def", "name": "_swig_setattr_nondynamic_method", "data": "def _swig_setattr_nondynamic_method(set):\n\tdef set_attr(self, name, value):\n\t\tif (name == \"thisown\"):\n\t\t\treturn self.this.own(value)\n\t\tif hasattr(self, name) or (name == \"this\"):\n\t\t\tset(self, name, value)\n\t\telse:\n\t\t\traise AttributeError(\"You cannot add attributes to %s\" % self)\n\treturn set_attr\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleDisk')", "\t_param_SimpleDisk = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleDisk", "\t_param_SimpleDisk = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleDisk", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_DiskImage", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel"]}, {"term": "class", "name": "SimpleDisk", "data": "class SimpleDisk(m5.internal.param_SimObject.SimObject):\n\tthisown = _swig_property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc='The membership flag')\n\n\tdef __init__(self, *args, **kwargs):\n\t\traise AttributeError(\"No constructor defined - class is abstract\")\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleDisk')", "\t_param_SimpleDisk = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleDisk", "\t_param_SimpleDisk = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleDisk", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_DiskImage", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel"]}, {"term": "class", "name": "SimpleDiskParams", "data": "class SimpleDiskParams(m5.internal.param_SimObject.SimObjectParams):\n\tthisown = _swig_property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc='The membership flag')\n\t__repr__ = _swig_repr\n\n\tdef create(self):\n\t\treturn _param_SimpleDisk.SimpleDiskParams_create(self)\n\tdisk = _swig_property(_param_SimpleDisk.SimpleDiskParams_disk_get, _param_SimpleDisk.SimpleDiskParams_disk_set)\n\tsystem = _swig_property(_param_SimpleDisk.SimpleDiskParams_system_get, _param_SimpleDisk.SimpleDiskParams_system_set)\n\n\tdef __init__(self):\n\t\tthis = _param_SimpleDisk.new_SimpleDiskParams()\n\t\ttry:\n\t\t\tself.this.append(this)\n\t\texcept __builtin__.Exception:\n\t\t\tself.this = this\n\t__swig_destroy__ = _param_SimpleDisk.delete_SimpleDiskParams\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleDisk')", "\t_param_SimpleDisk = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleDisk", "\t_param_SimpleDisk = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleDisk", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_DiskImage", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel"]}], [{"term": "def", "name": "simple_dtype", "data": "def simple_dtype():\n\tld = np.dtype(\"longdouble\")\n\treturn np.dtype(\n\t\t{\n\t\t\t\"names\": [\"bool_\", \"uint_\", \"float_\", \"ldbl_\"],\n\t\t\t\"formats\": [\"?\", \"u4\", \"f4\", \"f{}\".format(ld.itemsize)],\n\t\t\t\"offsets\": [0, 4, 8, (16 if ld.alignment > 4 else 12)],\n\t\t}\n\t)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "packed_dtype", "data": "def packed_dtype():\n\treturn np.dtype([(\"bool_\", \"?\"), (\"uint_\", \"u4\"), (\"float_\", \"f4\"), (\"ldbl_\", \"g\")])\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "dt_fmt", "data": "def dt_fmt():\n\tfrom sys import byteorder\n\n\te = \"<\" if byteorder == \"little\" else \">\"\n\treturn (\n\t\t\"{{'names':['bool_','uint_','float_','ldbl_'],\"\n\t\t\" 'formats':['?','\" + e + \"u4','\" + e + \"f4','\" + e + \"f{}'],\"\n\t\t\" 'offsets':[0,4,8,{}], 'itemsize':{}}}\"\n\t)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "simple_dtype_fmt", "data": "def simple_dtype_fmt():\n\tld = np.dtype(\"longdouble\")\n\tsimple_ld_off = 12 + 4 * (ld.alignment > 4)\n\treturn dt_fmt().format(ld.itemsize, simple_ld_off, simple_ld_off + ld.itemsize)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "packed_dtype_fmt", "data": "def packed_dtype_fmt():\n\tfrom sys import byteorder\n\n\treturn \"[('bool_', '?'), ('uint_', '{e}u4'), ('float_', '{e}f4'), ('ldbl_', '{e}f{}')]\".format(\n\t\tnp.dtype(\"longdouble\").itemsize, e=\"<\" if byteorder == \"little\" else \">\"\n\t)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "partial_ld_offset", "data": "def partial_ld_offset():\n\treturn (\n\t\t12\n\t\t+ 4 * (np.dtype(\"uint64\").alignment > 4)\n\t\t+ 8\n\t\t+ 8 * (np.dtype(\"longdouble\").alignment > 8)\n\t)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "partial_dtype_fmt", "data": "def partial_dtype_fmt():\n\tld = np.dtype(\"longdouble\")\n\tpartial_ld_off = partial_ld_offset()\n\tpartial_size = partial_ld_off + ld.itemsize\n\tpartial_end_padding = partial_size % np.dtype(\"uint64\").alignment\n\treturn dt_fmt().format(\n\t\tld.itemsize, partial_ld_off, partial_size + partial_end_padding\n\t)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "partial_nested_fmt", "data": "def partial_nested_fmt():\n\tld = np.dtype(\"longdouble\")\n\tpartial_nested_off = 8 + 8 * (ld.alignment > 8)\n\tpartial_ld_off = partial_ld_offset()\n\tpartial_size = partial_ld_off + ld.itemsize\n\tpartial_end_padding = partial_size % np.dtype(\"uint64\").alignment\n\tpartial_nested_size = partial_nested_off * 2 + partial_size + partial_end_padding\n\treturn \"{{'names':['a'], 'formats':[{}], 'offsets':[{}], 'itemsize':{}}}\".format(\n\t\tpartial_dtype_fmt(), partial_nested_off, partial_nested_size\n\t)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "assert_equal", "data": "def assert_equal(actual, expected_data, expected_dtype):\n\tnp.testing.assert_equal(actual, np.array(expected_data, dtype=expected_dtype))\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_format_descriptors", "data": "def test_format_descriptors():\n\twith pytest.raises(RuntimeError) as excinfo:\n\t\tm.get_format_unbound()\n\tassert re.match(\n\t\t\"^NumPy type info missing for .*UnboundStruct.*$\", str(excinfo.value)\n\t)\n\n\tld = np.dtype(\"longdouble\")\n\tldbl_fmt = (\"4x\" if ld.alignment > 4 else \"\") + ld.char\n\tss_fmt = \"^T{?:bool_:3xI:uint_:f:float_:\" + ldbl_fmt + \":ldbl_:}\"\n\tdbl = np.dtype(\"double\")\n\tend_padding = ld.itemsize % np.dtype(\"uint64\").alignment\n\tpartial_fmt = (\n\t\t\"^T{?:bool_:3xI:uint_:f:float_:\"\n\t\t+ str(4 * (dbl.alignment > 4) + dbl.itemsize + 8 * (ld.alignment > 8))\n\t\t+ \"xg:ldbl_:\"\n\t\t+ (str(end_padding) + \"x}\" if end_padding > 0 else \"}\")\n\t)\n\tnested_extra = str(max(8, ld.alignment))\n\tassert m.print_format_descriptors() == [\n\t\tss_fmt,\n\t\t\"^T{?:bool_:I:uint_:f:float_:g:ldbl_:}\",\n\t\t\"^T{\" + ss_fmt + \":a:^T{?:bool_:I:uint_:f:float_:g:ldbl_:}:b:}\",\n\t\tpartial_fmt,\n\t\t\"^T{\" + nested_extra + \"x\" + partial_fmt + \":a:\" + nested_extra + \"x}\",\n\t\t\"^T{3s:a:3s:b:}\",\n\t\t\"^T{(3)4s:a:(2)i:b:(3)B:c:1x(4, 2)f:d:}\",\n\t\t\"^T{q:e1:B:e2:}\",\n\t\t\"^T{Zf:cflt:Zd:cdbl:}\",\n\t]\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_dtype", "data": "def test_dtype(simple_dtype):\n\tfrom sys import byteorder\n\n\te = \"<\" if byteorder == \"little\" else \">\"\n\n\tassert m.print_dtypes() == [\n\t\tsimple_dtype_fmt(),\n\t\tpacked_dtype_fmt(),\n\t\t\"[('a', {}), ('b', {})]\".format(simple_dtype_fmt(), packed_dtype_fmt()),\n\t\tpartial_dtype_fmt(),\n\t\tpartial_nested_fmt(),\n\t\t\"[('a', 'S3'), ('b', 'S3')]\",\n\t\t(\n\t\t\t\"{{'names':['a','b','c','d'], \"\n\t\t\t+ \"'formats':[('S4', (3,)),('\"\n\t\t\t+ e\n\t\t\t+ \"i4', (2,)),('u1', (3,)),('\"\n\t\t\t+ e\n\t\t\t+ \"f4', (4, 2))], \"\n\t\t\t+ \"'offsets':[0,12,20,24], 'itemsize':56}}\"\n\t\t).format(e=e),\n\t\t\"[('e1', '\" + e + \"i8'), ('e2', 'u1')]\",\n\t\t\"[('x', 'i1'), ('y', '\" + e + \"u8')]\",\n\t\t\"[('cflt', '\" + e + \"c8'), ('cdbl', '\" + e + \"c16')]\",\n\t]\n\n\td1 = np.dtype(\n\t\t{\n\t\t\t\"names\": [\"a\", \"b\"],\n\t\t\t\"formats\": [\"int32\", \"float64\"],\n\t\t\t\"offsets\": [1, 10],\n\t\t\t\"itemsize\": 20,\n\t\t}\n\t)\n\td2 = np.dtype([(\"a\", \"i4\"), (\"b\", \"f4\")])\n\tassert m.test_dtype_ctors() == [\n\t\tnp.dtype(\"int32\"),\n\t\tnp.dtype(\"float64\"),\n\t\tnp.dtype(\"bool\"),\n\t\td1,\n\t\td1,\n\t\tnp.dtype(\"uint32\"),\n\t\td2,\n\t]\n\n\tassert m.test_dtype_methods() == [\n\t\tnp.dtype(\"int32\"),\n\t\tsimple_dtype,\n\t\tFalse,\n\t\tTrue,\n\t\tnp.dtype(\"int32\").itemsize,\n\t\tsimple_dtype.itemsize,\n\t]\n\n\tassert m.trailing_padding_dtype() == m.buffer_to_dtype(\n\t\tnp.zeros(1, m.trailing_padding_dtype())\n\t)\n\n\tassert m.test_dtype_kind() == list(\"iiiiiuuuuuffffcccbMmO\")\n\tassert m.test_dtype_char_() == list(\"bhilqBHILQefdgFDG?MmO\")\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_recarray", "data": "def test_recarray(simple_dtype, packed_dtype):\n\telements = [(False, 0, 0.0, -0.0), (True, 1, 1.5, -2.5), (False, 2, 3.0, -5.0)]\n\n\tfor func, dtype in [\n\t\t(m.create_rec_simple, simple_dtype),\n\t\t(m.create_rec_packed, packed_dtype),\n\t]:\n\t\tarr = func(0)\n\t\tassert arr.dtype == dtype\n\t\tassert_equal(arr, [], simple_dtype)\n\t\tassert_equal(arr, [], packed_dtype)\n\n\t\tarr = func(3)\n\t\tassert arr.dtype == dtype\n\t\tassert_equal(arr, elements, simple_dtype)\n\t\tassert_equal(arr, elements, packed_dtype)\n\n\t\t# Show what recarray's look like in NumPy.\n\t\tassert type(arr[0]) == np.void\n\t\tassert type(arr[0].item()) == tuple\n\n\t\tif dtype == simple_dtype:\n\t\t\tassert m.print_rec_simple(arr) == [\n\t\t\t\t\"s:0,0,0,-0\",\n\t\t\t\t\"s:1,1,1.5,-2.5\",\n\t\t\t\t\"s:0,2,3,-5\",\n\t\t\t]\n\t\telse:\n\t\t\tassert m.print_rec_packed(arr) == [\n\t\t\t\t\"p:0,0,0,-0\",\n\t\t\t\t\"p:1,1,1.5,-2.5\",\n\t\t\t\t\"p:0,2,3,-5\",\n\t\t\t]\n\n\tnested_dtype = np.dtype([(\"a\", simple_dtype), (\"b\", packed_dtype)])\n\n\tarr = m.create_rec_nested(0)\n\tassert arr.dtype == nested_dtype\n\tassert_equal(arr, [], nested_dtype)\n\n\tarr = m.create_rec_nested(3)\n\tassert arr.dtype == nested_dtype\n\tassert_equal(\n\t\tarr,\n\t\t[\n\t\t\t((False, 0, 0.0, -0.0), (True, 1, 1.5, -2.5)),\n\t\t\t((True, 1, 1.5, -2.5), (False, 2, 3.0, -5.0)),\n\t\t\t((False, 2, 3.0, -5.0), (True, 3, 4.5, -7.5)),\n\t\t],\n\t\tnested_dtype,\n\t)\n\tassert m.print_rec_nested(arr) == [\n\t\t\"n:a=s:0,0,0,-0;b=p:1,1,1.5,-2.5\",\n\t\t\"n:a=s:1,1,1.5,-2.5;b=p:0,2,3,-5\",\n\t\t\"n:a=s:0,2,3,-5;b=p:1,3,4.5,-7.5\",\n\t]\n\n\tarr = m.create_rec_partial(3)\n\tassert str(arr.dtype) == partial_dtype_fmt()\n\tpartial_dtype = arr.dtype\n\tassert \"\" not in arr.dtype.fields\n\tassert partial_dtype.itemsize > simple_dtype.itemsize\n\tassert_equal(arr, elements, simple_dtype)\n\tassert_equal(arr, elements, packed_dtype)\n\n\tarr = m.create_rec_partial_nested(3)\n\tassert str(arr.dtype) == partial_nested_fmt()\n\tassert \"\" not in arr.dtype.fields\n\tassert \"\" not in arr.dtype.fields[\"a\"][0].fields\n\tassert arr.dtype.itemsize > partial_dtype.itemsize\n\tnp.testing.assert_equal(arr[\"a\"], m.create_rec_partial(3))\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_array_constructors", "data": "def test_array_constructors():\n\tdata = np.arange(1, 7, dtype=\"int32\")\n\tfor i in range(8):\n\t\tnp.testing.assert_array_equal(m.test_array_ctors(10 + i), data.reshape((3, 2)))\n\t\tnp.testing.assert_array_equal(m.test_array_ctors(20 + i), data.reshape((3, 2)))\n\tfor i in range(5):\n\t\tnp.testing.assert_array_equal(m.test_array_ctors(30 + i), data)\n\t\tnp.testing.assert_array_equal(m.test_array_ctors(40 + i), data)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_string_array", "data": "def test_string_array():\n\tarr = m.create_string_array(True)\n\tassert str(arr.dtype) == \"[('a', 'S3'), ('b', 'S3')]\"\n\tassert m.print_string_array(arr) == [\n\t\t\"a='',b=''\",\n\t\t\"a='a',b='a'\",\n\t\t\"a='ab',b='ab'\",\n\t\t\"a='abc',b='abc'\",\n\t]\n\tdtype = arr.dtype\n\tassert arr[\"a\"].tolist() == [b\"\", b\"a\", b\"ab\", b\"abc\"]\n\tassert arr[\"b\"].tolist() == [b\"\", b\"a\", b\"ab\", b\"abc\"]\n\tarr = m.create_string_array(False)\n\tassert dtype == arr.dtype\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_array_array", "data": "def test_array_array():\n\tfrom sys import byteorder\n\n\te = \"<\" if byteorder == \"little\" else \">\"\n\n\tarr = m.create_array_array(3)\n\tassert str(arr.dtype) == (\n\t\t\"{{'names':['a','b','c','d'], \"\n\t\t+ \"'formats':[('S4', (3,)),('\"\n\t\t+ e\n\t\t+ \"i4', (2,)),('u1', (3,)),('{e}f4', (4, 2))], \"\n\t\t+ \"'offsets':[0,12,20,24], 'itemsize':56}}\"\n\t).format(e=e)\n\tassert m.print_array_array(arr) == [\n\t\t\"a={{A,B,C,D},{K,L,M,N},{U,V,W,X}},b={0,1},\"\n\t\t+ \"c={0,1,2},d={{0,1},{10,11},{20,21},{30,31}}\",\n\t\t\"a={{W,X,Y,Z},{G,H,I,J},{Q,R,S,T}},b={1000,1001},\"\n\t\t+ \"c={10,11,12},d={{100,101},{110,111},{120,121},{130,131}}\",\n\t\t\"a={{S,T,U,V},{C,D,E,F},{M,N,O,P}},b={2000,2001},\"\n\t\t+ \"c={20,21,22},d={{200,201},{210,211},{220,221},{230,231}}\",\n\t]\n\tassert arr[\"a\"].tolist() == [\n\t\t[b\"ABCD\", b\"KLMN\", b\"UVWX\"],\n\t\t[b\"WXYZ\", b\"GHIJ\", b\"QRST\"],\n\t\t[b\"STUV\", b\"CDEF\", b\"MNOP\"],\n\t]\n\tassert arr[\"b\"].tolist() == [[0, 1], [1000, 1001], [2000, 2001]]\n\tassert m.create_array_array(0).dtype == arr.dtype\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_enum_array", "data": "def test_enum_array():\n\tfrom sys import byteorder\n\n\te = \"<\" if byteorder == \"little\" else \">\"\n\n\tarr = m.create_enum_array(3)\n\tdtype = arr.dtype\n\tassert dtype == np.dtype([(\"e1\", e + \"i8\"), (\"e2\", \"u1\")])\n\tassert m.print_enum_array(arr) == [\"e1=A,e2=X\", \"e1=B,e2=Y\", \"e1=A,e2=X\"]\n\tassert arr[\"e1\"].tolist() == [-1, 1, -1]\n\tassert arr[\"e2\"].tolist() == [1, 2, 1]\n\tassert m.create_enum_array(0).dtype == dtype\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_complex_array", "data": "def test_complex_array():\n\tfrom sys import byteorder\n\n\te = \"<\" if byteorder == \"little\" else \">\"\n\n\tarr = m.create_complex_array(3)\n\tdtype = arr.dtype\n\tassert dtype == np.dtype([(\"cflt\", e + \"c8\"), (\"cdbl\", e + \"c16\")])\n\tassert m.print_complex_array(arr) == [\n\t\t\"c:(0,0.25),(0.5,0.75)\",\n\t\t\"c:(1,1.25),(1.5,1.75)\",\n\t\t\"c:(2,2.25),(2.5,2.75)\",\n\t]\n\tassert arr[\"cflt\"].tolist() == [0.0 + 0.25j, 1.0 + 1.25j, 2.0 + 2.25j]\n\tassert arr[\"cdbl\"].tolist() == [0.5 + 0.75j, 1.5 + 1.75j, 2.5 + 2.75j]\n\tassert m.create_complex_array(0).dtype == dtype\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_signature", "data": "def test_signature(doc):\n\tassert (\n\t\tdoc(m.create_rec_nested)\n\t\t== \"create_rec_nested(arg0: int) -> numpy.ndarray[NestedStruct]\"\n\t)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_scalar_conversion", "data": "def test_scalar_conversion():\n\tn = 3\n\tarrays = [\n\t\tm.create_rec_simple(n),\n\t\tm.create_rec_packed(n),\n\t\tm.create_rec_nested(n),\n\t\tm.create_enum_array(n),\n\t]\n\tfuncs = [m.f_simple, m.f_packed, m.f_nested]\n\n\tfor i, func in enumerate(funcs):\n\t\tfor j, arr in enumerate(arrays):\n\t\t\tif i == j and i < 2:\n\t\t\t\tassert [func(arr[k]) for k in range(n)] == [k * 10 for k in range(n)]\n\t\t\telse:\n\t\t\t\twith pytest.raises(TypeError) as excinfo:\n\t\t\t\t\tfunc(arr[0])\n\t\t\t\tassert \"incompatible function arguments\" in str(excinfo.value)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_vectorize", "data": "def test_vectorize():\n\tn = 3\n\tarray = m.create_rec_simple(n)\n\tvalues = m.f_simple_vectorized(array)\n\tnp.testing.assert_array_equal(values, [0, 10, 20])\n\tarray_2 = m.f_simple_pass_thru_vectorized(array)\n\tnp.testing.assert_array_equal(array, array_2)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_cls_and_dtype_conversion", "data": "def test_cls_and_dtype_conversion(simple_dtype):\n\ts = m.SimpleStruct()\n\tassert s.astuple() == (False, 0, 0.0, 0.0)\n\tassert m.SimpleStruct.fromtuple(s.astuple()).astuple() == s.astuple()\n\n\ts.uint_ = 2\n\tassert m.f_simple(s) == 20\n\n\t# Try as recarray of shape==(1,).\n\ts_recarray = np.array([(False, 2, 0.0, 0.0)], dtype=simple_dtype)\n\t# Show that this will work for vectorized case.\n\tnp.testing.assert_array_equal(m.f_simple_vectorized(s_recarray), [20])\n\n\t# Show as a scalar that inherits from np.generic.\n\ts_scalar = s_recarray[0]\n\tassert isinstance(s_scalar, np.void)\n\tassert m.f_simple(s_scalar) == 20\n\n\t# Show that an *array* scalar (np.ndarray.shape == ()) does not convert.\n\t# More specifically, conversion to SimpleStruct is not implicit.\n\ts_recarray_scalar = s_recarray.reshape(())\n\tassert isinstance(s_recarray_scalar, np.ndarray)\n\tassert s_recarray_scalar.dtype == simple_dtype\n\twith pytest.raises(TypeError) as excinfo:\n\t\tm.f_simple(s_recarray_scalar)\n\tassert \"incompatible function arguments\" in str(excinfo.value)\n\t# Explicitly convert to m.SimpleStruct.\n\tassert m.f_simple(m.SimpleStruct.fromtuple(s_recarray_scalar.item())) == 20\n\n\t# Show that an array of dtype=object does *not* convert.\n\ts_array_object = np.array([s])\n\tassert s_array_object.dtype == object\n\twith pytest.raises(TypeError) as excinfo:\n\t\tm.f_simple_vectorized(s_array_object)\n\tassert \"incompatible function arguments\" in str(excinfo.value)\n\t# Explicitly convert to `np.array(..., dtype=simple_dtype)`\n\ts_array = np.array([s.astuple()], dtype=simple_dtype)\n\tnp.testing.assert_array_equal(m.f_simple_vectorized(s_array), [20])\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_register_dtype", "data": "def test_register_dtype():\n\twith pytest.raises(RuntimeError) as excinfo:\n\t\tm.register_dtype()\n\tassert \"dtype is already registered\" in str(excinfo.value)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_str_leak", "data": "def test_str_leak():\n\tfrom sys import getrefcount\n\n\tfmt = \"f4\"\n\tpytest.gc_collect()\n\tstart = getrefcount(fmt)\n\td = m.dtype_wrapper(fmt)\n\tassert d is np.dtype(\"f4\")\n\tdel d\n\tpytest.gc_collect()\n\tassert getrefcount(fmt) == start\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_compare_buffer_info", "data": "def test_compare_buffer_info():\n\tassert all(m.compare_buffer_info())\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}], [{"term": "def", "name": "simple_dtype", "data": "def simple_dtype():\n\tld = np.dtype(\"longdouble\")\n\treturn np.dtype(\n\t\t{\n\t\t\t\"names\": [\"bool_\", \"uint_\", \"float_\", \"ldbl_\"],\n\t\t\t\"formats\": [\"?\", \"u4\", \"f4\", \"f{}\".format(ld.itemsize)],\n\t\t\t\"offsets\": [0, 4, 8, (16 if ld.alignment > 4 else 12)],\n\t\t}\n\t)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "packed_dtype", "data": "def packed_dtype():\n\treturn np.dtype([(\"bool_\", \"?\"), (\"uint_\", \"u4\"), (\"float_\", \"f4\"), (\"ldbl_\", \"g\")])\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "dt_fmt", "data": "def dt_fmt():\n\tfrom sys import byteorder\n\n\te = \"<\" if byteorder == \"little\" else \">\"\n\treturn (\n\t\t\"{{'names':['bool_','uint_','float_','ldbl_'],\"\n\t\t\" 'formats':['?','\" + e + \"u4','\" + e + \"f4','\" + e + \"f{}'],\"\n\t\t\" 'offsets':[0,4,8,{}], 'itemsize':{}}}\"\n\t)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "simple_dtype_fmt", "data": "def simple_dtype_fmt():\n\tld = np.dtype(\"longdouble\")\n\tsimple_ld_off = 12 + 4 * (ld.alignment > 4)\n\treturn dt_fmt().format(ld.itemsize, simple_ld_off, simple_ld_off + ld.itemsize)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "packed_dtype_fmt", "data": "def packed_dtype_fmt():\n\tfrom sys import byteorder\n\n\treturn \"[('bool_', '?'), ('uint_', '{e}u4'), ('float_', '{e}f4'), ('ldbl_', '{e}f{}')]\".format(\n\t\tnp.dtype(\"longdouble\").itemsize, e=\"<\" if byteorder == \"little\" else \">\"\n\t)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "partial_ld_offset", "data": "def partial_ld_offset():\n\treturn (\n\t\t12\n\t\t+ 4 * (np.dtype(\"uint64\").alignment > 4)\n\t\t+ 8\n\t\t+ 8 * (np.dtype(\"longdouble\").alignment > 8)\n\t)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "partial_dtype_fmt", "data": "def partial_dtype_fmt():\n\tld = np.dtype(\"longdouble\")\n\tpartial_ld_off = partial_ld_offset()\n\tpartial_size = partial_ld_off + ld.itemsize\n\tpartial_end_padding = partial_size % np.dtype(\"uint64\").alignment\n\treturn dt_fmt().format(\n\t\tld.itemsize, partial_ld_off, partial_size + partial_end_padding\n\t)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "partial_nested_fmt", "data": "def partial_nested_fmt():\n\tld = np.dtype(\"longdouble\")\n\tpartial_nested_off = 8 + 8 * (ld.alignment > 8)\n\tpartial_ld_off = partial_ld_offset()\n\tpartial_size = partial_ld_off + ld.itemsize\n\tpartial_end_padding = partial_size % np.dtype(\"uint64\").alignment\n\tpartial_nested_size = partial_nested_off * 2 + partial_size + partial_end_padding\n\treturn \"{{'names':['a'], 'formats':[{}], 'offsets':[{}], 'itemsize':{}}}\".format(\n\t\tpartial_dtype_fmt(), partial_nested_off, partial_nested_size\n\t)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "assert_equal", "data": "def assert_equal(actual, expected_data, expected_dtype):\n\tnp.testing.assert_equal(actual, np.array(expected_data, dtype=expected_dtype))\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_format_descriptors", "data": "def test_format_descriptors():\n\twith pytest.raises(RuntimeError) as excinfo:\n\t\tm.get_format_unbound()\n\tassert re.match(\n\t\t\"^NumPy type info missing for .*UnboundStruct.*$\", str(excinfo.value)\n\t)\n\n\tld = np.dtype(\"longdouble\")\n\tldbl_fmt = (\"4x\" if ld.alignment > 4 else \"\") + ld.char\n\tss_fmt = \"^T{?:bool_:3xI:uint_:f:float_:\" + ldbl_fmt + \":ldbl_:}\"\n\tdbl = np.dtype(\"double\")\n\tend_padding = ld.itemsize % np.dtype(\"uint64\").alignment\n\tpartial_fmt = (\n\t\t\"^T{?:bool_:3xI:uint_:f:float_:\"\n\t\t+ str(4 * (dbl.alignment > 4) + dbl.itemsize + 8 * (ld.alignment > 8))\n\t\t+ \"xg:ldbl_:\"\n\t\t+ (str(end_padding) + \"x}\" if end_padding > 0 else \"}\")\n\t)\n\tnested_extra = str(max(8, ld.alignment))\n\tassert m.print_format_descriptors() == [\n\t\tss_fmt,\n\t\t\"^T{?:bool_:I:uint_:f:float_:g:ldbl_:}\",\n\t\t\"^T{\" + ss_fmt + \":a:^T{?:bool_:I:uint_:f:float_:g:ldbl_:}:b:}\",\n\t\tpartial_fmt,\n\t\t\"^T{\" + nested_extra + \"x\" + partial_fmt + \":a:\" + nested_extra + \"x}\",\n\t\t\"^T{3s:a:3s:b:}\",\n\t\t\"^T{(3)4s:a:(2)i:b:(3)B:c:1x(4, 2)f:d:}\",\n\t\t\"^T{q:e1:B:e2:}\",\n\t\t\"^T{Zf:cflt:Zd:cdbl:}\",\n\t]\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_dtype", "data": "def test_dtype(simple_dtype):\n\tfrom sys import byteorder\n\n\te = \"<\" if byteorder == \"little\" else \">\"\n\n\tassert m.print_dtypes() == [\n\t\tsimple_dtype_fmt(),\n\t\tpacked_dtype_fmt(),\n\t\t\"[('a', {}), ('b', {})]\".format(simple_dtype_fmt(), packed_dtype_fmt()),\n\t\tpartial_dtype_fmt(),\n\t\tpartial_nested_fmt(),\n\t\t\"[('a', 'S3'), ('b', 'S3')]\",\n\t\t(\n\t\t\t\"{{'names':['a','b','c','d'], \"\n\t\t\t+ \"'formats':[('S4', (3,)),('\"\n\t\t\t+ e\n\t\t\t+ \"i4', (2,)),('u1', (3,)),('\"\n\t\t\t+ e\n\t\t\t+ \"f4', (4, 2))], \"\n\t\t\t+ \"'offsets':[0,12,20,24], 'itemsize':56}}\"\n\t\t).format(e=e),\n\t\t\"[('e1', '\" + e + \"i8'), ('e2', 'u1')]\",\n\t\t\"[('x', 'i1'), ('y', '\" + e + \"u8')]\",\n\t\t\"[('cflt', '\" + e + \"c8'), ('cdbl', '\" + e + \"c16')]\",\n\t]\n\n\td1 = np.dtype(\n\t\t{\n\t\t\t\"names\": [\"a\", \"b\"],\n\t\t\t\"formats\": [\"int32\", \"float64\"],\n\t\t\t\"offsets\": [1, 10],\n\t\t\t\"itemsize\": 20,\n\t\t}\n\t)\n\td2 = np.dtype([(\"a\", \"i4\"), (\"b\", \"f4\")])\n\tassert m.test_dtype_ctors() == [\n\t\tnp.dtype(\"int32\"),\n\t\tnp.dtype(\"float64\"),\n\t\tnp.dtype(\"bool\"),\n\t\td1,\n\t\td1,\n\t\tnp.dtype(\"uint32\"),\n\t\td2,\n\t]\n\n\tassert m.test_dtype_methods() == [\n\t\tnp.dtype(\"int32\"),\n\t\tsimple_dtype,\n\t\tFalse,\n\t\tTrue,\n\t\tnp.dtype(\"int32\").itemsize,\n\t\tsimple_dtype.itemsize,\n\t]\n\n\tassert m.trailing_padding_dtype() == m.buffer_to_dtype(\n\t\tnp.zeros(1, m.trailing_padding_dtype())\n\t)\n\n\tassert m.test_dtype_kind() == list(\"iiiiiuuuuuffffcccbMmO\")\n\tassert m.test_dtype_char_() == list(\"bhilqBHILQefdgFDG?MmO\")\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_recarray", "data": "def test_recarray(simple_dtype, packed_dtype):\n\telements = [(False, 0, 0.0, -0.0), (True, 1, 1.5, -2.5), (False, 2, 3.0, -5.0)]\n\n\tfor func, dtype in [\n\t\t(m.create_rec_simple, simple_dtype),\n\t\t(m.create_rec_packed, packed_dtype),\n\t]:\n\t\tarr = func(0)\n\t\tassert arr.dtype == dtype\n\t\tassert_equal(arr, [], simple_dtype)\n\t\tassert_equal(arr, [], packed_dtype)\n\n\t\tarr = func(3)\n\t\tassert arr.dtype == dtype\n\t\tassert_equal(arr, elements, simple_dtype)\n\t\tassert_equal(arr, elements, packed_dtype)\n\n\t\t# Show what recarray's look like in NumPy.\n\t\tassert type(arr[0]) == np.void\n\t\tassert type(arr[0].item()) == tuple\n\n\t\tif dtype == simple_dtype:\n\t\t\tassert m.print_rec_simple(arr) == [\n\t\t\t\t\"s:0,0,0,-0\",\n\t\t\t\t\"s:1,1,1.5,-2.5\",\n\t\t\t\t\"s:0,2,3,-5\",\n\t\t\t]\n\t\telse:\n\t\t\tassert m.print_rec_packed(arr) == [\n\t\t\t\t\"p:0,0,0,-0\",\n\t\t\t\t\"p:1,1,1.5,-2.5\",\n\t\t\t\t\"p:0,2,3,-5\",\n\t\t\t]\n\n\tnested_dtype = np.dtype([(\"a\", simple_dtype), (\"b\", packed_dtype)])\n\n\tarr = m.create_rec_nested(0)\n\tassert arr.dtype == nested_dtype\n\tassert_equal(arr, [], nested_dtype)\n\n\tarr = m.create_rec_nested(3)\n\tassert arr.dtype == nested_dtype\n\tassert_equal(\n\t\tarr,\n\t\t[\n\t\t\t((False, 0, 0.0, -0.0), (True, 1, 1.5, -2.5)),\n\t\t\t((True, 1, 1.5, -2.5), (False, 2, 3.0, -5.0)),\n\t\t\t((False, 2, 3.0, -5.0), (True, 3, 4.5, -7.5)),\n\t\t],\n\t\tnested_dtype,\n\t)\n\tassert m.print_rec_nested(arr) == [\n\t\t\"n:a=s:0,0,0,-0;b=p:1,1,1.5,-2.5\",\n\t\t\"n:a=s:1,1,1.5,-2.5;b=p:0,2,3,-5\",\n\t\t\"n:a=s:0,2,3,-5;b=p:1,3,4.5,-7.5\",\n\t]\n\n\tarr = m.create_rec_partial(3)\n\tassert str(arr.dtype) == partial_dtype_fmt()\n\tpartial_dtype = arr.dtype\n\tassert \"\" not in arr.dtype.fields\n\tassert partial_dtype.itemsize > simple_dtype.itemsize\n\tassert_equal(arr, elements, simple_dtype)\n\tassert_equal(arr, elements, packed_dtype)\n\n\tarr = m.create_rec_partial_nested(3)\n\tassert str(arr.dtype) == partial_nested_fmt()\n\tassert \"\" not in arr.dtype.fields\n\tassert \"\" not in arr.dtype.fields[\"a\"][0].fields\n\tassert arr.dtype.itemsize > partial_dtype.itemsize\n\tnp.testing.assert_equal(arr[\"a\"], m.create_rec_partial(3))\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_array_constructors", "data": "def test_array_constructors():\n\tdata = np.arange(1, 7, dtype=\"int32\")\n\tfor i in range(8):\n\t\tnp.testing.assert_array_equal(m.test_array_ctors(10 + i), data.reshape((3, 2)))\n\t\tnp.testing.assert_array_equal(m.test_array_ctors(20 + i), data.reshape((3, 2)))\n\tfor i in range(5):\n\t\tnp.testing.assert_array_equal(m.test_array_ctors(30 + i), data)\n\t\tnp.testing.assert_array_equal(m.test_array_ctors(40 + i), data)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_string_array", "data": "def test_string_array():\n\tarr = m.create_string_array(True)\n\tassert str(arr.dtype) == \"[('a', 'S3'), ('b', 'S3')]\"\n\tassert m.print_string_array(arr) == [\n\t\t\"a='',b=''\",\n\t\t\"a='a',b='a'\",\n\t\t\"a='ab',b='ab'\",\n\t\t\"a='abc',b='abc'\",\n\t]\n\tdtype = arr.dtype\n\tassert arr[\"a\"].tolist() == [b\"\", b\"a\", b\"ab\", b\"abc\"]\n\tassert arr[\"b\"].tolist() == [b\"\", b\"a\", b\"ab\", b\"abc\"]\n\tarr = m.create_string_array(False)\n\tassert dtype == arr.dtype\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_array_array", "data": "def test_array_array():\n\tfrom sys import byteorder\n\n\te = \"<\" if byteorder == \"little\" else \">\"\n\n\tarr = m.create_array_array(3)\n\tassert str(arr.dtype) == (\n\t\t\"{{'names':['a','b','c','d'], \"\n\t\t+ \"'formats':[('S4', (3,)),('\"\n\t\t+ e\n\t\t+ \"i4', (2,)),('u1', (3,)),('{e}f4', (4, 2))], \"\n\t\t+ \"'offsets':[0,12,20,24], 'itemsize':56}}\"\n\t).format(e=e)\n\tassert m.print_array_array(arr) == [\n\t\t\"a={{A,B,C,D},{K,L,M,N},{U,V,W,X}},b={0,1},\"\n\t\t+ \"c={0,1,2},d={{0,1},{10,11},{20,21},{30,31}}\",\n\t\t\"a={{W,X,Y,Z},{G,H,I,J},{Q,R,S,T}},b={1000,1001},\"\n\t\t+ \"c={10,11,12},d={{100,101},{110,111},{120,121},{130,131}}\",\n\t\t\"a={{S,T,U,V},{C,D,E,F},{M,N,O,P}},b={2000,2001},\"\n\t\t+ \"c={20,21,22},d={{200,201},{210,211},{220,221},{230,231}}\",\n\t]\n\tassert arr[\"a\"].tolist() == [\n\t\t[b\"ABCD\", b\"KLMN\", b\"UVWX\"],\n\t\t[b\"WXYZ\", b\"GHIJ\", b\"QRST\"],\n\t\t[b\"STUV\", b\"CDEF\", b\"MNOP\"],\n\t]\n\tassert arr[\"b\"].tolist() == [[0, 1], [1000, 1001], [2000, 2001]]\n\tassert m.create_array_array(0).dtype == arr.dtype\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_enum_array", "data": "def test_enum_array():\n\tfrom sys import byteorder\n\n\te = \"<\" if byteorder == \"little\" else \">\"\n\n\tarr = m.create_enum_array(3)\n\tdtype = arr.dtype\n\tassert dtype == np.dtype([(\"e1\", e + \"i8\"), (\"e2\", \"u1\")])\n\tassert m.print_enum_array(arr) == [\"e1=A,e2=X\", \"e1=B,e2=Y\", \"e1=A,e2=X\"]\n\tassert arr[\"e1\"].tolist() == [-1, 1, -1]\n\tassert arr[\"e2\"].tolist() == [1, 2, 1]\n\tassert m.create_enum_array(0).dtype == dtype\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_complex_array", "data": "def test_complex_array():\n\tfrom sys import byteorder\n\n\te = \"<\" if byteorder == \"little\" else \">\"\n\n\tarr = m.create_complex_array(3)\n\tdtype = arr.dtype\n\tassert dtype == np.dtype([(\"cflt\", e + \"c8\"), (\"cdbl\", e + \"c16\")])\n\tassert m.print_complex_array(arr) == [\n\t\t\"c:(0,0.25),(0.5,0.75)\",\n\t\t\"c:(1,1.25),(1.5,1.75)\",\n\t\t\"c:(2,2.25),(2.5,2.75)\",\n\t]\n\tassert arr[\"cflt\"].tolist() == [0.0 + 0.25j, 1.0 + 1.25j, 2.0 + 2.25j]\n\tassert arr[\"cdbl\"].tolist() == [0.5 + 0.75j, 1.5 + 1.75j, 2.5 + 2.75j]\n\tassert m.create_complex_array(0).dtype == dtype\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_signature", "data": "def test_signature(doc):\n\tassert (\n\t\tdoc(m.create_rec_nested)\n\t\t== \"create_rec_nested(arg0: int) -> numpy.ndarray[NestedStruct]\"\n\t)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_scalar_conversion", "data": "def test_scalar_conversion():\n\tn = 3\n\tarrays = [\n\t\tm.create_rec_simple(n),\n\t\tm.create_rec_packed(n),\n\t\tm.create_rec_nested(n),\n\t\tm.create_enum_array(n),\n\t]\n\tfuncs = [m.f_simple, m.f_packed, m.f_nested]\n\n\tfor i, func in enumerate(funcs):\n\t\tfor j, arr in enumerate(arrays):\n\t\t\tif i == j and i < 2:\n\t\t\t\tassert [func(arr[k]) for k in range(n)] == [k * 10 for k in range(n)]\n\t\t\telse:\n\t\t\t\twith pytest.raises(TypeError) as excinfo:\n\t\t\t\t\tfunc(arr[0])\n\t\t\t\tassert \"incompatible function arguments\" in str(excinfo.value)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_vectorize", "data": "def test_vectorize():\n\tn = 3\n\tarray = m.create_rec_simple(n)\n\tvalues = m.f_simple_vectorized(array)\n\tnp.testing.assert_array_equal(values, [0, 10, 20])\n\tarray_2 = m.f_simple_pass_thru_vectorized(array)\n\tnp.testing.assert_array_equal(array, array_2)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_cls_and_dtype_conversion", "data": "def test_cls_and_dtype_conversion(simple_dtype):\n\ts = m.SimpleStruct()\n\tassert s.astuple() == (False, 0, 0.0, 0.0)\n\tassert m.SimpleStruct.fromtuple(s.astuple()).astuple() == s.astuple()\n\n\ts.uint_ = 2\n\tassert m.f_simple(s) == 20\n\n\t# Try as recarray of shape==(1,).\n\ts_recarray = np.array([(False, 2, 0.0, 0.0)], dtype=simple_dtype)\n\t# Show that this will work for vectorized case.\n\tnp.testing.assert_array_equal(m.f_simple_vectorized(s_recarray), [20])\n\n\t# Show as a scalar that inherits from np.generic.\n\ts_scalar = s_recarray[0]\n\tassert isinstance(s_scalar, np.void)\n\tassert m.f_simple(s_scalar) == 20\n\n\t# Show that an *array* scalar (np.ndarray.shape == ()) does not convert.\n\t# More specifically, conversion to SimpleStruct is not implicit.\n\ts_recarray_scalar = s_recarray.reshape(())\n\tassert isinstance(s_recarray_scalar, np.ndarray)\n\tassert s_recarray_scalar.dtype == simple_dtype\n\twith pytest.raises(TypeError) as excinfo:\n\t\tm.f_simple(s_recarray_scalar)\n\tassert \"incompatible function arguments\" in str(excinfo.value)\n\t# Explicitly convert to m.SimpleStruct.\n\tassert m.f_simple(m.SimpleStruct.fromtuple(s_recarray_scalar.item())) == 20\n\n\t# Show that an array of dtype=object does *not* convert.\n\ts_array_object = np.array([s])\n\tassert s_array_object.dtype == object\n\twith pytest.raises(TypeError) as excinfo:\n\t\tm.f_simple_vectorized(s_array_object)\n\tassert \"incompatible function arguments\" in str(excinfo.value)\n\t# Explicitly convert to `np.array(..., dtype=simple_dtype)`\n\ts_array = np.array([s.astuple()], dtype=simple_dtype)\n\tnp.testing.assert_array_equal(m.f_simple_vectorized(s_array), [20])\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_register_dtype", "data": "def test_register_dtype():\n\twith pytest.raises(RuntimeError) as excinfo:\n\t\tm.register_dtype()\n\tassert \"dtype is already registered\" in str(excinfo.value)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_str_leak", "data": "def test_str_leak():\n\tfrom sys import getrefcount\n\n\tfmt = \"f4\"\n\tpytest.gc_collect()\n\tstart = getrefcount(fmt)\n\td = m.dtype_wrapper(fmt)\n\tassert d is np.dtype(\"f4\")\n\tdel d\n\tpytest.gc_collect()\n\tassert getrefcount(fmt) == start\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_compare_buffer_info", "data": "def test_compare_buffer_info():\n\tassert all(m.compare_buffer_info())\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}], [{"term": "class", "name": "ScannerError", "data": "class ScannerError(MarkedError):\n\tpass\n\n", "description": null, "category": "simple", "imports": ["from .error import MarkedError", "from .tokens import *  # NOQA", "\tfrom __builtin__ import unicode"]}, {"term": "class", "name": "classSimpleKey:", "data": "class SimpleKey:\n\t# See below simple keys treatment.\n\tdef __init__(self, token_number, index, line, column, mark):\n\t\tself.token_number = token_number\n\t\tself.index = index\n\t\tself.line = line\n\t\tself.column = column\n\t\tself.mark = mark\n\n", "description": null, "category": "simple", "imports": ["from .error import MarkedError", "from .tokens import *  # NOQA", "\tfrom __builtin__ import unicode"]}, {"term": "class", "name": "classScanner:", "data": "class Scanner:\n\tdef __init__(self):\n\t\t\"\"\"Initialize the scanner.\"\"\"\n\t\t# It is assumed that Scanner and Reader will have a common descendant.\n\t\t# Reader do the dirty work of checking for BOM and converting the\n\t\t# input data to Unicode. It also adds NUL to the end.\n\t\t#\n\t\t# Reader supports the following methods\n\t\t#\tself.peek(i=0)\t\t # peek the next i-th character\n\t\t#\tself.prefix(l=1)\t # peek the next l characters\n\t\t#\tself.forward(l=1)\t # read the next l characters and move the pointer.\n\n\t\t# Had we reached the end of the stream?\n\t\tself.done = False\n\n\t\t# The number of unclosed '{' and '['. `flow_level == 0` means block\n\t\t# context.\n\t\tself.flow_level = 0\n\n\t\t# List of processed tokens that are not yet emitted.\n\t\tself.tokens = []\n\n\t\t# Add the STREAM-START token.\n\t\tself.fetch_stream_start()\n\n\t\t# Number of tokens that were emitted through the `get_token` method.\n\t\tself.tokens_taken = 0\n\n\t\t# Variables related to simple keys treatment.\n\n\t\t# A simple key is a key that is not denoted by the '?' indicator.\n\t\t# We emit the KEY token before all keys, so when we find a potential\n\t\t# simple key, we try to locate the corresponding ':' indicator.\n\t\t# Simple keys should be limited to a single line.\n\n\t\t# Can a simple key start at the current position? A simple key may\n\t\t# start:\n\t\t# - after '{', '[', ',' (in the flow context),\n\t\tself.allow_simple_key = False\n\n\t\t# Keep track of possible simple keys. This is a dictionary. The key\n\t\t# is `flow_level`; there can be no more that one possible simple key\n\t\t# for each level. The value is a SimpleKey record:\n\t\t#\t(token_number, index, line, column, mark)\n\t\t# A simple key may start with SCALAR(flow), '[', or '{' tokens.\n\t\tself.possible_simple_keys = {}\n\n\t# Public methods.\n\n\tdef check_token(self, *choices):\n\t\t# Check if the next token is one of the given types.\n\t\twhile self.need_more_tokens():\n\t\t\tself.fetch_more_tokens()\n\t\tif self.tokens:\n\t\t\tif not choices:\n\t\t\t\treturn True\n\t\t\tfor choice in choices:\n\t\t\t\tif isinstance(self.tokens[0], choice):\n\t\t\t\t\treturn True\n\t\treturn False\n\n\tdef peek_token(self):\n\t\t# Return the next token, but do not delete if from the queue.\n\t\twhile self.need_more_tokens():\n\t\t\tself.fetch_more_tokens()\n\t\tif self.tokens:\n\t\t\treturn self.tokens[0]\n\n\tdef get_token(self):\n\t\t# Return the next token.\n\t\twhile self.need_more_tokens():\n\t\t\tself.fetch_more_tokens()\n\t\tif self.tokens:\n\t\t\tself.tokens_taken += 1\n\t\t\treturn self.tokens.pop(0)\n\n\t# Private methods.\n\n\tdef need_more_tokens(self):\n\t\tif self.done:\n\t\t\treturn False\n\t\tif not self.tokens:\n\t\t\treturn True\n\t\t# The current token may be a potential simple key, so we\n\t\t# need to look further.\n\t\tself.stale_possible_simple_keys()\n\t\tif self.next_possible_simple_key() == self.tokens_taken:\n\t\t\treturn True\n\n\tdef fetch_more_tokens(self):\n\n\t\t# Eat whitespaces and comments until we reach the next token.\n\t\tself.scan_to_next_token()\n\n\t\t# Remove obsolete possible simple keys.\n\t\tself.stale_possible_simple_keys()\n\n\t\t# Peek the next character.\n\t\tch = self.peek()\n\n\t\t# Is it the end of stream?\n\t\tif ch == '\\0':\n\t\t\treturn self.fetch_stream_end()\n\n\t\t# Note: the order of the following checks is NOT significant.\n\n\t\t# Is it the flow sequence start indicator?\n\t\tif ch == '[':\n\t\t\treturn self.fetch_flow_sequence_start()\n\n\t\t# Is it the flow mapping start indicator?\n\t\tif ch == '{':\n\t\t\treturn self.fetch_flow_mapping_start()\n\n\t\t# Is it the flow sequence end indicator?\n\t\tif ch == ']':\n\t\t\treturn self.fetch_flow_sequence_end()\n\n\t\t# Is it the flow mapping end indicator?\n\t\tif ch == '}':\n\t\t\treturn self.fetch_flow_mapping_end()\n\n\t\t# Is it the flow entry indicator?\n\t\tif ch == ',':\n\t\t\treturn self.fetch_flow_entry()\n\n\t\t# Is it the value indicator?\n\t\tif ch == ':' and self.flow_level:\n\t\t\treturn self.fetch_value()\n\n\t\t# Is it a double quoted scalar?\n\t\tif ch == '\\\"':\n\t\t\treturn self.fetch_double()\n\n\t\t# It must be a plain scalar then.\n\t\tif self.check_plain():\n\t\t\treturn self.fetch_plain()\n\n\t\t# No? It's an error. Let's produce a nice error message.\n\t\traise ScannerError(\"while scanning for the next token\", None,\n\t\t\t\t\"found character %r that cannot start any token\" % ch,\n\t\t\t\tself.get_mark())\n\n\t# Simple keys treatment.\n\n\tdef next_possible_simple_key(self):\n\t\t# Return the number of the nearest possible simple key. Actually we\n\t\t# don't need to loop through the whole dictionary. We may replace it\n\t\t# with the following code:\n\t\t#\tif not self.possible_simple_keys:\n\t\t#\t\treturn None\n\t\t#\treturn self.possible_simple_keys[\n\t\t#\t\t\tmin(self.possible_simple_keys.keys())].token_number\n\t\tmin_token_number = None\n\t\tfor level in self.possible_simple_keys:\n\t\t\tkey = self.possible_simple_keys[level]\n\t\t\tif min_token_number is None or key.token_number < min_token_number:\n\t\t\t\tmin_token_number = key.token_number\n\t\treturn min_token_number\n\n\tdef stale_possible_simple_keys(self):\n\t\t# Remove entries that are no longer possible simple keys. According to\n\t\t# the YAML specification, simple keys\n\t\t# - should be limited to a single line,\n\t\t# Disabling this procedure will allow simple keys of any length and\n\t\t# height (may cause problems if indentation is broken though).\n\t\tfor level in list(self.possible_simple_keys):\n\t\t\tkey = self.possible_simple_keys[level]\n\t\t\tif key.line != self.line:\n\t\t\t\tdel self.possible_simple_keys[level]\n\n\tdef save_possible_simple_key(self):\n\t\t# The next token may start a simple key. We check if it's possible\n\t\t# and save its position. This function is called for\n\t\t#\tSCALAR(flow), '[', and '{'.\n\n\t\t# The next token might be a simple key. Let's save it's number and\n\t\t# position.\n\t\tif self.allow_simple_key:\n\t\t\tself.remove_possible_simple_key()\n\t\t\ttoken_number = self.tokens_taken + len(self.tokens)\n\t\t\tkey = SimpleKey(token_number,\n\t\t\t\t\tself.index, self.line, self.column, self.get_mark())\n\t\t\tself.possible_simple_keys[self.flow_level] = key\n\n\tdef remove_possible_simple_key(self):\n\t\t# Remove the saved possible key position at the current flow level.\n\t\tif self.flow_level in self.possible_simple_keys:\n\t\t\tdel self.possible_simple_keys[self.flow_level]\n\n\t# Fetchers.\n\n\tdef fetch_stream_start(self):\n\t\t# We always add STREAM-START as the first token and STREAM-END as the\n\t\t# last token.\n\n\t\t# Read the token.\n\t\tmark = self.get_mark()\n\n\t\t# Add STREAM-START.\n\t\tself.tokens.append(StreamStartToken(mark, mark,\n\t\t\tencoding=self.encoding))\n\n\tdef fetch_stream_end(self):\n\t\t# Reset simple keys.\n\t\tself.remove_possible_simple_key()\n\t\tself.allow_simple_key = False\n\t\tself.possible_simple_keys = {}\n\n\t\t# Read the token.\n\t\tmark = self.get_mark()\n\n\t\t# Add STREAM-END.\n\t\tself.tokens.append(StreamEndToken(mark, mark))\n\n\t\t# The steam is finished.\n\t\tself.done = True\n\n\tdef fetch_flow_sequence_start(self):\n\t\tself.fetch_flow_collection_start(FlowSequenceStartToken)\n\n\tdef fetch_flow_mapping_start(self):\n\t\tself.fetch_flow_collection_start(FlowMappingStartToken)\n\n\tdef fetch_flow_collection_start(self, TokenClass):\n\n\t\t# '[' and '{' may start a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# Increase the flow level.\n\t\tself.flow_level += 1\n\n\t\t# Simple keys are allowed after '[' and '{'.\n\t\tself.allow_simple_key = True\n\n\t\t# Add FLOW-SEQUENCE-START or FLOW-MAPPING-START.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(TokenClass(start_mark, end_mark))\n\n\tdef fetch_flow_sequence_end(self):\n\t\tself.fetch_flow_collection_end(FlowSequenceEndToken)\n\n\tdef fetch_flow_mapping_end(self):\n\t\tself.fetch_flow_collection_end(FlowMappingEndToken)\n\n\tdef fetch_flow_collection_end(self, TokenClass):\n\n\t\t# Reset possible simple key on the current level.\n\t\tself.remove_possible_simple_key()\n\n\t\t# Decrease the flow level.\n\t\tself.flow_level -= 1\n\n\t\t# No simple keys after ']' or '}'.\n\t\tself.allow_simple_key = False\n\n\t\t# Add FLOW-SEQUENCE-END or FLOW-MAPPING-END.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(TokenClass(start_mark, end_mark))\n\n\tdef fetch_value(self):\n\t\t# Do we determine a simple key?\n\t\tif self.flow_level in self.possible_simple_keys:\n\n\t\t\t# Add KEY.\n\t\t\tkey = self.possible_simple_keys[self.flow_level]\n\t\t\tdel self.possible_simple_keys[self.flow_level]\n\t\t\tself.tokens.insert(key.token_number - self.tokens_taken,\n\t\t\t\t\tKeyToken(key.mark, key.mark))\n\n\t\t\t# There cannot be two simple keys one after another.\n\t\t\tself.allow_simple_key = False\n\n\t\t# Add VALUE.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(ValueToken(start_mark, end_mark))\n\n\tdef fetch_flow_entry(self):\n\n\t\t# Simple keys are allowed after ','.\n\t\tself.allow_simple_key = True\n\n\t\t# Reset possible simple key on the current level.\n\t\tself.remove_possible_simple_key()\n\n\t\t# Add FLOW-ENTRY.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(FlowEntryToken(start_mark, end_mark))\n\n\tdef fetch_double(self):\n\t\t# A flow scalar could be a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# No simple keys after flow scalars.\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add SCALAR.\n\t\tself.tokens.append(self.scan_flow_scalar())\n\n\tdef fetch_plain(self):\n\n\t\tself.save_possible_simple_key()\n\n\t\t# No simple keys after plain scalars.\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add SCALAR. May change `allow_simple_key`.\n\t\tself.tokens.append(self.scan_plain())\n\n\t# Checkers.\n\n\tdef check_plain(self):\n\t\treturn self.peek() in '0123456789-ntf'\n\n\t# Scanners.\n\n\tdef scan_to_next_token(self):\n\t\twhile self.peek() in ' \\t\\n':\n\t\t\tself.forward()\n\n\tdef scan_flow_scalar(self):\n\t\t# See the specification for details.\n\t\t# Note that we loose indentation rules for quoted scalars. Quoted\n\t\t# scalars don't need to adhere indentation because \" and ' clearly\n\t\t# mark the beginning and the end of them. Therefore we are less\n\t\t# restrictive then the specification requires. We only need to check\n\t\t# that document separators are not included in scalars.\n\t\tchunks = []\n\t\tstart_mark = self.get_mark()\n\t\tquote = self.peek()\n\t\tself.forward()\n\t\tchunks.extend(self.scan_flow_scalar_non_spaces(start_mark))\n\t\twhile self.peek() != quote:\n\t\t\tchunks.extend(self.scan_flow_scalar_spaces(start_mark))\n\t\t\tchunks.extend(self.scan_flow_scalar_non_spaces(start_mark))\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\treturn ScalarToken(unicode().join(chunks), False, start_mark, end_mark, '\"')\n\n\tESCAPE_REPLACEMENTS = {\n\t\t'b': '\\x08',\n\t\t't': '\\x09',\n\t\t'n': '\\x0A',\n\t\t'f': '\\x0C',\n\t\t'r': '\\x0D',\n\t\t'\\\"': '\\\"',\n\t\t'\\\\': '\\\\',\n\t}\n\n\tESCAPE_CODES = {\n\t\t'u': 4,\n\t}\n\n\tdef scan_flow_scalar_non_spaces(self, start_mark):\n\t\t# See the specification for details.\n\t\tchunks = []\n\t\twhile True:\n\t\t\tlength = 0\n\t\t\twhile self.peek(length) not in '\\\"\\\\\\0 \\t\\n':\n\t\t\t\tlength += 1\n\t\t\tif length:\n\t\t\t\tchunks.append(self.prefix(length))\n\t\t\t\tself.forward(length)\n\t\t\tch = self.peek()\n\t\t\tif ch == '\\\\':\n\t\t\t\tself.forward()\n\t\t\t\tch = self.peek()\n\t\t\t\tif ch in self.ESCAPE_REPLACEMENTS:\n\t\t\t\t\tchunks.append(self.ESCAPE_REPLACEMENTS[ch])\n\t\t\t\t\tself.forward()\n\t\t\t\telif ch in self.ESCAPE_CODES:\n\t\t\t\t\tlength = self.ESCAPE_CODES[ch]\n\t\t\t\t\tself.forward()\n\t\t\t\t\tfor k in range(length):\n\t\t\t\t\t\tif self.peek(k) not in '0123456789ABCDEFabcdef':\n\t\t\t\t\t\t\traise ScannerError(\"while scanning a double-quoted scalar\", start_mark,\n\t\t\t\t\t\t\t\t\t\"expected escape sequence of %d hexdecimal numbers, but found %r\" %\n\t\t\t\t\t\t\t\t\t\t(length, self.peek(k)), self.get_mark())\n\t\t\t\t\tcode = int(self.prefix(length), 16)\n\t\t\t\t\tchunks.append(chr(code))\n\t\t\t\t\tself.forward(length)\n\t\t\t\telse:\n\t\t\t\t\traise ScannerError(\"while scanning a double-quoted scalar\", start_mark,\n\t\t\t\t\t\t\t\"found unknown escape character %r\" % ch, self.get_mark())\n\t\t\telse:\n\t\t\t\treturn chunks\n\n\tdef scan_flow_scalar_spaces(self, start_mark):\n\t\t# See the specification for details.\n\t\tchunks = []\n\t\tlength = 0\n\t\twhile self.peek(length) in ' \\t':\n\t\t\tlength += 1\n\t\twhitespaces = self.prefix(length)\n\t\tself.forward(length)\n\t\tch = self.peek()\n\t\tif ch == '\\0':\n\t\t\traise ScannerError(\"while scanning a quoted scalar\", start_mark,\n\t\t\t\t\t\"found unexpected end of stream\", self.get_mark())\n\t\telif ch == '\\n':\n\t\t\traise ScannerError(\"while scanning a quoted scalar\", start_mark,\n\t\t\t\t\t\"found unexpected line end\", self.get_mark())\n\t\telse:\n\t\t\tchunks.append(whitespaces)\n\t\treturn chunks\n\n\tdef scan_plain(self):\n\t\tchunks = []\n\t\tstart_mark = self.get_mark()\n\t\tspaces = []\n\t\twhile True:\n\t\t\tlength = 0\n\t\t\twhile True:\n\t\t\t\tif self.peek(length) not in 'eE.0123456789nul-tr+fas':\n\t\t\t\t\tbreak\n\t\t\t\tlength += 1\n\t\t\tif length == 0:\n\t\t\t\tbreak\n\t\t\tself.allow_simple_key = False\n\t\t\tchunks.extend(spaces)\n\t\t\tchunks.append(self.prefix(length))\n\t\t\tself.forward(length)\n\t\tend_mark = self.get_mark()\n\t\treturn ScalarToken(''.join(chunks), True, start_mark, end_mark)\n", "description": "Initialize the scanner.", "category": "simple", "imports": ["from .error import MarkedError", "from .tokens import *  # NOQA", "\tfrom __builtin__ import unicode"]}], [{"term": "def", "name": "ApN", "data": "def ApN(accur):\n\taccur = int(accur)\n\tElev = NE\n\tJ = range(1+int(math.ceil(ApLen/accur)))\n\tI = range(1+int(math.ceil(((ApLen*Div)+RSW/2)/accur)))\n\ts = []\n\tfor i in I:\n\t\tK = []\n\t\tT = []\n\t\tfor j in J:\n\t\t\tperp = Div*ApLen+(RSW/2)\t  -  i*accur\t - j*accur*Div\n\t\t\tpar = ApLen - j*accur\n\t\t\tif perp <= 0:\n\t\t\t\tperp = 0\n\t\t\tif par <= 0:\n\t\t\t\tpar = 0\n\t\t\tZ = Elev + Slope*par\n\t\t\tK.append([par,perp,Z])\n\t\t\tif perp == 0:\n\t\t\t\tT.append(j)\n\t\ts.append(K)\n\t\tif len(T) > 0:\n\t\t\tJ = range(T[0]+1)\n\tF = [1,-1]\n\tfor n in range(2):\n\t\t#folder \n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\t\t\n\t\tf.write( '\\n')\n\t\t\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\t\n\t\tf.write( '\\n')\n\t\tf.write( 'Runway: Code '+str(CN)+'\\n')\n\t\tf.write( '0\\n')\n\t\n\t\tf.write('\\n')\n\t\tf.write('\\n')\n\t\tf.write('\\n')\n\t\tf.write('\\n')\t\n\t\tf.write('#KMLStyler\\n')\n\t\tf.write('\\n')\t\t\t\t\n\t\tf.write('\\n')\n\t\tf.write('Dimensions\\n')\n\t\tf.write('-\\n')\n\t\tfor b in range(len(ToOls)):\n\t\t\tf.write(''+str(ToOls[1][b])+'\\n')\n\n\t\t\t\t\t\t\n\t\tf.write('\\n')\n\t\tf.write('\\n')\n\t\tf.write('\\n')\n\n\t\tif n == 0:\n\t\t\tf.write( 'North'+NRunwayInfo[0]+'1\\n')\n\t\t\t\n\t\t\t   \n\t\tif n == 1:\n\t\t\tf.write( 'North'+NRunwayInfo[0]+'2\\n')\n\t\thero = []\n\t\t\n\t\tI = range(len(s))\n\t\tfor i in I:\n\t\t\tJ = range(len(s[i]))\n\t\t\tfor j in J:\t\t\t   \n\t\t\t\tif i < max(I):\n\t\t\t\t\tif j < (len(s[i+1])-1):\n\t##\t\t\t\t\tprint 'flag1',(len(s[i+1])-1),j < (len(s[i+1])-1)\n\n\n\t\t\t\t\t\tif n == 0:\n\t\t\t\t\t\t\txx =[\n\t\t\t\t\t\t\t[s[i][j][0]*F[1],\ts[i][j][1]*F[0],\t\ts[i][j][2]],\n\t\t\t\t\t\t\t[s[i][j+1][0]*F[1],  s[i][j+1][1]*F[0],\t  s[i][j+1][2]],\n\t\t\t\t\t\t\t[s[i+1][j+1][0]*F[1],s[i+1][j+1][1]*F[0],\ts[i+1][j+1][2]],\n\t\t\t\t\t\t\t[s[i+1][j][0]*F[1],  s[i+1][j][1]*F[0],\t  s[i+1][j][2]],\n\t\t\t\t\t\t\t[s[i][j][0]*F[1],\ts[i][j][1]*F[0],\t\ts[i][j][2]]\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t\tns = 'n'\n\t\t\t\t\t\tif n == 1:\n\t\t\t\t\t\t\txx =[\n\t\t\t\t\t\t\t[s[i][j][0]*F[1],\ts[i][j][1]*F[1],\t\ts[i][j][2]],\n\t\t\t\t\t\t\t[s[i][j+1][0]*F[1],  s[i][j+1][1]*F[1],\t  s[i][j+1][2]],\n\t\t\t\t\t\t\t[s[i+1][j+1][0]*F[1],s[i+1][j+1][1]*F[1],\ts[i+1][j+1][2]],\n\t\t\t\t\t\t\t[s[i+1][j][0]*F[1],  s[i+1][j][1]*F[1],\t  s[i+1][j][2]],\n\t\t\t\t\t\t\t[s[i][j][0]*F[1],\ts[i][j][1]*F[1],\t\ts[i][j][2]]\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t\tns = 'n'\n\t\t\t\t\t\tf.write(   \"\\n\")\n\t\t\t\t\t\tf.write(   \"n=\"+str(n)+\" i=\"+str(i)+\" j=\"+str(j)+\"\\n\")  \n\t\t\t\t\t\tf.write(   \"#m_ylw-pushpin\\n\")\n\t\t\t\t\t\t##extended data\n\t\t\t\t\t\tH = []\n\t\t\t\t\t\tfor h in range(len(xx)):\n\t\t\t\t\t\t\te = xx[h][2]\n\t\t\t\t\t\t\tUtm = mdl.toUTM(NTE,NTN,STE,STN,ARP,SE,NE,xx[h][0],xx[h][1],xx[h][2],ns)\n\t\t\t\t\t\t\tWgs = list(mdl.U_W(Utm[0],Utm[1],zone, e))\n\t\t\t\t\t\t\tH.append(Wgs[2])\n\t\t\t\t\t\tHn = min(H)\n\t\t\t\t\t\tHm = max(H)\n\t\t\t\t\t\tf.write(   \"\")\n\t\t\t\t\t\tf.write(   '')\n\t\t\t\t\t\tf.write(   ''+NRunwayInfo[0]+'')\n\t\t\t\t\t\tf.write(   ''+str(Hn)+'')\n\t\t\t\t\t\tf.write(   ''+str(Hm)+'')\n\t\t\t\t\t\tf.write(   '')\t\n\t\t\t\t\t\tf.write(   \"\")\n\t\t\t\t\t\n\t\t\t\t\t\tf.write(   \"\\n\")\n\t\t\t\t\t\tf.write(   \"absolute\\n\")\n\t\t\t\t\t\tf.write(   \"\\n\")\n\t\t\t\t\t\tf.write(   \"\\n\")\n\t\t\t\t\t\tf.write(   \"\\n\")\n\t\t\t\t\t\t\n\t\t\t\t\t\tfor h in range(len(xx)):\n\t\t\t\t\t\t\te = xx[h][2]\n\t\t\t\t\t\t\tUtm = mdl.toUTM(NTE,NTN,STE,STN,ARP,SE,NE,xx[h][0],xx[h][1],xx[h][2],ns)\n\t\t\t\t\t\t\tWgs = list(mdl.U_W(Utm[0],Utm[1],zone, e))\n\t\t\t\t\t\t\tH.append(Wgs[2])\n\t\t\t\t\t\t\tf.write(str(Wgs[0])+\",\"+str(Wgs[1])+\",\"+str(Wgs[2]))\n\t\t\t\t\t\t\tf.write(   \"\\n\")\n\n\t\t\t\t\t\tf.write(   \"\\n\")\n\t\t\t\t\t\tf.write(   \"\\n\")\n\t\t\t\t\t\tf.write(   \"\\n\")   \n\t\t\t\t\t\t\n\t\t\t\t\t\t\n\t\t\t\t\t\tf.write(   \"\\n\")\t\t\n\t\t\t\t\t\tf.write(   \"\\n\")\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\t\t\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n", "description": null, "category": "simple", "imports": ["import math", "import OLSDims", "import mdl", "import EnvSettings", "from osgeo import osr"]}, {"term": "def", "name": "ApS", "data": "def ApS(accur):\n\taccur = int(accur)\n\tElev = SE\n\tJ = range(1+int(math.ceil(ApLen/accur)))\n\tI = range(1+int(math.ceil(((ApLen*Div)+RSW/2)/accur)))\n\ts = []\n\tfor i in I:\n\t\tK = []\n\t\tT = []\n\t\tfor j in J:\n\t\t\tperp = Div*ApLen+(RSW/2)\t  -  i*accur\t - j*accur*Div\n\t\t\tpar = ApLen - j*accur\n\t\t\tif perp <= 0:\n\t\t\t\tperp = 0\n\t\t\tif par <= 0:\n\t\t\t\tpar = 0\n\t\t\tZ = Elev + Slope*par\n\t\t\tK.append([par,perp,Z])\n\t\t\t\n\t\t\tif perp == 0:\n\t\t\t\tT.append(j)\n\t\t\t\n\t\ts.append(K)\n\t\t\n\t\tif len(T) > 0:\n\t\t\tJ = range(T[0]+1)\n\tF = [1,-1]\n\tfor n in range(2):\n\t\t#folder \n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\t\t\n\t\tf.write( '\\n')\n\t\t\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\t\n\t\tf.write( '\\n')\n\t\tf.write( 'Runway: Code '+str(CN)+'\\n')\n\t\tf.write( '0\\n')\n\t\n\t\tf.write('\\n')\n\t\tf.write('\\n')\n\t\tf.write('\\n')\n\t\tf.write('\\n')\t\n\t\tf.write('#KMLStyler\\n')\n\t\tf.write('\\n')\t\t\t\t\n\t\tf.write('\\n')\n\t\tf.write('Dimensions\\n')\n\t\tf.write('-\\n')\n\t\tfor b in range(len(ToOls)):\n\t\t\tf.write(''+str(ToOls[1][b])+'\\n')\n\n\t\t\t\t\t\t\n\t\tf.write('\\n')\n\t\tf.write('\\n')\n\t\tf.write('\\n')\n\n\t\tif n == 0:\n\t\t\tf.write( 'North'+NRunwayInfo[0]+'1\\n')\n\t\t\t\n\t\t\t   \n\t\tif n == 1:\n\t\t\tf.write( 'North'+NRunwayInfo[0]+'2\\n')\n\t\thero = []\n\t\t\n\t\tI = range(len(s))\n\t\tfor i in I:\n\t\t\tJ = range(len(s[i]))\n\t\t\tfor j in J:\t\t\t   \n\t\t\t\tif i < max(I):\n\t\t\t\t\tif j < (len(s[i+1])-1):\n\t##\t\t\t\t\tprint 'flag1',(len(s[i+1])-1),j < (len(s[i+1])-1)\n\n\n\t\t\t\t\t\tif n == 0:\n\t\t\t\t\t\t\txx =[\n\t\t\t\t\t\t\t[s[i][j][0]*F[1],\ts[i][j][1]*F[0],\t\ts[i][j][2]],\n\t\t\t\t\t\t\t[s[i][j+1][0]*F[1],  s[i][j+1][1]*F[0],\t  s[i][j+1][2]],\n\t\t\t\t\t\t\t[s[i+1][j+1][0]*F[1],s[i+1][j+1][1]*F[0],\ts[i+1][j+1][2]],\n\t\t\t\t\t\t\t[s[i+1][j][0]*F[1],  s[i+1][j][1]*F[0],\t  s[i+1][j][2]],\n\t\t\t\t\t\t\t[s[i][j][0]*F[1],\ts[i][j][1]*F[0],\t\ts[i][j][2]]\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t\tns = 's'\n\t\t\t\t\t\tif n == 1:\n\t\t\t\t\t\t\txx =[\n\t\t\t\t\t\t\t[s[i][j][0]*F[1],\ts[i][j][1]*F[1],\t\ts[i][j][2]],\n\t\t\t\t\t\t\t[s[i][j+1][0]*F[1],  s[i][j+1][1]*F[1],\t  s[i][j+1][2]],\n\t\t\t\t\t\t\t[s[i+1][j+1][0]*F[1],s[i+1][j+1][1]*F[1],\ts[i+1][j+1][2]],\n\t\t\t\t\t\t\t[s[i+1][j][0]*F[1],  s[i+1][j][1]*F[1],\t  s[i+1][j][2]],\n\t\t\t\t\t\t\t[s[i][j][0]*F[1],\ts[i][j][1]*F[1],\t\ts[i][j][2]]\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t\tns = 's'\n\t\t\t\t\t\tf.write(   \"\\n\")\n\t\t\t\t\t\tf.write(   \"n=\"+str(n)+\" i=\"+str(i)+\" j=\"+str(j)+\"\\n\")  \n\t\t\t\t\t\tf.write(   \"#m_ylw-pushpin\\n\")\n\t\t\t\t\t\t##extended data\n\t\t\t\t\t\tH = []\n\t\t\t\t\t\tfor h in range(len(xx)):\n\t\t\t\t\t\t\te = xx[h][2]\n\t\t\t\t\t\t\tUtm = mdl.toUTM(NTE,NTN,STE,STN,ARP,SE,NE,xx[h][0],xx[h][1],xx[h][2],ns)\n\t\t\t\t\t\t\tWgs = list(mdl.U_W(Utm[0],Utm[1],zone, e))\n\t\t\t\t\t\t\tH.append(Wgs[2])\n\t\t\t\t\t\tHn = min(H)\n\t\t\t\t\t\tHm = max(H)\n\t\t\t\t\t\tf.write(   \"\")\n\t\t\t\t\t\tf.write(   '')\n\t\t\t\t\t\tf.write(   ''+NRunwayInfo[0]+'')\n\t\t\t\t\t\tf.write(   ''+str(Hn)+'')\n\t\t\t\t\t\tf.write(   ''+str(Hm)+'')\n\t\t\t\t\t\tf.write(   '')\t\n\t\t\t\t\t\tf.write(   \"\")\n\t\t\t\t\t\n\t\t\t\t\t\tf.write(   \"\\n\")\n\t\t\t\t\t\tf.write(   \"absolute\\n\")\n\t\t\t\t\t\tf.write(   \"\\n\")\n\t\t\t\t\t\tf.write(   \"\\n\")\n\t\t\t\t\t\tf.write(   \"\\n\")\n\t\t\t\t\t\t\n\t\t\t\t\t\tfor h in range(len(xx)):\n\t\t\t\t\t\t\te = xx[h][2]\n\t\t\t\t\t\t\tUtm = mdl.toUTM(NTE,NTN,STE,STN,ARP,SE,NE,xx[h][0],xx[h][1],xx[h][2],ns)\n\t\t\t\t\t\t\tWgs = list(mdl.U_W(Utm[0],Utm[1],zone, e))\n\t\t\t\t\t\t\tH.append(Wgs[2])\n\t\t\t\t\t\t\tf.write(str(Wgs[0])+\",\"+str(Wgs[1])+\",\"+str(Wgs[2]))\n\t\t\t\t\t\t\tf.write(   \"\\n\")\n\n\t\t\t\t\t\tf.write(   \"\\n\")\n\t\t\t\t\t\tf.write(   \"\\n\")\n\t\t\t\t\t\tf.write(   \"\\n\")   \n\t\t\t\t\t\t\n\t\t\t\t\t\t\n\t\t\t\t\t\tf.write(   \"\\n\")\t\t\n\t\t\t\t\t\tf.write(   \"\\n\")\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\t\t\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n", "description": null, "category": "simple", "imports": ["import math", "import OLSDims", "import mdl", "import EnvSettings", "from osgeo import osr"]}], [{"term": "def", "name": "in_tree", "data": "def in_tree(response, name, uclass, drv, depth, last_child):\n\tlines = [x.strip() for x in response.splitlines()]\n\tleaf = ''\n\tif depth != 0:\n\t\tleaf = '   ' + '\t' * (depth - 1) ;\n\t\tif not last_child:\n\t\t\tleaf = leaf + r'\\|'\n\t\telse:\n\t\t\t\t\t\tleaf = leaf + '`'\n\n\tleaf = leaf + '-- ' + name\n\tline = (r' *{:10.10} *[0-9]*  \\[ [ +] \\]   {:20.20}  [` |]{}$'\n\t\t\t.format(uclass, drv, leaf))\n\tprog = re.compile(line)\n\tfor l in lines:\n\t\tif prog.match(l):\n\t\t\treturn True\n\treturn False\n\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}, {"term": "def", "name": "test_bind_unbind_with_node", "data": "def test_bind_unbind_with_node(u_boot_console):\n\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, False)\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'simple_bus', 1, True)\n\n\t#Unbind child #1. No error expected and all devices should be there except for bind-test-child1\n\tresponse = u_boot_console.run_command('unbind  /bind-test/bind-test-child1')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'simple_bus', 0, True)\n\tassert 'bind-test-child1' not in tree\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'simple_bus', 1, True)\n\n\t#bind child #1. No error expected and all devices should be there\n\tresponse = u_boot_console.run_command('bind  /bind-test/bind-test-child1 phy_sandbox')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, True)\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'simple_bus', 1, False)\n\n\t#Unbind child #2. No error expected and all devices should be there except for bind-test-child2\n\tresponse = u_boot_console.run_command('unbind  /bind-test/bind-test-child2')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, True)\n\tassert 'bind-test-child2' not in tree\n\n\n\t#Bind child #2. No error expected and all devices should be there\n\tresponse = u_boot_console.run_command('bind /bind-test/bind-test-child2 simple_bus')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, False)\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'simple_bus', 1, True)\n\n\t#Unbind parent. No error expected. All devices should be removed and unbound\n\tresponse = u_boot_console.run_command('unbind  /bind-test')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert 'bind-test' not in tree\n\tassert 'bind-test-child1' not in tree\n\tassert 'bind-test-child2' not in tree\n\n\t#try binding invalid node with valid driver\n\tresponse = u_boot_console.run_command('bind  /not-a-valid-node simple_bus')\n\tassert response != ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert 'not-a-valid-node' not in tree\n\n\t#try binding valid node with invalid driver\n\tresponse = u_boot_console.run_command('bind  /bind-test not_a_driver')\n\tassert response != ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert 'bind-test' not in tree\n\n\t#bind /bind-test. Device should come up as well as its children\n\tresponse = u_boot_console.run_command('bind  /bind-test simple_bus')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, False)\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'simple_bus', 1, True)\n\n\tresponse = u_boot_console.run_command('unbind  /bind-test')\n\tassert response == ''\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}, {"term": "def", "name": "get_next_line", "data": "def get_next_line(tree, name):\n\ttreelines = [x.strip() for x in tree.splitlines() if x.strip()]\n\tchild_line = ''\n\tfor idx, line in enumerate(treelines):\n\t\tif ('-- ' + name) in line:\n\t\t\ttry:\n\t\t\t\tchild_line = treelines[idx+1]\n\t\t\texcept:\n\t\t\t\tpass\n\t\t\tbreak\n\treturn child_line\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}, {"term": "def", "name": "test_bind_unbind_with_uclass", "data": "def test_bind_unbind_with_uclass(u_boot_console):\n\t#bind /bind-test\n\tresponse = u_boot_console.run_command('bind  /bind-test simple_bus')\n\tassert response == ''\n\n\t#make sure bind-test-child2 is there and get its uclass/index pair\n\ttree = u_boot_console.run_command('dm tree')\n\tchild2_line = [x.strip() for x in tree.splitlines() if '-- bind-test-child2' in x]\n\tassert len(child2_line) == 1\n\n\tchild2_uclass = child2_line[0].split()[0]\n\tchild2_index = int(child2_line[0].split()[1])\n\n\t#bind simple_bus as a child of bind-test-child2\n\tresponse = u_boot_console.run_command('bind  {} {} simple_bus'.format(child2_uclass, child2_index, 'simple_bus'))\n\n\t#check that the child is there and its uclass/index pair is right\n\ttree = u_boot_console.run_command('dm tree')\n\n\tchild_of_child2_line = get_next_line(tree, 'bind-test-child2')\n\tassert child_of_child2_line\n\tchild_of_child2_index = int(child_of_child2_line.split()[1])\n\tassert in_tree(tree, 'simple_bus', 'simple_bus', 'simple_bus', 2, True)\n\tassert child_of_child2_index == child2_index + 1\n\n\t#unbind the child and check it has been removed\n\tresponse = u_boot_console.run_command('unbind  simple_bus {}'.format(child_of_child2_index))\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'simple_bus', 1, True)\n\tassert not in_tree(tree, 'simple_bus', 'simple_bus', 'simple_bus', 2, True)\n\tchild_of_child2_line = get_next_line(tree, 'bind-test-child2')\n\tassert child_of_child2_line == ''\n\n\t#bind simple_bus as a child of bind-test-child2\n\tresponse = u_boot_console.run_command('bind  {} {} simple_bus'.format(child2_uclass, child2_index, 'simple_bus'))\n\n\t#check that the child is there and its uclass/index pair is right\n\ttree = u_boot_console.run_command('dm tree')\n\ttreelines = [x.strip() for x in tree.splitlines() if x.strip()]\n\n\tchild_of_child2_line = get_next_line(tree, 'bind-test-child2')\n\tassert child_of_child2_line\n\tchild_of_child2_index = int(child_of_child2_line.split()[1])\n\tassert in_tree(tree, 'simple_bus', 'simple_bus', 'simple_bus', 2, True)\n\tassert child_of_child2_index == child2_index + 1\n\n\t#unbind the child and check it has been removed\n\tresponse = u_boot_console.run_command('unbind  {} {} simple_bus'.format(child2_uclass, child2_index, 'simple_bus'))\n\tassert response == ''\n\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'simple_bus', 1, True)\n\n\tchild_of_child2_line = get_next_line(tree, 'bind-test-child2')\n\tassert child_of_child2_line == ''\n\n\t#unbind the child again and check it doesn't change the tree\n\ttree_old = u_boot_console.run_command('dm tree')\n\tresponse = u_boot_console.run_command('unbind  {} {} simple_bus'.format(child2_uclass, child2_index, 'simple_bus'))\n\ttree_new = u_boot_console.run_command('dm tree')\n\n\tassert response == ''\n\tassert tree_old == tree_new\n\n\tresponse = u_boot_console.run_command('unbind  /bind-test')\n\tassert response == ''\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}], [{"term": "def", "name": "in_tree", "data": "def in_tree(response, name, uclass, drv, depth, last_child):\n\tlines = [x.strip() for x in response.splitlines()]\n\tleaf = ''\n\tif depth != 0:\n\t\tleaf = '   ' + '\t' * (depth - 1) ;\n\t\tif not last_child:\n\t\t\tleaf = leaf + r'\\|'\n\t\telse:\n\t\t\t\t\t\tleaf = leaf + '`'\n\n\tleaf = leaf + '-- ' + name\n\tline = (r' *{:10.10} *[0-9]*  \\[ [ +] \\]   {:20.20}  [` |]{}$'\n\t\t\t.format(uclass, drv, leaf))\n\tprog = re.compile(line)\n\tfor l in lines:\n\t\tif prog.match(l):\n\t\t\treturn True\n\treturn False\n\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}, {"term": "def", "name": "test_bind_unbind_with_node", "data": "def test_bind_unbind_with_node(u_boot_console):\n\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, False)\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'simple_bus', 1, True)\n\n\t#Unbind child #1. No error expected and all devices should be there except for bind-test-child1\n\tresponse = u_boot_console.run_command('unbind  /bind-test/bind-test-child1')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'simple_bus', 0, True)\n\tassert 'bind-test-child1' not in tree\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'simple_bus', 1, True)\n\n\t#bind child #1. No error expected and all devices should be there\n\tresponse = u_boot_console.run_command('bind  /bind-test/bind-test-child1 phy_sandbox')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, True)\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'simple_bus', 1, False)\n\n\t#Unbind child #2. No error expected and all devices should be there except for bind-test-child2\n\tresponse = u_boot_console.run_command('unbind  /bind-test/bind-test-child2')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, True)\n\tassert 'bind-test-child2' not in tree\n\n\n\t#Bind child #2. No error expected and all devices should be there\n\tresponse = u_boot_console.run_command('bind /bind-test/bind-test-child2 simple_bus')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, False)\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'simple_bus', 1, True)\n\n\t#Unbind parent. No error expected. All devices should be removed and unbound\n\tresponse = u_boot_console.run_command('unbind  /bind-test')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert 'bind-test' not in tree\n\tassert 'bind-test-child1' not in tree\n\tassert 'bind-test-child2' not in tree\n\n\t#try binding invalid node with valid driver\n\tresponse = u_boot_console.run_command('bind  /not-a-valid-node simple_bus')\n\tassert response != ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert 'not-a-valid-node' not in tree\n\n\t#try binding valid node with invalid driver\n\tresponse = u_boot_console.run_command('bind  /bind-test not_a_driver')\n\tassert response != ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert 'bind-test' not in tree\n\n\t#bind /bind-test. Device should come up as well as its children\n\tresponse = u_boot_console.run_command('bind  /bind-test simple_bus')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, False)\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'simple_bus', 1, True)\n\n\tresponse = u_boot_console.run_command('unbind  /bind-test')\n\tassert response == ''\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}, {"term": "def", "name": "get_next_line", "data": "def get_next_line(tree, name):\n\ttreelines = [x.strip() for x in tree.splitlines() if x.strip()]\n\tchild_line = ''\n\tfor idx, line in enumerate(treelines):\n\t\tif ('-- ' + name) in line:\n\t\t\ttry:\n\t\t\t\tchild_line = treelines[idx+1]\n\t\t\texcept:\n\t\t\t\tpass\n\t\t\tbreak\n\treturn child_line\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}, {"term": "def", "name": "test_bind_unbind_with_uclass", "data": "def test_bind_unbind_with_uclass(u_boot_console):\n\t#bind /bind-test\n\tresponse = u_boot_console.run_command('bind  /bind-test simple_bus')\n\tassert response == ''\n\n\t#make sure bind-test-child2 is there and get its uclass/index pair\n\ttree = u_boot_console.run_command('dm tree')\n\tchild2_line = [x.strip() for x in tree.splitlines() if '-- bind-test-child2' in x]\n\tassert len(child2_line) == 1\n\n\tchild2_uclass = child2_line[0].split()[0]\n\tchild2_index = int(child2_line[0].split()[1])\n\n\t#bind simple_bus as a child of bind-test-child2\n\tresponse = u_boot_console.run_command('bind  {} {} simple_bus'.format(child2_uclass, child2_index, 'simple_bus'))\n\n\t#check that the child is there and its uclass/index pair is right\n\ttree = u_boot_console.run_command('dm tree')\n\n\tchild_of_child2_line = get_next_line(tree, 'bind-test-child2')\n\tassert child_of_child2_line\n\tchild_of_child2_index = int(child_of_child2_line.split()[1])\n\tassert in_tree(tree, 'simple_bus', 'simple_bus', 'simple_bus', 2, True)\n\tassert child_of_child2_index == child2_index + 1\n\n\t#unbind the child and check it has been removed\n\tresponse = u_boot_console.run_command('unbind  simple_bus {}'.format(child_of_child2_index))\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'simple_bus', 1, True)\n\tassert not in_tree(tree, 'simple_bus', 'simple_bus', 'simple_bus', 2, True)\n\tchild_of_child2_line = get_next_line(tree, 'bind-test-child2')\n\tassert child_of_child2_line == ''\n\n\t#bind simple_bus as a child of bind-test-child2\n\tresponse = u_boot_console.run_command('bind  {} {} simple_bus'.format(child2_uclass, child2_index, 'simple_bus'))\n\n\t#check that the child is there and its uclass/index pair is right\n\ttree = u_boot_console.run_command('dm tree')\n\ttreelines = [x.strip() for x in tree.splitlines() if x.strip()]\n\n\tchild_of_child2_line = get_next_line(tree, 'bind-test-child2')\n\tassert child_of_child2_line\n\tchild_of_child2_index = int(child_of_child2_line.split()[1])\n\tassert in_tree(tree, 'simple_bus', 'simple_bus', 'simple_bus', 2, True)\n\tassert child_of_child2_index == child2_index + 1\n\n\t#unbind the child and check it has been removed\n\tresponse = u_boot_console.run_command('unbind  {} {} simple_bus'.format(child2_uclass, child2_index, 'simple_bus'))\n\tassert response == ''\n\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'simple_bus', 1, True)\n\n\tchild_of_child2_line = get_next_line(tree, 'bind-test-child2')\n\tassert child_of_child2_line == ''\n\n\t#unbind the child again and check it doesn't change the tree\n\ttree_old = u_boot_console.run_command('dm tree')\n\tresponse = u_boot_console.run_command('unbind  {} {} simple_bus'.format(child2_uclass, child2_index, 'simple_bus'))\n\ttree_new = u_boot_console.run_command('dm tree')\n\n\tassert response == ''\n\tassert tree_old == tree_new\n\n\tresponse = u_boot_console.run_command('unbind  /bind-test')\n\tassert response == ''\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}], [{"term": "class", "name": "TagTestCaseBase", "data": "class TagTestCaseBase(unittest.TestCase):\n\tdef setUp(self):\n\t\tself.t1 = tag.Tag(tag.tagClassUniversal, tag.tagFormatSimple, 3)\n\t\tself.t2 = tag.Tag(tag.tagClassUniversal, tag.tagFormatSimple, 3)\n", "description": null, "category": "simple", "imports": ["from pyasn1.type import tag", "from pyasn1.error import PyAsn1Error", "from sys import version_info", "\t\timport unittest2 as unittest", "\t\timport unittest", "\timport unittest"]}, {"term": "class", "name": "TagCmpTestCase", "data": "class TagCmpTestCase(TagTestCaseBase):\n\tdef testCmp(self):\n\t\tassert self.t1 == self.t2, 'tag comparation fails'\n\n\tdef testHash(self):\n\t\tassert hash(self.t1) == hash(self.t2), 'tag hash comparation fails'\n\n\tdef testSequence(self):\n\t\tassert self.t1[0] == self.t2[0] and \\\n\t\t\t   self.t1[1] == self.t2[1] and \\\n\t\t\t   self.t1[2] == self.t2[2], 'tag sequence protocol fails'\n", "description": null, "category": "simple", "imports": ["from pyasn1.type import tag", "from pyasn1.error import PyAsn1Error", "from sys import version_info", "\t\timport unittest2 as unittest", "\t\timport unittest", "\timport unittest"]}, {"term": "class", "name": "TagSetTestCaseBase", "data": "class TagSetTestCaseBase(unittest.TestCase):\n\tdef setUp(self):\n\t\tself.ts1 = tag.initTagSet(\n\t\t\ttag.Tag(tag.tagClassUniversal, tag.tagFormatSimple, 12)\n\t\t\t)\n\t\tself.ts2 = tag.initTagSet(\n\t\t\ttag.Tag(tag.tagClassUniversal, tag.tagFormatSimple, 12)\n\t\t\t)\n", "description": null, "category": "simple", "imports": ["from pyasn1.type import tag", "from pyasn1.error import PyAsn1Error", "from sys import version_info", "\t\timport unittest2 as unittest", "\t\timport unittest", "\timport unittest"]}, {"term": "class", "name": "TagSetCmpTestCase", "data": "class TagSetCmpTestCase(TagSetTestCaseBase):\n\tdef testCmp(self):\n\t\tassert self.ts1 == self.ts2, 'tag set comparation fails'\n\n\tdef testHash(self):\n\t\tassert hash(self.ts1) == hash(self.ts2), 'tag set hash comp. fails'\n\n\tdef testLen(self):\n\t\tassert len(self.ts1) == len(self.ts2), 'tag length comparation fails'\n", "description": null, "category": "simple", "imports": ["from pyasn1.type import tag", "from pyasn1.error import PyAsn1Error", "from sys import version_info", "\t\timport unittest2 as unittest", "\t\timport unittest", "\timport unittest"]}, {"term": "class", "name": "TaggingTestSuite", "data": "class TaggingTestSuite(TagSetTestCaseBase):\n\tdef testImplicitTag(self):\n\t\tt = self.ts1.tagImplicitly(\n\t\t\ttag.Tag(tag.tagClassApplication, tag.tagFormatSimple, 14)\n\t\t\t)\n\t\tassert t == tag.TagSet(\n\t\t\ttag.Tag(tag.tagClassApplication, tag.tagFormatSimple, 12),\n\t\t\ttag.Tag(tag.tagClassApplication, tag.tagFormatSimple, 14)\n\t\t\t), 'implicit tagging went wrong'\n\n\tdef testExplicitTag(self):\n\t\tt = self.ts1.tagExplicitly(\n\t\t\ttag.Tag(tag.tagClassPrivate, tag.tagFormatSimple, 32)\n\t\t\t)\n\t\tassert t == tag.TagSet(\n\t\t\ttag.Tag(tag.tagClassUniversal, tag.tagFormatSimple, 12),\n\t\t\ttag.Tag(tag.tagClassUniversal, tag.tagFormatSimple, 12),\n\t\t\ttag.Tag(tag.tagClassPrivate, tag.tagFormatConstructed, 32)\n\t\t\t), 'explicit tagging went wrong'\n", "description": null, "category": "simple", "imports": ["from pyasn1.type import tag", "from pyasn1.error import PyAsn1Error", "from sys import version_info", "\t\timport unittest2 as unittest", "\t\timport unittest", "\timport unittest"]}, {"term": "class", "name": "TagSetAddTestSuite", "data": "class TagSetAddTestSuite(TagSetTestCaseBase):\n\tdef testAdd(self):\n\t\tt = self.ts1 + tag.Tag(tag.tagClassApplication, tag.tagFormatSimple, 2)\n\t\tassert t == tag.TagSet(\n\t\t\ttag.Tag(tag.tagClassUniversal, tag.tagFormatSimple, 12),\n\t\t\ttag.Tag(tag.tagClassUniversal, tag.tagFormatSimple, 12),\n\t\t\ttag.Tag(tag.tagClassApplication, tag.tagFormatSimple, 2)\n\t\t\t), 'TagSet.__add__() fails'\n\n\tdef testRadd(self):\n\t\tt = tag.Tag(tag.tagClassApplication, tag.tagFormatSimple, 2) + self.ts1\n\t\tassert t == tag.TagSet(\n\t\t\ttag.Tag(tag.tagClassUniversal, tag.tagFormatSimple, 12),\n\t\t\ttag.Tag(tag.tagClassApplication, tag.tagFormatSimple, 2),\n\t\t\ttag.Tag(tag.tagClassUniversal, tag.tagFormatSimple, 12)\n\t\t\t), 'TagSet.__radd__() fails'\n", "description": null, "category": "simple", "imports": ["from pyasn1.type import tag", "from pyasn1.error import PyAsn1Error", "from sys import version_info", "\t\timport unittest2 as unittest", "\t\timport unittest", "\timport unittest"]}, {"term": "class", "name": "SuperTagSetTestCase", "data": "class SuperTagSetTestCase(TagSetTestCaseBase):\n\tdef testSuperTagCheck1(self):\n\t\tassert self.ts1.isSuperTagSetOf(\n\t\t\ttag.TagSet(\n\t\t\ttag.Tag(tag.tagClassUniversal, tag.tagFormatSimple, 12),\n\t\t\ttag.Tag(tag.tagClassUniversal, tag.tagFormatSimple, 12)\n\t\t\t)), 'isSuperTagSetOf() fails'\n\n\tdef testSuperTagCheck2(self):\n\t\tassert not self.ts1.isSuperTagSetOf(\n\t\t\ttag.TagSet(\n\t\t\ttag.Tag(tag.tagClassUniversal, tag.tagFormatSimple, 12),\n\t\t\ttag.Tag(tag.tagClassUniversal, tag.tagFormatSimple, 13)\n\t\t\t)), 'isSuperTagSetOf() fails'\n\n\tdef testSuperTagCheck3(self):\n\t\tassert self.ts1.isSuperTagSetOf(\n\t\t\ttag.TagSet((), tag.Tag(tag.tagClassUniversal,\n\t\t\t\t\t\t\t\t   tag.tagFormatSimple, 12))\n\t\t\t), 'isSuperTagSetOf() fails'\n", "description": null, "category": "simple", "imports": ["from pyasn1.type import tag", "from pyasn1.error import PyAsn1Error", "from sys import version_info", "\t\timport unittest2 as unittest", "\t\timport unittest", "\timport unittest"]}], [{"term": "class", "name": "TestIsSimplePath", "data": "class TestIsSimplePath(object):\n\t\"\"\"Unit tests for the\n\t:func:`networkx.algorithms.simple_paths.is_simple_path` function.\n\n\t\"\"\"\n\n\tdef test_empty_list(self):\n\t\t\"\"\"Tests that the empty list is not a valid path, since there\n\t\tshould be a one-to-one correspondence between paths as lists of\n\t\tnodes and paths as lists of edges.\n\n\t\t\"\"\"\n\t\tG = nx.trivial_graph()\n\t\tassert_false(nx.is_simple_path(G, []))\n\n\tdef test_trivial_path(self):\n\t\t\"\"\"Tests that the trivial path, a path of length one, is\n\t\tconsidered a simple path in a graph.\n\n\t\t\"\"\"\n\t\tG = nx.trivial_graph()\n\t\tassert_true(nx.is_simple_path(G, [0]))\n\n\tdef test_trivial_nonpath(self):\n\t\t\"\"\"Tests that a list whose sole element is an object not in the\n\t\tgraph is not considered a simple path.\n\n\t\t\"\"\"\n\t\tG = nx.trivial_graph()\n\t\tassert_false(nx.is_simple_path(G, ['not a node']))\n\n\tdef test_simple_path(self):\n\t\tG = nx.path_graph(2)\n\t\tassert_true(nx.is_simple_path(G, [0, 1]))\n\n\tdef test_non_simple_path(self):\n\t\tG = nx.path_graph(2)\n\t\tassert_false(nx.is_simple_path(G, [0, 1, 0]))\n\n\tdef test_cycle(self):\n\t\tG = nx.cycle_graph(3)\n\t\tassert_false(nx.is_simple_path(G, [0, 1, 2, 0]))\n\n\tdef test_missing_node(self):\n\t\tG = nx.path_graph(2)\n\t\tassert_false(nx.is_simple_path(G, [0, 2]))\n\n\tdef test_directed_path(self):\n\t\tG = nx.DiGraph([(0, 1), (1, 2)])\n\t\tassert_true(nx.is_simple_path(G, [0, 1, 2]))\n\n\tdef test_directed_non_path(self):\n\t\tG = nx.DiGraph([(0, 1), (1, 2)])\n\t\tassert_false(nx.is_simple_path(G, [2, 1, 0]))\n\n\tdef test_directed_cycle(self):\n\t\tG = nx.DiGraph([(0, 1), (1, 2), (2, 0)])\n\t\tassert_false(nx.is_simple_path(G, [0, 1, 2, 0]))\n\n\tdef test_multigraph(self):\n\t\tG = nx.MultiGraph([(0, 1), (0, 1)])\n\t\tassert_true(nx.is_simple_path(G, [0, 1]))\n\n\tdef test_multidigraph(self):\n\t\tG = nx.MultiDiGraph([(0, 1), (0, 1), (1, 0), (1, 0)])\n\t\tassert_true(nx.is_simple_path(G, [0, 1]))\n\n", "description": "Unit tests for the\n\t:func:`networkx.algorithms.simple_paths.is_simple_path` function.\n\n\t", "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths", "data": "def test_all_simple_paths():\n\tG = nx.path_graph(4)\n\tpaths = nx.all_simple_paths(G,0,3)\n\tassert_equal(set(tuple(p) for p in paths),{(0,1,2,3)})\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_cutoff", "data": "def test_all_simple_paths_cutoff():\n\tG = nx.complete_graph(4)\n\tpaths = nx.all_simple_paths(G,0,1,cutoff=1)\n\tassert_equal(set(tuple(p) for p in paths),{(0,1)})\n\tpaths = nx.all_simple_paths(G,0,1,cutoff=2)\n\tassert_equal(set(tuple(p) for p in paths),{(0,1),(0,2,1),(0,3,1)})\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_multigraph", "data": "def test_all_simple_paths_multigraph():\n\tG = nx.MultiGraph([(1,2),(1,2)])\n\tpaths = nx.all_simple_paths(G,1,2)\n\tassert_equal(set(tuple(p) for p in paths),{(1,2),(1,2)})\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_multigraph_with_cutoff", "data": "def test_all_simple_paths_multigraph_with_cutoff():\n\tG = nx.MultiGraph([(1,2),(1,2),(1,10),(10,2)])\n\tpaths = nx.all_simple_paths(G,1,2, cutoff=1)\n\tassert_equal(set(tuple(p) for p in paths),{(1,2),(1,2)})\n\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_directed", "data": "def test_all_simple_paths_directed():\n\tG = nx.DiGraph()\n\tnx.add_path(G, [1, 2, 3])\n\tnx.add_path(G, [3, 2, 1])\n\tpaths = nx.all_simple_paths(G,1,3)\n\tassert_equal(set(tuple(p) for p in paths),{(1,2,3)})\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_empty", "data": "def test_all_simple_paths_empty():\n\tG = nx.path_graph(4)\n\tpaths = nx.all_simple_paths(G,0,3,cutoff=2)\n\tassert_equal(list(list(p) for p in paths),[])\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "hamiltonian_path", "data": "def hamiltonian_path(G,source):\n\tsource = arbitrary_element(G)\n\tneighbors = set(G[source])-set([source])\n\tn = len(G)\n\tfor target in neighbors:\n\t\tfor path in nx.all_simple_paths(G,source,target):\n\t\t\tif len(path) == n:\n\t\t\t\tyield path\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_hamiltonian_path", "data": "def test_hamiltonian_path():\n\tfrom itertools import permutations\n\tG=nx.complete_graph(4)\n\tpaths = [list(p) for p in hamiltonian_path(G,0)]\n\texact = [[0]+list(p) for p in permutations([1,2,3],3) ]\n\tassert_equal(sorted(paths),sorted(exact))\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_cutoff_zero", "data": "def test_cutoff_zero():\n\tG = nx.complete_graph(4)\n\tpaths = nx.all_simple_paths(G,0,3,cutoff=0)\n\tassert_equal(list(list(p) for p in paths),[])\n\tpaths = nx.all_simple_paths(nx.MultiGraph(G),0,3,cutoff=0)\n\tassert_equal(list(list(p) for p in paths),[])\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_source_missing", "data": "def test_source_missing():\n\tG = nx.Graph()\n\tnx.add_path(G, [1, 2, 3])\n\tpaths = list(nx.all_simple_paths(nx.MultiGraph(G),0,3))\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_target_missing", "data": "def test_target_missing():\n\tG = nx.Graph()\n\tnx.add_path(G, [1, 2, 3])\n\tpaths = list(nx.all_simple_paths(nx.MultiGraph(G),1,4))\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_shortest_simple_paths", "data": "def test_shortest_simple_paths():\n\tG = cnlti(nx.grid_2d_graph(4, 4), first_label=1, ordering=\"sorted\")\n\tpaths = nx.shortest_simple_paths(G, 1, 12)\n\tassert_equal(next(paths), [1, 2, 3, 4, 8, 12])\n\tassert_equal(next(paths), [1, 5, 6, 7, 8, 12])\n\tassert_equal([len(path) for path in nx.shortest_simple_paths(G, 1, 12)],\n\t\t\t\t sorted([len(path) for path in nx.all_simple_paths(G, 1, 12)]))\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_shortest_simple_paths_directed", "data": "def test_shortest_simple_paths_directed():\n\tG = nx.cycle_graph(7, create_using=nx.DiGraph())\n\tpaths = nx.shortest_simple_paths(G, 0, 3)\n\tassert_equal([path for path in paths], [[0, 1, 2, 3]])\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_Greg_Bernstein", "data": "def test_Greg_Bernstein():\n\tg1 = nx.Graph()\n\tg1.add_nodes_from([\"N0\", \"N1\", \"N2\", \"N3\", \"N4\"])\n\tg1.add_edge(\"N4\", \"N1\", weight=10.0, capacity=50, name=\"L5\")\n\tg1.add_edge(\"N4\", \"N0\", weight=7.0, capacity=40, name=\"L4\")\n\tg1.add_edge(\"N0\", \"N1\", weight=10.0, capacity=45, name=\"L1\")\n\tg1.add_edge(\"N3\", \"N0\", weight=10.0, capacity=50, name=\"L0\")\n\tg1.add_edge(\"N2\", \"N3\", weight=12.0, capacity=30, name=\"L2\")\n\tg1.add_edge(\"N1\", \"N2\", weight=15.0, capacity=42, name=\"L3\")\n\tsolution = [['N1', 'N0', 'N3'], ['N1', 'N2', 'N3'], ['N1', 'N4', 'N0', 'N3']]\n\tresult = list(nx.shortest_simple_paths(g1, 'N1', 'N3', weight='weight'))\n\tassert_equal(result, solution)\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_weighted_shortest_simple_path", "data": "def test_weighted_shortest_simple_path():\n\tdef cost_func(path):\n\t\treturn sum(G.edge[u][v]['weight'] for (u, v) in zip(path, path[1:]))\n\tG = nx.complete_graph(5)\n\tweight = {(u, v): random.randint(1, 100) for (u, v) in G.edges()}\n\tnx.set_edge_attributes(G, 'weight', weight)\n\tcost = 0\n\tfor path in nx.shortest_simple_paths(G, 0, 3, weight='weight'):\n\t\tthis_cost = cost_func(path)\n\t\tassert_true(cost <= this_cost)\n\t\tcost = this_cost\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_directed_weighted_shortest_simple_path", "data": "def test_directed_weighted_shortest_simple_path():\n\tdef cost_func(path):\n\t\treturn sum(G.edge[u][v]['weight'] for (u, v) in zip(path, path[1:]))\n\tG = nx.complete_graph(5)\n\tG = G.to_directed()\n\tweight = {(u, v): random.randint(1, 100) for (u, v) in G.edges()}\n\tnx.set_edge_attributes(G, 'weight', weight)\n\tcost = 0\n\tfor path in nx.shortest_simple_paths(G, 0, 3, weight='weight'):\n\t\tthis_cost = cost_func(path)\n\t\tassert_true(cost <= this_cost)\n\t\tcost = this_cost\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_weight_name", "data": "def test_weight_name():\n\tG = nx.cycle_graph(7)\n\tnx.set_edge_attributes(G, 'weight', 1)\n\tnx.set_edge_attributes(G, 'foo', 1)\n\tG.edge[1][2]['foo'] = 7\n\tpaths = list(nx.shortest_simple_paths(G, 0, 3, weight='foo'))\n\tsolution = [[0, 6, 5, 4, 3], [0, 1, 2, 3]]\n\tassert_equal(paths, solution)\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_ssp_source_missing", "data": "def test_ssp_source_missing():\n\tG = nx.Graph()\n\tnx.add_path(G, [1, 2, 3])\n\tpaths = list(nx.shortest_simple_paths(G, 0, 3))\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_ssp_target_missing", "data": "def test_ssp_target_missing():\n\tG = nx.Graph()\n\tnx.add_path(G, [1, 2, 3])\n\tpaths = list(nx.shortest_simple_paths(G, 1, 4))\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_ssp_multigraph", "data": "def test_ssp_multigraph():\n\tG = nx.MultiGraph()\n\tnx.add_path(G, [1, 2, 3])\n\tpaths = list(nx.shortest_simple_paths(G, 1, 4))\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_ssp_source_missing", "data": "def test_ssp_source_missing():\n\tG = nx.Graph()\n\tnx.add_path(G, [0, 1, 2])\n\tnx.add_path(G, [3, 4, 5])\n\tpaths = list(nx.shortest_simple_paths(G, 0, 3))\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_bidirectional_shortest_path_restricted", "data": "def test_bidirectional_shortest_path_restricted():\n\tgrid = cnlti(nx.grid_2d_graph(4,4), first_label=1, ordering=\"sorted\")\n\tcycle = nx.cycle_graph(7)\n\tdirected_cycle = nx.cycle_graph(7, create_using=nx.DiGraph())\n\tlength, path = _bidirectional_shortest_path(cycle, 0, 3)\n\tassert_equal(path, [0, 1, 2, 3])\n\tlength, path = _bidirectional_shortest_path(cycle, 0, 3, ignore_nodes=[1])\n\tassert_equal(path, [0, 6, 5, 4, 3])\n\tlength, path = _bidirectional_shortest_path(grid, 1, 12)\n\tassert_equal(path, [1, 2, 3, 4, 8, 12])\n\tlength, path = _bidirectional_shortest_path(grid, 1, 12, ignore_nodes=[2])\n\tassert_equal(path, [1, 5, 6, 10, 11, 12])\n\tlength, path = _bidirectional_shortest_path(grid, 1, 12, ignore_nodes=[2, 6])\n\tassert_equal(path, [1, 5, 9, 10, 11, 12])\n\tlength, path = _bidirectional_shortest_path(grid, 1, 12,\n\t\t\t\t\t\t\t\t\t\t\t\tignore_nodes=[2, 6],\n\t\t\t\t\t\t\t\t\t\t\t\tignore_edges=[(10, 11)])\n\tassert_equal(path, [1, 5, 9, 10, 14, 15, 16, 12])\n\tlength, path = _bidirectional_shortest_path(directed_cycle, 0, 3)\n\tassert_equal(path, [0, 1, 2, 3])\n\tassert_raises(\n\t\tnx.NetworkXNoPath,\n\t\t_bidirectional_shortest_path,\n\t\tdirected_cycle,\n\t\t0, 3,\n\t\tignore_nodes=[1],\n\t)\n\tlength, path = _bidirectional_shortest_path(directed_cycle, 0, 3,\n\t\t\t\t\t\t\t\t\t\t\t\tignore_edges=[(2, 1)])\n\tassert_equal(path, [0, 1, 2, 3])\n\tassert_raises(\n\t\tnx.NetworkXNoPath,\n\t\t_bidirectional_shortest_path,\n\t\tdirected_cycle,\n\t\t0, 3,\n\t\tignore_edges=[(1, 2)],\n\t)\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "validate_path", "data": "def validate_path(G, s, t, soln_len, path):\n\tassert_equal(path[0], s)\n\tassert_equal(path[-1], t)\n\tassert_equal(soln_len, sum(G[u][v].get('weight', 1)\n\t\t\t\t\tfor u, v in zip(path[:-1], path[1:])))\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "validate_length_path", "data": "def validate_length_path(G, s, t, soln_len, length, path):\n\tassert_equal(soln_len, length)\n\tvalidate_path(G, s, t, length, path)\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_bidirectional_dijksta_restricted", "data": "def test_bidirectional_dijksta_restricted():\n\tXG = nx.DiGraph()\n\tXG.add_weighted_edges_from([('s', 'u', 10), ('s', 'x', 5),\n\t\t\t\t\t\t\t\t('u', 'v', 1), ('u', 'x', 2),\n\t\t\t\t\t\t\t\t('v', 'y', 1), ('x', 'u', 3),\n\t\t\t\t\t\t\t\t('x', 'v', 5), ('x', 'y', 2),\n\t\t\t\t\t\t\t\t('y', 's', 7), ('y', 'v', 6)])\n\n\tXG3 = nx.Graph()\n\tXG3.add_weighted_edges_from([[0, 1, 2], [1, 2, 12],\n\t\t\t\t\t\t\t\t [2, 3, 1], [3, 4, 5],\n\t\t\t\t\t\t\t\t [4, 5, 1], [5, 0, 10]])\n\tvalidate_length_path(XG, 's', 'v', 9,\n\t\t\t\t\t\t *_bidirectional_dijkstra(XG, 's', 'v'))\n\tvalidate_length_path(XG, 's', 'v', 10,\n\t\t\t\t\t\t *_bidirectional_dijkstra(XG, 's', 'v', ignore_nodes=['u']))\n\tvalidate_length_path(XG, 's', 'v', 11,\n\t\t\t\t\t\t *_bidirectional_dijkstra(XG, 's', 'v', ignore_edges=[('s', 'x')]))\n\tassert_raises(\n\t\tnx.NetworkXNoPath,\n\t\t_bidirectional_dijkstra,\n\t\tXG,\n\t\t's', 'v',\n\t\tignore_nodes=['u'],\n\t\tignore_edges=[('s', 'x')],\n\t)\n\tvalidate_length_path(XG3, 0, 3, 15, *_bidirectional_dijkstra(XG3, 0, 3))\n\tvalidate_length_path(XG3, 0, 3, 16,\n\t\t\t\t\t\t *_bidirectional_dijkstra(XG3, 0, 3, ignore_nodes=[1]))\n\tvalidate_length_path(XG3, 0, 3, 16,\n\t\t\t\t\t\t *_bidirectional_dijkstra(XG3, 0, 3, ignore_edges=[(2, 3)]))\n\tassert_raises(\n\t\tnx.NetworkXNoPath,\n\t\t_bidirectional_dijkstra,\n\t\tXG3,\n\t\t0, 3,\n\t\tignore_nodes=[1],\n\t\tignore_edges=[(5, 4)],\n\t)\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_bidirectional_dijkstra_no_path", "data": "def test_bidirectional_dijkstra_no_path():\n\tG = nx.Graph()\n\tnx.add_path(G, [1, 2, 3])\n\tnx.add_path(G, [4, 5, 6])\n\tpath = _bidirectional_dijkstra(G, 1, 6)\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}], [{"term": "def", "name": "get_closing_bracket_index", "data": "def get_closing_bracket_index(expression, open_bracket_index):\n\tbracket_level = 1\n\ti = open_bracket_index + 1\n\twhile bracket_level > 0:\n\t\tcharacter = expression[i]\n\t\tif character == \"(\":\n\t\t\tbracket_level += 1\n\t\telif character == \")\":\n\t\t\tbracket_level -= 1\n\t\ti += 1\n\treturn i - 1\n\n", "description": null, "category": "simple", "imports": []}, {"term": "def", "name": "parse", "data": "def parse(expression):\n\tsimple_expression = []\n\ti = 0\n\twhile i < len(expression):\n\t\tvalue = expression[i]\n\t\tif value == \"(\":\n\t\t\tclosing_bracket_index = get_closing_bracket_index(expression, i)\n\t\t\tsimple_expression.append(parse(expression[i+1:closing_bracket_index]))\n\t\t\ti = closing_bracket_index + 1\n\t\telse:\n\t\t\tsimple_expression.append(value)\n\t\t\ti += 1\n\treturn simple_expression\n\n", "description": null, "category": "simple", "imports": []}, {"term": "def", "name": "evaluate", "data": "def evaluate(simple_expression):\n\tif isinstance(simple_expression, str):\n\t\treturn int(simple_expression)\n\n\tvalue = evaluate(simple_expression[0])\n\ti = 1\n\twhile i < len(simple_expression):\n\t\toperation = simple_expression[i]\n\t\tif operation == \"+\":\n\t\t\tvalue += evaluate(simple_expression[i + 1])\n\t\telif operation == \"*\":\n\t\t\tvalue *= evaluate(simple_expression[i + 1])\n\t\ti += 2\n\treturn value\n\n", "description": null, "category": "simple", "imports": []}, {"term": "def", "name": "insert_precedence", "data": "def insert_precedence(simple_expression):\n\tif isinstance(simple_expression, str):\n\t\treturn simple_expression\n\n\twith_precedence = []\n\ti = 0\n\twhile i < len(simple_expression):\n\t\tvalue = simple_expression[i]\n\t\tif value == \"+\":\n\t\t\twith_precedence[-1] = [\n\t\t\t\twith_precedence[-1],\n\t\t\t\t\"+\",\n\t\t\t\tinsert_precedence(simple_expression[i + 1])\n\t\t\t]\n\t\t\ti += 2\n\t\telse:\n\t\t\twith_precedence.append(insert_precedence(value))\n\t\t\ti += 1\n\treturn with_precedence\n\n", "description": null, "category": "simple", "imports": []}], [{"term": "class", "name": "GLUnurbs", "data": "class GLUnurbs(glustruct.GLUStruct, simple.GLUnurbs):\n\t\"\"\"GLU Nurbs structure with oor and callback storage support\n\t\n\tIMPORTANT NOTE: the texture coordinate callback receives a raw ctypes \n\tdata-pointer, as without knowing what type of evaluation is being done \n\t(1D or 2D) we cannot safely determine the size of the array to convert \n\tit.  This is a limitation of the C implementation.  To convert to regular \n\tdata-pointer, just call yourNurb.ptrAsArray( ptr, size, arrays.GLfloatArray )\n\twith the size of data you expect.\n\t\"\"\"\n\tFUNCTION_TYPE = PLATFORM.functionTypeFor(PLATFORM.GLU)\n\tCALLBACK_FUNCTION_REGISTRARS = {\n\t\t# mapping from \"which\" to a function that should take 3 parameters,\n\t\t# the nurb, the which and the function pointer...\n\t}\n\tCALLBACK_TYPES = {\n\t\t# mapping from \"which\" GLU enumeration to a ctypes function type\n\t\tsimple.GLU_NURBS_BEGIN: FUNCTION_TYPE( \n\t\t\tNone, simple.GLenum \n\t\t),\n\t\tsimple.GLU_NURBS_BEGIN_DATA: FUNCTION_TYPE( \n\t\t\tNone, simple.GLenum, ctypes.POINTER(simple.GLvoid) \n\t\t),\n\t\tsimple.GLU_NURBS_VERTEX: FUNCTION_TYPE( \n\t\t\tNone, ctypes.POINTER(simple.GLfloat)\n\t\t),\n\t\tsimple.GLU_NURBS_VERTEX_DATA: FUNCTION_TYPE( \n\t\t\tNone, ctypes.POINTER(simple.GLfloat), ctypes.POINTER(simple.GLvoid) \n\t\t),\n\t\tsimple.GLU_NURBS_NORMAL: FUNCTION_TYPE( \n\t\t\tNone, ctypes.POINTER(simple.GLfloat)\n\t\t),\n\t\tsimple.GLU_NURBS_NORMAL_DATA: FUNCTION_TYPE( \n\t\t\tNone, ctypes.POINTER(simple.GLfloat), ctypes.POINTER(simple.GLvoid) \n\t\t),\n\t\tsimple.GLU_NURBS_COLOR: FUNCTION_TYPE( \n\t\t\tNone, ctypes.POINTER(simple.GLfloat)\n\t\t),\n\t\tsimple.GLU_NURBS_COLOR_DATA: FUNCTION_TYPE( \n\t\t\tNone, ctypes.POINTER(simple.GLfloat), ctypes.POINTER(simple.GLvoid) \n\t\t),\n\t\tsimple.GLU_NURBS_TEXTURE_COORD: FUNCTION_TYPE( \n\t\t\tNone, ctypes.POINTER(simple.GLfloat)\n\t\t),\n\t\tsimple.GLU_NURBS_TEXTURE_COORD_DATA: FUNCTION_TYPE( \n\t\t\tNone, ctypes.POINTER(simple.GLfloat), ctypes.POINTER(simple.GLvoid) \n\t\t),\n\t\tsimple.GLU_NURBS_END:FUNCTION_TYPE( \n\t\t\tNone\n\t\t),\n\t\tsimple.GLU_NURBS_END_DATA: FUNCTION_TYPE( \n\t\t\tNone, ctypes.POINTER(simple.GLvoid) \n\t\t),\n\t\tsimple.GLU_NURBS_ERROR:FUNCTION_TYPE( \n\t\t\tNone, simple.GLenum, \n\t\t),\n\t}\n\tWRAPPER_METHODS = {\n\t\tsimple.GLU_NURBS_BEGIN: None,\n\t\tsimple.GLU_NURBS_BEGIN_DATA: '_justOOR',\n\t\tsimple.GLU_NURBS_VERTEX: '_vec3',\n\t\tsimple.GLU_NURBS_VERTEX_DATA: '_vec3',\n\t\tsimple.GLU_NURBS_NORMAL: '_vec3',\n\t\tsimple.GLU_NURBS_NORMAL_DATA: '_vec3',\n\t\tsimple.GLU_NURBS_COLOR: '_vec4',\n\t\tsimple.GLU_NURBS_COLOR_DATA: '_vec4',\n\t\tsimple.GLU_NURBS_TEXTURE_COORD: '_tex',\n\t\tsimple.GLU_NURBS_TEXTURE_COORD_DATA: '_tex',\n\t\tsimple.GLU_NURBS_END: None,\n\t\tsimple.GLU_NURBS_END_DATA: '_justOOR',\n\t\tsimple.GLU_NURBS_ERROR: None,\n\t}\n\tdef _justOOR( self, function ):\n\t\t\"\"\"Just do OOR on the last argument...\"\"\"\n\t\tdef getOOR( *args ):\n\t\t\targs = args[:-1] + (self.originalObject(args[-1]),)\n\t\t\treturn function( *args )\n\t\treturn getOOR\n\tdef _vec3( self, function, size=3 ):\n\t\t\"\"\"Convert first arg to size-element array, do OOR on arg2 if present\"\"\"\n\t\tdef vec( *args ):\n\t\t\tvec = self.ptrAsArray(args[0],size,arrays.GLfloatArray)\n\t\t\tif len(args) > 1:\n\t\t\t\toor = self.originalObject(args[1])\n\t\t\t\treturn function( vec, oor )\n\t\t\telse:\n\t\t\t\treturn function( vec )\n\t\treturn vec\n\tdef _vec4( self, function ):\n\t\t\"\"\"Size-4 vector version...\"\"\"\n\t\treturn self._vec3( function, 4 )\n\tdef _tex( self, function ):\n\t\t\"\"\"Texture coordinate callback \n\t\t\n\t\tNOTE: there is no way for *us* to tell what size the array is, you will \n\t\tget back a raw data-point, not an array, as you do for all other callback \n\t\ttypes!!!\n\t\t\"\"\"\n\t\tdef oor( *args ):\n\t\t\tif len(args) > 1:\n\t\t\t\toor = self.originalObject(args[1])\n\t\t\t\treturn function( args[0], oor )\n\t\t\telse:\n\t\t\t\treturn function( args[0] )\n\t\treturn oor\n", "description": "GLU Nurbs structure with oor and callback storage support\n\t\n\tIMPORTANT NOTE: the texture coordinate callback receives a raw ctypes \n\tdata-pointer, as without knowing what type of evaluation is being done \n\t(1D or 2D) we cannot safely determine the size of the array to convert \n\tit.  This is a limitation of the C implementation.  To convert to regular \n\tdata-pointer, just call yourNurb.ptrAsArray( ptr, size, arrays.GLfloatArray )\n\twith the size of data you expect.\n\t", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL"]}, {"term": "def", "name": "_callbackWithType", "data": "def _callbackWithType( funcType ):\n\t\"\"\"Get gluNurbsCallback function with set last arg-type\"\"\"\n\tresult =  platform.copyBaseFunction(\n\t\tsimple.gluNurbsCallback\n\t)\n\tresult.argtypes = [ctypes.POINTER(GLUnurbs), simple.GLenum, funcType]\n\tassert result.argtypes[-1] == funcType\n\treturn result\n", "description": "Get gluNurbsCallback function with set last arg-type", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL"]}, {"term": "def", "name": "gluNurbsCallback", "data": "def gluNurbsCallback( nurb, which, CallBackFunc ):\n\t\"\"\"Dispatch to the nurb's addCallback operation\"\"\"\n\treturn nurb.addCallback( which, CallBackFunc )\n", "description": "Dispatch to the nurb's addCallback operation", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL"]}, {"term": "def", "name": "gluNewNurbsRenderer", "data": "def gluNewNurbsRenderer( baseFunction ):\n\t\"\"\"Return a new nurbs renderer for the system (dereferences pointer)\"\"\"\n\tnewSet = baseFunction()\n\tnew = newSet[0]\n\t#new.__class__ = GLUnurbs # yes, I know, ick\n\treturn new\n", "description": "Return a new nurbs renderer for the system (dereferences pointer)", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL"]}, {"term": "def", "name": "gluNurbsCallbackData", "data": "def gluNurbsCallbackData( baseFunction, nurb, userData ):\n\t\"\"\"Note the Python object for use as userData by the nurb\"\"\"\n\treturn baseFunction( \n\t\tnurb, nurb.noteObject( userData ) \n\t)\n", "description": "Note the Python object for use as userData by the nurb", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL"]}, {"term": "def", "name": "checkOrder", "data": "def checkOrder( order,knotCount,name ):\n\t\"\"\"Check that order is valid...\"\"\"\n\tif order < 1:\n\t\traise error.GLUError( \n\t\t\t\"\"\"%s should be 1 or more, is %s\"\"\"%( name,order,) \n\t\t)\n\telif order > MAX_ORDER:\n\t\traise error.GLUError( \n\t\t\t\"\"\"%s should be %s or less, is %s\"\"\"%( name, MAX_ORDER, order) \n\t\t)\n\telif knotCount < (2*order):\n\t\traise error.GLUError( \n\t\t\t\"\"\"Knotcount must be at least 2x %s is %s should be at least %s\"\"\"%( name, knotCount, 2*order) \n", "description": "Check that order is valid...", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL"]}, {"term": "def", "name": "checkKnots", "data": "def checkKnots( knots, name ):\n\t\"\"\"Check that knots are in ascending order\"\"\"\n\tif len(knots):\n\t\tknot = knots[0]\n\t\tfor next in knots[1:]:\n\t\t\tif next < knot:\n\t\t\t\traise error.GLUError(\n\t\t\t\t\t\"\"\"%s has decreasing knot %s after %s\"\"\"%( name, next, knot )\n\t\t\t\t)\n", "description": "Check that knots are in ascending order", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL"]}, {"term": "def", "name": "gluNurbsCallbackDataEXT", "data": "def gluNurbsCallbackDataEXT( baseFunction,nurb, userData ):\n\t\"\"\"Note the Python object for use as userData by the nurb\"\"\"\n\treturn baseFunction( \n\t\tnurb, nurb.noteObject( userData ) \n\t)\n", "description": "Note the Python object for use as userData by the nurb", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL"]}, {"term": "def", "name": "gluNurbsCurve", "data": "def gluNurbsCurve( baseFunction, nurb, knots, control, type ):\n\t\"\"\"Pythonic version of gluNurbsCurve\n\t\n\tCalculates knotCount, stride, and order automatically\n\t\"\"\"\n\tknots = arrays.GLfloatArray.asArray( knots )\n\tknotCount = arrays.GLfloatArray.arraySize( knots )\n\tcontrol = arrays.GLfloatArray.asArray( control )\n\ttry:\n\t\tlength,step = arrays.GLfloatArray.dimensions( control )\n\texcept ValueError, err:\n\t\traise error.GLUError( \"\"\"Need a 2-dimensional control array\"\"\" )\n\torder = knotCount - length\n\tif OpenGL.ERROR_CHECKING:\n\t\tcheckOrder( order, knotCount, 'order of NURBS curve')\n\t\tcheckKnots( knots, 'knots of NURBS curve')\n\treturn baseFunction(\n\t\tnurb, knotCount, knots, step, control, order, type,\n\t)\n", "description": "Pythonic version of gluNurbsCurve\n\t\n\tCalculates knotCount, stride, and order automatically\n\t", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL"]}, {"term": "def", "name": "gluNurbsSurface", "data": "def gluNurbsSurface( baseFunction, nurb, sKnots, tKnots, control, type ):\n\t\"\"\"Pythonic version of gluNurbsSurface\n\t\n\tCalculates knotCount, stride, and order automatically\n\t\"\"\"\n\tsKnots = arrays.GLfloatArray.asArray( sKnots )\n\tsKnotCount = arrays.GLfloatArray.arraySize( sKnots )\n\ttKnots = arrays.GLfloatArray.asArray( tKnots )\n\ttKnotCount = arrays.GLfloatArray.arraySize( tKnots )\n\tcontrol = arrays.GLfloatArray.asArray( control )\n\n\ttry:\n\t\tlength,width,step = arrays.GLfloatArray.dimensions( control )\n\texcept ValueError, err:\n\t\traise error.GLUError( \"\"\"Need a 3-dimensional control array\"\"\" )\n\tsOrder = sKnotCount - length \n\ttOrder = tKnotCount - width \n\tsStride = width*step\n\ttStride = step\n\tif OpenGL.ERROR_CHECKING:\n\t\tcheckOrder( sOrder, sKnotCount, 'sOrder of NURBS surface')\n\t\tcheckOrder( tOrder, tKnotCount, 'tOrder of NURBS surface')\n\t\tcheckKnots( sKnots, 'sKnots of NURBS surface')\n\t\tcheckKnots( tKnots, 'tKnots of NURBS surface')\n\tif not (sKnotCount-sOrder)*(tKnotCount-tOrder) == length*width:\n\t\traise error.GLUError(\n\t\t\t\"\"\"Invalid NURB structure\"\"\",\n\t\t\tnurb, sKnotCount, sKnots, tKnotCount, tKnots,\n\t\t\tsStride, tStride, control,\n\t\t\tsOrder,tOrder,\n\t\t\ttype\n\t\t)\n\n\tresult = baseFunction(\n\t\tnurb, sKnotCount, sKnots, tKnotCount, tKnots,\n\t\tsStride, tStride, control,\n\t\tsOrder,tOrder,\n\t\ttype\n\t)\n\treturn result\n", "description": "Pythonic version of gluNurbsSurface\n\t\n\tCalculates knotCount, stride, and order automatically\n\t", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL"]}, {"term": "def", "name": "gluPwlCurve", "data": "def gluPwlCurve( baseFunction, nurb, data, type ):\n\t\"\"\"gluPwlCurve -- piece-wise linear curve within GLU context\n\t\n\tdata -- the data-array \n\ttype -- determines number of elements/data-point\n\t\"\"\"\n\tdata = arrays.GLfloatArray.asArray( data )\n\tif type == simple.GLU_MAP1_TRIM_2:\n\t\tdivisor = 2\n\telif type == simple.GLU_MAP_TRIM_3:\n\t\tdivisor = 3\n\telse:\n\t\traise ValueError( \"\"\"Unrecognised type constant: %s\"\"\"%(type))\n\tsize = arrays.GLfloatArray.arraySize( data )\n\tsize = int(size//divisor)\n\treturn baseFunction( nurb, size, data, divisor, type )\n", "description": "gluPwlCurve -- piece-wise linear curve within GLU context\n\t\n\tdata -- the data-array \n\ttype -- determines number of elements/data-point\n\t", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL"]}], [{"term": "def", "name": "ShortSetNames", "data": "def ShortSetNames(set_names_list):\n\t\"\"\" Using a table with rules, shorten the names of these sets\n\tArgs:\n\t\tset_names_list: list set Names \n\tReturns:\n\t\tset_names_list: list Edited set Names to be \n\t\t\tin the format setX* or testX*\n\t\"\"\"\n\n\tif not isinstance(set_names_list, list):\n\t\traise Exception(\"Input to ShortSetNames must be a list\")\n\n\tlogging.debug(\"Original set names list: \" + \", \".join(set_names_list))\n\n\t# returns a TRUE/FALSE vector indicating which \n\t# elements of the character vector contain a match\n\tsimple = [bool(re.search(r\"(set|test)[0-9A-Z]+[0-9A-Z0-9]*$\", x)) for x in set_names_list]\n\tlogging.debug(\"simple: \\n\" + \",\".join(list([str(x) for x in simple])))\n   \n\t# We edit the values of set_names_list who are true for simple ^\n\t# by removing anything before 'set' or 'test'\n\t# We count the number of values that were false\n\tnleft = 0\n\tsimple_set_names = []\n\tfor i in range(len(simple)):\n\t\tif simple[i]:\n\t\t\tnew_set_name = re.sub(\"^.*(set|test)\", \"\\\\1\", set_names_list[i]) \n\t\t\tset_names_list[i] = new_set_name\n\t\t\tsimple_set_names.append(new_set_name)\n\t\telse:\n\t\t\tnleft += 1\n\tlogging.debug(\"fixed set_names:\\n\" + \",\".join(list(set_names_list)))\n\n\tcandidates = [\"set\" + x for x in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"]\n\tlogging.debug(candidates)\n\n\t# get the elements in candidates that are not in set_names_list[simple]\n\tcandidates = [x for x in candidates if x not in simple_set_names]\n\tif (nleft > len(candidates)):\n\t\traise Exception(f\"Too many unexpected set names: {nleft}\")\n\n\t# Get the non-simple values from set_names_list\n\toldComplex = [x for x in set_names_list if x not in simple_set_names]\n\tlogging.debug(\"oldComplex:\\n\" + \",\".join(oldComplex))\n\n\tcnd_ix = 0 \n\tfor i in range(len(simple)):\n\t\tif not simple[i]:\n\t\t\tlogging.info(f\"Set {set_names_list[i]} simplified to {candidates[cnd_ix]}\")\n\t\t\tset_names_list[i] = candidates[cnd_ix]\n\t\t\tcnd_ix += 1\n\t\t\t\n\tif (len(set_names_list) != len(set(set_names_list))):\n\t\traise Exception(\"Non-unique set names!:\\n\" + \\\n\t\t\t\t\t\t\", \".join(set_names_list))\n\telse:\n\t\tlogging.info(\"Finished running short set names\")\n\t\tlogging.debug(\"Final set names list: \" + \", \".join(set_names_list))\n\n\treturn(set_names_list)\n\n\n", "description": " Using a table with rules, shorten the names of these sets\n\tArgs:\n\t\tset_names_list: list set Names \n\tReturns:\n\t\tset_names_list: list Edited set Names to be \n\t\t\tin the format setX* or testX*\n\t", "category": "simple", "imports": ["import re", "import logging", "import pandas as pd"]}, {"term": "def", "name": "applyRules", "data": "def applyRules(rules_df, desc_str_list):\n\t\"\"\"\n\tArgs:\n\t\trules_df: data frame with rules (looks like):\n\t\tstr(number), str [, str [str, etc...] replace_str\n\n\t\tdesc_str_list: list\n\t\"\"\"\n\tfor j in range(len(desc_str_list)):\n\t\tfor i in range(0, len(rules_df.index)):\n\t\t\tdesc_str_list[j] = desc_str_list[j].replace(rules_df.iloc[i][\"V1\"], \n\t\t\t\t\t\t\t\t\t\t\t\t\t\trules_df.iloc[i][\"V2\"])\n\treturn desc_str_list\n\t\t\n\n\n", "description": "\n\tArgs:\n\t\trules_df: data frame with rules (looks like):\n\t\tstr(number), str [, str [str, etc...] replace_str\n\n\t\tdesc_str_list: list\n\t", "category": "simple", "imports": ["import re", "import logging", "import pandas as pd"]}, {"term": "def", "name": "testShortSetNames", "data": "def testShortSetNames():\n\tlogging.basicConfig(level=logging.DEBUG)\n\tset_name_list1 = [\n\t\t\t\"mytest3\",\n\t\t\t\"myset5\",\n\t\t\t\"superdooper\",\n\t\t\t\"foo\",\n\t\t\t\"footest\",\n\t\t\t\"simpletest\",\n\t\t\t\"setA\"\n\t\t\t]\n\tShortSetNames(set_name_list1)\n\n", "description": null, "category": "simple", "imports": ["import re", "import logging", "import pandas as pd"]}], [], [], [], [{"term": "def", "name": "simple", "data": "def simple(size, n_attr):\n\tgen_model = model.simple.SimpleConvolutionGenerator(\n\t\tname=\"G\",\n\t\tout_size=size)\n\tdisc_model = model.simple.SimpleConvolutionDiscriminator(\n\t\tname=\"D\",\n\t\tinput_size=size,\n\t\tn_attr=n_attr)\n\treturn gen_model, disc_model\n", "description": null, "category": "simple", "imports": ["import model"]}, {"term": "def", "name": "sample", "data": "def sample(size, n_attr):\n\tgen_model = model.simple.SimpleUpsampleGenerator(\n\t\tname=\"G\",\n\t\tout_size=size)\n\tdisc_model = model.simple.SimpleDownsampleDiscriminator(\n\t\tname=\"D\",\n\t\tinput_size=size,\n\t\tn_attr=n_attr)\n\treturn gen_model, disc_model\n", "description": null, "category": "simple", "imports": ["import model"]}, {"term": "def", "name": "simple_debug", "data": "def simple_debug(size, n_attr):\n\tgen_model = model.simple.SimpleConvolutionGenerator(\n\t\tname=\"G\",\n\t\tdebug=True,\n\t\tout_size=size)\n\tdisc_model = model.simple.SimpleConvolutionDiscriminator(\n\t\tname=\"D\",\n\t\tinput_size=size,\n\t\tdebug=True,\n\t\tn_attr=n_attr)\n\treturn gen_model, disc_model\n", "description": null, "category": "simple", "imports": ["import model"]}, {"term": "def", "name": "sample_debug", "data": "def sample_debug(size, n_attr):\n\tgen_model = model.simple.SimpleUpsampleGenerator(\n\t\tname=\"G\",\n\t\tdebug=True,\n\t\tout_size=size)\n\tdisc_model = model.simple.SimpleDownsampleDiscriminator(\n\t\tname=\"D\",\n\t\tdebug=True,\n\t\tinput_size=size,\n\t\tn_attr=n_attr)\n\treturn gen_model, disc_model\n", "description": null, "category": "simple", "imports": ["import model"]}, {"term": "def", "name": "simple_mask", "data": "def simple_mask(size, n_attr):\n\td_map_depth = 64\n\tif size == 64:\n\t\tmap_size = 4\n\t\td_layers = 5\n\t\tg_layers = 4\n\telif size == 128:\n\t\tmap_size = 4\n\t\td_layers = 6\n\t\tg_layers = 5\n\t\t\n\tgen_model = model.simple.MaskConvolutionGenerator(\n\t\tname=\"G\",\n\t\tmap_size=map_size,\n\t\tmask_num=9,\n\t\tn_layer=g_layers)\n\tdisc_model = model.simple.SimpleConvolutionDiscriminator(\n\t\tname=\"D\",\n\t\tmap_depth=d_map_depth,\n\t\tn_layer=d_layers,\n\t\tn_attr=n_attr)\n\treturn gen_model, disc_model\n", "description": null, "category": "simple", "imports": ["import model"]}, {"term": "def", "name": "deep", "data": "def deep(size, n_attr):\n\tgen_model = model.deep.DeepGenerator(\n\t\tname=\"G\",\n\t\tmap_depth=32,\n\t\tout_size=size)\n\tdisc_model = model.deep.DeepDiscriminator(\n\t\tname=\"D\",\n\t\tn_attr=n_attr,\n\t\tmap_depth=32,\n\t\tinput_size=size)\n\treturn gen_model, disc_model\n", "description": null, "category": "simple", "imports": ["import model"]}, {"term": "def", "name": "res", "data": "def res(size, n_attr):\n\tgen_model = model.deep.ResidualGenerator(\n\t\tname=\"G\",\n\t\tout_size=size)\n\tdisc_model = model.deep.ResidualDiscriminator(\n\t\tname=\"D\",\n\t\tn_attr=n_attr,\n\t\tinput_size=size)\n", "description": null, "category": "simple", "imports": ["import model"]}], [{"term": "class", "name": "listaEnlazadaSimple", "data": "class listaEnlazadaSimple(): \n\tdef __init__(self): \n\t\tself.primero = None \n\t\tself.ultimo = None\n\t\t\n\tdef getHead(self):\n\t\treturn self.primero\n\t\n\tdef estaVacio(self): \n\t\treturn self.primero == None\n\t\n\tdef agregarAlInicio(self, dato):\n\t\tif self.estaVacio(): \n\t\t\tself.primero = self.ultimo = Nodo(dato)\n\t\telse:\n\t\t\taux = Nodo(dato)\n\t\t\taux.siguiente = self.primero\n\t\t\tself.primero = aux\n\n\tdef agregarAlFinal(self, dato): \n\t\tif self.estaVacio():\n\t\t\tself.primero = self.ultimo = Nodo(dato)\n\t\telse:\n\t\t\taux = self.ultimo\n\t\t\tself.ultimo = Nodo(dato)\n\t\t\taux.siguiente = self.ultimo\n\t\n\tdef eliminarAlInicio(self):\n\t\tif self.estaVacio():\n\t\t\tprint(\"Lista vacia\")\n\t\telif self.primero == self.ultimo:\n\t\t\tself.primero = self.ultimo = None\n\t\telse:\n\t\t\tself.primero = self.primero.siguiente\n\t\n\tdef eliminarAlFinal(self):\n\t\tif self.estaVacio():\n\t\t\tprint(\"Lista vacia\")\n\t\telif self.primero == self.ultimo:\n\t\t\tself.primero = self.ultimo = None\n\t\telse:\n\t\t\taux = self.primero\n\t\t\twhile aux.siguiente != self.ultimo:\n\t\t\t\taux = aux.siguiente\n\t\t\taux.siguiente = None\n\t\n\tdef recorrerLista(self): \n\t\tif self.estaVacio(): \n\t\t\tprint(\"La lista esta vac\u00c3\u00ada\\n\") \n\t\taux = self.primero\n\t\tprint(end='\\n| ')\n\t\twhile aux != None: \n\t\t\tprint(aux.dato, end=' | ') \n\t\t\taux = aux.siguiente\n\t\tprint(\"\\n\")\n\t\n\tdef tamanio(self):\n\t\tcount = 0 \n\t\tif self.estaVacio(): \n\t\t\treturn '0'\n\t\taux = self.primero \n\t\twhile aux != None: \n\t\t\tcount += 1\n\t\t\taux = aux.siguiente\n\t\treturn count\n\n\tdef ordenamiento(self):\n\t\tactual = aux = None\n\t\tif not (self.estaVacio()):\n\t\t\tactual = self.primero\n\t\t\twhile (actual.siguiente):\n\t\t\t\taux = actual.siguiente\n\t\t\t\twhile (aux):\n\t\t\t\t\tif (aux.dato < actual.dato):\n\t\t\t\t\t\ttmp = actual.dato\n\t\t\t\t\t\tactual.dato = aux.dato\n\t\t\t\t\t\taux.dato = tmp\n\t\t\t\t\taux = aux.siguiente\n\t\t\t\tactual = actual.siguiente\n\t\telse:\n\t\t\tprint(\"No hay elementos\")\n\t\n\tdef sortedMerge(self, a, b):\n\t\tresult = None\n\t\t\n\t\t# Base cases\n\t\tif a == None:\n\t\t\treturn b\n\t\tif b == None:\n\t\t\treturn a\n\t\t\n\t\t# pick either a or b and recur..\n\t\tif a.dato <= b.dato:\n\t\t\tresult = a\n\t\t\tresult.siguiente = self.sortedMerge(a.siguiente, b)\n\t\telse:\n\t\t\tresult = b\n\t\t\tresult.siguiente = self.sortedMerge(a, b.siguiente)\n\t\treturn result\n\n\tdef mergeSort(self, h):\n\t\t\n\t\t# Base case if head is None\n\t\tif h == None or h.siguiente == None:\n\t\t\treturn h\n\n\t\t# get the middle of the list\n\t\tmiddle = self.getMiddle(h)\n\t\tnexttomiddle = middle.siguiente\n\n\t\t# set the next of middle node to None\n\t\tmiddle.siguiente = None\n\n\t\t# Apply mergeSort on left list\n\t\tleft = self.mergeSort(h)\n\t\t\n\t\t# Apply mergeSort on right list\n\t\tright = self.mergeSort(nexttomiddle)\n\n\t\t# Merge the left and right lists\n\t\tsortedlist = self.sortedMerge(left, right)\n\t\treturn sortedlist\n\n\t# Utility function to get the middle\n\t# of the linked list\n\tdef getMiddle(self, head):\n\t\tif (head == None):\n\t\t\treturn head\n\n\t\tslow = head\n\t\tfast = head\n\n\t\twhile (fast.siguiente != None and\n\t\t\t\tfast.siguiente.siguiente != None):\n\t\t\tslow = slow.siguiente\n\t\t\tfast = fast.siguiente.siguiente\n\t\t\n\t\treturn slow\n\t\n\tdef buscarDato(self, date):\n\t\tif self.primero is None:\n\t\t\tprint(\"La lista no tiene elementos\")\n\t\taux = self.primero\n\t\twhile aux is not None:\n\t\t\tif aux.dato == date:\n\t\t\t\treturn (f\"{date}, Dato encontrado\")\n\t\t\taux = aux.siguiente\n\t\treturn (f\"{date}, Dato no encontrado\")\n", "description": null, "category": "simple", "imports": ["from Nodo import Nodo"]}], [{"term": "class", "name": "ScannerError", "data": "class ScannerError(MarkedYAMLError):\n\tpass\n", "description": null, "category": "simple", "imports": ["from .error import MarkedYAMLError", "from .tokens import *", "#\timport psyco"]}, {"term": "class", "name": "SimpleKey", "data": "class SimpleKey(object):\n\t# See below simple keys treatment.\n\n\tdef __init__(self, token_number, required, index, line, column, mark):\n\t\tself.token_number = token_number\n\t\tself.required = required\n\t\tself.index = index\n\t\tself.line = line\n\t\tself.column = column\n\t\tself.mark = mark\n", "description": null, "category": "simple", "imports": ["from .error import MarkedYAMLError", "from .tokens import *", "#\timport psyco"]}, {"term": "class", "name": "Scanner", "data": "class Scanner(object):\n\n\tdef __init__(self):\n\t\t\"\"\"Initialize the scanner.\"\"\"\n\t\t# It is assumed that Scanner and Reader will have a common descendant.\n\t\t# Reader do the dirty work of checking for BOM and converting the\n\t\t# input data to Unicode. It also adds NUL to the end.\n\t\t#\n\t\t# Reader supports the following methods\n\t\t#   self.peek(i=0)\t   # peek the next i-th character\n\t\t#   self.prefix(l=1)\t # peek the next l characters\n\t\t#   self.forward(l=1)\t# read the next l characters and move the pointer.\n\n\t\t# Had we reached the end of the stream?\n\t\tself.done = False\n\n\t\t# The number of unclosed '{' and '['. `flow_level == 0` means block\n\t\t# context.\n\t\tself.flow_level = 0\n\n\t\t# List of processed tokens that are not yet emitted.\n\t\tself.tokens = []\n\n\t\t# Add the STREAM-START token.\n\t\tself.fetch_stream_start()\n\n\t\t# Number of tokens that were emitted through the `get_token` method.\n\t\tself.tokens_taken = 0\n\n\t\t# The current indentation level.\n\t\tself.indent = -1\n\n\t\t# Past indentation levels.\n\t\tself.indents = []\n\n\t\t# Variables related to simple keys treatment.\n\n\t\t# A simple key is a key that is not denoted by the '?' indicator.\n\t\t# Example of simple keys:\n\t\t#   ---\n\t\t#   block simple key: value\n\t\t#   ? not a simple key:\n\t\t#   : { flow simple key: value }\n\t\t# We emit the KEY token before all keys, so when we find a potential\n\t\t# simple key, we try to locate the corresponding ':' indicator.\n\t\t# Simple keys should be limited to a single line and 1024 characters.\n\n\t\t# Can a simple key start at the current position? A simple key may\n\t\t# start:\n\t\t# - at the beginning of the line, not counting indentation spaces\n\t\t#\t   (in block context),\n\t\t# - after '{', '[', ',' (in the flow context),\n\t\t# - after '?', ':', '-' (in the block context).\n\t\t# In the block context, this flag also signifies if a block collection\n\t\t# may start at the current position.\n\t\tself.allow_simple_key = True\n\n\t\t# Keep track of possible simple keys. This is a dictionary. The key\n\t\t# is `flow_level`; there can be no more that one possible simple key\n\t\t# for each level. The value is a SimpleKey record:\n\t\t#   (token_number, required, index, line, column, mark)\n\t\t# A simple key may start with ALIAS, ANCHOR, TAG, SCALAR(flow),\n\t\t# '[', or '{' tokens.\n\t\tself.possible_simple_keys = {}\n\n\t# Public methods.\n\n\tdef check_token(self, *choices):\n\t\t# Check if the next token is one of the given types.\n\t\twhile self.need_more_tokens():\n\t\t\tself.fetch_more_tokens()\n\t\tif self.tokens:\n\t\t\tif not choices:\n\t\t\t\treturn True\n\t\t\tfor choice in choices:\n\t\t\t\tif isinstance(self.tokens[0], choice):\n\t\t\t\t\treturn True\n\t\treturn False\n\n\tdef peek_token(self):\n\t\t# Return the next token, but do not delete if from the queue.\n\t\twhile self.need_more_tokens():\n\t\t\tself.fetch_more_tokens()\n\t\tif self.tokens:\n\t\t\treturn self.tokens[0]\n\n\tdef get_token(self):\n\t\t# Return the next token.\n\t\twhile self.need_more_tokens():\n\t\t\tself.fetch_more_tokens()\n\t\tif self.tokens:\n\t\t\tself.tokens_taken += 1\n\t\t\treturn self.tokens.pop(0)\n\n\t# Private methods.\n\n\tdef need_more_tokens(self):\n\t\tif self.done:\n\t\t\treturn False\n\t\tif not self.tokens:\n\t\t\treturn True\n\t\t# The current token may be a potential simple key, so we\n\t\t# need to look further.\n\t\tself.stale_possible_simple_keys()\n\t\tif self.next_possible_simple_key() == self.tokens_taken:\n\t\t\treturn True\n\n\tdef fetch_more_tokens(self):\n\n\t\t# Eat whitespaces and comments until we reach the next token.\n\t\tself.scan_to_next_token()\n\n\t\t# Remove obsolete possible simple keys.\n\t\tself.stale_possible_simple_keys()\n\n\t\t# Compare the current indentation and column. It may add some tokens\n\t\t# and decrease the current indentation level.\n\t\tself.unwind_indent(self.column)\n\n\t\t# Peek the next character.\n\t\tch = self.peek()\n\n\t\t# Is it the end of stream?\n\t\tif ch == u'\\0':\n\t\t\treturn self.fetch_stream_end()\n\n\t\t# Is it a directive?\n\t\tif ch == u'%' and self.check_directive():\n\t\t\treturn self.fetch_directive()\n\n\t\t# Is it the document start?\n\t\tif ch == u'-' and self.check_document_start():\n\t\t\treturn self.fetch_document_start()\n\n\t\t# Is it the document end?\n\t\tif ch == u'.' and self.check_document_end():\n\t\t\treturn self.fetch_document_end()\n\n\t\t# TODO: support for BOM within a stream.\n\t\t#if ch == u'\\uFEFF':\n\t\t#\treturn self.fetch_bom()\t<-- issue BOMToken\n\n\t\t# Note: the order of the following checks is NOT significant.\n\n\t\t# Is it the flow sequence start indicator?\n\t\tif ch == u'[':\n\t\t\treturn self.fetch_flow_sequence_start()\n\n\t\t# Is it the flow mapping start indicator?\n\t\tif ch == u'{':\n\t\t\treturn self.fetch_flow_mapping_start()\n\n\t\t# Is it the flow sequence end indicator?\n\t\tif ch == u']':\n\t\t\treturn self.fetch_flow_sequence_end()\n\n\t\t# Is it the flow mapping end indicator?\n\t\tif ch == u'}':\n\t\t\treturn self.fetch_flow_mapping_end()\n\n\t\t# Is it the flow entry indicator?\n\t\tif ch == u',':\n\t\t\treturn self.fetch_flow_entry()\n\n\t\t# Is it the block entry indicator?\n\t\tif ch == u'-' and self.check_block_entry():\n\t\t\treturn self.fetch_block_entry()\n\n\t\t# Is it the key indicator?\n\t\tif ch == u'?' and self.check_key():\n\t\t\treturn self.fetch_key()\n\n\t\t# Is it the value indicator?\n\t\tif ch == u':' and self.check_value():\n\t\t\treturn self.fetch_value()\n\n\t\t# Is it an alias?\n\t\tif ch == u'*':\n\t\t\treturn self.fetch_alias()\n\n\t\t# Is it an anchor?\n\t\tif ch == u'&':\n\t\t\treturn self.fetch_anchor()\n\n\t\t# Is it a tag?\n\t\tif ch == u'!':\n\t\t\treturn self.fetch_tag()\n\n\t\t# Is it a literal scalar?\n\t\tif ch == u'|' and not self.flow_level:\n\t\t\treturn self.fetch_literal()\n\n\t\t# Is it a folded scalar?\n\t\tif ch == u'>' and not self.flow_level:\n\t\t\treturn self.fetch_folded()\n\n\t\t# Is it a single quoted scalar?\n\t\tif ch == u'\\'':\n\t\t\treturn self.fetch_single()\n\n\t\t# Is it a double quoted scalar?\n\t\tif ch == u'\\\"':\n\t\t\treturn self.fetch_double()\n\n\t\t# It must be a plain scalar then.\n\t\tif self.check_plain():\n\t\t\treturn self.fetch_plain()\n\n\t\t# No? It's an error. Let's produce a nice error message.\n\t\traise ScannerError(\"while scanning for the next token\", None,\n\t\t\t\t\"found character %r that cannot start any token\"\n\t\t\t\t% ch.encode('utf-8'), self.get_mark())\n\n\t# Simple keys treatment.\n\n\tdef next_possible_simple_key(self):\n\t\t# Return the number of the nearest possible simple key. Actually we\n\t\t# don't need to loop through the whole dictionary. We may replace it\n\t\t# with the following code:\n\t\t#   if not self.possible_simple_keys:\n\t\t#\t   return None\n\t\t#   return self.possible_simple_keys[\n\t\t#\t\t   min(self.possible_simple_keys.keys())].token_number\n\t\tmin_token_number = None\n\t\tfor level in self.possible_simple_keys:\n\t\t\tkey = self.possible_simple_keys[level]\n\t\t\tif min_token_number is None or key.token_number < min_token_number:\n\t\t\t\tmin_token_number = key.token_number\n\t\treturn min_token_number\n\n\tdef stale_possible_simple_keys(self):\n\t\t# Remove entries that are no longer possible simple keys. According to\n\t\t# the YAML specification, simple keys\n\t\t# - should be limited to a single line,\n\t\t# - should be no longer than 1024 characters.\n\t\t# Disabling this procedure will allow simple keys of any length and\n\t\t# height (may cause problems if indentation is broken though).\n\t\tfor level in self.possible_simple_keys.keys():\n\t\t\tkey = self.possible_simple_keys[level]\n\t\t\tif key.line != self.line  \\\n\t\t\t\t\tor self.index-key.index > 1024:\n\t\t\t\tif key.required:\n\t\t\t\t\traise ScannerError(\"while scanning a simple key\", key.mark,\n\t\t\t\t\t\t\t\"could not found expected ':'\", self.get_mark())\n\t\t\t\tdel self.possible_simple_keys[level]\n\n\tdef save_possible_simple_key(self):\n\t\t# The next token may start a simple key. We check if it's possible\n\t\t# and save its position. This function is called for\n\t\t#   ALIAS, ANCHOR, TAG, SCALAR(flow), '[', and '{'.\n\n\t\t# Check if a simple key is required at the current position.\n\t\trequired = not self.flow_level and self.indent == self.column\n\n\t\t# A simple key is required only if it is the first token in the current\n\t\t# line. Therefore it is always allowed.\n\t\tassert self.allow_simple_key or not required\n\n\t\t# The next token might be a simple key. Let's save it's number and\n\t\t# position.\n\t\tif self.allow_simple_key:\n\t\t\tself.remove_possible_simple_key()\n\t\t\ttoken_number = self.tokens_taken+len(self.tokens)\n\t\t\tkey = SimpleKey(token_number, required,\n\t\t\t\t\tself.index, self.line, self.column, self.get_mark())\n\t\t\tself.possible_simple_keys[self.flow_level] = key\n\n\tdef remove_possible_simple_key(self):\n\t\t# Remove the saved possible key position at the current flow level.\n\t\tif self.flow_level in self.possible_simple_keys:\n\t\t\tkey = self.possible_simple_keys[self.flow_level]\n\t\t\t\n\t\t\tif key.required:\n\t\t\t\traise ScannerError(\"while scanning a simple key\", key.mark,\n\t\t\t\t\t\t\"could not found expected ':'\", self.get_mark())\n\n\t\t\tdel self.possible_simple_keys[self.flow_level]\n\n\t# Indentation functions.\n\n\tdef unwind_indent(self, column):\n\n\t\t## In flow context, tokens should respect indentation.\n\t\t## Actually the condition should be `self.indent >= column` according to\n\t\t## the spec. But this condition will prohibit intuitively correct\n\t\t## constructions such as\n\t\t## key : {\n\t\t## }\n\t\t#if self.flow_level and self.indent > column:\n\t\t#\traise ScannerError(None, None,\n\t\t#\t\t\t\"invalid intendation or unclosed '[' or '{'\",\n\t\t#\t\t\tself.get_mark())\n\n\t\t# In the flow context, indentation is ignored. We make the scanner less\n\t\t# restrictive then specification requires.\n\t\tif self.flow_level:\n\t\t\treturn\n\n\t\t# In block context, we may need to issue the BLOCK-END tokens.\n\t\twhile self.indent > column:\n\t\t\tmark = self.get_mark()\n\t\t\tself.indent = self.indents.pop()\n\t\t\tself.tokens.append(BlockEndToken(mark, mark))\n\n\tdef add_indent(self, column):\n\t\t# Check if we need to increase indentation.\n\t\tif self.indent < column:\n\t\t\tself.indents.append(self.indent)\n\t\t\tself.indent = column\n\t\t\treturn True\n\t\treturn False\n\n\t# Fetchers.\n\n\tdef fetch_stream_start(self):\n\t\t# We always add STREAM-START as the first token and STREAM-END as the\n\t\t# last token.\n\n\t\t# Read the token.\n\t\tmark = self.get_mark()\n\t\t\n\t\t# Add STREAM-START.\n\t\tself.tokens.append(StreamStartToken(mark, mark,\n\t\t\tencoding=self.encoding))\n\t\t\n\n\tdef fetch_stream_end(self):\n\n\t\t# Set the current intendation to -1.\n\t\tself.unwind_indent(-1)\n\n\t\t# Reset simple keys.\n\t\tself.remove_possible_simple_key()\n\t\tself.allow_simple_key = False\n\t\tself.possible_simple_keys = {}\n\n\t\t# Read the token.\n\t\tmark = self.get_mark()\n\t\t\n\t\t# Add STREAM-END.\n\t\tself.tokens.append(StreamEndToken(mark, mark))\n\n\t\t# The steam is finished.\n\t\tself.done = True\n\n\tdef fetch_directive(self):\n\t\t\n\t\t# Set the current intendation to -1.\n\t\tself.unwind_indent(-1)\n\n\t\t# Reset simple keys.\n\t\tself.remove_possible_simple_key()\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add DIRECTIVE.\n\t\tself.tokens.append(self.scan_directive())\n\n\tdef fetch_document_start(self):\n\t\tself.fetch_document_indicator(DocumentStartToken)\n\n\tdef fetch_document_end(self):\n\t\tself.fetch_document_indicator(DocumentEndToken)\n\n\tdef fetch_document_indicator(self, TokenClass):\n\n\t\t# Set the current intendation to -1.\n\t\tself.unwind_indent(-1)\n\n\t\t# Reset simple keys. Note that there could not be a block collection\n\t\t# after '---'.\n\t\tself.remove_possible_simple_key()\n\t\tself.allow_simple_key = False\n\n\t\t# Add DOCUMENT-START or DOCUMENT-END.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward(3)\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(TokenClass(start_mark, end_mark))\n\n\tdef fetch_flow_sequence_start(self):\n\t\tself.fetch_flow_collection_start(FlowSequenceStartToken)\n\n\tdef fetch_flow_mapping_start(self):\n\t\tself.fetch_flow_collection_start(FlowMappingStartToken)\n\n\tdef fetch_flow_collection_start(self, TokenClass):\n\n\t\t# '[' and '{' may start a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# Increase the flow level.\n\t\tself.flow_level += 1\n\n\t\t# Simple keys are allowed after '[' and '{'.\n\t\tself.allow_simple_key = True\n\n\t\t# Add FLOW-SEQUENCE-START or FLOW-MAPPING-START.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(TokenClass(start_mark, end_mark))\n\n\tdef fetch_flow_sequence_end(self):\n\t\tself.fetch_flow_collection_end(FlowSequenceEndToken)\n\n\tdef fetch_flow_mapping_end(self):\n\t\tself.fetch_flow_collection_end(FlowMappingEndToken)\n\n\tdef fetch_flow_collection_end(self, TokenClass):\n\n\t\t# Reset possible simple key on the current level.\n\t\tself.remove_possible_simple_key()\n\n\t\t# Decrease the flow level.\n\t\tself.flow_level -= 1\n\n\t\t# No simple keys after ']' or '}'.\n\t\tself.allow_simple_key = False\n\n\t\t# Add FLOW-SEQUENCE-END or FLOW-MAPPING-END.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(TokenClass(start_mark, end_mark))\n\n\tdef fetch_flow_entry(self):\n\n\t\t# Simple keys are allowed after ','.\n\t\tself.allow_simple_key = True\n\n\t\t# Reset possible simple key on the current level.\n\t\tself.remove_possible_simple_key()\n\n\t\t# Add FLOW-ENTRY.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(FlowEntryToken(start_mark, end_mark))\n\n\tdef fetch_block_entry(self):\n\n\t\t# Block context needs additional checks.\n\t\tif not self.flow_level:\n\n\t\t\t# Are we allowed to start a new entry?\n\t\t\tif not self.allow_simple_key:\n\t\t\t\traise ScannerError(None, None,\n\t\t\t\t\t\t\"sequence entries are not allowed here\",\n\t\t\t\t\t\tself.get_mark())\n\n\t\t\t# We may need to add BLOCK-SEQUENCE-START.\n\t\t\tif self.add_indent(self.column):\n\t\t\t\tmark = self.get_mark()\n\t\t\t\tself.tokens.append(BlockSequenceStartToken(mark, mark))\n\n\t\t# It's an error for the block entry to occur in the flow context,\n\t\t# but we let the parser detect this.\n\t\telse:\n\t\t\tpass\n\n\t\t# Simple keys are allowed after '-'.\n\t\tself.allow_simple_key = True\n\n\t\t# Reset possible simple key on the current level.\n\t\tself.remove_possible_simple_key()\n\n\t\t# Add BLOCK-ENTRY.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(BlockEntryToken(start_mark, end_mark))\n\n\tdef fetch_key(self):\n\t\t\n\t\t# Block context needs additional checks.\n\t\tif not self.flow_level:\n\n\t\t\t# Are we allowed to start a key (not nessesary a simple)?\n\t\t\tif not self.allow_simple_key:\n\t\t\t\traise ScannerError(None, None,\n\t\t\t\t\t\t\"mapping keys are not allowed here\",\n\t\t\t\t\t\tself.get_mark())\n\n\t\t\t# We may need to add BLOCK-MAPPING-START.\n\t\t\tif self.add_indent(self.column):\n\t\t\t\tmark = self.get_mark()\n\t\t\t\tself.tokens.append(BlockMappingStartToken(mark, mark))\n\n\t\t# Simple keys are allowed after '?' in the block context.\n\t\tself.allow_simple_key = not self.flow_level\n\n\t\t# Reset possible simple key on the current level.\n\t\tself.remove_possible_simple_key()\n\n\t\t# Add KEY.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(KeyToken(start_mark, end_mark))\n\n\tdef fetch_value(self):\n\n\t\t# Do we determine a simple key?\n\t\tif self.flow_level in self.possible_simple_keys:\n\n\t\t\t# Add KEY.\n\t\t\tkey = self.possible_simple_keys[self.flow_level]\n\t\t\tdel self.possible_simple_keys[self.flow_level]\n\t\t\tself.tokens.insert(key.token_number-self.tokens_taken,\n\t\t\t\t\tKeyToken(key.mark, key.mark))\n\n\t\t\t# If this key starts a new block mapping, we need to add\n\t\t\t# BLOCK-MAPPING-START.\n\t\t\tif not self.flow_level:\n\t\t\t\tif self.add_indent(key.column):\n\t\t\t\t\tself.tokens.insert(key.token_number-self.tokens_taken,\n\t\t\t\t\t\t\tBlockMappingStartToken(key.mark, key.mark))\n\n\t\t\t# There cannot be two simple keys one after another.\n\t\t\tself.allow_simple_key = False\n\n\t\t# It must be a part of a complex key.\n\t\telse:\n\t\t\t\n\t\t\t# Block context needs additional checks.\n\t\t\t# (Do we really need them? They will be catched by the parser\n\t\t\t# anyway.)\n\t\t\tif not self.flow_level:\n\n\t\t\t\t# We are allowed to start a complex value if and only if\n\t\t\t\t# we can start a simple key.\n\t\t\t\tif not self.allow_simple_key:\n\t\t\t\t\traise ScannerError(None, None,\n\t\t\t\t\t\t\t\"mapping values are not allowed here\",\n\t\t\t\t\t\t\tself.get_mark())\n\n\t\t\t# If this value starts a new block mapping, we need to add\n\t\t\t# BLOCK-MAPPING-START.  It will be detected as an error later by\n\t\t\t# the parser.\n\t\t\tif not self.flow_level:\n\t\t\t\tif self.add_indent(self.column):\n\t\t\t\t\tmark = self.get_mark()\n\t\t\t\t\tself.tokens.append(BlockMappingStartToken(mark, mark))\n\n\t\t\t# Simple keys are allowed after ':' in the block context.\n\t\t\tself.allow_simple_key = not self.flow_level\n\n\t\t\t# Reset possible simple key on the current level.\n\t\t\tself.remove_possible_simple_key()\n\n\t\t# Add VALUE.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(ValueToken(start_mark, end_mark))\n\n\tdef fetch_alias(self):\n\n\t\t# ALIAS could be a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# No simple keys after ALIAS.\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add ALIAS.\n\t\tself.tokens.append(self.scan_anchor(AliasToken))\n\n\tdef fetch_anchor(self):\n\n\t\t# ANCHOR could start a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# No simple keys after ANCHOR.\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add ANCHOR.\n\t\tself.tokens.append(self.scan_anchor(AnchorToken))\n\n\tdef fetch_tag(self):\n\n\t\t# TAG could start a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# No simple keys after TAG.\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add TAG.\n\t\tself.tokens.append(self.scan_tag())\n\n\tdef fetch_literal(self):\n\t\tself.fetch_block_scalar(style='|')\n\n\tdef fetch_folded(self):\n\t\tself.fetch_block_scalar(style='>')\n\n\tdef fetch_block_scalar(self, style):\n\n\t\t# A simple key may follow a block scalar.\n\t\tself.allow_simple_key = True\n\n\t\t# Reset possible simple key on the current level.\n\t\tself.remove_possible_simple_key()\n\n\t\t# Scan and add SCALAR.\n\t\tself.tokens.append(self.scan_block_scalar(style))\n\n\tdef fetch_single(self):\n\t\tself.fetch_flow_scalar(style='\\'')\n\n\tdef fetch_double(self):\n\t\tself.fetch_flow_scalar(style='\"')\n\n\tdef fetch_flow_scalar(self, style):\n\n\t\t# A flow scalar could be a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# No simple keys after flow scalars.\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add SCALAR.\n\t\tself.tokens.append(self.scan_flow_scalar(style))\n\n\tdef fetch_plain(self):\n\n\t\t# A plain scalar could be a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# No simple keys after plain scalars. But note that `scan_plain` will\n\t\t# change this flag if the scan is finished at the beginning of the\n\t\t# line.\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add SCALAR. May change `allow_simple_key`.\n\t\tself.tokens.append(self.scan_plain())\n\n\t# Checkers.\n\n\tdef check_directive(self):\n\n\t\t# DIRECTIVE:\t\t^ '%' ...\n\t\t# The '%' indicator is already checked.\n\t\tif self.column == 0:\n\t\t\treturn True\n\n\tdef check_document_start(self):\n\n\t\t# DOCUMENT-START:   ^ '---' (' '|'\\n')\n\t\tif self.column == 0:\n\t\t\tif self.prefix(3) == u'---'  \\\n\t\t\t\t\tand self.peek(3) in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\treturn True\n\n\tdef check_document_end(self):\n\n\t\t# DOCUMENT-END:\t ^ '...' (' '|'\\n')\n\t\tif self.column == 0:\n\t\t\tif self.prefix(3) == u'...'  \\\n\t\t\t\t\tand self.peek(3) in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\treturn True\n\n\tdef check_block_entry(self):\n\n\t\t# BLOCK-ENTRY:\t  '-' (' '|'\\n')\n\t\treturn self.peek(1) in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029'\n\n\tdef check_key(self):\n\n\t\t# KEY(flow context):\t'?'\n\t\tif self.flow_level:\n\t\t\treturn True\n\n\t\t# KEY(block context):   '?' (' '|'\\n')\n\t\telse:\n\t\t\treturn self.peek(1) in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029'\n\n\tdef check_value(self):\n\n\t\t# VALUE(flow context):  ':'\n\t\tif self.flow_level:\n\t\t\treturn True\n\n\t\t# VALUE(block context): ':' (' '|'\\n')\n\t\telse:\n\t\t\treturn self.peek(1) in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029'\n\n\tdef check_plain(self):\n\n\t\t# A plain scalar may start with any non-space character except:\n\t\t#   '-', '?', ':', ',', '[', ']', '{', '}',\n\t\t#   '#', '&', '*', '!', '|', '>', '\\'', '\\\"',\n\t\t#   '%', '@', '`'.\n\t\t#\n\t\t# It may also start with\n\t\t#   '-', '?', ':'\n\t\t# if it is followed by a non-space character.\n\t\t#\n\t\t# Note that we limit the last rule to the block context (except the\n\t\t# '-' character) because we want the flow context to be space\n\t\t# independent.\n\t\tch = self.peek()\n\t\treturn ch not in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029-?:,[]{}#&*!|>\\'\\\"%@`'  \\\n\t\t\t\tor (self.peek(1) not in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029'\n\t\t\t\t\t\tand (ch == u'-' or (not self.flow_level and ch in u'?:')))\n\n\t# Scanners.\n\n\tdef scan_to_next_token(self):\n\t\t# We ignore spaces, line breaks and comments.\n\t\t# If we find a line break in the block context, we set the flag\n\t\t# `allow_simple_key` on.\n\t\t# The byte order mark is stripped if it's the first character in the\n\t\t# stream. We do not yet support BOM inside the stream as the\n\t\t# specification requires. Any such mark will be considered as a part\n\t\t# of the document.\n\t\t#\n\t\t# TODO: We need to make tab handling rules more sane. A good rule is\n\t\t#   Tabs cannot precede tokens\n\t\t#   BLOCK-SEQUENCE-START, BLOCK-MAPPING-START, BLOCK-END,\n\t\t#   KEY(block), VALUE(block), BLOCK-ENTRY\n\t\t# So the checking code is\n\t\t#   if :\n\t\t#\t   self.allow_simple_keys = False\n\t\t# We also need to add the check for `allow_simple_keys == True` to\n\t\t# `unwind_indent` before issuing BLOCK-END.\n\t\t# Scanners for block, flow, and plain scalars need to be modified.\n\n\t\tif self.index == 0 and self.peek() == u'\\uFEFF':\n\t\t\tself.forward()\n\t\tfound = False\n\t\twhile not found:\n\t\t\twhile self.peek() == u' ':\n\t\t\t\tself.forward()\n\t\t\tif self.peek() == u'#':\n\t\t\t\twhile self.peek() not in u'\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\t\tself.forward()\n\t\t\tif self.scan_line_break():\n\t\t\t\tif not self.flow_level:\n\t\t\t\t\tself.allow_simple_key = True\n\t\t\telse:\n\t\t\t\tfound = True\n\n\tdef scan_directive(self):\n\t\t# See the specification for details.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tname = self.scan_directive_name(start_mark)\n\t\tvalue = None\n\t\tif name == u'YAML':\n\t\t\tvalue = self.scan_yaml_directive_value(start_mark)\n\t\t\tend_mark = self.get_mark()\n\t\telif name == u'TAG':\n\t\t\tvalue = self.scan_tag_directive_value(start_mark)\n\t\t\tend_mark = self.get_mark()\n\t\telse:\n\t\t\tend_mark = self.get_mark()\n\t\t\twhile self.peek() not in u'\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tself.forward()\n\t\tself.scan_directive_ignored_line(start_mark)\n\t\treturn DirectiveToken(name, value, start_mark, end_mark)\n\n\tdef scan_directive_name(self, start_mark):\n\t\t# See the specification for details.\n\t\tlength = 0\n\t\tch = self.peek(length)\n\t\twhile u'0' <= ch <= u'9' or u'A' <= ch <= u'Z' or u'a' <= ch <= u'z'\t\\\n\t\t\t\tor ch in u'-_':\n\t\t\tlength += 1\n\t\t\tch = self.peek(length)\n\t\tif not length:\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected alphabetic or numeric character, but found %r\"\n\t\t\t\t\t% ch.encode('utf-8'), self.get_mark())\n\t\tvalue = self.prefix(length)\n\t\tself.forward(length)\n\t\tch = self.peek()\n\t\tif ch not in u'\\0 \\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected alphabetic or numeric character, but found %r\"\n\t\t\t\t\t% ch.encode('utf-8'), self.get_mark())\n\t\treturn value\n\n\tdef scan_yaml_directive_value(self, start_mark):\n\t\t# See the specification for details.\n\t\twhile self.peek() == u' ':\n\t\t\tself.forward()\n\t\tmajor = self.scan_yaml_directive_number(start_mark)\n\t\tif self.peek() != '.':\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected a digit or '.', but found %r\"\n\t\t\t\t\t% self.peek().encode('utf-8'),\n\t\t\t\t\tself.get_mark())\n\t\tself.forward()\n\t\tminor = self.scan_yaml_directive_number(start_mark)\n\t\tif self.peek() not in u'\\0 \\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected a digit or ' ', but found %r\"\n\t\t\t\t\t% self.peek().encode('utf-8'),\n\t\t\t\t\tself.get_mark())\n\t\treturn (major, minor)\n\n\tdef scan_yaml_directive_number(self, start_mark):\n\t\t# See the specification for details.\n\t\tch = self.peek()\n\t\tif not (u'0' <= ch <= u'9'):\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected a digit, but found %r\" % ch.encode('utf-8'),\n\t\t\t\t\tself.get_mark())\n\t\tlength = 0\n\t\twhile u'0' <= self.peek(length) <= u'9':\n\t\t\tlength += 1\n\t\tvalue = int(self.prefix(length))\n\t\tself.forward(length)\n\t\treturn value\n\n\tdef scan_tag_directive_value(self, start_mark):\n\t\t# See the specification for details.\n\t\twhile self.peek() == u' ':\n\t\t\tself.forward()\n\t\thandle = self.scan_tag_directive_handle(start_mark)\n\t\twhile self.peek() == u' ':\n\t\t\tself.forward()\n\t\tprefix = self.scan_tag_directive_prefix(start_mark)\n\t\treturn (handle, prefix)\n\n\tdef scan_tag_directive_handle(self, start_mark):\n\t\t# See the specification for details.\n\t\tvalue = self.scan_tag_handle('directive', start_mark)\n\t\tch = self.peek()\n\t\tif ch != u' ':\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected ' ', but found %r\" % ch.encode('utf-8'),\n\t\t\t\t\tself.get_mark())\n\t\treturn value\n\n\tdef scan_tag_directive_prefix(self, start_mark):\n\t\t# See the specification for details.\n\t\tvalue = self.scan_tag_uri('directive', start_mark)\n\t\tch = self.peek()\n\t\tif ch not in u'\\0 \\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected ' ', but found %r\" % ch.encode('utf-8'),\n\t\t\t\t\tself.get_mark())\n\t\treturn value\n\n\tdef scan_directive_ignored_line(self, start_mark):\n\t\t# See the specification for details.\n\t\twhile self.peek() == u' ':\n\t\t\tself.forward()\n\t\tif self.peek() == u'#':\n\t\t\twhile self.peek() not in u'\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tself.forward()\n\t\tch = self.peek()\n\t\tif ch not in u'\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected a comment or a line break, but found %r\"\n\t\t\t\t\t\t% ch.encode('utf-8'), self.get_mark())\n\t\tself.scan_line_break()\n\n\tdef scan_anchor(self, TokenClass):\n\t\t# The specification does not restrict characters for anchors and\n\t\t# aliases. This may lead to problems, for instance, the document:\n\t\t#   [ *alias, value ]\n\t\t# can be interpteted in two ways, as\n\t\t#   [ \"value\" ]\n\t\t# and\n\t\t#   [ *alias , \"value\" ]\n\t\t# Therefore we restrict aliases to numbers and ASCII letters.\n\t\tstart_mark = self.get_mark()\n\t\tindicator = self.peek()\n\t\tif indicator == u'*':\n\t\t\tname = 'alias'\n\t\telse:\n\t\t\tname = 'anchor'\n\t\tself.forward()\n\t\tlength = 0\n\t\tch = self.peek(length)\n\t\twhile u'0' <= ch <= u'9' or u'A' <= ch <= u'Z' or u'a' <= ch <= u'z'\t\\\n\t\t\t\tor ch in u'-_':\n\t\t\tlength += 1\n\t\t\tch = self.peek(length)\n\t\tif not length:\n\t\t\traise ScannerError(\"while scanning an %s\" % name, start_mark,\n\t\t\t\t\t\"expected alphabetic or numeric character, but found %r\"\n\t\t\t\t\t% ch.encode('utf-8'), self.get_mark())\n\t\tvalue = self.prefix(length)\n\t\tself.forward(length)\n\t\tch = self.peek()\n\t\tif ch not in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029?:,]}%@`':\n\t\t\traise ScannerError(\"while scanning an %s\" % name, start_mark,\n\t\t\t\t\t\"expected alphabetic or numeric character, but found %r\"\n\t\t\t\t\t% ch.encode('utf-8'), self.get_mark())\n\t\tend_mark = self.get_mark()\n\t\treturn TokenClass(value, start_mark, end_mark)\n\n\tdef scan_tag(self):\n\t\t# See the specification for details.\n\t\tstart_mark = self.get_mark()\n\t\tch = self.peek(1)\n\t\tif ch == u'<':\n\t\t\thandle = None\n\t\t\tself.forward(2)\n\t\t\tsuffix = self.scan_tag_uri('tag', start_mark)\n\t\t\tif self.peek() != u'>':\n\t\t\t\traise ScannerError(\"while parsing a tag\", start_mark,\n\t\t\t\t\t\t\"expected '>', but found %r\" % self.peek().encode('utf-8'),\n\t\t\t\t\t\tself.get_mark())\n\t\t\tself.forward()\n\t\telif ch in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\thandle = None\n\t\t\tsuffix = u'!'\n\t\t\tself.forward()\n\t\telse:\n\t\t\tlength = 1\n\t\t\tuse_handle = False\n\t\t\twhile ch not in u'\\0 \\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tif ch == u'!':\n\t\t\t\t\tuse_handle = True\n\t\t\t\t\tbreak\n\t\t\t\tlength += 1\n\t\t\t\tch = self.peek(length)\n\t\t\thandle = u'!'\n\t\t\tif use_handle:\n\t\t\t\thandle = self.scan_tag_handle('tag', start_mark)\n\t\t\telse:\n\t\t\t\thandle = u'!'\n\t\t\t\tself.forward()\n\t\t\tsuffix = self.scan_tag_uri('tag', start_mark)\n\t\tch = self.peek()\n\t\tif ch not in u'\\0 \\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a tag\", start_mark,\n\t\t\t\t\t\"expected ' ', but found %r\" % ch.encode('utf-8'),\n\t\t\t\t\tself.get_mark())\n\t\tvalue = (handle, suffix)\n\t\tend_mark = self.get_mark()\n\t\treturn TagToken(value, start_mark, end_mark)\n\n\tdef scan_block_scalar(self, style):\n\t\t# See the specification for details.\n\n\t\tif style == '>':\n\t\t\tfolded = True\n\t\telse:\n\t\t\tfolded = False\n\n\t\tchunks = []\n\t\tstart_mark = self.get_mark()\n\n\t\t# Scan the header.\n\t\tself.forward()\n\t\tchomping, increment = self.scan_block_scalar_indicators(start_mark)\n\t\tself.scan_block_scalar_ignored_line(start_mark)\n\n\t\t# Determine the indentation level and go to the first non-empty line.\n\t\tmin_indent = self.indent+1\n\t\tif min_indent < 1:\n\t\t\tmin_indent = 1\n\t\tif increment is None:\n\t\t\tbreaks, max_indent, end_mark = self.scan_block_scalar_indentation()\n\t\t\tindent = max(min_indent, max_indent)\n\t\telse:\n\t\t\tindent = min_indent+increment-1\n\t\t\tbreaks, end_mark = self.scan_block_scalar_breaks(indent)\n\t\tline_break = u''\n\n\t\t# Scan the inner part of the block scalar.\n\t\twhile self.column == indent and self.peek() != u'\\0':\n\t\t\tchunks.extend(breaks)\n\t\t\tleading_non_space = self.peek() not in u' \\t'\n\t\t\tlength = 0\n\t\t\twhile self.peek(length) not in u'\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tlength += 1\n\t\t\tchunks.append(self.prefix(length))\n\t\t\tself.forward(length)\n\t\t\tline_break = self.scan_line_break()\n\t\t\tbreaks, end_mark = self.scan_block_scalar_breaks(indent)\n\t\t\tif self.column == indent and self.peek() != u'\\0':\n\n\t\t\t\t# Unfortunately, folding rules are ambiguous.\n\t\t\t\t#\n\t\t\t\t# This is the folding according to the specification:\n\t\t\t\t\n\t\t\t\tif folded and line_break == u'\\n'   \\\n\t\t\t\t\t\tand leading_non_space and self.peek() not in u' \\t':\n\t\t\t\t\tif not breaks:\n\t\t\t\t\t\tchunks.append(u' ')\n\t\t\t\telse:\n\t\t\t\t\tchunks.append(line_break)\n\t\t\t\t\n\t\t\t\t# This is Clark Evans's interpretation (also in the spec\n\t\t\t\t# examples):\n\t\t\t\t#\n\t\t\t\t#if folded and line_break == u'\\n':\n\t\t\t\t#\tif not breaks:\n\t\t\t\t#\t\tif self.peek() not in ' \\t':\n\t\t\t\t#\t\t\tchunks.append(u' ')\n\t\t\t\t#\t\telse:\n\t\t\t\t#\t\t\tchunks.append(line_break)\n\t\t\t\t#else:\n\t\t\t\t#\tchunks.append(line_break)\n\t\t\telse:\n\t\t\t\tbreak\n\n\t\t# Chomp the tail.\n\t\tif chomping is not False:\n\t\t\tchunks.append(line_break)\n\t\tif chomping is True:\n\t\t\tchunks.extend(breaks)\n\n\t\t# We are done.\n\t\treturn ScalarToken(u''.join(chunks), False, start_mark, end_mark,\n\t\t\t\tstyle)\n\n\tdef scan_block_scalar_indicators(self, start_mark):\n\t\t# See the specification for details.\n\t\tchomping = None\n\t\tincrement = None\n\t\tch = self.peek()\n\t\tif ch in u'+-':\n\t\t\tif ch == '+':\n\t\t\t\tchomping = True\n\t\t\telse:\n\t\t\t\tchomping = False\n\t\t\tself.forward()\n\t\t\tch = self.peek()\n\t\t\tif ch in u'0123456789':\n\t\t\t\tincrement = int(ch)\n\t\t\t\tif increment == 0:\n\t\t\t\t\traise ScannerError(\"while scanning a block scalar\", start_mark,\n\t\t\t\t\t\t\t\"expected indentation indicator in the range 1-9, but found 0\",\n\t\t\t\t\t\t\tself.get_mark())\n\t\t\t\tself.forward()\n\t\telif ch in u'0123456789':\n\t\t\tincrement = int(ch)\n\t\t\tif increment == 0:\n\t\t\t\traise ScannerError(\"while scanning a block scalar\", start_mark,\n\t\t\t\t\t\t\"expected indentation indicator in the range 1-9, but found 0\",\n\t\t\t\t\t\tself.get_mark())\n\t\t\tself.forward()\n\t\t\tch = self.peek()\n\t\t\tif ch in u'+-':\n\t\t\t\tif ch == '+':\n\t\t\t\t\tchomping = True\n\t\t\t\telse:\n\t\t\t\t\tchomping = False\n\t\t\t\tself.forward()\n\t\tch = self.peek()\n\t\tif ch not in u'\\0 \\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a block scalar\", start_mark,\n\t\t\t\t\t\"expected chomping or indentation indicators, but found %r\"\n\t\t\t\t\t\t% ch.encode('utf-8'), self.get_mark())\n\t\treturn chomping, increment\n\n\tdef scan_block_scalar_ignored_line(self, start_mark):\n\t\t# See the specification for details.\n\t\twhile self.peek() == u' ':\n\t\t\tself.forward()\n\t\tif self.peek() == u'#':\n\t\t\twhile self.peek() not in u'\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tself.forward()\n\t\tch = self.peek()\n\t\tif ch not in u'\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a block scalar\", start_mark,\n\t\t\t\t\t\"expected a comment or a line break, but found %r\"\n\t\t\t\t\t\t% ch.encode('utf-8'), self.get_mark())\n\t\tself.scan_line_break()\n\n\tdef scan_block_scalar_indentation(self):\n\t\t# See the specification for details.\n\t\tchunks = []\n\t\tmax_indent = 0\n\t\tend_mark = self.get_mark()\n\t\twhile self.peek() in u' \\r\\n\\x85\\u2028\\u2029':\n\t\t\tif self.peek() != u' ':\n\t\t\t\tchunks.append(self.scan_line_break())\n\t\t\t\tend_mark = self.get_mark()\n\t\t\telse:\n\t\t\t\tself.forward()\n\t\t\t\tif self.column > max_indent:\n\t\t\t\t\tmax_indent = self.column\n\t\treturn chunks, max_indent, end_mark\n\n\tdef scan_block_scalar_breaks(self, indent):\n\t\t# See the specification for details.\n\t\tchunks = []\n\t\tend_mark = self.get_mark()\n\t\twhile self.column < indent and self.peek() == u' ':\n\t\t\tself.forward()\n\t\twhile self.peek() in u'\\r\\n\\x85\\u2028\\u2029':\n\t\t\tchunks.append(self.scan_line_break())\n\t\t\tend_mark = self.get_mark()\n\t\t\twhile self.column < indent and self.peek() == u' ':\n\t\t\t\tself.forward()\n\t\treturn chunks, end_mark\n\n\tdef scan_flow_scalar(self, style):\n\t\t# See the specification for details.\n\t\t# Note that we loose indentation rules for quoted scalars. Quoted\n\t\t# scalars don't need to adhere indentation because \" and ' clearly\n\t\t# mark the beginning and the end of them. Therefore we are less\n\t\t# restrictive then the specification requires. We only need to check\n\t\t# that document separators are not included in scalars.\n\t\tif style == '\"':\n\t\t\tdouble = True\n\t\telse:\n\t\t\tdouble = False\n\t\tchunks = []\n\t\tstart_mark = self.get_mark()\n\t\tquote = self.peek()\n\t\tself.forward()\n\t\tchunks.extend(self.scan_flow_scalar_non_spaces(double, start_mark))\n\t\twhile self.peek() != quote:\n\t\t\tchunks.extend(self.scan_flow_scalar_spaces(double, start_mark))\n\t\t\tchunks.extend(self.scan_flow_scalar_non_spaces(double, start_mark))\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\treturn ScalarToken(u''.join(chunks), False, start_mark, end_mark,\n\t\t\t\tstyle)\n\n\tESCAPE_REPLACEMENTS = {\n\t\tu'0':   u'\\0',\n\t\tu'a':   u'\\x07',\n\t\tu'b':   u'\\x08',\n\t\tu't':   u'\\x09',\n\t\tu'\\t':  u'\\x09',\n\t\tu'n':   u'\\x0A',\n\t\tu'v':   u'\\x0B',\n\t\tu'f':   u'\\x0C',\n\t\tu'r':   u'\\x0D',\n\t\tu'e':   u'\\x1B',\n\t\tu' ':   u'\\x20',\n\t\tu'\\\"':  u'\\\"',\n\t\tu'\\\\':  u'\\\\',\n\t\tu'N':   u'\\x85',\n\t\tu'_':   u'\\xA0',\n\t\tu'L':   u'\\u2028',\n\t\tu'P':   u'\\u2029',\n\t}\n\n\tESCAPE_CODES = {\n\t\tu'x':   2,\n\t\tu'u':   4,\n\t\tu'U':   8,\n\t}\n\n\tdef scan_flow_scalar_non_spaces(self, double, start_mark):\n\t\t# See the specification for details.\n\t\tchunks = []\n\t\twhile True:\n\t\t\tlength = 0\n\t\t\twhile self.peek(length) not in u'\\'\\\"\\\\\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tlength += 1\n\t\t\tif length:\n\t\t\t\tchunks.append(self.prefix(length))\n\t\t\t\tself.forward(length)\n\t\t\tch = self.peek()\n\t\t\tif not double and ch == u'\\'' and self.peek(1) == u'\\'':\n\t\t\t\tchunks.append(u'\\'')\n\t\t\t\tself.forward(2)\n\t\t\telif (double and ch == u'\\'') or (not double and ch in u'\\\"\\\\'):\n\t\t\t\tchunks.append(ch)\n\t\t\t\tself.forward()\n\t\t\telif double and ch == u'\\\\':\n\t\t\t\tself.forward()\n\t\t\t\tch = self.peek()\n\t\t\t\tif ch in self.ESCAPE_REPLACEMENTS:\n\t\t\t\t\tchunks.append(self.ESCAPE_REPLACEMENTS[ch])\n\t\t\t\t\tself.forward()\n\t\t\t\telif ch in self.ESCAPE_CODES:\n\t\t\t\t\tlength = self.ESCAPE_CODES[ch]\n\t\t\t\t\tself.forward()\n\t\t\t\t\tfor k in range(length):\n\t\t\t\t\t\tif self.peek(k) not in u'0123456789ABCDEFabcdef':\n\t\t\t\t\t\t\traise ScannerError(\"while scanning a double-quoted scalar\", start_mark,\n\t\t\t\t\t\t\t\t\t\"expected escape sequence of %d hexdecimal numbers, but found %r\" %\n\t\t\t\t\t\t\t\t\t\t(length, self.peek(k).encode('utf-8')), self.get_mark())\n\t\t\t\t\tcode = int(self.prefix(length), 16)\n\t\t\t\t\tchunks.append(unichr(code))\n\t\t\t\t\tself.forward(length)\n\t\t\t\telif ch in u'\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\t\tself.scan_line_break()\n\t\t\t\t\tchunks.extend(self.scan_flow_scalar_breaks(double, start_mark))\n\t\t\t\telse:\n\t\t\t\t\traise ScannerError(\"while scanning a double-quoted scalar\", start_mark,\n\t\t\t\t\t\t\t\"found unknown escape character %r\" % ch.encode('utf-8'), self.get_mark())\n\t\t\telse:\n\t\t\t\treturn chunks\n\n\tdef scan_flow_scalar_spaces(self, double, start_mark):\n\t\t# See the specification for details.\n\t\tchunks = []\n\t\tlength = 0\n\t\twhile self.peek(length) in u' \\t':\n\t\t\tlength += 1\n\t\twhitespaces = self.prefix(length)\n\t\tself.forward(length)\n\t\tch = self.peek()\n\t\tif ch == u'\\0':\n\t\t\traise ScannerError(\"while scanning a quoted scalar\", start_mark,\n\t\t\t\t\t\"found unexpected end of stream\", self.get_mark())\n\t\telif ch in u'\\r\\n\\x85\\u2028\\u2029':\n\t\t\tline_break = self.scan_line_break()\n\t\t\tbreaks = self.scan_flow_scalar_breaks(double, start_mark)\n\t\t\tif line_break != u'\\n':\n\t\t\t\tchunks.append(line_break)\n\t\t\telif not breaks:\n\t\t\t\tchunks.append(u' ')\n\t\t\tchunks.extend(breaks)\n\t\telse:\n\t\t\tchunks.append(whitespaces)\n\t\treturn chunks\n\n\tdef scan_flow_scalar_breaks(self, double, start_mark):\n\t\t# See the specification for details.\n\t\tchunks = []\n\t\twhile True:\n\t\t\t# Instead of checking indentation, we check for document\n\t\t\t# separators.\n\t\t\tprefix = self.prefix(3)\n\t\t\tif (prefix == u'---' or prefix == u'...')   \\\n\t\t\t\t\tand self.peek(3) in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\traise ScannerError(\"while scanning a quoted scalar\", start_mark,\n\t\t\t\t\t\t\"found unexpected document separator\", self.get_mark())\n\t\t\twhile self.peek() in u' \\t':\n\t\t\t\tself.forward()\n\t\t\tif self.peek() in u'\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tchunks.append(self.scan_line_break())\n\t\t\telse:\n\t\t\t\treturn chunks\n\n\tdef scan_plain(self):\n\t\t# See the specification for details.\n\t\t# We add an additional restriction for the flow context:\n\t\t#   plain scalars in the flow context cannot contain ',', ':' and '?'.\n\t\t# We also keep track of the `allow_simple_key` flag here.\n\t\t# Indentation rules are loosed for the flow context.\n\t\tchunks = []\n\t\tstart_mark = self.get_mark()\n\t\tend_mark = start_mark\n\t\tindent = self.indent+1\n\t\t# We allow zero indentation for scalars, but then we need to check for\n\t\t# document separators at the beginning of the line.\n\t\t#if indent == 0:\n\t\t#\tindent = 1\n\t\tspaces = []\n\t\twhile True:\n\t\t\tlength = 0\n\t\t\tif self.peek() == u'#':\n\t\t\t\tbreak\n\t\t\twhile True:\n\t\t\t\tch = self.peek(length)\n\t\t\t\tif ch in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029'   \\\n\t\t\t\t\t\tor (not self.flow_level and ch == u':' and\n\t\t\t\t\t\t\t\tself.peek(length+1) in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029') \\\n\t\t\t\t\t\tor (self.flow_level and ch in u',:?[]{}'):\n\t\t\t\t\tbreak\n\t\t\t\tlength += 1\n\t\t\t# It's not clear what we should do with ':' in the flow context.\n\t\t\tif (self.flow_level and ch == u':'\n\t\t\t\t\tand self.peek(length+1) not in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029,[]{}'):\n\t\t\t\tself.forward(length)\n\t\t\t\traise ScannerError(\"while scanning a plain scalar\", start_mark,\n\t\t\t\t\t\"found unexpected ':'\", self.get_mark(),\n\t\t\t\t\t\"Please check http://pyyaml.org/wiki/YAMLColonInFlowContext for details.\")\n\t\t\tif length == 0:\n\t\t\t\tbreak\n\t\t\tself.allow_simple_key = False\n\t\t\tchunks.extend(spaces)\n\t\t\tchunks.append(self.prefix(length))\n\t\t\tself.forward(length)\n\t\t\tend_mark = self.get_mark()\n\t\t\tspaces = self.scan_plain_spaces(indent, start_mark)\n\t\t\tif not spaces or self.peek() == u'#' \\\n\t\t\t\t\tor (not self.flow_level and self.column < indent):\n\t\t\t\tbreak\n\t\treturn ScalarToken(u''.join(chunks), True, start_mark, end_mark)\n\n\tdef scan_plain_spaces(self, indent, start_mark):\n\t\t# See the specification for details.\n\t\t# The specification is really confusing about tabs in plain scalars.\n\t\t# We just forbid them completely. Do not use tabs in YAML!\n\t\tchunks = []\n\t\tlength = 0\n\t\twhile self.peek(length) in u' ':\n\t\t\tlength += 1\n\t\twhitespaces = self.prefix(length)\n\t\tself.forward(length)\n\t\tch = self.peek()\n\t\tif ch in u'\\r\\n\\x85\\u2028\\u2029':\n\t\t\tline_break = self.scan_line_break()\n\t\t\tself.allow_simple_key = True\n\t\t\tprefix = self.prefix(3)\n\t\t\tif (prefix == u'---' or prefix == u'...')   \\\n\t\t\t\t\tand self.peek(3) in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\treturn\n\t\t\tbreaks = []\n\t\t\twhile self.peek() in u' \\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tif self.peek() == ' ':\n\t\t\t\t\tself.forward()\n\t\t\t\telse:\n\t\t\t\t\tbreaks.append(self.scan_line_break())\n\t\t\t\t\tprefix = self.prefix(3)\n\t\t\t\t\tif (prefix == u'---' or prefix == u'...')   \\\n\t\t\t\t\t\t\tand self.peek(3) in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\t\t\treturn\n\t\t\tif line_break != u'\\n':\n\t\t\t\tchunks.append(line_break)\n\t\t\telif not breaks:\n\t\t\t\tchunks.append(u' ')\n\t\t\tchunks.extend(breaks)\n\t\telif whitespaces:\n\t\t\tchunks.append(whitespaces)\n\t\treturn chunks\n\n\tdef scan_tag_handle(self, name, start_mark):\n\t\t# See the specification for details.\n\t\t# For some strange reasons, the specification does not allow '_' in\n\t\t# tag handles. I have allowed it anyway.\n\t\tch = self.peek()\n\t\tif ch != u'!':\n\t\t\traise ScannerError(\"while scanning a %s\" % name, start_mark,\n\t\t\t\t\t\"expected '!', but found %r\" % ch.encode('utf-8'),\n\t\t\t\t\tself.get_mark())\n\t\tlength = 1\n\t\tch = self.peek(length)\n\t\tif ch != u' ':\n\t\t\twhile u'0' <= ch <= u'9' or u'A' <= ch <= u'Z' or u'a' <= ch <= u'z'\t\\\n\t\t\t\t\tor ch in u'-_':\n\t\t\t\tlength += 1\n\t\t\t\tch = self.peek(length)\n\t\t\tif ch != u'!':\n\t\t\t\tself.forward(length)\n\t\t\t\traise ScannerError(\"while scanning a %s\" % name, start_mark,\n\t\t\t\t\t\t\"expected '!', but found %r\" % ch.encode('utf-8'),\n\t\t\t\t\t\tself.get_mark())\n\t\t\tlength += 1\n\t\tvalue = self.prefix(length)\n\t\tself.forward(length)\n\t\treturn value\n\n\tdef scan_tag_uri(self, name, start_mark):\n\t\t# See the specification for details.\n\t\t# Note: we do not check if URI is well-formed.\n\t\tchunks = []\n\t\tlength = 0\n\t\tch = self.peek(length)\n\t\twhile u'0' <= ch <= u'9' or u'A' <= ch <= u'Z' or u'a' <= ch <= u'z'\t\\\n\t\t\t\tor ch in u'-;/?:@&=+$,_.!~*\\'()[]%':\n\t\t\tif ch == u'%':\n\t\t\t\tchunks.append(self.prefix(length))\n\t\t\t\tself.forward(length)\n\t\t\t\tlength = 0\n\t\t\t\tchunks.append(self.scan_uri_escapes(name, start_mark))\n\t\t\telse:\n\t\t\t\tlength += 1\n\t\t\tch = self.peek(length)\n\t\tif length:\n\t\t\tchunks.append(self.prefix(length))\n\t\t\tself.forward(length)\n\t\t\tlength = 0\n\t\tif not chunks:\n\t\t\traise ScannerError(\"while parsing a %s\" % name, start_mark,\n\t\t\t\t\t\"expected URI, but found %r\" % ch.encode('utf-8'),\n\t\t\t\t\tself.get_mark())\n\t\treturn u''.join(chunks)\n\n\tdef scan_uri_escapes(self, name, start_mark):\n\t\t# See the specification for details.\n\t\tbytes = []\n\t\tmark = self.get_mark()\n\t\twhile self.peek() == u'%':\n\t\t\tself.forward()\n\t\t\tfor k in range(2):\n\t\t\t\tif self.peek(k) not in u'0123456789ABCDEFabcdef':\n\t\t\t\t\traise ScannerError(\"while scanning a %s\" % name, start_mark,\n\t\t\t\t\t\t\t\"expected URI escape sequence of 2 hexdecimal numbers, but found %r\" %\n\t\t\t\t\t\t\t\t(self.peek(k).encode('utf-8')), self.get_mark())\n\t\t\tbytes.append(chr(int(self.prefix(2), 16)))\n\t\t\tself.forward(2)\n\t\ttry:\n\t\t\tvalue = unicode(''.join(bytes), 'utf-8')\n\t\texcept UnicodeDecodeError, exc:\n\t\t\traise ScannerError(\"while scanning a %s\" % name, start_mark, str(exc), mark)\n\t\treturn value\n\n\tdef scan_line_break(self):\n\t\t# Transforms:\n\t\t#   '\\r\\n'\t  :   '\\n'\n\t\t#   '\\r'\t\t:   '\\n'\n\t\t#   '\\n'\t\t:   '\\n'\n\t\t#   '\\x85'\t  :   '\\n'\n\t\t#   '\\u2028'\t:   '\\u2028'\n\t\t#   '\\u2029\t :   '\\u2029'\n\t\t#   default\t :   ''\n\t\tch = self.peek()\n\t\tif ch in u'\\r\\n\\x85':\n\t\t\tif self.prefix(2) == u'\\r\\n':\n\t\t\t\tself.forward(2)\n\t\t\telse:\n\t\t\t\tself.forward()\n\t\t\treturn u'\\n'\n\t\telif ch in u'\\u2028\\u2029':\n\t\t\tself.forward()\n\t\t\treturn ch\n\t\treturn u''\n", "description": "Initialize the scanner.", "category": "simple", "imports": ["from .error import MarkedYAMLError", "from .tokens import *", "#\timport psyco"]}], [{"term": "class", "name": "ScannerError", "data": "class ScannerError(MarkedYAMLError):\n\tpass\n", "description": null, "category": "simple", "imports": ["from error import MarkedYAMLError", "from tokens import *", "#\timport psyco"]}, {"term": "class", "name": "SimpleKey", "data": "class SimpleKey(object):\n\t# See below simple keys treatment.\n\n\tdef __init__(self, token_number, required, index, line, column, mark):\n\t\tself.token_number = token_number\n\t\tself.required = required\n\t\tself.index = index\n\t\tself.line = line\n\t\tself.column = column\n\t\tself.mark = mark\n", "description": null, "category": "simple", "imports": ["from error import MarkedYAMLError", "from tokens import *", "#\timport psyco"]}, {"term": "class", "name": "Scanner", "data": "class Scanner(object):\n\n\tdef __init__(self):\n\t\t\"\"\"Initialize the scanner.\"\"\"\n\t\t# It is assumed that Scanner and Reader will have a common descendant.\n\t\t# Reader do the dirty work of checking for BOM and converting the\n\t\t# input data to Unicode. It also adds NUL to the end.\n\t\t#\n\t\t# Reader supports the following methods\n\t\t#   self.peek(i=0)\t   # peek the next i-th character\n\t\t#   self.prefix(l=1)\t # peek the next l characters\n\t\t#   self.forward(l=1)\t# read the next l characters and move the pointer.\n\n\t\t# Had we reached the end of the stream?\n\t\tself.done = False\n\n\t\t# The number of unclosed '{' and '['. `flow_level == 0` means block\n\t\t# context.\n\t\tself.flow_level = 0\n\n\t\t# List of processed tokens that are not yet emitted.\n\t\tself.tokens = []\n\n\t\t# Add the STREAM-START token.\n\t\tself.fetch_stream_start()\n\n\t\t# Number of tokens that were emitted through the `get_token` method.\n\t\tself.tokens_taken = 0\n\n\t\t# The current indentation level.\n\t\tself.indent = -1\n\n\t\t# Past indentation levels.\n\t\tself.indents = []\n\n\t\t# Variables related to simple keys treatment.\n\n\t\t# A simple key is a key that is not denoted by the '?' indicator.\n\t\t# Example of simple keys:\n\t\t#   ---\n\t\t#   block simple key: value\n\t\t#   ? not a simple key:\n\t\t#   : { flow simple key: value }\n\t\t# We emit the KEY token before all keys, so when we find a potential\n\t\t# simple key, we try to locate the corresponding ':' indicator.\n\t\t# Simple keys should be limited to a single line and 1024 characters.\n\n\t\t# Can a simple key start at the current position? A simple key may\n\t\t# start:\n\t\t# - at the beginning of the line, not counting indentation spaces\n\t\t#\t   (in block context),\n\t\t# - after '{', '[', ',' (in the flow context),\n\t\t# - after '?', ':', '-' (in the block context).\n\t\t# In the block context, this flag also signifies if a block collection\n\t\t# may start at the current position.\n\t\tself.allow_simple_key = True\n\n\t\t# Keep track of possible simple keys. This is a dictionary. The key\n\t\t# is `flow_level`; there can be no more that one possible simple key\n\t\t# for each level. The value is a SimpleKey record:\n\t\t#   (token_number, required, index, line, column, mark)\n\t\t# A simple key may start with ALIAS, ANCHOR, TAG, SCALAR(flow),\n\t\t# '[', or '{' tokens.\n\t\tself.possible_simple_keys = {}\n\n\t# Public methods.\n\n\tdef check_token(self, *choices):\n\t\t# Check if the next token is one of the given types.\n\t\twhile self.need_more_tokens():\n\t\t\tself.fetch_more_tokens()\n\t\tif self.tokens:\n\t\t\tif not choices:\n\t\t\t\treturn True\n\t\t\tfor choice in choices:\n\t\t\t\tif isinstance(self.tokens[0], choice):\n\t\t\t\t\treturn True\n\t\treturn False\n\n\tdef peek_token(self):\n\t\t# Return the next token, but do not delete if from the queue.\n\t\twhile self.need_more_tokens():\n\t\t\tself.fetch_more_tokens()\n\t\tif self.tokens:\n\t\t\treturn self.tokens[0]\n\n\tdef get_token(self):\n\t\t# Return the next token.\n\t\twhile self.need_more_tokens():\n\t\t\tself.fetch_more_tokens()\n\t\tif self.tokens:\n\t\t\tself.tokens_taken += 1\n\t\t\treturn self.tokens.pop(0)\n\n\t# Private methods.\n\n\tdef need_more_tokens(self):\n\t\tif self.done:\n\t\t\treturn False\n\t\tif not self.tokens:\n\t\t\treturn True\n\t\t# The current token may be a potential simple key, so we\n\t\t# need to look further.\n\t\tself.stale_possible_simple_keys()\n\t\tif self.next_possible_simple_key() == self.tokens_taken:\n\t\t\treturn True\n\n\tdef fetch_more_tokens(self):\n\n\t\t# Eat whitespaces and comments until we reach the next token.\n\t\tself.scan_to_next_token()\n\n\t\t# Remove obsolete possible simple keys.\n\t\tself.stale_possible_simple_keys()\n\n\t\t# Compare the current indentation and column. It may add some tokens\n\t\t# and decrease the current indentation level.\n\t\tself.unwind_indent(self.column)\n\n\t\t# Peek the next character.\n\t\tch = self.peek()\n\n\t\t# Is it the end of stream?\n\t\tif ch == u'\\0':\n\t\t\treturn self.fetch_stream_end()\n\n\t\t# Is it a directive?\n\t\tif ch == u'%' and self.check_directive():\n\t\t\treturn self.fetch_directive()\n\n\t\t# Is it the document start?\n\t\tif ch == u'-' and self.check_document_start():\n\t\t\treturn self.fetch_document_start()\n\n\t\t# Is it the document end?\n\t\tif ch == u'.' and self.check_document_end():\n\t\t\treturn self.fetch_document_end()\n\n\t\t# TODO: support for BOM within a stream.\n\t\t#if ch == u'\\uFEFF':\n\t\t#\treturn self.fetch_bom()\t<-- issue BOMToken\n\n\t\t# Note: the order of the following checks is NOT significant.\n\n\t\t# Is it the flow sequence start indicator?\n\t\tif ch == u'[':\n\t\t\treturn self.fetch_flow_sequence_start()\n\n\t\t# Is it the flow mapping start indicator?\n\t\tif ch == u'{':\n\t\t\treturn self.fetch_flow_mapping_start()\n\n\t\t# Is it the flow sequence end indicator?\n\t\tif ch == u']':\n\t\t\treturn self.fetch_flow_sequence_end()\n\n\t\t# Is it the flow mapping end indicator?\n\t\tif ch == u'}':\n\t\t\treturn self.fetch_flow_mapping_end()\n\n\t\t# Is it the flow entry indicator?\n\t\tif ch == u',':\n\t\t\treturn self.fetch_flow_entry()\n\n\t\t# Is it the block entry indicator?\n\t\tif ch == u'-' and self.check_block_entry():\n\t\t\treturn self.fetch_block_entry()\n\n\t\t# Is it the key indicator?\n\t\tif ch == u'?' and self.check_key():\n\t\t\treturn self.fetch_key()\n\n\t\t# Is it the value indicator?\n\t\tif ch == u':' and self.check_value():\n\t\t\treturn self.fetch_value()\n\n\t\t# Is it an alias?\n\t\tif ch == u'*':\n\t\t\treturn self.fetch_alias()\n\n\t\t# Is it an anchor?\n\t\tif ch == u'&':\n\t\t\treturn self.fetch_anchor()\n\n\t\t# Is it a tag?\n\t\tif ch == u'!':\n\t\t\treturn self.fetch_tag()\n\n\t\t# Is it a literal scalar?\n\t\tif ch == u'|' and not self.flow_level:\n\t\t\treturn self.fetch_literal()\n\n\t\t# Is it a folded scalar?\n\t\tif ch == u'>' and not self.flow_level:\n\t\t\treturn self.fetch_folded()\n\n\t\t# Is it a single quoted scalar?\n\t\tif ch == u'\\'':\n\t\t\treturn self.fetch_single()\n\n\t\t# Is it a double quoted scalar?\n\t\tif ch == u'\\\"':\n\t\t\treturn self.fetch_double()\n\n\t\t# It must be a plain scalar then.\n\t\tif self.check_plain():\n\t\t\treturn self.fetch_plain()\n\n\t\t# No? It's an error. Let's produce a nice error message.\n\t\traise ScannerError(\"while scanning for the next token\", None,\n\t\t\t\t\"found character %r that cannot start any token\"\n\t\t\t\t% ch.encode('utf-8'), self.get_mark())\n\n\t# Simple keys treatment.\n\n\tdef next_possible_simple_key(self):\n\t\t# Return the number of the nearest possible simple key. Actually we\n\t\t# don't need to loop through the whole dictionary. We may replace it\n\t\t# with the following code:\n\t\t#   if not self.possible_simple_keys:\n\t\t#\t   return None\n\t\t#   return self.possible_simple_keys[\n\t\t#\t\t   min(self.possible_simple_keys.keys())].token_number\n\t\tmin_token_number = None\n\t\tfor level in self.possible_simple_keys:\n\t\t\tkey = self.possible_simple_keys[level]\n\t\t\tif min_token_number is None or key.token_number < min_token_number:\n\t\t\t\tmin_token_number = key.token_number\n\t\treturn min_token_number\n\n\tdef stale_possible_simple_keys(self):\n\t\t# Remove entries that are no longer possible simple keys. According to\n\t\t# the YAML specification, simple keys\n\t\t# - should be limited to a single line,\n\t\t# - should be no longer than 1024 characters.\n\t\t# Disabling this procedure will allow simple keys of any length and\n\t\t# height (may cause problems if indentation is broken though).\n\t\tfor level in self.possible_simple_keys.keys():\n\t\t\tkey = self.possible_simple_keys[level]\n\t\t\tif key.line != self.line  \\\n\t\t\t\t\tor self.index-key.index > 1024:\n\t\t\t\tif key.required:\n\t\t\t\t\traise ScannerError(\"while scanning a simple key\", key.mark,\n\t\t\t\t\t\t\t\"could not found expected ':'\", self.get_mark())\n\t\t\t\tdel self.possible_simple_keys[level]\n\n\tdef save_possible_simple_key(self):\n\t\t# The next token may start a simple key. We check if it's possible\n\t\t# and save its position. This function is called for\n\t\t#   ALIAS, ANCHOR, TAG, SCALAR(flow), '[', and '{'.\n\n\t\t# Check if a simple key is required at the current position.\n\t\trequired = not self.flow_level and self.indent == self.column\n\n\t\t# A simple key is required only if it is the first token in the current\n\t\t# line. Therefore it is always allowed.\n\t\tassert self.allow_simple_key or not required\n\n\t\t# The next token might be a simple key. Let's save it's number and\n\t\t# position.\n\t\tif self.allow_simple_key:\n\t\t\tself.remove_possible_simple_key()\n\t\t\ttoken_number = self.tokens_taken+len(self.tokens)\n\t\t\tkey = SimpleKey(token_number, required,\n\t\t\t\t\tself.index, self.line, self.column, self.get_mark())\n\t\t\tself.possible_simple_keys[self.flow_level] = key\n\n\tdef remove_possible_simple_key(self):\n\t\t# Remove the saved possible key position at the current flow level.\n\t\tif self.flow_level in self.possible_simple_keys:\n\t\t\tkey = self.possible_simple_keys[self.flow_level]\n\t\t\t\n\t\t\tif key.required:\n\t\t\t\traise ScannerError(\"while scanning a simple key\", key.mark,\n\t\t\t\t\t\t\"could not found expected ':'\", self.get_mark())\n\n\t\t\tdel self.possible_simple_keys[self.flow_level]\n\n\t# Indentation functions.\n\n\tdef unwind_indent(self, column):\n\n\t\t## In flow context, tokens should respect indentation.\n\t\t## Actually the condition should be `self.indent >= column` according to\n\t\t## the spec. But this condition will prohibit intuitively correct\n\t\t## constructions such as\n\t\t## key : {\n\t\t## }\n\t\t#if self.flow_level and self.indent > column:\n\t\t#\traise ScannerError(None, None,\n\t\t#\t\t\t\"invalid intendation or unclosed '[' or '{'\",\n\t\t#\t\t\tself.get_mark())\n\n\t\t# In the flow context, indentation is ignored. We make the scanner less\n\t\t# restrictive then specification requires.\n\t\tif self.flow_level:\n\t\t\treturn\n\n\t\t# In block context, we may need to issue the BLOCK-END tokens.\n\t\twhile self.indent > column:\n\t\t\tmark = self.get_mark()\n\t\t\tself.indent = self.indents.pop()\n\t\t\tself.tokens.append(BlockEndToken(mark, mark))\n\n\tdef add_indent(self, column):\n\t\t# Check if we need to increase indentation.\n\t\tif self.indent < column:\n\t\t\tself.indents.append(self.indent)\n\t\t\tself.indent = column\n\t\t\treturn True\n\t\treturn False\n\n\t# Fetchers.\n\n\tdef fetch_stream_start(self):\n\t\t# We always add STREAM-START as the first token and STREAM-END as the\n\t\t# last token.\n\n\t\t# Read the token.\n\t\tmark = self.get_mark()\n\t\t\n\t\t# Add STREAM-START.\n\t\tself.tokens.append(StreamStartToken(mark, mark,\n\t\t\tencoding=self.encoding))\n\t\t\n\n\tdef fetch_stream_end(self):\n\n\t\t# Set the current intendation to -1.\n\t\tself.unwind_indent(-1)\n\n\t\t# Reset simple keys.\n\t\tself.remove_possible_simple_key()\n\t\tself.allow_simple_key = False\n\t\tself.possible_simple_keys = {}\n\n\t\t# Read the token.\n\t\tmark = self.get_mark()\n\t\t\n\t\t# Add STREAM-END.\n\t\tself.tokens.append(StreamEndToken(mark, mark))\n\n\t\t# The steam is finished.\n\t\tself.done = True\n\n\tdef fetch_directive(self):\n\t\t\n\t\t# Set the current intendation to -1.\n\t\tself.unwind_indent(-1)\n\n\t\t# Reset simple keys.\n\t\tself.remove_possible_simple_key()\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add DIRECTIVE.\n\t\tself.tokens.append(self.scan_directive())\n\n\tdef fetch_document_start(self):\n\t\tself.fetch_document_indicator(DocumentStartToken)\n\n\tdef fetch_document_end(self):\n\t\tself.fetch_document_indicator(DocumentEndToken)\n\n\tdef fetch_document_indicator(self, TokenClass):\n\n\t\t# Set the current intendation to -1.\n\t\tself.unwind_indent(-1)\n\n\t\t# Reset simple keys. Note that there could not be a block collection\n\t\t# after '---'.\n\t\tself.remove_possible_simple_key()\n\t\tself.allow_simple_key = False\n\n\t\t# Add DOCUMENT-START or DOCUMENT-END.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward(3)\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(TokenClass(start_mark, end_mark))\n\n\tdef fetch_flow_sequence_start(self):\n\t\tself.fetch_flow_collection_start(FlowSequenceStartToken)\n\n\tdef fetch_flow_mapping_start(self):\n\t\tself.fetch_flow_collection_start(FlowMappingStartToken)\n\n\tdef fetch_flow_collection_start(self, TokenClass):\n\n\t\t# '[' and '{' may start a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# Increase the flow level.\n\t\tself.flow_level += 1\n\n\t\t# Simple keys are allowed after '[' and '{'.\n\t\tself.allow_simple_key = True\n\n\t\t# Add FLOW-SEQUENCE-START or FLOW-MAPPING-START.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(TokenClass(start_mark, end_mark))\n\n\tdef fetch_flow_sequence_end(self):\n\t\tself.fetch_flow_collection_end(FlowSequenceEndToken)\n\n\tdef fetch_flow_mapping_end(self):\n\t\tself.fetch_flow_collection_end(FlowMappingEndToken)\n\n\tdef fetch_flow_collection_end(self, TokenClass):\n\n\t\t# Reset possible simple key on the current level.\n\t\tself.remove_possible_simple_key()\n\n\t\t# Decrease the flow level.\n\t\tself.flow_level -= 1\n\n\t\t# No simple keys after ']' or '}'.\n\t\tself.allow_simple_key = False\n\n\t\t# Add FLOW-SEQUENCE-END or FLOW-MAPPING-END.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(TokenClass(start_mark, end_mark))\n\n\tdef fetch_flow_entry(self):\n\n\t\t# Simple keys are allowed after ','.\n\t\tself.allow_simple_key = True\n\n\t\t# Reset possible simple key on the current level.\n\t\tself.remove_possible_simple_key()\n\n\t\t# Add FLOW-ENTRY.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(FlowEntryToken(start_mark, end_mark))\n\n\tdef fetch_block_entry(self):\n\n\t\t# Block context needs additional checks.\n\t\tif not self.flow_level:\n\n\t\t\t# Are we allowed to start a new entry?\n\t\t\tif not self.allow_simple_key:\n\t\t\t\traise ScannerError(None, None,\n\t\t\t\t\t\t\"sequence entries are not allowed here\",\n\t\t\t\t\t\tself.get_mark())\n\n\t\t\t# We may need to add BLOCK-SEQUENCE-START.\n\t\t\tif self.add_indent(self.column):\n\t\t\t\tmark = self.get_mark()\n\t\t\t\tself.tokens.append(BlockSequenceStartToken(mark, mark))\n\n\t\t# It's an error for the block entry to occur in the flow context,\n\t\t# but we let the parser detect this.\n\t\telse:\n\t\t\tpass\n\n\t\t# Simple keys are allowed after '-'.\n\t\tself.allow_simple_key = True\n\n\t\t# Reset possible simple key on the current level.\n\t\tself.remove_possible_simple_key()\n\n\t\t# Add BLOCK-ENTRY.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(BlockEntryToken(start_mark, end_mark))\n\n\tdef fetch_key(self):\n\t\t\n\t\t# Block context needs additional checks.\n\t\tif not self.flow_level:\n\n\t\t\t# Are we allowed to start a key (not nessesary a simple)?\n\t\t\tif not self.allow_simple_key:\n\t\t\t\traise ScannerError(None, None,\n\t\t\t\t\t\t\"mapping keys are not allowed here\",\n\t\t\t\t\t\tself.get_mark())\n\n\t\t\t# We may need to add BLOCK-MAPPING-START.\n\t\t\tif self.add_indent(self.column):\n\t\t\t\tmark = self.get_mark()\n\t\t\t\tself.tokens.append(BlockMappingStartToken(mark, mark))\n\n\t\t# Simple keys are allowed after '?' in the block context.\n\t\tself.allow_simple_key = not self.flow_level\n\n\t\t# Reset possible simple key on the current level.\n\t\tself.remove_possible_simple_key()\n\n\t\t# Add KEY.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(KeyToken(start_mark, end_mark))\n\n\tdef fetch_value(self):\n\n\t\t# Do we determine a simple key?\n\t\tif self.flow_level in self.possible_simple_keys:\n\n\t\t\t# Add KEY.\n\t\t\tkey = self.possible_simple_keys[self.flow_level]\n\t\t\tdel self.possible_simple_keys[self.flow_level]\n\t\t\tself.tokens.insert(key.token_number-self.tokens_taken,\n\t\t\t\t\tKeyToken(key.mark, key.mark))\n\n\t\t\t# If this key starts a new block mapping, we need to add\n\t\t\t# BLOCK-MAPPING-START.\n\t\t\tif not self.flow_level:\n\t\t\t\tif self.add_indent(key.column):\n\t\t\t\t\tself.tokens.insert(key.token_number-self.tokens_taken,\n\t\t\t\t\t\t\tBlockMappingStartToken(key.mark, key.mark))\n\n\t\t\t# There cannot be two simple keys one after another.\n\t\t\tself.allow_simple_key = False\n\n\t\t# It must be a part of a complex key.\n\t\telse:\n\t\t\t\n\t\t\t# Block context needs additional checks.\n\t\t\t# (Do we really need them? They will be catched by the parser\n\t\t\t# anyway.)\n\t\t\tif not self.flow_level:\n\n\t\t\t\t# We are allowed to start a complex value if and only if\n\t\t\t\t# we can start a simple key.\n\t\t\t\tif not self.allow_simple_key:\n\t\t\t\t\traise ScannerError(None, None,\n\t\t\t\t\t\t\t\"mapping values are not allowed here\",\n\t\t\t\t\t\t\tself.get_mark())\n\n\t\t\t# If this value starts a new block mapping, we need to add\n\t\t\t# BLOCK-MAPPING-START.  It will be detected as an error later by\n\t\t\t# the parser.\n\t\t\tif not self.flow_level:\n\t\t\t\tif self.add_indent(self.column):\n\t\t\t\t\tmark = self.get_mark()\n\t\t\t\t\tself.tokens.append(BlockMappingStartToken(mark, mark))\n\n\t\t\t# Simple keys are allowed after ':' in the block context.\n\t\t\tself.allow_simple_key = not self.flow_level\n\n\t\t\t# Reset possible simple key on the current level.\n\t\t\tself.remove_possible_simple_key()\n\n\t\t# Add VALUE.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(ValueToken(start_mark, end_mark))\n\n\tdef fetch_alias(self):\n\n\t\t# ALIAS could be a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# No simple keys after ALIAS.\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add ALIAS.\n\t\tself.tokens.append(self.scan_anchor(AliasToken))\n\n\tdef fetch_anchor(self):\n\n\t\t# ANCHOR could start a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# No simple keys after ANCHOR.\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add ANCHOR.\n\t\tself.tokens.append(self.scan_anchor(AnchorToken))\n\n\tdef fetch_tag(self):\n\n\t\t# TAG could start a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# No simple keys after TAG.\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add TAG.\n\t\tself.tokens.append(self.scan_tag())\n\n\tdef fetch_literal(self):\n\t\tself.fetch_block_scalar(style='|')\n\n\tdef fetch_folded(self):\n\t\tself.fetch_block_scalar(style='>')\n\n\tdef fetch_block_scalar(self, style):\n\n\t\t# A simple key may follow a block scalar.\n\t\tself.allow_simple_key = True\n\n\t\t# Reset possible simple key on the current level.\n\t\tself.remove_possible_simple_key()\n\n\t\t# Scan and add SCALAR.\n\t\tself.tokens.append(self.scan_block_scalar(style))\n\n\tdef fetch_single(self):\n\t\tself.fetch_flow_scalar(style='\\'')\n\n\tdef fetch_double(self):\n\t\tself.fetch_flow_scalar(style='\"')\n\n\tdef fetch_flow_scalar(self, style):\n\n\t\t# A flow scalar could be a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# No simple keys after flow scalars.\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add SCALAR.\n\t\tself.tokens.append(self.scan_flow_scalar(style))\n\n\tdef fetch_plain(self):\n\n\t\t# A plain scalar could be a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# No simple keys after plain scalars. But note that `scan_plain` will\n\t\t# change this flag if the scan is finished at the beginning of the\n\t\t# line.\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add SCALAR. May change `allow_simple_key`.\n\t\tself.tokens.append(self.scan_plain())\n\n\t# Checkers.\n\n\tdef check_directive(self):\n\n\t\t# DIRECTIVE:\t\t^ '%' ...\n\t\t# The '%' indicator is already checked.\n\t\tif self.column == 0:\n\t\t\treturn True\n\n\tdef check_document_start(self):\n\n\t\t# DOCUMENT-START:   ^ '---' (' '|'\\n')\n\t\tif self.column == 0:\n\t\t\tif self.prefix(3) == u'---'  \\\n\t\t\t\t\tand self.peek(3) in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\treturn True\n\n\tdef check_document_end(self):\n\n\t\t# DOCUMENT-END:\t ^ '...' (' '|'\\n')\n\t\tif self.column == 0:\n\t\t\tif self.prefix(3) == u'...'  \\\n\t\t\t\t\tand self.peek(3) in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\treturn True\n\n\tdef check_block_entry(self):\n\n\t\t# BLOCK-ENTRY:\t  '-' (' '|'\\n')\n\t\treturn self.peek(1) in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029'\n\n\tdef check_key(self):\n\n\t\t# KEY(flow context):\t'?'\n\t\tif self.flow_level:\n\t\t\treturn True\n\n\t\t# KEY(block context):   '?' (' '|'\\n')\n\t\telse:\n\t\t\treturn self.peek(1) in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029'\n\n\tdef check_value(self):\n\n\t\t# VALUE(flow context):  ':'\n\t\tif self.flow_level:\n\t\t\treturn True\n\n\t\t# VALUE(block context): ':' (' '|'\\n')\n\t\telse:\n\t\t\treturn self.peek(1) in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029'\n\n\tdef check_plain(self):\n\n\t\t# A plain scalar may start with any non-space character except:\n\t\t#   '-', '?', ':', ',', '[', ']', '{', '}',\n\t\t#   '#', '&', '*', '!', '|', '>', '\\'', '\\\"',\n\t\t#   '%', '@', '`'.\n\t\t#\n\t\t# It may also start with\n\t\t#   '-', '?', ':'\n\t\t# if it is followed by a non-space character.\n\t\t#\n\t\t# Note that we limit the last rule to the block context (except the\n\t\t# '-' character) because we want the flow context to be space\n\t\t# independent.\n\t\tch = self.peek()\n\t\treturn ch not in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029-?:,[]{}#&*!|>\\'\\\"%@`'  \\\n\t\t\t\tor (self.peek(1) not in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029'\n\t\t\t\t\t\tand (ch == u'-' or (not self.flow_level and ch in u'?:')))\n\n\t# Scanners.\n\n\tdef scan_to_next_token(self):\n\t\t# We ignore spaces, line breaks and comments.\n\t\t# If we find a line break in the block context, we set the flag\n\t\t# `allow_simple_key` on.\n\t\t# The byte order mark is stripped if it's the first character in the\n\t\t# stream. We do not yet support BOM inside the stream as the\n\t\t# specification requires. Any such mark will be considered as a part\n\t\t# of the document.\n\t\t#\n\t\t# TODO: We need to make tab handling rules more sane. A good rule is\n\t\t#   Tabs cannot precede tokens\n\t\t#   BLOCK-SEQUENCE-START, BLOCK-MAPPING-START, BLOCK-END,\n\t\t#   KEY(block), VALUE(block), BLOCK-ENTRY\n\t\t# So the checking code is\n\t\t#   if :\n\t\t#\t   self.allow_simple_keys = False\n\t\t# We also need to add the check for `allow_simple_keys == True` to\n\t\t# `unwind_indent` before issuing BLOCK-END.\n\t\t# Scanners for block, flow, and plain scalars need to be modified.\n\n\t\tif self.index == 0 and self.peek() == u'\\uFEFF':\n\t\t\tself.forward()\n\t\tfound = False\n\t\twhile not found:\n\t\t\twhile self.peek() == u' ':\n\t\t\t\tself.forward()\n\t\t\tif self.peek() == u'#':\n\t\t\t\twhile self.peek() not in u'\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\t\tself.forward()\n\t\t\tif self.scan_line_break():\n\t\t\t\tif not self.flow_level:\n\t\t\t\t\tself.allow_simple_key = True\n\t\t\telse:\n\t\t\t\tfound = True\n\n\tdef scan_directive(self):\n\t\t# See the specification for details.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tname = self.scan_directive_name(start_mark)\n\t\tvalue = None\n\t\tif name == u'YAML':\n\t\t\tvalue = self.scan_yaml_directive_value(start_mark)\n\t\t\tend_mark = self.get_mark()\n\t\telif name == u'TAG':\n\t\t\tvalue = self.scan_tag_directive_value(start_mark)\n\t\t\tend_mark = self.get_mark()\n\t\telse:\n\t\t\tend_mark = self.get_mark()\n\t\t\twhile self.peek() not in u'\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tself.forward()\n\t\tself.scan_directive_ignored_line(start_mark)\n\t\treturn DirectiveToken(name, value, start_mark, end_mark)\n\n\tdef scan_directive_name(self, start_mark):\n\t\t# See the specification for details.\n\t\tlength = 0\n\t\tch = self.peek(length)\n\t\twhile u'0' <= ch <= u'9' or u'A' <= ch <= u'Z' or u'a' <= ch <= u'z'\t\\\n\t\t\t\tor ch in u'-_':\n\t\t\tlength += 1\n\t\t\tch = self.peek(length)\n\t\tif not length:\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected alphabetic or numeric character, but found %r\"\n\t\t\t\t\t% ch.encode('utf-8'), self.get_mark())\n\t\tvalue = self.prefix(length)\n\t\tself.forward(length)\n\t\tch = self.peek()\n\t\tif ch not in u'\\0 \\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected alphabetic or numeric character, but found %r\"\n\t\t\t\t\t% ch.encode('utf-8'), self.get_mark())\n\t\treturn value\n\n\tdef scan_yaml_directive_value(self, start_mark):\n\t\t# See the specification for details.\n\t\twhile self.peek() == u' ':\n\t\t\tself.forward()\n\t\tmajor = self.scan_yaml_directive_number(start_mark)\n\t\tif self.peek() != '.':\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected a digit or '.', but found %r\"\n\t\t\t\t\t% self.peek().encode('utf-8'),\n\t\t\t\t\tself.get_mark())\n\t\tself.forward()\n\t\tminor = self.scan_yaml_directive_number(start_mark)\n\t\tif self.peek() not in u'\\0 \\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected a digit or ' ', but found %r\"\n\t\t\t\t\t% self.peek().encode('utf-8'),\n\t\t\t\t\tself.get_mark())\n\t\treturn (major, minor)\n\n\tdef scan_yaml_directive_number(self, start_mark):\n\t\t# See the specification for details.\n\t\tch = self.peek()\n\t\tif not (u'0' <= ch <= u'9'):\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected a digit, but found %r\" % ch.encode('utf-8'),\n\t\t\t\t\tself.get_mark())\n\t\tlength = 0\n\t\twhile u'0' <= self.peek(length) <= u'9':\n\t\t\tlength += 1\n\t\tvalue = int(self.prefix(length))\n\t\tself.forward(length)\n\t\treturn value\n\n\tdef scan_tag_directive_value(self, start_mark):\n\t\t# See the specification for details.\n\t\twhile self.peek() == u' ':\n\t\t\tself.forward()\n\t\thandle = self.scan_tag_directive_handle(start_mark)\n\t\twhile self.peek() == u' ':\n\t\t\tself.forward()\n\t\tprefix = self.scan_tag_directive_prefix(start_mark)\n\t\treturn (handle, prefix)\n\n\tdef scan_tag_directive_handle(self, start_mark):\n\t\t# See the specification for details.\n\t\tvalue = self.scan_tag_handle('directive', start_mark)\n\t\tch = self.peek()\n\t\tif ch != u' ':\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected ' ', but found %r\" % ch.encode('utf-8'),\n\t\t\t\t\tself.get_mark())\n\t\treturn value\n\n\tdef scan_tag_directive_prefix(self, start_mark):\n\t\t# See the specification for details.\n\t\tvalue = self.scan_tag_uri('directive', start_mark)\n\t\tch = self.peek()\n\t\tif ch not in u'\\0 \\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected ' ', but found %r\" % ch.encode('utf-8'),\n\t\t\t\t\tself.get_mark())\n\t\treturn value\n\n\tdef scan_directive_ignored_line(self, start_mark):\n\t\t# See the specification for details.\n\t\twhile self.peek() == u' ':\n\t\t\tself.forward()\n\t\tif self.peek() == u'#':\n\t\t\twhile self.peek() not in u'\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tself.forward()\n\t\tch = self.peek()\n\t\tif ch not in u'\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected a comment or a line break, but found %r\"\n\t\t\t\t\t\t% ch.encode('utf-8'), self.get_mark())\n\t\tself.scan_line_break()\n\n\tdef scan_anchor(self, TokenClass):\n\t\t# The specification does not restrict characters for anchors and\n\t\t# aliases. This may lead to problems, for instance, the document:\n\t\t#   [ *alias, value ]\n\t\t# can be interpteted in two ways, as\n\t\t#   [ \"value\" ]\n\t\t# and\n\t\t#   [ *alias , \"value\" ]\n\t\t# Therefore we restrict aliases to numbers and ASCII letters.\n\t\tstart_mark = self.get_mark()\n\t\tindicator = self.peek()\n\t\tif indicator == u'*':\n\t\t\tname = 'alias'\n\t\telse:\n\t\t\tname = 'anchor'\n\t\tself.forward()\n\t\tlength = 0\n\t\tch = self.peek(length)\n\t\twhile u'0' <= ch <= u'9' or u'A' <= ch <= u'Z' or u'a' <= ch <= u'z'\t\\\n\t\t\t\tor ch in u'-_':\n\t\t\tlength += 1\n\t\t\tch = self.peek(length)\n\t\tif not length:\n\t\t\traise ScannerError(\"while scanning an %s\" % name, start_mark,\n\t\t\t\t\t\"expected alphabetic or numeric character, but found %r\"\n\t\t\t\t\t% ch.encode('utf-8'), self.get_mark())\n\t\tvalue = self.prefix(length)\n\t\tself.forward(length)\n\t\tch = self.peek()\n\t\tif ch not in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029?:,]}%@`':\n\t\t\traise ScannerError(\"while scanning an %s\" % name, start_mark,\n\t\t\t\t\t\"expected alphabetic or numeric character, but found %r\"\n\t\t\t\t\t% ch.encode('utf-8'), self.get_mark())\n\t\tend_mark = self.get_mark()\n\t\treturn TokenClass(value, start_mark, end_mark)\n\n\tdef scan_tag(self):\n\t\t# See the specification for details.\n\t\tstart_mark = self.get_mark()\n\t\tch = self.peek(1)\n\t\tif ch == u'<':\n\t\t\thandle = None\n\t\t\tself.forward(2)\n\t\t\tsuffix = self.scan_tag_uri('tag', start_mark)\n\t\t\tif self.peek() != u'>':\n\t\t\t\traise ScannerError(\"while parsing a tag\", start_mark,\n\t\t\t\t\t\t\"expected '>', but found %r\" % self.peek().encode('utf-8'),\n\t\t\t\t\t\tself.get_mark())\n\t\t\tself.forward()\n\t\telif ch in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\thandle = None\n\t\t\tsuffix = u'!'\n\t\t\tself.forward()\n\t\telse:\n\t\t\tlength = 1\n\t\t\tuse_handle = False\n\t\t\twhile ch not in u'\\0 \\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tif ch == u'!':\n\t\t\t\t\tuse_handle = True\n\t\t\t\t\tbreak\n\t\t\t\tlength += 1\n\t\t\t\tch = self.peek(length)\n\t\t\thandle = u'!'\n\t\t\tif use_handle:\n\t\t\t\thandle = self.scan_tag_handle('tag', start_mark)\n\t\t\telse:\n\t\t\t\thandle = u'!'\n\t\t\t\tself.forward()\n\t\t\tsuffix = self.scan_tag_uri('tag', start_mark)\n\t\tch = self.peek()\n\t\tif ch not in u'\\0 \\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a tag\", start_mark,\n\t\t\t\t\t\"expected ' ', but found %r\" % ch.encode('utf-8'),\n\t\t\t\t\tself.get_mark())\n\t\tvalue = (handle, suffix)\n\t\tend_mark = self.get_mark()\n\t\treturn TagToken(value, start_mark, end_mark)\n\n\tdef scan_block_scalar(self, style):\n\t\t# See the specification for details.\n\n\t\tif style == '>':\n\t\t\tfolded = True\n\t\telse:\n\t\t\tfolded = False\n\n\t\tchunks = []\n\t\tstart_mark = self.get_mark()\n\n\t\t# Scan the header.\n\t\tself.forward()\n\t\tchomping, increment = self.scan_block_scalar_indicators(start_mark)\n\t\tself.scan_block_scalar_ignored_line(start_mark)\n\n\t\t# Determine the indentation level and go to the first non-empty line.\n\t\tmin_indent = self.indent+1\n\t\tif min_indent < 1:\n\t\t\tmin_indent = 1\n\t\tif increment is None:\n\t\t\tbreaks, max_indent, end_mark = self.scan_block_scalar_indentation()\n\t\t\tindent = max(min_indent, max_indent)\n\t\telse:\n\t\t\tindent = min_indent+increment-1\n\t\t\tbreaks, end_mark = self.scan_block_scalar_breaks(indent)\n\t\tline_break = u''\n\n\t\t# Scan the inner part of the block scalar.\n\t\twhile self.column == indent and self.peek() != u'\\0':\n\t\t\tchunks.extend(breaks)\n\t\t\tleading_non_space = self.peek() not in u' \\t'\n\t\t\tlength = 0\n\t\t\twhile self.peek(length) not in u'\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tlength += 1\n\t\t\tchunks.append(self.prefix(length))\n\t\t\tself.forward(length)\n\t\t\tline_break = self.scan_line_break()\n\t\t\tbreaks, end_mark = self.scan_block_scalar_breaks(indent)\n\t\t\tif self.column == indent and self.peek() != u'\\0':\n\n\t\t\t\t# Unfortunately, folding rules are ambiguous.\n\t\t\t\t#\n\t\t\t\t# This is the folding according to the specification:\n\t\t\t\t\n\t\t\t\tif folded and line_break == u'\\n'   \\\n\t\t\t\t\t\tand leading_non_space and self.peek() not in u' \\t':\n\t\t\t\t\tif not breaks:\n\t\t\t\t\t\tchunks.append(u' ')\n\t\t\t\telse:\n\t\t\t\t\tchunks.append(line_break)\n\t\t\t\t\n\t\t\t\t# This is Clark Evans's interpretation (also in the spec\n\t\t\t\t# examples):\n\t\t\t\t#\n\t\t\t\t#if folded and line_break == u'\\n':\n\t\t\t\t#\tif not breaks:\n\t\t\t\t#\t\tif self.peek() not in ' \\t':\n\t\t\t\t#\t\t\tchunks.append(u' ')\n\t\t\t\t#\t\telse:\n\t\t\t\t#\t\t\tchunks.append(line_break)\n\t\t\t\t#else:\n\t\t\t\t#\tchunks.append(line_break)\n\t\t\telse:\n\t\t\t\tbreak\n\n\t\t# Chomp the tail.\n\t\tif chomping is not False:\n\t\t\tchunks.append(line_break)\n\t\tif chomping is True:\n\t\t\tchunks.extend(breaks)\n\n\t\t# We are done.\n\t\treturn ScalarToken(u''.join(chunks), False, start_mark, end_mark,\n\t\t\t\tstyle)\n\n\tdef scan_block_scalar_indicators(self, start_mark):\n\t\t# See the specification for details.\n\t\tchomping = None\n\t\tincrement = None\n\t\tch = self.peek()\n\t\tif ch in u'+-':\n\t\t\tif ch == '+':\n\t\t\t\tchomping = True\n\t\t\telse:\n\t\t\t\tchomping = False\n\t\t\tself.forward()\n\t\t\tch = self.peek()\n\t\t\tif ch in u'0123456789':\n\t\t\t\tincrement = int(ch)\n\t\t\t\tif increment == 0:\n\t\t\t\t\traise ScannerError(\"while scanning a block scalar\", start_mark,\n\t\t\t\t\t\t\t\"expected indentation indicator in the range 1-9, but found 0\",\n\t\t\t\t\t\t\tself.get_mark())\n\t\t\t\tself.forward()\n\t\telif ch in u'0123456789':\n\t\t\tincrement = int(ch)\n\t\t\tif increment == 0:\n\t\t\t\traise ScannerError(\"while scanning a block scalar\", start_mark,\n\t\t\t\t\t\t\"expected indentation indicator in the range 1-9, but found 0\",\n\t\t\t\t\t\tself.get_mark())\n\t\t\tself.forward()\n\t\t\tch = self.peek()\n\t\t\tif ch in u'+-':\n\t\t\t\tif ch == '+':\n\t\t\t\t\tchomping = True\n\t\t\t\telse:\n\t\t\t\t\tchomping = False\n\t\t\t\tself.forward()\n\t\tch = self.peek()\n\t\tif ch not in u'\\0 \\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a block scalar\", start_mark,\n\t\t\t\t\t\"expected chomping or indentation indicators, but found %r\"\n\t\t\t\t\t\t% ch.encode('utf-8'), self.get_mark())\n\t\treturn chomping, increment\n\n\tdef scan_block_scalar_ignored_line(self, start_mark):\n\t\t# See the specification for details.\n\t\twhile self.peek() == u' ':\n\t\t\tself.forward()\n\t\tif self.peek() == u'#':\n\t\t\twhile self.peek() not in u'\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tself.forward()\n\t\tch = self.peek()\n\t\tif ch not in u'\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a block scalar\", start_mark,\n\t\t\t\t\t\"expected a comment or a line break, but found %r\"\n\t\t\t\t\t\t% ch.encode('utf-8'), self.get_mark())\n\t\tself.scan_line_break()\n\n\tdef scan_block_scalar_indentation(self):\n\t\t# See the specification for details.\n\t\tchunks = []\n\t\tmax_indent = 0\n\t\tend_mark = self.get_mark()\n\t\twhile self.peek() in u' \\r\\n\\x85\\u2028\\u2029':\n\t\t\tif self.peek() != u' ':\n\t\t\t\tchunks.append(self.scan_line_break())\n\t\t\t\tend_mark = self.get_mark()\n\t\t\telse:\n\t\t\t\tself.forward()\n\t\t\t\tif self.column > max_indent:\n\t\t\t\t\tmax_indent = self.column\n\t\treturn chunks, max_indent, end_mark\n\n\tdef scan_block_scalar_breaks(self, indent):\n\t\t# See the specification for details.\n\t\tchunks = []\n\t\tend_mark = self.get_mark()\n\t\twhile self.column < indent and self.peek() == u' ':\n\t\t\tself.forward()\n\t\twhile self.peek() in u'\\r\\n\\x85\\u2028\\u2029':\n\t\t\tchunks.append(self.scan_line_break())\n\t\t\tend_mark = self.get_mark()\n\t\t\twhile self.column < indent and self.peek() == u' ':\n\t\t\t\tself.forward()\n\t\treturn chunks, end_mark\n\n\tdef scan_flow_scalar(self, style):\n\t\t# See the specification for details.\n\t\t# Note that we loose indentation rules for quoted scalars. Quoted\n\t\t# scalars don't need to adhere indentation because \" and ' clearly\n\t\t# mark the beginning and the end of them. Therefore we are less\n\t\t# restrictive then the specification requires. We only need to check\n\t\t# that document separators are not included in scalars.\n\t\tif style == '\"':\n\t\t\tdouble = True\n\t\telse:\n\t\t\tdouble = False\n\t\tchunks = []\n\t\tstart_mark = self.get_mark()\n\t\tquote = self.peek()\n\t\tself.forward()\n\t\tchunks.extend(self.scan_flow_scalar_non_spaces(double, start_mark))\n\t\twhile self.peek() != quote:\n\t\t\tchunks.extend(self.scan_flow_scalar_spaces(double, start_mark))\n\t\t\tchunks.extend(self.scan_flow_scalar_non_spaces(double, start_mark))\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\treturn ScalarToken(u''.join(chunks), False, start_mark, end_mark,\n\t\t\t\tstyle)\n\n\tESCAPE_REPLACEMENTS = {\n\t\tu'0':   u'\\0',\n\t\tu'a':   u'\\x07',\n\t\tu'b':   u'\\x08',\n\t\tu't':   u'\\x09',\n\t\tu'\\t':  u'\\x09',\n\t\tu'n':   u'\\x0A',\n\t\tu'v':   u'\\x0B',\n\t\tu'f':   u'\\x0C',\n\t\tu'r':   u'\\x0D',\n\t\tu'e':   u'\\x1B',\n\t\tu' ':   u'\\x20',\n\t\tu'\\\"':  u'\\\"',\n\t\tu'\\\\':  u'\\\\',\n\t\tu'N':   u'\\x85',\n\t\tu'_':   u'\\xA0',\n\t\tu'L':   u'\\u2028',\n\t\tu'P':   u'\\u2029',\n\t}\n\n\tESCAPE_CODES = {\n\t\tu'x':   2,\n\t\tu'u':   4,\n\t\tu'U':   8,\n\t}\n\n\tdef scan_flow_scalar_non_spaces(self, double, start_mark):\n\t\t# See the specification for details.\n\t\tchunks = []\n\t\twhile True:\n\t\t\tlength = 0\n\t\t\twhile self.peek(length) not in u'\\'\\\"\\\\\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tlength += 1\n\t\t\tif length:\n\t\t\t\tchunks.append(self.prefix(length))\n\t\t\t\tself.forward(length)\n\t\t\tch = self.peek()\n\t\t\tif not double and ch == u'\\'' and self.peek(1) == u'\\'':\n\t\t\t\tchunks.append(u'\\'')\n\t\t\t\tself.forward(2)\n\t\t\telif (double and ch == u'\\'') or (not double and ch in u'\\\"\\\\'):\n\t\t\t\tchunks.append(ch)\n\t\t\t\tself.forward()\n\t\t\telif double and ch == u'\\\\':\n\t\t\t\tself.forward()\n\t\t\t\tch = self.peek()\n\t\t\t\tif ch in self.ESCAPE_REPLACEMENTS:\n\t\t\t\t\tchunks.append(self.ESCAPE_REPLACEMENTS[ch])\n\t\t\t\t\tself.forward()\n\t\t\t\telif ch in self.ESCAPE_CODES:\n\t\t\t\t\tlength = self.ESCAPE_CODES[ch]\n\t\t\t\t\tself.forward()\n\t\t\t\t\tfor k in range(length):\n\t\t\t\t\t\tif self.peek(k) not in u'0123456789ABCDEFabcdef':\n\t\t\t\t\t\t\traise ScannerError(\"while scanning a double-quoted scalar\", start_mark,\n\t\t\t\t\t\t\t\t\t\"expected escape sequence of %d hexdecimal numbers, but found %r\" %\n\t\t\t\t\t\t\t\t\t\t(length, self.peek(k).encode('utf-8')), self.get_mark())\n\t\t\t\t\tcode = int(self.prefix(length), 16)\n\t\t\t\t\tchunks.append(unichr(code))\n\t\t\t\t\tself.forward(length)\n\t\t\t\telif ch in u'\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\t\tself.scan_line_break()\n\t\t\t\t\tchunks.extend(self.scan_flow_scalar_breaks(double, start_mark))\n\t\t\t\telse:\n\t\t\t\t\traise ScannerError(\"while scanning a double-quoted scalar\", start_mark,\n\t\t\t\t\t\t\t\"found unknown escape character %r\" % ch.encode('utf-8'), self.get_mark())\n\t\t\telse:\n\t\t\t\treturn chunks\n\n\tdef scan_flow_scalar_spaces(self, double, start_mark):\n\t\t# See the specification for details.\n\t\tchunks = []\n\t\tlength = 0\n\t\twhile self.peek(length) in u' \\t':\n\t\t\tlength += 1\n\t\twhitespaces = self.prefix(length)\n\t\tself.forward(length)\n\t\tch = self.peek()\n\t\tif ch == u'\\0':\n\t\t\traise ScannerError(\"while scanning a quoted scalar\", start_mark,\n\t\t\t\t\t\"found unexpected end of stream\", self.get_mark())\n\t\telif ch in u'\\r\\n\\x85\\u2028\\u2029':\n\t\t\tline_break = self.scan_line_break()\n\t\t\tbreaks = self.scan_flow_scalar_breaks(double, start_mark)\n\t\t\tif line_break != u'\\n':\n\t\t\t\tchunks.append(line_break)\n\t\t\telif not breaks:\n\t\t\t\tchunks.append(u' ')\n\t\t\tchunks.extend(breaks)\n\t\telse:\n\t\t\tchunks.append(whitespaces)\n\t\treturn chunks\n\n\tdef scan_flow_scalar_breaks(self, double, start_mark):\n\t\t# See the specification for details.\n\t\tchunks = []\n\t\twhile True:\n\t\t\t# Instead of checking indentation, we check for document\n\t\t\t# separators.\n\t\t\tprefix = self.prefix(3)\n\t\t\tif (prefix == u'---' or prefix == u'...')   \\\n\t\t\t\t\tand self.peek(3) in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\traise ScannerError(\"while scanning a quoted scalar\", start_mark,\n\t\t\t\t\t\t\"found unexpected document separator\", self.get_mark())\n\t\t\twhile self.peek() in u' \\t':\n\t\t\t\tself.forward()\n\t\t\tif self.peek() in u'\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tchunks.append(self.scan_line_break())\n\t\t\telse:\n\t\t\t\treturn chunks\n\n\tdef scan_plain(self):\n\t\t# See the specification for details.\n\t\t# We add an additional restriction for the flow context:\n\t\t#   plain scalars in the flow context cannot contain ',', ':' and '?'.\n\t\t# We also keep track of the `allow_simple_key` flag here.\n\t\t# Indentation rules are loosed for the flow context.\n\t\tchunks = []\n\t\tstart_mark = self.get_mark()\n\t\tend_mark = start_mark\n\t\tindent = self.indent+1\n\t\t# We allow zero indentation for scalars, but then we need to check for\n\t\t# document separators at the beginning of the line.\n\t\t#if indent == 0:\n\t\t#\tindent = 1\n\t\tspaces = []\n\t\twhile True:\n\t\t\tlength = 0\n\t\t\tif self.peek() == u'#':\n\t\t\t\tbreak\n\t\t\twhile True:\n\t\t\t\tch = self.peek(length)\n\t\t\t\tif ch in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029'   \\\n\t\t\t\t\t\tor (not self.flow_level and ch == u':' and\n\t\t\t\t\t\t\t\tself.peek(length+1) in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029') \\\n\t\t\t\t\t\tor (self.flow_level and ch in u',:?[]{}'):\n\t\t\t\t\tbreak\n\t\t\t\tlength += 1\n\t\t\t# It's not clear what we should do with ':' in the flow context.\n\t\t\tif (self.flow_level and ch == u':'\n\t\t\t\t\tand self.peek(length+1) not in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029,[]{}'):\n\t\t\t\tself.forward(length)\n\t\t\t\traise ScannerError(\"while scanning a plain scalar\", start_mark,\n\t\t\t\t\t\"found unexpected ':'\", self.get_mark(),\n\t\t\t\t\t\"Please check http://pyyaml.org/wiki/YAMLColonInFlowContext for details.\")\n\t\t\tif length == 0:\n\t\t\t\tbreak\n\t\t\tself.allow_simple_key = False\n\t\t\tchunks.extend(spaces)\n\t\t\tchunks.append(self.prefix(length))\n\t\t\tself.forward(length)\n\t\t\tend_mark = self.get_mark()\n\t\t\tspaces = self.scan_plain_spaces(indent, start_mark)\n\t\t\tif not spaces or self.peek() == u'#' \\\n\t\t\t\t\tor (not self.flow_level and self.column < indent):\n\t\t\t\tbreak\n\t\treturn ScalarToken(u''.join(chunks), True, start_mark, end_mark)\n\n\tdef scan_plain_spaces(self, indent, start_mark):\n\t\t# See the specification for details.\n\t\t# The specification is really confusing about tabs in plain scalars.\n\t\t# We just forbid them completely. Do not use tabs in YAML!\n\t\tchunks = []\n\t\tlength = 0\n\t\twhile self.peek(length) in u' ':\n\t\t\tlength += 1\n\t\twhitespaces = self.prefix(length)\n\t\tself.forward(length)\n\t\tch = self.peek()\n\t\tif ch in u'\\r\\n\\x85\\u2028\\u2029':\n\t\t\tline_break = self.scan_line_break()\n\t\t\tself.allow_simple_key = True\n\t\t\tprefix = self.prefix(3)\n\t\t\tif (prefix == u'---' or prefix == u'...')   \\\n\t\t\t\t\tand self.peek(3) in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\treturn\n\t\t\tbreaks = []\n\t\t\twhile self.peek() in u' \\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tif self.peek() == ' ':\n\t\t\t\t\tself.forward()\n\t\t\t\telse:\n\t\t\t\t\tbreaks.append(self.scan_line_break())\n\t\t\t\t\tprefix = self.prefix(3)\n\t\t\t\t\tif (prefix == u'---' or prefix == u'...')   \\\n\t\t\t\t\t\t\tand self.peek(3) in u'\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\t\t\treturn\n\t\t\tif line_break != u'\\n':\n\t\t\t\tchunks.append(line_break)\n\t\t\telif not breaks:\n\t\t\t\tchunks.append(u' ')\n\t\t\tchunks.extend(breaks)\n\t\telif whitespaces:\n\t\t\tchunks.append(whitespaces)\n\t\treturn chunks\n\n\tdef scan_tag_handle(self, name, start_mark):\n\t\t# See the specification for details.\n\t\t# For some strange reasons, the specification does not allow '_' in\n\t\t# tag handles. I have allowed it anyway.\n\t\tch = self.peek()\n\t\tif ch != u'!':\n\t\t\traise ScannerError(\"while scanning a %s\" % name, start_mark,\n\t\t\t\t\t\"expected '!', but found %r\" % ch.encode('utf-8'),\n\t\t\t\t\tself.get_mark())\n\t\tlength = 1\n\t\tch = self.peek(length)\n\t\tif ch != u' ':\n\t\t\twhile u'0' <= ch <= u'9' or u'A' <= ch <= u'Z' or u'a' <= ch <= u'z'\t\\\n\t\t\t\t\tor ch in u'-_':\n\t\t\t\tlength += 1\n\t\t\t\tch = self.peek(length)\n\t\t\tif ch != u'!':\n\t\t\t\tself.forward(length)\n\t\t\t\traise ScannerError(\"while scanning a %s\" % name, start_mark,\n\t\t\t\t\t\t\"expected '!', but found %r\" % ch.encode('utf-8'),\n\t\t\t\t\t\tself.get_mark())\n\t\t\tlength += 1\n\t\tvalue = self.prefix(length)\n\t\tself.forward(length)\n\t\treturn value\n\n\tdef scan_tag_uri(self, name, start_mark):\n\t\t# See the specification for details.\n\t\t# Note: we do not check if URI is well-formed.\n\t\tchunks = []\n\t\tlength = 0\n\t\tch = self.peek(length)\n\t\twhile u'0' <= ch <= u'9' or u'A' <= ch <= u'Z' or u'a' <= ch <= u'z'\t\\\n\t\t\t\tor ch in u'-;/?:@&=+$,_.!~*\\'()[]%':\n\t\t\tif ch == u'%':\n\t\t\t\tchunks.append(self.prefix(length))\n\t\t\t\tself.forward(length)\n\t\t\t\tlength = 0\n\t\t\t\tchunks.append(self.scan_uri_escapes(name, start_mark))\n\t\t\telse:\n\t\t\t\tlength += 1\n\t\t\tch = self.peek(length)\n\t\tif length:\n\t\t\tchunks.append(self.prefix(length))\n\t\t\tself.forward(length)\n\t\t\tlength = 0\n\t\tif not chunks:\n\t\t\traise ScannerError(\"while parsing a %s\" % name, start_mark,\n\t\t\t\t\t\"expected URI, but found %r\" % ch.encode('utf-8'),\n\t\t\t\t\tself.get_mark())\n\t\treturn u''.join(chunks)\n\n\tdef scan_uri_escapes(self, name, start_mark):\n\t\t# See the specification for details.\n\t\tbytes = []\n\t\tmark = self.get_mark()\n\t\twhile self.peek() == u'%':\n\t\t\tself.forward()\n\t\t\tfor k in range(2):\n\t\t\t\tif self.peek(k) not in u'0123456789ABCDEFabcdef':\n\t\t\t\t\traise ScannerError(\"while scanning a %s\" % name, start_mark,\n\t\t\t\t\t\t\t\"expected URI escape sequence of 2 hexdecimal numbers, but found %r\" %\n\t\t\t\t\t\t\t\t(self.peek(k).encode('utf-8')), self.get_mark())\n\t\t\tbytes.append(chr(int(self.prefix(2), 16)))\n\t\t\tself.forward(2)\n\t\ttry:\n\t\t\tvalue = unicode(''.join(bytes), 'utf-8')\n\t\texcept UnicodeDecodeError, exc:\n\t\t\traise ScannerError(\"while scanning a %s\" % name, start_mark, str(exc), mark)\n\t\treturn value\n\n\tdef scan_line_break(self):\n\t\t# Transforms:\n\t\t#   '\\r\\n'\t  :   '\\n'\n\t\t#   '\\r'\t\t:   '\\n'\n\t\t#   '\\n'\t\t:   '\\n'\n\t\t#   '\\x85'\t  :   '\\n'\n\t\t#   '\\u2028'\t:   '\\u2028'\n\t\t#   '\\u2029\t :   '\\u2029'\n\t\t#   default\t :   ''\n\t\tch = self.peek()\n\t\tif ch in u'\\r\\n\\x85':\n\t\t\tif self.prefix(2) == u'\\r\\n':\n\t\t\t\tself.forward(2)\n\t\t\telse:\n\t\t\t\tself.forward()\n\t\t\treturn u'\\n'\n\t\telif ch in u'\\u2028\\u2029':\n\t\t\tself.forward()\n\t\t\treturn ch\n\t\treturn u''\n", "description": "Initialize the scanner.", "category": "simple", "imports": ["from error import MarkedYAMLError", "from tokens import *", "#\timport psyco"]}], [{"term": "class", "name": "ScannerError", "data": "class ScannerError(MarkedYAMLError):\n\tpass\n", "description": null, "category": "simple", "imports": ["from .error import MarkedYAMLError", "from .tokens import *", "#\timport psyco"]}, {"term": "class", "name": "classSimpleKey:", "data": "class SimpleKey:\n\t# See below simple keys treatment.\n\n\tdef __init__(self, token_number, required, index, line, column, mark):\n\t\tself.token_number = token_number\n\t\tself.required = required\n\t\tself.index = index\n\t\tself.line = line\n\t\tself.column = column\n\t\tself.mark = mark\n", "description": null, "category": "simple", "imports": ["from .error import MarkedYAMLError", "from .tokens import *", "#\timport psyco"]}, {"term": "class", "name": "classScanner:", "data": "class Scanner:\n\n\tdef __init__(self):\n\t\t\"\"\"Initialize the scanner.\"\"\"\n\t\t# It is assumed that Scanner and Reader will have a common descendant.\n\t\t# Reader do the dirty work of checking for BOM and converting the\n\t\t# input data to Unicode. It also adds NUL to the end.\n\t\t#\n\t\t# Reader supports the following methods\n\t\t#   self.peek(i=0)\t   # peek the next i-th character\n\t\t#   self.prefix(l=1)\t # peek the next l characters\n\t\t#   self.forward(l=1)\t# read the next l characters and move the pointer.\n\n\t\t# Had we reached the end of the stream?\n\t\tself.done = False\n\n\t\t# The number of unclosed '{' and '['. `flow_level == 0` means block\n\t\t# context.\n\t\tself.flow_level = 0\n\n\t\t# List of processed tokens that are not yet emitted.\n\t\tself.tokens = []\n\n\t\t# Add the STREAM-START token.\n\t\tself.fetch_stream_start()\n\n\t\t# Number of tokens that were emitted through the `get_token` method.\n\t\tself.tokens_taken = 0\n\n\t\t# The current indentation level.\n\t\tself.indent = -1\n\n\t\t# Past indentation levels.\n\t\tself.indents = []\n\n\t\t# Variables related to simple keys treatment.\n\n\t\t# A simple key is a key that is not denoted by the '?' indicator.\n\t\t# Example of simple keys:\n\t\t#   ---\n\t\t#   block simple key: value\n\t\t#   ? not a simple key:\n\t\t#   : { flow simple key: value }\n\t\t# We emit the KEY token before all keys, so when we find a potential\n\t\t# simple key, we try to locate the corresponding ':' indicator.\n\t\t# Simple keys should be limited to a single line and 1024 characters.\n\n\t\t# Can a simple key start at the current position? A simple key may\n\t\t# start:\n\t\t# - at the beginning of the line, not counting indentation spaces\n\t\t#\t   (in block context),\n\t\t# - after '{', '[', ',' (in the flow context),\n\t\t# - after '?', ':', '-' (in the block context).\n\t\t# In the block context, this flag also signifies if a block collection\n\t\t# may start at the current position.\n\t\tself.allow_simple_key = True\n\n\t\t# Keep track of possible simple keys. This is a dictionary. The key\n\t\t# is `flow_level`; there can be no more that one possible simple key\n\t\t# for each level. The value is a SimpleKey record:\n\t\t#   (token_number, required, index, line, column, mark)\n\t\t# A simple key may start with ALIAS, ANCHOR, TAG, SCALAR(flow),\n\t\t# '[', or '{' tokens.\n\t\tself.possible_simple_keys = {}\n\n\t# Public methods.\n\n\tdef check_token(self, *choices):\n\t\t# Check if the next token is one of the given types.\n\t\twhile self.need_more_tokens():\n\t\t\tself.fetch_more_tokens()\n\t\tif self.tokens:\n\t\t\tif not choices:\n\t\t\t\treturn True\n\t\t\tfor choice in choices:\n\t\t\t\tif isinstance(self.tokens[0], choice):\n\t\t\t\t\treturn True\n\t\treturn False\n\n\tdef peek_token(self):\n\t\t# Return the next token, but do not delete if from the queue.\n\t\twhile self.need_more_tokens():\n\t\t\tself.fetch_more_tokens()\n\t\tif self.tokens:\n\t\t\treturn self.tokens[0]\n\n\tdef get_token(self):\n\t\t# Return the next token.\n\t\twhile self.need_more_tokens():\n\t\t\tself.fetch_more_tokens()\n\t\tif self.tokens:\n\t\t\tself.tokens_taken += 1\n\t\t\treturn self.tokens.pop(0)\n\n\t# Private methods.\n\n\tdef need_more_tokens(self):\n\t\tif self.done:\n\t\t\treturn False\n\t\tif not self.tokens:\n\t\t\treturn True\n\t\t# The current token may be a potential simple key, so we\n\t\t# need to look further.\n\t\tself.stale_possible_simple_keys()\n\t\tif self.next_possible_simple_key() == self.tokens_taken:\n\t\t\treturn True\n\n\tdef fetch_more_tokens(self):\n\n\t\t# Eat whitespaces and comments until we reach the next token.\n\t\tself.scan_to_next_token()\n\n\t\t# Remove obsolete possible simple keys.\n\t\tself.stale_possible_simple_keys()\n\n\t\t# Compare the current indentation and column. It may add some tokens\n\t\t# and decrease the current indentation level.\n\t\tself.unwind_indent(self.column)\n\n\t\t# Peek the next character.\n\t\tch = self.peek()\n\n\t\t# Is it the end of stream?\n\t\tif ch == '\\0':\n\t\t\treturn self.fetch_stream_end()\n\n\t\t# Is it a directive?\n\t\tif ch == '%' and self.check_directive():\n\t\t\treturn self.fetch_directive()\n\n\t\t# Is it the document start?\n\t\tif ch == '-' and self.check_document_start():\n\t\t\treturn self.fetch_document_start()\n\n\t\t# Is it the document end?\n\t\tif ch == '.' and self.check_document_end():\n\t\t\treturn self.fetch_document_end()\n\n\t\t# TODO: support for BOM within a stream.\n\t\t#if ch == '\\uFEFF':\n\t\t#\treturn self.fetch_bom()\t<-- issue BOMToken\n\n\t\t# Note: the order of the following checks is NOT significant.\n\n\t\t# Is it the flow sequence start indicator?\n\t\tif ch == '[':\n\t\t\treturn self.fetch_flow_sequence_start()\n\n\t\t# Is it the flow mapping start indicator?\n\t\tif ch == '{':\n\t\t\treturn self.fetch_flow_mapping_start()\n\n\t\t# Is it the flow sequence end indicator?\n\t\tif ch == ']':\n\t\t\treturn self.fetch_flow_sequence_end()\n\n\t\t# Is it the flow mapping end indicator?\n\t\tif ch == '}':\n\t\t\treturn self.fetch_flow_mapping_end()\n\n\t\t# Is it the flow entry indicator?\n\t\tif ch == ',':\n\t\t\treturn self.fetch_flow_entry()\n\n\t\t# Is it the block entry indicator?\n\t\tif ch == '-' and self.check_block_entry():\n\t\t\treturn self.fetch_block_entry()\n\n\t\t# Is it the key indicator?\n\t\tif ch == '?' and self.check_key():\n\t\t\treturn self.fetch_key()\n\n\t\t# Is it the value indicator?\n\t\tif ch == ':' and self.check_value():\n\t\t\treturn self.fetch_value()\n\n\t\t# Is it an alias?\n\t\tif ch == '*':\n\t\t\treturn self.fetch_alias()\n\n\t\t# Is it an anchor?\n\t\tif ch == '&':\n\t\t\treturn self.fetch_anchor()\n\n\t\t# Is it a tag?\n\t\tif ch == '!':\n\t\t\treturn self.fetch_tag()\n\n\t\t# Is it a literal scalar?\n\t\tif ch == '|' and not self.flow_level:\n\t\t\treturn self.fetch_literal()\n\n\t\t# Is it a folded scalar?\n\t\tif ch == '>' and not self.flow_level:\n\t\t\treturn self.fetch_folded()\n\n\t\t# Is it a single quoted scalar?\n\t\tif ch == '\\'':\n\t\t\treturn self.fetch_single()\n\n\t\t# Is it a double quoted scalar?\n\t\tif ch == '\\\"':\n\t\t\treturn self.fetch_double()\n\n\t\t# It must be a plain scalar then.\n\t\tif self.check_plain():\n\t\t\treturn self.fetch_plain()\n\n\t\t# No? It's an error. Let's produce a nice error message.\n\t\traise ScannerError(\"while scanning for the next token\", None,\n\t\t\t\t\"found character %r that cannot start any token\" % ch,\n\t\t\t\tself.get_mark())\n\n\t# Simple keys treatment.\n\n\tdef next_possible_simple_key(self):\n\t\t# Return the number of the nearest possible simple key. Actually we\n\t\t# don't need to loop through the whole dictionary. We may replace it\n\t\t# with the following code:\n\t\t#   if not self.possible_simple_keys:\n\t\t#\t   return None\n\t\t#   return self.possible_simple_keys[\n\t\t#\t\t   min(self.possible_simple_keys.keys())].token_number\n\t\tmin_token_number = None\n\t\tfor level in self.possible_simple_keys:\n\t\t\tkey = self.possible_simple_keys[level]\n\t\t\tif min_token_number is None or key.token_number < min_token_number:\n\t\t\t\tmin_token_number = key.token_number\n\t\treturn min_token_number\n\n\tdef stale_possible_simple_keys(self):\n\t\t# Remove entries that are no longer possible simple keys. According to\n\t\t# the YAML specification, simple keys\n\t\t# - should be limited to a single line,\n\t\t# - should be no longer than 1024 characters.\n\t\t# Disabling this procedure will allow simple keys of any length and\n\t\t# height (may cause problems if indentation is broken though).\n\t\tfor level in list(self.possible_simple_keys):\n\t\t\tkey = self.possible_simple_keys[level]\n\t\t\tif key.line != self.line  \\\n\t\t\t\t\tor self.index-key.index > 1024:\n\t\t\t\tif key.required:\n\t\t\t\t\traise ScannerError(\"while scanning a simple key\", key.mark,\n\t\t\t\t\t\t\t\"could not found expected ':'\", self.get_mark())\n\t\t\t\tdel self.possible_simple_keys[level]\n\n\tdef save_possible_simple_key(self):\n\t\t# The next token may start a simple key. We check if it's possible\n\t\t# and save its position. This function is called for\n\t\t#   ALIAS, ANCHOR, TAG, SCALAR(flow), '[', and '{'.\n\n\t\t# Check if a simple key is required at the current position.\n\t\trequired = not self.flow_level and self.indent == self.column\n\n\t\t# A simple key is required only if it is the first token in the current\n\t\t# line. Therefore it is always allowed.\n\t\tassert self.allow_simple_key or not required\n\n\t\t# The next token might be a simple key. Let's save it's number and\n\t\t# position.\n\t\tif self.allow_simple_key:\n\t\t\tself.remove_possible_simple_key()\n\t\t\ttoken_number = self.tokens_taken+len(self.tokens)\n\t\t\tkey = SimpleKey(token_number, required,\n\t\t\t\t\tself.index, self.line, self.column, self.get_mark())\n\t\t\tself.possible_simple_keys[self.flow_level] = key\n\n\tdef remove_possible_simple_key(self):\n\t\t# Remove the saved possible key position at the current flow level.\n\t\tif self.flow_level in self.possible_simple_keys:\n\t\t\tkey = self.possible_simple_keys[self.flow_level]\n\t\t\t\n\t\t\tif key.required:\n\t\t\t\traise ScannerError(\"while scanning a simple key\", key.mark,\n\t\t\t\t\t\t\"could not found expected ':'\", self.get_mark())\n\n\t\t\tdel self.possible_simple_keys[self.flow_level]\n\n\t# Indentation functions.\n\n\tdef unwind_indent(self, column):\n\n\t\t## In flow context, tokens should respect indentation.\n\t\t## Actually the condition should be `self.indent >= column` according to\n\t\t## the spec. But this condition will prohibit intuitively correct\n\t\t## constructions such as\n\t\t## key : {\n\t\t## }\n\t\t#if self.flow_level and self.indent > column:\n\t\t#\traise ScannerError(None, None,\n\t\t#\t\t\t\"invalid intendation or unclosed '[' or '{'\",\n\t\t#\t\t\tself.get_mark())\n\n\t\t# In the flow context, indentation is ignored. We make the scanner less\n\t\t# restrictive then specification requires.\n\t\tif self.flow_level:\n\t\t\treturn\n\n\t\t# In block context, we may need to issue the BLOCK-END tokens.\n\t\twhile self.indent > column:\n\t\t\tmark = self.get_mark()\n\t\t\tself.indent = self.indents.pop()\n\t\t\tself.tokens.append(BlockEndToken(mark, mark))\n\n\tdef add_indent(self, column):\n\t\t# Check if we need to increase indentation.\n\t\tif self.indent < column:\n\t\t\tself.indents.append(self.indent)\n\t\t\tself.indent = column\n\t\t\treturn True\n\t\treturn False\n\n\t# Fetchers.\n\n\tdef fetch_stream_start(self):\n\t\t# We always add STREAM-START as the first token and STREAM-END as the\n\t\t# last token.\n\n\t\t# Read the token.\n\t\tmark = self.get_mark()\n\t\t\n\t\t# Add STREAM-START.\n\t\tself.tokens.append(StreamStartToken(mark, mark,\n\t\t\tencoding=self.encoding))\n\t\t\n\n\tdef fetch_stream_end(self):\n\n\t\t# Set the current intendation to -1.\n\t\tself.unwind_indent(-1)\n\n\t\t# Reset simple keys.\n\t\tself.remove_possible_simple_key()\n\t\tself.allow_simple_key = False\n\t\tself.possible_simple_keys = {}\n\n\t\t# Read the token.\n\t\tmark = self.get_mark()\n\t\t\n\t\t# Add STREAM-END.\n\t\tself.tokens.append(StreamEndToken(mark, mark))\n\n\t\t# The steam is finished.\n\t\tself.done = True\n\n\tdef fetch_directive(self):\n\t\t\n\t\t# Set the current intendation to -1.\n\t\tself.unwind_indent(-1)\n\n\t\t# Reset simple keys.\n\t\tself.remove_possible_simple_key()\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add DIRECTIVE.\n\t\tself.tokens.append(self.scan_directive())\n\n\tdef fetch_document_start(self):\n\t\tself.fetch_document_indicator(DocumentStartToken)\n\n\tdef fetch_document_end(self):\n\t\tself.fetch_document_indicator(DocumentEndToken)\n\n\tdef fetch_document_indicator(self, TokenClass):\n\n\t\t# Set the current intendation to -1.\n\t\tself.unwind_indent(-1)\n\n\t\t# Reset simple keys. Note that there could not be a block collection\n\t\t# after '---'.\n\t\tself.remove_possible_simple_key()\n\t\tself.allow_simple_key = False\n\n\t\t# Add DOCUMENT-START or DOCUMENT-END.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward(3)\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(TokenClass(start_mark, end_mark))\n\n\tdef fetch_flow_sequence_start(self):\n\t\tself.fetch_flow_collection_start(FlowSequenceStartToken)\n\n\tdef fetch_flow_mapping_start(self):\n\t\tself.fetch_flow_collection_start(FlowMappingStartToken)\n\n\tdef fetch_flow_collection_start(self, TokenClass):\n\n\t\t# '[' and '{' may start a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# Increase the flow level.\n\t\tself.flow_level += 1\n\n\t\t# Simple keys are allowed after '[' and '{'.\n\t\tself.allow_simple_key = True\n\n\t\t# Add FLOW-SEQUENCE-START or FLOW-MAPPING-START.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(TokenClass(start_mark, end_mark))\n\n\tdef fetch_flow_sequence_end(self):\n\t\tself.fetch_flow_collection_end(FlowSequenceEndToken)\n\n\tdef fetch_flow_mapping_end(self):\n\t\tself.fetch_flow_collection_end(FlowMappingEndToken)\n\n\tdef fetch_flow_collection_end(self, TokenClass):\n\n\t\t# Reset possible simple key on the current level.\n\t\tself.remove_possible_simple_key()\n\n\t\t# Decrease the flow level.\n\t\tself.flow_level -= 1\n\n\t\t# No simple keys after ']' or '}'.\n\t\tself.allow_simple_key = False\n\n\t\t# Add FLOW-SEQUENCE-END or FLOW-MAPPING-END.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(TokenClass(start_mark, end_mark))\n\n\tdef fetch_flow_entry(self):\n\n\t\t# Simple keys are allowed after ','.\n\t\tself.allow_simple_key = True\n\n\t\t# Reset possible simple key on the current level.\n\t\tself.remove_possible_simple_key()\n\n\t\t# Add FLOW-ENTRY.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(FlowEntryToken(start_mark, end_mark))\n\n\tdef fetch_block_entry(self):\n\n\t\t# Block context needs additional checks.\n\t\tif not self.flow_level:\n\n\t\t\t# Are we allowed to start a new entry?\n\t\t\tif not self.allow_simple_key:\n\t\t\t\traise ScannerError(None, None,\n\t\t\t\t\t\t\"sequence entries are not allowed here\",\n\t\t\t\t\t\tself.get_mark())\n\n\t\t\t# We may need to add BLOCK-SEQUENCE-START.\n\t\t\tif self.add_indent(self.column):\n\t\t\t\tmark = self.get_mark()\n\t\t\t\tself.tokens.append(BlockSequenceStartToken(mark, mark))\n\n\t\t# It's an error for the block entry to occur in the flow context,\n\t\t# but we let the parser detect this.\n\t\telse:\n\t\t\tpass\n\n\t\t# Simple keys are allowed after '-'.\n\t\tself.allow_simple_key = True\n\n\t\t# Reset possible simple key on the current level.\n\t\tself.remove_possible_simple_key()\n\n\t\t# Add BLOCK-ENTRY.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(BlockEntryToken(start_mark, end_mark))\n\n\tdef fetch_key(self):\n\t\t\n\t\t# Block context needs additional checks.\n\t\tif not self.flow_level:\n\n\t\t\t# Are we allowed to start a key (not nessesary a simple)?\n\t\t\tif not self.allow_simple_key:\n\t\t\t\traise ScannerError(None, None,\n\t\t\t\t\t\t\"mapping keys are not allowed here\",\n\t\t\t\t\t\tself.get_mark())\n\n\t\t\t# We may need to add BLOCK-MAPPING-START.\n\t\t\tif self.add_indent(self.column):\n\t\t\t\tmark = self.get_mark()\n\t\t\t\tself.tokens.append(BlockMappingStartToken(mark, mark))\n\n\t\t# Simple keys are allowed after '?' in the block context.\n\t\tself.allow_simple_key = not self.flow_level\n\n\t\t# Reset possible simple key on the current level.\n\t\tself.remove_possible_simple_key()\n\n\t\t# Add KEY.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(KeyToken(start_mark, end_mark))\n\n\tdef fetch_value(self):\n\n\t\t# Do we determine a simple key?\n\t\tif self.flow_level in self.possible_simple_keys:\n\n\t\t\t# Add KEY.\n\t\t\tkey = self.possible_simple_keys[self.flow_level]\n\t\t\tdel self.possible_simple_keys[self.flow_level]\n\t\t\tself.tokens.insert(key.token_number-self.tokens_taken,\n\t\t\t\t\tKeyToken(key.mark, key.mark))\n\n\t\t\t# If this key starts a new block mapping, we need to add\n\t\t\t# BLOCK-MAPPING-START.\n\t\t\tif not self.flow_level:\n\t\t\t\tif self.add_indent(key.column):\n\t\t\t\t\tself.tokens.insert(key.token_number-self.tokens_taken,\n\t\t\t\t\t\t\tBlockMappingStartToken(key.mark, key.mark))\n\n\t\t\t# There cannot be two simple keys one after another.\n\t\t\tself.allow_simple_key = False\n\n\t\t# It must be a part of a complex key.\n\t\telse:\n\t\t\t\n\t\t\t# Block context needs additional checks.\n\t\t\t# (Do we really need them? They will be catched by the parser\n\t\t\t# anyway.)\n\t\t\tif not self.flow_level:\n\n\t\t\t\t# We are allowed to start a complex value if and only if\n\t\t\t\t# we can start a simple key.\n\t\t\t\tif not self.allow_simple_key:\n\t\t\t\t\traise ScannerError(None, None,\n\t\t\t\t\t\t\t\"mapping values are not allowed here\",\n\t\t\t\t\t\t\tself.get_mark())\n\n\t\t\t# If this value starts a new block mapping, we need to add\n\t\t\t# BLOCK-MAPPING-START.  It will be detected as an error later by\n\t\t\t# the parser.\n\t\t\tif not self.flow_level:\n\t\t\t\tif self.add_indent(self.column):\n\t\t\t\t\tmark = self.get_mark()\n\t\t\t\t\tself.tokens.append(BlockMappingStartToken(mark, mark))\n\n\t\t\t# Simple keys are allowed after ':' in the block context.\n\t\t\tself.allow_simple_key = not self.flow_level\n\n\t\t\t# Reset possible simple key on the current level.\n\t\t\tself.remove_possible_simple_key()\n\n\t\t# Add VALUE.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(ValueToken(start_mark, end_mark))\n\n\tdef fetch_alias(self):\n\n\t\t# ALIAS could be a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# No simple keys after ALIAS.\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add ALIAS.\n\t\tself.tokens.append(self.scan_anchor(AliasToken))\n\n\tdef fetch_anchor(self):\n\n\t\t# ANCHOR could start a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# No simple keys after ANCHOR.\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add ANCHOR.\n\t\tself.tokens.append(self.scan_anchor(AnchorToken))\n\n\tdef fetch_tag(self):\n\n\t\t# TAG could start a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# No simple keys after TAG.\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add TAG.\n\t\tself.tokens.append(self.scan_tag())\n\n\tdef fetch_literal(self):\n\t\tself.fetch_block_scalar(style='|')\n\n\tdef fetch_folded(self):\n\t\tself.fetch_block_scalar(style='>')\n\n\tdef fetch_block_scalar(self, style):\n\n\t\t# A simple key may follow a block scalar.\n\t\tself.allow_simple_key = True\n\n\t\t# Reset possible simple key on the current level.\n\t\tself.remove_possible_simple_key()\n\n\t\t# Scan and add SCALAR.\n\t\tself.tokens.append(self.scan_block_scalar(style))\n\n\tdef fetch_single(self):\n\t\tself.fetch_flow_scalar(style='\\'')\n\n\tdef fetch_double(self):\n\t\tself.fetch_flow_scalar(style='\"')\n\n\tdef fetch_flow_scalar(self, style):\n\n\t\t# A flow scalar could be a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# No simple keys after flow scalars.\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add SCALAR.\n\t\tself.tokens.append(self.scan_flow_scalar(style))\n\n\tdef fetch_plain(self):\n\n\t\t# A plain scalar could be a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# No simple keys after plain scalars. But note that `scan_plain` will\n\t\t# change this flag if the scan is finished at the beginning of the\n\t\t# line.\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add SCALAR. May change `allow_simple_key`.\n\t\tself.tokens.append(self.scan_plain())\n\n\t# Checkers.\n\n\tdef check_directive(self):\n\n\t\t# DIRECTIVE:\t\t^ '%' ...\n\t\t# The '%' indicator is already checked.\n\t\tif self.column == 0:\n\t\t\treturn True\n\n\tdef check_document_start(self):\n\n\t\t# DOCUMENT-START:   ^ '---' (' '|'\\n')\n\t\tif self.column == 0:\n\t\t\tif self.prefix(3) == '---'  \\\n\t\t\t\t\tand self.peek(3) in '\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\treturn True\n\n\tdef check_document_end(self):\n\n\t\t# DOCUMENT-END:\t ^ '...' (' '|'\\n')\n\t\tif self.column == 0:\n\t\t\tif self.prefix(3) == '...'  \\\n\t\t\t\t\tand self.peek(3) in '\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\treturn True\n\n\tdef check_block_entry(self):\n\n\t\t# BLOCK-ENTRY:\t  '-' (' '|'\\n')\n\t\treturn self.peek(1) in '\\0 \\t\\r\\n\\x85\\u2028\\u2029'\n\n\tdef check_key(self):\n\n\t\t# KEY(flow context):\t'?'\n\t\tif self.flow_level:\n\t\t\treturn True\n\n\t\t# KEY(block context):   '?' (' '|'\\n')\n\t\telse:\n\t\t\treturn self.peek(1) in '\\0 \\t\\r\\n\\x85\\u2028\\u2029'\n\n\tdef check_value(self):\n\n\t\t# VALUE(flow context):  ':'\n\t\tif self.flow_level:\n\t\t\treturn True\n\n\t\t# VALUE(block context): ':' (' '|'\\n')\n\t\telse:\n\t\t\treturn self.peek(1) in '\\0 \\t\\r\\n\\x85\\u2028\\u2029'\n\n\tdef check_plain(self):\n\n\t\t# A plain scalar may start with any non-space character except:\n\t\t#   '-', '?', ':', ',', '[', ']', '{', '}',\n\t\t#   '#', '&', '*', '!', '|', '>', '\\'', '\\\"',\n\t\t#   '%', '@', '`'.\n\t\t#\n\t\t# It may also start with\n\t\t#   '-', '?', ':'\n\t\t# if it is followed by a non-space character.\n\t\t#\n\t\t# Note that we limit the last rule to the block context (except the\n\t\t# '-' character) because we want the flow context to be space\n\t\t# independent.\n\t\tch = self.peek()\n\t\treturn ch not in '\\0 \\t\\r\\n\\x85\\u2028\\u2029-?:,[]{}#&*!|>\\'\\\"%@`'  \\\n\t\t\t\tor (self.peek(1) not in '\\0 \\t\\r\\n\\x85\\u2028\\u2029'\n\t\t\t\t\t\tand (ch == '-' or (not self.flow_level and ch in '?:')))\n\n\t# Scanners.\n\n\tdef scan_to_next_token(self):\n\t\t# We ignore spaces, line breaks and comments.\n\t\t# If we find a line break in the block context, we set the flag\n\t\t# `allow_simple_key` on.\n\t\t# The byte order mark is stripped if it's the first character in the\n\t\t# stream. We do not yet support BOM inside the stream as the\n\t\t# specification requires. Any such mark will be considered as a part\n\t\t# of the document.\n\t\t#\n\t\t# TODO: We need to make tab handling rules more sane. A good rule is\n\t\t#   Tabs cannot precede tokens\n\t\t#   BLOCK-SEQUENCE-START, BLOCK-MAPPING-START, BLOCK-END,\n\t\t#   KEY(block), VALUE(block), BLOCK-ENTRY\n\t\t# So the checking code is\n\t\t#   if :\n\t\t#\t   self.allow_simple_keys = False\n\t\t# We also need to add the check for `allow_simple_keys == True` to\n\t\t# `unwind_indent` before issuing BLOCK-END.\n\t\t# Scanners for block, flow, and plain scalars need to be modified.\n\n\t\tif self.index == 0 and self.peek() == '\\uFEFF':\n\t\t\tself.forward()\n\t\tfound = False\n\t\twhile not found:\n\t\t\twhile self.peek() == ' ':\n\t\t\t\tself.forward()\n\t\t\tif self.peek() == '#':\n\t\t\t\twhile self.peek() not in '\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\t\tself.forward()\n\t\t\tif self.scan_line_break():\n\t\t\t\tif not self.flow_level:\n\t\t\t\t\tself.allow_simple_key = True\n\t\t\telse:\n\t\t\t\tfound = True\n\n\tdef scan_directive(self):\n\t\t# See the specification for details.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tname = self.scan_directive_name(start_mark)\n\t\tvalue = None\n\t\tif name == 'YAML':\n\t\t\tvalue = self.scan_yaml_directive_value(start_mark)\n\t\t\tend_mark = self.get_mark()\n\t\telif name == 'TAG':\n\t\t\tvalue = self.scan_tag_directive_value(start_mark)\n\t\t\tend_mark = self.get_mark()\n\t\telse:\n\t\t\tend_mark = self.get_mark()\n\t\t\twhile self.peek() not in '\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tself.forward()\n\t\tself.scan_directive_ignored_line(start_mark)\n\t\treturn DirectiveToken(name, value, start_mark, end_mark)\n\n\tdef scan_directive_name(self, start_mark):\n\t\t# See the specification for details.\n\t\tlength = 0\n\t\tch = self.peek(length)\n\t\twhile '0' <= ch <= '9' or 'A' <= ch <= 'Z' or 'a' <= ch <= 'z'  \\\n\t\t\t\tor ch in '-_':\n\t\t\tlength += 1\n\t\t\tch = self.peek(length)\n\t\tif not length:\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected alphabetic or numeric character, but found %r\"\n\t\t\t\t\t% ch, self.get_mark())\n\t\tvalue = self.prefix(length)\n\t\tself.forward(length)\n\t\tch = self.peek()\n\t\tif ch not in '\\0 \\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected alphabetic or numeric character, but found %r\"\n\t\t\t\t\t% ch, self.get_mark())\n\t\treturn value\n\n\tdef scan_yaml_directive_value(self, start_mark):\n\t\t# See the specification for details.\n\t\twhile self.peek() == ' ':\n\t\t\tself.forward()\n\t\tmajor = self.scan_yaml_directive_number(start_mark)\n\t\tif self.peek() != '.':\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected a digit or '.', but found %r\" % self.peek(),\n\t\t\t\t\tself.get_mark())\n\t\tself.forward()\n\t\tminor = self.scan_yaml_directive_number(start_mark)\n\t\tif self.peek() not in '\\0 \\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected a digit or ' ', but found %r\" % self.peek(),\n\t\t\t\t\tself.get_mark())\n\t\treturn (major, minor)\n\n\tdef scan_yaml_directive_number(self, start_mark):\n\t\t# See the specification for details.\n\t\tch = self.peek()\n\t\tif not ('0' <= ch <= '9'):\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected a digit, but found %r\" % ch, self.get_mark())\n\t\tlength = 0\n\t\twhile '0' <= self.peek(length) <= '9':\n\t\t\tlength += 1\n\t\tvalue = int(self.prefix(length))\n\t\tself.forward(length)\n\t\treturn value\n\n\tdef scan_tag_directive_value(self, start_mark):\n\t\t# See the specification for details.\n\t\twhile self.peek() == ' ':\n\t\t\tself.forward()\n\t\thandle = self.scan_tag_directive_handle(start_mark)\n\t\twhile self.peek() == ' ':\n\t\t\tself.forward()\n\t\tprefix = self.scan_tag_directive_prefix(start_mark)\n\t\treturn (handle, prefix)\n\n\tdef scan_tag_directive_handle(self, start_mark):\n\t\t# See the specification for details.\n\t\tvalue = self.scan_tag_handle('directive', start_mark)\n\t\tch = self.peek()\n\t\tif ch != ' ':\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected ' ', but found %r\" % ch, self.get_mark())\n\t\treturn value\n\n\tdef scan_tag_directive_prefix(self, start_mark):\n\t\t# See the specification for details.\n\t\tvalue = self.scan_tag_uri('directive', start_mark)\n\t\tch = self.peek()\n\t\tif ch not in '\\0 \\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected ' ', but found %r\" % ch, self.get_mark())\n\t\treturn value\n\n\tdef scan_directive_ignored_line(self, start_mark):\n\t\t# See the specification for details.\n\t\twhile self.peek() == ' ':\n\t\t\tself.forward()\n\t\tif self.peek() == '#':\n\t\t\twhile self.peek() not in '\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tself.forward()\n\t\tch = self.peek()\n\t\tif ch not in '\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected a comment or a line break, but found %r\"\n\t\t\t\t\t\t% ch, self.get_mark())\n\t\tself.scan_line_break()\n\n\tdef scan_anchor(self, TokenClass):\n\t\t# The specification does not restrict characters for anchors and\n\t\t# aliases. This may lead to problems, for instance, the document:\n\t\t#   [ *alias, value ]\n\t\t# can be interpteted in two ways, as\n\t\t#   [ \"value\" ]\n\t\t# and\n\t\t#   [ *alias , \"value\" ]\n\t\t# Therefore we restrict aliases to numbers and ASCII letters.\n\t\tstart_mark = self.get_mark()\n\t\tindicator = self.peek()\n\t\tif indicator == '*':\n\t\t\tname = 'alias'\n\t\telse:\n\t\t\tname = 'anchor'\n\t\tself.forward()\n\t\tlength = 0\n\t\tch = self.peek(length)\n\t\twhile '0' <= ch <= '9' or 'A' <= ch <= 'Z' or 'a' <= ch <= 'z'  \\\n\t\t\t\tor ch in '-_':\n\t\t\tlength += 1\n\t\t\tch = self.peek(length)\n\t\tif not length:\n\t\t\traise ScannerError(\"while scanning an %s\" % name, start_mark,\n\t\t\t\t\t\"expected alphabetic or numeric character, but found %r\"\n\t\t\t\t\t% ch, self.get_mark())\n\t\tvalue = self.prefix(length)\n\t\tself.forward(length)\n\t\tch = self.peek()\n\t\tif ch not in '\\0 \\t\\r\\n\\x85\\u2028\\u2029?:,]}%@`':\n\t\t\traise ScannerError(\"while scanning an %s\" % name, start_mark,\n\t\t\t\t\t\"expected alphabetic or numeric character, but found %r\"\n\t\t\t\t\t% ch, self.get_mark())\n\t\tend_mark = self.get_mark()\n\t\treturn TokenClass(value, start_mark, end_mark)\n\n\tdef scan_tag(self):\n\t\t# See the specification for details.\n\t\tstart_mark = self.get_mark()\n\t\tch = self.peek(1)\n\t\tif ch == '<':\n\t\t\thandle = None\n\t\t\tself.forward(2)\n\t\t\tsuffix = self.scan_tag_uri('tag', start_mark)\n\t\t\tif self.peek() != '>':\n\t\t\t\traise ScannerError(\"while parsing a tag\", start_mark,\n\t\t\t\t\t\t\"expected '>', but found %r\" % self.peek(),\n\t\t\t\t\t\tself.get_mark())\n\t\t\tself.forward()\n\t\telif ch in '\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\thandle = None\n\t\t\tsuffix = '!'\n\t\t\tself.forward()\n\t\telse:\n\t\t\tlength = 1\n\t\t\tuse_handle = False\n\t\t\twhile ch not in '\\0 \\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tif ch == '!':\n\t\t\t\t\tuse_handle = True\n\t\t\t\t\tbreak\n\t\t\t\tlength += 1\n\t\t\t\tch = self.peek(length)\n\t\t\thandle = '!'\n\t\t\tif use_handle:\n\t\t\t\thandle = self.scan_tag_handle('tag', start_mark)\n\t\t\telse:\n\t\t\t\thandle = '!'\n\t\t\t\tself.forward()\n\t\t\tsuffix = self.scan_tag_uri('tag', start_mark)\n\t\tch = self.peek()\n\t\tif ch not in '\\0 \\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a tag\", start_mark,\n\t\t\t\t\t\"expected ' ', but found %r\" % ch, self.get_mark())\n\t\tvalue = (handle, suffix)\n\t\tend_mark = self.get_mark()\n\t\treturn TagToken(value, start_mark, end_mark)\n\n\tdef scan_block_scalar(self, style):\n\t\t# See the specification for details.\n\n\t\tif style == '>':\n\t\t\tfolded = True\n\t\telse:\n\t\t\tfolded = False\n\n\t\tchunks = []\n\t\tstart_mark = self.get_mark()\n\n\t\t# Scan the header.\n\t\tself.forward()\n\t\tchomping, increment = self.scan_block_scalar_indicators(start_mark)\n\t\tself.scan_block_scalar_ignored_line(start_mark)\n\n\t\t# Determine the indentation level and go to the first non-empty line.\n\t\tmin_indent = self.indent+1\n\t\tif min_indent < 1:\n\t\t\tmin_indent = 1\n\t\tif increment is None:\n\t\t\tbreaks, max_indent, end_mark = self.scan_block_scalar_indentation()\n\t\t\tindent = max(min_indent, max_indent)\n\t\telse:\n\t\t\tindent = min_indent+increment-1\n\t\t\tbreaks, end_mark = self.scan_block_scalar_breaks(indent)\n\t\tline_break = ''\n\n\t\t# Scan the inner part of the block scalar.\n\t\twhile self.column == indent and self.peek() != '\\0':\n\t\t\tchunks.extend(breaks)\n\t\t\tleading_non_space = self.peek() not in ' \\t'\n\t\t\tlength = 0\n\t\t\twhile self.peek(length) not in '\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tlength += 1\n\t\t\tchunks.append(self.prefix(length))\n\t\t\tself.forward(length)\n\t\t\tline_break = self.scan_line_break()\n\t\t\tbreaks, end_mark = self.scan_block_scalar_breaks(indent)\n\t\t\tif self.column == indent and self.peek() != '\\0':\n\n\t\t\t\t# Unfortunately, folding rules are ambiguous.\n\t\t\t\t#\n\t\t\t\t# This is the folding according to the specification:\n\t\t\t\t\n\t\t\t\tif folded and line_break == '\\n'\t\\\n\t\t\t\t\t\tand leading_non_space and self.peek() not in ' \\t':\n\t\t\t\t\tif not breaks:\n\t\t\t\t\t\tchunks.append(' ')\n\t\t\t\telse:\n\t\t\t\t\tchunks.append(line_break)\n\t\t\t\t\n\t\t\t\t# This is Clark Evans's interpretation (also in the spec\n\t\t\t\t# examples):\n\t\t\t\t#\n\t\t\t\t#if folded and line_break == '\\n':\n\t\t\t\t#\tif not breaks:\n\t\t\t\t#\t\tif self.peek() not in ' \\t':\n\t\t\t\t#\t\t\tchunks.append(' ')\n\t\t\t\t#\t\telse:\n\t\t\t\t#\t\t\tchunks.append(line_break)\n\t\t\t\t#else:\n\t\t\t\t#\tchunks.append(line_break)\n\t\t\telse:\n\t\t\t\tbreak\n\n\t\t# Chomp the tail.\n\t\tif chomping is not False:\n\t\t\tchunks.append(line_break)\n\t\tif chomping is True:\n\t\t\tchunks.extend(breaks)\n\n\t\t# We are done.\n\t\treturn ScalarToken(''.join(chunks), False, start_mark, end_mark,\n\t\t\t\tstyle)\n\n\tdef scan_block_scalar_indicators(self, start_mark):\n\t\t# See the specification for details.\n\t\tchomping = None\n\t\tincrement = None\n\t\tch = self.peek()\n\t\tif ch in '+-':\n\t\t\tif ch == '+':\n\t\t\t\tchomping = True\n\t\t\telse:\n\t\t\t\tchomping = False\n\t\t\tself.forward()\n\t\t\tch = self.peek()\n\t\t\tif ch in '0123456789':\n\t\t\t\tincrement = int(ch)\n\t\t\t\tif increment == 0:\n\t\t\t\t\traise ScannerError(\"while scanning a block scalar\", start_mark,\n\t\t\t\t\t\t\t\"expected indentation indicator in the range 1-9, but found 0\",\n\t\t\t\t\t\t\tself.get_mark())\n\t\t\t\tself.forward()\n\t\telif ch in '0123456789':\n\t\t\tincrement = int(ch)\n\t\t\tif increment == 0:\n\t\t\t\traise ScannerError(\"while scanning a block scalar\", start_mark,\n\t\t\t\t\t\t\"expected indentation indicator in the range 1-9, but found 0\",\n\t\t\t\t\t\tself.get_mark())\n\t\t\tself.forward()\n\t\t\tch = self.peek()\n\t\t\tif ch in '+-':\n\t\t\t\tif ch == '+':\n\t\t\t\t\tchomping = True\n\t\t\t\telse:\n\t\t\t\t\tchomping = False\n\t\t\t\tself.forward()\n\t\tch = self.peek()\n\t\tif ch not in '\\0 \\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a block scalar\", start_mark,\n\t\t\t\t\t\"expected chomping or indentation indicators, but found %r\"\n\t\t\t\t\t% ch, self.get_mark())\n\t\treturn chomping, increment\n\n\tdef scan_block_scalar_ignored_line(self, start_mark):\n\t\t# See the specification for details.\n\t\twhile self.peek() == ' ':\n\t\t\tself.forward()\n\t\tif self.peek() == '#':\n\t\t\twhile self.peek() not in '\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tself.forward()\n\t\tch = self.peek()\n\t\tif ch not in '\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a block scalar\", start_mark,\n\t\t\t\t\t\"expected a comment or a line break, but found %r\" % ch,\n\t\t\t\t\tself.get_mark())\n\t\tself.scan_line_break()\n\n\tdef scan_block_scalar_indentation(self):\n\t\t# See the specification for details.\n\t\tchunks = []\n\t\tmax_indent = 0\n\t\tend_mark = self.get_mark()\n\t\twhile self.peek() in ' \\r\\n\\x85\\u2028\\u2029':\n\t\t\tif self.peek() != ' ':\n\t\t\t\tchunks.append(self.scan_line_break())\n\t\t\t\tend_mark = self.get_mark()\n\t\t\telse:\n\t\t\t\tself.forward()\n\t\t\t\tif self.column > max_indent:\n\t\t\t\t\tmax_indent = self.column\n\t\treturn chunks, max_indent, end_mark\n\n\tdef scan_block_scalar_breaks(self, indent):\n\t\t# See the specification for details.\n\t\tchunks = []\n\t\tend_mark = self.get_mark()\n\t\twhile self.column < indent and self.peek() == ' ':\n\t\t\tself.forward()\n\t\twhile self.peek() in '\\r\\n\\x85\\u2028\\u2029':\n\t\t\tchunks.append(self.scan_line_break())\n\t\t\tend_mark = self.get_mark()\n\t\t\twhile self.column < indent and self.peek() == ' ':\n\t\t\t\tself.forward()\n\t\treturn chunks, end_mark\n\n\tdef scan_flow_scalar(self, style):\n\t\t# See the specification for details.\n\t\t# Note that we loose indentation rules for quoted scalars. Quoted\n\t\t# scalars don't need to adhere indentation because \" and ' clearly\n\t\t# mark the beginning and the end of them. Therefore we are less\n\t\t# restrictive then the specification requires. We only need to check\n\t\t# that document separators are not included in scalars.\n\t\tif style == '\"':\n\t\t\tdouble = True\n\t\telse:\n\t\t\tdouble = False\n\t\tchunks = []\n\t\tstart_mark = self.get_mark()\n\t\tquote = self.peek()\n\t\tself.forward()\n\t\tchunks.extend(self.scan_flow_scalar_non_spaces(double, start_mark))\n\t\twhile self.peek() != quote:\n\t\t\tchunks.extend(self.scan_flow_scalar_spaces(double, start_mark))\n\t\t\tchunks.extend(self.scan_flow_scalar_non_spaces(double, start_mark))\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\treturn ScalarToken(''.join(chunks), False, start_mark, end_mark,\n\t\t\t\tstyle)\n\n\tESCAPE_REPLACEMENTS = {\n\t\t'0':\t'\\0',\n\t\t'a':\t'\\x07',\n\t\t'b':\t'\\x08',\n\t\t't':\t'\\x09',\n\t\t'\\t':   '\\x09',\n\t\t'n':\t'\\x0A',\n\t\t'v':\t'\\x0B',\n\t\t'f':\t'\\x0C',\n\t\t'r':\t'\\x0D',\n\t\t'e':\t'\\x1B',\n\t\t' ':\t'\\x20',\n\t\t'\\\"':   '\\\"',\n\t\t'\\\\':   '\\\\',\n\t\t'N':\t'\\x85',\n\t\t'_':\t'\\xA0',\n\t\t'L':\t'\\u2028',\n\t\t'P':\t'\\u2029',\n\t}\n\n\tESCAPE_CODES = {\n\t\t'x':\t2,\n\t\t'u':\t4,\n\t\t'U':\t8,\n\t}\n\n\tdef scan_flow_scalar_non_spaces(self, double, start_mark):\n\t\t# See the specification for details.\n\t\tchunks = []\n\t\twhile True:\n\t\t\tlength = 0\n\t\t\twhile self.peek(length) not in '\\'\\\"\\\\\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tlength += 1\n\t\t\tif length:\n\t\t\t\tchunks.append(self.prefix(length))\n\t\t\t\tself.forward(length)\n\t\t\tch = self.peek()\n\t\t\tif not double and ch == '\\'' and self.peek(1) == '\\'':\n\t\t\t\tchunks.append('\\'')\n\t\t\t\tself.forward(2)\n\t\t\telif (double and ch == '\\'') or (not double and ch in '\\\"\\\\'):\n\t\t\t\tchunks.append(ch)\n\t\t\t\tself.forward()\n\t\t\telif double and ch == '\\\\':\n\t\t\t\tself.forward()\n\t\t\t\tch = self.peek()\n\t\t\t\tif ch in self.ESCAPE_REPLACEMENTS:\n\t\t\t\t\tchunks.append(self.ESCAPE_REPLACEMENTS[ch])\n\t\t\t\t\tself.forward()\n\t\t\t\telif ch in self.ESCAPE_CODES:\n\t\t\t\t\tlength = self.ESCAPE_CODES[ch]\n\t\t\t\t\tself.forward()\n\t\t\t\t\tfor k in range(length):\n\t\t\t\t\t\tif self.peek(k) not in '0123456789ABCDEFabcdef':\n\t\t\t\t\t\t\traise ScannerError(\"while scanning a double-quoted scalar\", start_mark,\n\t\t\t\t\t\t\t\t\t\"expected escape sequence of %d hexdecimal numbers, but found %r\" %\n\t\t\t\t\t\t\t\t\t\t(length, self.peek(k)), self.get_mark())\n\t\t\t\t\tcode = int(self.prefix(length), 16)\n\t\t\t\t\tchunks.append(chr(code))\n\t\t\t\t\tself.forward(length)\n\t\t\t\telif ch in '\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\t\tself.scan_line_break()\n\t\t\t\t\tchunks.extend(self.scan_flow_scalar_breaks(double, start_mark))\n\t\t\t\telse:\n\t\t\t\t\traise ScannerError(\"while scanning a double-quoted scalar\", start_mark,\n\t\t\t\t\t\t\t\"found unknown escape character %r\" % ch, self.get_mark())\n\t\t\telse:\n\t\t\t\treturn chunks\n\n\tdef scan_flow_scalar_spaces(self, double, start_mark):\n\t\t# See the specification for details.\n\t\tchunks = []\n\t\tlength = 0\n\t\twhile self.peek(length) in ' \\t':\n\t\t\tlength += 1\n\t\twhitespaces = self.prefix(length)\n\t\tself.forward(length)\n\t\tch = self.peek()\n\t\tif ch == '\\0':\n\t\t\traise ScannerError(\"while scanning a quoted scalar\", start_mark,\n\t\t\t\t\t\"found unexpected end of stream\", self.get_mark())\n\t\telif ch in '\\r\\n\\x85\\u2028\\u2029':\n\t\t\tline_break = self.scan_line_break()\n\t\t\tbreaks = self.scan_flow_scalar_breaks(double, start_mark)\n\t\t\tif line_break != '\\n':\n\t\t\t\tchunks.append(line_break)\n\t\t\telif not breaks:\n\t\t\t\tchunks.append(' ')\n\t\t\tchunks.extend(breaks)\n\t\telse:\n\t\t\tchunks.append(whitespaces)\n\t\treturn chunks\n\n\tdef scan_flow_scalar_breaks(self, double, start_mark):\n\t\t# See the specification for details.\n\t\tchunks = []\n\t\twhile True:\n\t\t\t# Instead of checking indentation, we check for document\n\t\t\t# separators.\n\t\t\tprefix = self.prefix(3)\n\t\t\tif (prefix == '---' or prefix == '...')   \\\n\t\t\t\t\tand self.peek(3) in '\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\traise ScannerError(\"while scanning a quoted scalar\", start_mark,\n\t\t\t\t\t\t\"found unexpected document separator\", self.get_mark())\n\t\t\twhile self.peek() in ' \\t':\n\t\t\t\tself.forward()\n\t\t\tif self.peek() in '\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tchunks.append(self.scan_line_break())\n\t\t\telse:\n\t\t\t\treturn chunks\n\n\tdef scan_plain(self):\n\t\t# See the specification for details.\n\t\t# We add an additional restriction for the flow context:\n\t\t#   plain scalars in the flow context cannot contain ',', ':' and '?'.\n\t\t# We also keep track of the `allow_simple_key` flag here.\n\t\t# Indentation rules are loosed for the flow context.\n\t\tchunks = []\n\t\tstart_mark = self.get_mark()\n\t\tend_mark = start_mark\n\t\tindent = self.indent+1\n\t\t# We allow zero indentation for scalars, but then we need to check for\n\t\t# document separators at the beginning of the line.\n\t\t#if indent == 0:\n\t\t#\tindent = 1\n\t\tspaces = []\n\t\twhile True:\n\t\t\tlength = 0\n\t\t\tif self.peek() == '#':\n\t\t\t\tbreak\n\t\t\twhile True:\n\t\t\t\tch = self.peek(length)\n\t\t\t\tif ch in '\\0 \\t\\r\\n\\x85\\u2028\\u2029'\t\\\n\t\t\t\t\t\tor (not self.flow_level and ch == ':' and\n\t\t\t\t\t\t\t\tself.peek(length+1) in '\\0 \\t\\r\\n\\x85\\u2028\\u2029') \\\n\t\t\t\t\t\tor (self.flow_level and ch in ',:?[]{}'):\n\t\t\t\t\tbreak\n\t\t\t\tlength += 1\n\t\t\t# It's not clear what we should do with ':' in the flow context.\n\t\t\tif (self.flow_level and ch == ':'\n\t\t\t\t\tand self.peek(length+1) not in '\\0 \\t\\r\\n\\x85\\u2028\\u2029,[]{}'):\n\t\t\t\tself.forward(length)\n\t\t\t\traise ScannerError(\"while scanning a plain scalar\", start_mark,\n\t\t\t\t\t\"found unexpected ':'\", self.get_mark(),\n\t\t\t\t\t\"Please check http://pyyaml.org/wiki/YAMLColonInFlowContext for details.\")\n\t\t\tif length == 0:\n\t\t\t\tbreak\n\t\t\tself.allow_simple_key = False\n\t\t\tchunks.extend(spaces)\n\t\t\tchunks.append(self.prefix(length))\n\t\t\tself.forward(length)\n\t\t\tend_mark = self.get_mark()\n\t\t\tspaces = self.scan_plain_spaces(indent, start_mark)\n\t\t\tif not spaces or self.peek() == '#' \\\n\t\t\t\t\tor (not self.flow_level and self.column < indent):\n\t\t\t\tbreak\n\t\treturn ScalarToken(''.join(chunks), True, start_mark, end_mark)\n\n\tdef scan_plain_spaces(self, indent, start_mark):\n\t\t# See the specification for details.\n\t\t# The specification is really confusing about tabs in plain scalars.\n\t\t# We just forbid them completely. Do not use tabs in YAML!\n\t\tchunks = []\n\t\tlength = 0\n\t\twhile self.peek(length) in ' ':\n\t\t\tlength += 1\n\t\twhitespaces = self.prefix(length)\n\t\tself.forward(length)\n\t\tch = self.peek()\n\t\tif ch in '\\r\\n\\x85\\u2028\\u2029':\n\t\t\tline_break = self.scan_line_break()\n\t\t\tself.allow_simple_key = True\n\t\t\tprefix = self.prefix(3)\n\t\t\tif (prefix == '---' or prefix == '...')   \\\n\t\t\t\t\tand self.peek(3) in '\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\treturn\n\t\t\tbreaks = []\n\t\t\twhile self.peek() in ' \\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tif self.peek() == ' ':\n\t\t\t\t\tself.forward()\n\t\t\t\telse:\n\t\t\t\t\tbreaks.append(self.scan_line_break())\n\t\t\t\t\tprefix = self.prefix(3)\n\t\t\t\t\tif (prefix == '---' or prefix == '...')   \\\n\t\t\t\t\t\t\tand self.peek(3) in '\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\t\t\treturn\n\t\t\tif line_break != '\\n':\n\t\t\t\tchunks.append(line_break)\n\t\t\telif not breaks:\n\t\t\t\tchunks.append(' ')\n\t\t\tchunks.extend(breaks)\n\t\telif whitespaces:\n\t\t\tchunks.append(whitespaces)\n\t\treturn chunks\n\n\tdef scan_tag_handle(self, name, start_mark):\n\t\t# See the specification for details.\n\t\t# For some strange reasons, the specification does not allow '_' in\n\t\t# tag handles. I have allowed it anyway.\n\t\tch = self.peek()\n\t\tif ch != '!':\n\t\t\traise ScannerError(\"while scanning a %s\" % name, start_mark,\n\t\t\t\t\t\"expected '!', but found %r\" % ch, self.get_mark())\n\t\tlength = 1\n\t\tch = self.peek(length)\n\t\tif ch != ' ':\n\t\t\twhile '0' <= ch <= '9' or 'A' <= ch <= 'Z' or 'a' <= ch <= 'z'  \\\n\t\t\t\t\tor ch in '-_':\n\t\t\t\tlength += 1\n\t\t\t\tch = self.peek(length)\n\t\t\tif ch != '!':\n\t\t\t\tself.forward(length)\n\t\t\t\traise ScannerError(\"while scanning a %s\" % name, start_mark,\n\t\t\t\t\t\t\"expected '!', but found %r\" % ch, self.get_mark())\n\t\t\tlength += 1\n\t\tvalue = self.prefix(length)\n\t\tself.forward(length)\n\t\treturn value\n\n\tdef scan_tag_uri(self, name, start_mark):\n\t\t# See the specification for details.\n\t\t# Note: we do not check if URI is well-formed.\n\t\tchunks = []\n\t\tlength = 0\n\t\tch = self.peek(length)\n\t\twhile '0' <= ch <= '9' or 'A' <= ch <= 'Z' or 'a' <= ch <= 'z'  \\\n\t\t\t\tor ch in '-;/?:@&=+$,_.!~*\\'()[]%':\n\t\t\tif ch == '%':\n\t\t\t\tchunks.append(self.prefix(length))\n\t\t\t\tself.forward(length)\n\t\t\t\tlength = 0\n\t\t\t\tchunks.append(self.scan_uri_escapes(name, start_mark))\n\t\t\telse:\n\t\t\t\tlength += 1\n\t\t\tch = self.peek(length)\n\t\tif length:\n\t\t\tchunks.append(self.prefix(length))\n\t\t\tself.forward(length)\n\t\t\tlength = 0\n\t\tif not chunks:\n\t\t\traise ScannerError(\"while parsing a %s\" % name, start_mark,\n\t\t\t\t\t\"expected URI, but found %r\" % ch, self.get_mark())\n\t\treturn ''.join(chunks)\n\n\tdef scan_uri_escapes(self, name, start_mark):\n\t\t# See the specification for details.\n\t\tcodes = []\n\t\tmark = self.get_mark()\n\t\twhile self.peek() == '%':\n\t\t\tself.forward()\n\t\t\tfor k in range(2):\n\t\t\t\tif self.peek(k) not in '0123456789ABCDEFabcdef':\n\t\t\t\t\traise ScannerError(\"while scanning a %s\" % name, start_mark,\n\t\t\t\t\t\t\t\"expected URI escape sequence of 2 hexdecimal numbers, but found %r\"\n\t\t\t\t\t\t\t% self.peek(k), self.get_mark())\n\t\t\tcodes.append(int(self.prefix(2), 16))\n\t\t\tself.forward(2)\n\t\ttry:\n\t\t\tvalue = bytes(codes).decode('utf-8')\n\t\texcept UnicodeDecodeError as exc:\n\t\t\traise ScannerError(\"while scanning a %s\" % name, start_mark, str(exc), mark)\n\t\treturn value\n\n\tdef scan_line_break(self):\n\t\t# Transforms:\n\t\t#   '\\r\\n'\t  :   '\\n'\n\t\t#   '\\r'\t\t:   '\\n'\n\t\t#   '\\n'\t\t:   '\\n'\n\t\t#   '\\x85'\t  :   '\\n'\n\t\t#   '\\u2028'\t:   '\\u2028'\n\t\t#   '\\u2029\t :   '\\u2029'\n\t\t#   default\t :   ''\n\t\tch = self.peek()\n\t\tif ch in '\\r\\n\\x85':\n\t\t\tif self.prefix(2) == '\\r\\n':\n\t\t\t\tself.forward(2)\n\t\t\telse:\n\t\t\t\tself.forward()\n\t\t\treturn '\\n'\n\t\telif ch in '\\u2028\\u2029':\n\t\t\tself.forward()\n\t\t\treturn ch\n\t\treturn ''\n", "description": "Initialize the scanner.", "category": "simple", "imports": ["from .error import MarkedYAMLError", "from .tokens import *", "#\timport psyco"]}], [{"term": "class", "name": "SequentialDataFixture", "data": "class SequentialDataFixture(object):\n\tdef __init__(self, start_from):\n\t\tsuper(SequentialDataFixture, self).__init__()\n\t\tself.gen = count(start_from)\n\n\tdef generate_data(self, field):\n\t\treturn self.gen.next()\n\n", "description": null, "category": "simple", "imports": ["import datetime", "from django.contrib.auth.models import Permission", "from django_dynamic_fixture import G", "from django_webtest import WebTest", "from itertools import count", "from ereports.engine.config import reportform_factory", "from ereports.engine.datasource import Datasource", "from ereports.engine.renderer import BaseHtmlRender, BaseXlsRender", "from ereports.engine.report import BaseReport, BaseGrouper, ImproperlyConfigured", "from ereports.tests.app.models import SimpleDemoModel, SimpleDateModel", "from ereports.tests.app.reports import SimpleDemoReport, SimpleDateReport, SimpleDateModelSource"]}, {"term": "def", "name": "fake_callable", "data": "def fake_callable(orig):\n\treturn u'cba'\n\n", "description": null, "category": "simple", "imports": ["import datetime", "from django.contrib.auth.models import Permission", "from django_dynamic_fixture import G", "from django_webtest import WebTest", "from itertools import count", "from ereports.engine.config import reportform_factory", "from ereports.engine.datasource import Datasource", "from ereports.engine.renderer import BaseHtmlRender, BaseXlsRender", "from ereports.engine.report import BaseReport, BaseGrouper, ImproperlyConfigured", "from ereports.tests.app.models import SimpleDemoModel, SimpleDateModel", "from ereports.tests.app.reports import SimpleDemoReport, SimpleDateReport, SimpleDateModelSource"]}, {"term": "class", "name": "TestBaseGroup", "data": "class TestBaseGroup(WebTest):\n\tdef test_init(self):\n\t\tg = BaseGrouper(SimpleDemoReport, 'char', 'Character')\n\t\tself.assertEqual(g.report, SimpleDemoReport)\n\t\tself.assertEqual(g.group_by, 'char')\n\t\tself.assertEqual(g.internal_order, 'Character')\n\t\tself.assertFalse(g._processed)\n\n\tdef test_items_basestring(self):\n\t\tG(SimpleDateModel, char='abc', date=datetime.date.today(), date_range=datetime.date.today())\n\t\tr = SimpleDateReport.as_report()\n\t\tg = BaseGrouper(r, 'char', 'Character')\n\t\tself.assertEqual(list(g.items()), [(u'abc', list(r))])\n\t\tself.assertTrue(g._processed)\n\n\t\t# call again to ensure _processed param handled properly and no error\n\t\tg._process()\n\t\tself.assertTrue(g._processed)\n\n\tdef test_items_callable(self):\n\t\tG(SimpleDateModel, char='abc', date=datetime.date.today(), date_range=datetime.date.today())\n\t\tr = SimpleDateReport.as_report()\n\t\tg = BaseGrouper(r, fake_callable, 'Groups')\n\t\tself.assertEqual(list(g.items()), [(u'cba', list(r))])\n\n\tdef test_items_other(self):\n\t\tG(SimpleDemoModel, char='abc')\n\t\tr = SimpleDemoReport.as_report()\n\t\tr.list_display = ['char', 'integer1']\n\t\tg = BaseGrouper(r, 'wrong', 'wrong')\n\t\tself.assertEqual(list(g.items()), [(None, list(r))])\n\n\tdef test_items_sorted(self):\n\t\tG(SimpleDateModel, char='cba', date=datetime.date.today(), date_range=datetime.date.today())\n\t\tG(SimpleDateModel, char='bac', date=datetime.date.today(), date_range=datetime.date.today())\n\t\tG(SimpleDateModel, char='abc', date=datetime.date.today(), date_range=datetime.date.today())\n\t\tr = SimpleDateReport.as_report()\n\t\tg = BaseGrouper(r, 'char', 'Groups')\n\t\texpected = [(u'abc', [r[2]]),\n\t\t\t\t\t(u'bac', [r[1]]),\n\t\t\t\t\t(u'cba', [r[0]])]\n\n\t\tself.assertEqual(list(g.items()), expected)\n\n\tdef test_values(self):\n\t\tG(SimpleDateModel, char='abc', date=datetime.date.today(), date_range=datetime.date.today())\n\t\tr = SimpleDateReport.as_report()\n\t\tg = BaseGrouper(r, 'char', 'Groups')\n\t\tself.assertEqual(g.values(), [list(r)])\n\n\tdef test_keys(self):\n\t\tG(SimpleDateModel, char='abc', date=datetime.date.today(), date_range=datetime.date.today())\n\t\tr = SimpleDateReport.as_report()\n\t\tg = BaseGrouper(r, 'char', 'Groups')\n\t\tself.assertEqual(g.keys(), [u'abc'])\n\n", "description": null, "category": "simple", "imports": ["import datetime", "from django.contrib.auth.models import Permission", "from django_dynamic_fixture import G", "from django_webtest import WebTest", "from itertools import count", "from ereports.engine.config import reportform_factory", "from ereports.engine.datasource import Datasource", "from ereports.engine.renderer import BaseHtmlRender, BaseXlsRender", "from ereports.engine.report import BaseReport, BaseGrouper, ImproperlyConfigured", "from ereports.tests.app.models import SimpleDemoModel, SimpleDateModel", "from ereports.tests.app.reports import SimpleDemoReport, SimpleDateReport, SimpleDateModelSource"]}, {"term": "class", "name": "TestBaseReport", "data": "class TestBaseReport(WebTest):\n\tdef test_inherit(self):\n\t\tTestReport = type('TestReport', (BaseReport,), {'model': Permission})\n\t\tr = TestReport.as_report()\n\t\tself.assertIsInstance(list(r), list)\n\n\tdef test_repr(self):\n\t\tr = SimpleDemoReport.as_report()\n\t\tself.assertEqual(repr(r), \"\")\n\n\tdef test_type_error_exception(self):\n\t\twith self.assertRaises(TypeError):\n\t\t\tBaseReport.as_report(models=\"\")\n\n\tdef test_improperly_configured_exception(self):\n\t\tG(SimpleDemoModel, n=2, char='abc', integer1=10, integer2=20)\n\t\twith self.assertRaises(ImproperlyConfigured):\n\t\t\tBaseReport.as_report(models=SimpleDemoModel)\n\n\tdef test_slice(self):\n\t\tinstances = G(SimpleDemoModel, n=2, char='abc', integer1=10, integer2=20, boolean=True)\n\t\tr = BaseReport.as_report(model=SimpleDemoModel)\n\t\tself.assertSequenceEqual(list(r[:1]), [(instances[0].pk, u'abc', 10, 20, True)])\n\n\tdef test_getitem(self):\n\t\tinstances = G(SimpleDemoModel, n=2, char='abc', integer1=10, integer2=20, boolean=True)\n\t\tr = BaseReport.as_report(model=SimpleDemoModel)\n\t\tself.assertSequenceEqual(r[1].values(), (instances[1].pk, u'abc', 10, 20, True))\n\n\tdef test_datasource(self):\n\t\tinstances = G(SimpleDemoModel, n=2, char='abc', integer1=10, integer2=20, boolean=True)\n\t\tds = Datasource.as_datasource(model=SimpleDemoModel)\n\t\tr = BaseReport.as_report(datasource=ds)\n\t\tself.assertSequenceEqual(r[1].values(), (instances[1].pk, u'abc', 10, 20, True))\n\n\tdef test_datasource_custom_list_display(self):\n\t\tG(SimpleDemoModel, n=2, char='abc', integer1=10, integer2=20)\n\n\t\tds = Datasource.as_datasource(model=SimpleDemoModel)\n\t\tr = BaseReport.as_report(datasource=ds,\n\t\t\t\t\t\t\t\t list_display=['integer2', 'char', 'integer1'])\n\n\t\tself.assertSequenceEqual(r[1], (20, u'abc', 10))\n\t\tself.assertSequenceEqual(r[:1], [(20, u'abc', 10)])\n\n\tdef test_datasource_std_list_display(self):\n\t\tG(SimpleDemoModel, n=2, char='abc', integer1=10, integer2=20)\n\n\t\tds = Datasource.as_datasource(model=SimpleDemoModel,\n\t\t\t\t\t\t\t\t\t  columns=['integer2', 'char', 'integer1'])\n\t\tr = BaseReport.as_report(datasource=ds)\n\n\t\tself.assertSequenceEqual([c.name for c in ds.columns], r.display_order())\n\t\tself.assertSequenceEqual(r[1], (20, u'abc', 10))\n\n\tdef test_headers(self):\n\t\tG(SimpleDemoModel, n=2, char='abc', integer1=10, integer2=20)\n\n\t\tds = Datasource.as_datasource(model=SimpleDemoModel)\n\t\tr = BaseReport.as_report(datasource=ds,\n\t\t\t\t\t\t\t\t list_display=['integer2', 'char', 'integer1'])\n\n\t\tself.assertSequenceEqual(['Integer #2', 'Character', 'Integer #1'], r.headers)\n\n\t\tds = Datasource.as_datasource(model=SimpleDemoModel,\n\t\t\t\t\t\t\t\t\t  columns=['integer2', 'char', 'integer1'])\n\t\tr = BaseReport.as_report(datasource=ds)\n\n\t\tself.assertSequenceEqual(['Integer #2', 'Character', 'Integer #1'], r.headers)\n\n\tdef test_get_column_values(self):\n\t\tG(SimpleDemoModel, n=10, data_fixture=SequentialDataFixture(0))\n\t\tds = Datasource.as_datasource(model=SimpleDemoModel)\n\t\tr = BaseReport.as_report(datasource=ds,\n\t\t\t\t\t\t\t\t list_display=['integer2', 'char', 'integer1'])\n\n\t\tself.assertSequenceEqual([1, 3, 5, 7, 9, 11, 13, 15, 17, 19], r.get_column_values('integer1'))\n\n\tdef test_get_config_form_class(self):\n\t\tr = SimpleDemoReport.as_report()\n\t\tf = reportform_factory(r, bases=(r.config_form_class,))\n\t\tself.assertIn('integer1', f.base_fields)\n\t\tself.assertIn('_format', f.base_fields)\n\n\tdef test_get_format_labels(self):\n\t\tr = SimpleDemoReport.as_report()\n\t\tself.assertEqual(r.formats_dict, {'html': BaseHtmlRender, 'xls': BaseXlsRender})\n\n\tdef test_format_labels(self):\n\t\tr = SimpleDemoReport.as_report()\n\t\tself.assertSequenceEqual(sorted(r.get_format_labels()), ['html', 'xls'])\n\n\tdef test_get_renderer_class_format(self):\n\t\tr = SimpleDemoReport.as_report()\n\t\tself.assertEqual(r.get_renderer_class_for_format('html'), BaseHtmlRender)\n\n\tdef test_get_renderer_for_format(self):\n\t\tr = SimpleDemoReport.as_report()\n\t\trenderer = r.get_renderer_for_format('html')\n\t\tself.assertIsInstance(renderer, BaseHtmlRender)\n\n\tdef test_get_groups(self):\n\t\tr = SimpleDemoReport.as_report()\n\n\t\twith self.assertRaises(ImproperlyConfigured):\n\t\t\tr.get_groups()\n\n\t\tG(SimpleDateModel, char='abc', date=datetime.date.today(), date_range=datetime.date.today())\n\t\tr = SimpleDateReport.as_report(datasource=SimpleDateModelSource.as_datasource())\n\t\tg = r.get_groups()\n\t\tself.assertEqual(len(g), 1)\n\n\tdef test_has_subtotals(self):\n\t\tr = SimpleDemoReport.as_report()\n\n\t\tself.assertFalse(r.has_subtotals())\n\n\t\tr.column_totals = ['integer1']\n\t\tself.assertTrue(r.has_subtotals())\n\n", "description": null, "category": "simple", "imports": ["import datetime", "from django.contrib.auth.models import Permission", "from django_dynamic_fixture import G", "from django_webtest import WebTest", "from itertools import count", "from ereports.engine.config import reportform_factory", "from ereports.engine.datasource import Datasource", "from ereports.engine.renderer import BaseHtmlRender, BaseXlsRender", "from ereports.engine.report import BaseReport, BaseGrouper, ImproperlyConfigured", "from ereports.tests.app.models import SimpleDemoModel, SimpleDateModel", "from ereports.tests.app.reports import SimpleDemoReport, SimpleDateReport, SimpleDateModelSource"]}, {"term": "class", "name": "TestExtendedReport", "data": "class TestExtendedReport(WebTest):\n\tdef test_datasource_custom_list_display(self):\n\t\tG(SimpleDemoModel, n=2, char='abc', integer1=10, integer2=20)\n\t\tr = SimpleDemoReport.as_report()\n\t\tself.assertEqual(r.datasource[1].values(), [u'abc', 10])\n\t\tself.assertEqual(r[1], (u'abc',))\n\t\tself.assertSequenceEqual(r[:1], [(u'abc',)])\n", "description": null, "category": "simple", "imports": ["import datetime", "from django.contrib.auth.models import Permission", "from django_dynamic_fixture import G", "from django_webtest import WebTest", "from itertools import count", "from ereports.engine.config import reportform_factory", "from ereports.engine.datasource import Datasource", "from ereports.engine.renderer import BaseHtmlRender, BaseXlsRender", "from ereports.engine.report import BaseReport, BaseGrouper, ImproperlyConfigured", "from ereports.tests.app.models import SimpleDemoModel, SimpleDateModel", "from ereports.tests.app.reports import SimpleDemoReport, SimpleDateReport, SimpleDateModelSource"]}], [{"term": "def", "name": "deleteNode", "data": "  def deleteNode(self, root:TreeNode, key:int):\n\t# \u5206\u7c7b\u8ba8\u8bba\uff1a1) \u5b8c\u5907\uff0c2\uff09\u4e0d\u91cd\u590d.\n\tif not root:\n\t  return None\n\tdef findReplacement(target:TreeNode):\n\t  # \u9009\u62e9\u4e00\u4e2a\u6bd4 target \u5927\u7684\u3002\u5f53\u7136\u4e5f\u53ef\u4ee5\u9009\u62e9\u4e00\u4e2a\u6bd4\u5b83\u5c0f\u7684\u3002\n\t  # \u4e5f\u5c31\u662f\u51fa\u95e8\u53f3\u62d0\uff0c\u5411\u5de6\u4e0b\u8d70 /\n\t  # bigger \u662f\u76f8\u5bf9\u4e8e target \u800c\u8a00\u3002\n\t  prev = target\n\t  bigger = target.right\n\t  while bigger.left:\n\t\tprev = bigger\n\t\tbigger = bigger.left\n\t  return prev,bigger\n\n\tdef deleteLeafNode(parent:TreeNode, leaf:TreeNode):\n\t  if parent.left == leaf:\n\t\tparent.left = None\n\t  if parent.right == leaf:\n\t\tparent.right = None\n\n\tdef deleteBranchWithOneChild(parent:TreeNode,branch:TreeNode):\n\t  if parent.left == branch:\n\t\tparent.left = branch.left if branch.left else branch.right\n\t  else:\n\t\tparent.right = branch.left if branch.left else branch.right\n\n\tdef deleteBranchWithTwoChild(branch:TreeNode):\n\t  # \u6362\u503c\u518d\u5220\u9664\u53e6\u4e00\u4e2a\u8282\u70b9\n\t  prev,replacement = findReplacement(branch)\n\t  branch.val = replacement.val\n\t  if replacement.left or replacement.right:\n\t\t# \u8fd9\u6211\u4eec\u7684\u8fd9\u4e2a\u573a\u666f\u4e0b\u5176\u5b9e\u6700\u591a replacement.right \u53ef\u80fd\u4e3a\u771f\u3002\n\t\t# \u5982\u679c\u662f\u627e\u4e00\u4e2a\u7a0d\u5c0f\u7684\u66ff\u4ee3\u503c\u7684\u8bdd\uff0c\u6700\u591a replacement.left \u53ef\u80fd\u4e3a\u771f\n\t\tdeleteBranchWithOneChild(prev,replacement)\n\t  else:\n\t\tdeleteLeafNode(prev, replacement)\n\n\tdef deleteRootNode(root:TreeNode):\n\t  if root.left and root.right:\n\t\tdeleteBranchWithTwoChild(root)\n\t\treturn root\n\t  elif root.left:\n\t\treturn root.left\n\t  elif root.right:\n\t\treturn root.right\n\t  else:\n\t\treturn None\n\n\tparent = None\n\ttarget = root\n\twhile target:\n\t  if target.val == key:\n\t\tbreak\n\t  elif target.val < key:\n\t\tparent = target\n\t\ttarget = target.right\n\t  else:\n\t\tparent = target\n\t\ttarget = target.left\n\tif not target:\n\t  return root\n\tif parent:\n\t  if (target.left and target.right):\n\t\tdeleteBranchWithTwoChild(target)\n\t  elif target.left or target.right:\n\t\tdeleteBranchWithOneChild(parent,target)\n\t  else:\n\t\tdeleteLeafNode(parent, target)\n\t  return root\n\telse:\n\t  return deleteRootNode(root)\n\n", "description": null, "category": "simple", "imports": ["from tree_node import  *"]}], [{"term": "class", "name": "BrowserTestRunnerTest", "data": "class BrowserTestRunnerTest(unittest.TestCase):\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "_ExtractTestResults", "data": "  def _ExtractTestResults(self, test_result):\n\tdelimiter = test_result['path_delimiter']\n\tfailures = []\n\tsuccesses = []\n\tdef _IsLeafNode(node):\n\t  test_dict = node[1]\n\t  return ('expected' in test_dict and\n\t\t\t  isinstance(test_dict['expected'], basestring))\n\tnode_queues = []\n\tfor t in test_result['tests']:\n\t  node_queues.append((t, test_result['tests'][t]))\n\twhile node_queues:\n\t  node = node_queues.pop()\n\t  full_test_name, test_dict = node\n\t  if _IsLeafNode(node):\n\t\tif all(res not in test_dict['expected'].split() for res in\n\t\t\t   test_dict['actual'].split()):\n\t\t  failures.append(full_test_name)\n\t\telse:\n\t\t  successes.append(full_test_name)\n\t  else:\n\t\tfor k in test_dict:\n\t\t  node_queues.append(\n\t\t\t  ('%s%s%s' % (full_test_name, delimiter, k),\n\t\t\t   test_dict[k]))\n\treturn successes, failures\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "baseTest", "data": "  def baseTest(self, test_filter,\n\t\t\t   failures, successes, test_name='SimpleTest'):\n\tconfig = project_config.ProjectConfig(\n\t\ttop_level_dir=os.path.join(util.GetTelemetryDir(), 'examples'),\n\t\tclient_configs=[],\n\t\tbenchmark_dirs=[\n\t\t\tos.path.join(util.GetTelemetryDir(), 'examples', 'browser_tests')]\n\t)\n\ttemp_file = tempfile.NamedTemporaryFile(delete=False)\n\ttemp_file.close()\n\ttemp_file_name = temp_file.name\n\ttry:\n\t  browser_test_runner.Run(\n\t\t  config,\n\t\t  [test_name,\n\t\t   '--write-full-results-to=%s' % temp_file_name,\n\t\t   '--test-filter=%s' % test_filter])\n\t  with open(temp_file_name) as f:\n\t\ttest_result = json.load(f)\n\n\t  actual_successes, actual_failures = self._ExtractTestResults(test_result)\n\t  self.assertEquals(set(actual_failures), set(failures))\n\t  self.assertEquals(set(actual_successes), set(successes))\n\tfinally:\n\t  os.remove(temp_file_name)\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "testJsonOutputFormatNegativeFilter", "data": "  def testJsonOutputFormatNegativeFilter(self):\n\tself.baseTest(\n\t\t'^(add|multiplier).*',\n\t\t['browser_tests.simple_numeric_test.SimpleTest.add_1_and_2',\n\t\t 'browser_tests.simple_numeric_test.SimpleTest.add_7_and_3',\n\t\t 'browser_tests.simple_numeric_test.SimpleTest.multiplier_simple_2'],\n\t\t['browser_tests.simple_numeric_test.SimpleTest.add_2_and_3',\n\t\t 'browser_tests.simple_numeric_test.SimpleTest.multiplier_simple',\n\t\t 'browser_tests.simple_numeric_test.SimpleTest.multiplier_simple_3'])\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "testJsonOutputWhenSetupClassFailed", "data": "  def testJsonOutputWhenSetupClassFailed(self):\n\tself.baseTest(\n\t\t'.*',\n\t\t['browser_tests.failed_tests.SetUpClassFailedTest.dummy_test_0',\n\t\t 'browser_tests.failed_tests.SetUpClassFailedTest.dummy_test_1',\n\t\t 'browser_tests.failed_tests.SetUpClassFailedTest.dummy_test_2'],\n\t\t[], test_name='SetUpClassFailedTest')\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "testJsonOutputWhenTearDownClassFailed", "data": "  def testJsonOutputWhenTearDownClassFailed(self):\n\tself.baseTest(\n\t\t'.*',\n\t\t['browser_tests.failed_tests.TearDownClassFailedTest.dummy_test_0',\n\t\t 'browser_tests.failed_tests.TearDownClassFailedTest.dummy_test_1',\n\t\t 'browser_tests.failed_tests.TearDownClassFailedTest.dummy_test_2'],\n\t\t[], test_name='TearDownClassFailedTest')\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "testSetUpProcessCalledOnce", "data": "  def testSetUpProcessCalledOnce(self):\n\tself.baseTest(\n\t\t'.*',\n\t\t[],\n\t\t['browser_tests.process_tests.FailIfSetUpProcessCalledTwice.Dummy_0',\n\t\t 'browser_tests.process_tests.FailIfSetUpProcessCalledTwice.Dummy_1',\n\t\t 'browser_tests.process_tests.FailIfSetUpProcessCalledTwice.Dummy_2'],\n\t\ttest_name='FailIfSetUpProcessCalledTwice')\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "testTearDownProcessCalledOnce", "data": "  def testTearDownProcessCalledOnce(self):\n\tself.baseTest(\n\t\t'.*',\n\t\t[],\n\t\t['browser_tests.process_tests.FailIfTearDownProcessCalledTwice.Dummy_0',\n\t\t 'browser_tests.process_tests.FailIfTearDownProcessCalledTwice.Dummy_1',\n\t\t 'browser_tests.process_tests.FailIfTearDownProcessCalledTwice.Dummy_2'\n\t\t], test_name='FailIfTearDownProcessCalledTwice')\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "testJsonOutputFormatPositiveFilter", "data": "  def testJsonOutputFormatPositiveFilter(self):\n\tself.baseTest(\n\t\t'(TestSimple|TestException).*',\n\t\t['browser_tests.simple_numeric_test.SimpleTest.TestException',\n\t\t 'browser_tests.simple_numeric_test.SimpleTest.TestSimple'], [])\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "testExecutingTestsInSortedOrder", "data": "  def testExecutingTestsInSortedOrder(self):\n\talphabetical_tests = []\n\tprefix = 'browser_tests.simple_numeric_test.SimpleTest.Alphabetical_'\n\tfor i in xrange(20):\n\t  alphabetical_tests.append(prefix + str(i))\n\tfor c in string.uppercase[:26]:\n\t  alphabetical_tests.append(prefix + c)\n\tfor c in string.lowercase[:26]:\n\t  alphabetical_tests.append(prefix + c)\n\talphabetical_tests.sort()\n\tself.baseTest(\n\t\t'Alphabetical', [], alphabetical_tests)\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "shardingRangeTestHelper", "data": "  def shardingRangeTestHelper(self, total_shards, num_tests):\n\tshard_ranges = []\n\tfor shard_index in xrange(0, total_shards):\n\t  shard_ranges.append(run_browser_tests._TestRangeForShard(\n\t\t  total_shards, shard_index, num_tests))\n\t# Make assertions about ranges\n\tnum_tests_run = 0\n\tfor i in xrange(0, len(shard_ranges)):\n\t  cur_range = shard_ranges[i]\n\t  if i < num_tests:\n\t\tself.assertGreater(cur_range[1], cur_range[0])\n\t\tnum_tests_run += (cur_range[1] - cur_range[0])\n\t  else:\n\t\t# Not enough tests to go around all of the shards.\n\t\tself.assertEquals(cur_range[0], cur_range[1])\n\t# Make assertions about non-overlapping ranges\n\tfor i in xrange(1, len(shard_ranges)):\n\t  prev_range = shard_ranges[i - 1]\n\t  cur_range = shard_ranges[i]\n\t  self.assertEquals(prev_range[1], cur_range[0])\n\t# Assert that we run all of the tests (very important)\n\tself.assertEquals(num_tests_run, num_tests)\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "testShardsWithPrimeNumTests", "data": "  def testShardsWithPrimeNumTests(self):\n\tfor total_shards in xrange(1, 20):\n\t  # Nice non-prime number\n\t  self.shardingRangeTestHelper(total_shards, 101)\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "testShardsWithDivisibleNumTests", "data": "  def testShardsWithDivisibleNumTests(self):\n\tfor total_shards in xrange(1, 6):\n\t  self.shardingRangeTestHelper(total_shards, 8)\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "testShardBoundaryConditions", "data": "  def testShardBoundaryConditions(self):\n\tself.shardingRangeTestHelper(1, 0)\n\tself.shardingRangeTestHelper(1, 1)\n\tself.shardingRangeTestHelper(2, 1)\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "baseShardingTest", "data": "  def baseShardingTest(self, total_shards, shard_index, failures, successes,\n\t\t\t\t\t   opt_abbr_input_json_file=None,\n\t\t\t\t\t   opt_test_filter='',\n\t\t\t\t\t   opt_filter_tests_after_sharding=False):\n\tconfig = project_config.ProjectConfig(\n\t\ttop_level_dir=os.path.join(util.GetTelemetryDir(), 'examples'),\n\t\tclient_configs=[],\n\t\tbenchmark_dirs=[\n\t\t\tos.path.join(util.GetTelemetryDir(), 'examples', 'browser_tests')]\n\t)\n\ttemp_file = tempfile.NamedTemporaryFile(delete=False)\n\ttemp_file.close()\n\ttemp_file_name = temp_file.name\n\topt_args = []\n\tif opt_abbr_input_json_file:\n\t  opt_args += [\n\t\t  '--read-abbreviated-json-results-from=%s' % opt_abbr_input_json_file]\n\tif opt_test_filter:\n\t  opt_args += [\n\t\t  '--test-filter=%s' % opt_test_filter]\n\tif opt_filter_tests_after_sharding:\n\t  opt_args += ['--filter-tests-after-sharding']\n\ttry:\n\t  browser_test_runner.Run(\n\t\t  config,\n\t\t  ['SimpleShardingTest',\n\t\t   '--write-full-results-to=%s' % temp_file_name,\n\t\t   '--total-shards=%d' % total_shards,\n\t\t   '--shard-index=%d' % shard_index] + opt_args)\n\t  with open(temp_file_name) as f:\n\t\ttest_result = json.load(f)\n\t  actual_successes, actual_failures = self._ExtractTestResults(test_result)\n\t  self.assertEquals(set(actual_failures), set(failures))\n\t  self.assertEquals(set(actual_successes), set(successes))\n\tfinally:\n\t  os.remove(temp_file_name)\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "testShardedTestRun", "data": "  def testShardedTestRun(self):\n\tself.baseShardingTest(3, 0, [], [\n\t\t'browser_tests.simple_sharding_test.SimpleShardingTest.Test1',\n\t\t'browser_tests.simple_sharding_test.SimpleShardingTest.Test2',\n\t\t'browser_tests.simple_sharding_test.SimpleShardingTest.Test3',\n\t\t'browser_tests.simple_sharding_test.SimpleShardingTest.passing_test_0',\n\t\t'browser_tests.simple_sharding_test.SimpleShardingTest.passing_test_1',\n\t])\n\tself.baseShardingTest(3, 1, [], [\n\t\t'browser_tests.simple_sharding_test.SimpleShardingTest.passing_test_2',\n\t\t'browser_tests.simple_sharding_test.SimpleShardingTest.passing_test_3',\n\t\t'browser_tests.simple_sharding_test.SimpleShardingTest.passing_test_4',\n\t\t'browser_tests.simple_sharding_test.SimpleShardingTest.passing_test_5',\n\t])\n\tself.baseShardingTest(3, 2, [], [\n\t\t'browser_tests.simple_sharding_test.SimpleShardingTest.passing_test_6',\n\t\t'browser_tests.simple_sharding_test.SimpleShardingTest.passing_test_7',\n\t\t'browser_tests.simple_sharding_test.SimpleShardingTest.passing_test_8',\n\t\t'browser_tests.simple_sharding_test.SimpleShardingTest.passing_test_9',\n\t])\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "writeMockTestResultsFile", "data": "  def writeMockTestResultsFile(self):\n\tmock_test_results = {\n\t\t'passes': [\n\t\t\t'Test1',\n\t\t\t'Test2',\n\t\t\t'Test3',\n\t\t\t'passing_test_0',\n\t\t\t'passing_test_1',\n\t\t\t'passing_test_2',\n\t\t\t'passing_test_3',\n\t\t\t'passing_test_4',\n\t\t\t'passing_test_5',\n\t\t\t'passing_test_6',\n\t\t\t'passing_test_7',\n\t\t\t'passing_test_8',\n\t\t\t'passing_test_9',\n\t\t],\n\t\t'failures': [],\n\t\t'valid': True,\n\t\t'times': {\n\t\t\t'Test1': 3.0,\n\t\t\t'Test2': 3.0,\n\t\t\t'Test3': 3.0,\n\t\t\t'passing_test_0': 3.0,\n\t\t\t'passing_test_1': 2.0,\n\t\t\t'passing_test_2': 2.0,\n\t\t\t'passing_test_3': 2.0,\n\t\t\t'passing_test_4': 2.0,\n\t\t\t'passing_test_5': 1.0,\n\t\t\t'passing_test_6': 1.0,\n\t\t\t'passing_test_7': 1.0,\n\t\t\t'passing_test_8': 1.0,\n\t\t\t'passing_test_9': 0.5,\n\t\t}\n\t}\n\ttemp_file = tempfile.NamedTemporaryFile(delete=False)\n\ttemp_file.close()\n\ttemp_file_name = temp_file.name\n\twith open(temp_file_name, 'w') as f:\n\t  json.dump(mock_test_results, f)\n\treturn temp_file_name\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "testSplittingShardsByTimes", "data": "  def testSplittingShardsByTimes(self):\n\ttemp_file_name = self.writeMockTestResultsFile()\n\t# It seems that the sorting order of the first four tests above is:\n\t#   passing_test_0, Test1, Test2, Test3\n\t# This is probably because the relative order of the \"fixed\" tests\n\t# (starting with \"Test\") and the generated ones (\"passing_\") is\n\t# not well defined, and the sorting is stable afterward.  The\n\t# expectations have been adjusted for this fact.\n\ttry:\n\t  self.baseShardingTest(4, 0, [], [\n\t\t  'browser_tests.simple_sharding_test' +\n\t\t  '.SimpleShardingTest.passing_test_0',\n\t\t  'browser_tests.simple_sharding_test' +\n\t\t  '.SimpleShardingTest.passing_test_1',\n\t\t  'browser_tests.simple_sharding_test' +\n\t\t  '.SimpleShardingTest.passing_test_5',\n\t\t  'browser_tests.simple_sharding_test' +\n\t\t  '.SimpleShardingTest.passing_test_9'\n\t  ], temp_file_name)\n\t  self.baseShardingTest(4, 1, [], [\n\t\t  'browser_tests.simple_sharding_test' +\n\t\t  '.SimpleShardingTest.Test1',\n\t\t  'browser_tests.simple_sharding_test' +\n\t\t  '.SimpleShardingTest.passing_test_2',\n\t\t  'browser_tests.simple_sharding_test' +\n\t\t  '.SimpleShardingTest.passing_test_6'\n\t  ], temp_file_name)\n\t  self.baseShardingTest(4, 2, [], [\n\t\t  'browser_tests.simple_sharding_test' +\n\t\t  '.SimpleShardingTest.Test2',\n\t\t  'browser_tests.simple_sharding_test' +\n\t\t  '.SimpleShardingTest.passing_test_3',\n\t\t  'browser_tests.simple_sharding_test' +\n\t\t  '.SimpleShardingTest.passing_test_7'\n\t  ], temp_file_name)\n\t  self.baseShardingTest(4, 3, [], [\n\t\t  'browser_tests.simple_sharding_test.SimpleShardingTest.Test3',\n\t\t  'browser_tests.simple_sharding_test' +\n\t\t  '.SimpleShardingTest.passing_test_4',\n\t\t  'browser_tests.simple_sharding_test' +\n\t\t  '.SimpleShardingTest.passing_test_8'\n\t  ], temp_file_name)\n\tfinally:\n\t  os.remove(temp_file_name)\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "testFilteringAfterSharding", "data": "  def testFilteringAfterSharding(self):\n\ttemp_file_name = self.writeMockTestResultsFile()\n\ttry:\n\t  self.baseShardingTest(\n\t\t  4, 1, [],\n\t\t  ['browser_tests.simple_sharding_test.SimpleShardingTest.Test1',\n\t\t   'browser_tests.simple_sharding_test' +\n\t\t   '.SimpleShardingTest.passing_test_2',\n\t\t   'browser_tests.simple_sharding_test' +\n\t\t   '.SimpleShardingTest.passing_test_6'\n\t\t  ], temp_file_name,\n\t\t  opt_test_filter='(Test1|passing_test_2|passing_test_6)',\n\t\t  opt_filter_tests_after_sharding=True)\n\tfinally:\n\t  os.remove(temp_file_name)\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "testMedianComputation", "data": "  def testMedianComputation(self):\n\tself.assertEquals(2.0, run_browser_tests._MedianTestTime(\n\t\t{'test1': 2.0, 'test2': 7.0, 'test3': 1.0}))\n\tself.assertEquals(2.0, run_browser_tests._MedianTestTime(\n\t\t{'test1': 2.0}))\n\tself.assertEquals(0.0, run_browser_tests._MedianTestTime({}))\n\tself.assertEqual(4.0, run_browser_tests._MedianTestTime(\n\t\t{'test1': 2.0, 'test2': 6.0, 'test3': 1.0, 'test4': 8.0}))\n\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "class", "name": "Algebra", "data": "class Algebra(\n\tserially_executed_browser_test_case.SeriallyExecutedBrowserTestCase):\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "GenerateTestCases_Simple", "data": "  def GenerateTestCases_Simple(cls, options):\n\tdel options  # Unused.\n\tyield 'testOne', (1, 2)\n\tyield 'testTwo', (3, 3)\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "Simple", "data": "  def Simple(self, x, y):\n\tself.assertEquals(x, y)\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "TestNumber", "data": "  def TestNumber(self):\n\tself.assertEquals(0, 1)\n\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "class", "name": "ErrorneousGeometric", "data": "class ErrorneousGeometric(\n\tserially_executed_browser_test_case.SeriallyExecutedBrowserTestCase):\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "GenerateTestCases_Compare", "data": "  def GenerateTestCases_Compare(cls, options):\n\tdel options  # Unused.\n\tassert False, 'I am a problematic generator'\n\tyield 'testBasic', ('square', 'circle')\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "Compare", "data": "  def Compare(self, x, y):\n\tself.assertEquals(x, y)\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "TestAngle", "data": "  def TestAngle(self):\n\tself.assertEquals(90, 450)\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}, {"term": "def", "name": "testLoadAllTestsInModule", "data": "  def testLoadAllTestsInModule(self):\n\tcontext = browser_test_context.TypTestContext()\n\tcontext.finder_options = options_for_unittests.GetCopy()\n\tcontext.test_class = Algebra\n\tcontext.test_case_ids_to_run.add(\n\t\t'telemetry.testing.browser_test_runner_unittest.Algebra.TestNumber')\n\tcontext.test_case_ids_to_run.add(\n\t\t'telemetry.testing.browser_test_runner_unittest.Algebra.testOne')\n\tcontext.Freeze()\n\tbrowser_test_context._global_test_context = context\n\ttry:\n\t  # This should not invoke GenerateTestCases of ErrorneousGeometric class,\n\t  # otherwise that would throw Exception.\n\t  tests = serially_executed_browser_test_case.LoadAllTestsInModule(\n\t\t  sys.modules[__name__])\n\t  self.assertEquals(\n\t\t  sorted([t.id() for t in tests]),\n\t\t  ['telemetry.testing.browser_test_runner_unittest.Algebra.TestNumber',\n\t\t   'telemetry.testing.browser_test_runner_unittest.Algebra.testOne'])\n\tfinally:\n\t  browser_test_context._global_test_context = None\n", "description": null, "category": "simple", "imports": ["import os", "import string", "import sys", "import tempfile", "import unittest", "import json", "from telemetry import decorators", "from telemetry import project_config", "from telemetry.core import util", "from telemetry.testing import browser_test_context", "from telemetry.testing import browser_test_runner", "from telemetry.testing import options_for_unittests", "from telemetry.testing import run_browser_tests", "from telemetry.testing import serially_executed_browser_test_case", "\t# Assert that we run all of the tests (very important)"]}], [{"term": "def", "name": "trim", "data": "def trim(value, num):\n\treturn value[:num]\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "make_data_div", "data": "def make_data_div(value):\n\t\"\"\"A filter that uses a decorator (@mark_safe).\"\"\"\n\treturn '' % value\n\n", "description": "A filter that uses a decorator (@mark_safe).", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "noop", "data": "def noop(value, param=None):\n\t\"\"\"A noop filter that always return its first argument and does nothing with\n\tits second (optional) one.\n\tUseful for testing out whitespace in filter arguments (see #19882).\"\"\"\n\treturn value\n\n", "description": "A noop filter that always return its first argument and does nothing with\n\tits second (optional) one.\n\tUseful for testing out whitespace in filter arguments (see #19882).", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "context_stack_length", "data": "def context_stack_length(context):\n\treturn len(context.dicts)\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "no_params", "data": "def no_params():\n\t\"\"\"Expected no_params __doc__\"\"\"\n\treturn \"no_params - Expected result\"\n\n", "description": "Expected no_params __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "one_param", "data": "def one_param(arg):\n\t\"\"\"Expected one_param __doc__\"\"\"\n\treturn \"one_param - Expected result: %s\" % arg\n\n", "description": "Expected one_param __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "explicit_no_context", "data": "def explicit_no_context(arg):\n\t\"\"\"Expected explicit_no_context __doc__\"\"\"\n\treturn \"explicit_no_context - Expected result: %s\" % arg\n\n", "description": "Expected explicit_no_context __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "no_params_with_context", "data": "def no_params_with_context(context):\n\t\"\"\"Expected no_params_with_context __doc__\"\"\"\n\treturn \"no_params_with_context - Expected result (context value: %s)\" % context['value']\n\n", "description": "Expected no_params_with_context __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "params_and_context", "data": "def params_and_context(context, arg):\n\t\"\"\"Expected params_and_context __doc__\"\"\"\n\treturn \"params_and_context - Expected result (context value: %s): %s\" % (context['value'], arg)\n\n", "description": "Expected params_and_context __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_two_params", "data": "def simple_two_params(one, two):\n\t\"\"\"Expected simple_two_params __doc__\"\"\"\n\treturn \"simple_two_params - Expected result: %s, %s\" % (one, two)\n\n", "description": "Expected simple_two_params __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_keyword_only_param", "data": "def simple_keyword_only_param(*, kwarg):\n\treturn \"simple_keyword_only_param - Expected result: %s\" % kwarg\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_keyword_only_default", "data": "def simple_keyword_only_default(*, kwarg=42):\n\treturn \"simple_keyword_only_default - Expected result: %s\" % kwarg\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_one_default", "data": "def simple_one_default(one, two='hi'):\n\t\"\"\"Expected simple_one_default __doc__\"\"\"\n\treturn \"simple_one_default - Expected result: %s, %s\" % (one, two)\n\n", "description": "Expected simple_one_default __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_unlimited_args", "data": "def simple_unlimited_args(one, two='hi', *args):\n\t\"\"\"Expected simple_unlimited_args __doc__\"\"\"\n\treturn \"simple_unlimited_args - Expected result: %s\" % (\n\t\t', '.join(str(arg) for arg in [one, two] + list(args))\n\t)\n\n", "description": "Expected simple_unlimited_args __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_only_unlimited_args", "data": "def simple_only_unlimited_args(*args):\n\t\"\"\"Expected simple_only_unlimited_args __doc__\"\"\"\n\treturn \"simple_only_unlimited_args - Expected result: %s\" % ', '.join(str(arg) for arg in args)\n\n", "description": "Expected simple_only_unlimited_args __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_unlimited_args_kwargs", "data": "def simple_unlimited_args_kwargs(one, two='hi', *args, **kwargs):\n\t\"\"\"Expected simple_unlimited_args_kwargs __doc__\"\"\"\n\t# Sort the dictionary by key to guarantee the order for testing.\n\tsorted_kwarg = sorted(kwargs.items(), key=operator.itemgetter(0))\n\treturn \"simple_unlimited_args_kwargs - Expected result: %s / %s\" % (\n\t\t', '.join(str(arg) for arg in [one, two] + list(args)),\n\t\t', '.join('%s=%s' % (k, v) for (k, v) in sorted_kwarg)\n\t)\n\n", "description": "Expected simple_unlimited_args_kwargs __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_tag_without_context_parameter", "data": "def simple_tag_without_context_parameter(arg):\n\t\"\"\"Expected simple_tag_without_context_parameter __doc__\"\"\"\n\treturn \"Expected result\"\n\n", "description": "Expected simple_tag_without_context_parameter __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "escape_naive", "data": "def escape_naive(context):\n\t\"\"\"A tag that doesn't even think about escaping issues\"\"\"\n\treturn \"Hello {0}!\".format(context['name'])\n\n", "description": "A tag that doesn't even think about escaping issues", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "escape_explicit", "data": "def escape_explicit(context):\n\t\"\"\"A tag that uses escape explicitly\"\"\"\n\treturn escape(\"Hello {0}!\".format(context['name']))\n\n", "description": "A tag that uses escape explicitly", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "escape_format_html", "data": "def escape_format_html(context):\n\t\"\"\"A tag that uses format_html\"\"\"\n\treturn format_html(\"Hello {0}!\", context['name'])\n\n", "description": "A tag that uses format_html", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "current_app", "data": "def current_app(context):\n\treturn \"%s\" % context.current_app\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "use_l10n", "data": "def use_l10n(context):\n\treturn \"%s\" % context.use_l10n\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "minustwo_overridden_name", "data": "def minustwo_overridden_name(value):\n\treturn value - 2\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "counter", "data": "def counter(parser, token):\n\treturn CounterNode()\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "class", "name": "CounterNode", "data": "class CounterNode(template.Node):\n\tdef __init__(self):\n\t\tself.count = 0\n\n\tdef render(self, context):\n\t\tcount = self.count\n\t\tself.count = count + 1\n\t\treturn count\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}], [{"term": "def", "name": "simple", "data": "def simple(e):\n\tcode = e.code\n\n\tif code.endswith('Exception'):\n\t\tcode = code.rstrip('Exception')\n\n\ttry:\n\t\t# Dynamically get the error class.\n\t\tsimple_e = getattr(sys.modules[__name__], code)(e)\n\texcept AttributeError:\n\t\t# Return original exception on failure.\n\t\treturn e\n\n\treturn simple_e\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "SimpleException", "data": "class SimpleException(BotoServerError):\n\tdef __init__(self, e):\n\t\tsuper(SimpleException, self).__init__(e.status, e.reason, e.body)\n\t\tself.error_message = self.message\n\n\tdef __repr__(self):\n\t\treturn self.__class__.__name__ + ': ' + self.error_message\n\tdef __str__(self):\n\t\treturn self.__class__.__name__ + ': ' + self.error_message\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "ValidationError", "data": "class ValidationError(SimpleException): pass\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "Throttling", "data": "class Throttling(SimpleException): pass\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "SourceBundleDeletion", "data": "class SourceBundleDeletion(SimpleException): pass\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}], [{"term": "class", "name": "Simple", "data": "class Simple():\n\tcount = 0\n\n\tdef __init__(self):\n\t\tSimple.count += 1\n\n\t@staticmethod\n\tdef get_count():\n\t\treturn Simple.count\n\n\tdef sm():\n\t\tprint('this is static method')\n\t# sm \ub97c static method \uac00 \ub420 \uc218 \uc788\ub3c4\ub85d \ud55c\ub2e4!!\n\tsm = staticmethod(sm)\n\n\t@staticmethod\n\tdef sm2():\n\t\tprint('this is static method2')\n\n\tdef sm3():\n\t\tprint('this is not static method')\n\t\treturn Simple.count\n\n\t@classmethod\n\tdef sm4(cls):\n\t\tprint('this is class method')\n\t\treturn cls.count\n\n\t@classmethod\n\tdef sm5(cls):\n\t\tprint('this is class method and initialzing..')\n\t\treturn cls()\n\n", "description": null, "category": "simple", "imports": []}, {"term": "def", "name": "main", "data": "def main():\n\tSimple.sm()\n\ts = Simple()\n\ts.sm()\n\tSimple.sm2()\n\tSimple.sm3()\n\ts.sm2()\n\t# s.sm3() # error\n\ts2 = Simple()\n\tprint(s2.get_count())\n\tprint(Simple.get_count())\n\n\t# class method\n\tprint(s2.sm4())\n\n\t# clsss method\n\ts2.sm5()\n\tprint(s2.sm4())\n\n", "description": null, "category": "simple", "imports": []}], [{"term": "def", "name": "test_highlight_merge", "data": "def test_highlight_merge():\n\n\tc = Controllers(dict(index='index'), 'docs', [])\n\n\tsource = {\n\t\t'a': 'a simple string',\n\t\t'ax': 'an unrelated string',\n\t\t'ab': True,\n\t\t'ai': 5,\n\t\t'b': {\n\t\t\t'prop': 'a simple internal property',\n\t\t\t'propx': 'an unrelated internal property',\n\t\t\t'propn': None,\n\t\t\t'propi': 8,\n\t\t\t'propf': 8.0,\n\t\t},\n\t\t'c': [\n\t\t\t{'arrayprop': 'simple'},\n\t\t\t{'arrayprop': 'unrelated'},\n\t\t],\n\t\t'd': ['simple', 'unrelated', 'simple'],\n\t\t'dd': [['simple', 'unrelated'], ['simple']]\n\t}\n\n\thighlights = {\n\t\t'a': ['simple'],\n\t\t'b.prop': ['simple'],\n\t\t'c.arrayprop': ['simple'],\n\t\t'd': ['simple'],\n\t\t'dd': ['simple'],\n\t}\n\n\tsource = c._merge_highlight_into_source(source, highlights, DONT_HIGHLIGHT)\n\n\tassert source == {\n\t\t'a': 'a simple string',\n\t\t'ax': 'an unrelated string',\n\t\t'ab': True,\n\t\t'ai': 5,\n\t\t'b': {\n\t\t\t'prop': 'a simple internal property',\n\t\t\t'propx': 'an unrelated internal property',\n\t\t\t'propn': None,\n\t\t\t'propi': 8,\n\t\t\t'propf': 8.0,\n\t\t},\n\t\t'c': [\n\t\t\t{'arrayprop': 'simple'},\n\t\t\t{'arrayprop': 'unrelated'},\n\t\t],\n\t\t'd': ['simple', 'unrelated', 'simple'],\n\t\t'dd': [['simple', 'unrelated'], ['simple']]\n", "description": null, "category": "simple", "imports": ["from apies.controllers import Controllers"]}], [], [{"term": "class", "name": "SimpleModel", "data": "class SimpleModel(Model):\n\t\"\"\"Simple Test Model\"\"\"\n\tname = StringProperty()\n\tstrs = ListProperty(str)\n\tnum = IntegerProperty()\n", "description": "Simple Test Model", "category": "simple", "imports": ["from boto.sdb.db.property import ListProperty, StringProperty, ReferenceProperty, IntegerProperty", "from boto.sdb.db.model import Model", "import time"]}, {"term": "class", "name": "SubModel", "data": "class SubModel(SimpleModel):\n\t\"\"\"Simple Subclassed Model\"\"\"\n\tref = ReferenceProperty(SimpleModel, collection_name=\"reverse_ref\")\n\n", "description": "Simple Subclassed Model", "category": "simple", "imports": ["from boto.sdb.db.property import ListProperty, StringProperty, ReferenceProperty, IntegerProperty", "from boto.sdb.db.model import Model", "import time"]}, {"term": "class", "name": "TestQuerying", "data": "class TestQuerying(object):\n\t\"\"\"Test different querying capabilities\"\"\"\n\n\tdef setup_class(cls):\n\t\t\"\"\"Setup this class\"\"\"\n\t\tcls.objs = []\n\n\t\to = SimpleModel()\n\t\to.name = \"Simple Object\"\n\t\to.strs = [\"B\", \"A\", \"C\", \"Foo\"]\n\t\to.num = 1\n\t\to.put()\n\t\tcls.objs.append(o)\n\n\t\to2 = SimpleModel()\n\t\to2.name = \"Referenced Object\"\n\t\to2.num = 2\n\t\to2.put()\n\t\tcls.objs.append(o2)\n\n\t\to3 = SubModel()\n\t\to3.name = \"Sub Object\"\n\t\to3.num = 3\n\t\to3.ref = o2\n\t\to3.put()\n\t\tcls.objs.append(o3)\n\n\t\ttime.sleep(3)\n\n\n\n\tdef teardown_class(cls):\n\t\t\"\"\"Remove our objects\"\"\"\n\t\tfor o in cls.objs:\n\t\t\ttry:\n\t\t\t\to.delete()\n\t\t\texcept:\n\t\t\t\tpass\n\n\tdef test_find(self):\n\t\t\"\"\"Test using the \"Find\" method\"\"\"\n\t\tassert(SimpleModel.find(name=\"Simple Object\").next().id == self.objs[0].id)\n\t\tassert(SimpleModel.find(name=\"Referenced Object\").next().id == self.objs[1].id)\n\t\tassert(SimpleModel.find(name=\"Sub Object\").next().id == self.objs[2].id)\n\n\tdef test_like_filter(self):\n\t\t\"\"\"Test a \"like\" filter\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name like\", \"% Object\")\n\t\tassert(query.count() == 3)\n\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name not like\", \"% Object\")\n\t\tassert(query.count() == 0)\n\n\tdef test_equals_filter(self):\n\t\t\"\"\"Test an \"=\" and \"!=\" filter\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name =\", \"Simple Object\")\n\t\tassert(query.count() == 1)\n\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name !=\", \"Simple Object\")\n\t\tassert(query.count() == 2)\n\n\tdef test_or_filter(self):\n\t\t\"\"\"Test a filter function as an \"or\" \"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name =\", [\"Simple Object\", \"Sub Object\"])\n\t\tassert(query.count() == 2)\n\n\tdef test_and_filter(self):\n\t\t\"\"\"Test Multiple filters which are an \"and\" \"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name like\", \"% Object\")\n\t\tquery.filter(\"name like\", \"Simple %\")\n\t\tassert(query.count() == 1)\n\n\tdef test_none_filter(self):\n\t\t\"\"\"Test filtering for a value that's not set\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"ref =\", None)\n\t\tassert(query.count() == 2)\n\n\tdef test_greater_filter(self):\n\t\t\"\"\"Test filtering Using >, >=\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"num >\", 1)\n\t\tassert(query.count() == 2)\n\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"num >=\", 1)\n\t\tassert(query.count() == 3)\n\n\tdef test_less_filter(self):\n\t\t\"\"\"Test filtering Using <, <=\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"num <\", 3)\n\t\tassert(query.count() == 2)\n\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"num <=\", 3)\n\t\tassert(query.count() == 3)\n\n\tdef test_query_on_list(self):\n\t\t\"\"\"Test querying on a list\"\"\"\n\t\tassert(SimpleModel.find(strs=\"A\").next().id == self.objs[0].id)\n\t\tassert(SimpleModel.find(strs=\"B\").next().id == self.objs[0].id)\n\t\tassert(SimpleModel.find(strs=\"C\").next().id == self.objs[0].id)\n\n\tdef test_like(self):\n\t\t\"\"\"Test with a \"like\" expression\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"strs like\", \"%oo%\")\n\t\tprint query.get_query()\n\t\tassert(query.count() == 1)\n", "description": "Test different querying capabilities", "category": "simple", "imports": ["from boto.sdb.db.property import ListProperty, StringProperty, ReferenceProperty, IntegerProperty", "from boto.sdb.db.model import Model", "import time"]}], [{"term": "class", "name": "SimpleModel", "data": "class SimpleModel(Model):\n\t\"\"\"Simple Test Model\"\"\"\n\tname = StringProperty()\n\tstrs = ListProperty(str)\n\tnum = IntegerProperty()\n", "description": "Simple Test Model", "category": "simple", "imports": ["from boto.sdb.db.property import ListProperty, StringProperty, ReferenceProperty, IntegerProperty", "from boto.sdb.db.model import Model", "import time"]}, {"term": "class", "name": "SubModel", "data": "class SubModel(SimpleModel):\n\t\"\"\"Simple Subclassed Model\"\"\"\n\tref = ReferenceProperty(SimpleModel, collection_name=\"reverse_ref\")\n\n", "description": "Simple Subclassed Model", "category": "simple", "imports": ["from boto.sdb.db.property import ListProperty, StringProperty, ReferenceProperty, IntegerProperty", "from boto.sdb.db.model import Model", "import time"]}, {"term": "class", "name": "TestQuerying", "data": "class TestQuerying(object):\n\t\"\"\"Test different querying capabilities\"\"\"\n\n\tdef setup_class(cls):\n\t\t\"\"\"Setup this class\"\"\"\n\t\tcls.objs = []\n\n\t\to = SimpleModel()\n\t\to.name = \"Simple Object\"\n\t\to.strs = [\"B\", \"A\", \"C\", \"Foo\"]\n\t\to.num = 1\n\t\to.put()\n\t\tcls.objs.append(o)\n\n\t\to2 = SimpleModel()\n\t\to2.name = \"Referenced Object\"\n\t\to2.num = 2\n\t\to2.put()\n\t\tcls.objs.append(o2)\n\n\t\to3 = SubModel()\n\t\to3.name = \"Sub Object\"\n\t\to3.num = 3\n\t\to3.ref = o2\n\t\to3.put()\n\t\tcls.objs.append(o3)\n\n\t\ttime.sleep(3)\n\n\n\n\tdef teardown_class(cls):\n\t\t\"\"\"Remove our objects\"\"\"\n\t\tfor o in cls.objs:\n\t\t\ttry:\n\t\t\t\to.delete()\n\t\t\texcept:\n\t\t\t\tpass\n\n\tdef test_find(self):\n\t\t\"\"\"Test using the \"Find\" method\"\"\"\n\t\tassert(SimpleModel.find(name=\"Simple Object\").next().id == self.objs[0].id)\n\t\tassert(SimpleModel.find(name=\"Referenced Object\").next().id == self.objs[1].id)\n\t\tassert(SimpleModel.find(name=\"Sub Object\").next().id == self.objs[2].id)\n\n\tdef test_like_filter(self):\n\t\t\"\"\"Test a \"like\" filter\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name like\", \"% Object\")\n\t\tassert(query.count() == 3)\n\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name not like\", \"% Object\")\n\t\tassert(query.count() == 0)\n\n\tdef test_equals_filter(self):\n\t\t\"\"\"Test an \"=\" and \"!=\" filter\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name =\", \"Simple Object\")\n\t\tassert(query.count() == 1)\n\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name !=\", \"Simple Object\")\n\t\tassert(query.count() == 2)\n\n\tdef test_or_filter(self):\n\t\t\"\"\"Test a filter function as an \"or\" \"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name =\", [\"Simple Object\", \"Sub Object\"])\n\t\tassert(query.count() == 2)\n\n\tdef test_and_filter(self):\n\t\t\"\"\"Test Multiple filters which are an \"and\" \"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name like\", \"% Object\")\n\t\tquery.filter(\"name like\", \"Simple %\")\n\t\tassert(query.count() == 1)\n\n\tdef test_none_filter(self):\n\t\t\"\"\"Test filtering for a value that's not set\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"ref =\", None)\n\t\tassert(query.count() == 2)\n\n\tdef test_greater_filter(self):\n\t\t\"\"\"Test filtering Using >, >=\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"num >\", 1)\n\t\tassert(query.count() == 2)\n\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"num >=\", 1)\n\t\tassert(query.count() == 3)\n\n\tdef test_less_filter(self):\n\t\t\"\"\"Test filtering Using <, <=\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"num <\", 3)\n\t\tassert(query.count() == 2)\n\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"num <=\", 3)\n\t\tassert(query.count() == 3)\n\n\tdef test_query_on_list(self):\n\t\t\"\"\"Test querying on a list\"\"\"\n\t\tassert(SimpleModel.find(strs=\"A\").next().id == self.objs[0].id)\n\t\tassert(SimpleModel.find(strs=\"B\").next().id == self.objs[0].id)\n\t\tassert(SimpleModel.find(strs=\"C\").next().id == self.objs[0].id)\n\n\tdef test_like(self):\n\t\t\"\"\"Test with a \"like\" expression\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"strs like\", \"%oo%\")\n\t\tprint query.get_query()\n\t\tassert(query.count() == 1)\n", "description": "Test different querying capabilities", "category": "simple", "imports": ["from boto.sdb.db.property import ListProperty, StringProperty, ReferenceProperty, IntegerProperty", "from boto.sdb.db.model import Model", "import time"]}], [{"term": "class", "name": "SimpleModel", "data": "class SimpleModel(Model):\n\t\"\"\"Simple Test Model\"\"\"\n\tname = StringProperty()\n\tstrs = ListProperty(str)\n\tnum = IntegerProperty()\n", "description": "Simple Test Model", "category": "simple", "imports": ["from boto.sdb.db.property import ListProperty, StringProperty, ReferenceProperty, IntegerProperty", "from boto.sdb.db.model import Model", "import time"]}, {"term": "class", "name": "SubModel", "data": "class SubModel(SimpleModel):\n\t\"\"\"Simple Subclassed Model\"\"\"\n\tref = ReferenceProperty(SimpleModel, collection_name=\"reverse_ref\")\n\n", "description": "Simple Subclassed Model", "category": "simple", "imports": ["from boto.sdb.db.property import ListProperty, StringProperty, ReferenceProperty, IntegerProperty", "from boto.sdb.db.model import Model", "import time"]}, {"term": "class", "name": "TestQuerying", "data": "class TestQuerying(object):\n\t\"\"\"Test different querying capabilities\"\"\"\n\n\tdef setup_class(cls):\n\t\t\"\"\"Setup this class\"\"\"\n\t\tcls.objs = []\n\n\t\to = SimpleModel()\n\t\to.name = \"Simple Object\"\n\t\to.strs = [\"B\", \"A\", \"C\", \"Foo\"]\n\t\to.num = 1\n\t\to.put()\n\t\tcls.objs.append(o)\n\n\t\to2 = SimpleModel()\n\t\to2.name = \"Referenced Object\"\n\t\to2.num = 2\n\t\to2.put()\n\t\tcls.objs.append(o2)\n\n\t\to3 = SubModel()\n\t\to3.name = \"Sub Object\"\n\t\to3.num = 3\n\t\to3.ref = o2\n\t\to3.put()\n\t\tcls.objs.append(o3)\n\n\t\ttime.sleep(3)\n\n\n\n\tdef teardown_class(cls):\n\t\t\"\"\"Remove our objects\"\"\"\n\t\tfor o in cls.objs:\n\t\t\ttry:\n\t\t\t\to.delete()\n\t\t\texcept:\n\t\t\t\tpass\n\n\tdef test_find(self):\n\t\t\"\"\"Test using the \"Find\" method\"\"\"\n\t\tassert(SimpleModel.find(name=\"Simple Object\").next().id == self.objs[0].id)\n\t\tassert(SimpleModel.find(name=\"Referenced Object\").next().id == self.objs[1].id)\n\t\tassert(SimpleModel.find(name=\"Sub Object\").next().id == self.objs[2].id)\n\n\tdef test_like_filter(self):\n\t\t\"\"\"Test a \"like\" filter\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name like\", \"% Object\")\n\t\tassert(query.count() == 3)\n\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name not like\", \"% Object\")\n\t\tassert(query.count() == 0)\n\n\tdef test_equals_filter(self):\n\t\t\"\"\"Test an \"=\" and \"!=\" filter\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name =\", \"Simple Object\")\n\t\tassert(query.count() == 1)\n\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name !=\", \"Simple Object\")\n\t\tassert(query.count() == 2)\n\n\tdef test_or_filter(self):\n\t\t\"\"\"Test a filter function as an \"or\" \"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name =\", [\"Simple Object\", \"Sub Object\"])\n\t\tassert(query.count() == 2)\n\n\tdef test_and_filter(self):\n\t\t\"\"\"Test Multiple filters which are an \"and\" \"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name like\", \"% Object\")\n\t\tquery.filter(\"name like\", \"Simple %\")\n\t\tassert(query.count() == 1)\n\n\tdef test_none_filter(self):\n\t\t\"\"\"Test filtering for a value that's not set\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"ref =\", None)\n\t\tassert(query.count() == 2)\n\n\tdef test_greater_filter(self):\n\t\t\"\"\"Test filtering Using >, >=\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"num >\", 1)\n\t\tassert(query.count() == 2)\n\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"num >=\", 1)\n\t\tassert(query.count() == 3)\n\n\tdef test_less_filter(self):\n\t\t\"\"\"Test filtering Using <, <=\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"num <\", 3)\n\t\tassert(query.count() == 2)\n\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"num <=\", 3)\n\t\tassert(query.count() == 3)\n\n\tdef test_query_on_list(self):\n\t\t\"\"\"Test querying on a list\"\"\"\n\t\tassert(SimpleModel.find(strs=\"A\").next().id == self.objs[0].id)\n\t\tassert(SimpleModel.find(strs=\"B\").next().id == self.objs[0].id)\n\t\tassert(SimpleModel.find(strs=\"C\").next().id == self.objs[0].id)\n\n\tdef test_like(self):\n\t\t\"\"\"Test with a \"like\" expression\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"strs like\", \"%oo%\")\n\t\tprint query.get_query()\n\t\tassert(query.count() == 1)\n", "description": "Test different querying capabilities", "category": "simple", "imports": ["from boto.sdb.db.property import ListProperty, StringProperty, ReferenceProperty, IntegerProperty", "from boto.sdb.db.model import Model", "import time"]}], [{"term": "class", "name": "Test_SimpleTree", "data": "class Test_SimpleTree(unittest.TestCase):\n\n\tdef test_add_child(self):\n\t\t# add first to empty\n\t\tnode1 = SimpleTreeNode('a', None)\n\t\ttree = SimpleTree(None)\n\t\ttree.AddChild(None, node1)\n\t\tself.assertEqual(tree.Root, node1)\n\t\tself.assertEqual(tree.Root.NodeValue, 'a')\n\t\tself.assertEqual(tree.Root.Parent, None)\n\t\tself.assertEqual(tree.Root.Children, [])\n\t\t# add second\n\t\tnode2 = SimpleTreeNode('b', node1)\n\t\ttree.AddChild(node1, node2)\n\t\tself.assertEqual(tree.Root, node1)\n\t\tself.assertEqual(tree.Root.NodeValue, 'a')\n\t\tself.assertEqual(tree.Root.Parent, None)\n\t\tself.assertEqual(tree.Root.Children, [node2])\n\t\tself.assertEqual(node2.Parent, node1)\n\t\tself.assertEqual(node2.Children, [])\n\t\t# add third to second\n\t\tnode3 = SimpleTreeNode('c', node2)\n\t\ttree.AddChild(node2, node3)\n\t\tself.assertEqual(tree.Root, node1)\n\t\tself.assertEqual(tree.Root.Children, [node2])\n\t\tself.assertEqual(node2.Children, [node3])\n\t\tself.assertEqual(node3.Parent, node2)\n\t\tself.assertEqual(node3.Children, [])\n\t\t# add fourth to first\n\t\tnode4 = SimpleTreeNode('d', node1)\n\t\ttree.AddChild(node1, node4)\n\t\tself.assertEqual(tree.Root, node1)\n\t\tself.assertEqual(tree.Root.Children, [node2, node4])\n\t\tself.assertEqual(node4.Parent, node1)\n\t\tself.assertEqual(node4.Children, [])\n\t\tself.assertEqual(node3.Parent, node2)\n\t\tself.assertEqual(node3.Children, [])\n\n\tdef test_get_all_nodes(self):\n\t\t# empty\n\t\ttree = SimpleTree(None)\n\t\tnodes = tree.GetAllNodes()\n\t\tself.assertEqual(nodes, [None])\n\t\t# full\n\t\tnode1 = SimpleTreeNode('a', None)\n\t\ttree = SimpleTree(None)\n\t\ttree.AddChild(None, node1)\n\t\tnode2 = SimpleTreeNode('b', node1)\n\t\ttree.AddChild(node1, node2)\n\t\tnode3 = SimpleTreeNode('c', node2)\n\t\ttree.AddChild(node2, node3)\n\t\tnode4 = SimpleTreeNode('d', node1)\n\t\ttree.AddChild(node1, node4)\n\t\tnodes = tree.GetAllNodes()\n\t\tself.assertEqual(nodes, [node1, node2, node3, node4])\n\n\tdef test_delete_node(self):\n\t\t# from empty\n\t\ttree = SimpleTree(None)\n\t\tnode_to_del = SimpleTreeNode('a', None)\n\t\ttree.DeleteNode(node_to_del)\n\t\tself.assertEqual(tree.Root, None)\n\t\t# from unitary\n\t\tnode1 = SimpleTreeNode('a', None)\n\t\ttree.AddChild(None, node1)\n\t\ttree.DeleteNode(node_to_del)\n\t\tself.assertEqual(tree.Root, None)\n\t\t# del non-existing\n\t\tnode_to_del = SimpleTreeNode('1', None)\n\t\ttree.AddChild(None, node1)\n\t\tnode2 = SimpleTreeNode('b', node1)\n\t\ttree.AddChild(node1, node2)\n\t\tnode3 = SimpleTreeNode('c', node2)\n\t\ttree.AddChild(node2, node3)\n\t\tnode4 = SimpleTreeNode('d', node1)\n\t\ttree.AddChild(node1, node4)\n\t\ttree.DeleteNode(node_to_del)\n\t\tself.assertEqual(tree.Root, node1)\n\t\tself.assertEqual(tree.Root.NodeValue, 'a')\n\t\tself.assertEqual(tree.Root.Parent, None)\n\t\tself.assertEqual(tree.Root.Children, [node2, node4])\n\t\tself.assertEqual(node2.Parent, node1)\n\t\tself.assertEqual(node2.Children, [node3])\n\t\tself.assertEqual(node3.Parent, node2)\n\t\tself.assertEqual(node3.Children, [])\n\t\tself.assertEqual(node4.Parent, node1)\n\t\tself.assertEqual(node4.Children, [])\n\t\t# del existing leaf\n\t\tleaf_to_del = SimpleTreeNode('c', None)\n\t\ttree.DeleteNode(leaf_to_del)\n\t\tself.assertEqual(tree.Root, node1)\n\t\tself.assertEqual(tree.Root.NodeValue, 'a')\n\t\tself.assertEqual(tree.Root.Parent, None)\n\t\tself.assertEqual(tree.Root.Children, [node2, node4])\n\t\tself.assertEqual(node2.Parent, node1)\n\t\tself.assertEqual(node2.Children, [])\n\t\tself.assertEqual(node3.Parent, None)\n\t\tself.assertEqual(node3.Children, [])\n\t\tself.assertEqual(node4.Parent, node1)\n\t\tself.assertEqual(node4.Children, [])\n\t\t# del existing node\n\t\ttree.AddChild(node2, node3)\n\t\tnode_to_del = SimpleTreeNode('b', None)\n\t\ttree.DeleteNode(node_to_del)\n\t\tself.assertEqual(tree.Root, node1)\n\t\tself.assertEqual(tree.Root.NodeValue, 'a')\n\t\tself.assertEqual(tree.Root.Parent, None)\n\t\tself.assertEqual(tree.Root.Children, [node4])\n\t\tself.assertEqual(node2.Parent, None)\n\t\t# del root from tree\n\t\troot_to_del = SimpleTreeNode('a', None)\n\t\ttree.DeleteNode(root_to_del)\n\t\tself.assertEqual(tree.Root, None)\n\n\tdef test_find_node(self):\n\t\t# find in empty\n\t\ttree = SimpleTree(None)\n\t\tself.assertEqual(tree.FindNodesByValue('a'), [])\n\t\t# find non-existing\n\t\tnode1 = SimpleTreeNode('a', None)\n\t\ttree.AddChild(None, node1)\n\t\tnode2 = SimpleTreeNode('b', node1)\n\t\ttree.AddChild(node1, node2)\n\t\tnode3 = SimpleTreeNode('c', node2)\n\t\ttree.AddChild(node2, node3)\n\t\tnode4 = SimpleTreeNode('d', node1)\n\t\ttree.AddChild(node1, node4)\n\t\tself.assertEqual(tree.FindNodesByValue('e'), [])\n\t\t# find existing\n\t\tself.assertEqual(tree.FindNodesByValue('a')[0].NodeValue, 'a')\n\t\tself.assertEqual(len(tree.FindNodesByValue('a')), 1)\n\t\t# find several existing\n\t\tnode5 = SimpleTreeNode('a', None)\n\t\ttree.AddChild(node4, node5)\n\t\tself.assertEqual(tree.FindNodesByValue('a'), [node1, node5])\n\n\tdef test_move_node(self):\n\t\t# move from empty\n\t\ttree = SimpleTree(None)\n\t\tnode1 = SimpleTreeNode('a', None)\n\t\tnode2 = SimpleTreeNode('b', None)\n\t\ttree.MoveNode(node1, node2)\n\t\tself.assertEqual(tree.Root, None)\n\t\ttree.MoveNode(None, None)\n\t\tself.assertEqual(tree.Root, None)\n\t\t# move non-existing node\n\t\tnon_existing_node = SimpleTreeNode('1', None)\n\t\ttree.AddChild(None, node1)\n\t\ttree.AddChild(node1, node2)\n\t\ttree.MoveNode(non_existing_node, node2)\n\t\tself.assertEqual(tree.Root, node1)\n\t\tself.assertEqual(tree.Root.NodeValue, 'a')\n\t\tself.assertEqual(tree.Root.Parent, None)\n\t\tself.assertEqual(tree.Root.Children, [node2])\n\t\tself.assertEqual(node2.Parent, node1)\n\t\tself.assertEqual(node2.Children, [])\n\t\t# move to non-existing node\n\t\tnode3 = SimpleTreeNode('c', node2)\n\t\ttree.AddChild(node2, node3)\n\t\tnode4 = SimpleTreeNode('d', node1)\n\t\ttree.AddChild(node1, node4)\n\t\ttree.MoveNode(non_existing_node, node2)\n\t\tself.assertEqual(tree.Root, node1)\n\t\tself.assertEqual(tree.Root.NodeValue, 'a')\n\t\tself.assertEqual(tree.Root.Parent, None)\n\t\tself.assertEqual(tree.Root.Children, [node2, node4])\n\t\tself.assertEqual(node2.Parent, node1)\n\t\tself.assertEqual(node3.Parent, node2)\n\t\tself.assertEqual(node3.Children, [])\n\t\tself.assertEqual(node4.Parent, node1)\n\t\tself.assertEqual(node4.Children, [])\n\t\t# move root\n\t\ttree.MoveNode(node1, node2)\n\t\tself.assertEqual(tree.Root, node1)\n\t\tself.assertEqual(tree.Root.NodeValue, 'a')\n\t\tself.assertEqual(tree.Root.Parent, None)\n\t\tself.assertEqual(tree.Root.Children, [node2, node4])\n\t\tself.assertEqual(node2.Parent, node1)\n\t\tself.assertEqual(node3.Parent, node2)\n\t\tself.assertEqual(node3.Children, [])\n\t\tself.assertEqual(node4.Parent, node1)\n\t\tself.assertEqual(node4.Children, [])\n\t\t# move to root\n\t\ttree.MoveNode(node3, node1)\n\t\tself.assertEqual(node2.Children, [])\n\t\tself.assertEqual(len(node1.Children), 3)\n\t\tself.assertEqual(node2 in node1.Children,True)\n\t\tself.assertEqual(node3 in node1.Children,True)\n\t\tself.assertEqual(node4 in node1.Children,True)\n\t\t# move existing\n\t\tnode5 = SimpleTreeNode('e', None)\n\t\ttree.AddChild(node2, node5)\n\t\tnode6 = SimpleTreeNode('f', None)\n\t\ttree.AddChild(node5, node6)\n\t\ttree.MoveNode(node5, node3)\n\t\tself.assertEqual(node2.Children, [])\n\t\tself.assertEqual(node3.Children, [node5])\n\t\tself.assertEqual(node5.Children, [node6])\n\n\tdef test_count(self):\n\t\t# count empty\n\t\ttree = SimpleTree(None)\n\t\tself.assertEqual(tree.Count(), 0)\n\t\t# count non-empty\n\t\tnode1 = SimpleTreeNode('a', None)\n\t\ttree.AddChild(None, node1)\n\t\tnode2 = SimpleTreeNode('b', node1)\n\t\ttree.AddChild(node1, node2)\n\t\tnode3 = SimpleTreeNode('c', node2)\n\t\ttree.AddChild(node2, node3)\n\t\tnode4 = SimpleTreeNode('d', node1)\n\t\ttree.AddChild(node1, node4)\n\t\tself.assertEqual(tree.Count(), 4)\n\t\t# count after deleting\n\t\ttree.DeleteNode(node3)\n\t\tself.assertEqual(tree.Count(), 3)\n\n\tdef test_leaf_count(self):\n\t\t# leaf count empty\n\t\ttree = SimpleTree(None)\n\t\tself.assertEqual(tree.LeafCount(), 0)\n\t\t# leaf count non-empty\n\t\tnode1 = SimpleTreeNode('a', None)\n\t\ttree.AddChild(None, node1)\n\t\tnode2 = SimpleTreeNode('b', node1)\n\t\ttree.AddChild(node1, node2)\n\t\tnode3 = SimpleTreeNode('c', node2)\n\t\ttree.AddChild(node2, node3)\n\t\tnode4 = SimpleTreeNode('d', node1)\n\t\ttree.AddChild(node1, node4)\n\t\tself.assertEqual(tree.LeafCount(), 2)\n\t\t# leaf count after deleting\n\t\ttree.DeleteNode(node3)\n\t\tself.assertEqual(tree.LeafCount(), 2)\n\t\t# leaf count after moving\n\t\ttree.AddChild(node2, node3)\n\t\ttree.MoveNode(node3, node4)#\n\t\tself.assertEqual(tree.LeafCount(), 2)\n", "description": null, "category": "simple", "imports": ["import unittest", "from Tree import SimpleTreeNode, SimpleTree"]}], [{"term": "class", "name": "SimpleRNNLayerTest", "data": "class SimpleRNNLayerTest(test.TestCase, parameterized.TestCase):\n", "description": null, "category": "simple", "imports": ["from __future__ import absolute_import", "from __future__ import division", "from __future__ import print_function", "from absl.testing import parameterized", "import numpy as np", "from tensorflow.python import keras", "from tensorflow.python.eager import context", "from tensorflow.python.framework import dtypes", "from tensorflow.python.framework import test_util as tf_test_util", "from tensorflow.python.keras import combinations", "from tensorflow.python.keras import testing_utils", "from tensorflow.python.platform import test", "from tensorflow.python.training import gradient_descent"]}, {"term": "def", "name": "test_return_sequences_SimpleRNN", "data": "  def test_return_sequences_SimpleRNN(self):\n\tnum_samples = 2\n\ttimesteps = 3\n\tembedding_dim = 4\n\tunits = 2\n\ttesting_utils.layer_test(\n\t\tkeras.layers.SimpleRNN,\n\t\tkwargs={'units': units,\n\t\t\t\t'return_sequences': True},\n\t\tinput_shape=(num_samples, timesteps, embedding_dim))\n", "description": null, "category": "simple", "imports": ["from __future__ import absolute_import", "from __future__ import division", "from __future__ import print_function", "from absl.testing import parameterized", "import numpy as np", "from tensorflow.python import keras", "from tensorflow.python.eager import context", "from tensorflow.python.framework import dtypes", "from tensorflow.python.framework import test_util as tf_test_util", "from tensorflow.python.keras import combinations", "from tensorflow.python.keras import testing_utils", "from tensorflow.python.platform import test", "from tensorflow.python.training import gradient_descent"]}, {"term": "def", "name": "test_float64_SimpleRNN", "data": "  def test_float64_SimpleRNN(self):\n\tnum_samples = 2\n\ttimesteps = 3\n\tembedding_dim = 4\n\tunits = 2\n\ttesting_utils.layer_test(\n\t\tkeras.layers.SimpleRNN,\n\t\tkwargs={'units': units,\n\t\t\t\t'return_sequences': True,\n\t\t\t\t'dtype': 'float64'},\n\t\tinput_shape=(num_samples, timesteps, embedding_dim),\n\t\tinput_dtype='float64')\n", "description": null, "category": "simple", "imports": ["from __future__ import absolute_import", "from __future__ import division", "from __future__ import print_function", "from absl.testing import parameterized", "import numpy as np", "from tensorflow.python import keras", "from tensorflow.python.eager import context", "from tensorflow.python.framework import dtypes", "from tensorflow.python.framework import test_util as tf_test_util", "from tensorflow.python.keras import combinations", "from tensorflow.python.keras import testing_utils", "from tensorflow.python.platform import test", "from tensorflow.python.training import gradient_descent"]}, {"term": "def", "name": "test_dynamic_behavior_SimpleRNN", "data": "  def test_dynamic_behavior_SimpleRNN(self):\n\tnum_samples = 2\n\ttimesteps = 3\n\tembedding_dim = 4\n\tunits = 2\n\tlayer = keras.layers.SimpleRNN(units, input_shape=(None, embedding_dim))\n\tmodel = keras.models.Sequential()\n\tmodel.add(layer)\n\tmodel.compile('rmsprop', 'mse')\n\tx = np.random.random((num_samples, timesteps, embedding_dim))\n\ty = np.random.random((num_samples, units))\n\tmodel.train_on_batch(x, y)\n", "description": null, "category": "simple", "imports": ["from __future__ import absolute_import", "from __future__ import division", "from __future__ import print_function", "from absl.testing import parameterized", "import numpy as np", "from tensorflow.python import keras", "from tensorflow.python.eager import context", "from tensorflow.python.framework import dtypes", "from tensorflow.python.framework import test_util as tf_test_util", "from tensorflow.python.keras import combinations", "from tensorflow.python.keras import testing_utils", "from tensorflow.python.platform import test", "from tensorflow.python.training import gradient_descent"]}, {"term": "def", "name": "test_dropout_SimpleRNN", "data": "  def test_dropout_SimpleRNN(self):\n\tnum_samples = 2\n\ttimesteps = 3\n\tembedding_dim = 4\n\tunits = 2\n\ttesting_utils.layer_test(\n\t\tkeras.layers.SimpleRNN,\n\t\tkwargs={'units': units,\n\t\t\t\t'dropout': 0.1,\n\t\t\t\t'recurrent_dropout': 0.1},\n\t\tinput_shape=(num_samples, timesteps, embedding_dim))\n", "description": null, "category": "simple", "imports": ["from __future__ import absolute_import", "from __future__ import division", "from __future__ import print_function", "from absl.testing import parameterized", "import numpy as np", "from tensorflow.python import keras", "from tensorflow.python.eager import context", "from tensorflow.python.framework import dtypes", "from tensorflow.python.framework import test_util as tf_test_util", "from tensorflow.python.keras import combinations", "from tensorflow.python.keras import testing_utils", "from tensorflow.python.platform import test", "from tensorflow.python.training import gradient_descent"]}, {"term": "def", "name": "test_implementation_mode_SimpleRNN", "data": "  def test_implementation_mode_SimpleRNN(self):\n\tnum_samples = 2\n\ttimesteps = 3\n\tembedding_dim = 4\n\tunits = 2\n\tfor mode in [0, 1, 2]:\n\t  testing_utils.layer_test(\n\t\t  keras.layers.SimpleRNN,\n\t\t  kwargs={'units': units,\n\t\t\t\t  'implementation': mode},\n\t\t  input_shape=(num_samples, timesteps, embedding_dim))\n", "description": null, "category": "simple", "imports": ["from __future__ import absolute_import", "from __future__ import division", "from __future__ import print_function", "from absl.testing import parameterized", "import numpy as np", "from tensorflow.python import keras", "from tensorflow.python.eager import context", "from tensorflow.python.framework import dtypes", "from tensorflow.python.framework import test_util as tf_test_util", "from tensorflow.python.keras import combinations", "from tensorflow.python.keras import testing_utils", "from tensorflow.python.platform import test", "from tensorflow.python.training import gradient_descent"]}, {"term": "def", "name": "test_constraints_SimpleRNN", "data": "  def test_constraints_SimpleRNN(self):\n\tembedding_dim = 4\n\tlayer_class = keras.layers.SimpleRNN\n\tk_constraint = keras.constraints.max_norm(0.01)\n\tr_constraint = keras.constraints.max_norm(0.01)\n\tb_constraint = keras.constraints.max_norm(0.01)\n\tlayer = layer_class(\n\t\t5,\n\t\treturn_sequences=False,\n\t\tweights=None,\n\t\tinput_shape=(None, embedding_dim),\n\t\tkernel_constraint=k_constraint,\n\t\trecurrent_constraint=r_constraint,\n\t\tbias_constraint=b_constraint)\n\tlayer.build((None, None, embedding_dim))\n\tself.assertEqual(layer.cell.kernel.constraint, k_constraint)\n\tself.assertEqual(layer.cell.recurrent_kernel.constraint, r_constraint)\n\tself.assertEqual(layer.cell.bias.constraint, b_constraint)\n", "description": null, "category": "simple", "imports": ["from __future__ import absolute_import", "from __future__ import division", "from __future__ import print_function", "from absl.testing import parameterized", "import numpy as np", "from tensorflow.python import keras", "from tensorflow.python.eager import context", "from tensorflow.python.framework import dtypes", "from tensorflow.python.framework import test_util as tf_test_util", "from tensorflow.python.keras import combinations", "from tensorflow.python.keras import testing_utils", "from tensorflow.python.platform import test", "from tensorflow.python.training import gradient_descent"]}, {"term": "def", "name": "test_with_masking_layer_SimpleRNN", "data": "  def test_with_masking_layer_SimpleRNN(self):\n\tlayer_class = keras.layers.SimpleRNN\n\tinputs = np.random.random((2, 3, 4))\n\ttargets = np.abs(np.random.random((2, 3, 5)))\n\ttargets /= targets.sum(axis=-1, keepdims=True)\n\tmodel = keras.models.Sequential()\n\tmodel.add(keras.layers.Masking(input_shape=(3, 4)))\n\tmodel.add(layer_class(units=5, return_sequences=True, unroll=False))\n\tmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n\tmodel.fit(inputs, targets, epochs=1, batch_size=2, verbose=1)\n", "description": null, "category": "simple", "imports": ["from __future__ import absolute_import", "from __future__ import division", "from __future__ import print_function", "from absl.testing import parameterized", "import numpy as np", "from tensorflow.python import keras", "from tensorflow.python.eager import context", "from tensorflow.python.framework import dtypes", "from tensorflow.python.framework import test_util as tf_test_util", "from tensorflow.python.keras import combinations", "from tensorflow.python.keras import testing_utils", "from tensorflow.python.platform import test", "from tensorflow.python.training import gradient_descent"]}, {"term": "def", "name": "test_from_config_SimpleRNN", "data": "  def test_from_config_SimpleRNN(self):\n\tlayer_class = keras.layers.SimpleRNN\n\tfor stateful in (False, True):\n\t  l1 = layer_class(units=1, stateful=stateful)\n\t  l2 = layer_class.from_config(l1.get_config())\n\t  assert l1.get_config() == l2.get_config()\n", "description": null, "category": "simple", "imports": ["from __future__ import absolute_import", "from __future__ import division", "from __future__ import print_function", "from absl.testing import parameterized", "import numpy as np", "from tensorflow.python import keras", "from tensorflow.python.eager import context", "from tensorflow.python.framework import dtypes", "from tensorflow.python.framework import test_util as tf_test_util", "from tensorflow.python.keras import combinations", "from tensorflow.python.keras import testing_utils", "from tensorflow.python.platform import test", "from tensorflow.python.training import gradient_descent"]}, {"term": "def", "name": "test_regularizers_SimpleRNN", "data": "  def test_regularizers_SimpleRNN(self):\n\tembedding_dim = 4\n\tlayer_class = keras.layers.SimpleRNN\n\tlayer = layer_class(\n\t\t5,\n\t\treturn_sequences=False,\n\t\tweights=None,\n\t\tinput_shape=(None, embedding_dim),\n\t\tkernel_regularizer=keras.regularizers.l1(0.01),\n\t\trecurrent_regularizer=keras.regularizers.l1(0.01),\n\t\tbias_regularizer='l2',\n\t\tactivity_regularizer='l1')\n\tlayer.build((None, None, 2))\n\tself.assertLen(layer.losses, 3)\n\n\tx = keras.backend.variable(np.ones((2, 3, 2)))\n\tlayer(x)\n\tif context.executing_eagerly():\n\t  self.assertLen(layer.losses, 4)\n\telse:\n\t  self.assertLen(layer.get_losses_for(x), 1)\n", "description": null, "category": "simple", "imports": ["from __future__ import absolute_import", "from __future__ import division", "from __future__ import print_function", "from absl.testing import parameterized", "import numpy as np", "from tensorflow.python import keras", "from tensorflow.python.eager import context", "from tensorflow.python.framework import dtypes", "from tensorflow.python.framework import test_util as tf_test_util", "from tensorflow.python.keras import combinations", "from tensorflow.python.keras import testing_utils", "from tensorflow.python.platform import test", "from tensorflow.python.training import gradient_descent"]}, {"term": "def", "name": "test_statefulness_SimpleRNN", "data": "  def test_statefulness_SimpleRNN(self):\n\tnum_samples = 2\n\ttimesteps = 3\n\tembedding_dim = 4\n\tunits = 2\n\tlayer_class = keras.layers.SimpleRNN\n\tmodel = keras.models.Sequential()\n\tmodel.add(\n\t\tkeras.layers.Embedding(\n\t\t\t4,\n\t\t\tembedding_dim,\n\t\t\tmask_zero=True,\n\t\t\tinput_length=timesteps,\n\t\t\tbatch_input_shape=(num_samples, timesteps)))\n\tlayer = layer_class(\n\t\tunits, return_sequences=False, stateful=True, weights=None)\n\tmodel.add(layer)\n\tmodel.compile(\n\t\toptimizer=gradient_descent.GradientDescentOptimizer(0.01),\n\t\tloss='mse',\n\t\trun_eagerly=testing_utils.should_run_eagerly())\n\tout1 = model.predict(np.ones((num_samples, timesteps)))\n\tself.assertEqual(out1.shape, (num_samples, units))\n\n\t# train once so that the states change\n\tmodel.train_on_batch(\n\t\tnp.ones((num_samples, timesteps)), np.ones((num_samples, units)))\n\tout2 = model.predict(np.ones((num_samples, timesteps)))\n\n\t# if the state is not reset, output should be different\n\tself.assertNotEqual(out1.max(), out2.max())\n\n\t# check that output changes after states are reset\n\t# (even though the model itself didn't change)\n\tlayer.reset_states()\n\tout3 = model.predict(np.ones((num_samples, timesteps)))\n\tself.assertNotEqual(out2.max(), out3.max())\n\n\t# check that container-level reset_states() works\n\tmodel.reset_states()\n\tout4 = model.predict(np.ones((num_samples, timesteps)))\n\tnp.testing.assert_allclose(out3, out4, atol=1e-5)\n\n\t# check that the call to `predict` updated the states\n\tout5 = model.predict(np.ones((num_samples, timesteps)))\n\tself.assertNotEqual(out4.max(), out5.max())\n\n\t# Check masking\n\tlayer.reset_states()\n\n\tleft_padded_input = np.ones((num_samples, timesteps))\n\tleft_padded_input[0, :1] = 0\n\tleft_padded_input[1, :2] = 0\n\tout6 = model.predict(left_padded_input)\n\n\tlayer.reset_states()\n\n\tright_padded_input = np.ones((num_samples, timesteps))\n\tright_padded_input[0, -1:] = 0\n\tright_padded_input[1, -2:] = 0\n\tout7 = model.predict(right_padded_input)\n\n\tnp.testing.assert_allclose(out7, out6, atol=1e-5)\n", "description": null, "category": "simple", "imports": ["from __future__ import absolute_import", "from __future__ import division", "from __future__ import print_function", "from absl.testing import parameterized", "import numpy as np", "from tensorflow.python import keras", "from tensorflow.python.eager import context", "from tensorflow.python.framework import dtypes", "from tensorflow.python.framework import test_util as tf_test_util", "from tensorflow.python.keras import combinations", "from tensorflow.python.keras import testing_utils", "from tensorflow.python.platform import test", "from tensorflow.python.training import gradient_descent"]}, {"term": "def", "name": "test_get_initial_states", "data": "  def test_get_initial_states(self):\n\tbatch_size = 4\n\tcell = keras.layers.SimpleRNNCell(20)\n\tinitial_state = cell.get_initial_state(\n\t\tbatch_size=batch_size, dtype=dtypes.float32)\n\t_, state = cell(np.ones((batch_size, 20), dtype=np.float32), initial_state)\n\tself.assertLen(state, 1)\n\tself.assertEqual(state[0].shape, initial_state.shape)\n\n", "description": null, "category": "simple", "imports": ["from __future__ import absolute_import", "from __future__ import division", "from __future__ import print_function", "from absl.testing import parameterized", "import numpy as np", "from tensorflow.python import keras", "from tensorflow.python.eager import context", "from tensorflow.python.framework import dtypes", "from tensorflow.python.framework import test_util as tf_test_util", "from tensorflow.python.keras import combinations", "from tensorflow.python.keras import testing_utils", "from tensorflow.python.platform import test", "from tensorflow.python.training import gradient_descent"]}], [{"term": "class", "name": "DivNorm", "data": "class DivNorm(nn.Module):\n\t\"\"\"\n\tImplements Schwartz and Simoncelli 2001 style divisive normalization.\n\tLesion of E/I connections\n\tparams:\n\t  input_dim: Number of channels in input\n\t  hidden_dim: Number of hidden channels\n\t  kernel_size: Size of kernel in convolutions\n\tExample:\n\t  x = torch.zeros(1, 1, 100, 100)\n\t  net = DivNormExcInh(1, 16, 15)\n\t  out = net(x)\n\t\"\"\"\n\n\tdef __init__(self,\n\t\t\t\t in_channels,\n\t\t\t\t divnorm_fsize=5,\n\t\t\t\t exc_lesion=True,\n\t\t\t\t inh_lesion=True,\n\t\t\t\t exc_fsize=7,\n\t\t\t\t inh_fsize=5,\n\t\t\t\t padding_mode='zeros',\n\t\t\t\t groups=1,\n\t\t\t\t ):\n\t\tsuper(DivNorm, self).__init__()\n\t\tself.in_channels = in_channels\t\n\t\tself.hidden_dim = in_channels\n\n\t\tself.div = nn.Conv2d(\n\t\t\tself.hidden_dim,\n\t\t\tself.hidden_dim,\n\t\t\tdivnorm_fsize,\n\t\t\tpadding=(divnorm_fsize - 1) // 2,\n\t\t\tpadding_mode=padding_mode,\n\t\t\tgroups=groups,\n\t\t\tbias=False)\n\t\tif exc_lesion:\n\t\t\tself.e_e = None\n\t\telse:\n\t\t\tself.e_e = nn.Conv2d(\n\t\t\t\tself.hidden_dim, self.hidden_dim, \n\t\t\t\texc_fsize, bias=True, padding=(exc_fsize - 1) // 2,\n\t\t\t\t)\n\t\tif inh_lesion:\n\t\t\tself.i_e = None\n\t\telse:\n\t\t\tself.i_e = nn.Conv2d(\n\t\t\t\tself.hidden_dim, self.hidden_dim, inh_fsize, \n\t\t\t\tpadding=(inh_fsize - 1) // 2,\n\t\t\t\tbias=True)\n\t\tself.sigma = nn.Parameter(torch.ones([1, self.hidden_dim, 1, 1]))\n\t\tself.output_bn = nn.BatchNorm2d(in_channels)\n\t\tself.output_relu = nn.ReLU(inplace=True)\n\t\n\tdef forward(self, x, residual=True, square_act=True):\n\t\t\"\"\"\n\t\tparams:\n\t\t\tx: Input activation tensor\n\t\treturns:\n\t\t\toutput: Output post normalization\n\t\t\"\"\"\n\t\treturn self.forward_divnorm(x=x, residual=residual, square_act=square_act)\n\t\t\n\tdef forward_divnorm(self, x, residual=True, square_act=True):\n\t\t\"\"\"\n\t\tparams:\n\t\t  x: Input grayscale image tensor\n\t\tReturns:\n\t\t  output: Output post divisive normalization\n\t\t\"\"\"\n\t\tidentity = x\n\t\tsimple_cells = nn.Identity()(x)\n\n\t\tif square_act:\n\t\t\tsimple_cells = simple_cells ** 2\n\t\t\tnorm = self.div(simple_cells) + self.sigma ** 2 + 1e-5\n\t\t\tif (norm == 0).any():\n\t\t\t\timport ipdb; ipdb.set_trace()\n\t\t\tsimple_cells = simple_cells / norm\n\t\telse:\n\t\t\tnorm = 1 + F.relu(self.div(simple_cells))\n\t\t\t#norm = F.relu(self.div(simple_cells)) + self.sigma ** 2 + 1e-5\n\t\t\tsimple_cells = simple_cells / norm\n\t\toutput = simple_cells\n\t\tif self.i_e is not None:\n\t\t\tinhibition = self.i_e(simple_cells)\n\t\t\toutput = output - inhibition\n\t\tif self.e_e is not None:\t\t\t\t\n\t\t\t# Excitatory lateral connections (Center corresponds to self-excitation)\n\t\t\texcitation = self.e_e(simple_cells)\n\t\t\toutput = output + excitation\n\t\toutput = self.output_bn(output)\n\t\tif residual:\n\t\t\toutput += identity\n\t\toutput = self.output_relu(output)\n\t\treturn output\n", "description": "\n\tImplements Schwartz and Simoncelli 2001 style divisive normalization.\n\tLesion of E/I connections\n\tparams:\n\t  input_dim: Number of channels in input\n\t  hidden_dim: Number of hidden channels\n\t  kernel_size: Size of kernel in convolutions\n\tExample:\n\t  x = torch.zeros(1, 1, 100, 100)\n\t  net = DivNormExcInh(1, 16, 15)\n\t  out = net(x)\n\t", "category": "simple", "imports": ["import math", "import numpy as np", "import torch  # pylint: disable=import-error", "import torch.nn as nn  # pylint: disable=import-error", "import torch.nn.functional as F  # pylint: disable=import-error", "from numpy.core.numeric import True_", "\t\t\t\timport ipdb; ipdb.set_trace()"]}], [{"term": "class", "name": "SimpleModel", "data": "class SimpleModel(Model):\n\t\"\"\"Simple Test Model\"\"\"\n\tname = StringProperty()\n\tstrs = ListProperty(str)\n\tnum = IntegerProperty()\n", "description": "Simple Test Model", "category": "simple", "imports": ["from boto.sdb.db.property import ListProperty, StringProperty, ReferenceProperty, IntegerProperty", "from boto.sdb.db.model import Model", "import time"]}, {"term": "class", "name": "SubModel", "data": "class SubModel(SimpleModel):\n\t\"\"\"Simple Subclassed Model\"\"\"\n\tref = ReferenceProperty(SimpleModel, collection_name=\"reverse_ref\")\n\n", "description": "Simple Subclassed Model", "category": "simple", "imports": ["from boto.sdb.db.property import ListProperty, StringProperty, ReferenceProperty, IntegerProperty", "from boto.sdb.db.model import Model", "import time"]}, {"term": "class", "name": "TestQuerying", "data": "class TestQuerying(object):\n\t\"\"\"Test different querying capabilities\"\"\"\n\n\tdef setup_class(cls):\n\t\t\"\"\"Setup this class\"\"\"\n\t\tcls.objs = []\n\n\t\to = SimpleModel()\n\t\to.name = \"Simple Object\"\n\t\to.strs = [\"B\", \"A\", \"C\", \"Foo\"]\n\t\to.num = 1\n\t\to.put()\n\t\tcls.objs.append(o)\n\n\t\to2 = SimpleModel()\n\t\to2.name = \"Referenced Object\"\n\t\to2.num = 2\n\t\to2.put()\n\t\tcls.objs.append(o2)\n\n\t\to3 = SubModel()\n\t\to3.name = \"Sub Object\"\n\t\to3.num = 3\n\t\to3.ref = o2\n\t\to3.put()\n\t\tcls.objs.append(o3)\n\n\t\ttime.sleep(3)\n\n\n\n\tdef teardown_class(cls):\n\t\t\"\"\"Remove our objects\"\"\"\n\t\tfor o in cls.objs:\n\t\t\ttry:\n\t\t\t\to.delete()\n\t\t\texcept:\n\t\t\t\tpass\n\n\tdef test_find(self):\n\t\t\"\"\"Test using the \"Find\" method\"\"\"\n\t\tassert(SimpleModel.find(name=\"Simple Object\").next().id == self.objs[0].id)\n\t\tassert(SimpleModel.find(name=\"Referenced Object\").next().id == self.objs[1].id)\n\t\tassert(SimpleModel.find(name=\"Sub Object\").next().id == self.objs[2].id)\n\n\tdef test_like_filter(self):\n\t\t\"\"\"Test a \"like\" filter\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name like\", \"% Object\")\n\t\tassert(query.count() == 3)\n\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name not like\", \"% Object\")\n\t\tassert(query.count() == 0)\n\n\tdef test_equals_filter(self):\n\t\t\"\"\"Test an \"=\" and \"!=\" filter\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name =\", \"Simple Object\")\n\t\tassert(query.count() == 1)\n\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name !=\", \"Simple Object\")\n\t\tassert(query.count() == 2)\n\n\tdef test_or_filter(self):\n\t\t\"\"\"Test a filter function as an \"or\" \"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name =\", [\"Simple Object\", \"Sub Object\"])\n\t\tassert(query.count() == 2)\n\n\tdef test_and_filter(self):\n\t\t\"\"\"Test Multiple filters which are an \"and\" \"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name like\", \"% Object\")\n\t\tquery.filter(\"name like\", \"Simple %\")\n\t\tassert(query.count() == 1)\n\n\tdef test_none_filter(self):\n\t\t\"\"\"Test filtering for a value that's not set\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"ref =\", None)\n\t\tassert(query.count() == 2)\n\n\tdef test_greater_filter(self):\n\t\t\"\"\"Test filtering Using >, >=\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"num >\", 1)\n\t\tassert(query.count() == 2)\n\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"num >=\", 1)\n\t\tassert(query.count() == 3)\n\n\tdef test_less_filter(self):\n\t\t\"\"\"Test filtering Using <, <=\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"num <\", 3)\n\t\tassert(query.count() == 2)\n\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"num <=\", 3)\n\t\tassert(query.count() == 3)\n\n\tdef test_query_on_list(self):\n\t\t\"\"\"Test querying on a list\"\"\"\n\t\tassert(SimpleModel.find(strs=\"A\").next().id == self.objs[0].id)\n\t\tassert(SimpleModel.find(strs=\"B\").next().id == self.objs[0].id)\n\t\tassert(SimpleModel.find(strs=\"C\").next().id == self.objs[0].id)\n\n\tdef test_like(self):\n\t\t\"\"\"Test with a \"like\" expression\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"strs like\", \"%oo%\")\n\t\tprint query.get_query()\n\t\tassert(query.count() == 1)\n", "description": "Test different querying capabilities", "category": "simple", "imports": ["from boto.sdb.db.property import ListProperty, StringProperty, ReferenceProperty, IntegerProperty", "from boto.sdb.db.model import Model", "import time"]}], [{"term": "class", "name": "HTTPSitemapTests", "data": "class HTTPSitemapTests(SitemapTestsBase):\n\n\t@ignore_warnings(category=RemovedInDjango110Warning)\n\tdef test_simple_sitemap_index(self):\n\t\t\"A simple sitemap index can be rendered\"\n\t\t# The URL for views.sitemap in tests/urls/http.py has been updated\n\t\t# with a name but since reversing by Python path is tried first\n\t\t# before reversing by name and works since we're giving\n\t\t# name='django.contrib.sitemaps.views.sitemap', we need to silence\n\t\t# the erroneous warning until reversing by dotted path is removed.\n\t\t# The test will work without modification when it's removed.\n\t\tresponse = self.client.get('/simple/index.xml')\n\t\texpected_content = \"\"\"\n", "description": "\n", "category": "simple", "imports": ["from __future__ import unicode_literals", "import os", "from datetime import date", "from unittest import skipUnless", "from django.apps import apps", "from django.conf import settings", "from django.contrib.sitemaps import GenericSitemap, Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import ignore_warnings, modify_settings, override_settings", "from django.utils._os import upath", "from django.utils.deprecation import RemovedInDjango110Warning", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_simple_sitemap_custom_index", "data": "\tdef test_simple_sitemap_custom_index(self):\n\t\t\"A simple sitemap index can be rendered with a custom template\"\n\t\t# The URL for views.sitemap in tests/urls/http.py has been updated\n\t\t# with a name but since reversing by Python path is tried first\n\t\t# before reversing by name and works since we're giving\n\t\t# name='django.contrib.sitemaps.views.sitemap', we need to silence\n\t\t# the erroneous warning until reversing by dotted path is removed.\n\t\t# The test will work without modification when it's removed.\n\t\tresponse = self.client.get('/simple/custom-index.xml')\n\t\texpected_content = \"\"\"\n\n", "description": "\n\n", "category": "simple", "imports": ["from __future__ import unicode_literals", "import os", "from datetime import date", "from unittest import skipUnless", "from django.apps import apps", "from django.conf import settings", "from django.contrib.sitemaps import GenericSitemap, Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import ignore_warnings, modify_settings, override_settings", "from django.utils._os import upath", "from django.utils.deprecation import RemovedInDjango110Warning", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_simple_sitemap_section", "data": "\tdef test_simple_sitemap_section(self):\n\t\t\"A simple sitemap section can be rendered\"\n\t\tresponse = self.client.get('/simple/sitemap-simple.xml')\n\t\texpected_content = \"\"\"\n", "description": "\n", "category": "simple", "imports": ["from __future__ import unicode_literals", "import os", "from datetime import date", "from unittest import skipUnless", "from django.apps import apps", "from django.conf import settings", "from django.contrib.sitemaps import GenericSitemap, Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import ignore_warnings, modify_settings, override_settings", "from django.utils._os import upath", "from django.utils.deprecation import RemovedInDjango110Warning", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_simple_sitemap", "data": "\tdef test_simple_sitemap(self):\n\t\t\"A simple sitemap can be rendered\"\n\t\tresponse = self.client.get('/simple/sitemap.xml')\n\t\texpected_content = \"\"\"\n", "description": "\n", "category": "simple", "imports": ["from __future__ import unicode_literals", "import os", "from datetime import date", "from unittest import skipUnless", "from django.apps import apps", "from django.conf import settings", "from django.contrib.sitemaps import GenericSitemap, Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import ignore_warnings, modify_settings, override_settings", "from django.utils._os import upath", "from django.utils.deprecation import RemovedInDjango110Warning", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_simple_custom_sitemap", "data": "\tdef test_simple_custom_sitemap(self):\n\t\t\"A simple sitemap can be rendered with a custom template\"\n\t\tresponse = self.client.get('/simple/custom-sitemap.xml')\n\t\texpected_content = \"\"\"\n\n", "description": "\n\n", "category": "simple", "imports": ["from __future__ import unicode_literals", "import os", "from datetime import date", "from unittest import skipUnless", "from django.apps import apps", "from django.conf import settings", "from django.contrib.sitemaps import GenericSitemap, Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import ignore_warnings, modify_settings, override_settings", "from django.utils._os import upath", "from django.utils.deprecation import RemovedInDjango110Warning", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_sitemap_last_modified", "data": "\tdef test_sitemap_last_modified(self):\n\t\t\"Tests that Last-Modified header is set correctly\"\n\t\tresponse = self.client.get('/lastmod/sitemap.xml')\n\t\tself.assertEqual(response['Last-Modified'], 'Wed, 13 Mar 2013 10:00:00 GMT')\n", "description": null, "category": "simple", "imports": ["from __future__ import unicode_literals", "import os", "from datetime import date", "from unittest import skipUnless", "from django.apps import apps", "from django.conf import settings", "from django.contrib.sitemaps import GenericSitemap, Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import ignore_warnings, modify_settings, override_settings", "from django.utils._os import upath", "from django.utils.deprecation import RemovedInDjango110Warning", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_sitemap_last_modified_date", "data": "\tdef test_sitemap_last_modified_date(self):\n\t\t\"\"\"\n\t\tThe Last-Modified header should be support dates (without time).\n\t\t\"\"\"\n\t\tresponse = self.client.get('/lastmod/date-sitemap.xml')\n\t\tself.assertEqual(response['Last-Modified'], 'Wed, 13 Mar 2013 00:00:00 GMT')\n", "description": "\n\t\tThe Last-Modified header should be support dates (without time).\n\t\t", "category": "simple", "imports": ["from __future__ import unicode_literals", "import os", "from datetime import date", "from unittest import skipUnless", "from django.apps import apps", "from django.conf import settings", "from django.contrib.sitemaps import GenericSitemap, Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import ignore_warnings, modify_settings, override_settings", "from django.utils._os import upath", "from django.utils.deprecation import RemovedInDjango110Warning", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_sitemap_last_modified_tz", "data": "\tdef test_sitemap_last_modified_tz(self):\n\t\t\"\"\"\n\t\tThe Last-Modified header should be converted from timezone aware dates\n\t\tto GMT.\n\t\t\"\"\"\n\t\tresponse = self.client.get('/lastmod/tz-sitemap.xml')\n\t\tself.assertEqual(response['Last-Modified'], 'Wed, 13 Mar 2013 15:00:00 GMT')\n", "description": "\n\t\tThe Last-Modified header should be converted from timezone aware dates\n\t\tto GMT.\n\t\t", "category": "simple", "imports": ["from __future__ import unicode_literals", "import os", "from datetime import date", "from unittest import skipUnless", "from django.apps import apps", "from django.conf import settings", "from django.contrib.sitemaps import GenericSitemap, Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import ignore_warnings, modify_settings, override_settings", "from django.utils._os import upath", "from django.utils.deprecation import RemovedInDjango110Warning", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_sitemap_last_modified_missing", "data": "\tdef test_sitemap_last_modified_missing(self):\n\t\t\"Tests that Last-Modified header is missing when sitemap has no lastmod\"\n\t\tresponse = self.client.get('/generic/sitemap.xml')\n\t\tself.assertFalse(response.has_header('Last-Modified'))\n", "description": null, "category": "simple", "imports": ["from __future__ import unicode_literals", "import os", "from datetime import date", "from unittest import skipUnless", "from django.apps import apps", "from django.conf import settings", "from django.contrib.sitemaps import GenericSitemap, Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import ignore_warnings, modify_settings, override_settings", "from django.utils._os import upath", "from django.utils.deprecation import RemovedInDjango110Warning", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_sitemap_last_modified_mixed", "data": "\tdef test_sitemap_last_modified_mixed(self):\n\t\t\"Tests that Last-Modified header is omitted when lastmod not on all items\"\n\t\tresponse = self.client.get('/lastmod-mixed/sitemap.xml')\n\t\tself.assertFalse(response.has_header('Last-Modified'))\n", "description": null, "category": "simple", "imports": ["from __future__ import unicode_literals", "import os", "from datetime import date", "from unittest import skipUnless", "from django.apps import apps", "from django.conf import settings", "from django.contrib.sitemaps import GenericSitemap, Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import ignore_warnings, modify_settings, override_settings", "from django.utils._os import upath", "from django.utils.deprecation import RemovedInDjango110Warning", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_localized_priority", "data": "\tdef test_localized_priority(self):\n\t\t\"The priority value should not be localized (Refs #14164)\"\n\t\tactivate('fr')\n\t\tself.assertEqual('0,3', localize(0.3))\n\n\t\t# Retrieve the sitemap. Check that priorities\n\t\t# haven't been rendered in localized format\n\t\tresponse = self.client.get('/simple/sitemap.xml')\n\t\tself.assertContains(response, '0.5')\n\t\tself.assertContains(response, '%s' % date.today())\n\t\tdeactivate()\n", "description": null, "category": "simple", "imports": ["from __future__ import unicode_literals", "import os", "from datetime import date", "from unittest import skipUnless", "from django.apps import apps", "from django.conf import settings", "from django.contrib.sitemaps import GenericSitemap, Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import ignore_warnings, modify_settings, override_settings", "from django.utils._os import upath", "from django.utils.deprecation import RemovedInDjango110Warning", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_requestsite_sitemap", "data": "\tdef test_requestsite_sitemap(self):\n\t\t# Make sure hitting the flatpages sitemap without the sites framework\n\t\t# installed doesn't raise an exception.\n\t\tresponse = self.client.get('/simple/sitemap.xml')\n\t\texpected_content = \"\"\"\n", "description": "\n", "category": "simple", "imports": ["from __future__ import unicode_literals", "import os", "from datetime import date", "from unittest import skipUnless", "from django.apps import apps", "from django.conf import settings", "from django.contrib.sitemaps import GenericSitemap, Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import ignore_warnings, modify_settings, override_settings", "from django.utils._os import upath", "from django.utils.deprecation import RemovedInDjango110Warning", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_sitemap_get_urls_no_site_1", "data": "\tdef test_sitemap_get_urls_no_site_1(self):\n\t\t\"\"\"\n\t\tCheck we get ImproperlyConfigured if we don't pass a site object to\n\t\tSitemap.get_urls and no Site objects exist\n\t\t\"\"\"\n\t\tSite.objects.all().delete()\n\t\tself.assertRaises(ImproperlyConfigured, Sitemap().get_urls)\n", "description": "\n\t\tCheck we get ImproperlyConfigured if we don't pass a site object to\n\t\tSitemap.get_urls and no Site objects exist\n\t\t", "category": "simple", "imports": ["from __future__ import unicode_literals", "import os", "from datetime import date", "from unittest import skipUnless", "from django.apps import apps", "from django.conf import settings", "from django.contrib.sitemaps import GenericSitemap, Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import ignore_warnings, modify_settings, override_settings", "from django.utils._os import upath", "from django.utils.deprecation import RemovedInDjango110Warning", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_sitemap_get_urls_no_site_2", "data": "\tdef test_sitemap_get_urls_no_site_2(self):\n\t\t\"\"\"\n\t\tCheck we get ImproperlyConfigured when we don't pass a site object to\n\t\tSitemap.get_urls if Site objects exists, but the sites framework is not\n\t\tactually installed.\n\t\t\"\"\"\n\t\tself.assertRaises(ImproperlyConfigured, Sitemap().get_urls)\n", "description": "\n\t\tCheck we get ImproperlyConfigured when we don't pass a site object to\n\t\tSitemap.get_urls if Site objects exists, but the sites framework is not\n\t\tactually installed.\n\t\t", "category": "simple", "imports": ["from __future__ import unicode_literals", "import os", "from datetime import date", "from unittest import skipUnless", "from django.apps import apps", "from django.conf import settings", "from django.contrib.sitemaps import GenericSitemap, Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import ignore_warnings, modify_settings, override_settings", "from django.utils._os import upath", "from django.utils.deprecation import RemovedInDjango110Warning", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_sitemap_item", "data": "\tdef test_sitemap_item(self):\n\t\t\"\"\"\n\t\tCheck to make sure that the raw item is included with each\n\t\tSitemap.get_url() url result.\n\t\t\"\"\"\n\t\ttest_sitemap = GenericSitemap({'queryset': TestModel.objects.all()})\n\n\t\tdef is_testmodel(url):\n\t\t\treturn isinstance(url['item'], TestModel)\n\t\titem_in_url_info = all(map(is_testmodel, test_sitemap.get_urls()))\n\t\tself.assertTrue(item_in_url_info)\n", "description": "\n\t\tCheck to make sure that the raw item is included with each\n\t\tSitemap.get_url() url result.\n\t\t", "category": "simple", "imports": ["from __future__ import unicode_literals", "import os", "from datetime import date", "from unittest import skipUnless", "from django.apps import apps", "from django.conf import settings", "from django.contrib.sitemaps import GenericSitemap, Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import ignore_warnings, modify_settings, override_settings", "from django.utils._os import upath", "from django.utils.deprecation import RemovedInDjango110Warning", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_cached_sitemap_index", "data": "\tdef test_cached_sitemap_index(self):\n\t\t\"\"\"\n\t\tCheck that a cached sitemap index can be rendered (#2713).\n\t\t\"\"\"\n\t\tresponse = self.client.get('/cached/index.xml')\n\t\texpected_content = \"\"\"\n", "description": "\n\t\tCheck that a cached sitemap index can be rendered (#2713).\n\t\t", "category": "simple", "imports": ["from __future__ import unicode_literals", "import os", "from datetime import date", "from unittest import skipUnless", "from django.apps import apps", "from django.conf import settings", "from django.contrib.sitemaps import GenericSitemap, Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import ignore_warnings, modify_settings, override_settings", "from django.utils._os import upath", "from django.utils.deprecation import RemovedInDjango110Warning", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_x_robots_sitemap", "data": "\tdef test_x_robots_sitemap(self):\n\t\t# The URL for views.sitemap in tests/urls/http.py has been updated\n\t\t# with a name but since reversing by Python path is tried first\n\t\t# before reversing by name and works since we're giving\n\t\t# name='django.contrib.sitemaps.views.sitemap', we need to silence\n\t\t# the erroneous warning until reversing by dotted path is removed.\n\t\t# The test will work without modification when it's removed.\n\t\tresponse = self.client.get('/simple/index.xml')\n\t\tself.assertEqual(response['X-Robots-Tag'], 'noindex, noodp, noarchive')\n\n\t\tresponse = self.client.get('/simple/sitemap.xml')\n\t\tself.assertEqual(response['X-Robots-Tag'], 'noindex, noodp, noarchive')\n", "description": null, "category": "simple", "imports": ["from __future__ import unicode_literals", "import os", "from datetime import date", "from unittest import skipUnless", "from django.apps import apps", "from django.conf import settings", "from django.contrib.sitemaps import GenericSitemap, Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import ignore_warnings, modify_settings, override_settings", "from django.utils._os import upath", "from django.utils.deprecation import RemovedInDjango110Warning", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_empty_sitemap", "data": "\tdef test_empty_sitemap(self):\n\t\tresponse = self.client.get('/empty/sitemap.xml')\n\t\tself.assertEqual(response.status_code, 200)\n", "description": null, "category": "simple", "imports": ["from __future__ import unicode_literals", "import os", "from datetime import date", "from unittest import skipUnless", "from django.apps import apps", "from django.conf import settings", "from django.contrib.sitemaps import GenericSitemap, Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import ignore_warnings, modify_settings, override_settings", "from django.utils._os import upath", "from django.utils.deprecation import RemovedInDjango110Warning", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_simple_i18nsitemap_index", "data": "\tdef test_simple_i18nsitemap_index(self):\n\t\t\"A simple i18n sitemap index can be rendered\"\n\t\tresponse = self.client.get('/simple/i18n.xml')\n\t\texpected_content = \"\"\"\n", "description": "\n", "category": "simple", "imports": ["from __future__ import unicode_literals", "import os", "from datetime import date", "from unittest import skipUnless", "from django.apps import apps", "from django.conf import settings", "from django.contrib.sitemaps import GenericSitemap, Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import ignore_warnings, modify_settings, override_settings", "from django.utils._os import upath", "from django.utils.deprecation import RemovedInDjango110Warning", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "from .base import SitemapTestsBase", "from .models import TestModel"]}], [{"term": "class", "name": "SimpleSitemap", "data": "class SimpleSitemap(Sitemap):\n\tchangefreq = \"never\"\n\tpriority = 0.5\n\tlocation = '/location/'\n\tlastmod = datetime.now()\n\n\tdef items(self):\n\t\treturn [object()]\n\n", "description": null, "category": "simple", "imports": ["from collections import OrderedDict", "from datetime import date, datetime", "from django.conf.urls import url", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "SimplePagedSitemap", "data": "class SimplePagedSitemap(Sitemap):\n\tdef items(self):\n\t\treturn [object() for x in range(Sitemap.limit + 1)]\n\n", "description": null, "category": "simple", "imports": ["from collections import OrderedDict", "from datetime import date, datetime", "from django.conf.urls import url", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "SimpleI18nSitemap", "data": "class SimpleI18nSitemap(Sitemap):\n\tchangefreq = \"never\"\n\tpriority = 0.5\n\ti18n = True\n\n\tdef items(self):\n\t\treturn I18nTestModel.objects.order_by('pk').all()\n\n", "description": null, "category": "simple", "imports": ["from collections import OrderedDict", "from datetime import date, datetime", "from django.conf.urls import url", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "EmptySitemap", "data": "class EmptySitemap(Sitemap):\n\tchangefreq = \"never\"\n\tpriority = 0.5\n\tlocation = '/location/'\n\n", "description": null, "category": "simple", "imports": ["from collections import OrderedDict", "from datetime import date, datetime", "from django.conf.urls import url", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "FixedLastmodSitemap", "data": "class FixedLastmodSitemap(SimpleSitemap):\n\tlastmod = datetime(2013, 3, 13, 10, 0, 0)\n\n", "description": null, "category": "simple", "imports": ["from collections import OrderedDict", "from datetime import date, datetime", "from django.conf.urls import url", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "FixedLastmodMixedSitemap", "data": "class FixedLastmodMixedSitemap(Sitemap):\n\tchangefreq = \"never\"\n\tpriority = 0.5\n\tlocation = '/location/'\n\tloop = 0\n\n\tdef items(self):\n\t\to1 = TestModel()\n\t\to1.lastmod = datetime(2013, 3, 13, 10, 0, 0)\n\t\to2 = TestModel()\n\t\treturn [o1, o2]\n\n", "description": null, "category": "simple", "imports": ["from collections import OrderedDict", "from datetime import date, datetime", "from django.conf.urls import url", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "FixedNewerLastmodSitemap", "data": "class FixedNewerLastmodSitemap(SimpleSitemap):\n\tlastmod = datetime(2013, 4, 20, 5, 0, 0)\n\n", "description": null, "category": "simple", "imports": ["from collections import OrderedDict", "from datetime import date, datetime", "from django.conf.urls import url", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "DateSiteMap", "data": "class DateSiteMap(SimpleSitemap):\n\tlastmod = date(2013, 3, 13)\n\n", "description": null, "category": "simple", "imports": ["from collections import OrderedDict", "from datetime import date, datetime", "from django.conf.urls import url", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "TimezoneSiteMap", "data": "class TimezoneSiteMap(SimpleSitemap):\n\tlastmod = datetime(2013, 3, 13, 10, 0, 0, tzinfo=timezone.get_fixed_timezone(-300))\n\n", "description": null, "category": "simple", "imports": ["from collections import OrderedDict", "from datetime import date, datetime", "from django.conf.urls import url", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "def", "name": "testmodelview", "data": "def testmodelview(request, id):\n\treturn HttpResponse()\n\n", "description": null, "category": "simple", "imports": ["from collections import OrderedDict", "from datetime import date, datetime", "from django.conf.urls import url", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}], [{"term": "class", "name": "classDocumentStore:", "data": "class DocumentStore:\n\t\"\"\"\n\tThe I{suds} document store provides a local repository\n\tfor xml documnts.\n\t@cvar protocol: The URL protocol for the store.\n\t@type protocol: str\n\t@cvar store: The mapping of URL location to documents.\n\t@type store: dict\n\t\"\"\"\n\t\n\tprotocol = 'suds'\n\t\n\tstore = {\n\t\t'schemas.xmlsoap.org/soap/encoding/' : encoding\n\t}\n\t\n\tdef open(self, url):\n\t\t\"\"\"\n\t\tOpen a document at the specified url.\n\t\t@param url: A document URL.\n\t\t@type url: str\n\t\t@return: A file pointer to the document.\n\t\t@rtype: StringIO\n\t\t\"\"\"\n\t\tprotocol, location = self.split(url)\n\t\tif protocol == self.protocol:\n\t\t\treturn self.find(location)\n\t\telse:\n\t\t\treturn None\n\t\t\n\tdef find(self, location):\n\t\t\"\"\"\n\t\tFind the specified location in the store.\n\t\t@param location: The I{location} part of a URL.\n\t\t@type location: str\n\t\t@return: An input stream to the document.\n\t\t@rtype: StringIO\n\t\t\"\"\"\n\t\ttry:\n\t\t\tcontent = self.store[location]\n\t\t\treturn StringIO(content)\n\t\texcept:\n\t\t\treason = 'location \"%s\" not in document store' % location\n\t\t\traise Exception, reason\n\t\t\n\tdef split(self, url):\n\t\t\"\"\"\n\t\tSplit the url into I{protocol} and I{location}\n\t\t@param url: A URL.\n\t\t@param url: str\n\t\t@return: (I{url}, I{location})\n\t\t@rtype: tuple\n\t\t\"\"\"\n\t\tparts = url.split('://', 1)\n\t\tif len(parts) == 2:\n\t\t\treturn parts\n\t\telse:\n", "description": "\n\tThe I{suds} document store provides a local repository\n\tfor xml documnts.\n\t@cvar protocol: The URL protocol for the store.\n\t@type protocol: str\n\t@cvar store: The mapping of URL location to documents.\n\t@type store: dict\n\t", "category": "simple", "imports": ["from StringIO import StringIO", "from logging import getLogger"]}], [{"term": "class", "name": "ProcessThread", "data": "class ProcessThread(threading.Thread):\n\tdef __init__(self, target, pause=0.0125):\n\t\tthreading.Thread.__init__(self)\n\t\tself.setDaemon(True)\n\t\tself.target = target\n\t\tself.pause = pause\n\t\tself.stop_signal = threading.Event()\n\n\tdef stop(self):\n\t\tself.stop_signal.set()\n\n\tdef updatePause(self, pause):\n\t\tself.pause = pause\n\n\tdef run(self):\n\t\tstate = NORMAL\n\t\twhile (state != FINISH) and (not self.stop_signal.isSet()):\n\t\t\tstate = self.target()\n\t\t\tif (state == NOOP):\n\t\t\t\t# If there was no data to process sleep to avoid spinning\n\t\t\t\ttime.sleep(self.pause)\n", "description": null, "category": "simple", "imports": ["from ossie.cf import CF, CF__POA", "from ossie.utils import uuid", "from ossie.resource import Resource", "from ossie.properties import simple_property", "from ossie.properties import simpleseq_property", "from ossie.properties import struct_property", "from ossie.properties import structseq_property", "import Queue, copy, time, threading"]}, {"term": "class", "name": "TestAllPropTypes_base", "data": "class TestAllPropTypes_base(CF__POA.Resource, Resource):\n\t\t# These values can be altered in the __init__ of your derived class\n\n\t\tPAUSE = 0.0125 # The amount of time to sleep if process return NOOP\n\t\tTIMEOUT = 5.0 # The amount of time to wait for the process thread to die when stop() is called\n\t\tDEFAULT_QUEUE_SIZE = 100 # The number of BulkIO packets that can be in the queue before pushPacket will block\n\t\t\n\t\tdef __init__(self, identifier, execparams):\n\t\t\tloggerName = (execparams['NAME_BINDING'].replace('/', '.')).rsplit(\"_\", 1)[0]\n\t\t\tResource.__init__(self, identifier, execparams, loggerName=loggerName)\n\t\t\tself.threadControlLock = threading.RLock()\n\t\t\tself.process_thread = None\n\t\t\t# self.auto_start is deprecated and is only kept for API compatability\n\t\t\t# with 1.7.X and 1.8.0 components.  This variable may be removed\n\t\t\t# in future releases\n\t\t\tself.auto_start = False\n\t\t\t\n\t\tdef initialize(self):\n\t\t\tResource.initialize(self)\n\t\t\t\n\t\t\t# Instantiate the default implementations for all ports on this component\n\n\n\t\tdef start(self):\n\t\t\tself.threadControlLock.acquire()\n\t\t\ttry:\n\t\t\t\tResource.start(self)\n\t\t\t\tif self.process_thread == None:\n\t\t\t\t\tself.process_thread = ProcessThread(target=self.process, pause=self.PAUSE)\n\t\t\t\t\tself.process_thread.start()\n\t\t\tfinally:\n\t\t\t\tself.threadControlLock.release()\n\n\t\tdef process(self):\n\t\t\t\"\"\"The process method should process a single \"chunk\" of data and then return.  This method will be called\n\t\t\tfrom the processing thread again, and again, and again until it returns FINISH or stop() is called on the\n\t\t\tcomponent.  If no work is performed, then return NOOP\"\"\"\n\t\t\traise NotImplementedError\n\n\t\tdef stop(self):\n\t\t\tself.threadControlLock.acquire()\n\t\t\ttry:\n\t\t\t\tprocess_thread = self.process_thread\n\t\t\t\tself.process_thread = None\n\n\t\t\t\tif process_thread != None:\n\t\t\t\t\tprocess_thread.stop()\n\t\t\t\t\tprocess_thread.join(self.TIMEOUT)\n\t\t\t\t\tif process_thread.isAlive():\n\t\t\t\t\t\traise CF.Resource.StopError(CF.CF_NOTSET, \"Processing thread did not die\")\n\t\t\t\tResource.stop(self)\n\t\t\tfinally:\n\t\t\t\tself.threadControlLock.release()\n\n\t\tdef releaseObject(self):\n\t\t\ttry:\n\t\t\t\tself.stop()\n\t\t\texcept Exception:\n\t\t\t\tself._log.exception(\"Error stopping\")\n\t\t\tself.threadControlLock.acquire()\n\t\t\ttry:\n\t\t\t\tResource.releaseObject(self)\n\t\t\tfinally:\n\t\t\t\tself.threadControlLock.release()\n\n\t\t######################################################################\n\t\t# PORTS\n\t\t# \n\t\t# DO NOT ADD NEW PORTS HERE.  You can add ports in your derived class, in the SCD xml file, \n\t\t# or via the IDE.\n\t\t\t\t\n\n\t\t######################################################################\n\t\t# PROPERTIES\n\t\t# \n\t\t# DO NOT ADD NEW PROPERTIES HERE.  You can add properties in your derived class, in the PRF xml file\n\t\t# or by using the IDE.\t   \n\t\tsimple_string = simple_property(id_=\"simple_string\",\n\t\t\t\t\t\t\t\t\t\t  type_=\"string\",\n\t\t\t\t\t\t\t\t\t\t  mode=\"readwrite\",\n\t\t\t\t\t\t\t\t\t\t  action=\"external\",\n\t\t\t\t\t\t\t\t\t\t  kinds=(\"configure\",)\n\t\t\t\t\t\t\t\t\t\t  )\t   \n\t\tsimple_boolean = simple_property(id_=\"simple_boolean\",\n\t\t\t\t\t\t\t\t\t\t  type_=\"boolean\",\n\t\t\t\t\t\t\t\t\t\t  mode=\"readwrite\",\n\t\t\t\t\t\t\t\t\t\t  action=\"external\",\n\t\t\t\t\t\t\t\t\t\t  kinds=(\"configure\",)\n\t\t\t\t\t\t\t\t\t\t  )\t   \n\t\tsimple_ulong = simple_property(id_=\"simple_ulong\",\n\t\t\t\t\t\t\t\t\t\t  type_=\"ulong\",\n\t\t\t\t\t\t\t\t\t\t  mode=\"readwrite\",\n\t\t\t\t\t\t\t\t\t\t  action=\"external\",\n\t\t\t\t\t\t\t\t\t\t  kinds=(\"configure\",)\n", "description": "The process method should process a single \"chunk\" of data and then return.  This method will be called\n\t\t\tfrom the processing thread again, and again, and again until it returns FINISH or stop() is called on the\n\t\t\tcomponent.  If no work is performed, then return NOOP", "category": "simple", "imports": ["from ossie.cf import CF, CF__POA", "from ossie.utils import uuid", "from ossie.resource import Resource", "from ossie.properties import simple_property", "from ossie.properties import simpleseq_property", "from ossie.properties import struct_property", "from ossie.properties import structseq_property", "import Queue, copy, time, threading"]}, {"term": "class", "name": "ssStructVars", "data": "\t\tclass StructVars(object):\n\t\t\tstruct_string = simple_property(id_=\"struct_string\",\n\t\t\t\t\t\t\t\t\t\t  type_=\"string\",\n\t\t\t\t\t\t\t\t\t\t  )\n\t\t\tstruct_boolean = simple_property(id_=\"struct_boolean\",\n\t\t\t\t\t\t\t\t\t\t  type_=\"boolean\",\n\t\t\t\t\t\t\t\t\t\t  )\n\t\t\tstruct_ulong = simple_property(id_=\"struct_ulong\",\n\t\t\t\t\t\t\t\t\t\t  type_=\"ulong\",\n", "description": null, "category": "simple", "imports": ["from ossie.cf import CF, CF__POA", "from ossie.utils import uuid", "from ossie.resource import Resource", "from ossie.properties import simple_property", "from ossie.properties import simpleseq_property", "from ossie.properties import struct_property", "from ossie.properties import structseq_property", "import Queue, copy, time, threading"]}, {"term": "def", "name": "def__init__", "data": "\t\t\tdef __init__(self, **kw):\n\t\t\t\t\"\"\"Construct an initialized instance of this struct definition\"\"\"\n\t\t\t\tfor attrname, classattr in type(self).__dict__.items():\n\t\t\t\t\tif type(classattr) == simple_property:\n\t\t\t\t\t\tclassattr.initialize(self)\n\t\t\t\tfor k,v in kw.items():\n\t\t\t\t\tsetattr(self,k,v)\n", "description": "Construct an initialized instance of this struct definition", "category": "simple", "imports": ["from ossie.cf import CF, CF__POA", "from ossie.utils import uuid", "from ossie.resource import Resource", "from ossie.properties import simple_property", "from ossie.properties import simpleseq_property", "from ossie.properties import struct_property", "from ossie.properties import structseq_property", "import Queue, copy, time, threading"]}, {"term": "def", "name": "def__str__", "data": "\t\t\tdef __str__(self):\n\t\t\t\t\"\"\"Return a string representation of this structure\"\"\"\n\t\t\t\td = {}\n\t\t\t\td[\"struct_string\"] = self.struct_string\n\t\t\t\td[\"struct_boolean\"] = self.struct_boolean\n", "description": "Return a string representation of this structure", "category": "simple", "imports": ["from ossie.cf import CF, CF__POA", "from ossie.utils import uuid", "from ossie.resource import Resource", "from ossie.properties import simple_property", "from ossie.properties import simpleseq_property", "from ossie.properties import struct_property", "from ossie.properties import structseq_property", "import Queue, copy, time, threading"]}, {"term": "def", "name": "defgetId", "data": "\t\t\tdef getId(self):\n\t\t\t\treturn \"struct_vars\"\n", "description": null, "category": "simple", "imports": ["from ossie.cf import CF, CF__POA", "from ossie.utils import uuid", "from ossie.resource import Resource", "from ossie.properties import simple_property", "from ossie.properties import simpleseq_property", "from ossie.properties import struct_property", "from ossie.properties import structseq_property", "import Queue, copy, time, threading"]}, {"term": "def", "name": "defisStruct", "data": "\t\t\tdef isStruct(self):\n\t\t\t\treturn True\n", "description": null, "category": "simple", "imports": ["from ossie.cf import CF, CF__POA", "from ossie.utils import uuid", "from ossie.resource import Resource", "from ossie.properties import simple_property", "from ossie.properties import simpleseq_property", "from ossie.properties import struct_property", "from ossie.properties import structseq_property", "import Queue, copy, time, threading"]}, {"term": "def", "name": "defgetMembers", "data": "\t\t\tdef getMembers(self):\n", "description": null, "category": "simple", "imports": ["from ossie.cf import CF, CF__POA", "from ossie.utils import uuid", "from ossie.resource import Resource", "from ossie.properties import simple_property", "from ossie.properties import simpleseq_property", "from ossie.properties import struct_property", "from ossie.properties import structseq_property", "import Queue, copy, time, threading"]}, {"term": "class", "name": "ssStructSeqVars", "data": "\t\tclass StructSeqVars(object):\n\t\t\tstruct_seq_string = simple_property(id_=\"struct_seq_string\",\n\t\t\t\t\t\t\t\t\t\t  type_=\"string\",\n\t\t\t\t\t\t\t\t\t\t  )\n\t\t\tstruct_seq_boolean = simple_property(id_=\"struct_seq_boolean\",\n\t\t\t\t\t\t\t\t\t\t  type_=\"boolean\",\n\t\t\t\t\t\t\t\t\t\t  )\n\t\t\tstruct_seq_ulong = simple_property(id_=\"struct_seq_ulong\",\n\t\t\t\t\t\t\t\t\t\t  type_=\"ulong\",\n", "description": null, "category": "simple", "imports": ["from ossie.cf import CF, CF__POA", "from ossie.utils import uuid", "from ossie.resource import Resource", "from ossie.properties import simple_property", "from ossie.properties import simpleseq_property", "from ossie.properties import struct_property", "from ossie.properties import structseq_property", "import Queue, copy, time, threading"]}, {"term": "def", "name": "def__init__", "data": "\t\t\tdef __init__(self, struct_seq_string=\"\", struct_seq_boolean=False, struct_seq_ulong=0, struct_seq_objref=\"\", struct_seq_short=0, struct_seq_float=0, struct_seq_octet=0, struct_seq_char=\"\", struct_seq_ushort=0, struct_seq_double=0, struct_seq_long=0, struct_seq_longlong=0, struct_seq_ulonglong=0):\n\t\t\t\tself.struct_seq_string = struct_seq_string\n\t\t\t\tself.struct_seq_boolean = struct_seq_boolean\n\t\t\t\tself.struct_seq_ulong = struct_seq_ulong\n\t\t\t\tself.struct_seq_objref = struct_seq_objref\n\t\t\t\tself.struct_seq_short = struct_seq_short\n\t\t\t\tself.struct_seq_float = struct_seq_float\n\t\t\t\tself.struct_seq_octet = struct_seq_octet\n\t\t\t\tself.struct_seq_char = struct_seq_char\n\t\t\t\tself.struct_seq_ushort = struct_seq_ushort\n\t\t\t\tself.struct_seq_double = struct_seq_double\n\t\t\t\tself.struct_seq_long = struct_seq_long\n\t\t\t\tself.struct_seq_longlong = struct_seq_longlong\n\t\t\t\tself.struct_seq_ulonglong = struct_seq_ulonglong\n", "description": null, "category": "simple", "imports": ["from ossie.cf import CF, CF__POA", "from ossie.utils import uuid", "from ossie.resource import Resource", "from ossie.properties import simple_property", "from ossie.properties import simpleseq_property", "from ossie.properties import struct_property", "from ossie.properties import structseq_property", "import Queue, copy, time, threading"]}, {"term": "def", "name": "def__str__", "data": "\t\t\tdef __str__(self):\n\t\t\t\t\"\"\"Return a string representation of this structure\"\"\"\n\t\t\t\td = {}\n\t\t\t\td[\"struct_seq_string\"] = self.struct_seq_string\n\t\t\t\td[\"struct_seq_boolean\"] = self.struct_seq_boolean\n\t\t\t\td[\"struct_seq_ulong\"] = self.struct_seq_ulong\n\t\t\t\td[\"struct_seq_objref\"] = self.struct_seq_objref\n\t\t\t\td[\"struct_seq_short\"] = self.struct_seq_short\n\t\t\t\td[\"struct_seq_float\"] = self.struct_seq_float\n\t\t\t\td[\"struct_seq_octet\"] = self.struct_seq_octet\n\t\t\t\td[\"struct_seq_char\"] = self.struct_seq_char\n\t\t\t\td[\"struct_seq_ushort\"] = self.struct_seq_ushort\n\t\t\t\td[\"struct_seq_double\"] = self.struct_seq_double\n\t\t\t\td[\"struct_seq_long\"] = self.struct_seq_long\n\t\t\t\td[\"struct_seq_longlong\"] = self.struct_seq_longlong\n\t\t\t\td[\"struct_seq_ulonglong\"] = self.struct_seq_ulonglong\n\t\t\t\treturn str(d)\n", "description": "Return a string representation of this structure", "category": "simple", "imports": ["from ossie.cf import CF, CF__POA", "from ossie.utils import uuid", "from ossie.resource import Resource", "from ossie.properties import simple_property", "from ossie.properties import simpleseq_property", "from ossie.properties import struct_property", "from ossie.properties import structseq_property", "import Queue, copy, time, threading"]}, {"term": "def", "name": "defgetId", "data": "\t\t\tdef getId(self):\n\t\t\t\treturn \"struct_seq_vars\"\n", "description": null, "category": "simple", "imports": ["from ossie.cf import CF, CF__POA", "from ossie.utils import uuid", "from ossie.resource import Resource", "from ossie.properties import simple_property", "from ossie.properties import simpleseq_property", "from ossie.properties import struct_property", "from ossie.properties import structseq_property", "import Queue, copy, time, threading"]}, {"term": "def", "name": "defisStruct", "data": "\t\t\tdef isStruct(self):\n\t\t\t\treturn True\n", "description": null, "category": "simple", "imports": ["from ossie.cf import CF, CF__POA", "from ossie.utils import uuid", "from ossie.resource import Resource", "from ossie.properties import simple_property", "from ossie.properties import simpleseq_property", "from ossie.properties import struct_property", "from ossie.properties import structseq_property", "import Queue, copy, time, threading"]}, {"term": "def", "name": "defgetMembers", "data": "\t\t\tdef getMembers(self):\n\t\t\t\treturn [(\"struct_seq_string\",self.struct_seq_string),(\"struct_seq_boolean\",self.struct_seq_boolean),(\"struct_seq_ulong\",self.struct_seq_ulong),(\"struct_seq_objref\",self.struct_seq_objref),(\"struct_seq_short\",self.struct_seq_short),(\"struct_seq_float\",self.struct_seq_float),(\"struct_seq_octet\",self.struct_seq_octet),(\"struct_seq_char\",self.struct_seq_char),(\"struct_seq_ushort\",self.struct_seq_ushort),(\"struct_seq_double\",self.struct_seq_double),(\"struct_seq_long\",self.struct_seq_long),(\"struct_seq_longlong\",self.struct_seq_longlong),(\"struct_seq_ulonglong\",self.struct_seq_ulonglong)]\n\n", "description": null, "category": "simple", "imports": ["from ossie.cf import CF, CF__POA", "from ossie.utils import uuid", "from ossie.resource import Resource", "from ossie.properties import simple_property", "from ossie.properties import simpleseq_property", "from ossie.properties import struct_property", "from ossie.properties import structseq_property", "import Queue, copy, time, threading"]}], [{"term": "def", "name": "trim", "data": "def trim(value, num):\n\treturn value[:num]\n\n", "description": null, "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "noop", "data": "def noop(value, param=None):\n\t\"\"\"A noop filter that always return its first argument and does nothing with\n\tits second (optional) one.\n\tUseful for testing out whitespace in filter arguments (see #19882).\"\"\"\n\treturn value\n\n", "description": "A noop filter that always return its first argument and does nothing with\n\tits second (optional) one.\n\tUseful for testing out whitespace in filter arguments (see #19882).", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "context_stack_length", "data": "def context_stack_length(context):\n\treturn len(context.dicts)\n\n", "description": null, "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "no_params", "data": "def no_params():\n\t\"\"\"Expected no_params __doc__\"\"\"\n\treturn \"no_params - Expected result\"\n\n", "description": "Expected no_params __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "one_param", "data": "def one_param(arg):\n\t\"\"\"Expected one_param __doc__\"\"\"\n\treturn \"one_param - Expected result: %s\" % arg\n\n", "description": "Expected one_param __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "explicit_no_context", "data": "def explicit_no_context(arg):\n\t\"\"\"Expected explicit_no_context __doc__\"\"\"\n\treturn \"explicit_no_context - Expected result: %s\" % arg\n\n", "description": "Expected explicit_no_context __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "no_params_with_context", "data": "def no_params_with_context(context):\n\t\"\"\"Expected no_params_with_context __doc__\"\"\"\n\treturn \"no_params_with_context - Expected result (context value: %s)\" % context['value']\n\n", "description": "Expected no_params_with_context __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "params_and_context", "data": "def params_and_context(context, arg):\n\t\"\"\"Expected params_and_context __doc__\"\"\"\n\treturn \"params_and_context - Expected result (context value: %s): %s\" % (context['value'], arg)\n\n", "description": "Expected params_and_context __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "simple_two_params", "data": "def simple_two_params(one, two):\n\t\"\"\"Expected simple_two_params __doc__\"\"\"\n\treturn \"simple_two_params - Expected result: %s, %s\" % (one, two)\n\n", "description": "Expected simple_two_params __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "simple_one_default", "data": "def simple_one_default(one, two='hi'):\n\t\"\"\"Expected simple_one_default __doc__\"\"\"\n\treturn \"simple_one_default - Expected result: %s, %s\" % (one, two)\n\n", "description": "Expected simple_one_default __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "simple_unlimited_args", "data": "def simple_unlimited_args(one, two='hi', *args):\n\t\"\"\"Expected simple_unlimited_args __doc__\"\"\"\n\treturn \"simple_unlimited_args - Expected result: %s\" % (\n\t\t', '.join(six.text_type(arg) for arg in [one, two] + list(args))\n\t)\n\n", "description": "Expected simple_unlimited_args __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "simple_only_unlimited_args", "data": "def simple_only_unlimited_args(*args):\n\t\"\"\"Expected simple_only_unlimited_args __doc__\"\"\"\n\treturn \"simple_only_unlimited_args - Expected result: %s\" % ', '.join(six.text_type(arg) for arg in args)\n\n", "description": "Expected simple_only_unlimited_args __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "simple_unlimited_args_kwargs", "data": "def simple_unlimited_args_kwargs(one, two='hi', *args, **kwargs):\n\t\"\"\"Expected simple_unlimited_args_kwargs __doc__\"\"\"\n\t# Sort the dictionary by key to guarantee the order for testing.\n\tsorted_kwarg = sorted(six.iteritems(kwargs), key=operator.itemgetter(0))\n\treturn \"simple_unlimited_args_kwargs - Expected result: %s / %s\" % (\n\t\t', '.join(six.text_type(arg) for arg in [one, two] + list(args)),\n\t\t', '.join('%s=%s' % (k, v) for (k, v) in sorted_kwarg)\n\t)\n\n", "description": "Expected simple_unlimited_args_kwargs __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "simple_tag_without_context_parameter", "data": "def simple_tag_without_context_parameter(arg):\n\t\"\"\"Expected simple_tag_without_context_parameter __doc__\"\"\"\n\treturn \"Expected result\"\n\n", "description": "Expected simple_tag_without_context_parameter __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "escape_naive", "data": "def escape_naive(context):\n\t\"\"\"A tag that doesn't even think about escaping issues\"\"\"\n\treturn \"Hello {0}!\".format(context['name'])\n\n", "description": "A tag that doesn't even think about escaping issues", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "escape_explicit", "data": "def escape_explicit(context):\n\t\"\"\"A tag that uses escape explicitly\"\"\"\n\treturn escape(\"Hello {0}!\".format(context['name']))\n\n", "description": "A tag that uses escape explicitly", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "escape_format_html", "data": "def escape_format_html(context):\n\t\"\"\"A tag that uses format_html\"\"\"\n\treturn format_html(\"Hello {0}!\", context['name'])\n\n", "description": "A tag that uses format_html", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "current_app", "data": "def current_app(context):\n\treturn \"%s\" % context.current_app\n\n", "description": null, "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "use_l10n", "data": "def use_l10n(context):\n\treturn \"%s\" % context.use_l10n\n\n", "description": null, "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "minustwo_overridden_name", "data": "def minustwo_overridden_name(value):\n\treturn value - 2\n\n", "description": null, "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "fassignment_no_params", "data": "\tdef assignment_no_params():\n\t\t\"\"\"Expected assignment_no_params __doc__\"\"\"\n", "description": "Expected assignment_no_params __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "fassignment_tag_without_context_parameter", "data": "\tdef assignment_tag_without_context_parameter(arg):\n\t\t\"\"\"Expected assignment_tag_without_context_parameter __doc__\"\"\"\n", "description": "Expected assignment_tag_without_context_parameter __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "counter", "data": "def counter(parser, token):\n\treturn CounterNode()\n\n", "description": null, "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "class", "name": "CounterNode", "data": "class CounterNode(template.Node):\n\tdef __init__(self):\n\t\tself.count = 0\n\n\tdef render(self, context):\n\t\tcount = self.count\n\t\tself.count = count + 1\n\t\treturn count\n", "description": null, "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}], [{"term": "def", "name": "simple_queue", "data": "def simple_queue():\n\t\"\"\"Fixture that get the queue.\"\"\"\n\tsimple_queue_fixed = queue.SimpleQueue()\n\twith patch(\n\t\t\"homeassistant.components.system_log.queue.SimpleQueue\",\n\t\treturn_value=simple_queue_fixed,\n\t):\n\t\tyield simple_queue_fixed\n\n", "description": "Fixture that get the queue.", "category": "simple", "imports": ["import asyncio", "import logging", "import queue", "from unittest.mock import MagicMock, patch", "import pytest", "from homeassistant.bootstrap import async_setup_component", "from homeassistant.components import system_log", "from homeassistant.core import callback", "from tests.common import async_capture_events"]}, {"term": "def", "name": "ncdef_async_block_until_queue_empty", "data": "async def _async_block_until_queue_empty(hass, sq):\n\t# Unfortunately we are stuck with polling\n\tawait hass.async_block_till_done()\n\twhile not sq.empty():\n\t\tawait asyncio.sleep(0.01)\n\thass.data[system_log.DOMAIN].acquire()\n\thass.data[system_log.DOMAIN].release()\n\tawait hass.async_block_till_done()\n\tawait hass.async_block_till_done()\n\n", "description": null, "category": "simple", "imports": ["import asyncio", "import logging", "import queue", "from unittest.mock import MagicMock, patch", "import pytest", "from homeassistant.bootstrap import async_setup_component", "from homeassistant.components import system_log", "from homeassistant.core import callback", "from tests.common import async_capture_events"]}, {"term": "def", "name": "ncdefget_error_log", "data": "async def get_error_log(hass_ws_client):\n\t\"\"\"Fetch all entries from system_log via the API.\"\"\"\n\tclient = await hass_ws_client()\n\tawait client.send_json({\"id\": 5, \"type\": \"system_log/list\"})\n\n\tmsg = await client.receive_json()\n\n\tassert msg[\"id\"] == 5\n\tassert msg[\"success\"]\n\treturn msg[\"result\"]\n\n", "description": "Fetch all entries from system_log via the API.", "category": "simple", "imports": ["import asyncio", "import logging", "import queue", "from unittest.mock import MagicMock, patch", "import pytest", "from homeassistant.bootstrap import async_setup_component", "from homeassistant.components import system_log", "from homeassistant.core import callback", "from tests.common import async_capture_events"]}, {"term": "def", "name": "_generate_and_log_exception", "data": "def _generate_and_log_exception(exception, log):\n\ttry:\n\t\traise Exception(exception)\n\texcept:  # noqa: E722 pylint: disable=bare-except\n\t\t_LOGGER.exception(log)\n\n", "description": null, "category": "simple", "imports": ["import asyncio", "import logging", "import queue", "from unittest.mock import MagicMock, patch", "import pytest", "from homeassistant.bootstrap import async_setup_component", "from homeassistant.components import system_log", "from homeassistant.core import callback", "from tests.common import async_capture_events"]}, {"term": "def", "name": "find_log", "data": "def find_log(logs, level):\n\t\"\"\"Return log with specific level.\"\"\"\n\tif not isinstance(level, tuple):\n\t\tlevel = (level,)\n\tlog = next(\n\t\t(log for log in logs if log[\"level\"] in level),\n\t\tNone,\n\t)\n\tassert log is not None\n\treturn log\n\n", "description": "Return log with specific level.", "category": "simple", "imports": ["import asyncio", "import logging", "import queue", "from unittest.mock import MagicMock, patch", "import pytest", "from homeassistant.bootstrap import async_setup_component", "from homeassistant.components import system_log", "from homeassistant.core import callback", "from tests.common import async_capture_events"]}, {"term": "def", "name": "assert_log", "data": "def assert_log(log, exception, message, level):\n\t\"\"\"Assert that specified values are in a specific log entry.\"\"\"\n\tif not isinstance(message, list):\n\t\tmessage = [message]\n\n\tassert log[\"name\"] == \"test_logger\"\n\tassert exception in log[\"exception\"]\n\tassert message == log[\"message\"]\n\tassert level == log[\"level\"]\n\tassert \"timestamp\" in log\n\n", "description": "Assert that specified values are in a specific log entry.", "category": "simple", "imports": ["import asyncio", "import logging", "import queue", "from unittest.mock import MagicMock, patch", "import pytest", "from homeassistant.bootstrap import async_setup_component", "from homeassistant.components import system_log", "from homeassistant.core import callback", "from tests.common import async_capture_events"]}, {"term": "def", "name": "get_frame", "data": "def get_frame(name):\n\t\"\"\"Get log stack frame.\"\"\"\n\treturn (name, 5, None, None)\n\n", "description": "Get log stack frame.", "category": "simple", "imports": ["import asyncio", "import logging", "import queue", "from unittest.mock import MagicMock, patch", "import pytest", "from homeassistant.bootstrap import async_setup_component", "from homeassistant.components import system_log", "from homeassistant.core import callback", "from tests.common import async_capture_events"]}, {"term": "def", "name": "ncdeftest_normal_logs", "data": "async def test_normal_logs(hass, simple_queue, hass_ws_client):\n\t\"\"\"Test that debug and info are not logged.\"\"\"\n\tawait async_setup_component(hass, system_log.DOMAIN, BASIC_CONFIG)\n\n\t_LOGGER.debug(\"debug\")\n\t_LOGGER.info(\"info\")\n\tawait _async_block_until_queue_empty(hass, simple_queue)\n\n\t# Assert done by get_error_log\n\tlogs = await get_error_log(hass_ws_client)\n\tassert len([msg for msg in logs if msg[\"level\"] in (\"DEBUG\", \"INFO\")]) == 0\n\n", "description": "Test that debug and info are not logged.", "category": "simple", "imports": ["import asyncio", "import logging", "import queue", "from unittest.mock import MagicMock, patch", "import pytest", "from homeassistant.bootstrap import async_setup_component", "from homeassistant.components import system_log", "from homeassistant.core import callback", "from tests.common import async_capture_events"]}, {"term": "def", "name": "ncdeftest_exception", "data": "async def test_exception(hass, simple_queue, hass_ws_client):\n\t\"\"\"Test that exceptions are logged and retrieved correctly.\"\"\"\n\tawait async_setup_component(hass, system_log.DOMAIN, BASIC_CONFIG)\n\t_generate_and_log_exception(\"exception message\", \"log message\")\n\tawait _async_block_until_queue_empty(hass, simple_queue)\n\tlog = find_log(await get_error_log(hass_ws_client), \"ERROR\")\n\tassert log is not None\n\tassert_log(log, \"exception message\", \"log message\", \"ERROR\")\n\n", "description": "Test that exceptions are logged and retrieved correctly.", "category": "simple", "imports": ["import asyncio", "import logging", "import queue", "from unittest.mock import MagicMock, patch", "import pytest", "from homeassistant.bootstrap import async_setup_component", "from homeassistant.components import system_log", "from homeassistant.core import callback", "from tests.common import async_capture_events"]}, {"term": "def", "name": "ncdeftest_warning", "data": "async def test_warning(hass, simple_queue, hass_ws_client):\n\t\"\"\"Test that warning are logged and retrieved correctly.\"\"\"\n\tawait async_setup_component(hass, system_log.DOMAIN, BASIC_CONFIG)\n\t_LOGGER.warning(\"warning message\")\n\tawait _async_block_until_queue_empty(hass, simple_queue)\n\n\tlog = find_log(await get_error_log(hass_ws_client), \"WARNING\")\n\tassert_log(log, \"\", \"warning message\", \"WARNING\")\n\n", "description": "Test that warning are logged and retrieved correctly.", "category": "simple", "imports": ["import asyncio", "import logging", "import queue", "from unittest.mock import MagicMock, patch", "import pytest", "from homeassistant.bootstrap import async_setup_component", "from homeassistant.components import system_log", "from homeassistant.core import callback", "from tests.common import async_capture_events"]}, {"term": "def", "name": "ncdeftest_error", "data": "async def test_error(hass, simple_queue, hass_ws_client):\n\t\"\"\"Test that errors are logged and retrieved correctly.\"\"\"\n\tawait async_setup_component(hass, system_log.DOMAIN, BASIC_CONFIG)\n\t_LOGGER.error(\"error message\")\n\tawait _async_block_until_queue_empty(hass, simple_queue)\n\n\tlog = find_log(await get_error_log(hass_ws_client), \"ERROR\")\n\tassert_log(log, \"\", \"error message\", \"ERROR\")\n\n", "description": "Test that errors are logged and retrieved correctly.", "category": "simple", "imports": ["import asyncio", "import logging", "import queue", "from unittest.mock import MagicMock, patch", "import pytest", "from homeassistant.bootstrap import async_setup_component", "from homeassistant.components import system_log", "from homeassistant.core import callback", "from tests.common import async_capture_events"]}, {"term": "def", "name": "ncdeftest_config_not_fire_event", "data": "async def test_config_not_fire_event(hass, simple_queue):\n\t\"\"\"Test that errors are not posted as events with default config.\"\"\"\n\tawait async_setup_component(hass, system_log.DOMAIN, BASIC_CONFIG)\n\tevents = []\n\n\t@callback\n\tdef event_listener(event):\n\t\t\"\"\"Listen to events of type system_log_event.\"\"\"\n\t\tevents.append(event)\n\n\thass.bus.async_listen(system_log.EVENT_SYSTEM_LOG, event_listener)\n\n\t_LOGGER.error(\"error message\")\n\tawait _async_block_until_queue_empty(hass, simple_queue)\n\n\tassert len(events) == 0\n\n", "description": "Test that errors are not posted as events with default config.", "category": "simple", "imports": ["import asyncio", "import logging", "import queue", "from unittest.mock import MagicMock, patch", "import pytest", "from homeassistant.bootstrap import async_setup_component", "from homeassistant.components import system_log", "from homeassistant.core import callback", "from tests.common import async_capture_events"]}, {"term": "def", "name": "ncdeftest_error_posted_as_event", "data": "async def test_error_posted_as_event(hass, simple_queue):\n\t\"\"\"Test that error are posted as events.\"\"\"\n\tawait async_setup_component(\n\t\thass, system_log.DOMAIN, {\"system_log\": {\"max_entries\": 2, \"fire_event\": True}}\n\t)\n\tevents = async_capture_events(hass, system_log.EVENT_SYSTEM_LOG)\n\n\t_LOGGER.error(\"error message\")\n\tawait _async_block_until_queue_empty(hass, simple_queue)\n\n\tassert len(events) == 1\n\tassert_log(events[0].data, \"\", \"error message\", \"ERROR\")\n\n", "description": "Test that error are posted as events.", "category": "simple", "imports": ["import asyncio", "import logging", "import queue", "from unittest.mock import MagicMock, patch", "import pytest", "from homeassistant.bootstrap import async_setup_component", "from homeassistant.components import system_log", "from homeassistant.core import callback", "from tests.common import async_capture_events"]}, {"term": "def", "name": "ncdeftest_critical", "data": "async def test_critical(hass, simple_queue, hass_ws_client):\n\t\"\"\"Test that critical are logged and retrieved correctly.\"\"\"\n\tawait async_setup_component(hass, system_log.DOMAIN, BASIC_CONFIG)\n\t_LOGGER.critical(\"critical message\")\n\tawait _async_block_until_queue_empty(hass, simple_queue)\n\n\tlog = find_log(await get_error_log(hass_ws_client), \"CRITICAL\")\n\tassert_log(log, \"\", \"critical message\", \"CRITICAL\")\n\n", "description": "Test that critical are logged and retrieved correctly.", "category": "simple", "imports": ["import asyncio", "import logging", "import queue", "from unittest.mock import MagicMock, patch", "import pytest", "from homeassistant.bootstrap import async_setup_component", "from homeassistant.components import system_log", "from homeassistant.core import callback", "from tests.common import async_capture_events"]}, {"term": "def", "name": "ncdeftest_remove_older_logs", "data": "async def test_remove_older_logs(hass, simple_queue, hass_ws_client):\n\t\"\"\"Test that older logs are rotated out.\"\"\"\n\tawait async_setup_component(hass, system_log.DOMAIN, BASIC_CONFIG)\n\t_LOGGER.error(\"error message 1\")\n\t_LOGGER.error(\"error message 2\")\n\t_LOGGER.error(\"error message 3\")\n\tawait _async_block_until_queue_empty(hass, simple_queue)\n\n\tlog = await get_error_log(hass_ws_client)\n\tassert_log(log[0], \"\", \"error message 3\", \"ERROR\")\n\tassert_log(log[1], \"\", \"error message 2\", \"ERROR\")\n\n", "description": "Test that older logs are rotated out.", "category": "simple", "imports": ["import asyncio", "import logging", "import queue", "from unittest.mock import MagicMock, patch", "import pytest", "from homeassistant.bootstrap import async_setup_component", "from homeassistant.components import system_log", "from homeassistant.core import callback", "from tests.common import async_capture_events"]}, {"term": "def", "name": "log_msg", "data": "def log_msg(nr=2):\n\t\"\"\"Log an error at same line.\"\"\"\n\t_LOGGER.error(\"error message %s\", nr)\n\n", "description": "Log an error at same line.", "category": "simple", "imports": ["import asyncio", "import logging", "import queue", "from unittest.mock import MagicMock, patch", "import pytest", "from homeassistant.bootstrap import async_setup_component", "from homeassistant.components import system_log", "from homeassistant.core import callback", "from tests.common import async_capture_events"]}, {"term": "def", "name": "ncdeftest_dedupe_logs", "data": "async def test_dedupe_logs(hass, simple_queue, hass_ws_client):\n\t\"\"\"Test that duplicate log entries are dedupe.\"\"\"\n\tawait async_setup_component(hass, system_log.DOMAIN, {})\n\t_LOGGER.error(\"error message 1\")\n\tlog_msg()\n\tlog_msg(\"2-2\")\n\t_LOGGER.error(\"error message 3\")\n\tawait _async_block_until_queue_empty(hass, simple_queue)\n\n\tlog = await get_error_log(hass_ws_client)\n\tassert_log(log[0], \"\", \"error message 3\", \"ERROR\")\n\tassert log[1][\"count\"] == 2\n\tassert_log(log[1], \"\", [\"error message 2\", \"error message 2-2\"], \"ERROR\")\n\n\tlog_msg()\n\tawait _async_block_until_queue_empty(hass, simple_queue)\n\n\tlog = await get_error_log(hass_ws_client)\n\tassert_log(log[0], \"\", [\"error message 2\", \"error message 2-2\"], \"ERROR\")\n\tassert log[0][\"timestamp\"] > log[0][\"first_occurred\"]\n\n\tlog_msg(\"2-3\")\n\tlog_msg(\"2-4\")\n\tlog_msg(\"2-5\")\n\tlog_msg(\"2-6\")\n\tawait _async_block_until_queue_empty(hass, simple_queue)\n\n\tlog = await get_error_log(hass_ws_client)\n\tassert_log(\n\t\tlog[0],\n\t\t\"\",\n\t\t[\n\t\t\t\"error message 2-2\",\n\t\t\t\"error message 2-3\",\n\t\t\t\"error message 2-4\",\n\t\t\t\"error message 2-5\",\n\t\t\t\"error message 2-6\",\n\t\t],\n\t\t\"ERROR\",\n\t)\n\n", "description": "Test that duplicate log entries are dedupe.", "category": "simple", "imports": ["import asyncio", "import logging", "import queue", "from unittest.mock import MagicMock, patch", "import pytest", "from homeassistant.bootstrap import async_setup_component", "from homeassistant.components import system_log", "from homeassistant.core import callback", "from tests.common import async_capture_events"]}, {"term": "def", "name": "ncdeftest_clear_logs", "data": "async def test_clear_logs(hass, simple_queue, hass_ws_client):\n\t\"\"\"Test that the log can be cleared via a service call.\"\"\"\n\tawait async_setup_component(hass, system_log.DOMAIN, BASIC_CONFIG)\n\t_LOGGER.error(\"error message\")\n\tawait _async_block_until_queue_empty(hass, simple_queue)\n\n\tawait hass.services.async_call(system_log.DOMAIN, system_log.SERVICE_CLEAR, {})\n\tawait _async_block_until_queue_empty(hass, simple_queue)\n\n\t# Assert done by get_error_log\n\tawait get_error_log(hass_ws_client)\n\n", "description": "Test that the log can be cleared via a service call.", "category": "simple", "imports": ["import asyncio", "import logging", "import queue", "from unittest.mock import MagicMock, patch", "import pytest", "from homeassistant.bootstrap import async_setup_component", "from homeassistant.components import system_log", "from homeassistant.core import callback", "from tests.common import async_capture_events"]}, {"term": "def", "name": "ncdeftest_write_log", "data": "async def test_write_log(hass):\n\t\"\"\"Test that error propagates to logger.\"\"\"\n\tawait async_setup_component(hass, system_log.DOMAIN, BASIC_CONFIG)\n\tlogger = MagicMock()\n\twith patch(\"logging.getLogger\", return_value=logger) as mock_logging:\n\t\tawait hass.services.async_call(\n\t\t\tsystem_log.DOMAIN, system_log.SERVICE_WRITE, {\"message\": \"test_message\"}\n\t\t)\n\t\tawait hass.async_block_till_done()\n\tmock_logging.assert_called_once_with(\"homeassistant.components.system_log.external\")\n\tassert logger.method_calls[0] == (\"error\", (\"test_message\",))\n\n", "description": "Test that error propagates to logger.", "category": "simple", "imports": ["import asyncio", "import logging", "import queue", "from unittest.mock import MagicMock, patch", "import pytest", "from homeassistant.bootstrap import async_setup_component", "from homeassistant.components import system_log", "from homeassistant.core import callback", "from tests.common import async_capture_events"]}, {"term": "def", "name": "ncdeftest_write_choose_logger", "data": "async def test_write_choose_logger(hass):\n\t\"\"\"Test that correct logger is chosen.\"\"\"\n\tawait async_setup_component(hass, system_log.DOMAIN, BASIC_CONFIG)\n\twith patch(\"logging.getLogger\") as mock_logging:\n\t\tawait hass.services.async_call(\n\t\t\tsystem_log.DOMAIN,\n\t\t\tsystem_log.SERVICE_WRITE,\n\t\t\t{\"message\": \"test_message\", \"logger\": \"myLogger\"},\n\t\t)\n\t\tawait hass.async_block_till_done()\n\tmock_logging.assert_called_once_with(\"myLogger\")\n\n", "description": "Test that correct logger is chosen.", "category": "simple", "imports": ["import asyncio", "import logging", "import queue", "from unittest.mock import MagicMock, patch", "import pytest", "from homeassistant.bootstrap import async_setup_component", "from homeassistant.components import system_log", "from homeassistant.core import callback", "from tests.common import async_capture_events"]}, {"term": "def", "name": "ncdeftest_write_choose_level", "data": "async def test_write_choose_level(hass):\n\t\"\"\"Test that correct logger is chosen.\"\"\"\n\tawait async_setup_component(hass, system_log.DOMAIN, BASIC_CONFIG)\n\tlogger = MagicMock()\n\twith patch(\"logging.getLogger\", return_value=logger):\n\t\tawait hass.services.async_call(\n\t\t\tsystem_log.DOMAIN,\n\t\t\tsystem_log.SERVICE_WRITE,\n\t\t\t{\"message\": \"test_message\", \"level\": \"debug\"},\n\t\t)\n\t\tawait hass.async_block_till_done()\n\tassert logger.method_calls[0] == (\"debug\", (\"test_message\",))\n\n", "description": "Test that correct logger is chosen.", "category": "simple", "imports": ["import asyncio", "import logging", "import queue", "from unittest.mock import MagicMock, patch", "import pytest", "from homeassistant.bootstrap import async_setup_component", "from homeassistant.components import system_log", "from homeassistant.core import callback", "from tests.common import async_capture_events"]}, {"term": "def", "name": "ncdeftest_unknown_path", "data": "async def test_unknown_path(hass, simple_queue, hass_ws_client):\n\t\"\"\"Test error logged from unknown path.\"\"\"\n\tawait async_setup_component(hass, system_log.DOMAIN, BASIC_CONFIG)\n\t_LOGGER.findCaller = MagicMock(return_value=(\"unknown_path\", 0, None, None))\n\t_LOGGER.error(\"error message\")\n\tawait _async_block_until_queue_empty(hass, simple_queue)\n\tlog = (await get_error_log(hass_ws_client))[0]\n\tassert log[\"source\"] == [\"unknown_path\", 0]\n\n", "description": "Test error logged from unknown path.", "category": "simple", "imports": ["import asyncio", "import logging", "import queue", "from unittest.mock import MagicMock, patch", "import pytest", "from homeassistant.bootstrap import async_setup_component", "from homeassistant.components import system_log", "from homeassistant.core import callback", "from tests.common import async_capture_events"]}, {"term": "def", "name": "ncdefasync_log_error_from_test_path", "data": "async def async_log_error_from_test_path(hass, path, sq):\n\t\"\"\"Log error while mocking the path.\"\"\"\n\tcall_path = \"internal_path.py\"\n\twith patch.object(\n\t\t_LOGGER, \"findCaller\", MagicMock(return_value=(call_path, 0, None, None))\n\t), patch(\n\t\t\"traceback.extract_stack\",\n\t\tMagicMock(\n\t\t\treturn_value=[\n\t\t\t\tget_frame(\"main_path/main.py\"),\n\t\t\t\tget_frame(path),\n\t\t\t\tget_frame(call_path),\n\t\t\t\tget_frame(\"venv_path/logging/log.py\"),\n\t\t\t]\n\t\t),\n\t):\n\t\t_LOGGER.error(\"error message\")\n\t\tawait _async_block_until_queue_empty(hass, sq)\n\n", "description": "Log error while mocking the path.", "category": "simple", "imports": ["import asyncio", "import logging", "import queue", "from unittest.mock import MagicMock, patch", "import pytest", "from homeassistant.bootstrap import async_setup_component", "from homeassistant.components import system_log", "from homeassistant.core import callback", "from tests.common import async_capture_events"]}, {"term": "def", "name": "ncdeftest_homeassistant_path", "data": "async def test_homeassistant_path(hass, simple_queue, hass_ws_client):\n\t\"\"\"Test error logged from Home Assistant path.\"\"\"\n\tawait async_setup_component(hass, system_log.DOMAIN, BASIC_CONFIG)\n\twith patch(\n\t\t\"homeassistant.components.system_log.HOMEASSISTANT_PATH\",\n\t\tnew=[\"venv_path/homeassistant\"],\n\t):\n\t\tawait async_log_error_from_test_path(\n\t\t\thass, \"venv_path/homeassistant/component/component.py\", simple_queue\n\t\t)\n\t\tlog = (await get_error_log(hass_ws_client))[0]\n\tassert log[\"source\"] == [\"component/component.py\", 5]\n\n", "description": "Test error logged from Home Assistant path.", "category": "simple", "imports": ["import asyncio", "import logging", "import queue", "from unittest.mock import MagicMock, patch", "import pytest", "from homeassistant.bootstrap import async_setup_component", "from homeassistant.components import system_log", "from homeassistant.core import callback", "from tests.common import async_capture_events"]}, {"term": "def", "name": "ncdeftest_config_path", "data": "async def test_config_path(hass, simple_queue, hass_ws_client):\n\t\"\"\"Test error logged from config path.\"\"\"\n\tawait async_setup_component(hass, system_log.DOMAIN, BASIC_CONFIG)\n\twith patch.object(hass.config, \"config_dir\", new=\"config\"):\n\t\tawait async_log_error_from_test_path(\n\t\t\thass, \"config/custom_component/test.py\", simple_queue\n\t\t)\n\t\tlog = (await get_error_log(hass_ws_client))[0]\n\tassert log[\"source\"] == [\"custom_component/test.py\", 5]\n", "description": "Test error logged from config path.", "category": "simple", "imports": ["import asyncio", "import logging", "import queue", "from unittest.mock import MagicMock, patch", "import pytest", "from homeassistant.bootstrap import async_setup_component", "from homeassistant.components import system_log", "from homeassistant.core import callback", "from tests.common import async_capture_events"]}], [{"term": "def", "name": "in_tree", "data": "def in_tree(response, name, uclass, drv, depth, last_child):\n\tlines = [x.strip() for x in response.splitlines()]\n\tleaf = ''\n\tif depth != 0:\n\t\tleaf = '   ' + '\t' * (depth - 1) ;\n\t\tif not last_child:\n\t\t\tleaf = leaf + r'\\|'\n\t\telse:\n\t\t\t\t\t\tleaf = leaf + '`'\n\n\tleaf = leaf + '-- ' + name\n\tline = (r' *{:10.10} *[0-9]*  \\[ [ +] \\]   {:20.20}  [` |]{}$'\n\t\t\t.format(uclass, drv, leaf))\n\tprog = re.compile(line)\n\tfor l in lines:\n\t\tif prog.match(l):\n\t\t\treturn True\n\treturn False\n\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}, {"term": "def", "name": "test_bind_unbind_with_node", "data": "def test_bind_unbind_with_node(u_boot_console):\n\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, False)\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'simple_bus', 1, True)\n\n\t#Unbind child #1. No error expected and all devices should be there except for bind-test-child1\n\tresponse = u_boot_console.run_command('unbind  /bind-test/bind-test-child1')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'simple_bus', 0, True)\n\tassert 'bind-test-child1' not in tree\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'simple_bus', 1, True)\n\n\t#bind child #1. No error expected and all devices should be there\n\tresponse = u_boot_console.run_command('bind  /bind-test/bind-test-child1 phy_sandbox')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, True)\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'simple_bus', 1, False)\n\n\t#Unbind child #2. No error expected and all devices should be there except for bind-test-child2\n\tresponse = u_boot_console.run_command('unbind  /bind-test/bind-test-child2')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, True)\n\tassert 'bind-test-child2' not in tree\n\n\n\t#Bind child #2. No error expected and all devices should be there\n\tresponse = u_boot_console.run_command('bind /bind-test/bind-test-child2 simple_bus')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, False)\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'simple_bus', 1, True)\n\n\t#Unbind parent. No error expected. All devices should be removed and unbound\n\tresponse = u_boot_console.run_command('unbind  /bind-test')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert 'bind-test' not in tree\n\tassert 'bind-test-child1' not in tree\n\tassert 'bind-test-child2' not in tree\n\n\t#try binding invalid node with valid driver\n\tresponse = u_boot_console.run_command('bind  /not-a-valid-node simple_bus')\n\tassert response != ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert 'not-a-valid-node' not in tree\n\n\t#try binding valid node with invalid driver\n\tresponse = u_boot_console.run_command('bind  /bind-test not_a_driver')\n\tassert response != ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert 'bind-test' not in tree\n\n\t#bind /bind-test. Device should come up as well as its children\n\tresponse = u_boot_console.run_command('bind  /bind-test simple_bus')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, False)\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'simple_bus', 1, True)\n\n\tresponse = u_boot_console.run_command('unbind  /bind-test')\n\tassert response == ''\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}, {"term": "def", "name": "get_next_line", "data": "def get_next_line(tree, name):\n\ttreelines = [x.strip() for x in tree.splitlines() if x.strip()]\n\tchild_line = ''\n\tfor idx, line in enumerate(treelines):\n\t\tif ('-- ' + name) in line:\n\t\t\ttry:\n\t\t\t\tchild_line = treelines[idx+1]\n\t\t\texcept:\n\t\t\t\tpass\n\t\t\tbreak\n\treturn child_line\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}, {"term": "def", "name": "test_bind_unbind_with_uclass", "data": "def test_bind_unbind_with_uclass(u_boot_console):\n\t#bind /bind-test\n\tresponse = u_boot_console.run_command('bind  /bind-test simple_bus')\n\tassert response == ''\n\n\t#make sure bind-test-child2 is there and get its uclass/index pair\n\ttree = u_boot_console.run_command('dm tree')\n\tchild2_line = [x.strip() for x in tree.splitlines() if '-- bind-test-child2' in x]\n\tassert len(child2_line) == 1\n\n\tchild2_uclass = child2_line[0].split()[0]\n\tchild2_index = int(child2_line[0].split()[1])\n\n\t#bind simple_bus as a child of bind-test-child2\n\tresponse = u_boot_console.run_command('bind  {} {} simple_bus'.format(child2_uclass, child2_index, 'simple_bus'))\n\n\t#check that the child is there and its uclass/index pair is right\n\ttree = u_boot_console.run_command('dm tree')\n\n\tchild_of_child2_line = get_next_line(tree, 'bind-test-child2')\n\tassert child_of_child2_line\n\tchild_of_child2_index = int(child_of_child2_line.split()[1])\n\tassert in_tree(tree, 'simple_bus', 'simple_bus', 'simple_bus', 2, True)\n\tassert child_of_child2_index == child2_index + 1\n\n\t#unbind the child and check it has been removed\n\tresponse = u_boot_console.run_command('unbind  simple_bus {}'.format(child_of_child2_index))\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'simple_bus', 1, True)\n\tassert not in_tree(tree, 'simple_bus', 'simple_bus', 'simple_bus', 2, True)\n\tchild_of_child2_line = get_next_line(tree, 'bind-test-child2')\n\tassert child_of_child2_line == ''\n\n\t#bind simple_bus as a child of bind-test-child2\n\tresponse = u_boot_console.run_command('bind  {} {} simple_bus'.format(child2_uclass, child2_index, 'simple_bus'))\n\n\t#check that the child is there and its uclass/index pair is right\n\ttree = u_boot_console.run_command('dm tree')\n\ttreelines = [x.strip() for x in tree.splitlines() if x.strip()]\n\n\tchild_of_child2_line = get_next_line(tree, 'bind-test-child2')\n\tassert child_of_child2_line\n\tchild_of_child2_index = int(child_of_child2_line.split()[1])\n\tassert in_tree(tree, 'simple_bus', 'simple_bus', 'simple_bus', 2, True)\n\tassert child_of_child2_index == child2_index + 1\n\n\t#unbind the child and check it has been removed\n\tresponse = u_boot_console.run_command('unbind  {} {} simple_bus'.format(child2_uclass, child2_index, 'simple_bus'))\n\tassert response == ''\n\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'simple_bus', 1, True)\n\n\tchild_of_child2_line = get_next_line(tree, 'bind-test-child2')\n\tassert child_of_child2_line == ''\n\n\t#unbind the child again and check it doesn't change the tree\n\ttree_old = u_boot_console.run_command('dm tree')\n\tresponse = u_boot_console.run_command('unbind  {} {} simple_bus'.format(child2_uclass, child2_index, 'simple_bus'))\n\ttree_new = u_boot_console.run_command('dm tree')\n\n\tassert response == ''\n\tassert tree_old == tree_new\n\n\tresponse = u_boot_console.run_command('unbind  /bind-test')\n\tassert response == ''\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}], [{"term": "class", "name": "SimpleModel", "data": "class SimpleModel(Model):\n\t\"\"\"Simple Test Model\"\"\"\n\tname = StringProperty()\n\tstrs = ListProperty(str)\n\tnum = IntegerProperty()\n", "description": "Simple Test Model", "category": "simple", "imports": ["from boto.sdb.db.property import ListProperty, StringProperty, ReferenceProperty, IntegerProperty", "from boto.sdb.db.model import Model", "import time"]}, {"term": "class", "name": "SubModel", "data": "class SubModel(SimpleModel):\n\t\"\"\"Simple Subclassed Model\"\"\"\n\tref = ReferenceProperty(SimpleModel, collection_name=\"reverse_ref\")\n\n", "description": "Simple Subclassed Model", "category": "simple", "imports": ["from boto.sdb.db.property import ListProperty, StringProperty, ReferenceProperty, IntegerProperty", "from boto.sdb.db.model import Model", "import time"]}, {"term": "class", "name": "TestQuerying", "data": "class TestQuerying(object):\n\t\"\"\"Test different querying capabilities\"\"\"\n\n\tdef setup_class(cls):\n\t\t\"\"\"Setup this class\"\"\"\n\t\tcls.objs = []\n\n\t\to = SimpleModel()\n\t\to.name = \"Simple Object\"\n\t\to.strs = [\"B\", \"A\", \"C\", \"Foo\"]\n\t\to.num = 1\n\t\to.put()\n\t\tcls.objs.append(o)\n\n\t\to2 = SimpleModel()\n\t\to2.name = \"Referenced Object\"\n\t\to2.num = 2\n\t\to2.put()\n\t\tcls.objs.append(o2)\n\n\t\to3 = SubModel()\n\t\to3.name = \"Sub Object\"\n\t\to3.num = 3\n\t\to3.ref = o2\n\t\to3.put()\n\t\tcls.objs.append(o3)\n\n\t\ttime.sleep(3)\n\n\n\n\tdef teardown_class(cls):\n\t\t\"\"\"Remove our objects\"\"\"\n\t\tfor o in cls.objs:\n\t\t\ttry:\n\t\t\t\to.delete()\n\t\t\texcept:\n\t\t\t\tpass\n\n\tdef test_find(self):\n\t\t\"\"\"Test using the \"Find\" method\"\"\"\n\t\tassert(SimpleModel.find(name=\"Simple Object\").next().id == self.objs[0].id)\n\t\tassert(SimpleModel.find(name=\"Referenced Object\").next().id == self.objs[1].id)\n\t\tassert(SimpleModel.find(name=\"Sub Object\").next().id == self.objs[2].id)\n\n\tdef test_like_filter(self):\n\t\t\"\"\"Test a \"like\" filter\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name like\", \"% Object\")\n\t\tassert(query.count() == 3)\n\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name not like\", \"% Object\")\n\t\tassert(query.count() == 0)\n\n\tdef test_equals_filter(self):\n\t\t\"\"\"Test an \"=\" and \"!=\" filter\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name =\", \"Simple Object\")\n\t\tassert(query.count() == 1)\n\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name !=\", \"Simple Object\")\n\t\tassert(query.count() == 2)\n\n\tdef test_or_filter(self):\n\t\t\"\"\"Test a filter function as an \"or\" \"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name =\", [\"Simple Object\", \"Sub Object\"])\n\t\tassert(query.count() == 2)\n\n\tdef test_and_filter(self):\n\t\t\"\"\"Test Multiple filters which are an \"and\" \"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name like\", \"% Object\")\n\t\tquery.filter(\"name like\", \"Simple %\")\n\t\tassert(query.count() == 1)\n\n\tdef test_none_filter(self):\n\t\t\"\"\"Test filtering for a value that's not set\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"ref =\", None)\n\t\tassert(query.count() == 2)\n\n\tdef test_greater_filter(self):\n\t\t\"\"\"Test filtering Using >, >=\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"num >\", 1)\n\t\tassert(query.count() == 2)\n\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"num >=\", 1)\n\t\tassert(query.count() == 3)\n\n\tdef test_less_filter(self):\n\t\t\"\"\"Test filtering Using <, <=\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"num <\", 3)\n\t\tassert(query.count() == 2)\n\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"num <=\", 3)\n\t\tassert(query.count() == 3)\n\n\tdef test_query_on_list(self):\n\t\t\"\"\"Test querying on a list\"\"\"\n\t\tassert(SimpleModel.find(strs=\"A\").next().id == self.objs[0].id)\n\t\tassert(SimpleModel.find(strs=\"B\").next().id == self.objs[0].id)\n\t\tassert(SimpleModel.find(strs=\"C\").next().id == self.objs[0].id)\n\n\tdef test_like(self):\n\t\t\"\"\"Test with a \"like\" expression\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"strs like\", \"%oo%\")\n\t\tprint query.get_query()\n\t\tassert(query.count() == 1)\n", "description": "Test different querying capabilities", "category": "simple", "imports": ["from boto.sdb.db.property import ListProperty, StringProperty, ReferenceProperty, IntegerProperty", "from boto.sdb.db.model import Model", "import time"]}], [], [{"term": "def", "name": "GenerateTopasScripts", "data": "def GenerateTopasScripts(BaseDirectory, iteration, **variable_dict):\n\t\"\"\"\n\tThis file simply returns a list object, where each list entry corresponds to\n\ta line in the topas script.\n\tWhen it is called from an Optimiser object,it will receive a dictionary that contains the current values of \n\tthe variables you set up in optimisation_params when you initialised the optimiser.\n\t\"\"\"\n\t\n\tSimpleBeam = []\n\tSimpleBeam.append('# Set threading self:')\n\tSimpleBeam.append('------------------------------------------------------------')\n\tSimpleBeam.append('i:Ts/NumberOfThreads = 0  ')\n\tSimpleBeam.append('i:Ts/ShowHistoryCountAtInterval = 1000000')\n\tSimpleBeam.append('b:Ts/ShowHistoryCountOnSingleLine = \"True\"')\n\tSimpleBeam.append('')\n\tSimpleBeam.append('# Add World:')\n\tSimpleBeam.append('------------------------------------------------------------')\n\tSimpleBeam.append('s:Ge/World/Type = \"TsBox\"')\n\tSimpleBeam.append('s:Ge/World/Material = \"Air\"')\n\tSimpleBeam.append('d:Ge/World/HLX = 250 mm ')\n\tSimpleBeam.append('d:Ge/World/HLY = 250 mm')\n\tSimpleBeam.append('d:Ge/World/HLZ = 1200.0 mm')\n\tSimpleBeam.append('d:Ge/World/RotX = 0. deg')\n\tSimpleBeam.append('d:Ge/World/RotY = 0. deg')\n\tSimpleBeam.append('d:Ge/World/RotZ = 0. deg')\n\tSimpleBeam.append('')\n\tSimpleBeam.append('d:Ge/SID = 1000 mm')\n\tSimpleBeam.append('d:Ge/SecondaryCollimatorOffset = 20 mm')\n\tSimpleBeam.append('')\n\tSimpleBeam.append('# Ta scattering foil')\n\tSimpleBeam.append('# ------------------------------------------------------------')\n\tSimpleBeam.append('s:Ge/TaFoil/Type\t\t\t   = \"TsCylinder\"')\n\tSimpleBeam.append('s:Ge/TaFoil/Parent\t\t\t = \"World\"')\n\tSimpleBeam.append('s:Ge/TaFoil/Material\t\t   = \"G4_Ta\"')\n\tSimpleBeam.append('d:Ge/TaFoil/TransX\t\t\t = 0 cm')\n\tSimpleBeam.append('d:Ge/TaFoil/TransY\t\t\t = 0 cm')\n\tSimpleBeam.append('d:Ge/TaFoil/TransZ\t\t\t = Ge/SID mm')\n\tSimpleBeam.append('d:Ge/TaFoil/RotX\t\t\t   = 0 deg')\n\tSimpleBeam.append('d:Ge/TaFoil/RotY\t\t\t   = 0 deg')\n\tSimpleBeam.append('d:Ge/TaFoil/RotZ\t\t\t   = 0 deg')\n\tSimpleBeam.append('d:Ge/TaFoil/RMax\t\t\t   = 10 mm')\n\tSimpleBeam.append('d:Ge/TaFoil/HL\t\t\t\t = 0.1 mm')\n\tSimpleBeam.append('s:Ge/TaFoil/Color\t\t\t  = \"lightblue\"')\n\tSimpleBeam.append('')\n\tSimpleBeam.append('# Al scattering foil')\n\tSimpleBeam.append('# ------------------------------------------------------------')\n\tSimpleBeam.append('s:Ge/AlFoil/Type\t\t\t   = \"TsCylinder\"')\n\tSimpleBeam.append('s:Ge/AlFoil/Parent\t\t\t = \"World\"')\n\tSimpleBeam.append('s:Ge/AlFoil/Material\t\t   = \"G4_Al\"')\n\tSimpleBeam.append('d:Ge/AlFoil/TransX\t\t\t = 0 cm')\n\tSimpleBeam.append('d:Ge/AlFoil/TransY\t\t\t = 0 cm')\n\tSimpleBeam.append('d:Ge/AlFoil/foil_offset\t\t= 24.9 mm')\n\tSimpleBeam.append('d:Ge/AlFoil/TransZ\t\t\t = Ge/TaFoil/TransZ - Ge/AlFoil/foil_offset mm')\n\tSimpleBeam.append('d:Ge/AlFoil/RotX\t\t\t   = 0 deg')\n\tSimpleBeam.append('d:Ge/AlFoil/RotY\t\t\t   = 0 deg')\n\tSimpleBeam.append('d:Ge/AlFoil/RotZ\t\t\t   = 0 deg')\n\tSimpleBeam.append('d:Ge/AlFoil/RMax\t\t\t   = 10 mm')\n\tSimpleBeam.append('d:Ge/AlFoil/HL\t\t\t\t = 1. mm')\n\tSimpleBeam.append('s:Ge/AlFoil/Color\t\t\t  = \"red\"')\n\tSimpleBeam.append('')\n\tSimpleBeam.append('# Add phase space scorer below foils:')\n\tSimpleBeam.append('------------------------------------------------------------')\n\tSimpleBeam.append('# s:Ge/Magic/Type\t = \"TsBox\"')\n\tSimpleBeam.append('# s:Ge/Magic/Parent   = \"World\"')\n\tSimpleBeam.append('# s:Ge/Magic/Material = \"Vacuum\"')\n\tSimpleBeam.append('# d:Ge/Magic/HLX\t  = 100 mm')\n\tSimpleBeam.append('# d:Ge/Magic/HLY\t  = 100 mm')\n\tSimpleBeam.append('# d:Ge/Magic/HLZ\t  = 1 mm')\n\tSimpleBeam.append('# d:Ge/Magic/TransX   = 0. cm')\n\tSimpleBeam.append('# d:Ge/Magic/TransY   = 0. cm')\n\tSimpleBeam.append('# d:Ge/Magic/TransZ   = Ge/AlFoil/TransZ - 3 mm')\n\tSimpleBeam.append('# d:Ge/Magic/RotX\t = 0. deg')\n\tSimpleBeam.append('# d:Ge/Magic/RotY\t = 0. deg')\n\tSimpleBeam.append('# d:Ge/Magic/RotZ\t = 0. deg')\n\tSimpleBeam.append('# s:Ge/Magic/Color\t= \"skyblue\"')\n\tSimpleBeam.append('# s:Ge/Magic/DrawingStyle = \"wireframe\"')\n\tSimpleBeam.append('')\n\tSimpleBeam.append('')\n\tSimpleBeam.append('# s:Sc/PhaseSpaceFromColl/Quantity\t\t\t\t\t= \"PhaseSpace\"')\n\tSimpleBeam.append('# b:Sc/PhaseSpaceFromColl/OutputToConsole\t\t\t = \"False\"')\n\tSimpleBeam.append('# s:Sc/PhaseSpaceFromColl/Surface\t\t\t\t\t = \"Magic/ZMinusSurface\"')\n\tSimpleBeam.append('# s:Sc/PhaseSpaceFromColl/OutputType\t\t\t\t  = \"Binary\" # ASCII, Binary, Limited or ROOT')\n\tSimpleBeam.append('# s:Sc/PhaseSpaceFromColl/OutputFile\t\t\t\t  = \"Results/scattered_phase_space\"')\n\tSimpleBeam.append('# i:Sc/PhaseSpaceFromColl/OutputBufferSize\t\t\t= 1000')\n\tSimpleBeam.append('# #s:Sc/PhaseSpaceFromColl/OnlyIncludeParticlesGoing  = \"In\"')\n\tSimpleBeam.append('# b:Sc/PhaseSpaceFromColl/IncludeTOPASTime\t\t\t= \"False\"')\n\tSimpleBeam.append('# b:Sc/PhaseSpaceFromColl/IncludeTimeOfFlight\t\t = \"False\"')\n\tSimpleBeam.append('# b:Sc/PhaseSpaceFromColl/IncludeRunID\t\t\t\t= \"False\"')\n\tSimpleBeam.append('# b:Sc/PhaseSpaceFromColl/IncludeEventID\t\t\t  = \"False\"')\n\tSimpleBeam.append('# b:Sc/PhaseSpaceFromColl/IncludeTrackID\t\t\t  = \"False\"')\n\tSimpleBeam.append('# b:Sc/PhaseSpaceFromColl/IncludeParentID\t\t\t = \"False\"')\n\tSimpleBeam.append('# b:Sc/PhaseSpaceFromColl/IncludeCreatorProcess\t   = \"False\"')\n\tSimpleBeam.append('# b:Sc/PhaseSpaceFromColl/IncludeVertexInfo\t\t   = \"False\"')\n\tSimpleBeam.append('# b:Sc/PhaseSpaceFromColl/IncludeSeed\t\t\t\t = \"False\"')\n\tSimpleBeam.append('')\n\tSimpleBeam.append('')\n\tSimpleBeam.append('# # Beam parameters (parameterised source):')\n\tSimpleBeam.append('------------------------------------------------------------')\n\tSimpleBeam.append('s:So/Beam/Type\t\t\t\t\t = \"Beam\"')\n\tSimpleBeam.append('sc:So/Beam/Component\t\t\t\t= \"ElectronSource\"')\n\tSimpleBeam.append('sc:So/Beam/BeamParticle\t\t\t = \"e-\"')\n\tSimpleBeam.append(f'dc:So/Beam/BeamEnergy\t\t\t   = {variable_dict[\"BeamEnergy\"]} MeV')\n\tSimpleBeam.append(f'uc:So/Beam/BeamEnergySpread\t\t = {variable_dict[\"BeamEnergySpread\"]}')\n\tSimpleBeam.append('sc:So/Beam/BeamPositionDistribution = \"Gaussian\" ')\n\tSimpleBeam.append('sc:So/Beam/BeamAngularDistribution  = \"Gaussian\" ')\n\tSimpleBeam.append('sc:So/Beam/BeamPositionCutoffShape = \"Ellipse\"')\n\tSimpleBeam.append(f'dc:So/Beam/BeamPositionCutoffX = {variable_dict[\"BeamPositionCutoffX\"]} mm')\n\tSimpleBeam.append(f'dc:So/Beam/BeamPositionCutoffY = {variable_dict[\"BeamPositionCutoffY\"]} mm')\n\tSimpleBeam.append(f'dc:So/Beam/BeamPositionSpreadX = {variable_dict[\"BeamPositionSpreadX\"]} mm')\n\tSimpleBeam.append(f'dc:So/Beam/BeamPositionSpreadY = {variable_dict[\"BeamPositionSpreadY\"]} mm')\n\tSimpleBeam.append(f'dc:So/Beam/BeamAngularCutoffX = {variable_dict[\"BeamAngularCutoffX\"]} deg')\n\tSimpleBeam.append(f'dc:So/Beam/BeamAngularCutoffY = {variable_dict[\"BeamAngularCutoffY\"]} deg')\n\tSimpleBeam.append(f'dc:So/Beam/BeamAngularSpreadX = {variable_dict[\"BeamAngularSpreadX\"]} deg')\n\tSimpleBeam.append(f'dc:So/Beam/BeamAngularSpreadY = {variable_dict[\"BeamAngularSpreadY\"]} deg')\n\tSimpleBeam.append('ic:So/Beam/NumberOfHistoriesInRun = 10000000')\n\tSimpleBeam.append('# ic:So/Beam/NumberOfHistoriesInRun = 500')\n\tSimpleBeam.append('')\n\tSimpleBeam.append('# # Electron source position')\n\tSimpleBeam.append('# ------------------------------------------------------------')\n\tSimpleBeam.append('s:Ge/ElectronSource/Parent = \"World\"')\n\tSimpleBeam.append('s:Ge/ElectronSource/Type=\"TsSPhere\"')\n\tSimpleBeam.append('d:Ge/ElectronSource/Rmax = 5 mm')\n\tSimpleBeam.append('d:Ge/ElectronSource/TransZ = 1100 mm')\n\tSimpleBeam.append('d:Ge/ElectronSource/RotX = 180. deg')\n\tSimpleBeam.append('s:Ge/ElectronSource/Material = Ge/World/Material')\n\tSimpleBeam.append('s:Ge/ElectronSource/Color = \"yellow\"')\n\tSimpleBeam.append('sc:Ge/ElectronSource/DrawingStyle = \"Solid\"')\n\tSimpleBeam.append('')\n\tSimpleBeam.append('')\n\tSimpleBeam.append('')\n\tSimpleBeam.append('# Add the phantom')\n\tSimpleBeam.append('------------------------------------------------------------')\n\tSimpleBeam.append('# Phantom')\n\tSimpleBeam.append('s:Ge/Phantom/Type = \"TsBox\"')\n\tSimpleBeam.append('s:Ge/Phantom/Parent = \"World\"')\n\tSimpleBeam.append('sc:Ge/Phantom/Material = \"G4_WATER\"')\n\tSimpleBeam.append('# We draw the phantom to be field size plus one beamlet')\n\tSimpleBeam.append('dc:Ge/Phantom/HLX = 75 mm')\n\tSimpleBeam.append('dc:Ge/Phantom/HLY = 75 mm')\n\tSimpleBeam.append('dc:Ge/Phantom/HLZ =  75 mm')\n\tSimpleBeam.append('dc:Ge/Phantom/TransX = 0. cm')\n\tSimpleBeam.append('dc:Ge/Phantom/TransY = 0. cm')\n\tSimpleBeam.append('dc:Ge/Phantom/TransZ = 70. cm')\n\tSimpleBeam.append('dc:Ge/Phantom/RotX = 0. deg')\n\tSimpleBeam.append('dc:Ge/Phantom/RotY = 0. deg')\n\tSimpleBeam.append('dc:Ge/Phantom/RotZ = 0. deg')\n\tSimpleBeam.append('ic:Ge/Phantom/XBins = 30')\n\tSimpleBeam.append('ic:Ge/Phantom/YBins = 30')\n\tSimpleBeam.append('ic:Ge/Phantom/ZBins = 30')\n\tSimpleBeam.append('sc:Ge/Phantom/Color\t= \"green\"')\n\tSimpleBeam.append('sc:Ge/Phantom/DrawingStyle = \"Solid\"')\n\tSimpleBeam.append('')\n\tSimpleBeam.append('')\n\tSimpleBeam.append('# Add Volume scorer to phantom:')\n\tSimpleBeam.append('------------------------------------------------------------')\n\tSimpleBeam.append('s:Sc/PhantomScorer/Component = \"Phantom\"')\n\tSimpleBeam.append('s:Sc/PhantomScorer/Material = \"Water\"')\n\tSimpleBeam.append('s:Sc/PhantomScorer/Quantity\t\t\t\t  = \"DoseToMedium\"')\n\tSimpleBeam.append('b:Sc/PhantomScorer/OutputToConsole\t\t   = \"FALSE\"')\n\tSimpleBeam.append('s:Sc/PhantomScorer/IfOutputFileAlreadyExists = \"Overwrite\"')\n\tSimpleBeam.append('s:Sc/PhantomScorer/OutputType = \"Binary\" ')\n\tSimpleBeam.append('s:Sc/PhantomScorer/OutputFile\t\t\t\t   =  \"../Results/WaterTank_itt_' + str(iteration) + '\"')\n\tSimpleBeam.append('')\n\tSimpleBeam.append('')\n\tSimpleBeam.append('# Graphics View and trajectory filters:')\n\tSimpleBeam.append('------------------------------------------------------------')\n\tSimpleBeam.append('b:Gr/Enable = \"False\"  ')\n\tSimpleBeam.append('s:Gr/ViewA/Type\t\t\t  = \"OpenGL\"')\n\tSimpleBeam.append('d:Gr/ViewA/Theta\t\t\t= 90 deg')\n\tSimpleBeam.append('d:Gr/ViewA/Phi\t\t\t  = 0 deg')\n\tSimpleBeam.append('u:Gr/ViewA/TransX\t\t   = 0')\n\tSimpleBeam.append('u:Gr/ViewA/TransY\t\t   = 0.')\n\tSimpleBeam.append('s:Gr/ViewA/Projection\t   = \"Orthogonal\"')\n\tSimpleBeam.append('d:Gr/ViewA/PerspectiveAngle = 60 deg')\n\tSimpleBeam.append('u:Gr/ViewA/Zoom\t\t\t = 1')\n\tSimpleBeam.append('b:Gr/ViewA/IncludeStepPoints = \"False\"')\n\tSimpleBeam.append('b:Gr/ViewA/HiddenLineRemovalForTrajectories = \"True\"')\n\tSimpleBeam.append('')\n\tSimpleBeam.append('# Physics')\n\tSimpleBeam.append('------------------------------------------------------------')\n\tSimpleBeam.append('sv:Ph/Default/Modules = 1 \"g4em-standard_opt0\"')\n\tSimpleBeam.append('b:Ph/ListProcesses = \"False\"')\n\tSimpleBeam.append('')\n\tSimpleBeam.append('------------------------------------------------------------')\n\tSimpleBeam.append('# QT')\n\tSimpleBeam.append('# --')\n\tSimpleBeam.append('Ts/UseQt = Gr/Enable')\n\tSimpleBeam.append('Ts/PauseBeforeQuit = Gr/Enable')\n\tSimpleBeam.append('Ts/IncludeDefaultGeant4QtWidgets = \"F\"')\n\n\treturn [SimpleBeam], ['SimpleBeam']\n", "description": "\n\tThis file simply returns a list object, where each list entry corresponds to\n\ta line in the topas script.\n\tWhen it is called from an Optimiser object,it will receive a dictionary that contains the current values of \n\tthe variables you set up in optimisation_params when you initialised the optimiser.\n\t", "category": "simple", "imports": ["from pathlib import Path"]}], [{"term": "def", "name": "mixture_simple", "data": "def mixture_simple():\n\tc = mpc.mixture.LTE(species=[mpc.species.from_name(sp) for sp in \n\t\t\t\t\t\t\t\t ['O2','O2+','O','O-','O+','O++']],\n\t\t\t\t\t\tx0=[1,0,0,0,0,0],\n\t\t\t\t\t\tT=1000, P=101325,\n\t\t\t\t\t\tgfe_ni0=1e20, gfe_reltol=1e-10, gfe_maxiter=1000)\n\treturn c\n", "description": null, "category": "simple", "imports": ["import pytest", "import minplascalc as mpc"]}, {"term": "def", "name": "mixture_complex", "data": "def mixture_complex():\n\tc = mpc.mixture.LTE(species=[mpc.species.from_name(sp) for sp in \n\t\t\t\t\t\t\t\t ['O2','O2+','O','O+','O++','CO','CO+','C',\n\t\t\t\t\t\t\t\t  'C+','C++','SiO','SiO+','Si','Si+', 'Si++']],\n\t\t\t\t\t\tx0=[0,0,0,0,0,0.5,0,0,0,0,0.5,0,0,0,0],\n\t\t\t\t\t\tT=10000, P=101325,\n\t\t\t\t\t\tgfe_ni0=1e20, gfe_reltol=1e-10, gfe_maxiter=1000)\n\treturn c\n", "description": null, "category": "simple", "imports": ["import pytest", "import minplascalc as mpc"]}, {"term": "def", "name": "test_density_simple", "data": "def test_density_simple(mixture_simple, T, P, result, tol):\n\tmixture_simple.T = T\n\tmixture_simple.P = P\n\n\tthisresult = mixture_simple.calculate_density()\n\n\tassert thisresult == pytest.approx(result, abs=tol)\n\n", "description": null, "category": "simple", "imports": ["import pytest", "import minplascalc as mpc"]}, {"term": "def", "name": "test_density_complex", "data": "def test_density_complex(mixture_complex, x0, result, tol):\n\tmixture_complex.x0 = x0\n\n\tthisresult = mixture_complex.calculate_density()\n\n\tassert thisresult == pytest.approx(result, abs=tol)\n", "description": null, "category": "simple", "imports": ["import pytest", "import minplascalc as mpc"]}, {"term": "def", "name": "test_enthalpy_simple", "data": "def test_enthalpy_simple(mixture_simple, T, P, result, tol):\n\tmixture_simple.T = T\n\tmixture_simple.P = P\n\t\n\tthisresult = mixture_simple.calculate_enthalpy()\n\n\tassert thisresult == pytest.approx(result, abs=tol)\n", "description": null, "category": "simple", "imports": ["import pytest", "import minplascalc as mpc"]}, {"term": "def", "name": "test_enthalpy_complex", "data": "def test_enthalpy_complex(mixture_complex, x0, result, tol):\n\tmixture_complex.x0 = x0\n\t\n\tthisresult = mixture_complex.calculate_enthalpy()\n\n\tassert thisresult == pytest.approx(result, abs=tol)\n\n", "description": null, "category": "simple", "imports": ["import pytest", "import minplascalc as mpc"]}, {"term": "def", "name": "test_heat_capacity_simple", "data": "def test_heat_capacity_simple(mixture_simple, T, P, result, tol):\n\tmixture_simple.T = T\n\tmixture_simple.P = P\n\n\tthisresult = mixture_simple.calculate_heat_capacity()\n\n\tassert thisresult == pytest.approx(result, abs=tol)\n\n", "description": null, "category": "simple", "imports": ["import pytest", "import minplascalc as mpc"]}, {"term": "def", "name": "test_heat_capacity_complex", "data": "def test_heat_capacity_complex(mixture_complex, x0, result, tol):\n\tmixture_complex.x0 = x0\n\n\tthisresult = mixture_complex.calculate_heat_capacity()\n\n\tassert thisresult == pytest.approx(result, abs=tol)\n", "description": null, "category": "simple", "imports": ["import pytest", "import minplascalc as mpc"]}, {"term": "def", "name": "test_LTE_fallthrough", "data": "def test_LTE_fallthrough(mixture_simple, T, P, result, tol):\n\tmixture_simple.T = T\n\tmixture_simple.P = P\n\t\n\tmixture_simple.calculate_composition()\n\tthisresult = mixture_simple.calculate_enthalpy()\n\n\tassert thisresult == pytest.approx(result, abs=tol)\n\n", "description": null, "category": "simple", "imports": ["import pytest", "import minplascalc as mpc"]}, {"term": "def", "name": "test_calculate_viscosity", "data": "def test_calculate_viscosity(mixture_simple):\n\twith pytest.raises(NotImplementedError):\n\t\tmixture_simple.calculate_viscosity()\n\n", "description": null, "category": "simple", "imports": ["import pytest", "import minplascalc as mpc"]}, {"term": "def", "name": "test_calculate_thermal_conductivity", "data": "def test_calculate_thermal_conductivity(mixture_simple):\n\twith pytest.raises(NotImplementedError):\n\t\tmixture_simple.calculate_thermal_conductivity()\n\n", "description": null, "category": "simple", "imports": ["import pytest", "import minplascalc as mpc"]}, {"term": "def", "name": "test_calculate_electrical_conductivity", "data": "def test_calculate_electrical_conductivity(mixture_simple):\n\twith pytest.raises(NotImplementedError):\n\t\tmixture_simple.calculate_electrical_conductivity()\n\n", "description": null, "category": "simple", "imports": ["import pytest", "import minplascalc as mpc"]}, {"term": "def", "name": "test_calculate_total_emission_coefficient", "data": "def test_calculate_total_emission_coefficient(mixture_simple):\n\twith pytest.raises(NotImplementedError):\n\t\tmixture_simple.calculate_total_emission_coefficient()\n\n", "description": null, "category": "simple", "imports": ["import pytest", "import minplascalc as mpc"]}, {"term": "def", "name": "test_species_setter_exception", "data": "def test_species_setter_exception(mixture_simple):\n\twith pytest.raises(TypeError):\n\t\tmixture_simple.species = [mpc.species.from_name(sp) \n\t\t\t\t\t\t\t\t  for sp in ['O','O+']]\n\n", "description": null, "category": "simple", "imports": ["import pytest", "import minplascalc as mpc"]}, {"term": "def", "name": "test_species_item_exception", "data": "def test_species_item_exception(mixture_simple):\n\twith pytest.raises(TypeError):\n\t\tmixture_simple.species[0] = mpc.species.from_name('O')\n\n", "description": null, "category": "simple", "imports": ["import pytest", "import minplascalc as mpc"]}, {"term": "def", "name": "test_x0_item_exception", "data": "def test_x0_item_exception(mixture_simple):\n\twith pytest.raises(TypeError):\n\t\tmixture_simple.x0[0] = 0.5\n", "description": null, "category": "simple", "imports": ["import pytest", "import minplascalc as mpc"]}], [{"term": "def", "name": "asInt", "data": "def asInt( value ):\n\tif isinstance( value, float ):\n\t\treturn int(round(value,0))\n\treturn value\n", "description": null, "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "def", "name": "fglReadPixels", "data": "\tdef glReadPixels( x,y,width,height,format,type=type, array=None ):\n\t\t\"\"\"Read specified pixels from the current display buffer\n\t\t\n\t\tThis typed version returns data in your specified default \n\t\tarray data-type format, or in the passed array, which will \n\t\tbe converted to the array-type required by the format.\n\t\t\"\"\"\n\t\tx,y,width,height = asInt(x),asInt(y),asInt(width),asInt(height)\n\t\tarrayType = arrays.GL_CONSTANT_TO_ARRAY_TYPE[ images.TYPE_TO_ARRAYTYPE.get(type,type) ]\n\t\tif array is None:\n\t\t\tarray = images.SetupPixelRead( format, (width,height), type )\n\t\telse:\n\t\t\tarray = arrayType.asArray( array )\r\n\t\timageData = arrayType.voidDataPointer( array )\n\t\tsimple.glReadPixels( \n\t\t\tint(x),int(y),\n\t\t\tint(width), int(height),\n\t\t\tformat,type, \n\t\t\timageData\n\t\t)\n", "description": "Read specified pixels from the current display buffer\n\t\t\n\t\tThis typed version returns data in your specified default \n\t\tarray data-type format, or in the passed array, which will \n\t\tbe converted to the array-type required by the format.\n\t\t", "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "def", "name": "fglGetTexImage", "data": "\tdef glGetTexImage( target, level,format,type=type ):\n\t\t\"\"\"Get a texture-level as an image\"\"\"\n\t\tfrom OpenGL.GL import glget\n\t\tdims = [glget.glGetTexLevelParameteriv( target, level, simple.GL_TEXTURE_WIDTH )]\n\t\tif target != simple.GL_TEXTURE_1D:\n\t\t\tdims.append( glget.glGetTexLevelParameteriv( target, level, simple.GL_TEXTURE_HEIGHT ) )\n\t\t\tif target != simple.GL_TEXTURE_2D:\n\t\t\t\tdims.append( glget.glGetTexLevelParameteriv( target, level, simple.GL_TEXTURE_DEPTH ) )\n\t\tarray = images.SetupPixelRead( format, tuple(dims), type )\n\t\tarrayType = arrays.GL_CONSTANT_TO_ARRAY_TYPE[ images.TYPE_TO_ARRAYTYPE.get(type,type) ]\n\t\tsimple.glGetTexImage( \n\t\t\ttarget, level, format, type, ctypes.c_void_p( arrayType.dataPointer(array)) \n\t\t)\n", "description": "Get a texture-level as an image", "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "def", "name": "glReadPixels", "data": "def glReadPixels( x,y,width,height,format,type, array=None, outputType=str ):\n\t\"\"\"Read specified pixels from the current display buffer\n\t\n\tx,y,width,height -- location and dimensions of the image to read \n\t\tfrom the buffer\n\tformat -- pixel format for the resulting data\n\ttype -- data-format for the resulting data\n\tarray -- optional array/offset into which to store the value\n\toutputType -- default (str) provides string output of the \n\t\tresults iff OpenGL.UNSIGNED_BYTE_IMAGES_AS_STRING is True \n\t\tand type == GL_UNSIGNED_BYTE.  Any other value will cause \n\t\toutput in the default array output format.\n\t\n\treturns the pixel data array in the format defined by the \n\tformat, type and outputType\n\t\"\"\"\n\tx,y,width,height = asInt(x),asInt(y),asInt(width),asInt(height)\n\t\n\tarrayType = arrays.GL_CONSTANT_TO_ARRAY_TYPE[ images.TYPE_TO_ARRAYTYPE.get(type,type) ]\n\tif array is None:\n\t\tarray = images.SetupPixelRead( format, (width,height), type )\n\telse:\n\t\tarray = arrayType.asArray( array )\n\timageData = arrayType.voidDataPointer( array )\n\tsimple.glReadPixels( \n\t\tx,y,width,height,\n\t\tformat,type, \n\t\timageData\n\t)\n\tif outputType is str:\n\t\treturn images.returnFormat( array, type )\n\telse:\n\t\treturn array\n", "description": "Read specified pixels from the current display buffer\n\t\n\tx,y,width,height -- location and dimensions of the image to read \n\t\tfrom the buffer\n\tformat -- pixel format for the resulting data\n\ttype -- data-format for the resulting data\n\tarray -- optional array/offset into which to store the value\n\toutputType -- default (str) provides string output of the \n\t\tresults iff OpenGL.UNSIGNED_BYTE_IMAGES_AS_STRING is True \n\t\tand type == GL_UNSIGNED_BYTE.  Any other value will cause \n\t\toutput in the default array output format.\n\t\n\treturns the pixel data array in the format defined by the \n\tformat, type and outputType\n\t", "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "def", "name": "glGetTexImage", "data": "def glGetTexImage( target, level,format,type, outputType=str ):\n\t\"\"\"Get a texture-level as an image\n\t\n\ttarget -- enum constant for the texture engine to be read \n\tlevel -- the mip-map level to read \n\tformat -- image format to read out the data \n\ttype -- data-type into which to read the data\n\t\n\toutputType -- default (str) provides string output of the \n\t\tresults iff OpenGL.UNSIGNED_BYTE_IMAGES_AS_STRING is True \n\t\tand type == GL_UNSIGNED_BYTE.  Any other value will cause \n\t\toutput in the default array output format.\n\t\n\treturns the pixel data array in the format defined by the \n\tformat, type and outputType\n\t\"\"\"\n\tfrom OpenGL.GL import glget\n\tdims = [glget.glGetTexLevelParameteriv( target, level, simple.GL_TEXTURE_WIDTH )]\n\tif target != simple.GL_TEXTURE_1D:\n\t\tdims.append( glget.glGetTexLevelParameteriv( target, level, simple.GL_TEXTURE_HEIGHT ) )\n\t\tif target != simple.GL_TEXTURE_2D:\n\t\t\tdims.append( glget.glGetTexLevelParameteriv( target, level, simple.GL_TEXTURE_DEPTH ) )\n\tarray = images.SetupPixelRead( format, tuple(dims), type )\n\tarrayType = arrays.GL_CONSTANT_TO_ARRAY_TYPE[ images.TYPE_TO_ARRAYTYPE.get(type,type) ]\n\tsimple.glGetTexImage( \n\t\ttarget, level, format, type, ctypes.c_void_p( arrayType.dataPointer(array)) \n\t)\n\tif outputType is str:\n\t\treturn images.returnFormat( array, type )\n\telse:\n\t\treturn array\n\n", "description": "Get a texture-level as an image\n\t\n\ttarget -- enum constant for the texture engine to be read \n\tlevel -- the mip-map level to read \n\tformat -- image format to read out the data \n\ttype -- data-type into which to read the data\n\t\n\toutputType -- default (str) provides string output of the \n\t\tresults iff OpenGL.UNSIGNED_BYTE_IMAGES_AS_STRING is True \n\t\tand type == GL_UNSIGNED_BYTE.  Any other value will cause \n\t\toutput in the default array output format.\n\t\n\treturns the pixel data array in the format defined by the \n\tformat, type and outputType\n\t", "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "def", "name": "asWrapper", "data": "def asWrapper( value ):\n\tif not isinstance( value, wrapper.Wrapper ):\n\t\treturn wrapper.wrapper( value )\n\treturn value\n", "description": null, "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "def", "name": "asIntConverter", "data": "def asIntConverter( value, *args ):\n\tif isinstance( value, float ):\n\t\treturn int(round(value,0))\n\treturn value\n", "description": null, "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "def", "name": "setDimensionsAsInts", "data": "def setDimensionsAsInts( baseOperation ):\n\t\"\"\"Set arguments with names in INT_DIMENSION_NAMES to asInt processing\"\"\"\n\tbaseOperation = asWrapper( baseOperation )\n\targNames = getattr( baseOperation, 'pyConverterNames', baseOperation.argNames )\n\tfor i,argName in enumerate(argNames):\n\t\tif argName in INT_DIMENSION_NAMES:\n\t\t\tbaseOperation.setPyConverter( argName, asIntConverter )\n\treturn baseOperation\n\n\t\n", "description": "Set arguments with names in INT_DIMENSION_NAMES to asInt processing", "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "class", "name": "ImageInputConverter", "data": "class ImageInputConverter( object ):\n\tdef __init__( self, rank, pixelsName=None, typeName='type' ):\n\t\tself.rank = rank\n\t\tself.typeName = typeName\n\t\tself.pixelsName = pixelsName\n\tdef finalise( self, wrapper ):\n\t\t\"\"\"Get our pixel index from the wrapper\"\"\"\n\t\tself.typeIndex = wrapper.pyArgIndex( self.typeName )\n\t\tself.pixelsIndex = wrapper.pyArgIndex( self.pixelsName )\n\tdef __call__( self, arg, baseOperation, pyArgs ):\n\t\t\"\"\"pyConverter for the pixels argument\"\"\"\n\t\timages.setupDefaultTransferMode()\n\t\timages.rankPacking( self.rank )\n\t\ttype = pyArgs[ self.typeIndex ]\n\t\tarrayType = arrays.GL_CONSTANT_TO_ARRAY_TYPE[ images.TYPE_TO_ARRAYTYPE[ type ] ]\n", "description": "Get our pixel index from the wrapper", "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "class", "name": "TypedImageInputConverter", "data": "class TypedImageInputConverter( ImageInputConverter ):\n\tdef __init__( self, rank, pixelsName, arrayType, typeName=None ):\n\t\tself.rank = rank\n\t\tself.arrayType = arrayType\n\t\tself.pixelsName = pixelsName\n\t\tself.typeName = typeName\n\tdef __call__( self, arg, baseOperation, pyArgs ):\n\t\t\"\"\"The pyConverter for the pixels\"\"\"\n\t\timages.setupDefaultTransferMode()\n\t\timages.rankPacking( self.rank )\n\t\treturn self.arrayType.asArray( arg )\n\tdef finalise( self, wrapper ):\n\t\t\"\"\"Get our pixel index from the wrapper\"\"\"\n\t\tself.pixelsIndex = wrapper.pyArgIndex( self.pixelsName )\n\tdef width( self, pyArgs, index, wrappedOperation ):\n\t\t\"\"\"Extract the width from the pixels argument\"\"\"\n\t\treturn self.arrayType.dimensions( pyArgs[self.pixelsIndex] )[0]\n\tdef height( self, pyArgs, index, wrappedOperation ):\n\t\t\"\"\"Extract the height from the pixels argument\"\"\"\n\t\treturn self.arrayType.dimensions( pyArgs[self.pixelsIndex] )[1]\n\tdef depth( self, pyArgs, index, wrappedOperation ):\n\t\t\"\"\"Extract the depth from the pixels argument\"\"\"\n\t\treturn self.arrayType.dimensions( pyArgs[self.pixelsIndex] )[2]\n\tdef type( self, pyArgs, index, wrappedOperation ):\n\t\t\"\"\"Provide the item-type argument from our stored value\n\t\t\n\t\tThis is used for pre-bound processing where we want to provide \n\t\tthe type by implication...\n\t\t\"\"\"\n\t\treturn self.typeName\n", "description": "The pyConverter for the pixels", "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "class", "name": "CompressedImageConverter", "data": "class CompressedImageConverter( object ):\n\tdef finalise( self, wrapper ):\n\t\t\"\"\"Get our pixel index from the wrapper\"\"\"\n\t\tself.dataIndex = wrapper.pyArgIndex( 'data' )\n\tdef __call__( self, pyArgs, index, wrappedOperation ):\n\t\t\"\"\"Create a data-size measurement for our image\"\"\"\n\t\targ = pyArgs[ self.dataIndex ]\n\t\treturn arrays.ArrayType.arrayByteCount( arg )\n\n\n", "description": "Get our pixel index from the wrapper", "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "def", "name": "setImageInput", "data": "def setImageInput( \n\tbaseOperation, arrayType=None, dimNames=DIMENSION_NAMES, \n", "description": null, "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "def", "name": "typedImageFunction", "data": "def typedImageFunction( suffix, arrayConstant,  baseFunction ):\n\t\"\"\"Produce a typed version of the given image function\"\"\"\n\tfunctionName = baseFunction.__name__\n\tfunctionName = '%(functionName)s%(suffix)s'%locals()\n\tif baseFunction:\n\t\tarrayType = arrays.GL_CONSTANT_TO_ARRAY_TYPE[ arrayConstant ]\n\t\tfunction = setDimensionsAsInts(\n\t\t\tsetImageInput(\n\t\t\t\tbaseFunction, \n\t\t\t\tarrayType,\n\t\t\t\ttypeName = arrayConstant,\n\t\t\t)\n\t\t)\n\t\treturn functionName, function\n\telse:\n\t\treturn functionName, baseFunction\n", "description": "Produce a typed version of the given image function", "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "def", "name": "_setDataSize", "data": "def _setDataSize( baseFunction, argument='imageSize' ):\n\t\"\"\"Set the data-size value to come from the data field\"\"\"\n\tif baseFunction:\n\t\tconverter = CompressedImageConverter()\n\t\treturn asWrapper( baseFunction ).setPyConverter(\n\t\t\targument\n\t\t).setCConverter( argument, converter )\n\telse:\n\t\treturn baseFunction\n", "description": "Set the data-size value to come from the data field", "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}, {"term": "def", "name": "compressedImageFunction", "data": "def compressedImageFunction( baseFunction ):\n\t\"\"\"Set the imageSize and dimensions-as-ints converters for baseFunction\"\"\"\n\tif baseFunction:\n\t\treturn setDimensionsAsInts(\n\t\t\t_setDataSize( \n\t\t\t\tbaseFunction, argument='imageSize'\n\t\t\t)\n\t\t)\n\telse:\n\t\treturn baseFunction\n", "description": "Set the imageSize and dimensions-as-ints converters for baseFunction", "category": "simple", "imports": ["from OpenGL.raw import GL as simple", "from OpenGL import images, arrays, wrapper, platform", "import ctypes", "\t\tfrom OpenGL.GL import glget", "##\t\tfrom OpenGL.GL import glget", "\tfrom OpenGL.GL import glget"]}], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [{"term": "def", "name": "simple", "data": "def simple(e):\n\tcode = e.code\n\n\tif code.endswith('Exception'):\n\t\tcode = code.rstrip('Exception')\n\n\ttry:\n\t\t# Dynamically get the error class.\n\t\tsimple_e = getattr(sys.modules[__name__], code)(e)\n\texcept AttributeError:\n\t\t# Return original exception on failure.\n\t\treturn e\n\n\treturn simple_e\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "SimpleException", "data": "class SimpleException(BotoServerError):\n\tdef __init__(self, e):\n\t\tsuper(SimpleException, self).__init__(e.status, e.reason, e.body)\n\t\tself.error_message = self.message\n\n\tdef __repr__(self):\n\t\treturn self.__class__.__name__ + ': ' + self.error_message\n\tdef __str__(self):\n\t\treturn self.__class__.__name__ + ': ' + self.error_message\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "ValidationError", "data": "class ValidationError(SimpleException): pass\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "Throttling", "data": "class Throttling(SimpleException): pass\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "SourceBundleDeletion", "data": "class SourceBundleDeletion(SimpleException): pass\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}], [{"term": "def", "name": "simple", "data": "def simple(e):\n\tcode = e.code\n\n\tif code.endswith('Exception'):\n\t\tcode = code.rstrip('Exception')\n\n\ttry:\n\t\t# Dynamically get the error class.\n\t\tsimple_e = getattr(sys.modules[__name__], code)(e)\n\texcept AttributeError:\n\t\t# Return original exception on failure.\n\t\treturn e\n\n\treturn simple_e\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "SimpleException", "data": "class SimpleException(BotoServerError):\n\tdef __init__(self, e):\n\t\tsuper(SimpleException, self).__init__(e.status, e.reason, e.body)\n\t\tself.error_message = self.message\n\n\tdef __repr__(self):\n\t\treturn self.__class__.__name__ + ': ' + self.error_message\n\tdef __str__(self):\n\t\treturn self.__class__.__name__ + ': ' + self.error_message\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "ValidationError", "data": "class ValidationError(SimpleException): pass\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "Throttling", "data": "class Throttling(SimpleException): pass\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "SourceBundleDeletion", "data": "class SourceBundleDeletion(SimpleException): pass\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}], [{"term": "class", "name": "classTestCycles:", "data": "class TestCycles:\n\tdef setUp(self):\n\t\tG=networkx.Graph()\n\t\tG.add_cycle([0,1,2,3])\n\t\tG.add_cycle([0,3,4,5])\n\t\tG.add_cycle([0,1,6,7,8])\n\t\tG.add_edge(8,9)\n\t\tself.G=G\n\t\t\n\tdef is_cyclic_permutation(self,a,b):\n\t\tn=len(a)\n\t\tif len(b)!=n:\n\t\t\treturn False\n\t\tl=a+a\n\t\treturn any(l[i:i+n]==b for i in range(2*n-n+1))\n\n\tdef test_cycle_basis(self):\n\t\tG=self.G\n\t\tcy=networkx.cycle_basis(G,0)\n\t\tsort_cy= sorted( sorted(c) for c in cy )\n\t\tassert_equal(sort_cy, [[0,1,2,3],[0,1,6,7,8],[0,3,4,5]])\n\t\tcy=networkx.cycle_basis(G,1)\n\t\tsort_cy= sorted( sorted(c) for c in cy )\n\t\tassert_equal(sort_cy, [[0,1,2,3],[0,1,6,7,8],[0,3,4,5]])\n\t\tcy=networkx.cycle_basis(G,9)\n\t\tsort_cy= sorted( sorted(c) for c in cy )\n\t\tassert_equal(sort_cy, [[0,1,2,3],[0,1,6,7,8],[0,3,4,5]])\n\t\t# test disconnected graphs\n\t\tG.add_cycle(list(\"ABC\"))\n\t\tcy=networkx.cycle_basis(G,9)\n\t\tsort_cy= sorted(sorted(c) for c in cy[:-1]) + [sorted(cy[-1])]\n\t\tassert_equal(sort_cy, [[0,1,2,3],[0,1,6,7,8],[0,3,4,5],['A','B','C']])\n\n\t@raises(nx.NetworkXNotImplemented)\n\tdef test_cycle_basis(self):\n\t\tG=nx.DiGraph()\n\t\tcy=networkx.cycle_basis(G,0)\n\n\t@raises(nx.NetworkXNotImplemented)\n\tdef test_cycle_basis(self):\n\t\tG=nx.MultiGraph()\n\t\tcy=networkx.cycle_basis(G,0)\n\n\tdef test_simple_cycles(self):\n\t\tG = nx.DiGraph([(0, 0), (0, 1), (0, 2), (1, 2), (2, 0), (2, 1), (2, 2)])\n\t\tcc=sorted(nx.simple_cycles(G))\n\t\tca=[[0], [0, 1, 2], [0, 2], [1, 2], [2]]\n\t\tfor c in cc:\n\t\t\tassert_true(any(self.is_cyclic_permutation(c,rc) for rc in ca))\n\n\t@raises(nx.NetworkXNotImplemented)\n\tdef test_simple_cycles_graph(self):\n\t\tG = nx.Graph()\n\t\tc = sorted(nx.simple_cycles(G))\n\n\tdef test_unsortable(self):\n\t\t#  TODO What does this test do?  das 6/2013\n\t\tG=nx.DiGraph()\n\t\tG.add_cycle(['a',1])\n\t\tc=list(nx.simple_cycles(G))\n\n\tdef test_simple_cycles_small(self):\n\t\tG = nx.DiGraph()\n\t\tG.add_cycle([1,2,3])\n\t\tc=sorted(nx.simple_cycles(G))\n\t\tassert_equal(len(c),1)\n\t\tassert_true(self.is_cyclic_permutation(c[0],[1,2,3]))\n\t\tG.add_cycle([10,20,30])\n\t\tcc=sorted(nx.simple_cycles(G))\n\t\tca=[[1,2,3],[10,20,30]]\n\t\tfor c in cc:\n\t\t\tassert_true(any(self.is_cyclic_permutation(c,rc) for rc in ca))\n\n\tdef test_simple_cycles_empty(self):\n\t\tG = nx.DiGraph()\n\t\tassert_equal(list(nx.simple_cycles(G)),[])\n\t\t\n\tdef test_complete_directed_graph(self):\n\t\t# see table 2 in Johnson's paper\n\t\tncircuits=[1,5,20,84,409,2365,16064]\n\t\tfor n,c in zip(range(2,9),ncircuits):\n\t\t\tG=nx.DiGraph(nx.complete_graph(n))\n\t\t\tassert_equal(len(list(nx.simple_cycles(G))),c)\n\t\t\n\tdef worst_case_graph(self,k):\n\t\t# see figure 1 in Johnson's paper\n\t\t# this graph has excactly 3k simple cycles\n\t\tG=nx.DiGraph()\n\t\tfor n in range(2,k+2):\n\t\t\tG.add_edge(1,n)\n\t\t\tG.add_edge(n,k+2)\n\t\tG.add_edge(2*k+1,1)\n\t\tfor n in range(k+2,2*k+2):\n\t\t\tG.add_edge(n,2*k+2)\n\t\t\tG.add_edge(n,n+1)\n\t\tG.add_edge(2*k+3,k+2)\n\t\tfor n in range(2*k+3,3*k+3):\n\t\t\tG.add_edge(2*k+2,n)\n\t\t\tG.add_edge(n,3*k+3)\n\t\tG.add_edge(3*k+3,2*k+2)\n\t\treturn G\n\n\tdef test_worst_case_graph(self):\n\t\t# see figure 1 in Johnson's paper\n\t\tfor k in range(3,10):\n\t\t\tG=self.worst_case_graph(k)\n\t\t\tl=len(list(nx.simple_cycles(G)))\n\t\t\tassert_equal(l,3*k)\n\t\n\tdef test_recursive_simple_and_not(self):\n\t\tfor k in range(2,10):\n\t\t\tG=self.worst_case_graph(k)\n\t\t\tcc=sorted(nx.simple_cycles(G))\n\t\t\trcc=sorted(nx.recursive_simple_cycles(G))\n\t\t\tassert_equal(len(cc),len(rcc))\n\t\t\tfor c in cc:\n\t\t\t\tassert_true(any(self.is_cyclic_permutation(c,rc) for rc in rcc))\n\t\t\tfor rc in rcc:\n\t\t\t\tassert_true(any(self.is_cyclic_permutation(rc,c) for c in cc))\n\n\tdef test_simple_graph_with_reported_bug(self):\n\t\tG=nx.DiGraph()\n\t\tedges = [(0, 2), (0, 3), (1, 0), (1, 3), (2, 1), (2, 4), \\\n\t\t\t\t(3, 2), (3, 4), (4, 0), (4, 1), (4, 5), (5, 0), \\\n\t\t\t\t(5, 1), (5, 2), (5, 3)]\n\t\tG.add_edges_from(edges)\n\t\tcc=sorted(nx.simple_cycles(G))\n\t\tassert_equal(len(cc),26)\n\t\trcc=sorted(nx.recursive_simple_cycles(G))\n\t\tassert_equal(len(cc),len(rcc))\n\t\tfor c in cc:\n\t\t\tassert_true(any(self.is_cyclic_permutation(c,rc) for rc in rcc))\n\t\tfor rc in rcc:\n\t\t\tassert_true(any(self.is_cyclic_permutation(rc,c) for c in cc))\n", "description": null, "category": "simple", "imports": ["from nose.tools import *", "import networkx", "import networkx as nx"]}], [{"term": "def", "name": "fswig_import_helper", "data": "\tdef swig_import_helper():\n\t\timport importlib\n\t\tpkg = __name__.rpartition('.')[0]\n\t\tmname = '.'.join((pkg, '_param_TimingSimpleCPU')).lstrip('.')\n\t\ttry:\n\t\t\treturn importlib.import_module(mname)\n\t\texcept ImportError:\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_TimingSimpleCPU')", "\t_param_TimingSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_TimingSimpleCPU", "\t_param_TimingSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_TimingSimpleCPU", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BaseSimpleCPU", "import m5.internal.param_BranchPredictor", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_BaseCPU", "import m5.internal.param_X86TLB", "import m5.internal.param_X86PagetableWalker", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BaseTLB", "import m5.internal.X86LocalApic_vector", "import m5.internal.param_X86LocalApic", "import m5.internal.param_BasicPioDevice", "import m5.internal.param_PioDevice", "import m5.internal.X86ISA_vector", "import m5.internal.param_X86ISA", "import m5.internal.Counter_vector", "import m5.internal.param_InstTracer", "import m5.internal.Process_vector", "import m5.internal.param_Process"]}, {"term": "def", "name": "fswig_import_helper", "data": "\tdef swig_import_helper():\n\t\tfrom os.path import dirname\n\t\timport imp\n\t\tfp = None\n\t\ttry:\n\t\t\tfp, pathname, description = imp.find_module('_param_TimingSimpleCPU', [dirname(__file__)])\n\t\texcept ImportError:\n\t\t\timport _param_TimingSimpleCPU\n\t\t\treturn _param_TimingSimpleCPU\n\t\ttry:\n\t\t\t_mod = imp.load_module('_param_TimingSimpleCPU', fp, pathname, description)\n\t\tfinally:\n\t\t\tif fp is not None:\n\t\t\t\tfp.close()\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_TimingSimpleCPU')", "\t_param_TimingSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_TimingSimpleCPU", "\t_param_TimingSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_TimingSimpleCPU", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BaseSimpleCPU", "import m5.internal.param_BranchPredictor", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_BaseCPU", "import m5.internal.param_X86TLB", "import m5.internal.param_X86PagetableWalker", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BaseTLB", "import m5.internal.X86LocalApic_vector", "import m5.internal.param_X86LocalApic", "import m5.internal.param_BasicPioDevice", "import m5.internal.param_PioDevice", "import m5.internal.X86ISA_vector", "import m5.internal.param_X86ISA", "import m5.internal.Counter_vector", "import m5.internal.param_InstTracer", "import m5.internal.Process_vector", "import m5.internal.param_Process"]}, {"term": "def", "name": "_swig_setattr_nondynamic", "data": "def _swig_setattr_nondynamic(self, class_type, name, value, static=1):\n\tif (name == \"thisown\"):\n\t\treturn self.this.own(value)\n\tif (name == \"this\"):\n\t\tif type(value).__name__ == 'SwigPyObject':\n\t\t\tself.__dict__[name] = value\n\t\t\treturn\n\tmethod = class_type.__swig_setmethods__.get(name, None)\n\tif method:\n\t\treturn method(self, value)\n\tif (not static):\n\t\tobject.__setattr__(self, name, value)\n\telse:\n\t\traise AttributeError(\"You cannot add attributes to %s\" % self)\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_TimingSimpleCPU')", "\t_param_TimingSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_TimingSimpleCPU", "\t_param_TimingSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_TimingSimpleCPU", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BaseSimpleCPU", "import m5.internal.param_BranchPredictor", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_BaseCPU", "import m5.internal.param_X86TLB", "import m5.internal.param_X86PagetableWalker", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BaseTLB", "import m5.internal.X86LocalApic_vector", "import m5.internal.param_X86LocalApic", "import m5.internal.param_BasicPioDevice", "import m5.internal.param_PioDevice", "import m5.internal.X86ISA_vector", "import m5.internal.param_X86ISA", "import m5.internal.Counter_vector", "import m5.internal.param_InstTracer", "import m5.internal.Process_vector", "import m5.internal.param_Process"]}, {"term": "def", "name": "_swig_setattr", "data": "def _swig_setattr(self, class_type, name, value):\n\treturn _swig_setattr_nondynamic(self, class_type, name, value, 0)\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_TimingSimpleCPU')", "\t_param_TimingSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_TimingSimpleCPU", "\t_param_TimingSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_TimingSimpleCPU", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BaseSimpleCPU", "import m5.internal.param_BranchPredictor", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_BaseCPU", "import m5.internal.param_X86TLB", "import m5.internal.param_X86PagetableWalker", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BaseTLB", "import m5.internal.X86LocalApic_vector", "import m5.internal.param_X86LocalApic", "import m5.internal.param_BasicPioDevice", "import m5.internal.param_PioDevice", "import m5.internal.X86ISA_vector", "import m5.internal.param_X86ISA", "import m5.internal.Counter_vector", "import m5.internal.param_InstTracer", "import m5.internal.Process_vector", "import m5.internal.param_Process"]}, {"term": "def", "name": "_swig_getattr", "data": "def _swig_getattr(self, class_type, name):\n\tif (name == \"thisown\"):\n\t\treturn self.this.own()\n\tmethod = class_type.__swig_getmethods__.get(name, None)\n\tif method:\n\t\treturn method(self)\n\traise AttributeError(\"'%s' object has no attribute '%s'\" % (class_type.__name__, name))\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_TimingSimpleCPU')", "\t_param_TimingSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_TimingSimpleCPU", "\t_param_TimingSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_TimingSimpleCPU", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BaseSimpleCPU", "import m5.internal.param_BranchPredictor", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_BaseCPU", "import m5.internal.param_X86TLB", "import m5.internal.param_X86PagetableWalker", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BaseTLB", "import m5.internal.X86LocalApic_vector", "import m5.internal.param_X86LocalApic", "import m5.internal.param_BasicPioDevice", "import m5.internal.param_PioDevice", "import m5.internal.X86ISA_vector", "import m5.internal.param_X86ISA", "import m5.internal.Counter_vector", "import m5.internal.param_InstTracer", "import m5.internal.Process_vector", "import m5.internal.param_Process"]}, {"term": "def", "name": "_swig_repr", "data": "def _swig_repr(self):\n\ttry:\n\t\tstrthis = \"proxy of \" + self.this.__repr__()\n\texcept __builtin__.Exception:\n\t\tstrthis = \"\"\n\treturn \"<%s.%s; %s >\" % (self.__class__.__module__, self.__class__.__name__, strthis,)\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_TimingSimpleCPU')", "\t_param_TimingSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_TimingSimpleCPU", "\t_param_TimingSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_TimingSimpleCPU", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BaseSimpleCPU", "import m5.internal.param_BranchPredictor", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_BaseCPU", "import m5.internal.param_X86TLB", "import m5.internal.param_X86PagetableWalker", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BaseTLB", "import m5.internal.X86LocalApic_vector", "import m5.internal.param_X86LocalApic", "import m5.internal.param_BasicPioDevice", "import m5.internal.param_PioDevice", "import m5.internal.X86ISA_vector", "import m5.internal.param_X86ISA", "import m5.internal.Counter_vector", "import m5.internal.param_InstTracer", "import m5.internal.Process_vector", "import m5.internal.param_Process"]}, {"term": "def", "name": "_swig_setattr_nondynamic_method", "data": "def _swig_setattr_nondynamic_method(set):\n\tdef set_attr(self, name, value):\n\t\tif (name == \"thisown\"):\n\t\t\treturn self.this.own(value)\n\t\tif hasattr(self, name) or (name == \"this\"):\n\t\t\tset(self, name, value)\n\t\telse:\n\t\t\traise AttributeError(\"You cannot add attributes to %s\" % self)\n\treturn set_attr\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_TimingSimpleCPU')", "\t_param_TimingSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_TimingSimpleCPU", "\t_param_TimingSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_TimingSimpleCPU", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BaseSimpleCPU", "import m5.internal.param_BranchPredictor", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_BaseCPU", "import m5.internal.param_X86TLB", "import m5.internal.param_X86PagetableWalker", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BaseTLB", "import m5.internal.X86LocalApic_vector", "import m5.internal.param_X86LocalApic", "import m5.internal.param_BasicPioDevice", "import m5.internal.param_PioDevice", "import m5.internal.X86ISA_vector", "import m5.internal.param_X86ISA", "import m5.internal.Counter_vector", "import m5.internal.param_InstTracer", "import m5.internal.Process_vector", "import m5.internal.param_Process"]}, {"term": "class", "name": "TimingSimpleCPU", "data": "class TimingSimpleCPU(m5.internal.param_BaseSimpleCPU.BaseSimpleCPU):\n\tthisown = _swig_property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc='The membership flag')\n\n\tdef __init__(self, *args, **kwargs):\n\t\traise AttributeError(\"No constructor defined - class is abstract\")\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_TimingSimpleCPU')", "\t_param_TimingSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_TimingSimpleCPU", "\t_param_TimingSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_TimingSimpleCPU", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BaseSimpleCPU", "import m5.internal.param_BranchPredictor", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_BaseCPU", "import m5.internal.param_X86TLB", "import m5.internal.param_X86PagetableWalker", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BaseTLB", "import m5.internal.X86LocalApic_vector", "import m5.internal.param_X86LocalApic", "import m5.internal.param_BasicPioDevice", "import m5.internal.param_PioDevice", "import m5.internal.X86ISA_vector", "import m5.internal.param_X86ISA", "import m5.internal.Counter_vector", "import m5.internal.param_InstTracer", "import m5.internal.Process_vector", "import m5.internal.param_Process"]}, {"term": "class", "name": "TimingSimpleCPUParams", "data": "class TimingSimpleCPUParams(m5.internal.param_BaseSimpleCPU.BaseSimpleCPUParams):\n\tthisown = _swig_property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc='The membership flag')\n\t__repr__ = _swig_repr\n\n\tdef create(self):\n\t\treturn _param_TimingSimpleCPU.TimingSimpleCPUParams_create(self)\n\n\tdef __init__(self):\n\t\tthis = _param_TimingSimpleCPU.new_TimingSimpleCPUParams()\n\t\ttry:\n\t\t\tself.this.append(this)\n\t\texcept __builtin__.Exception:\n\t\t\tself.this = this\n\t__swig_destroy__ = _param_TimingSimpleCPU.delete_TimingSimpleCPUParams\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_TimingSimpleCPU')", "\t_param_TimingSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_TimingSimpleCPU", "\t_param_TimingSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_TimingSimpleCPU", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BaseSimpleCPU", "import m5.internal.param_BranchPredictor", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_BaseCPU", "import m5.internal.param_X86TLB", "import m5.internal.param_X86PagetableWalker", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BaseTLB", "import m5.internal.X86LocalApic_vector", "import m5.internal.param_X86LocalApic", "import m5.internal.param_BasicPioDevice", "import m5.internal.param_PioDevice", "import m5.internal.X86ISA_vector", "import m5.internal.param_X86ISA", "import m5.internal.Counter_vector", "import m5.internal.param_InstTracer", "import m5.internal.Process_vector", "import m5.internal.param_Process"]}], [{"term": "class", "name": "SimpleGenerator", "data": "class SimpleGenerator(Generator):\n\tdef __init__(self, bboxes, labels, num_classes=0, image=None):\n\t\tassert(len(bboxes) == len(labels))\n\t\tself.bboxes\t   = bboxes\n\t\tself.labels\t   = labels\n\t\tself.num_classes_ = num_classes\n\t\tself.image\t\t= image\n\t\tsuper(SimpleGenerator, self).__init__(group_method='none', shuffle_groups=False)\n\n\tdef num_classes(self):\n\t\treturn self.num_classes_\n\n\tdef load_image(self, image_index):\n\t\treturn self.image\n\n\tdef size(self):\n\t\treturn len(self.bboxes)\n\n\tdef load_annotations(self, image_index):\n\t\tannotations = {'labels': self.labels[image_index], 'bboxes': self.bboxes[image_index]}\n\t\treturn annotations\n\n", "description": null, "category": "simple", "imports": ["from keras_retinanet.preprocessing.generator import Generator", "import numpy as np", "import pytest"]}, {"term": "class", "name": "TestLoadAnnotationsGroup", "data": "class TestLoadAnnotationsGroup(object):\n\tdef test_simple(self):\n\t\tinput_bboxes_group = [\n\t\t\tnp.array([\n\t\t\t\t[  0,   0,  10,  10],\n\t\t\t\t[150, 150, 350, 350]\n\t\t\t]),\n\t\t]\n\t\tinput_labels_group = [\n\t\t\tnp.array([\n\t\t\t\t1,\n\t\t\t\t3\n\t\t\t]),\n\t\t]\n\t\texpected_bboxes_group = input_bboxes_group\n\t\texpected_labels_group = input_labels_group\n\n\t\tsimple_generator = SimpleGenerator(input_bboxes_group, input_labels_group)\n\t\tannotations = simple_generator.load_annotations_group(simple_generator.groups[0])\n\n\t\tassert('bboxes' in annotations[0])\n\t\tassert('labels' in annotations[0])\n\t\tnp.testing.assert_equal(expected_bboxes_group[0], annotations[0]['bboxes'])\n\t\tnp.testing.assert_equal(expected_labels_group[0], annotations[0]['labels'])\n\n\tdef test_multiple(self):\n\t\tinput_bboxes_group = [\n\t\t\tnp.array([\n\t\t\t\t[  0,   0,  10,  10],\n\t\t\t\t[150, 150, 350, 350]\n\t\t\t]),\n\t\t\tnp.array([\n\t\t\t\t[0, 0, 50, 50],\n\t\t\t]),\n\t\t]\n\t\tinput_labels_group = [\n\t\t\tnp.array([\n\t\t\t\t1,\n\t\t\t\t0\n\t\t\t]),\n\t\t\tnp.array([\n\t\t\t\t3\n\t\t\t])\n\t\t]\n\t\texpected_bboxes_group = input_bboxes_group\n\t\texpected_labels_group = input_labels_group\n\n\t\tsimple_generator = SimpleGenerator(input_bboxes_group, input_labels_group)\n\t\tannotations_group_0 = simple_generator.load_annotations_group(simple_generator.groups[0])\n\t\tannotations_group_1 = simple_generator.load_annotations_group(simple_generator.groups[1])\n\n\t\tassert('bboxes' in annotations_group_0[0])\n\t\tassert('bboxes' in annotations_group_1[0])\n\t\tassert('labels' in annotations_group_0[0])\n\t\tassert('labels' in annotations_group_1[0])\n\t\tnp.testing.assert_equal(expected_bboxes_group[0], annotations_group_0[0]['bboxes'])\n\t\tnp.testing.assert_equal(expected_labels_group[0], annotations_group_0[0]['labels'])\n\t\tnp.testing.assert_equal(expected_bboxes_group[1], annotations_group_1[0]['bboxes'])\n\t\tnp.testing.assert_equal(expected_labels_group[1], annotations_group_1[0]['labels'])\n\n", "description": null, "category": "simple", "imports": ["from keras_retinanet.preprocessing.generator import Generator", "import numpy as np", "import pytest"]}, {"term": "class", "name": "TestFilterAnnotations", "data": "class TestFilterAnnotations(object):\n\tdef test_simple_filter(self):\n\t\tinput_bboxes_group = [\n\t\t\tnp.array([\n\t\t\t\t[  0,   0, 10, 10],\n\t\t\t\t[150, 150, 50, 50]\n\t\t\t]),\n\t\t]\n\t\tinput_labels_group = [\n\t\t\tnp.array([\n\t\t\t\t3,\n\t\t\t\t1\n\t\t\t]),\n\t\t]\n\n\t\tinput_image = np.zeros((500, 500, 3))\n\n\t\texpected_bboxes_group = [\n\t\t\tnp.array([\n\t\t\t\t[0, 0, 10, 10],\n\t\t\t]),\n\t\t]\n\t\texpected_labels_group = [\n\t\t\tnp.array([\n\t\t\t\t3,\n\t\t\t]),\n\t\t]\n\n\t\tsimple_generator = SimpleGenerator(input_bboxes_group, input_labels_group)\n\t\tannotations = simple_generator.load_annotations_group(simple_generator.groups[0])\n\t\t# expect a UserWarning\n\t\twith pytest.warns(UserWarning):\n\t\t\timage_group, annotations_group = simple_generator.filter_annotations([input_image], annotations, simple_generator.groups[0])\n\n\t\tnp.testing.assert_equal(expected_bboxes_group[0], annotations_group[0]['bboxes'])\n\t\tnp.testing.assert_equal(expected_labels_group[0], annotations_group[0]['labels'])\n\n\tdef test_multiple_filter(self):\n\t\tinput_bboxes_group = [\n\t\t\tnp.array([\n\t\t\t\t[  0,   0,  10,  10],\n\t\t\t\t[150, 150,  50,  50],\n\t\t\t\t[150, 150, 350, 350],\n\t\t\t\t[350, 350, 150, 150],\n\t\t\t\t[  1,   1,   2,   2],\n\t\t\t\t[  2,   2,   1,   1]\n\t\t\t]),\n\t\t\tnp.array([\n\t\t\t\t[0, 0, -1, -1]\n\t\t\t]),\n\t\t\tnp.array([\n\t\t\t\t[-10, -10,\t0,\t0],\n\t\t\t\t[-10, -10, -100, -100],\n\t\t\t\t[ 10,  10,  100,  100]\n\t\t\t]),\n\t\t\tnp.array([\n\t\t\t\t[ 10,  10,  100,  100],\n\t\t\t\t[ 10,  10,  600,  600]\n\t\t\t]),\n\t\t]\n\n\t\tinput_labels_group = [\n\t\t\tnp.array([\n\t\t\t\t6,\n\t\t\t\t5,\n\t\t\t\t4,\n\t\t\t\t3,\n\t\t\t\t2,\n\t\t\t\t1\n\t\t\t]),\n\t\t\tnp.array([\n\t\t\t\t0\n\t\t\t]),\n\t\t\tnp.array([\n\t\t\t\t10,\n\t\t\t\t11,\n\t\t\t\t12\n\t\t\t]),\n\t\t\tnp.array([\n\t\t\t\t105,\n\t\t\t\t107\n\t\t\t]),\n\t\t]\n\n\t\tinput_image = np.zeros((500, 500, 3))\n\n\t\texpected_bboxes_group = [\n\t\t\tnp.array([\n\t\t\t\t[  0,   0,  10,  10],\n\t\t\t\t[150, 150, 350, 350],\n\t\t\t\t[  1,   1,   2,   2]\n\t\t\t]),\n\t\t\tnp.zeros((0, 4)),\n\t\t\tnp.array([\n\t\t\t\t[10, 10, 100, 100]\n\t\t\t]),\n\t\t\tnp.array([\n\t\t\t\t[ 10,  10,  100,  100]\n\t\t\t]),\n\t\t]\n\t\texpected_labels_group = [\n\t\t\tnp.array([\n\t\t\t\t6,\n\t\t\t\t4,\n\t\t\t\t2\n\t\t\t]),\n\t\t\tnp.zeros((0,)),\n\t\t\tnp.array([\n\t\t\t\t12\n\t\t\t]),\n\t\t\tnp.array([\n\t\t\t\t105\n\t\t\t]),\n\t\t]\n\n\t\tsimple_generator = SimpleGenerator(input_bboxes_group, input_labels_group)\n\t\t# expect a UserWarning\n\t\tannotations_group_0 = simple_generator.load_annotations_group(simple_generator.groups[0])\n\t\twith pytest.warns(UserWarning):\n\t\t\timage_group, annotations_group_0 = simple_generator.filter_annotations([input_image], annotations_group_0, simple_generator.groups[0])\n\n\t\tannotations_group_1 = simple_generator.load_annotations_group(simple_generator.groups[1])\n\t\twith pytest.warns(UserWarning):\n\t\t\timage_group, annotations_group_1 = simple_generator.filter_annotations([input_image], annotations_group_1, simple_generator.groups[1])\n\n\t\tannotations_group_2 = simple_generator.load_annotations_group(simple_generator.groups[2])\n\t\twith pytest.warns(UserWarning):\n\t\t\timage_group, annotations_group_2 = simple_generator.filter_annotations([input_image], annotations_group_2, simple_generator.groups[2])\n\n\t\tnp.testing.assert_equal(expected_bboxes_group[0], annotations_group_0[0]['bboxes'])\n\t\tnp.testing.assert_equal(expected_labels_group[0], annotations_group_0[0]['labels'])\n\n\t\tnp.testing.assert_equal(expected_bboxes_group[1], annotations_group_1[0]['bboxes'])\n\t\tnp.testing.assert_equal(expected_labels_group[1], annotations_group_1[0]['labels'])\n\n\t\tnp.testing.assert_equal(expected_bboxes_group[2], annotations_group_2[0]['bboxes'])\n\t\tnp.testing.assert_equal(expected_labels_group[2], annotations_group_2[0]['labels'])\n\n\tdef test_complete(self):\n\t\tinput_bboxes_group = [\n\t\t\tnp.array([\n\t\t\t\t[  0,   0, 50, 50],\n\t\t\t\t[150, 150, 50, 50],  # invalid bbox\n\t\t\t], dtype=float)\n\t\t]\n\n\t\tinput_labels_group = [\n\t\t\tnp.array([\n\t\t\t\t5,  # one object of class 5\n\t\t\t\t3,  # one object of class 3 with an invalid box\n\t\t\t], dtype=float)\n\t\t]\n\n\t\tinput_image = np.zeros((500, 500, 3), dtype=np.uint8)\n\n\t\tsimple_generator = SimpleGenerator(input_bboxes_group, input_labels_group, image=input_image, num_classes=6)\n\t\t# expect a UserWarning\n\t\twith pytest.warns(UserWarning):\n\t\t\t_, [_, labels_batch] = simple_generator[0]\n\n\t\t# test that only object with class 5 is present in labels_batch\n\t\tlabels = np.unique(np.argmax(labels_batch == 5, axis=2))\n\t\tassert(len(labels) == 1 and labels[0] == 0), 'Expected only class 0 to be present, but got classes {}'.format(labels)\n", "description": null, "category": "simple", "imports": ["from keras_retinanet.preprocessing.generator import Generator", "import numpy as np", "import pytest"]}], [], [{"term": "def", "name": "fwith_tp_del", "data": "\tdef with_tp_del(cls):\n\t\tclass C(object):\n\t\t\tdef __new__(cls, *args, **kwargs):\n\t\t\t\traise TypeError('requires _testcapi.with_tp_del')\n\t\treturn C\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "classNonGCSimpleBase:", "data": "class NonGCSimpleBase:\n\t\"\"\"\n\tThe base class for all the objects under test, equipped with various\n\ttesting features.\n\t\"\"\"\n\n\tsurvivors = []\n\tdel_calls = []\n\ttp_del_calls = []\n\terrors = []\n\n\t_cleaning = False\n\n\t__slots__ = ()\n\n\t@classmethod\n\tdef _cleanup(cls):\n\t\tcls.survivors.clear()\n\t\tcls.errors.clear()\n\t\tgc.garbage.clear()\n\t\tgc.collect()\n\t\tcls.del_calls.clear()\n\t\tcls.tp_del_calls.clear()\n\n\t@classmethod\n\t@contextlib.contextmanager\n\tdef test(cls):\n\t\t\"\"\"\n\t\tA context manager to use around all finalization tests.\n\t\t\"\"\"\n\t\twith support.disable_gc():\n\t\t\tcls.del_calls.clear()\n\t\t\tcls.tp_del_calls.clear()\n\t\t\tNonGCSimpleBase._cleaning = False\n\t\t\ttry:\n\t\t\t\tyield\n\t\t\t\tif cls.errors:\n\t\t\t\t\traise cls.errors[0]\n\t\t\tfinally:\n\t\t\t\tNonGCSimpleBase._cleaning = True\n\t\t\t\tcls._cleanup()\n\n\tdef check_sanity(self):\n\t\t\"\"\"\n\t\tCheck the object is sane (non-broken).\n\t\t\"\"\"\n\n\tdef __del__(self):\n\t\t\"\"\"\n\t\tPEP 442 finalizer.  Record that this was called, check the\n\t\tobject is in a sane state, and invoke a side effect.\n\t\t\"\"\"\n\t\ttry:\n\t\t\tif not self._cleaning:\n\t\t\t\tself.del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\t\t\tself.side_effect()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tA side effect called on destruction.\n\t\t\"\"\"\n\n", "description": "\n\tThe base class for all the objects under test, equipped with various\n\ttesting features.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleBase", "data": "class SimpleBase(NonGCSimpleBase):\n\n\tdef __init__(self):\n\t\tself.id_ = id(self)\n\n\tdef check_sanity(self):\n\t\tassert self.id_ == id(self)\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "NonGC", "data": "class NonGC(NonGCSimpleBase):\n\t__slots__ = ()\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "NonGCResurrector", "data": "class NonGCResurrector(NonGCSimpleBase):\n\t__slots__ = ()\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tResurrect self by storing self in a class-wide list.\n\t\t\"\"\"\n\t\tself.survivors.append(self)\n", "description": "\n\t\tResurrect self by storing self in a class-wide list.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "Simple", "data": "class Simple(SimpleBase):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleResurrector", "data": "class SimpleResurrector(NonGCResurrector, SimpleBase):\n\tpass\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "classTestBase:", "data": "class TestBase:\n\n\tdef setUp(self):\n\t\tself.old_garbage = gc.garbage[:]\n\t\tgc.garbage[:] = []\n\n\tdef tearDown(self):\n\t\t# None of the tests here should put anything in gc.garbage\n\t\ttry:\n\t\t\tself.assertEqual(gc.garbage, [])\n\t\tfinally:\n\t\t\tdel self.old_garbage\n\t\t\tgc.collect()\n\n\tdef assert_del_calls(self, ids):\n\t\tself.assertEqual(sorted(SimpleBase.del_calls), sorted(ids))\n\n\tdef assert_tp_del_calls(self, ids):\n\t\tself.assertEqual(sorted(SimpleBase.tp_del_calls), sorted(ids))\n\n\tdef assert_survivors(self, ids):\n\t\tself.assertEqual(sorted(id(x) for x in SimpleBase.survivors), sorted(ids))\n\n\tdef assert_garbage(self, ids):\n\t\tself.assertEqual(sorted(id(x) for x in gc.garbage), sorted(ids))\n\n\tdef clear_survivors(self):\n\t\tSimpleBase.survivors.clear()\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleFinalizationTest", "data": "class SimpleFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization without refcycles.\n\t\"\"\"\n\n\tdef test_simple(self):\n\t\twith SimpleBase.test():\n\t\t\ts = Simple()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_simple_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = SimpleResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\tself.assertIsNot(wr(), None)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\tself.assertIs(wr(), None)\n\n\tdef test_non_gc(self):\n\t\twith SimpleBase.test():\n\t\t\ts = NonGC()\n\t\t\tself.assertFalse(gc.is_tracked(s))\n\t\t\tids = [id(s)]\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_non_gc_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = NonGCResurrector()\n\t\t\tself.assertFalse(gc.is_tracked(s))\n\t\t\tids = [id(s)]\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids * 2)\n\t\t\tself.assert_survivors(ids)\n\n", "description": "\n\tTest finalization without refcycles.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "classSelfCycleBase:", "data": "class SelfCycleBase:\n\n\tdef __init__(self):\n\t\tsuper().__init__()\n\t\tself.ref = self\n\n\tdef check_sanity(self):\n\t\tsuper().check_sanity()\n\t\tassert self.ref is self\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleSelfCycle", "data": "class SimpleSelfCycle(SelfCycleBase, Simple):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SelfCycleResurrector", "data": "class SelfCycleResurrector(SelfCycleBase, SimpleResurrector):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SuicidalSelfCycle", "data": "class SuicidalSelfCycle(SelfCycleBase, Simple):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tExplicitly break the reference cycle.\n\t\t\"\"\"\n\t\tself.ref = None\n\n", "description": "\n\t\tExplicitly break the reference cycle.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SelfCycleFinalizationTest", "data": "class SelfCycleFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of an object having a single cyclic reference to\n\titself.\n\t\"\"\"\n\n\tdef test_simple(self):\n\t\twith SimpleBase.test():\n\t\t\ts = SimpleSelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_simple_resurrect(self):\n\t\t# Test that __del__ can resurrect the object being finalized.\n\t\twith SimpleBase.test():\n\t\t\ts = SelfCycleResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\t# XXX is this desirable?\n\t\t\tself.assertIs(wr(), None)\n\t\t\t# When trying to destroy the object a second time, __del__\n\t\t\t# isn't called anymore (and the object isn't resurrected).\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\n\tdef test_simple_suicide(self):\n\t\t# Test the GC is able to deal with an object that kills its last\n\t\t# reference during __del__.\n\t\twith SimpleBase.test():\n\t\t\ts = SuicidalSelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\n", "description": "\n\tTest finalization of an object having a single cyclic reference to\n\titself.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "classChainedBase:", "data": "class ChainedBase:\n\n\tdef chain(self, left):\n\t\tself.suicided = False\n\t\tself.left = left\n\t\tleft.right = self\n\n\tdef check_sanity(self):\n\t\tsuper().check_sanity()\n\t\tif self.suicided:\n\t\t\tassert self.left is None\n\t\t\tassert self.right is None\n\t\telse:\n\t\t\tleft = self.left\n\t\t\tif left.suicided:\n\t\t\t\tassert left.right is None\n\t\t\telse:\n\t\t\t\tassert left.right is self\n\t\t\tright = self.right\n\t\t\tif right.suicided:\n\t\t\t\tassert right.left is None\n\t\t\telse:\n\t\t\t\tassert right.left is self\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleChained", "data": "class SimpleChained(ChainedBase, Simple):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "ChainedResurrector", "data": "class ChainedResurrector(ChainedBase, SimpleResurrector):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SuicidalChained", "data": "class SuicidalChained(ChainedBase, Simple):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tExplicitly break the reference cycle.\n\t\t\"\"\"\n\t\tself.suicided = True\n\t\tself.left = None\n\t\tself.right = None\n\n", "description": "\n\t\tExplicitly break the reference cycle.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "CycleChainFinalizationTest", "data": "class CycleChainFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of a cyclic chain.  These tests are similar in\n\tspirit to the self-cycle tests above, but the collectable object\n\tgraph isn't trivial anymore.\n\t\"\"\"\n\n\tdef build_chain(self, classes):\n\t\tnodes = [cls() for cls in classes]\n\t\tfor i in range(len(nodes)):\n\t\t\tnodes[i].chain(nodes[i-1])\n\t\treturn nodes\n\n\tdef check_non_resurrecting_chain(self, classes):\n\t\tN = len(classes)\n\t\twith SimpleBase.test():\n\t\t\tnodes = self.build_chain(classes)\n\t\t\tids = [id(s) for s in nodes]\n\t\t\twrs = [weakref.ref(s) for s in nodes]\n\t\t\tdel nodes\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertEqual([wr() for wr in wrs], [None] * N)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\n\tdef check_resurrecting_chain(self, classes):\n\t\tN = len(classes)\n\t\twith SimpleBase.test():\n\t\t\tnodes = self.build_chain(classes)\n\t\t\tN = len(nodes)\n\t\t\tids = [id(s) for s in nodes]\n\t\t\tsurvivor_ids = [id(s) for s in nodes if isinstance(s, SimpleResurrector)]\n\t\t\twrs = [weakref.ref(s) for s in nodes]\n\t\t\tdel nodes\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(survivor_ids)\n\t\t\t# XXX desirable?\n\t\t\tself.assertEqual([wr() for wr in wrs], [None] * N)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_homogenous(self):\n\t\tself.check_non_resurrecting_chain([SimpleChained] * 3)\n\n\tdef test_homogenous_resurrect(self):\n\t\tself.check_resurrecting_chain([ChainedResurrector] * 3)\n\n\tdef test_homogenous_suicidal(self):\n\t\tself.check_non_resurrecting_chain([SuicidalChained] * 3)\n\n\tdef test_heterogenous_suicidal_one(self):\n\t\tself.check_non_resurrecting_chain([SuicidalChained, SimpleChained] * 2)\n\n\tdef test_heterogenous_suicidal_two(self):\n\t\tself.check_non_resurrecting_chain(\n\t\t\t[SuicidalChained] * 2 + [SimpleChained] * 2)\n\n\tdef test_heterogenous_resurrect_one(self):\n\t\tself.check_resurrecting_chain([ChainedResurrector, SimpleChained] * 2)\n\n\tdef test_heterogenous_resurrect_two(self):\n\t\tself.check_resurrecting_chain(\n\t\t\t[ChainedResurrector, SimpleChained, SuicidalChained] * 2)\n\n\tdef test_heterogenous_resurrect_three(self):\n\t\tself.check_resurrecting_chain(\n\t\t\t[ChainedResurrector] * 2 + [SimpleChained] * 2 + [SuicidalChained] * 2)\n\n", "description": "\n\tTest finalization of a cyclic chain.  These tests are similar in\n\tspirit to the self-cycle tests above, but the collectable object\n\tgraph isn't trivial anymore.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "LegacyBase", "data": "class LegacyBase(SimpleBase):\n\n\tdef __del__(self):\n\t\ttry:\n\t\t\t# Do not invoke side_effect here, since we are now exercising\n\t\t\t# the tp_del slot.\n\t\t\tif not self._cleaning:\n\t\t\t\tself.del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n\n\tdef __tp_del__(self):\n\t\t\"\"\"\n\t\tLegacy (pre-PEP 442) finalizer, mapped to a tp_del slot.\n\t\t\"\"\"\n\t\ttry:\n\t\t\tif not self._cleaning:\n\t\t\t\tself.tp_del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\t\t\tself.side_effect()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n", "description": "\n\t\tLegacy (pre-PEP 442) finalizer, mapped to a tp_del slot.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "Legacy", "data": "class Legacy(LegacyBase):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "LegacyResurrector", "data": "class LegacyResurrector(LegacyBase):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tResurrect self by storing self in a class-wide list.\n\t\t\"\"\"\n\t\tself.survivors.append(self)\n", "description": "\n\t\tResurrect self by storing self in a class-wide list.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "LegacySelfCycle", "data": "class LegacySelfCycle(SelfCycleBase, LegacyBase):\n\tpass\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "LegacyFinalizationTest", "data": "class LegacyFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of objects with a tp_del.\n\t\"\"\"\n\n\tdef tearDown(self):\n\t\t# These tests need to clean up a bit more, since they create\n\t\t# uncollectable objects.\n\t\tgc.garbage.clear()\n\t\tgc.collect()\n\t\tsuper().tearDown()\n\n\tdef test_legacy(self):\n\t\twith SimpleBase.test():\n\t\t\ts = Legacy()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\n\tdef test_legacy_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = LegacyResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\t# weakrefs are cleared before tp_del is called.\n\t\t\tself.assertIs(wr(), None)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids * 2)\n\t\t\tself.assert_survivors(ids)\n\t\tself.assertIs(wr(), None)\n\n\tdef test_legacy_self_cycle(self):\n\t\t# Self-cycles with legacy finalizers end up in gc.garbage.\n\t\twith SimpleBase.test():\n\t\t\ts = LegacySelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls([])\n\t\t\tself.assert_tp_del_calls([])\n\t\t\tself.assert_survivors([])\n\t\t\tself.assert_garbage(ids)\n\t\t\tself.assertIsNot(wr(), None)\n\t\t\t# Break the cycle to allow collection\n\t\t\tgc.garbage[0].ref = None\n\t\tself.assert_garbage([])\n\t\tself.assertIs(wr(), None)\n\n", "description": "\n\tTest finalization of objects with a tp_del.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}], [{"term": "def", "name": "fwith_tp_del", "data": "\tdef with_tp_del(cls):\n\t\tclass C(object):\n\t\t\tdef __new__(cls, *args, **kwargs):\n\t\t\t\traise TypeError('requires _testcapi.with_tp_del')\n\t\treturn C\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "classNonGCSimpleBase:", "data": "class NonGCSimpleBase:\n\t\"\"\"\n\tThe base class for all the objects under test, equipped with various\n\ttesting features.\n\t\"\"\"\n\n\tsurvivors = []\n\tdel_calls = []\n\ttp_del_calls = []\n\terrors = []\n\n\t_cleaning = False\n\n\t__slots__ = ()\n\n\t@classmethod\n\tdef _cleanup(cls):\n\t\tcls.survivors.clear()\n\t\tcls.errors.clear()\n\t\tgc.garbage.clear()\n\t\tgc.collect()\n\t\tcls.del_calls.clear()\n\t\tcls.tp_del_calls.clear()\n\n\t@classmethod\n\t@contextlib.contextmanager\n\tdef test(cls):\n\t\t\"\"\"\n\t\tA context manager to use around all finalization tests.\n\t\t\"\"\"\n\t\twith support.disable_gc():\n\t\t\tcls.del_calls.clear()\n\t\t\tcls.tp_del_calls.clear()\n\t\t\tNonGCSimpleBase._cleaning = False\n\t\t\ttry:\n\t\t\t\tyield\n\t\t\t\tif cls.errors:\n\t\t\t\t\traise cls.errors[0]\n\t\t\tfinally:\n\t\t\t\tNonGCSimpleBase._cleaning = True\n\t\t\t\tcls._cleanup()\n\n\tdef check_sanity(self):\n\t\t\"\"\"\n\t\tCheck the object is sane (non-broken).\n\t\t\"\"\"\n\n\tdef __del__(self):\n\t\t\"\"\"\n\t\tPEP 442 finalizer.  Record that this was called, check the\n\t\tobject is in a sane state, and invoke a side effect.\n\t\t\"\"\"\n\t\ttry:\n\t\t\tif not self._cleaning:\n\t\t\t\tself.del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\t\t\tself.side_effect()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tA side effect called on destruction.\n\t\t\"\"\"\n\n", "description": "\n\tThe base class for all the objects under test, equipped with various\n\ttesting features.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleBase", "data": "class SimpleBase(NonGCSimpleBase):\n\n\tdef __init__(self):\n\t\tself.id_ = id(self)\n\n\tdef check_sanity(self):\n\t\tassert self.id_ == id(self)\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "NonGC", "data": "class NonGC(NonGCSimpleBase):\n\t__slots__ = ()\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "NonGCResurrector", "data": "class NonGCResurrector(NonGCSimpleBase):\n\t__slots__ = ()\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tResurrect self by storing self in a class-wide list.\n\t\t\"\"\"\n\t\tself.survivors.append(self)\n", "description": "\n\t\tResurrect self by storing self in a class-wide list.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "Simple", "data": "class Simple(SimpleBase):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleResurrector", "data": "class SimpleResurrector(NonGCResurrector, SimpleBase):\n\tpass\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "classTestBase:", "data": "class TestBase:\n\n\tdef setUp(self):\n\t\tself.old_garbage = gc.garbage[:]\n\t\tgc.garbage[:] = []\n\n\tdef tearDown(self):\n\t\t# None of the tests here should put anything in gc.garbage\n\t\ttry:\n\t\t\tself.assertEqual(gc.garbage, [])\n\t\tfinally:\n\t\t\tdel self.old_garbage\n\t\t\tgc.collect()\n\n\tdef assert_del_calls(self, ids):\n\t\tself.assertEqual(sorted(SimpleBase.del_calls), sorted(ids))\n\n\tdef assert_tp_del_calls(self, ids):\n\t\tself.assertEqual(sorted(SimpleBase.tp_del_calls), sorted(ids))\n\n\tdef assert_survivors(self, ids):\n\t\tself.assertEqual(sorted(id(x) for x in SimpleBase.survivors), sorted(ids))\n\n\tdef assert_garbage(self, ids):\n\t\tself.assertEqual(sorted(id(x) for x in gc.garbage), sorted(ids))\n\n\tdef clear_survivors(self):\n\t\tSimpleBase.survivors.clear()\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleFinalizationTest", "data": "class SimpleFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization without refcycles.\n\t\"\"\"\n\n\tdef test_simple(self):\n\t\twith SimpleBase.test():\n\t\t\ts = Simple()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_simple_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = SimpleResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\tself.assertIsNot(wr(), None)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\tself.assertIs(wr(), None)\n\n\tdef test_non_gc(self):\n\t\twith SimpleBase.test():\n\t\t\ts = NonGC()\n\t\t\tself.assertFalse(gc.is_tracked(s))\n\t\t\tids = [id(s)]\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_non_gc_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = NonGCResurrector()\n\t\t\tself.assertFalse(gc.is_tracked(s))\n\t\t\tids = [id(s)]\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids * 2)\n\t\t\tself.assert_survivors(ids)\n\n", "description": "\n\tTest finalization without refcycles.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "classSelfCycleBase:", "data": "class SelfCycleBase:\n\n\tdef __init__(self):\n\t\tsuper().__init__()\n\t\tself.ref = self\n\n\tdef check_sanity(self):\n\t\tsuper().check_sanity()\n\t\tassert self.ref is self\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleSelfCycle", "data": "class SimpleSelfCycle(SelfCycleBase, Simple):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SelfCycleResurrector", "data": "class SelfCycleResurrector(SelfCycleBase, SimpleResurrector):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SuicidalSelfCycle", "data": "class SuicidalSelfCycle(SelfCycleBase, Simple):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tExplicitly break the reference cycle.\n\t\t\"\"\"\n\t\tself.ref = None\n\n", "description": "\n\t\tExplicitly break the reference cycle.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SelfCycleFinalizationTest", "data": "class SelfCycleFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of an object having a single cyclic reference to\n\titself.\n\t\"\"\"\n\n\tdef test_simple(self):\n\t\twith SimpleBase.test():\n\t\t\ts = SimpleSelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_simple_resurrect(self):\n\t\t# Test that __del__ can resurrect the object being finalized.\n\t\twith SimpleBase.test():\n\t\t\ts = SelfCycleResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\t# XXX is this desirable?\n\t\t\tself.assertIs(wr(), None)\n\t\t\t# When trying to destroy the object a second time, __del__\n\t\t\t# isn't called anymore (and the object isn't resurrected).\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\n\tdef test_simple_suicide(self):\n\t\t# Test the GC is able to deal with an object that kills its last\n\t\t# reference during __del__.\n\t\twith SimpleBase.test():\n\t\t\ts = SuicidalSelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\n", "description": "\n\tTest finalization of an object having a single cyclic reference to\n\titself.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "classChainedBase:", "data": "class ChainedBase:\n\n\tdef chain(self, left):\n\t\tself.suicided = False\n\t\tself.left = left\n\t\tleft.right = self\n\n\tdef check_sanity(self):\n\t\tsuper().check_sanity()\n\t\tif self.suicided:\n\t\t\tassert self.left is None\n\t\t\tassert self.right is None\n\t\telse:\n\t\t\tleft = self.left\n\t\t\tif left.suicided:\n\t\t\t\tassert left.right is None\n\t\t\telse:\n\t\t\t\tassert left.right is self\n\t\t\tright = self.right\n\t\t\tif right.suicided:\n\t\t\t\tassert right.left is None\n\t\t\telse:\n\t\t\t\tassert right.left is self\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleChained", "data": "class SimpleChained(ChainedBase, Simple):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "ChainedResurrector", "data": "class ChainedResurrector(ChainedBase, SimpleResurrector):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SuicidalChained", "data": "class SuicidalChained(ChainedBase, Simple):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tExplicitly break the reference cycle.\n\t\t\"\"\"\n\t\tself.suicided = True\n\t\tself.left = None\n\t\tself.right = None\n\n", "description": "\n\t\tExplicitly break the reference cycle.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "CycleChainFinalizationTest", "data": "class CycleChainFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of a cyclic chain.  These tests are similar in\n\tspirit to the self-cycle tests above, but the collectable object\n\tgraph isn't trivial anymore.\n\t\"\"\"\n\n\tdef build_chain(self, classes):\n\t\tnodes = [cls() for cls in classes]\n\t\tfor i in range(len(nodes)):\n\t\t\tnodes[i].chain(nodes[i-1])\n\t\treturn nodes\n\n\tdef check_non_resurrecting_chain(self, classes):\n\t\tN = len(classes)\n\t\twith SimpleBase.test():\n\t\t\tnodes = self.build_chain(classes)\n\t\t\tids = [id(s) for s in nodes]\n\t\t\twrs = [weakref.ref(s) for s in nodes]\n\t\t\tdel nodes\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertEqual([wr() for wr in wrs], [None] * N)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\n\tdef check_resurrecting_chain(self, classes):\n\t\tN = len(classes)\n\t\twith SimpleBase.test():\n\t\t\tnodes = self.build_chain(classes)\n\t\t\tN = len(nodes)\n\t\t\tids = [id(s) for s in nodes]\n\t\t\tsurvivor_ids = [id(s) for s in nodes if isinstance(s, SimpleResurrector)]\n\t\t\twrs = [weakref.ref(s) for s in nodes]\n\t\t\tdel nodes\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(survivor_ids)\n\t\t\t# XXX desirable?\n\t\t\tself.assertEqual([wr() for wr in wrs], [None] * N)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_homogenous(self):\n\t\tself.check_non_resurrecting_chain([SimpleChained] * 3)\n\n\tdef test_homogenous_resurrect(self):\n\t\tself.check_resurrecting_chain([ChainedResurrector] * 3)\n\n\tdef test_homogenous_suicidal(self):\n\t\tself.check_non_resurrecting_chain([SuicidalChained] * 3)\n\n\tdef test_heterogenous_suicidal_one(self):\n\t\tself.check_non_resurrecting_chain([SuicidalChained, SimpleChained] * 2)\n\n\tdef test_heterogenous_suicidal_two(self):\n\t\tself.check_non_resurrecting_chain(\n\t\t\t[SuicidalChained] * 2 + [SimpleChained] * 2)\n\n\tdef test_heterogenous_resurrect_one(self):\n\t\tself.check_resurrecting_chain([ChainedResurrector, SimpleChained] * 2)\n\n\tdef test_heterogenous_resurrect_two(self):\n\t\tself.check_resurrecting_chain(\n\t\t\t[ChainedResurrector, SimpleChained, SuicidalChained] * 2)\n\n\tdef test_heterogenous_resurrect_three(self):\n\t\tself.check_resurrecting_chain(\n\t\t\t[ChainedResurrector] * 2 + [SimpleChained] * 2 + [SuicidalChained] * 2)\n\n", "description": "\n\tTest finalization of a cyclic chain.  These tests are similar in\n\tspirit to the self-cycle tests above, but the collectable object\n\tgraph isn't trivial anymore.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "LegacyBase", "data": "class LegacyBase(SimpleBase):\n\n\tdef __del__(self):\n\t\ttry:\n\t\t\t# Do not invoke side_effect here, since we are now exercising\n\t\t\t# the tp_del slot.\n\t\t\tif not self._cleaning:\n\t\t\t\tself.del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n\n\tdef __tp_del__(self):\n\t\t\"\"\"\n\t\tLegacy (pre-PEP 442) finalizer, mapped to a tp_del slot.\n\t\t\"\"\"\n\t\ttry:\n\t\t\tif not self._cleaning:\n\t\t\t\tself.tp_del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\t\t\tself.side_effect()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n", "description": "\n\t\tLegacy (pre-PEP 442) finalizer, mapped to a tp_del slot.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "Legacy", "data": "class Legacy(LegacyBase):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "LegacyResurrector", "data": "class LegacyResurrector(LegacyBase):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tResurrect self by storing self in a class-wide list.\n\t\t\"\"\"\n\t\tself.survivors.append(self)\n", "description": "\n\t\tResurrect self by storing self in a class-wide list.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "LegacySelfCycle", "data": "class LegacySelfCycle(SelfCycleBase, LegacyBase):\n\tpass\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "LegacyFinalizationTest", "data": "class LegacyFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of objects with a tp_del.\n\t\"\"\"\n\n\tdef tearDown(self):\n\t\t# These tests need to clean up a bit more, since they create\n\t\t# uncollectable objects.\n\t\tgc.garbage.clear()\n\t\tgc.collect()\n\t\tsuper().tearDown()\n\n\tdef test_legacy(self):\n\t\twith SimpleBase.test():\n\t\t\ts = Legacy()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\n\tdef test_legacy_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = LegacyResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\t# weakrefs are cleared before tp_del is called.\n\t\t\tself.assertIs(wr(), None)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids * 2)\n\t\t\tself.assert_survivors(ids)\n\t\tself.assertIs(wr(), None)\n\n\tdef test_legacy_self_cycle(self):\n\t\t# Self-cycles with legacy finalizers end up in gc.garbage.\n\t\twith SimpleBase.test():\n\t\t\ts = LegacySelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls([])\n\t\t\tself.assert_tp_del_calls([])\n\t\t\tself.assert_survivors([])\n\t\t\tself.assert_garbage(ids)\n\t\t\tself.assertIsNot(wr(), None)\n\t\t\t# Break the cycle to allow collection\n\t\t\tgc.garbage[0].ref = None\n\t\tself.assert_garbage([])\n\t\tself.assertIs(wr(), None)\n\n", "description": "\n\tTest finalization of objects with a tp_del.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}], [{"term": "def", "name": "test_branches_flow", "data": "def test_branches_flow(simple_pipeline):\n\tf = flows.FlowMultipleBranches()\n\tf.compile(simple_pipeline)\n\tr = f(a=1)\n\n\tassert r['mul_two'] == 2\n\tassert r['mul_three'] == 3\n\n", "description": null, "category": "simple", "imports": ["from test_core.test_flow import flows"]}, {"term": "def", "name": "test_save_result", "data": "def test_save_result(simple_pipeline):\n\tf = flows.FlowWithSaveResult()\n\tf.compile(simple_pipeline)\n\tr = f(a=1)\n\n\tassert r['mul_two'] == 2\n\tassert r['mul_three'] == 3\n\n", "description": null, "category": "simple", "imports": ["from test_core.test_flow import flows"]}, {"term": "def", "name": "test_flow_reconnect", "data": "def test_flow_reconnect(simple_pipeline):\n\tf = flows.FlowReconnect()\n\tf.compile(simple_pipeline)\n\tr = f(a=1)\n\n\tassert r['mul_two_patched'] == 2\n\tassert r['mul_three'] == 3\n\n", "description": null, "category": "simple", "imports": ["from test_core.test_flow import flows"]}, {"term": "def", "name": "test_hard_inheritance", "data": "def test_hard_inheritance(simple_pipeline):\n\tf = flows.HardInheritance()\n\tf.compile(simple_pipeline)\n\tr = f(a=1)\n\n\tassert r['mul_two_patched'] == 2\n\tassert r['mul_three'] == 3\n", "description": null, "category": "simple", "imports": ["from test_core.test_flow import flows"]}], [{"term": "def", "name": "trim", "data": "def trim(value, num):\n\treturn value[:num]\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "make_data_div", "data": "def make_data_div(value):\n\t\"\"\"A filter that uses a decorator (@mark_safe).\"\"\"\n\treturn '' % value\n\n", "description": "A filter that uses a decorator (@mark_safe).", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "noop", "data": "def noop(value, param=None):\n\t\"\"\"A noop filter that always return its first argument and does nothing with\n\tits second (optional) one.\n\tUseful for testing out whitespace in filter arguments (see #19882).\"\"\"\n\treturn value\n\n", "description": "A noop filter that always return its first argument and does nothing with\n\tits second (optional) one.\n\tUseful for testing out whitespace in filter arguments (see #19882).", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "context_stack_length", "data": "def context_stack_length(context):\n\treturn len(context.dicts)\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "no_params", "data": "def no_params():\n\t\"\"\"Expected no_params __doc__\"\"\"\n\treturn \"no_params - Expected result\"\n\n", "description": "Expected no_params __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "one_param", "data": "def one_param(arg):\n\t\"\"\"Expected one_param __doc__\"\"\"\n\treturn \"one_param - Expected result: %s\" % arg\n\n", "description": "Expected one_param __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "explicit_no_context", "data": "def explicit_no_context(arg):\n\t\"\"\"Expected explicit_no_context __doc__\"\"\"\n\treturn \"explicit_no_context - Expected result: %s\" % arg\n\n", "description": "Expected explicit_no_context __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "no_params_with_context", "data": "def no_params_with_context(context):\n\t\"\"\"Expected no_params_with_context __doc__\"\"\"\n\treturn \"no_params_with_context - Expected result (context value: %s)\" % context['value']\n\n", "description": "Expected no_params_with_context __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "params_and_context", "data": "def params_and_context(context, arg):\n\t\"\"\"Expected params_and_context __doc__\"\"\"\n\treturn \"params_and_context - Expected result (context value: %s): %s\" % (context['value'], arg)\n\n", "description": "Expected params_and_context __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_two_params", "data": "def simple_two_params(one, two):\n\t\"\"\"Expected simple_two_params __doc__\"\"\"\n\treturn \"simple_two_params - Expected result: %s, %s\" % (one, two)\n\n", "description": "Expected simple_two_params __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_keyword_only_param", "data": "def simple_keyword_only_param(*, kwarg):\n\treturn \"simple_keyword_only_param - Expected result: %s\" % kwarg\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_keyword_only_default", "data": "def simple_keyword_only_default(*, kwarg=42):\n\treturn \"simple_keyword_only_default - Expected result: %s\" % kwarg\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_one_default", "data": "def simple_one_default(one, two='hi'):\n\t\"\"\"Expected simple_one_default __doc__\"\"\"\n\treturn \"simple_one_default - Expected result: %s, %s\" % (one, two)\n\n", "description": "Expected simple_one_default __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_unlimited_args", "data": "def simple_unlimited_args(one, two='hi', *args):\n\t\"\"\"Expected simple_unlimited_args __doc__\"\"\"\n\treturn \"simple_unlimited_args - Expected result: %s\" % (\n\t\t', '.join(str(arg) for arg in [one, two, *args])\n\t)\n\n", "description": "Expected simple_unlimited_args __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_only_unlimited_args", "data": "def simple_only_unlimited_args(*args):\n\t\"\"\"Expected simple_only_unlimited_args __doc__\"\"\"\n\treturn \"simple_only_unlimited_args - Expected result: %s\" % ', '.join(str(arg) for arg in args)\n\n", "description": "Expected simple_only_unlimited_args __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_unlimited_args_kwargs", "data": "def simple_unlimited_args_kwargs(one, two='hi', *args, **kwargs):\n\t\"\"\"Expected simple_unlimited_args_kwargs __doc__\"\"\"\n\t# Sort the dictionary by key to guarantee the order for testing.\n\tsorted_kwarg = sorted(kwargs.items(), key=operator.itemgetter(0))\n\treturn \"simple_unlimited_args_kwargs - Expected result: %s / %s\" % (\n\t\t', '.join(str(arg) for arg in [one, two, *args]),\n\t\t', '.join('%s=%s' % (k, v) for (k, v) in sorted_kwarg)\n\t)\n\n", "description": "Expected simple_unlimited_args_kwargs __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_tag_without_context_parameter", "data": "def simple_tag_without_context_parameter(arg):\n\t\"\"\"Expected simple_tag_without_context_parameter __doc__\"\"\"\n\treturn \"Expected result\"\n\n", "description": "Expected simple_tag_without_context_parameter __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "escape_naive", "data": "def escape_naive(context):\n\t\"\"\"A tag that doesn't even think about escaping issues\"\"\"\n\treturn \"Hello {0}!\".format(context['name'])\n\n", "description": "A tag that doesn't even think about escaping issues", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "escape_explicit", "data": "def escape_explicit(context):\n\t\"\"\"A tag that uses escape explicitly\"\"\"\n\treturn escape(\"Hello {0}!\".format(context['name']))\n\n", "description": "A tag that uses escape explicitly", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "escape_format_html", "data": "def escape_format_html(context):\n\t\"\"\"A tag that uses format_html\"\"\"\n\treturn format_html(\"Hello {0}!\", context['name'])\n\n", "description": "A tag that uses format_html", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "current_app", "data": "def current_app(context):\n\treturn \"%s\" % context.current_app\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "use_l10n", "data": "def use_l10n(context):\n\treturn \"%s\" % context.use_l10n\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "minustwo_overridden_name", "data": "def minustwo_overridden_name(value):\n\treturn value - 2\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "counter", "data": "def counter(parser, token):\n\treturn CounterNode()\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "class", "name": "CounterNode", "data": "class CounterNode(template.Node):\n\tdef __init__(self):\n\t\tself.count = 0\n\n\tdef render(self, context):\n\t\tcount = self.count\n\t\tself.count = count + 1\n\t\treturn count\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}], [{"term": "def", "name": "glVertexPointerd", "data": "def glVertexPointerd( array ):\n\t\"Natural writing of glVertexPointerd using standard ctypes\"\n\targ2 = GL_DOUBLE\n\targ3 = 0 # stride\n\targ4 = arrays.asArray(array, GL_DOUBLE)\n\targ1 = arrays.arraySize( arg4, 'd' )\n\tplatform.OpenGL.glVertexPointer( arg1, arg2, arg3, arrays.ArrayDatatype.dataPointer(arg4) )\n\tglCheckError()\n\t# only store if we successfully set the value...\n\tstoredPointers[ GL_VERTEX_ARRAY ] = arg4\n", "description": null, "category": "simple", "imports": ["from OpenGL import platform, arrays, error, wrapper, contextdata, converters, constant", "from OpenGL.raw.GL.VERSION import GL_1_1 as simple", "import ctypes", "import weakref", "\tfrom OpenGL.GL import glGetIntegerv", "\tfrom OpenGL.GL import selection, feedback"]}, {"term": "def", "name": "wrapPointerFunction", "data": "def wrapPointerFunction( name, baseFunction, glType, arrayType,startArgs, defaultSize ):\n\t\"\"\"Wrap the given pointer-setting function\"\"\"\n\tfunction= wrapper.wrapper( baseFunction )\n\tif 'ptr' in baseFunction.argNames:\n\t\tpointer_name = 'ptr'\n\telse:\n\t\tpointer_name = 'pointer'\n\tassert not getattr( function, 'pyConverters', None ), \"\"\"Reusing wrappers?\"\"\"\n\tif arrayType:\n\t\tarrayModuleType = arrays.GL_CONSTANT_TO_ARRAY_TYPE[ glType ]\n\t\tfunction.setPyConverter( pointer_name, arrays.asArrayType(arrayModuleType) )\n\telse:\n\t\tfunction.setPyConverter( pointer_name, arrays.AsArrayOfType(pointer_name,'type') )\n\tfunction.setCConverter( pointer_name, converters.getPyArgsName( pointer_name ) )\n\tif 'size' in function.argNames:\n\t\tfunction.setPyConverter( 'size' )\n\t\tfunction.setCConverter( 'size', arrays.arraySizeOfFirstType(arrayModuleType,defaultSize) )\n\tif 'type' in function.argNames:\n\t\tfunction.setPyConverter( 'type' )\n\t\tfunction.setCConverter( 'type', glType )\n\tif 'stride' in function.argNames:\n\t\tfunction.setPyConverter( 'stride' )\n\t\tfunction.setCConverter( 'stride', 0 )\n\tfunction.setStoreValues( arrays.storePointerType( pointer_name, arrayType ) )\n\tfunction.setReturnValues( wrapper.returnPyArgument( pointer_name ) )\n\treturn name,function\n\n\n", "description": "Wrap the given pointer-setting function", "category": "simple", "imports": ["from OpenGL import platform, arrays, error, wrapper, contextdata, converters, constant", "from OpenGL.raw.GL.VERSION import GL_1_1 as simple", "import ctypes", "import weakref", "\tfrom OpenGL.GL import glGetIntegerv", "\tfrom OpenGL.GL import selection, feedback"]}, {"term": "def", "name": "glDrawElementsTyped", "data": "def glDrawElementsTyped( type, suffix ):\n\tarrayType = arrays.GL_CONSTANT_TO_ARRAY_TYPE[ type ]\n\tfunction = wrapper.wrapper(\n\t\tsimple.glDrawElements\n\t).setPyConverter('type').setCConverter(\n\t\t'type', type\n\t).setPyConverter('count').setCConverter(\n\t\t'count', arrays.AsArrayTypedSize( 'indices', arrayType ),\n\t).setPyConverter(\n\t\t'indices', arrays.AsArrayTyped( 'indices', arrayType ),\n\t).setReturnValues(\n\t\twrapper.returnPyArgument( 'indices' )\n\t)\n", "description": null, "category": "simple", "imports": ["from OpenGL import platform, arrays, error, wrapper, contextdata, converters, constant", "from OpenGL.raw.GL.VERSION import GL_1_1 as simple", "import ctypes", "import weakref", "\tfrom OpenGL.GL import glGetIntegerv", "\tfrom OpenGL.GL import selection, feedback"]}, {"term": "def", "name": "glSelectBuffer", "data": "def glSelectBuffer( size, buffer = None ):\n\t\"\"\"Create a selection buffer of the given size\n\t\"\"\"\n\tif buffer is None:\n\t\tbuffer = arrays.GLuintArray.zeros( (size,) )\n\tsimple.glSelectBuffer( size, buffer )\n\tcontextdata.setValue( simple.GL_SELECTION_BUFFER_POINTER, buffer )\n", "description": "Create a selection buffer of the given size\n\t", "category": "simple", "imports": ["from OpenGL import platform, arrays, error, wrapper, contextdata, converters, constant", "from OpenGL.raw.GL.VERSION import GL_1_1 as simple", "import ctypes", "import weakref", "\tfrom OpenGL.GL import glGetIntegerv", "\tfrom OpenGL.GL import selection, feedback"]}, {"term": "def", "name": "glFeedbackBuffer", "data": "def glFeedbackBuffer( size, type, buffer = None ):\n\t\"\"\"Create a selection buffer of the given size\n\t\"\"\"\n\tif buffer is None:\n\t\tbuffer = arrays.GLfloatArray.zeros( (size,) )\n\tsimple.glFeedbackBuffer( size, type, buffer )\n\tcontextdata.setValue( simple.GL_FEEDBACK_BUFFER_POINTER, buffer )\n\tcontextdata.setValue( \"GL_FEEDBACK_BUFFER_TYPE\", type )\n\treturn buffer\n", "description": "Create a selection buffer of the given size\n\t", "category": "simple", "imports": ["from OpenGL import platform, arrays, error, wrapper, contextdata, converters, constant", "from OpenGL.raw.GL.VERSION import GL_1_1 as simple", "import ctypes", "import weakref", "\tfrom OpenGL.GL import glGetIntegerv", "\tfrom OpenGL.GL import selection, feedback"]}, {"term": "def", "name": "glRenderMode", "data": "def glRenderMode( newMode ):\n\t\"\"\"Change to the given rendering mode\n\n\tIf the current mode is GL_FEEDBACK or GL_SELECT, return\n\tthe current buffer appropriate to the mode\n\t\"\"\"\n\t# must get the current mode to determine operation...\n\tfrom OpenGL.GL import glGetIntegerv\n\tfrom OpenGL.GL import selection, feedback\n\tcurrentMode = glGetIntegerv( simple.GL_RENDER_MODE )\n\ttry:\n\t\tcurrentMode = currentMode[0]\n\texcept (TypeError,ValueError,IndexError), err:\n\t\tpass\n\tif currentMode in (simple.GL_RENDER,0):\n\t\t# no array needs to be returned...\n\t\treturn simple.glRenderMode( newMode )\n\tresult = simple.glRenderMode( newMode )\n\t# result is now an integer telling us how many elements were copied...\n\n\tif result < 0:\n\t\tif currentMode == simple.GL_SELECT:\n\t\t\traise error.GLError(\n\t\t\t\tsimple.GL_STACK_OVERFLOW,\n\t\t\t\t\"glSelectBuffer too small to hold selection results\",\n\t\t\t)\n\t\telif currentMode == simple.GL_FEEDBACK:\n\t\t\traise error.GLError(\n\t\t\t\tsimple.GL_STACK_OVERFLOW,\n\t\t\t\t\"glFeedbackBuffer too small to hold selection results\",\n\t\t\t)\n\t\telse:\n\t\t\traise error.GLError(\n\t\t\t\tsimple.GL_STACK_OVERFLOW,\n\t\t\t\t\"Unknown glRenderMode buffer (%s) too small to hold selection results\"%(\n\t\t\t\t\tcurrentMode,\n\t\t\t\t),\n\t\t\t)\n\t# Okay, now that the easy cases are out of the way...\n\t#  Do we have a pre-stored pointer about which the user already knows?\n\tcontext = platform.GetCurrentContext()\n\tif context == 0:\n\t\traise error.Error(\n\t\t\t\"\"\"Returning from glRenderMode without a valid context!\"\"\"\n\t\t)\n\tarrayConstant, wrapperFunction = {\n\t\tsimple.GL_FEEDBACK: (simple.GL_FEEDBACK_BUFFER_POINTER,feedback.parseFeedback),\n\t\tsimple.GL_SELECT: (simple.GL_SELECTION_BUFFER_POINTER, selection.GLSelectRecord.fromArray),\n\t}[ currentMode ]\n\tcurrent = contextdata.getValue( arrayConstant )\n\t# XXX check to see if it's the *same* array we set currently!\n\tif current is None:\n\t\tcurrent = glGetPointerv( arrayConstant )\n\t# XXX now, can turn the array into the appropriate wrapper type...\n\tif wrapperFunction:\n\t\tcurrent = wrapperFunction( current, result )\n\treturn current\n", "description": "Change to the given rendering mode\n\n\tIf the current mode is GL_FEEDBACK or GL_SELECT, return\n\tthe current buffer appropriate to the mode\n\t", "category": "simple", "imports": ["from OpenGL import platform, arrays, error, wrapper, contextdata, converters, constant", "from OpenGL.raw.GL.VERSION import GL_1_1 as simple", "import ctypes", "import weakref", "\tfrom OpenGL.GL import glGetIntegerv", "\tfrom OpenGL.GL import selection, feedback"]}, {"term": "def", "name": "glGetPointerv", "data": "def glGetPointerv( constant ):\n\t\"\"\"Retrieve a stored pointer constant\"\"\"\n\t# do we have a cached version of the pointer?\n\t# get the base pointer from the underlying operation\n\tvp = ctypes.voidp()\n\tsimple.glGetPointerv( constant, ctypes.byref(vp) )\n\tcurrent = contextdata.getValue( constant )\n\tif current is not None:\n\t\tif arrays.ArrayDatatype.dataPointer( current ) == vp.value:\n\t\t\treturn current\n\t# XXX should be coercing to the proper type and converting to an array\n\treturn vp\n", "description": "Retrieve a stored pointer constant", "category": "simple", "imports": ["from OpenGL import platform, arrays, error, wrapper, contextdata, converters, constant", "from OpenGL.raw.GL.VERSION import GL_1_1 as simple", "import ctypes", "import weakref", "\tfrom OpenGL.GL import glGetIntegerv", "\tfrom OpenGL.GL import selection, feedback"]}], [{"term": "def", "name": "parseFeedback", "data": "def parseFeedback( buffer, entryCount ):\n\t\"\"\"Parse the feedback buffer into Python object records\"\"\"\n\tbufferIndex = 0\n\tresult = []\n\tgetVertex = createGetVertex( )\n\twhile bufferIndex < entryCount:\n\t\ttoken = int(buffer[bufferIndex])\n\t\tbufferIndex += 1\n\t\tif SINGLE_VERTEX_TOKENS.has_key( token):\n\t\t\tvData, bufferIndex = getVertex( buffer, bufferIndex )\n\t\t\tresult.append( (SINGLE_VERTEX_TOKENS.get(token), Vertex(*vData)) )\n\t\telif DOUBLE_VERTEX_TOKENS.has_key( token ):\n\t\t\tvData, bufferIndex = getVertex( buffer, bufferIndex )\n\t\t\tvData2, bufferIndex = getVertex( buffer, bufferIndex )\n\t\t\tresult.append( (\n\t\t\t\tDOUBLE_VERTEX_TOKENS.get(token), \n\t\t\t\tVertex(*vData),\n\t\t\t\tVertex(*vData2),\n\t\t\t) )\n\t\telif token == simple.GL_PASS_THROUGH_TOKEN:\n\t\t\tresult.append( (simple.GL_PASS_THROUGH_TOKEN, buffer[bufferIndex]))\n\t\t\tbufferIndex += 1\n\t\telif token == simple.GL_POLYGON_TOKEN:\n\t\t\ttemp = [simple.GL_POLYGON_TOKEN]\n\t\t\tcount = int(buffer[bufferIndex])\n\t\t\tbufferIndex += 1\n\t\t\tfor item in range(count):\n\t\t\t\tvData,bufferIndex = getVertex( buffer, bufferIndex )\n\t\t\t\ttemp.append( Vertex(*vData))\n\t\t\tresult.append( tuple(temp))\n\t\telse:\n\t\t\traise ValueError( \n\t\t\t\t\"\"\"Unrecognised token %r in feedback stream\"\"\"%(token,)\n\t\t\t)\n\treturn result\n", "description": "Parse the feedback buffer into Python object records", "category": "simple", "imports": ["from OpenGL import contextdata", "from OpenGL.raw import GL as simple", "from OpenGL.GL import glget"]}, {"term": "class", "name": "Vertex", "data": "class Vertex( object ):\n\t\"\"\"Simplistic holder for vertex data from a feedback buffer\"\"\"\n\t__slots__ = ('vertex','color','texture')\n\tdef __init__( self, vertex,color=None,texture=None):\n\t\t\"\"\"Store values for access\"\"\"\n\t\tself.vertex = vertex \n\t\tself.color = color \n", "description": "Simplistic holder for vertex data from a feedback buffer", "category": "simple", "imports": ["from OpenGL import contextdata", "from OpenGL.raw import GL as simple", "from OpenGL.GL import glget"]}, {"term": "def", "name": "createGetVertex", "data": "def createGetVertex( ):\n\tmode = contextdata.getValue( \"GL_FEEDBACK_BUFFER_TYPE\" )\n\tindexMode = glget.glGetBoolean( simple.GL_INDEX_MODE )\n\tcolorSize = [ 4,1 ][ int(indexMode) ]\n\tif mode in (simple.GL_2D,simple.GL_3D):\n\t\tif mode == simple.GL_2D:\n\t\t\tsize = 2\n\t\telse:\n\t\t\tsize = 3\n\t\tdef getVertex( buffer, bufferIndex ):\n\t\t\tend = bufferIndex+size\n\t\t\treturn (buffer[bufferIndex:end],None,None),end \n\telif mode == simple.GL_3D_COLOR:\n\t\tdef getVertex( buffer, bufferIndex ):\n\t\t\tend = bufferIndex+3\n\t\t\tcolorEnd = end + colorSize\n\t\t\treturn (buffer[bufferIndex:end],buffer[end:colorEnd],None),colorEnd \n\telse:\n\t\tif mode == simple.GL_3D_COLOR_TEXTURE:\n\t\t\tsize = 3\n\t\telse:\n\t\t\tsize = 4\n\t\tdef getVertex( buffer, bufferIndex ):\n\t\t\tend = bufferIndex+size\n\t\t\tcolorEnd = end + colorSize\n\t\t\ttextureEnd = colorEnd + 4\n\t\t\treturn (buffer[bufferIndex:end],buffer[end:colorEnd],buffer[colorEnd:textureEnd]),textureEnd\n", "description": null, "category": "simple", "imports": ["from OpenGL import contextdata", "from OpenGL.raw import GL as simple", "from OpenGL.GL import glget"]}], [{"term": "def", "name": "trim", "data": "def trim(value, num):\n\treturn value[:num]\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "make_data_div", "data": "def make_data_div(value):\n\t\"\"\"A filter that uses a decorator (@mark_safe).\"\"\"\n\treturn '' % value\n\n", "description": "A filter that uses a decorator (@mark_safe).", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "noop", "data": "def noop(value, param=None):\n\t\"\"\"A noop filter that always return its first argument and does nothing with\n\tits second (optional) one.\n\tUseful for testing out whitespace in filter arguments (see #19882).\"\"\"\n\treturn value\n\n", "description": "A noop filter that always return its first argument and does nothing with\n\tits second (optional) one.\n\tUseful for testing out whitespace in filter arguments (see #19882).", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "context_stack_length", "data": "def context_stack_length(context):\n\treturn len(context.dicts)\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "no_params", "data": "def no_params():\n\t\"\"\"Expected no_params __doc__\"\"\"\n\treturn \"no_params - Expected result\"\n\n", "description": "Expected no_params __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "one_param", "data": "def one_param(arg):\n\t\"\"\"Expected one_param __doc__\"\"\"\n\treturn \"one_param - Expected result: %s\" % arg\n\n", "description": "Expected one_param __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "explicit_no_context", "data": "def explicit_no_context(arg):\n\t\"\"\"Expected explicit_no_context __doc__\"\"\"\n\treturn \"explicit_no_context - Expected result: %s\" % arg\n\n", "description": "Expected explicit_no_context __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "no_params_with_context", "data": "def no_params_with_context(context):\n\t\"\"\"Expected no_params_with_context __doc__\"\"\"\n\treturn \"no_params_with_context - Expected result (context value: %s)\" % context['value']\n\n", "description": "Expected no_params_with_context __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "params_and_context", "data": "def params_and_context(context, arg):\n\t\"\"\"Expected params_and_context __doc__\"\"\"\n\treturn \"params_and_context - Expected result (context value: %s): %s\" % (context['value'], arg)\n\n", "description": "Expected params_and_context __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_two_params", "data": "def simple_two_params(one, two):\n\t\"\"\"Expected simple_two_params __doc__\"\"\"\n\treturn \"simple_two_params - Expected result: %s, %s\" % (one, two)\n\n", "description": "Expected simple_two_params __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_keyword_only_param", "data": "def simple_keyword_only_param(*, kwarg):\n\treturn \"simple_keyword_only_param - Expected result: %s\" % kwarg\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_keyword_only_default", "data": "def simple_keyword_only_default(*, kwarg=42):\n\treturn \"simple_keyword_only_default - Expected result: %s\" % kwarg\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_one_default", "data": "def simple_one_default(one, two='hi'):\n\t\"\"\"Expected simple_one_default __doc__\"\"\"\n\treturn \"simple_one_default - Expected result: %s, %s\" % (one, two)\n\n", "description": "Expected simple_one_default __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_unlimited_args", "data": "def simple_unlimited_args(one, two='hi', *args):\n\t\"\"\"Expected simple_unlimited_args __doc__\"\"\"\n\treturn \"simple_unlimited_args - Expected result: %s\" % (\n\t\t', '.join(str(arg) for arg in [one, two, *args])\n\t)\n\n", "description": "Expected simple_unlimited_args __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_only_unlimited_args", "data": "def simple_only_unlimited_args(*args):\n\t\"\"\"Expected simple_only_unlimited_args __doc__\"\"\"\n\treturn \"simple_only_unlimited_args - Expected result: %s\" % ', '.join(str(arg) for arg in args)\n\n", "description": "Expected simple_only_unlimited_args __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_unlimited_args_kwargs", "data": "def simple_unlimited_args_kwargs(one, two='hi', *args, **kwargs):\n\t\"\"\"Expected simple_unlimited_args_kwargs __doc__\"\"\"\n\t# Sort the dictionary by key to guarantee the order for testing.\n\tsorted_kwarg = sorted(kwargs.items(), key=operator.itemgetter(0))\n\treturn \"simple_unlimited_args_kwargs - Expected result: %s / %s\" % (\n\t\t', '.join(str(arg) for arg in [one, two, *args]),\n\t\t', '.join('%s=%s' % (k, v) for (k, v) in sorted_kwarg)\n\t)\n\n", "description": "Expected simple_unlimited_args_kwargs __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_tag_without_context_parameter", "data": "def simple_tag_without_context_parameter(arg):\n\t\"\"\"Expected simple_tag_without_context_parameter __doc__\"\"\"\n\treturn \"Expected result\"\n\n", "description": "Expected simple_tag_without_context_parameter __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "escape_naive", "data": "def escape_naive(context):\n\t\"\"\"A tag that doesn't even think about escaping issues\"\"\"\n\treturn \"Hello {0}!\".format(context['name'])\n\n", "description": "A tag that doesn't even think about escaping issues", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "escape_explicit", "data": "def escape_explicit(context):\n\t\"\"\"A tag that uses escape explicitly\"\"\"\n\treturn escape(\"Hello {0}!\".format(context['name']))\n\n", "description": "A tag that uses escape explicitly", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "escape_format_html", "data": "def escape_format_html(context):\n\t\"\"\"A tag that uses format_html\"\"\"\n\treturn format_html(\"Hello {0}!\", context['name'])\n\n", "description": "A tag that uses format_html", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "current_app", "data": "def current_app(context):\n\treturn \"%s\" % context.current_app\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "use_l10n", "data": "def use_l10n(context):\n\treturn \"%s\" % context.use_l10n\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "minustwo_overridden_name", "data": "def minustwo_overridden_name(value):\n\treturn value - 2\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "counter", "data": "def counter(parser, token):\n\treturn CounterNode()\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "class", "name": "CounterNode", "data": "class CounterNode(template.Node):\n\tdef __init__(self):\n\t\tself.count = 0\n\n\tdef render(self, context):\n\t\tcount = self.count\n\t\tself.count = count + 1\n\t\treturn count\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}], [], [], [{"term": "class", "name": "classTestLibraryInfo:", "data": "class TestLibraryInfo:\n\tdef test_simple(self):\n\t\twith temppath('foo.ini') as path:\n\t\t\twith open(path,  'w') as f:\n\t\t\t\tf.write(simple)\n\t\t\tpkg = os.path.splitext(path)[0]\n\t\t\tout = read_config(pkg)\n\n\t\tassert_(out.cflags() == simple_d['cflags'])\n\t\tassert_(out.libs() == simple_d['libflags'])\n\t\tassert_(out.name == simple_d['name'])\n\t\tassert_(out.version == simple_d['version'])\n\n\tdef test_simple_variable(self):\n\t\twith temppath('foo.ini') as path:\n\t\t\twith open(path,  'w') as f:\n\t\t\t\tf.write(simple_variable)\n\t\t\tpkg = os.path.splitext(path)[0]\n\t\t\tout = read_config(pkg)\n\n\t\tassert_(out.cflags() == simple_variable_d['cflags'])\n\t\tassert_(out.libs() == simple_variable_d['libflags'])\n\t\tassert_(out.name == simple_variable_d['name'])\n\t\tassert_(out.version == simple_variable_d['version'])\n\t\tout.vars['prefix'] = '/Users/david'\n\t\tassert_(out.cflags() == '-I/Users/david/include')\n", "description": null, "category": "simple", "imports": ["import os", "from numpy.distutils.npy_pkg_config import read_config, parse_flags", "from numpy.testing import temppath, assert_"]}, {"term": "class", "name": "classTestParseFlags:", "data": "class TestParseFlags:\n\tdef test_simple_cflags(self):\n\t\td = parse_flags(\"-I/usr/include\")\n\t\tassert_(d['include_dirs'] == ['/usr/include'])\n\n\t\td = parse_flags(\"-I/usr/include -DFOO\")\n\t\tassert_(d['include_dirs'] == ['/usr/include'])\n\t\tassert_(d['macros'] == ['FOO'])\n\n\t\td = parse_flags(\"-I /usr/include -DFOO\")\n\t\tassert_(d['include_dirs'] == ['/usr/include'])\n\t\tassert_(d['macros'] == ['FOO'])\n\n\tdef test_simple_lflags(self):\n\t\td = parse_flags(\"-L/usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tassert_(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tassert_(d['libraries'] == ['foo', 'bar'])\n\n\t\td = parse_flags(\"-L /usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tassert_(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tassert_(d['libraries'] == ['foo', 'bar'])\n", "description": null, "category": "simple", "imports": ["import os", "from numpy.distutils.npy_pkg_config import read_config, parse_flags", "from numpy.testing import temppath, assert_"]}], [{"term": "class", "name": "TestLibraryInfo", "data": "class TestLibraryInfo(object):\n\tdef test_simple(self):\n\t\twith temppath('foo.ini') as path:\n\t\t\twith open(path,  'w') as f:\n\t\t\t\tf.write(simple)\n\t\t\tpkg = os.path.splitext(path)[0]\n\t\t\tout = read_config(pkg)\n\n\t\tassert_(out.cflags() == simple_d['cflags'])\n\t\tassert_(out.libs() == simple_d['libflags'])\n\t\tassert_(out.name == simple_d['name'])\n\t\tassert_(out.version == simple_d['version'])\n\n\tdef test_simple_variable(self):\n\t\twith temppath('foo.ini') as path:\n\t\t\twith open(path,  'w') as f:\n\t\t\t\tf.write(simple_variable)\n\t\t\tpkg = os.path.splitext(path)[0]\n\t\t\tout = read_config(pkg)\n\n\t\tassert_(out.cflags() == simple_variable_d['cflags'])\n\t\tassert_(out.libs() == simple_variable_d['libflags'])\n\t\tassert_(out.name == simple_variable_d['name'])\n\t\tassert_(out.version == simple_variable_d['version'])\n\t\tout.vars['prefix'] = '/Users/david'\n\t\tassert_(out.cflags() == '-I/Users/david/include')\n", "description": null, "category": "simple", "imports": ["from __future__ import division, absolute_import, print_function", "import os", "from numpy.distutils.npy_pkg_config import read_config, parse_flags", "from numpy.testing import temppath, assert_"]}, {"term": "class", "name": "TestParseFlags", "data": "class TestParseFlags(object):\n\tdef test_simple_cflags(self):\n\t\td = parse_flags(\"-I/usr/include\")\n\t\tassert_(d['include_dirs'] == ['/usr/include'])\n\n\t\td = parse_flags(\"-I/usr/include -DFOO\")\n\t\tassert_(d['include_dirs'] == ['/usr/include'])\n\t\tassert_(d['macros'] == ['FOO'])\n\n\t\td = parse_flags(\"-I /usr/include -DFOO\")\n\t\tassert_(d['include_dirs'] == ['/usr/include'])\n\t\tassert_(d['macros'] == ['FOO'])\n\n\tdef test_simple_lflags(self):\n\t\td = parse_flags(\"-L/usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tassert_(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tassert_(d['libraries'] == ['foo', 'bar'])\n\n\t\td = parse_flags(\"-L /usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tassert_(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tassert_(d['libraries'] == ['foo', 'bar'])\n", "description": null, "category": "simple", "imports": ["from __future__ import division, absolute_import, print_function", "import os", "from numpy.distutils.npy_pkg_config import read_config, parse_flags", "from numpy.testing import temppath, assert_"]}], [{"term": "def", "name": "simple", "data": "def simple():\n\tprint('simple:', a + b)\n\n", "description": null, "category": "simple", "imports": []}, {"term": "def", "name": "simple", "data": "def simple():\n\t# \u041b\u043e\u043a\u0430\u043b\u044c\u043d\u043e\u0435 \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u043e \u0438\u043c\u0435\u043d  \u0438\u043c\u0435\u043d \u043f\u043e\u044f\u0432\u043b\u044f\u0435\u0442\u0441\u044f \u0432 \u043c\u043e\u043c\u0435\u043d\u0442 \u0432\u044b\u0437\u043e\u0432\u0430 \u0444\u0443\u043d\u043a\u0446\u0438\u0438\n\tc, d = 3, 4\n\tprint('simple:', c + d)\n\n", "description": null, "category": "simple", "imports": []}, {"term": "def", "name": "simple_2", "data": "def simple_2():\n\t# \u041b\u043e\u043a\u0430\u043b\u044c\u043d\u043e\u0435 \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u043e \u0438\u043c\u0435\u043d\n\tx, y = 3, 4\n\tprint('simple_2:', x + y)\n\t# print('simple_2:', c + d)\n", "description": null, "category": "simple", "imports": []}, {"term": "def", "name": "simple", "data": "def simple():\n\t# \u041b\u043e\u043a\u0430\u043b\u044c\u043d\u043e\u0435 \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u043e \u0438\u043c\u0435\u043d\n\ta, b = 3, 4\n\tprint('simple:', a + b)\n\n", "description": null, "category": "simple", "imports": []}, {"term": "def", "name": "simple", "data": "def simple():\n\t# \u041b\u043e\u043a\u0430\u043b\u044c\u043d\u043e\u0435 \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u043e \u0438\u043c\u0435\u043d\n\tb = 4\n\tprint('simple:', a + b)\n\n", "description": null, "category": "simple", "imports": []}, {"term": "def", "name": "simple", "data": "def simple():\n\t# \u041b\u043e\u043a\u0430\u043b\u044c\u043d\u043e\u0435 \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u043e \u0438\u043c\u0435\u043d\n\tprint('simple:', a + b)\n\ta = 9\n\tprint('simple:', a + b)\n\n", "description": null, "category": "simple", "imports": []}, {"term": "def", "name": "simple_3", "data": "def simple_3(a, b):\n\tprint('simple:', a + b)\n\n", "description": null, "category": "simple", "imports": []}], [], [{"term": "class", "name": "SimpleArray", "data": "class SimpleArray(tuple):\n\n\tdef _op(self, op, other):\n\t\tdef _o2(x, y):\n\t\t\ttry:\n\t\t\t\treturn op(x, y)\n\t\t\texcept ZeroDivisionError:\n\t\t\t\treturn DataError('#DIV/0', traceback.format_exc())\n\t\t\texcept Exception:\n\t\t\t\treturn DataError('#ERR', traceback.format_exc())\n\n\t\tif isinstance(other, tuple):\n\t\t\tif len(other) != len(self):\n\t\t\t\traise TypeError(\"tuples must have same length for %s\" % op)\n\t\t\treturn self.__class__(map(_o2, self, other))\n\t\telse:\n\t\t\treturn self.__class__(_o2(z, other) for z in self)\n\n\tdef _cast(self, other):\n\t\tif isinstance(other, self.__class__):\n\t\t\treturn other\n\t\telif isinstance(other, tuple):\n\t\t\treturn self.__class__(other)\n\t\telse:\n\t\t\t# other is a scalar\n\t\t\treturn self.__class__(itertools.repeat(other, len(self)))\n\n\tdef __add__(self, other):\n\t\treturn self._op(operator.add, other)\n\n\t__radd__ = __add__\n\n\tdef __pos__(self):\n\t\treturn self.__class__(map(operator.pos, self))\n\n\tdef __neg__(self):\n\t\treturn self.__class__(map(operator.neg, self))\n\n\tdef __sub__(self, other):\n\t\treturn self._op(operator.sub, other)\n\n\tdef __rsub__(self, other):\n\t\treturn self._cast(other)._op(operator.sub, self)\n\n\tdef __mul__(self, other):\n\t\treturn self._op(operator.mul, other)\n\n\t__rmul__ = __mul__\n\n\tdef __div__(self, other):\n\t\treturn self._op(operator.div, other)\n\n\tdef __floordiv__(self, other):\n\t\treturn self._op(operator.floordiv, other)\n\n\tdef __truediv__(self, other):\n\t\treturn self._op(operator.truediv, other)\n\n\tdef __rdiv__(self, other):\n\t\treturn self._cast(other)._op(operator.div, self)\n\n\tdef __rfloordiv__(self, other):\n\t\treturn self._cast(other)._op(operator.floordiv, self)\n\n\tdef __rtruediv__(self, other):\n\t\treturn self._cast(other)._op(operator.truediv, self)\n\n\tdef __repr__(self):\n\t\treturn \"%s(%s)\" % (self.__class__.__name__, tuple.__repr__(self))\n\n", "description": null, "category": "simple", "imports": ["import itertools", "import operator", "import traceback", "from .data_error import DataError", "\timport doctest"]}, {"term": "def", "name": "named_simple_array", "data": "def named_simple_array(typename, field_names):\n\t\"\"\" Return a subclass of SimpleArray, with named properties.\n\n\tThis method is to SimpleArray what namedtuple is to tuple.\n\tIt's less sophisticated than namedtuple so some namedtuple\n\tadvanced use cases may not work, but it's good enough for\n\tour needs in mis_builder, ie referring to subkpi values\n\tby name.\n\t\"\"\"\n\tprops = dict(\n\t\t(field_name, property(operator.itemgetter(i)))\n\t\tfor i, field_name in enumerate(field_names)\n\t)\n\treturn type(typename, (SimpleArray, ), props)\n\n", "description": " Return a subclass of SimpleArray, with named properties.\n\n\tThis method is to SimpleArray what namedtuple is to tuple.\n\tIt's less sophisticated than namedtuple so some namedtuple\n\tadvanced use cases may not work, but it's good enough for\n\tour needs in mis_builder, ie referring to subkpi values\n\tby name.\n\t", "category": "simple", "imports": ["import itertools", "import operator", "import traceback", "from .data_error import DataError", "\timport doctest"]}], [{"term": "def", "name": "fswig_import_helper", "data": "\tdef swig_import_helper():\n\t\timport importlib\n\t\tpkg = __name__.rpartition('.')[0]\n\t\tmname = '.'.join((pkg, '_param_SimpleTrace')).lstrip('.')\n\t\ttry:\n\t\t\treturn importlib.import_module(mname)\n\t\texcept ImportError:\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleTrace')", "\t_param_SimpleTrace = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleTrace", "\t_param_SimpleTrace = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleTrace", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_ProbeListenerObject", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize"]}, {"term": "def", "name": "fswig_import_helper", "data": "\tdef swig_import_helper():\n\t\tfrom os.path import dirname\n\t\timport imp\n\t\tfp = None\n\t\ttry:\n\t\t\tfp, pathname, description = imp.find_module('_param_SimpleTrace', [dirname(__file__)])\n\t\texcept ImportError:\n\t\t\timport _param_SimpleTrace\n\t\t\treturn _param_SimpleTrace\n\t\ttry:\n\t\t\t_mod = imp.load_module('_param_SimpleTrace', fp, pathname, description)\n\t\tfinally:\n\t\t\tif fp is not None:\n\t\t\t\tfp.close()\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleTrace')", "\t_param_SimpleTrace = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleTrace", "\t_param_SimpleTrace = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleTrace", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_ProbeListenerObject", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize"]}, {"term": "def", "name": "_swig_setattr_nondynamic", "data": "def _swig_setattr_nondynamic(self, class_type, name, value, static=1):\n\tif (name == \"thisown\"):\n\t\treturn self.this.own(value)\n\tif (name == \"this\"):\n\t\tif type(value).__name__ == 'SwigPyObject':\n\t\t\tself.__dict__[name] = value\n\t\t\treturn\n\tmethod = class_type.__swig_setmethods__.get(name, None)\n\tif method:\n\t\treturn method(self, value)\n\tif (not static):\n\t\tobject.__setattr__(self, name, value)\n\telse:\n\t\traise AttributeError(\"You cannot add attributes to %s\" % self)\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleTrace')", "\t_param_SimpleTrace = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleTrace", "\t_param_SimpleTrace = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleTrace", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_ProbeListenerObject", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize"]}, {"term": "def", "name": "_swig_setattr", "data": "def _swig_setattr(self, class_type, name, value):\n\treturn _swig_setattr_nondynamic(self, class_type, name, value, 0)\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleTrace')", "\t_param_SimpleTrace = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleTrace", "\t_param_SimpleTrace = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleTrace", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_ProbeListenerObject", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize"]}, {"term": "def", "name": "_swig_getattr", "data": "def _swig_getattr(self, class_type, name):\n\tif (name == \"thisown\"):\n\t\treturn self.this.own()\n\tmethod = class_type.__swig_getmethods__.get(name, None)\n\tif method:\n\t\treturn method(self)\n\traise AttributeError(\"'%s' object has no attribute '%s'\" % (class_type.__name__, name))\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleTrace')", "\t_param_SimpleTrace = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleTrace", "\t_param_SimpleTrace = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleTrace", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_ProbeListenerObject", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize"]}, {"term": "def", "name": "_swig_repr", "data": "def _swig_repr(self):\n\ttry:\n\t\tstrthis = \"proxy of \" + self.this.__repr__()\n\texcept __builtin__.Exception:\n\t\tstrthis = \"\"\n\treturn \"<%s.%s; %s >\" % (self.__class__.__module__, self.__class__.__name__, strthis,)\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleTrace')", "\t_param_SimpleTrace = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleTrace", "\t_param_SimpleTrace = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleTrace", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_ProbeListenerObject", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize"]}, {"term": "def", "name": "_swig_setattr_nondynamic_method", "data": "def _swig_setattr_nondynamic_method(set):\n\tdef set_attr(self, name, value):\n\t\tif (name == \"thisown\"):\n\t\t\treturn self.this.own(value)\n\t\tif hasattr(self, name) or (name == \"this\"):\n\t\t\tset(self, name, value)\n\t\telse:\n\t\t\traise AttributeError(\"You cannot add attributes to %s\" % self)\n\treturn set_attr\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleTrace')", "\t_param_SimpleTrace = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleTrace", "\t_param_SimpleTrace = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleTrace", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_ProbeListenerObject", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize"]}, {"term": "class", "name": "SimpleTrace", "data": "class SimpleTrace(m5.internal.param_ProbeListenerObject.ProbeListenerObject):\n\tthisown = _swig_property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc='The membership flag')\n\n\tdef __init__(self, *args, **kwargs):\n\t\traise AttributeError(\"No constructor defined - class is abstract\")\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleTrace')", "\t_param_SimpleTrace = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleTrace", "\t_param_SimpleTrace = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleTrace", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_ProbeListenerObject", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize"]}, {"term": "class", "name": "SimpleTraceParams", "data": "class SimpleTraceParams(m5.internal.param_ProbeListenerObject.ProbeListenerObjectParams):\n\tthisown = _swig_property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc='The membership flag')\n\t__repr__ = _swig_repr\n\n\tdef create(self):\n\t\treturn _param_SimpleTrace.SimpleTraceParams_create(self)\n\n\tdef __init__(self):\n\t\tthis = _param_SimpleTrace.new_SimpleTraceParams()\n\t\ttry:\n\t\t\tself.this.append(this)\n\t\texcept __builtin__.Exception:\n\t\t\tself.this = this\n\t__swig_destroy__ = _param_SimpleTrace.delete_SimpleTraceParams\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleTrace')", "\t_param_SimpleTrace = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleTrace", "\t_param_SimpleTrace = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleTrace", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_ProbeListenerObject", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize"]}], [{"term": "class", "name": "SimpleFlow", "data": "class SimpleFlow(ABC):\n\n\t@abstractmethod\n\tdef input(self, x):\n\t\tpass\n\n\t@abstractmethod\n\tdef output(self, x):\n\t\tpass\n\n\t@abstractmethod\n\tdef get_program_spec(self):\n\t\tpass\n\n\t@abstractmethod\n\tdef get_next_param(self):\n\t\tpass\n\n\t@abstractmethod\n\tdef get_name(self):\n\t\tpass\n\n", "description": null, "category": "simple", "imports": ["from abc import ABC, abstractmethod", "import random", "import string", "import re", "import hashlib"]}, {"term": "class", "name": "classSimpleFlow1:", "data": "class SimpleFlow1:\n\n\tdef __init__(self):\n\t\tself.program_spec = \"name: c1c2c3 => person: c1c2c3\"\n\t\tself.name = \"simple_flow1\"\n\n\tdef input(self, x):\n\t\treturn f\"name: {x}\"\n\n\tdef output(self, x):\n\t\treturn f\"person: {x}\"\n\n\tdef get_program_spec(self):\n\t\treturn self.program_spec\n\n\tdef get_next_param(self):\n\t\treturn random_string_generator(3)\n\n\tdef get_name(self):\n\t\treturn self.name\n\n", "description": null, "category": "simple", "imports": ["from abc import ABC, abstractmethod", "import random", "import string", "import re", "import hashlib"]}, {"term": "class", "name": "classSimpleFlow2:", "data": "class SimpleFlow2:\n\n\tdef __init__(self):\n\t\tself.program_spec = \"person: c1c2c3 => SELECT * FROM db WHERE user = c1c2c3\"\n\t\tself.name = \"simple_flow2\"\n\n\tdef input(self, x):\n\t\treturn f\"person: {x}\"\n\n\tdef output(self, x):\n\t\treturn f\"SELECT * FROM db WHERE user = {x}\"\n\n\tdef get_program_spec(self):\n\t\treturn self.program_spec\n\n\tdef get_next_param(self):\n\t\treturn random_string_generator(3)\n\n\tdef get_name(self):\n\t\treturn self.name\n\n", "description": null, "category": "simple", "imports": ["from abc import ABC, abstractmethod", "import random", "import string", "import re", "import hashlib"]}, {"term": "class", "name": "classSimpleFlow3:", "data": "class SimpleFlow3:\n\n\tdef __init__(self):\n\t\tself.long_string = random_string_generator(1233)\n\t\tself.program_spec = \"person: c1c2c3 => [if special_char in c1c2c3 'failed' else 'success']\"\n\t\tself.name = \"simple_flow3\"\n\n\tdef input(self, x):\n\t\treturn f\"person: {x}\"\n\n\tdef output(self, x):\n\t\treturn \"failed_\" if contains_special_chars(x) else \"success\"\n\n\tdef get_program_spec(self):\n\t\treturn self.program_spec\n\n\tdef get_next_param(self):\n\t\treturn random_string_generator(3)\n\n\tdef get_name(self):\n\t\treturn self.name\n\n", "description": null, "category": "simple", "imports": ["from abc import ABC, abstractmethod", "import random", "import string", "import re", "import hashlib"]}, {"term": "class", "name": "classSimpleHashFlow:", "data": "class SimpleHashFlow:\n\tdef __init__(self):\n\t\tself.program_spec = \"name: c1c2c3 => person: sha1hash\"\n\t\tself.name = \"simplehashflow\"\n\n\tdef input(self, x):\n\t\treturn f\"name: {x}\"\n\n\tdef output(self, x):\n\t\treturn f\"person: {hashlib.sha1(x.encode('utf-8')).hexdigest()}\"\n\n\tdef get_program_spec(self):\n\t\treturn self.program_spec\n\n\tdef get_next_param(self):\n\t\treturn random_string_generator(3)\n\n\tdef get_name(self):\n\t\treturn self.name\n\n", "description": null, "category": "simple", "imports": ["from abc import ABC, abstractmethod", "import random", "import string", "import re", "import hashlib"]}, {"term": "class", "name": "classSimpleLogicFlow:", "data": "class SimpleLogicFlow:\n\tdef __init__(self):\n\t\tself.program_spec = \"age: x name: {random string} => [if x > 1900 && x < 2020 'ok' else 'not ok'] (x is a 4-digit number)\"\n\t\tself.name = \"simplelogicflow\"\n\n\tdef input(self, x):\n\t\treturn f\"age: {x} name: {random_string_generator(4)}\"\n\n\tdef output(self, x):\n\t\treturn \"ok\" if x > 1900 and x < 2020 else \"not ok\"\n\n\tdef get_program_spec(self):\n\t\treturn self.program_spec\n\n\tdef get_next_param(self):\n\t\treturn random.randint(1000, 3000)\n\n\tdef get_name(self):\n\t\treturn self.name\n\n", "description": null, "category": "simple", "imports": ["from abc import ABC, abstractmethod", "import random", "import string", "import re", "import hashlib"]}, {"term": "class", "name": "classChainedSimpleFlow:", "data": "class ChainedSimpleFlow:\n\n\tdef __init__(self, simple_flows):\n\t\tself.simple_flows = simple_flows\n\t\tself.name = \"chained_flow\"\n\n\tdef input(self, x):\n\t\treturn self.simple_flows[0].input(x)\n\n\tdef output(self, x):\n\t\treturn self.simple_flows[-1].output(x)\n\n\tdef get_program_spec(self):\n\t\treturn \"\"\n\n\tdef get_next_param(self):\n\t\treturn self.simple_flows[0].get_next_param()\n\n\tdef get_name(self):\n\t\treturn self.name\n\n", "description": null, "category": "simple", "imports": ["from abc import ABC, abstractmethod", "import random", "import string", "import re", "import hashlib"]}, {"term": "def", "name": "random_string_generator", "data": "def random_string_generator(bytes_length, letters_only=False):\n\tif letters_only:\n\t\treturn ''.join(\n\t\t\t[random.choice(string.ascii_letters) for _ in\n\t\t\t range(0, bytes_length)])\n\treturn ''.join([random.choice(string.ascii_letters + string.punctuation) for _ in\n\t\t\t range(0, bytes_length)])\n\n", "description": null, "category": "simple", "imports": ["from abc import ABC, abstractmethod", "import random", "import string", "import re", "import hashlib"]}, {"term": "def", "name": "contains_special_chars", "data": "def contains_special_chars(s):\n\t# this as argument in compile method\n\tregex = re.compile('[@_!#$%^&*()<>?/\\|}{~:]')\n\t# Pass the string in search\n\t# method of regex object.\n\tif (regex.search(s) == None):\n\t\treturn False\n\treturn True\n\n", "description": null, "category": "simple", "imports": ["from abc import ABC, abstractmethod", "import random", "import string", "import re", "import hashlib"]}], [{"term": "class", "name": "SimpleTest", "data": "class SimpleTest(TestCase):\n\tdef test_liveness(self):\n\t\tresponse = self.client.get('/liveness/')\n\t\tself.assertContains(response, b'ok')\n\n\tdef test_readiness(self):\n\t\tresponse = self.client.get('/readiness/')\n\t\tself.assertContains(response, b'ok')\n\n\t@override_settings(SIMPLE_HEALTH_CHECKS={'simple_health_check.checks.dummy.DummyFalse': None})\n\tdef test_no_readiness(self):\n\t\tresponse = self.client.get('/readiness/')\n\t\tself.assertContains(response, b'down', status_code=503)\n\n\t@override_settings(\n\t\tSIMPLE_HEALTH_CHECK_ERROR_CODE=500,\n\t\tSIMPLE_HEALTH_CHECKS={'simple_health_check.checks.dummy.DummyFalse': None},\n\t)\n\tdef test_other_error_code(self):\n\t\tresponse = self.client.get('/readiness/')\n\t\tself.assertContains(response, b'down', status_code=500)\n\n\t@override_settings(\n\t\tCACHES={\n\t\t\t'default': {'BACKEND': 'django.core.cache.backends.locmem.LocMemCache'},\n\t\t},\n\t\tSIMPLE_HEALTH_CHECKS={'simple_health_check.checks.caches.CacheBackends': None},\n\t)\n\tdef test_caches(self):\n\t\tresponse = self.client.get('/readiness/')\n\t\tself.assertContains(response, b'ok')\n\n\t@override_settings(\n\t\tCACHES={\n\t\t\t'default': {'BACKEND': 'django.core.cache.backends.locmem.LocMemCache'},\n\t\t\t'c2': {'BACKEND': 'django.core.cache.backends.locmem.LocMemCache'},\n\t\t},\n\t\tSIMPLE_HEALTH_CHECKS={\n\t\t\t'simple_health_check.checks.caches.CacheBackends': [\n\t\t\t\tdict(alias='default'),\n\t\t\t\tdict(alias='c2'),\n\t\t\t],\n\t\t},\n\t)\n\tdef test_cache_aliases(self):\n\t\tresponse = self.client.get('/readiness/')\n\t\tself.assertContains(response, b'ok')\n\n\t@override_settings(\n\t\tCACHES={\n\t\t\t'default': {'BACKEND': 'django.core.cache.backends.locmem.LocMemCache'},\n\t\t},\n\t\tSIMPLE_HEALTH_CHECKS={\n\t\t\t'simple_health_check.checks.caches.CacheBackends': [\n\t\t\t\tdict(alias='default'),\n\t\t\t\tdict(alias='c2'),\n\t\t\t],\n\t\t},\n\t)\n\tdef test_cache_no_rediness(self):\n\t\tresponse = self.client.get('/readiness/')\n\t\tself.assertContains(response, b'down', status_code=503)\n\n\t@override_settings(\n\t\tSIMPLE_HEALTH_CHECKS={\n\t\t\t'simple_health_check.checks.ps.DiskUsage': None,\n\t\t},\n\t)\n\tdef test_ps_disk_usage_no_value(self):\n\t\tresponse = self.client.get('/readiness/')\n\t\tself.assertContains(response, b'ok')\n\n\t@override_settings(\n\t\tSIMPLE_HEALTH_CHECKS={\n\t\t\t'simple_health_check.checks.ps.DiskUsage': dict(max_usage_percent=99),\n\t\t},\n\t)\n\tdef test_ps_disk_usage(self):\n\t\tresponse = self.client.get('/readiness/')\n\t\tself.assertContains(response, b'ok')\n\n\t@override_settings(\n\t\tSIMPLE_HEALTH_CHECKS={\n\t\t\t'simple_health_check.checks.ps.DiskUsage': dict(max_usage_percent=0.001),\n\t\t},\n\t)\n\tdef test_ps_disk_usage_no_rediness(self):\n\t\tresponse = self.client.get('/readiness/')\n\t\tself.assertContains(response, b'down', status_code=503)\n\n\t@override_settings(\n\t\tSIMPLE_HEALTH_CHECKS={\n\t\t\t'simple_health_check.checks.ps.MemoryUsage': None,\n\t\t},\n\t)\n\tdef test_ps_memory_usage_no_value(self):\n\t\tresponse = self.client.get('/readiness/')\n\t\tself.assertContains(response, b'ok')\n\n\t@override_settings(\n\t\tSIMPLE_HEALTH_CHECKS={\n\t\t\t'simple_health_check.checks.ps.MemoryUsage': dict(min_memory_mb=10),\n\t\t},\n\t)\n\tdef test_ps_memory_usage(self):\n\t\tresponse = self.client.get('/readiness/')\n\t\tself.assertContains(response, b'ok')\n\n\t@override_settings(\n\t\tSIMPLE_HEALTH_CHECKS={\n\t\t\t'simple_health_check.checks.ps.MemoryUsage': dict(min_memory_mb=100_000),\n\t\t},\n\t)\n\tdef test_ps_memory_usage_no_rediness(self):\n\t\tresponse = self.client.get('/readiness/')\n\t\tself.assertContains(response, b'down', status_code=503)\n", "description": null, "category": "simple", "imports": ["from django.test import TestCase, override_settings"]}], [{"term": "class", "name": "#thetestsoftheOptionclassareextensiveaboutthis.", "data": "# the tests of the Option class are extensive about this.\n", "description": null, "category": "simple", "imports": ["# Sandboxed functions can import from modules through the use of the @imports", "# The order of the decorators matter: @imports needs to appear after other", "option('--with-imports', nargs='?', help='Imports')", "@depends('--with-imports')", "def with_imports(value):", "set_config('HAS_ABSPATH', with_imports)", "# It is still possible to import the full set from os.path.", "@depends('--with-imports')", "@imports('os.path')", "def with_imports(value):", "set_config('HAS_GETATIME', with_imports)", "@depends('--with-imports')", "def with_imports(value):", "set_config('HAS_GETATIME2', with_imports)"]}, {"term": "def", "name": "simple", "data": "def simple(simple):\n\tif simple:\n\t\treturn simple\n", "description": null, "category": "simple", "imports": ["# Sandboxed functions can import from modules through the use of the @imports", "# The order of the decorators matter: @imports needs to appear after other", "option('--with-imports', nargs='?', help='Imports')", "@depends('--with-imports')", "def with_imports(value):", "set_config('HAS_ABSPATH', with_imports)", "# It is still possible to import the full set from os.path.", "@depends('--with-imports')", "@imports('os.path')", "def with_imports(value):", "set_config('HAS_GETATIME', with_imports)", "@depends('--with-imports')", "def with_imports(value):", "set_config('HAS_GETATIME2', with_imports)"]}, {"term": "def", "name": "simple", "data": "def simple(simple):\n\treturn simple\n", "description": null, "category": "simple", "imports": ["# Sandboxed functions can import from modules through the use of the @imports", "# The order of the decorators matter: @imports needs to appear after other", "option('--with-imports', nargs='?', help='Imports')", "@depends('--with-imports')", "def with_imports(value):", "set_config('HAS_ABSPATH', with_imports)", "# It is still possible to import the full set from os.path.", "@depends('--with-imports')", "@imports('os.path')", "def with_imports(value):", "set_config('HAS_GETATIME', with_imports)", "@depends('--with-imports')", "def with_imports(value):", "set_config('HAS_GETATIME2', with_imports)"]}, {"term": "def", "name": "with_env", "data": "def with_env(with_env):\n\treturn with_env\n", "description": null, "category": "simple", "imports": ["# Sandboxed functions can import from modules through the use of the @imports", "# The order of the decorators matter: @imports needs to appear after other", "option('--with-imports', nargs='?', help='Imports')", "@depends('--with-imports')", "def with_imports(value):", "set_config('HAS_ABSPATH', with_imports)", "# It is still possible to import the full set from os.path.", "@depends('--with-imports')", "@imports('os.path')", "def with_imports(value):", "set_config('HAS_GETATIME', with_imports)", "@depends('--with-imports')", "def with_imports(value):", "set_config('HAS_GETATIME2', with_imports)"]}, {"term": "def", "name": "with_env2", "data": "def with_env2(values):\n\treturn values\n", "description": null, "category": "simple", "imports": ["# Sandboxed functions can import from modules through the use of the @imports", "# The order of the decorators matter: @imports needs to appear after other", "option('--with-imports', nargs='?', help='Imports')", "@depends('--with-imports')", "def with_imports(value):", "set_config('HAS_ABSPATH', with_imports)", "# It is still possible to import the full set from os.path.", "@depends('--with-imports')", "@imports('os.path')", "def with_imports(value):", "set_config('HAS_GETATIME', with_imports)", "@depends('--with-imports')", "def with_imports(value):", "set_config('HAS_GETATIME2', with_imports)"]}, {"term": "def", "name": "is_gcc", "data": "def is_gcc(cc):\n\treturn cc and 'gcc' in cc[0]\n", "description": null, "category": "simple", "imports": ["# Sandboxed functions can import from modules through the use of the @imports", "# The order of the decorators matter: @imports needs to appear after other", "option('--with-imports', nargs='?', help='Imports')", "@depends('--with-imports')", "def with_imports(value):", "set_config('HAS_ABSPATH', with_imports)", "# It is still possible to import the full set from os.path.", "@depends('--with-imports')", "@imports('os.path')", "def with_imports(value):", "set_config('HAS_GETATIME', with_imports)", "@depends('--with-imports')", "def with_imports(value):", "set_config('HAS_GETATIME2', with_imports)"]}, {"term": "def", "name": "with_env3", "data": "def with_env3(values):\n\treturn values\n", "description": null, "category": "simple", "imports": ["# Sandboxed functions can import from modules through the use of the @imports", "# The order of the decorators matter: @imports needs to appear after other", "option('--with-imports', nargs='?', help='Imports')", "@depends('--with-imports')", "def with_imports(value):", "set_config('HAS_ABSPATH', with_imports)", "# It is still possible to import the full set from os.path.", "@depends('--with-imports')", "@imports('os.path')", "def with_imports(value):", "set_config('HAS_GETATIME', with_imports)", "@depends('--with-imports')", "def with_imports(value):", "set_config('HAS_GETATIME2', with_imports)"]}, {"term": "def", "name": "with_env4", "data": "def with_env4(values):\n\treturn values\n", "description": null, "category": "simple", "imports": ["# Sandboxed functions can import from modules through the use of the @imports", "# The order of the decorators matter: @imports needs to appear after other", "option('--with-imports', nargs='?', help='Imports')", "@depends('--with-imports')", "def with_imports(value):", "set_config('HAS_ABSPATH', with_imports)", "# It is still possible to import the full set from os.path.", "@depends('--with-imports')", "@imports('os.path')", "def with_imports(value):", "set_config('HAS_GETATIME', with_imports)", "@depends('--with-imports')", "def with_imports(value):", "set_config('HAS_GETATIME2', with_imports)"]}, {"term": "def", "name": "with_env5", "data": "def with_env5(values):\n\treturn values\n", "description": null, "category": "simple", "imports": ["# Sandboxed functions can import from modules through the use of the @imports", "# The order of the decorators matter: @imports needs to appear after other", "option('--with-imports', nargs='?', help='Imports')", "@depends('--with-imports')", "def with_imports(value):", "set_config('HAS_ABSPATH', with_imports)", "# It is still possible to import the full set from os.path.", "@depends('--with-imports')", "@imports('os.path')", "def with_imports(value):", "set_config('HAS_GETATIME', with_imports)", "@depends('--with-imports')", "def with_imports(value):", "set_config('HAS_GETATIME2', with_imports)"]}, {"term": "def", "name": "simple", "data": "def simple(simple, help):\n\treturn 'simple' if simple else 'not-simple'\n", "description": null, "category": "simple", "imports": ["# Sandboxed functions can import from modules through the use of the @imports", "# The order of the decorators matter: @imports needs to appear after other", "option('--with-imports', nargs='?', help='Imports')", "@depends('--with-imports')", "def with_imports(value):", "set_config('HAS_ABSPATH', with_imports)", "# It is still possible to import the full set from os.path.", "@depends('--with-imports')", "@imports('os.path')", "def with_imports(value):", "set_config('HAS_GETATIME', with_imports)", "@depends('--with-imports')", "def with_imports(value):", "set_config('HAS_GETATIME2', with_imports)"]}, {"term": "def", "name": "default", "data": "def default(value):\n\treturn value\n", "description": null, "category": "simple", "imports": ["# Sandboxed functions can import from modules through the use of the @imports", "# The order of the decorators matter: @imports needs to appear after other", "option('--with-imports', nargs='?', help='Imports')", "@depends('--with-imports')", "def with_imports(value):", "set_config('HAS_ABSPATH', with_imports)", "# It is still possible to import the full set from os.path.", "@depends('--with-imports')", "@imports('os.path')", "def with_imports(value):", "set_config('HAS_GETATIME', with_imports)", "@depends('--with-imports')", "def with_imports(value):", "set_config('HAS_GETATIME2', with_imports)"]}, {"term": "def", "name": "choices", "data": "def choices(values, help):\n\tif len(values):\n\t\treturn {\n\t\t\t'alpha': ('a', 'b', 'c'),\n\t\t\t'numeric': ('0', '1', '2'),\n\t\t}.get(values[0])\n", "description": null, "category": "simple", "imports": ["# Sandboxed functions can import from modules through the use of the @imports", "# The order of the decorators matter: @imports needs to appear after other", "option('--with-imports', nargs='?', help='Imports')", "@depends('--with-imports')", "def with_imports(value):", "set_config('HAS_ABSPATH', with_imports)", "# It is still possible to import the full set from os.path.", "@depends('--with-imports')", "@imports('os.path')", "def with_imports(value):", "set_config('HAS_GETATIME', with_imports)", "@depends('--with-imports')", "def with_imports(value):", "set_config('HAS_GETATIME2', with_imports)"]}, {"term": "def", "name": "returned_choices", "data": "def returned_choices(values):\n\treturn values\n", "description": null, "category": "simple", "imports": ["# Sandboxed functions can import from modules through the use of the @imports", "# The order of the decorators matter: @imports needs to appear after other", "option('--with-imports', nargs='?', help='Imports')", "@depends('--with-imports')", "def with_imports(value):", "set_config('HAS_ABSPATH', with_imports)", "# It is still possible to import the full set from os.path.", "@depends('--with-imports')", "@imports('os.path')", "def with_imports(value):", "set_config('HAS_GETATIME', with_imports)", "@depends('--with-imports')", "def with_imports(value):", "set_config('HAS_GETATIME2', with_imports)"]}, {"term": "def", "name": "remainder", "data": "def remainder(*args):\n\treturn args\n", "description": null, "category": "simple", "imports": ["# Sandboxed functions can import from modules through the use of the @imports", "# The order of the decorators matter: @imports needs to appear after other", "option('--with-imports', nargs='?', help='Imports')", "@depends('--with-imports')", "def with_imports(value):", "set_config('HAS_ABSPATH', with_imports)", "# It is still possible to import the full set from os.path.", "@depends('--with-imports')", "@imports('os.path')", "def with_imports(value):", "set_config('HAS_GETATIME', with_imports)", "@depends('--with-imports')", "def with_imports(value):", "set_config('HAS_GETATIME2', with_imports)"]}, {"term": "def", "name": "include_path", "data": "def include_path(path, help):\n\treturn path[0] if path else None\n", "description": null, "category": "simple", "imports": ["# Sandboxed functions can import from modules through the use of the @imports", "# The order of the decorators matter: @imports needs to appear after other", "option('--with-imports', nargs='?', help='Imports')", "@depends('--with-imports')", "def with_imports(value):", "set_config('HAS_ABSPATH', with_imports)", "# It is still possible to import the full set from os.path.", "@depends('--with-imports')", "@imports('os.path')", "def with_imports(value):", "set_config('HAS_GETATIME', with_imports)", "@depends('--with-imports')", "def with_imports(value):", "set_config('HAS_GETATIME2', with_imports)"]}, {"term": "def", "name": "with_imports", "data": "def with_imports(value):\n\tif len(value):\n\t\treturn hasattr(os.path, 'abspath')\n", "description": null, "category": "simple", "imports": ["# Sandboxed functions can import from modules through the use of the @imports", "# The order of the decorators matter: @imports needs to appear after other", "option('--with-imports', nargs='?', help='Imports')", "@depends('--with-imports')", "def with_imports(value):", "set_config('HAS_ABSPATH', with_imports)", "# It is still possible to import the full set from os.path.", "@depends('--with-imports')", "@imports('os.path')", "def with_imports(value):", "set_config('HAS_GETATIME', with_imports)", "@depends('--with-imports')", "def with_imports(value):", "set_config('HAS_GETATIME2', with_imports)"]}, {"term": "def", "name": "with_imports", "data": "def with_imports(value):\n\tif len(value):\n\t\treturn hasattr(os.path, 'getatime')\n", "description": null, "category": "simple", "imports": ["# Sandboxed functions can import from modules through the use of the @imports", "# The order of the decorators matter: @imports needs to appear after other", "option('--with-imports', nargs='?', help='Imports')", "@depends('--with-imports')", "def with_imports(value):", "set_config('HAS_ABSPATH', with_imports)", "# It is still possible to import the full set from os.path.", "@depends('--with-imports')", "@imports('os.path')", "def with_imports(value):", "set_config('HAS_GETATIME', with_imports)", "@depends('--with-imports')", "def with_imports(value):", "set_config('HAS_GETATIME2', with_imports)"]}, {"term": "def", "name": "with_imports", "data": "def with_imports(value):\n\tif len(value):\n\t\treturn hasattr(os.path, 'getatime')\n", "description": null, "category": "simple", "imports": ["# Sandboxed functions can import from modules through the use of the @imports", "# The order of the decorators matter: @imports needs to appear after other", "option('--with-imports', nargs='?', help='Imports')", "@depends('--with-imports')", "def with_imports(value):", "set_config('HAS_ABSPATH', with_imports)", "# It is still possible to import the full set from os.path.", "@depends('--with-imports')", "@imports('os.path')", "def with_imports(value):", "set_config('HAS_GETATIME', with_imports)", "@depends('--with-imports')", "def with_imports(value):", "set_config('HAS_GETATIME2', with_imports)"]}], [{"term": "class", "name": "GLUnurbs", "data": "class GLUnurbs(glustruct.GLUStruct, simple.GLUnurbs):\n\t\"\"\"GLU Nurbs structure with oor and callback storage support\n\t\n\tIMPORTANT NOTE: the texture coordinate callback receives a raw ctypes \n\tdata-pointer, as without knowing what type of evaluation is being done \n\t(1D or 2D) we cannot safely determine the size of the array to convert \n\tit.  This is a limitation of the C implementation.  To convert to regular \n\tdata-pointer, just call yourNurb.ptrAsArray( ptr, size, arrays.GLfloatArray )\n\twith the size of data you expect.\n\t\"\"\"\n\tFUNCTION_TYPE = PLATFORM.functionTypeFor(PLATFORM.GLU)\n\tCALLBACK_FUNCTION_REGISTRARS = {\n\t\t# mapping from \"which\" to a function that should take 3 parameters,\n\t\t# the nurb, the which and the function pointer...\n\t}\n\tCALLBACK_TYPES = {\n\t\t# mapping from \"which\" GLU enumeration to a ctypes function type\n\t\tsimple.GLU_NURBS_BEGIN: FUNCTION_TYPE( \n\t\t\tNone, simple.GLenum \n\t\t),\n\t\tsimple.GLU_NURBS_BEGIN_DATA: FUNCTION_TYPE( \n\t\t\tNone, simple.GLenum, ctypes.POINTER(simple.GLvoid) \n\t\t),\n\t\tsimple.GLU_NURBS_VERTEX: FUNCTION_TYPE( \n\t\t\tNone, ctypes.POINTER(simple.GLfloat)\n\t\t),\n\t\tsimple.GLU_NURBS_VERTEX_DATA: FUNCTION_TYPE( \n\t\t\tNone, ctypes.POINTER(simple.GLfloat), ctypes.POINTER(simple.GLvoid) \n\t\t),\n\t\tsimple.GLU_NURBS_NORMAL: FUNCTION_TYPE( \n\t\t\tNone, ctypes.POINTER(simple.GLfloat)\n\t\t),\n\t\tsimple.GLU_NURBS_NORMAL_DATA: FUNCTION_TYPE( \n\t\t\tNone, ctypes.POINTER(simple.GLfloat), ctypes.POINTER(simple.GLvoid) \n\t\t),\n\t\tsimple.GLU_NURBS_COLOR: FUNCTION_TYPE( \n\t\t\tNone, ctypes.POINTER(simple.GLfloat)\n\t\t),\n\t\tsimple.GLU_NURBS_COLOR_DATA: FUNCTION_TYPE( \n\t\t\tNone, ctypes.POINTER(simple.GLfloat), ctypes.POINTER(simple.GLvoid) \n\t\t),\n\t\tsimple.GLU_NURBS_TEXTURE_COORD: FUNCTION_TYPE( \n\t\t\tNone, ctypes.POINTER(simple.GLfloat)\n\t\t),\n\t\tsimple.GLU_NURBS_TEXTURE_COORD_DATA: FUNCTION_TYPE( \n\t\t\tNone, ctypes.POINTER(simple.GLfloat), ctypes.POINTER(simple.GLvoid) \n\t\t),\n\t\tsimple.GLU_NURBS_END:FUNCTION_TYPE( \n\t\t\tNone\n\t\t),\n\t\tsimple.GLU_NURBS_END_DATA: FUNCTION_TYPE( \n\t\t\tNone, ctypes.POINTER(simple.GLvoid) \n\t\t),\n\t\tsimple.GLU_NURBS_ERROR:FUNCTION_TYPE( \n\t\t\tNone, simple.GLenum, \n\t\t),\n\t}\n\tWRAPPER_METHODS = {\n\t\tsimple.GLU_NURBS_BEGIN: None,\n\t\tsimple.GLU_NURBS_BEGIN_DATA: '_justOOR',\n\t\tsimple.GLU_NURBS_VERTEX: '_vec3',\n\t\tsimple.GLU_NURBS_VERTEX_DATA: '_vec3',\n\t\tsimple.GLU_NURBS_NORMAL: '_vec3',\n\t\tsimple.GLU_NURBS_NORMAL_DATA: '_vec3',\n\t\tsimple.GLU_NURBS_COLOR: '_vec4',\n\t\tsimple.GLU_NURBS_COLOR_DATA: '_vec4',\n\t\tsimple.GLU_NURBS_TEXTURE_COORD: '_tex',\n\t\tsimple.GLU_NURBS_TEXTURE_COORD_DATA: '_tex',\n\t\tsimple.GLU_NURBS_END: None,\n\t\tsimple.GLU_NURBS_END_DATA: '_justOOR',\n\t\tsimple.GLU_NURBS_ERROR: None,\n\t}\n\tdef _justOOR( self, function ):\n\t\t\"\"\"Just do OOR on the last argument...\"\"\"\n\t\tdef getOOR( *args ):\n\t\t\targs = args[:-1] + (self.originalObject(args[-1]),)\n\t\t\treturn function( *args )\n\t\treturn getOOR\n\tdef _vec3( self, function, size=3 ):\n\t\t\"\"\"Convert first arg to size-element array, do OOR on arg2 if present\"\"\"\n\t\tdef vec( *args ):\n\t\t\tvec = self.ptrAsArray(args[0],size,arrays.GLfloatArray)\n\t\t\tif len(args) > 1:\n\t\t\t\toor = self.originalObject(args[1])\n\t\t\t\treturn function( vec, oor )\n\t\t\telse:\n\t\t\t\treturn function( vec )\n\t\treturn vec\n\tdef _vec4( self, function ):\n\t\t\"\"\"Size-4 vector version...\"\"\"\n\t\treturn self._vec3( function, 4 )\n\tdef _tex( self, function ):\n\t\t\"\"\"Texture coordinate callback \n\t\t\n\t\tNOTE: there is no way for *us* to tell what size the array is, you will \n\t\tget back a raw data-point, not an array, as you do for all other callback \n\t\ttypes!!!\n\t\t\"\"\"\n\t\tdef oor( *args ):\n\t\t\tif len(args) > 1:\n\t\t\t\toor = self.originalObject(args[1])\n\t\t\t\treturn function( args[0], oor )\n\t\t\telse:\n\t\t\t\treturn function( args[0] )\n\t\treturn oor\n", "description": "GLU Nurbs structure with oor and callback storage support\n\t\n\tIMPORTANT NOTE: the texture coordinate callback receives a raw ctypes \n\tdata-pointer, as without knowing what type of evaluation is being done \n\t(1D or 2D) we cannot safely determine the size of the array to convert \n\tit.  This is a limitation of the C implementation.  To convert to regular \n\tdata-pointer, just call yourNurb.ptrAsArray( ptr, size, arrays.GLfloatArray )\n\twith the size of data you expect.\n\t", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL"]}, {"term": "def", "name": "_callbackWithType", "data": "def _callbackWithType( funcType ):\n\t\"\"\"Get gluNurbsCallback function with set last arg-type\"\"\"\n\tresult =  platform.copyBaseFunction(\n\t\tsimple.gluNurbsCallback\n\t)\n\tresult.argtypes = [ctypes.POINTER(GLUnurbs), simple.GLenum, funcType]\n\tassert result.argtypes[-1] == funcType\n\treturn result\n", "description": "Get gluNurbsCallback function with set last arg-type", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL"]}, {"term": "def", "name": "gluNurbsCallback", "data": "def gluNurbsCallback( nurb, which, CallBackFunc ):\n\t\"\"\"Dispatch to the nurb's addCallback operation\"\"\"\n\treturn nurb.addCallback( which, CallBackFunc )\n", "description": "Dispatch to the nurb's addCallback operation", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL"]}, {"term": "def", "name": "gluNewNurbsRenderer", "data": "def gluNewNurbsRenderer( baseFunction ):\n\t\"\"\"Return a new nurbs renderer for the system (dereferences pointer)\"\"\"\n\tnewSet = baseFunction()\n\tnew = newSet[0]\n\t#new.__class__ = GLUnurbs # yes, I know, ick\n\treturn new\n", "description": "Return a new nurbs renderer for the system (dereferences pointer)", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL"]}, {"term": "def", "name": "gluNurbsCallbackData", "data": "def gluNurbsCallbackData( baseFunction, nurb, userData ):\n\t\"\"\"Note the Python object for use as userData by the nurb\"\"\"\n\treturn baseFunction( \n\t\tnurb, nurb.noteObject( userData ) \n\t)\n", "description": "Note the Python object for use as userData by the nurb", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL"]}, {"term": "def", "name": "checkOrder", "data": "def checkOrder( order,knotCount,name ):\n\t\"\"\"Check that order is valid...\"\"\"\n\tif order < 1:\n\t\traise error.GLUError( \n\t\t\t\"\"\"%s should be 1 or more, is %s\"\"\"%( name,order,) \n\t\t)\n\telif order > MAX_ORDER:\n\t\traise error.GLUError( \n\t\t\t\"\"\"%s should be %s or less, is %s\"\"\"%( name, MAX_ORDER, order) \n\t\t)\n\telif knotCount < (2*order):\n\t\traise error.GLUError( \n\t\t\t\"\"\"Knotcount must be at least 2x %s is %s should be at least %s\"\"\"%( name, knotCount, 2*order) \n", "description": "Check that order is valid...", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL"]}, {"term": "def", "name": "checkKnots", "data": "def checkKnots( knots, name ):\n\t\"\"\"Check that knots are in ascending order\"\"\"\n\tif len(knots):\n\t\tknot = knots[0]\n\t\tfor next in knots[1:]:\n\t\t\tif next < knot:\n\t\t\t\traise error.GLUError(\n\t\t\t\t\t\"\"\"%s has decreasing knot %s after %s\"\"\"%( name, next, knot )\n\t\t\t\t)\n", "description": "Check that knots are in ascending order", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL"]}, {"term": "def", "name": "gluNurbsCallbackDataEXT", "data": "def gluNurbsCallbackDataEXT( baseFunction,nurb, userData ):\n\t\"\"\"Note the Python object for use as userData by the nurb\"\"\"\n\treturn baseFunction( \n\t\tnurb, nurb.noteObject( userData ) \n\t)\n", "description": "Note the Python object for use as userData by the nurb", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL"]}, {"term": "def", "name": "gluNurbsCurve", "data": "def gluNurbsCurve( baseFunction, nurb, knots, control, type ):\n\t\"\"\"Pythonic version of gluNurbsCurve\n\t\n\tCalculates knotCount, stride, and order automatically\n\t\"\"\"\n\tknots = arrays.GLfloatArray.asArray( knots )\n\tknotCount = arrays.GLfloatArray.arraySize( knots )\n\tcontrol = arrays.GLfloatArray.asArray( control )\n\ttry:\n\t\tlength,step = arrays.GLfloatArray.dimensions( control )\n\texcept ValueError, err:\n\t\traise error.GLUError( \"\"\"Need a 2-dimensional control array\"\"\" )\n\torder = knotCount - length\n\tif OpenGL.ERROR_CHECKING:\n\t\tcheckOrder( order, knotCount, 'order of NURBS curve')\n\t\tcheckKnots( knots, 'knots of NURBS curve')\n\treturn baseFunction(\n\t\tnurb, knotCount, knots, step, control, order, type,\n\t)\n", "description": "Pythonic version of gluNurbsCurve\n\t\n\tCalculates knotCount, stride, and order automatically\n\t", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL"]}, {"term": "def", "name": "gluNurbsSurface", "data": "def gluNurbsSurface( baseFunction, nurb, sKnots, tKnots, control, type ):\n\t\"\"\"Pythonic version of gluNurbsSurface\n\t\n\tCalculates knotCount, stride, and order automatically\n\t\"\"\"\n\tsKnots = arrays.GLfloatArray.asArray( sKnots )\n\tsKnotCount = arrays.GLfloatArray.arraySize( sKnots )\n\ttKnots = arrays.GLfloatArray.asArray( tKnots )\n\ttKnotCount = arrays.GLfloatArray.arraySize( tKnots )\n\tcontrol = arrays.GLfloatArray.asArray( control )\n\n\ttry:\n\t\tlength,width,step = arrays.GLfloatArray.dimensions( control )\n\texcept ValueError, err:\n\t\traise error.GLUError( \"\"\"Need a 3-dimensional control array\"\"\" )\n\tsOrder = sKnotCount - length \n\ttOrder = tKnotCount - width \n\tsStride = width*step\n\ttStride = step\n\tif OpenGL.ERROR_CHECKING:\n\t\tcheckOrder( sOrder, sKnotCount, 'sOrder of NURBS surface')\n\t\tcheckOrder( tOrder, tKnotCount, 'tOrder of NURBS surface')\n\t\tcheckKnots( sKnots, 'sKnots of NURBS surface')\n\t\tcheckKnots( tKnots, 'tKnots of NURBS surface')\n\tif not (sKnotCount-sOrder)*(tKnotCount-tOrder) == length*width:\n\t\traise error.GLUError(\n\t\t\t\"\"\"Invalid NURB structure\"\"\",\n\t\t\tnurb, sKnotCount, sKnots, tKnotCount, tKnots,\n\t\t\tsStride, tStride, control,\n\t\t\tsOrder,tOrder,\n\t\t\ttype\n\t\t)\n\n\tresult = baseFunction(\n\t\tnurb, sKnotCount, sKnots, tKnotCount, tKnots,\n\t\tsStride, tStride, control,\n\t\tsOrder,tOrder,\n\t\ttype\n\t)\n\treturn result\n", "description": "Pythonic version of gluNurbsSurface\n\t\n\tCalculates knotCount, stride, and order automatically\n\t", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL"]}, {"term": "def", "name": "gluPwlCurve", "data": "def gluPwlCurve( baseFunction, nurb, data, type ):\n\t\"\"\"gluPwlCurve -- piece-wise linear curve within GLU context\n\t\n\tdata -- the data-array \n\ttype -- determines number of elements/data-point\n\t\"\"\"\n\tdata = arrays.GLfloatArray.asArray( data )\n\tif type == simple.GLU_MAP1_TRIM_2:\n\t\tdivisor = 2\n\telif type == simple.GLU_MAP_TRIM_3:\n\t\tdivisor = 3\n\telse:\n\t\traise ValueError( \"\"\"Unrecognised type constant: %s\"\"\"%(type))\n\tsize = arrays.GLfloatArray.arraySize( data )\n\tsize = int(size//divisor)\n\treturn baseFunction( nurb, size, data, divisor, type )\n", "description": "gluPwlCurve -- piece-wise linear curve within GLU context\n\t\n\tdata -- the data-array \n\ttype -- determines number of elements/data-point\n\t", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL"]}], [{"term": "class", "name": "NumpyArrayEncoder", "data": "class NumpyArrayEncoder(JSONEncoder):\n\tdef default(self, obj):\n\t\tif isinstance(obj, numpy.ndarray):\n\t\t\treturn obj.tolist()\n\t\treturn JSONEncoder.default(self, obj)\n", "description": null, "category": "simple", "imports": ["import numpy as np", "import matplotlib.pyplot as plt", "import dataUtils", "import model_2020125001 as model", "import json", "from json import JSONEncoder", "import numpy"]}, {"term": "def", "name": "saveParams", "data": "def saveParams(params, path):\n\twith open(path, \"w\") as make_file:\n\t\tjson.dump(params, make_file, cls=NumpyArrayEncoder)\n\tprint(\"Done writing serialized NumPy array into file\")\n", "description": null, "category": "simple", "imports": ["import numpy as np", "import matplotlib.pyplot as plt", "import dataUtils", "import model_2020125001 as model", "import json", "from json import JSONEncoder", "import numpy"]}, {"term": "def", "name": "loadParams", "data": "def loadParams(path):\n\twith open(path, \"r\") as read_file:\n\t\tprint(\"Converting JSON encoded data into Numpy array\")\n\t\tdecodedArray = json.load(read_file)\n\treturn decodedArray\n\n", "description": null, "category": "simple", "imports": ["import numpy as np", "import matplotlib.pyplot as plt", "import dataUtils", "import model_2020125001 as model", "import json", "from json import JSONEncoder", "import numpy"]}, {"term": "def", "name": "main", "data": "def main():\n\tepochs = 61\n\tlearning_rate = 0.8\n\tbatch_size =128\n\tdecay_rate=1\n\tresume = False # path of model weights\n\tmodel_weights_path = 'weights_2020125001.json'\n\n\t### dataset loading \ud558\uae30.\n\tdataPath = 'dataset/train'\n\tvalPath = 'dataset/val'\n\tdataloader = dataUtils.Dataloader(dataPath, minibatch=batch_size)\n\tval_dataloader = dataUtils.Dataloader(valPath)\n\t\n\tnSample = dataloader.len()\n\tlayerDims = [7500,10,10,1]\n\n\tsimpleNN = model.NeuralNetwork(layerDims, nSample)\n\tif resume:\n\t\tsimpleNN.parameters = loadParams(resume)\n\n\tfor epoch in range (epochs):\t \n\t\ttraining(dataloader, simpleNN, learning_rate, epoch)\n\t\tif epoch%10==1:\n\t\t\t\n\t\t\t\n", "description": null, "category": "simple", "imports": ["import numpy as np", "import matplotlib.pyplot as plt", "import dataUtils", "import model_2020125001 as model", "import json", "from json import JSONEncoder", "import numpy"]}, {"term": "def", "name": "validation", "data": "def validation(dataloader, simpleNN):\n\tfor i, (images, targets) in enumerate(dataloader):\n\t\t# do validation\n\t\tA4=simpleNN.forward(images)\n\t\tpredictions = simpleNN.predict(images)\n\t\tprint(predictions)\n\t\tprint(targets)\n\t\tY_train=targets\n\t\tcost=simpleNN.compute_cost(A4,targets)\n\t\tprint ('Accuracy: %d' % float((np.dot(Y_train,predictions.T) + np.dot(1-Y_train,1-predictions.T))/float(Y_train.size)*100) + '%')\n\t\tprint (\"Cost after epoch: %f\" %(cost))\n", "description": null, "category": "simple", "imports": ["import numpy as np", "import matplotlib.pyplot as plt", "import dataUtils", "import model_2020125001 as model", "import json", "from json import JSONEncoder", "import numpy"]}, {"term": "def", "name": "training", "data": "def training(dataloader, simpleNN, learning_rate, epoch):\n\n\tfor i, (images, targets) in enumerate(dataloader):\n\t\t# do training\n\t\tA4=simpleNN.forward(images)\n\t\tcost=simpleNN.compute_cost(A4,targets)\n\t\tsimpleNN.backward()\n\t\tsimpleNN.update_params(learning_rate)\n\t\t#print ('Accuracy: %d' % float((np.dot(targets,predictions.T) + np.dot(1-targets,1-predictions.T))/float(targets.size)*100) + '%')\t\t\n\t\tpass\n\n\treturn simpleNN\n \n", "description": null, "category": "simple", "imports": ["import numpy as np", "import matplotlib.pyplot as plt", "import dataUtils", "import model_2020125001 as model", "import json", "from json import JSONEncoder", "import numpy"]}], [], [], [], [{"term": "class", "name": "TestGEXF", "data": "class TestGEXF(object):\n\t@classmethod\n\tdef setupClass(cls):\n\t\ttry:\n\t\t\timport xml.etree.ElementTree\n\t\texcept ImportError:\n\t\t\traise SkipTest('xml.etree.ElementTree not available.')\n\n\tdef setUp(self):\n\t\tself.simple_directed_data = \"\"\"\n\n\n\n\n\n\n\n\n\n\n", "description": "\n\n\n\n\n\n\n\n\n\n\n", "category": "simple", "imports": ["import io", "import time", "from nose import SkipTest", "from nose.tools import *", "import networkx as nx", "\t\t\timport xml.etree.ElementTree"]}, {"term": "def", "name": "ftest_read_simple_directed_graphml", "data": "\tdef test_read_simple_directed_graphml(self):\n\t\tG = self.simple_directed_graph\n\t\tH = nx.read_gexf(self.simple_directed_fh)\n\t\tassert_equal(sorted(G.nodes()), sorted(H.nodes()))\n\t\tassert_equal(sorted(G.edges()), sorted(H.edges()))\n\t\tassert_equal(sorted(G.edges(data=True)),\n\t\t\t\t\t sorted(H.edges(data=True)))\n\t\tself.simple_directed_fh.seek(0)\n", "description": null, "category": "simple", "imports": ["import io", "import time", "from nose import SkipTest", "from nose.tools import *", "import networkx as nx", "\t\t\timport xml.etree.ElementTree"]}, {"term": "def", "name": "ftest_write_read_simple_directed_graphml", "data": "\tdef test_write_read_simple_directed_graphml(self):\n\t\tG = self.simple_directed_graph\n\t\tfh = io.BytesIO()\n\t\tnx.write_gexf(G, fh)\n\t\tfh.seek(0)\n\t\tH = nx.read_gexf(fh)\n\t\tassert_equal(sorted(G.nodes()), sorted(H.nodes()))\n\t\tassert_equal(sorted(G.edges()), sorted(H.edges()))\n\t\tassert_equal(sorted(G.edges(data=True)),\n\t\t\t\t\t sorted(H.edges(data=True)))\n\t\tself.simple_directed_fh.seek(0)\n", "description": null, "category": "simple", "imports": ["import io", "import time", "from nose import SkipTest", "from nose.tools import *", "import networkx as nx", "\t\t\timport xml.etree.ElementTree"]}, {"term": "def", "name": "ftest_read_simple_undirected_graphml", "data": "\tdef test_read_simple_undirected_graphml(self):\n\t\tG = self.simple_undirected_graph\n\t\tH = nx.read_gexf(self.simple_undirected_fh)\n\t\tassert_equal(sorted(G.nodes()), sorted(H.nodes()))\n\t\tassert_equal(\n\t\t\tsorted(sorted(e) for e in G.edges()),\n\t\t\tsorted(sorted(e) for e in H.edges()))\n\t\tself.simple_undirected_fh.seek(0)\n", "description": null, "category": "simple", "imports": ["import io", "import time", "from nose import SkipTest", "from nose.tools import *", "import networkx as nx", "\t\t\timport xml.etree.ElementTree"]}, {"term": "def", "name": "ftest_read_attribute_graphml", "data": "\tdef test_read_attribute_graphml(self):\n\t\tG = self.attribute_graph\n\t\tH = nx.read_gexf(self.attribute_fh)\n\t\tassert_equal(sorted(G.nodes(True)), sorted(H.nodes(data=True)))\n\t\tge = sorted(G.edges(data=True))\n\t\the = sorted(H.edges(data=True))\n\t\tfor a, b in zip(ge, he):\n\t\t\tassert_equal(a, b)\n\t\tself.attribute_fh.seek(0)\n", "description": null, "category": "simple", "imports": ["import io", "import time", "from nose import SkipTest", "from nose.tools import *", "import networkx as nx", "\t\t\timport xml.etree.ElementTree"]}, {"term": "def", "name": "ftest_directed_edge_in_undirected", "data": "\tdef test_directed_edge_in_undirected(self):\n\t\ts = \"\"\"\n\n\n\n\n\n\n\n\n\n\n", "description": "\n\n\n\n\n\n\n\n\n\n\n", "category": "simple", "imports": ["import io", "import time", "from nose import SkipTest", "from nose.tools import *", "import networkx as nx", "\t\t\timport xml.etree.ElementTree"]}, {"term": "def", "name": "ftest_undirected_edge_in_directed", "data": "\tdef test_undirected_edge_in_directed(self):\n\t\ts = \"\"\"\n\n\n\n\n\n\n\n\n\n\n", "description": "\n\n\n\n\n\n\n\n\n\n\n", "category": "simple", "imports": ["import io", "import time", "from nose import SkipTest", "from nose.tools import *", "import networkx as nx", "\t\t\timport xml.etree.ElementTree"]}, {"term": "def", "name": "ftest_key_raises", "data": "\tdef test_key_raises(self):\n\t\ts = \"\"\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "description": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "category": "simple", "imports": ["import io", "import time", "from nose import SkipTest", "from nose.tools import *", "import networkx as nx", "\t\t\timport xml.etree.ElementTree"]}, {"term": "def", "name": "ftest_relabel", "data": "\tdef test_relabel(self):\n\t\ts = \"\"\"\n\n\n\n\n\n\n\n\n\n\n", "description": "\n\n\n\n\n\n\n\n\n\n\n", "category": "simple", "imports": ["import io", "import time", "from nose import SkipTest", "from nose.tools import *", "import networkx as nx", "\t\t\timport xml.etree.ElementTree"]}, {"term": "def", "name": "ftest_default_attribute", "data": "\tdef test_default_attribute(self):\n\t\tG = nx.Graph()\n\t\tG.add_node(1, label='1', color='green')\n\t\tnx.add_path(G, [0, 1, 2, 3])\n\t\tG.add_edge(1, 2, foo=3)\n\t\tG.graph['node_default'] = {'color': 'yellow'}\n\t\tG.graph['edge_default'] = {'foo': 7}\n\t\tfh = io.BytesIO()\n\t\tnx.write_gexf(G, fh)\n\t\tfh.seek(0)\n\t\tH = nx.read_gexf(fh, node_type=int)\n\t\tassert_equal(sorted(G.nodes()), sorted(H.nodes()))\n\t\tassert_equal(\n\t\t\tsorted(sorted(e) for e in G.edges()),\n\t\t\tsorted(sorted(e) for e in H.edges()))\n\t\t# Reading a gexf graph always sets mode attribute to either\n\t\t# 'static' or 'dynamic'. Remove the mode attribute from the\n\t\t# read graph for the sake of comparing remaining attributes.\n\t\tdel H.graph['mode']\n\t\tassert_equal(G.graph, H.graph)\n", "description": null, "category": "simple", "imports": ["import io", "import time", "from nose import SkipTest", "from nose.tools import *", "import networkx as nx", "\t\t\timport xml.etree.ElementTree"]}, {"term": "def", "name": "ftest_serialize_ints_to_strings", "data": "\tdef test_serialize_ints_to_strings(self):\n\t\tG = nx.Graph()\n\t\tG.add_node(1, id=7, label=77)\n\t\tfh = io.BytesIO()\n\t\tnx.write_gexf(G, fh)\n\t\tfh.seek(0)\n\t\tH = nx.read_gexf(fh, node_type=int)\n\t\tassert_equal(list(H), [7])\n\t\tassert_equal(H.node[7]['label'], '77')\n", "description": null, "category": "simple", "imports": ["import io", "import time", "from nose import SkipTest", "from nose.tools import *", "import networkx as nx", "\t\t\timport xml.etree.ElementTree"]}, {"term": "def", "name": "ftest_write_with_node_attributes", "data": "\tdef test_write_with_node_attributes(self):\n\t\t# Addresses #673.\n\t\tG = nx.OrderedGraph()\n\t\tG.add_nodes_from([0,1,2,3])\n\t\tG.add_edges_from([(0,1),(1,2),(2,3)])\n\t\tfor i in range(4):\n\t\t\tG.node[i]['id'] = i\n\t\t\tG.node[i]['label'] = i\n\t\t\tG.node[i]['pid'] = i\n\n\t\texpected = \"\"\"\n\n", "description": "\n\n", "category": "simple", "imports": ["import io", "import time", "from nose import SkipTest", "from nose.tools import *", "import networkx as nx", "\t\t\timport xml.etree.ElementTree"]}, {"term": "def", "name": "ftest_bool", "data": "\tdef test_bool(self):\n\t\tG = nx.Graph()\n\t\tG.add_node(1, testattr=True)\n\t\tfh = io.BytesIO()\n\t\tnx.write_gexf(G, fh)\n\t\tfh.seek(0)\n\t\tH = nx.read_gexf(fh, node_type=int)\n\t\tassert_equal(H.node[1]['testattr'], True)\n", "description": null, "category": "simple", "imports": ["import io", "import time", "from nose import SkipTest", "from nose.tools import *", "import networkx as nx", "\t\t\timport xml.etree.ElementTree"]}], [{"term": "def", "name": "annotated_simple_mapping", "data": "def annotated_simple_mapping(simple_mapping):\n\tmapping = LigandAtomMapping(simple_mapping.molA,\n\t\t\t\t\t\t\t\tsimple_mapping.molB,\n\t\t\t\t\t\t\t\tsimple_mapping.molA_to_molB,\n\t\t\t\t\t\t\t\tannotations={'foo': 'bar'})\n\treturn mapping\n\n", "description": null, "category": "simple", "imports": ["import pytest", "import pathlib", "import json", "from rdkit import Chem", "from openfe.setup.atom_mapping import LigandAtomMapping"]}, {"term": "def", "name": "test_atommapping_usage", "data": "def test_atommapping_usage(simple_mapping):\n\tassert simple_mapping.molA_to_molB[1] == 1\n\tassert simple_mapping.molA_to_molB.get(2, None) is None\n\tassert simple_mapping.annotations == {}\n\n\twith pytest.raises(KeyError):\n\t\tsimple_mapping.molA_to_molB[3]\n\n", "description": null, "category": "simple", "imports": ["import pytest", "import pathlib", "import json", "from rdkit import Chem", "from openfe.setup.atom_mapping import LigandAtomMapping"]}, {"term": "def", "name": "test_atommapping_hash", "data": "def test_atommapping_hash(simple_mapping, other_mapping):\n\t# these two mappings map the same molecules, but with a different mapping\n\tassert simple_mapping is not other_mapping\n\n", "description": null, "category": "simple", "imports": ["import pytest", "import pathlib", "import json", "from rdkit import Chem", "from openfe.setup.atom_mapping import LigandAtomMapping"]}, {"term": "def", "name": "test_draw_mapping_cairo", "data": "def test_draw_mapping_cairo(tmpdir, simple_mapping):\n\twith tmpdir.as_cwd():\n\t\tsimple_mapping.draw_to_file('test.png')\n\t\tfiled = pathlib.Path('test.png')\n\t\tassert filed.exists()\n\n", "description": null, "category": "simple", "imports": ["import pytest", "import pathlib", "import json", "from rdkit import Chem", "from openfe.setup.atom_mapping import LigandAtomMapping"]}, {"term": "def", "name": "test_draw_mapping_svg", "data": "def test_draw_mapping_svg(tmpdir, other_mapping):\n\twith tmpdir.as_cwd():\n\t\td2d = Chem.Draw.rdMolDraw2D.MolDraw2DSVG(600, 300, 300, 300)\n\t\tother_mapping.draw_to_file('test.svg', d2d=d2d)\n\t\tfiled = pathlib.Path('test.svg')\n\t\tassert filed.exists()\n\n", "description": null, "category": "simple", "imports": ["import pytest", "import pathlib", "import json", "from rdkit import Chem", "from openfe.setup.atom_mapping import LigandAtomMapping"]}, {"term": "class", "name": "classTestLigandAtomMappingSerialization:", "data": "class TestLigandAtomMappingSerialization:\n\tdef test_to_dict(self, benzene_phenol_mapping):\n\t\td = benzene_phenol_mapping.to_dict()\n\n\t\tassert isinstance(d, dict)\n\t\tassert 'molA' in d\n\t\tassert 'molB' in d\n\t\tassert 'annotations' in d\n\t\tassert isinstance(d['molA'], str)\n\n\tdef test_deserialize_roundtrip(self, benzene_phenol_mapping,\n\t\t\t\t\t\t\t\t   benzene_anisole_mapping):\n\n\t\troundtrip = LigandAtomMapping.from_dict(\n\t\t\t\t\t\tbenzene_phenol_mapping.to_dict())\n\n\t\tassert roundtrip == benzene_phenol_mapping\n\n\t\t# We don't check coordinates since that's already done in guefe for\n\t\t# SmallMoleculeComponent\n\n\t\tassert roundtrip != benzene_anisole_mapping\n\n\tdef test_file_roundtrip(self, benzene_phenol_mapping, tmpdir):\n\t\twith tmpdir.as_cwd():\n\t\t\twith open('tmpfile.json', 'w') as f:\n\t\t\t\tf.write(benzene_phenol_mapping.to_json())\n\n\t\t\twith open('tmpfile.json', 'r') as f:\n\t\t\t\td = json.load(f)\n\n\t\t\tassert isinstance(d, dict)\n\t\t\troundtrip = LigandAtomMapping.from_dict(d)\n\n\t\t\tassert roundtrip == benzene_phenol_mapping\n\n", "description": null, "category": "simple", "imports": ["import pytest", "import pathlib", "import json", "from rdkit import Chem", "from openfe.setup.atom_mapping import LigandAtomMapping"]}, {"term": "def", "name": "test_annotated_atommapping_hash_eq", "data": "def test_annotated_atommapping_hash_eq(simple_mapping,\n\t\t\t\t\t\t\t\t\t   annotated_simple_mapping):\n\tassert annotated_simple_mapping != simple_mapping\n\tassert hash(annotated_simple_mapping) != hash(simple_mapping)\n\n", "description": null, "category": "simple", "imports": ["import pytest", "import pathlib", "import json", "from rdkit import Chem", "from openfe.setup.atom_mapping import LigandAtomMapping"]}, {"term": "def", "name": "test_annotation_immutability", "data": "def test_annotation_immutability(annotated_simple_mapping):\n\tannot1 = annotated_simple_mapping.annotations\n\tannot1['foo'] = 'baz'\n\tannot2 = annotated_simple_mapping.annotations\n\tassert annot1 != annot2\n\tassert annot2 == {'foo': 'bar'}\n\n", "description": null, "category": "simple", "imports": ["import pytest", "import pathlib", "import json", "from rdkit import Chem", "from openfe.setup.atom_mapping import LigandAtomMapping"]}, {"term": "def", "name": "test_with_annotations", "data": "def test_with_annotations(simple_mapping, annotated_simple_mapping):\n\tnew_annot = simple_mapping.with_annotations({'foo': 'bar'})\n\tassert new_annot == annotated_simple_mapping\n", "description": null, "category": "simple", "imports": ["import pytest", "import pathlib", "import json", "from rdkit import Chem", "from openfe.setup.atom_mapping import LigandAtomMapping"]}], [{"term": "class", "name": "TestLibraryInfo", "data": "class TestLibraryInfo(TestCase):\n\tdef test_simple(self):\n\t\tfd, filename = mkstemp('foo.ini')\n\t\ttry:\n\t\t\tpkg = os.path.splitext(filename)[0]\n\t\t\ttry:\n\t\t\t\tos.write(fd, simple.encode('ascii'))\n\t\t\tfinally:\n\t\t\t\tos.close(fd)\n\n\t\t\tout = read_config(pkg)\n\t\t\tself.assertTrue(out.cflags() == simple_d['cflags'])\n\t\t\tself.assertTrue(out.libs() == simple_d['libflags'])\n\t\t\tself.assertTrue(out.name == simple_d['name'])\n\t\t\tself.assertTrue(out.version == simple_d['version'])\n\t\tfinally:\n\t\t\tos.remove(filename)\n\n\tdef test_simple_variable(self):\n\t\tfd, filename = mkstemp('foo.ini')\n\t\ttry:\n\t\t\tpkg = os.path.splitext(filename)[0]\n\t\t\ttry:\n\t\t\t\tos.write(fd, simple_variable.encode('ascii'))\n\t\t\tfinally:\n\t\t\t\tos.close(fd)\n\n\t\t\tout = read_config(pkg)\n\t\t\tself.assertTrue(out.cflags() == simple_variable_d['cflags'])\n\t\t\tself.assertTrue(out.libs() == simple_variable_d['libflags'])\n\t\t\tself.assertTrue(out.name == simple_variable_d['name'])\n\t\t\tself.assertTrue(out.version == simple_variable_d['version'])\n\n\t\t\tout.vars['prefix'] = '/Users/david'\n\t\t\tself.assertTrue(out.cflags() == '-I/Users/david/include')\n\t\tfinally:\n\t\t\tos.remove(filename)\n", "description": null, "category": "simple", "imports": ["import os", "from tempfile import mkstemp", "from numpy.testing import *", "from numpy.distutils.npy_pkg_config import read_config, parse_flags"]}, {"term": "class", "name": "TestParseFlags", "data": "class TestParseFlags(TestCase):\n\tdef test_simple_cflags(self):\n\t\td = parse_flags(\"-I/usr/include\")\n\t\tself.assertTrue(d['include_dirs'] == ['/usr/include'])\n\n\t\td = parse_flags(\"-I/usr/include -DFOO\")\n\t\tself.assertTrue(d['include_dirs'] == ['/usr/include'])\n\t\tself.assertTrue(d['macros'] == ['FOO'])\n\n\t\td = parse_flags(\"-I /usr/include -DFOO\")\n\t\tself.assertTrue(d['include_dirs'] == ['/usr/include'])\n\t\tself.assertTrue(d['macros'] == ['FOO'])\n\n\tdef test_simple_lflags(self):\n\t\td = parse_flags(\"-L/usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tself.assertTrue(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tself.assertTrue(d['libraries'] == ['foo', 'bar'])\n\n\t\td = parse_flags(\"-L /usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tself.assertTrue(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tself.assertTrue(d['libraries'] == ['foo', 'bar'])\n", "description": null, "category": "simple", "imports": ["import os", "from tempfile import mkstemp", "from numpy.testing import *", "from numpy.distutils.npy_pkg_config import read_config, parse_flags"]}], [{"term": "class", "name": "TestLibraryInfo", "data": "class TestLibraryInfo(TestCase):\n\tdef test_simple(self):\n\t\tfd, filename = mkstemp('foo.ini')\n\t\ttry:\n\t\t\tpkg = os.path.splitext(filename)[0]\n\t\t\ttry:\n\t\t\t\tos.write(fd, simple.encode('ascii'))\n\t\t\tfinally:\n\t\t\t\tos.close(fd)\n\n\t\t\tout = read_config(pkg)\n\t\t\tself.assertTrue(out.cflags() == simple_d['cflags'])\n\t\t\tself.assertTrue(out.libs() == simple_d['libflags'])\n\t\t\tself.assertTrue(out.name == simple_d['name'])\n\t\t\tself.assertTrue(out.version == simple_d['version'])\n\t\tfinally:\n\t\t\tos.remove(filename)\n\n\tdef test_simple_variable(self):\n\t\tfd, filename = mkstemp('foo.ini')\n\t\ttry:\n\t\t\tpkg = os.path.splitext(filename)[0]\n\t\t\ttry:\n\t\t\t\tos.write(fd, simple_variable.encode('ascii'))\n\t\t\tfinally:\n\t\t\t\tos.close(fd)\n\n\t\t\tout = read_config(pkg)\n\t\t\tself.assertTrue(out.cflags() == simple_variable_d['cflags'])\n\t\t\tself.assertTrue(out.libs() == simple_variable_d['libflags'])\n\t\t\tself.assertTrue(out.name == simple_variable_d['name'])\n\t\t\tself.assertTrue(out.version == simple_variable_d['version'])\n\n\t\t\tout.vars['prefix'] = '/Users/david'\n\t\t\tself.assertTrue(out.cflags() == '-I/Users/david/include')\n\t\tfinally:\n\t\t\tos.remove(filename)\n", "description": null, "category": "simple", "imports": ["import os", "from tempfile import mkstemp", "from numpy.testing import *", "from numpy.distutils.npy_pkg_config import read_config, parse_flags"]}, {"term": "class", "name": "TestParseFlags", "data": "class TestParseFlags(TestCase):\n\tdef test_simple_cflags(self):\n\t\td = parse_flags(\"-I/usr/include\")\n\t\tself.assertTrue(d['include_dirs'] == ['/usr/include'])\n\n\t\td = parse_flags(\"-I/usr/include -DFOO\")\n\t\tself.assertTrue(d['include_dirs'] == ['/usr/include'])\n\t\tself.assertTrue(d['macros'] == ['FOO'])\n\n\t\td = parse_flags(\"-I /usr/include -DFOO\")\n\t\tself.assertTrue(d['include_dirs'] == ['/usr/include'])\n\t\tself.assertTrue(d['macros'] == ['FOO'])\n\n\tdef test_simple_lflags(self):\n\t\td = parse_flags(\"-L/usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tself.assertTrue(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tself.assertTrue(d['libraries'] == ['foo', 'bar'])\n\n\t\td = parse_flags(\"-L /usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tself.assertTrue(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tself.assertTrue(d['libraries'] == ['foo', 'bar'])\n", "description": null, "category": "simple", "imports": ["import os", "from tempfile import mkstemp", "from numpy.testing import *", "from numpy.distutils.npy_pkg_config import read_config, parse_flags"]}], [{"term": "def", "name": "trim", "data": "def trim(value, num):\n\treturn value[:num]\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "make_data_div", "data": "def make_data_div(value):\n\t\"\"\"A filter that uses a decorator (@mark_safe).\"\"\"\n\treturn '' % value\n\n", "description": "A filter that uses a decorator (@mark_safe).", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "noop", "data": "def noop(value, param=None):\n\t\"\"\"A noop filter that always return its first argument and does nothing with\n\tits second (optional) one.\n\tUseful for testing out whitespace in filter arguments (see #19882).\"\"\"\n\treturn value\n\n", "description": "A noop filter that always return its first argument and does nothing with\n\tits second (optional) one.\n\tUseful for testing out whitespace in filter arguments (see #19882).", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "context_stack_length", "data": "def context_stack_length(context):\n\treturn len(context.dicts)\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "no_params", "data": "def no_params():\n\t\"\"\"Expected no_params __doc__\"\"\"\n\treturn \"no_params - Expected result\"\n\n", "description": "Expected no_params __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "one_param", "data": "def one_param(arg):\n\t\"\"\"Expected one_param __doc__\"\"\"\n\treturn \"one_param - Expected result: %s\" % arg\n\n", "description": "Expected one_param __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "explicit_no_context", "data": "def explicit_no_context(arg):\n\t\"\"\"Expected explicit_no_context __doc__\"\"\"\n\treturn \"explicit_no_context - Expected result: %s\" % arg\n\n", "description": "Expected explicit_no_context __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "no_params_with_context", "data": "def no_params_with_context(context):\n\t\"\"\"Expected no_params_with_context __doc__\"\"\"\n\treturn \"no_params_with_context - Expected result (context value: %s)\" % context['value']\n\n", "description": "Expected no_params_with_context __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "params_and_context", "data": "def params_and_context(context, arg):\n\t\"\"\"Expected params_and_context __doc__\"\"\"\n\treturn \"params_and_context - Expected result (context value: %s): %s\" % (context['value'], arg)\n\n", "description": "Expected params_and_context __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_two_params", "data": "def simple_two_params(one, two):\n\t\"\"\"Expected simple_two_params __doc__\"\"\"\n\treturn \"simple_two_params - Expected result: %s, %s\" % (one, two)\n\n", "description": "Expected simple_two_params __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_keyword_only_param", "data": "def simple_keyword_only_param(*, kwarg):\n\treturn \"simple_keyword_only_param - Expected result: %s\" % kwarg\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_keyword_only_default", "data": "def simple_keyword_only_default(*, kwarg=42):\n\treturn \"simple_keyword_only_default - Expected result: %s\" % kwarg\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_one_default", "data": "def simple_one_default(one, two='hi'):\n\t\"\"\"Expected simple_one_default __doc__\"\"\"\n\treturn \"simple_one_default - Expected result: %s, %s\" % (one, two)\n\n", "description": "Expected simple_one_default __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_unlimited_args", "data": "def simple_unlimited_args(one, two='hi', *args):\n\t\"\"\"Expected simple_unlimited_args __doc__\"\"\"\n\treturn \"simple_unlimited_args - Expected result: %s\" % (\n\t\t', '.join(str(arg) for arg in [one, two, *args])\n\t)\n\n", "description": "Expected simple_unlimited_args __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_only_unlimited_args", "data": "def simple_only_unlimited_args(*args):\n\t\"\"\"Expected simple_only_unlimited_args __doc__\"\"\"\n\treturn \"simple_only_unlimited_args - Expected result: %s\" % ', '.join(str(arg) for arg in args)\n\n", "description": "Expected simple_only_unlimited_args __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_unlimited_args_kwargs", "data": "def simple_unlimited_args_kwargs(one, two='hi', *args, **kwargs):\n\t\"\"\"Expected simple_unlimited_args_kwargs __doc__\"\"\"\n\t# Sort the dictionary by key to guarantee the order for testing.\n\tsorted_kwarg = sorted(kwargs.items(), key=operator.itemgetter(0))\n\treturn \"simple_unlimited_args_kwargs - Expected result: %s / %s\" % (\n\t\t', '.join(str(arg) for arg in [one, two, *args]),\n\t\t', '.join('%s=%s' % (k, v) for (k, v) in sorted_kwarg)\n\t)\n\n", "description": "Expected simple_unlimited_args_kwargs __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_tag_without_context_parameter", "data": "def simple_tag_without_context_parameter(arg):\n\t\"\"\"Expected simple_tag_without_context_parameter __doc__\"\"\"\n\treturn \"Expected result\"\n\n", "description": "Expected simple_tag_without_context_parameter __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "escape_naive", "data": "def escape_naive(context):\n\t\"\"\"A tag that doesn't even think about escaping issues\"\"\"\n\treturn \"Hello {}!\".format(context['name'])\n\n", "description": "A tag that doesn't even think about escaping issues", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "escape_explicit", "data": "def escape_explicit(context):\n\t\"\"\"A tag that uses escape explicitly\"\"\"\n\treturn escape(\"Hello {}!\".format(context['name']))\n\n", "description": "A tag that uses escape explicitly", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "escape_format_html", "data": "def escape_format_html(context):\n\t\"\"\"A tag that uses format_html\"\"\"\n\treturn format_html(\"Hello {0}!\", context['name'])\n\n", "description": "A tag that uses format_html", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "current_app", "data": "def current_app(context):\n\treturn str(context.current_app)\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "use_l10n", "data": "def use_l10n(context):\n\treturn str(context.use_l10n)\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "minustwo_overridden_name", "data": "def minustwo_overridden_name(value):\n\treturn value - 2\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "counter", "data": "def counter(parser, token):\n\treturn CounterNode()\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "class", "name": "CounterNode", "data": "class CounterNode(template.Node):\n\tdef __init__(self):\n\t\tself.count = 0\n\n\tdef render(self, context):\n\t\tcount = self.count\n\t\tself.count = count + 1\n\t\treturn count\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}], [], [], [], [], [], [], [], [], [{"term": "def", "name": "fwith_tp_del", "data": "\tdef with_tp_del(cls):\n\t\tclass C(object):\n\t\t\tdef __new__(cls, *args, **kwargs):\n\t\t\t\traise TypeError('requires _testcapi.with_tp_del')\n\t\treturn C\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "def", "name": "fwithout_gc", "data": "\tdef without_gc(cls):\n\t\tclass C:\n\t\t\tdef __new__(cls, *args, **kwargs):\n\t\t\t\traise TypeError('requires _testcapi.without_gc')\n\t\treturn C\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "classNonGCSimpleBase:", "data": "class NonGCSimpleBase:\n\t\"\"\"\n\tThe base class for all the objects under test, equipped with various\n\ttesting features.\n\t\"\"\"\n\n\tsurvivors = []\n\tdel_calls = []\n\ttp_del_calls = []\n\terrors = []\n\n\t_cleaning = False\n\n\t__slots__ = ()\n\n\t@classmethod\n\tdef _cleanup(cls):\n\t\tcls.survivors.clear()\n\t\tcls.errors.clear()\n\t\tgc.garbage.clear()\n\t\tgc.collect()\n\t\tcls.del_calls.clear()\n\t\tcls.tp_del_calls.clear()\n\n\t@classmethod\n\t@contextlib.contextmanager\n\tdef test(cls):\n\t\t\"\"\"\n\t\tA context manager to use around all finalization tests.\n\t\t\"\"\"\n\t\twith support.disable_gc():\n\t\t\tcls.del_calls.clear()\n\t\t\tcls.tp_del_calls.clear()\n\t\t\tNonGCSimpleBase._cleaning = False\n\t\t\ttry:\n\t\t\t\tyield\n\t\t\t\tif cls.errors:\n\t\t\t\t\traise cls.errors[0]\n\t\t\tfinally:\n\t\t\t\tNonGCSimpleBase._cleaning = True\n\t\t\t\tcls._cleanup()\n\n\tdef check_sanity(self):\n\t\t\"\"\"\n\t\tCheck the object is sane (non-broken).\n\t\t\"\"\"\n\n\tdef __del__(self):\n\t\t\"\"\"\n\t\tPEP 442 finalizer.  Record that this was called, check the\n\t\tobject is in a sane state, and invoke a side effect.\n\t\t\"\"\"\n\t\ttry:\n\t\t\tif not self._cleaning:\n\t\t\t\tself.del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\t\t\tself.side_effect()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tA side effect called on destruction.\n\t\t\"\"\"\n\n", "description": "\n\tThe base class for all the objects under test, equipped with various\n\ttesting features.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "SimpleBase", "data": "class SimpleBase(NonGCSimpleBase):\n\n\tdef __init__(self):\n\t\tself.id_ = id(self)\n\n\tdef check_sanity(self):\n\t\tassert self.id_ == id(self)\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "NonGC", "data": "class NonGC(NonGCSimpleBase):\n\t__slots__ = ()\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "NonGCResurrector", "data": "class NonGCResurrector(NonGCSimpleBase):\n\t__slots__ = ()\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tResurrect self by storing self in a class-wide list.\n\t\t\"\"\"\n\t\tself.survivors.append(self)\n", "description": "\n\t\tResurrect self by storing self in a class-wide list.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "Simple", "data": "class Simple(SimpleBase):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "SimpleResurrector", "data": "class SimpleResurrector(SimpleBase):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tResurrect self by storing self in a class-wide list.\n\t\t\"\"\"\n\t\tself.survivors.append(self)\n\n", "description": "\n\t\tResurrect self by storing self in a class-wide list.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "classTestBase:", "data": "class TestBase:\n\n\tdef setUp(self):\n\t\tself.old_garbage = gc.garbage[:]\n\t\tgc.garbage[:] = []\n\n\tdef tearDown(self):\n\t\t# None of the tests here should put anything in gc.garbage\n\t\ttry:\n\t\t\tself.assertEqual(gc.garbage, [])\n\t\tfinally:\n\t\t\tdel self.old_garbage\n\t\t\tgc.collect()\n\n\tdef assert_del_calls(self, ids):\n\t\tself.assertEqual(sorted(SimpleBase.del_calls), sorted(ids))\n\n\tdef assert_tp_del_calls(self, ids):\n\t\tself.assertEqual(sorted(SimpleBase.tp_del_calls), sorted(ids))\n\n\tdef assert_survivors(self, ids):\n\t\tself.assertEqual(sorted(id(x) for x in SimpleBase.survivors), sorted(ids))\n\n\tdef assert_garbage(self, ids):\n\t\tself.assertEqual(sorted(id(x) for x in gc.garbage), sorted(ids))\n\n\tdef clear_survivors(self):\n\t\tSimpleBase.survivors.clear()\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "SimpleFinalizationTest", "data": "class SimpleFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization without refcycles.\n\t\"\"\"\n\n\tdef test_simple(self):\n\t\twith SimpleBase.test():\n\t\t\ts = Simple()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_simple_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = SimpleResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\tself.assertIsNot(wr(), None)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\tself.assertIs(wr(), None)\n\n\t@support.cpython_only\n\tdef test_non_gc(self):\n\t\twith SimpleBase.test():\n\t\t\ts = NonGC()\n\t\t\tself.assertFalse(gc.is_tracked(s))\n\t\t\tids = [id(s)]\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\t@support.cpython_only\n\tdef test_non_gc_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = NonGCResurrector()\n\t\t\tself.assertFalse(gc.is_tracked(s))\n\t\t\tids = [id(s)]\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids * 2)\n\t\t\tself.assert_survivors(ids)\n\n", "description": "\n\tTest finalization without refcycles.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "classSelfCycleBase:", "data": "class SelfCycleBase:\n\n\tdef __init__(self):\n\t\tsuper().__init__()\n\t\tself.ref = self\n\n\tdef check_sanity(self):\n\t\tsuper().check_sanity()\n\t\tassert self.ref is self\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "SimpleSelfCycle", "data": "class SimpleSelfCycle(SelfCycleBase, Simple):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "SelfCycleResurrector", "data": "class SelfCycleResurrector(SelfCycleBase, SimpleResurrector):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "SuicidalSelfCycle", "data": "class SuicidalSelfCycle(SelfCycleBase, Simple):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tExplicitly break the reference cycle.\n\t\t\"\"\"\n\t\tself.ref = None\n\n", "description": "\n\t\tExplicitly break the reference cycle.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "SelfCycleFinalizationTest", "data": "class SelfCycleFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of an object having a single cyclic reference to\n\titself.\n\t\"\"\"\n\n\tdef test_simple(self):\n\t\twith SimpleBase.test():\n\t\t\ts = SimpleSelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_simple_resurrect(self):\n\t\t# Test that __del__ can resurrect the object being finalized.\n\t\twith SimpleBase.test():\n\t\t\ts = SelfCycleResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\t# XXX is this desirable?\n\t\t\tself.assertIs(wr(), None)\n\t\t\t# When trying to destroy the object a second time, __del__\n\t\t\t# isn't called anymore (and the object isn't resurrected).\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\n\tdef test_simple_suicide(self):\n\t\t# Test the GC is able to deal with an object that kills its last\n\t\t# reference during __del__.\n\t\twith SimpleBase.test():\n\t\t\ts = SuicidalSelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\n", "description": "\n\tTest finalization of an object having a single cyclic reference to\n\titself.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "classChainedBase:", "data": "class ChainedBase:\n\n\tdef chain(self, left):\n\t\tself.suicided = False\n\t\tself.left = left\n\t\tleft.right = self\n\n\tdef check_sanity(self):\n\t\tsuper().check_sanity()\n\t\tif self.suicided:\n\t\t\tassert self.left is None\n\t\t\tassert self.right is None\n\t\telse:\n\t\t\tleft = self.left\n\t\t\tif left.suicided:\n\t\t\t\tassert left.right is None\n\t\t\telse:\n\t\t\t\tassert left.right is self\n\t\t\tright = self.right\n\t\t\tif right.suicided:\n\t\t\t\tassert right.left is None\n\t\t\telse:\n\t\t\t\tassert right.left is self\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "SimpleChained", "data": "class SimpleChained(ChainedBase, Simple):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "ChainedResurrector", "data": "class ChainedResurrector(ChainedBase, SimpleResurrector):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "SuicidalChained", "data": "class SuicidalChained(ChainedBase, Simple):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tExplicitly break the reference cycle.\n\t\t\"\"\"\n\t\tself.suicided = True\n\t\tself.left = None\n\t\tself.right = None\n\n", "description": "\n\t\tExplicitly break the reference cycle.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "CycleChainFinalizationTest", "data": "class CycleChainFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of a cyclic chain.  These tests are similar in\n\tspirit to the self-cycle tests above, but the collectable object\n\tgraph isn't trivial anymore.\n\t\"\"\"\n\n\tdef build_chain(self, classes):\n\t\tnodes = [cls() for cls in classes]\n\t\tfor i in range(len(nodes)):\n\t\t\tnodes[i].chain(nodes[i-1])\n\t\treturn nodes\n\n\tdef check_non_resurrecting_chain(self, classes):\n\t\tN = len(classes)\n\t\twith SimpleBase.test():\n\t\t\tnodes = self.build_chain(classes)\n\t\t\tids = [id(s) for s in nodes]\n\t\t\twrs = [weakref.ref(s) for s in nodes]\n\t\t\tdel nodes\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertEqual([wr() for wr in wrs], [None] * N)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\n\tdef check_resurrecting_chain(self, classes):\n\t\tN = len(classes)\n\t\twith SimpleBase.test():\n\t\t\tnodes = self.build_chain(classes)\n\t\t\tN = len(nodes)\n\t\t\tids = [id(s) for s in nodes]\n\t\t\tsurvivor_ids = [id(s) for s in nodes if isinstance(s, SimpleResurrector)]\n\t\t\twrs = [weakref.ref(s) for s in nodes]\n\t\t\tdel nodes\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(survivor_ids)\n\t\t\t# XXX desirable?\n\t\t\tself.assertEqual([wr() for wr in wrs], [None] * N)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_homogenous(self):\n\t\tself.check_non_resurrecting_chain([SimpleChained] * 3)\n\n\tdef test_homogenous_resurrect(self):\n\t\tself.check_resurrecting_chain([ChainedResurrector] * 3)\n\n\tdef test_homogenous_suicidal(self):\n\t\tself.check_non_resurrecting_chain([SuicidalChained] * 3)\n\n\tdef test_heterogenous_suicidal_one(self):\n\t\tself.check_non_resurrecting_chain([SuicidalChained, SimpleChained] * 2)\n\n\tdef test_heterogenous_suicidal_two(self):\n\t\tself.check_non_resurrecting_chain(\n\t\t\t[SuicidalChained] * 2 + [SimpleChained] * 2)\n\n\tdef test_heterogenous_resurrect_one(self):\n\t\tself.check_resurrecting_chain([ChainedResurrector, SimpleChained] * 2)\n\n\tdef test_heterogenous_resurrect_two(self):\n\t\tself.check_resurrecting_chain(\n\t\t\t[ChainedResurrector, SimpleChained, SuicidalChained] * 2)\n\n\tdef test_heterogenous_resurrect_three(self):\n\t\tself.check_resurrecting_chain(\n\t\t\t[ChainedResurrector] * 2 + [SimpleChained] * 2 + [SuicidalChained] * 2)\n\n", "description": "\n\tTest finalization of a cyclic chain.  These tests are similar in\n\tspirit to the self-cycle tests above, but the collectable object\n\tgraph isn't trivial anymore.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "LegacyBase", "data": "class LegacyBase(SimpleBase):\n\n\tdef __del__(self):\n\t\ttry:\n\t\t\t# Do not invoke side_effect here, since we are now exercising\n\t\t\t# the tp_del slot.\n\t\t\tif not self._cleaning:\n\t\t\t\tself.del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n\n\tdef __tp_del__(self):\n\t\t\"\"\"\n\t\tLegacy (pre-PEP 442) finalizer, mapped to a tp_del slot.\n\t\t\"\"\"\n\t\ttry:\n\t\t\tif not self._cleaning:\n\t\t\t\tself.tp_del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\t\t\tself.side_effect()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n", "description": "\n\t\tLegacy (pre-PEP 442) finalizer, mapped to a tp_del slot.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "Legacy", "data": "class Legacy(LegacyBase):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "LegacyResurrector", "data": "class LegacyResurrector(LegacyBase):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tResurrect self by storing self in a class-wide list.\n\t\t\"\"\"\n\t\tself.survivors.append(self)\n", "description": "\n\t\tResurrect self by storing self in a class-wide list.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "LegacySelfCycle", "data": "class LegacySelfCycle(SelfCycleBase, LegacyBase):\n\tpass\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "LegacyFinalizationTest", "data": "class LegacyFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of objects with a tp_del.\n\t\"\"\"\n\n\tdef tearDown(self):\n\t\t# These tests need to clean up a bit more, since they create\n\t\t# uncollectable objects.\n\t\tgc.garbage.clear()\n\t\tgc.collect()\n\t\tsuper().tearDown()\n\n\tdef test_legacy(self):\n\t\twith SimpleBase.test():\n\t\t\ts = Legacy()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\n\tdef test_legacy_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = LegacyResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\t# weakrefs are cleared before tp_del is called.\n\t\t\tself.assertIs(wr(), None)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids * 2)\n\t\t\tself.assert_survivors(ids)\n\t\tself.assertIs(wr(), None)\n\n\tdef test_legacy_self_cycle(self):\n\t\t# Self-cycles with legacy finalizers end up in gc.garbage.\n\t\twith SimpleBase.test():\n\t\t\ts = LegacySelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls([])\n\t\t\tself.assert_tp_del_calls([])\n\t\t\tself.assert_survivors([])\n\t\t\tself.assert_garbage(ids)\n\t\t\tself.assertIsNot(wr(), None)\n\t\t\t# Break the cycle to allow collection\n\t\t\tgc.garbage[0].ref = None\n\t\tself.assert_garbage([])\n\t\tself.assertIs(wr(), None)\n\n", "description": "\n\tTest finalization of objects with a tp_del.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}], [{"term": "def", "name": "trim", "data": "def trim(value, num):\n\treturn value[:num]\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "make_data_div", "data": "def make_data_div(value):\n\t\"\"\"A filter that uses a decorator (@mark_safe).\"\"\"\n\treturn '' % value\n\n", "description": "A filter that uses a decorator (@mark_safe).", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "noop", "data": "def noop(value, param=None):\n\t\"\"\"A noop filter that always return its first argument and does nothing with\n\tits second (optional) one.\n\tUseful for testing out whitespace in filter arguments (see #19882).\"\"\"\n\treturn value\n\n", "description": "A noop filter that always return its first argument and does nothing with\n\tits second (optional) one.\n\tUseful for testing out whitespace in filter arguments (see #19882).", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "context_stack_length", "data": "def context_stack_length(context):\n\treturn len(context.dicts)\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "no_params", "data": "def no_params():\n\t\"\"\"Expected no_params __doc__\"\"\"\n\treturn \"no_params - Expected result\"\n\n", "description": "Expected no_params __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "one_param", "data": "def one_param(arg):\n\t\"\"\"Expected one_param __doc__\"\"\"\n\treturn \"one_param - Expected result: %s\" % arg\n\n", "description": "Expected one_param __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "explicit_no_context", "data": "def explicit_no_context(arg):\n\t\"\"\"Expected explicit_no_context __doc__\"\"\"\n\treturn \"explicit_no_context - Expected result: %s\" % arg\n\n", "description": "Expected explicit_no_context __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "no_params_with_context", "data": "def no_params_with_context(context):\n\t\"\"\"Expected no_params_with_context __doc__\"\"\"\n\treturn \"no_params_with_context - Expected result (context value: %s)\" % context['value']\n\n", "description": "Expected no_params_with_context __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "params_and_context", "data": "def params_and_context(context, arg):\n\t\"\"\"Expected params_and_context __doc__\"\"\"\n\treturn \"params_and_context - Expected result (context value: %s): %s\" % (context['value'], arg)\n\n", "description": "Expected params_and_context __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_two_params", "data": "def simple_two_params(one, two):\n\t\"\"\"Expected simple_two_params __doc__\"\"\"\n\treturn \"simple_two_params - Expected result: %s, %s\" % (one, two)\n\n", "description": "Expected simple_two_params __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_keyword_only_param", "data": "def simple_keyword_only_param(*, kwarg):\n\treturn \"simple_keyword_only_param - Expected result: %s\" % kwarg\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_keyword_only_default", "data": "def simple_keyword_only_default(*, kwarg=42):\n\treturn \"simple_keyword_only_default - Expected result: %s\" % kwarg\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_one_default", "data": "def simple_one_default(one, two='hi'):\n\t\"\"\"Expected simple_one_default __doc__\"\"\"\n\treturn \"simple_one_default - Expected result: %s, %s\" % (one, two)\n\n", "description": "Expected simple_one_default __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_unlimited_args", "data": "def simple_unlimited_args(one, two='hi', *args):\n\t\"\"\"Expected simple_unlimited_args __doc__\"\"\"\n\treturn \"simple_unlimited_args - Expected result: %s\" % (\n\t\t', '.join(str(arg) for arg in [one, two] + list(args))\n\t)\n\n", "description": "Expected simple_unlimited_args __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_only_unlimited_args", "data": "def simple_only_unlimited_args(*args):\n\t\"\"\"Expected simple_only_unlimited_args __doc__\"\"\"\n\treturn \"simple_only_unlimited_args - Expected result: %s\" % ', '.join(str(arg) for arg in args)\n\n", "description": "Expected simple_only_unlimited_args __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_unlimited_args_kwargs", "data": "def simple_unlimited_args_kwargs(one, two='hi', *args, **kwargs):\n\t\"\"\"Expected simple_unlimited_args_kwargs __doc__\"\"\"\n\t# Sort the dictionary by key to guarantee the order for testing.\n\tsorted_kwarg = sorted(kwargs.items(), key=operator.itemgetter(0))\n\treturn \"simple_unlimited_args_kwargs - Expected result: %s / %s\" % (\n\t\t', '.join(str(arg) for arg in [one, two] + list(args)),\n\t\t', '.join('%s=%s' % (k, v) for (k, v) in sorted_kwarg)\n\t)\n\n", "description": "Expected simple_unlimited_args_kwargs __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_tag_without_context_parameter", "data": "def simple_tag_without_context_parameter(arg):\n\t\"\"\"Expected simple_tag_without_context_parameter __doc__\"\"\"\n\treturn \"Expected result\"\n\n", "description": "Expected simple_tag_without_context_parameter __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "escape_naive", "data": "def escape_naive(context):\n\t\"\"\"A tag that doesn't even think about escaping issues\"\"\"\n\treturn \"Hello {0}!\".format(context['name'])\n\n", "description": "A tag that doesn't even think about escaping issues", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "escape_explicit", "data": "def escape_explicit(context):\n\t\"\"\"A tag that uses escape explicitly\"\"\"\n\treturn escape(\"Hello {0}!\".format(context['name']))\n\n", "description": "A tag that uses escape explicitly", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "escape_format_html", "data": "def escape_format_html(context):\n\t\"\"\"A tag that uses format_html\"\"\"\n\treturn format_html(\"Hello {0}!\", context['name'])\n\n", "description": "A tag that uses format_html", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "current_app", "data": "def current_app(context):\n\treturn \"%s\" % context.current_app\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "use_l10n", "data": "def use_l10n(context):\n\treturn \"%s\" % context.use_l10n\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "minustwo_overridden_name", "data": "def minustwo_overridden_name(value):\n\treturn value - 2\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "counter", "data": "def counter(parser, token):\n\treturn CounterNode()\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "class", "name": "CounterNode", "data": "class CounterNode(template.Node):\n\tdef __init__(self):\n\t\tself.count = 0\n\n\tdef render(self, context):\n\t\tcount = self.count\n\t\tself.count = count + 1\n\t\treturn count\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}], [], [{"term": "class", "name": "TestSimpleTableWithEnum", "data": "class TestSimpleTableWithEnum(object):\n\t__slots__ = ['_tab']\n\n\t@classmethod\n\tdef GetRootAsTestSimpleTableWithEnum(cls, buf, offset):\n\t\tn = flatbuffers.encode.Get(flatbuffers.packer.uoffset, buf, offset)\n\t\tx = TestSimpleTableWithEnum()\n\t\tx.Init(buf, n + offset)\n\t\treturn x\n\n\t@classmethod\n\tdef TestSimpleTableWithEnumBufferHasIdentifier(cls, buf, offset, size_prefixed=False):\n\t\treturn flatbuffers.util.BufferHasIdentifier(buf, offset, b\"\\x4D\\x4F\\x4E\\x53\", size_prefixed=size_prefixed)\n\n\t# TestSimpleTableWithEnum\n\tdef Init(self, buf, pos):\n\t\tself._tab = flatbuffers.table.Table(buf, pos)\n\n\t# TestSimpleTableWithEnum\n\tdef Color(self):\n\t\to = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(4))\n\t\tif o != 0:\n\t\t\treturn self._tab.Get(flatbuffers.number_types.Uint8Flags, o + self._tab.Pos)\n\t\treturn 2\n", "description": null, "category": "simple", "imports": ["import flatbuffers", "from flatbuffers.compat import import_numpy", "np = import_numpy()"]}, {"term": "def", "name": "TestSimpleTableWithEnumEnd", "data": "def TestSimpleTableWithEnumEnd(builder): return builder.EndObject()\n\n", "description": null, "category": "simple", "imports": ["import flatbuffers", "from flatbuffers.compat import import_numpy", "np = import_numpy()"]}, {"term": "class", "name": "TestSimpleTableWithEnumT", "data": "class TestSimpleTableWithEnumT(object):\n\n\t# TestSimpleTableWithEnumT\n\tdef __init__(self):\n\t\tself.color = 2  # type: int\n\n\t@classmethod\n\tdef InitFromBuf(cls, buf, pos):\n\t\ttestSimpleTableWithEnum = TestSimpleTableWithEnum()\n\t\ttestSimpleTableWithEnum.Init(buf, pos)\n\t\treturn cls.InitFromObj(testSimpleTableWithEnum)\n\n\t@classmethod\n\tdef InitFromObj(cls, testSimpleTableWithEnum):\n\t\tx = TestSimpleTableWithEnumT()\n\t\tx._UnPack(testSimpleTableWithEnum)\n\t\treturn x\n\n\t# TestSimpleTableWithEnumT\n\tdef _UnPack(self, testSimpleTableWithEnum):\n\t\tif testSimpleTableWithEnum is None:\n\t\t\treturn\n\t\tself.color = testSimpleTableWithEnum.Color()\n\n\t# TestSimpleTableWithEnumT\n\tdef Pack(self, builder):\n\t\tTestSimpleTableWithEnumStart(builder)\n\t\tTestSimpleTableWithEnumAddColor(builder, self.color)\n\t\ttestSimpleTableWithEnum = TestSimpleTableWithEnumEnd(builder)\n\t\treturn testSimpleTableWithEnum\n", "description": null, "category": "simple", "imports": ["import flatbuffers", "from flatbuffers.compat import import_numpy", "np = import_numpy()"]}], [], [], [], [], [], [], [], [{"term": "class", "name": "MWSTestCase", "data": "class MWSTestCase(unittest.TestCase):\n\n\tdef setUp(self):\n\t\tself.mws = MWSConnection(Merchant=simple, debug=0)\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_feedlist(self):\n\t\tself.mws.get_feed_submission_list()\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_inbound_status(self):\n\t\tresponse = self.mws.get_inbound_service_status()\n\t\tstatus = response.GetServiceStatusResult.Status\n\t\tself.assertIn(status, ('GREEN', 'GREEN_I', 'YELLOW', 'RED'))\n\n\t@property\n\tdef marketplace(self):\n\t\ttry:\n\t\t\treturn self._marketplace\n\t\texcept AttributeError:\n\t\t\tresponse = self.mws.list_marketplace_participations()\n\t\t\tresult = response.ListMarketplaceParticipationsResult\n\t\t\tself._marketplace = result.ListMarketplaces.Marketplace[0]\n\t\t\treturn self.marketplace\n\n\t@property\n\tdef marketplace_id(self):\n\t\treturn self.marketplace.MarketplaceId\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_marketplace_participations(self):\n\t\tresponse = self.mws.list_marketplace_participations()\n\t\tresult = response.ListMarketplaceParticipationsResult\n\t\tself.assertTrue(result.ListMarketplaces.Marketplace[0].MarketplaceId)\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_get_product_categories_for_asin(self):\n\t\tasin = '144930544X'\n\t\tresponse = self.mws.get_product_categories_for_asin(\n\t\t\tMarketplaceId=self.marketplace_id,\n\t\t\tASIN=asin)\n\t\tself.assertEqual(len(response._result.Self), 3)\n\t\tcategoryids = [x.ProductCategoryId for x in response._result.Self]\n\t\tself.assertSequenceEqual(categoryids, ['285856', '21', '491314'])\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_list_matching_products(self):\n\t\tresponse = self.mws.list_matching_products(\n\t\t\tMarketplaceId=self.marketplace_id,\n\t\t\tQuery='boto')\n\t\tproducts = response._result.Products\n\t\tself.assertTrue(len(products))\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_get_matching_product(self):\n\t\tasin = 'B001UDRNHO'\n\t\tresponse = self.mws.get_matching_product(\n\t\t\tMarketplaceId=self.marketplace_id,\n\t\t\tASINList=[asin])\n\t\tattributes = response._result[0].Product.AttributeSets.ItemAttributes\n\t\tself.assertEqual(attributes[0].Label, 'Serengeti')\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_get_matching_product_for_id(self):\n\t\tasins = ['B001UDRNHO', '144930544X']\n\t\tresponse = self.mws.get_matching_product_for_id(\n\t\t\tMarketplaceId=self.marketplace_id,\n\t\t\tIdType='ASIN',\n\t\t\tIdList=asins)\n\t\tself.assertEqual(len(response._result), 2)\n\t\tfor result in response._result:\n\t\t\tself.assertEqual(len(result.Products.Product), 1)\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_get_lowest_offer_listings_for_asin(self):\n\t\tasin = '144930544X'\n\t\tresponse = self.mws.get_lowest_offer_listings_for_asin(\n\t\t\tMarketplaceId=self.marketplace_id,\n\t\t\tItemCondition='New',\n\t\t\tASINList=[asin])\n\t\tlistings = response._result[0].Product.LowestOfferListings\n\t\tself.assertTrue(len(listings.LowestOfferListing))\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_list_inventory_supply(self):\n\t\tasof = (datetime.today() - timedelta(days=30)).isoformat()\n\t\tresponse = self.mws.list_inventory_supply(QueryStartDateTime=asof,\n\t\t\t\t\t\t\t\t\t\t\t\t  ResponseGroup='Basic')\n\t\tself.assertTrue(hasattr(response._result, 'InventorySupplyList'))\n", "description": null, "category": "simple", "imports": ["from __future__ import print_function", "import sys", "import os", "import os.path", "from datetime import datetime, timedelta", "from boto.mws.connection import MWSConnection", "from tests.compat import unittest"]}], [{"term": "def", "name": "getStatementData", "data": "def getStatementData(userInput):\n\tuser_input = userInput\n\n\ttry:\n\t\tf = open(\"./Annual_Reports/\" + str(user_input).casefold() + \"_report.json\", \"r\")\n\t\tannual_report = json.load(f)\n\t\tf.close()\n\n\texcept:\n\t\tquery = {\n\t\t\t\"query\": {\n\t\t\t\t\"query_string\": {\n\t\t\t\t\t\"query\": \"formType:\\\"10-K\\\" AND companyName:\" + str(user_input)\n\t\t\t\t}\n\t\t\t},\n\t\t\t\"from\": \"0\",\n\t\t\t\"size\": \"20\",\n\t\t\t\"sort\": [{ \"filedAt\": { \"order\": \"desc\" } }]\n\t\t}\n\n\t\tfilings = queryApi.get_filings(query)\n\t\tprint(json.dumps(filings, indent=4))\n\n\t\tif filings['filings'] == []:\n\t\t\tprint(\"Invalid company name!\")\n\t\t\tquit()\n\n\t\tannual_report_url = filings['filings'][0][\"linkToFilingDetails\"]\n\n\t\t# 10-K HTM File URL example\n\t\txbrl_json = xbrlApi.xbrl_to_json(\n\t\t\thtm_url=annual_report_url\n\t\t)\n\n\t\tannual_report = xbrl_json\n\t\tf = open(\"./Annual_Reports/\" + str(user_input).casefold() + \"_report.json\", \"w\")\n\t\tjson.dump(annual_report, f, indent=4, separators=(',', ': '))\n\t\tf.close()\n\n\tsimple_data = {}\n\n\tincome_statement = annual_report[\"StatementsOfIncome\"]\n\n\n\t#retrieving total revenue from income statement\n\tif \"RevenueFromContractWithCustomerExcludingAssessedTax\" in income_statement:\n\t\tfor revenue in income_statement[\"RevenueFromContractWithCustomerExcludingAssessedTax\"]:\n\t\t\tif \"segment\" not in revenue:\n\t\t\t\tsimple_data[\"Revenue\"] = round(float(revenue[\"value\"]), 2)\n\t\t\t\tbreak\n\n\tif \"Revenues\" in income_statement:\n\t\tsimple_data[\"Revenue\"] = round(float(income_statement[\"Revenues\"][0][\"value\"]),2)\n\n\tif \"Revenue\" not in simple_data:\n\t\tsimple_data[\"Revenue\"] = None\n\n\n\t#summing other sources of income\n\tif \"OtherIncome\" in income_statement:\n\t\tsimple_data[\"Other Income\"] = round(float(income_statement[\"OtherIncome\"][0][\"value\"]),2)\n\telse:\n\t\tsimple_data[\"Other Income\"] = 0\n\n\tif \"NonoperatingIncomeExpense\" in income_statement:\n\t\tsimple_data[\"Other Income\"] += round(float(income_statement[\"NonoperatingIncomeExpense\"][0][\"value\"]),2)\n\n\tif \"OtherNonoperatingIncomeExpense\" in income_statement:\n\t\tsimple_data[\"Other Income\"] += float(income_statement[\"OtherNonoperatingIncomeExpense\"][0][\"value\"])\n\n\tif \"InvestmentIncomeInterest\" in income_statement:\n\t\tsimple_data[\"Other Income\"] += float(income_statement[\"InvestmentIncomeInterest\"][0][\"value\"])\n\n\n\n\t#retrieving gross profit from income statement\n\tif \"GrossProfit\" in income_statement:\n\t\tsimple_data[\"Gross Profit\"] =  float(income_statement[\"GrossProfit\"][0][\"value\"])\n\telse:\n\t\tfor key in income_statement:\n\t\t\tif \"CostOf\" in key:\n\t\t\t\tsimple_data[\"Gross Profit\"] = simple_data[\"Revenue\"] - float(income_statement[key][0][\"value\"])\n\n\t#calculating gross profit margin\n\ttry:\n\t\tsimple_data[\"Gross Profit Margin (%)\"] = round(simple_data[\"Gross Profit\"] / simple_data[\"Revenue\"] * 100, 2)\n\texcept:\n\t\tsimple_data[\"Gross Profit Margin (%)\"] = None\n\n\n\n\t#retrieving net income from income statement\n\tif \"NetIncomeLoss\" in income_statement:\n\t\tsimple_data[\"Net Income\"] = float(income_statement[\"NetIncomeLoss\"][0][\"value\"])\n\telse:\n\t\tsimple_data[\"Net Income\"] = None\n\n\n\t#calculating net profit margin\n\ttry:\n\t\tsimple_data[\"Net Profit Margin (%)\"] = round(simple_data[\"Net Income\"] / (simple_data[\"Revenue\"] + simple_data[\"Other Income\"]) * 100, 2)\n\texcept:\n\t\tsimple_data[\"Net Profit Margin (%) \"] = None\n\n\t#retrieving diluted earnings per share\n\tif \"EarningsPerShareDiluted\" in income_statement:\n\t\tsimple_data[\"Diluted Earnings Per Share ($/Share)\"] = \"{:.2f}\".format(float(income_statement[\"EarningsPerShareDiluted\"][0][\"value\"]))\n\telse:\n\t\tsimple_data[\"Diluted Earnings Per Share ($/Share)\"] = None\n\n\t#retrieving common stock outstanding\n\tif \"EntityCommonStockSharesOutstanding\" in annual_report[\"CoverPage\"]:\n\n\t\tsimple_data[\"Common Stock Shares Outstanding\"] = 0\n\n\t\tif type(annual_report[\"CoverPage\"][\"EntityCommonStockSharesOutstanding\"]) == list:\n\t\t\tfor dict in annual_report[\"CoverPage\"][\"EntityCommonStockSharesOutstanding\"]:\n\t\t\t\tsimple_data[\"Common Stock Shares Outstanding\"] += int(dict[\"value\"])\n\t\telse:\n\t\t\tsimple_data[\"Common Stock Shares Outstanding\"] = int(annual_report[\"CoverPage\"][\"EntityCommonStockSharesOutstanding\"][\"value\"])\n\n\telse:\n\t\tsimple_data[\"Common Stock Shares Outstanding\"] = None\n\n\n\t#retrieving data from balance sheet\n\tbalance_sheet = annual_report[\"BalanceSheets\"]\n\n\tif \"AssetsCurrent\" in balance_sheet:\n\t\tsimple_data[\"Current Assets\"] = float(balance_sheet[\"AssetsCurrent\"][0][\"value\"])\n\telse:\n\t\tsimple_data[\"Current Assets\"] = None\n\n\tif \"Assets\" in balance_sheet:\n\t\tsimple_data[\"Total Assets\"] = float(balance_sheet[\"Assets\"][0][\"value\"])\n\telse:\n\t\tsimple_data[\"Total Assets\"] = None\n\n\tif \"LiabilitiesCurrent\" in balance_sheet:\n\t\tsimple_data[\"Current Liabilities\"] = float(balance_sheet[\"LiabilitiesCurrent\"][0][\"value\"])\n\telse:\n\t\tsimple_data[\"Current Liabilities\"] = None\n\n\tif \"Liabilities\" in balance_sheet:\n\t\tsimple_data[\"Total Liablities\"] = float(balance_sheet[\"Liabilities\"][0][\"value\"])\n\telse:\n\t\tsimple_data[\"Total Liablities\"] = None\n\n\tif \"StockholdersEquity\" in balance_sheet:\n\t\tsimple_data[\"Total Stockholders Equity\"] =  float(balance_sheet[\"StockholdersEquity\"][0][\"value\"])\n\telse:\n\t\tsimple_data[\"Total Stockholders Equity\"] = None\n\n\tif \"LiabilitiesAndStockholdersEquity\" in balance_sheet:\n\t\tsimple_data[\"Total Liabilities and Stockholders Equity\"] =  float(balance_sheet[\"LiabilitiesAndStockholdersEquity\"][0][\"value\"])\n\telse:\n\t\tsimple_data[\"Total Liabilities and Stockholders Equity\"] = None\n\n\n\n\t#calculating current ratio\n\ttry:\t\n\t\tsimple_data[\"Current Ratio\"] = round(simple_data[\"Current Assets\"] / simple_data[\"Current Liabilities\"], 2)\n\texcept:\n\t\tsimple_data[\"Current Ratio\"] = None\n\n\t#calculating return on equity\n\ttry:\n\t\tsimple_data[\"Return on Equity\"] = round(simple_data[\"Net Income\"] / simple_data[\"Total Stockholders Equity\"], 2)\n\texcept:\n\t\tsimple_data[\"Return on Equity\"] = None\n\n\ttry:\n\t\tsimple_data[\"Return on Assets\"] = round(simple_data[\"Net Income\"] / simple_data[\"Total Assets\"], 2)\n\texcept:\n\t\tsimple_data[\"Return on Assets\"] = None\n\n\tprint(simple_data)\n\treturn simple_data\n", "description": null, "category": "simple", "imports": ["from sec_api import QueryApi", "from sec_api import XbrlApi", "import json"]}], [{"term": "class", "name": "SimpleGraphTests", "data": "class SimpleGraphTests(unittest.TestCase):\n\tdef checkVertexAdjacency(self, graph, index, arr):\n\t\tself.assertTrue(graph.m_adjacency[index] == arr)\n\n\t\tfor i in range(graph.max_vertex):\n\t\t\tself.assertTrue(graph.m_adjacency[i][index] == arr[index])\n\n\tdef checkEdge(self, graph, v1, v2, value):\n\t\tself.assertTrue(graph.m_adjacency[v1][v2] == value)\n\t\tself.assertTrue(graph.m_adjacency[v2][v1] == value)\n\n\tdef addVertexes(self, graph, arr):\n\t\tfor val in arr:\n\t\t\tgraph.AddVertex(val)\n\n\n\tdef test_AddVertexEmpty(self):\n\t\tgraph = SimpleGraph(5)\n\t\tresult = graph.AddVertex(0)\n\t\tself.assertTrue(result)\n\t\tself.assertTrue(isinstance(graph.vertex[0], Vertex))\n\t\tself.assertTrue(graph.vertex[0].Value == 0)\n\t\tself.checkVertexAdjacency(graph, 0, [0] * 5)\n\n\n\tdef test_AddVertex(self):\n\t\tgraph = SimpleGraph(5)\n\t\tgraph.AddVertex(0)\n\t\tresult = graph.AddVertex(1)\n\t\tself.assertTrue(result)\n\t\tself.assertTrue(isinstance(graph.vertex[1], Vertex))\n\t\tself.assertTrue(graph.vertex[1].Value == 1)\n\t\tself.checkVertexAdjacency(graph, 1, [0] * 5)\n\n\n\tdef test_AddVertexFull(self):\n\t\tgraph = SimpleGraph(2)\n\t\tgraph.AddVertex(0)\n\t\tgraph.AddVertex(1)\n\t\tresult = graph.AddVertex(2)\n\t\tself.assertFalse(result)\n\n\n\tdef test_AddEdge(self):\n\t\tgraph = SimpleGraph(5)\n\t\tself.addVertexes(graph, [0, 1])\n\t\tself.checkEdge(graph, 0, 1, 0)\n\t\tgraph.AddEdge(0, 1)\n\t\tself.checkEdge(graph, 0, 1, 1)\n\n\n\tdef test_RemoveEdge(self):\n\t\tgraph = SimpleGraph(5)\n\t\tself.addVertexes(graph, [0, 1])\n\t\tgraph.AddEdge(0, 1)\n\t\tself.checkEdge(graph, 0, 1, 1)\n\t\tgraph.RemoveEdge(1, 0)\n\t\tself.checkEdge(graph, 0, 1, 0)\n\n\n\tdef test_RemoveVertex(self):\n\t\tgraph = SimpleGraph(5)\n\t\tself.addVertexes(graph, [0, 1, 2])\n\t\tgraph.AddEdge(0, 1)\n\t\tgraph.AddEdge(0, 2)\n\t\tgraph.RemoveVertex(0)\n\t\tself.checkVertexAdjacency(graph, 0, [0] * 5)\n\n\tdef test_DepthFirstSearchSingleVertexWithoutEdge(self):\n\t\tgraph = SimpleGraph(5)\n\t\tgraph.AddVertex(0)\n\t\tresult = graph.DepthFirstSearch(0, 0)\n\t\tself.assertTrue(result == [], result)\n\n\n\tdef test_DepthFirstSearchSingleVertexWithEdge(self):\n\t\tgraph = SimpleGraph(5)\n\t\tgraph.AddVertex(0)\n\t\tgraph.AddEdge(0, 0)\n\t\tresult = graph.DepthFirstSearch(0, 0)\n\t\tself.assertTrue(result == [graph.vertex[0], graph.vertex[0]], result)\n\n\n\tdef test_DepthFirstSearchTwoVertexWithoutEdge(self):\n\t\tgraph = SimpleGraph(5)\n\t\tself.addVertexes(graph, [0, 1])\n\t\tresult = graph.DepthFirstSearch(0, 1)\n\t\tself.assertTrue(result == [], result)\n\n\n\tdef test_DepthFirstSearchTwoVertexWithEdge(self):\n\t\tgraph = SimpleGraph(5)\n\t\tself.addVertexes(graph, [0, 1])\n\t\tgraph.AddEdge(0, 1)\n\t\tresult = graph.DepthFirstSearch(0, 1)\n\t\tself.assertTrue(result == [graph.vertex[0], graph.vertex[1]], result)\n\n\n\tdef test_DepthFirstSearchThreeVertexWithoutEdge(self):\n\t\tgraph = SimpleGraph(5)\n\t\tself.addVertexes(graph, [0, 1, 2])\n\t\tgraph.AddEdge(0, 1)\n\t\tresult = graph.DepthFirstSearch(0, 2)\n\t\tself.assertTrue(result == [], result)\n\n\tdef test_DepthFirstSearchThreeVertexWithEdge(self):\n\t\tgraph = SimpleGraph(5)\n\t\tself.addVertexes(graph, [0, 1, 2])\n\t\tgraph.AddEdge(0, 1)\n\t\tgraph.AddEdge(0, 2)\n\t\tresult = graph.DepthFirstSearch(0, 2)\n\t\tself.assertTrue(result == [graph.vertex[0], graph.vertex[2]], result)\n\n\n\tdef test_DepthFirstSearchThreeVertexWithTwoEdges(self):\n\t\tgraph = SimpleGraph(5)\n\t\tself.addVertexes(graph, [0, 1, 2])\n\t\tgraph.AddEdge(0, 1)\n\t\tgraph.AddEdge(1, 2)\n\t\tresult = graph.DepthFirstSearch(0, 2)\n\t\tself.assertTrue(result == [graph.vertex[0], graph.vertex[1], graph.vertex[2]], result)\n\t\t\n\t\t\n\tdef test_BreadthFirstSearchSingleVertexWithoutEdge(self):\n\t\tgraph = SimpleGraph(5)\n\t\tgraph.AddVertex(0)\n\t\tresult = graph.BreadthFirstSearch(0, 0)\n\t\tself.assertTrue(result == [], result)\n\n\n\tdef test_BreadthFirstSearchSingleVertexWithEdge(self):\n\t\tgraph = SimpleGraph(5)\n\t\tgraph.AddVertex(0)\n\t\tgraph.AddEdge(0, 0)\n\t\tresult = graph.BreadthFirstSearch(0, 0)\n\t\tself.assertTrue(result == [graph.vertex[0]], result)\n\n\n\tdef test_BreadthFirstSearchTwoVertexWithoutEdge(self):\n\t\tgraph = SimpleGraph(5)\n\t\tself.addVertexes(graph, [0, 1])\n\t\tresult = graph.BreadthFirstSearch(0, 1)\n\t\tself.assertTrue(result == [], result)\n\n\n\tdef test_BreadthFirstSearchTwoVertexWithEdge(self):\n\t\tgraph = SimpleGraph(5)\n\t\tself.addVertexes(graph, [0, 1])\n\t\tgraph.AddEdge(0, 1)\n\t\tresult = graph.BreadthFirstSearch(0, 1)\n\t\tself.assertTrue(result == [graph.vertex[0], graph.vertex[1]], result)\n\n\n\tdef test_BreadthFirstSearchThreeVertexWithoutEdge(self):\n\t\tgraph = SimpleGraph(5)\n\t\tself.addVertexes(graph, [0, 1, 2])\n\t\tgraph.AddEdge(0, 1)\n\t\tresult = graph.BreadthFirstSearch(0, 2)\n\t\tself.assertTrue(result == [], result)\n\t\t\n\n\tdef test_BreadthFirstSearchThreeVertexWithEdge(self):\n\t\tgraph = SimpleGraph(5)\n\t\tself.addVertexes(graph, [0, 1, 2])\n\t\tgraph.AddEdge(0, 1)\n\t\tgraph.AddEdge(0, 2)\n\t\tresult = graph.BreadthFirstSearch(0, 2)\n\t\tself.assertTrue(result == [graph.vertex[0], graph.vertex[2]], result)\n\n\n\tdef test_BreadthFirstSearchThreeVertexWithTwoEdges(self):\n\t\tgraph = SimpleGraph(5)\n\t\tself.addVertexes(graph, [0, 1, 2])\n\t\tgraph.AddEdge(0, 1)\n\t\tgraph.AddEdge(1, 2)\n\t\tresult = graph.BreadthFirstSearch(0, 2)\n\t\tself.assertTrue(result == [graph.vertex[0], graph.vertex[1], graph.vertex[2]], result)\n\t\t\n\t\t\n\tdef test_BreadthFirstSearchWithDifferentPaths(self):\n\t\tgraph = SimpleGraph(5)\n\t\tself.addVertexes(graph, [0, 1, 2, 3, 4])\n\t\tgraph.AddEdge(0, 1)\n\t\tgraph.AddEdge(1, 2)\n\t\tgraph.AddEdge(2, 3)\n\t\tgraph.AddEdge(3, 4)\n\t\tgraph.AddEdge(4, 0)\n\t\tresult = graph.BreadthFirstSearch(0, 2)\n\t\tself.assertTrue(result == [graph.vertex[0], graph.vertex[1], graph.vertex[2]], result)\n\t\t\n\tdef test_BreadthFirstSearchWithCycle(self):\n\t\tgraph = SimpleGraph(5)\n\t\tself.addVertexes(graph, [0, 1, 2])\n\t\tgraph.AddEdge(0, 1)\n\t\tgraph.AddEdge(1, 1)\n\t\tgraph.AddEdge(1, 2)\n\t\tresult = graph.BreadthFirstSearch(0, 2)\n\t\tself.assertTrue(result == [graph.vertex[0], graph.vertex[1], graph.vertex[2]], result)\n\n\tdef test_WeakVerticesEmpty(self):\n\t\tgraph = SimpleGraph(5)\n\t\tself.addVertexes(graph, [])\n\t\tresult = graph.WeakVertices()\n\t\tself.assertTrue(result == [], result)\n\n\n\tdef test_WeakVerticesOneWeekVertex(self):\n\t\tgraph = SimpleGraph(5)\n\t\tself.addVertexes(graph, [0])\n\t\tresult = graph.WeakVertices()\n\t\tself.assertTrue(result == [graph.vertex[0]], result)\n\n\n\tdef test_WeakVerticesTwoWeekVertices(self):\n\t\tgraph = SimpleGraph(5)\n\t\tself.addVertexes(graph, [0, 1])\n\t\tresult = graph.WeakVertices()\n\t\tself.assertTrue(result == [graph.vertex[0], graph.vertex[1]], result)\n\n\n\tdef test_WeakVerticesThreeWeekVertices(self):\n\t\tgraph = SimpleGraph(5)\n\t\tself.addVertexes(graph, [0, 1, 2])\n\t\tresult = graph.WeakVertices()\n\t\tself.assertTrue(result == [graph.vertex[0], graph.vertex[1], graph.vertex[2]], result)\n\n\n\tdef test_WeakVerticesThreeStrongVertices(self):\n\t\tgraph = SimpleGraph(5)\n\t\tself.addVertexes(graph, [0, 1, 2])\n\t\tgraph.AddEdge(0, 1)\n\t\tgraph.AddEdge(1, 2)\n\t\tgraph.AddEdge(2, 0)\n\t\tresult = graph.WeakVertices()\n\t\tself.assertTrue(result == [], result)\n\n\n\tdef test_WeakVerticesFourVerticesWithTriangle(self):\n\t\tgraph = SimpleGraph(5)\n\t\tself.addVertexes(graph, [0, 1, 2, 3])\n\t\tgraph.AddEdge(0, 1)\n\t\tgraph.AddEdge(1, 2)\n\t\tgraph.AddEdge(2, 0)\n\t\tresult = graph.WeakVertices()\n\t\tself.assertTrue(result == [graph.vertex[3]], result)\n\n\n\tdef test_WeakVerticesFiveVerticesWithTriangle(self):\n\t\tgraph = SimpleGraph(5)\n\t\tself.addVertexes(graph, [0, 1, 2, 3, 4])\n\t\tgraph.AddEdge(1, 2)\n\t\tgraph.AddEdge(2, 4)\n\t\tgraph.AddEdge(4, 1)\n\t\tresult = graph.WeakVertices()\n\t\tself.assertTrue(result == [graph.vertex[0], graph.vertex[3]], result)\n\n\n\tdef test_WeakVerticesFiveVerticesWithTwoTriangles(self):\n\t\tgraph = SimpleGraph(5)\n\t\tself.addVertexes(graph, [0, 1, 2, 3, 4])\n\t\tgraph.AddEdge(0, 1)\n\t\tgraph.AddEdge(1, 2)\n\t\tgraph.AddEdge(2, 0)\n\t\tgraph.AddEdge(0, 3)\n\t\tgraph.AddEdge(0, 4)\n\t\tgraph.AddEdge(3, 4)\n\t\tresult = graph.WeakVertices()\n\t\tself.assertTrue(result == [], result)\n\n\n\tdef test_WeakVerticesSixVerticesWithOneWeekVertex(self):\n\t\tgraph = SimpleGraph(6)\n\t\tself.addVertexes(graph, [0, 1, 2, 3, 4, 5])\n\t\tgraph.AddEdge(0, 1)\n\t\tgraph.AddEdge(1, 2)\n\t\tgraph.AddEdge(2, 0)\n\t\tgraph.AddEdge(0, 3)\n\t\tgraph.AddEdge(0, 4)\n\t\tgraph.AddEdge(3, 4)\n\t\tgraph.AddEdge(1, 5)\n\t\tresult = graph.WeakVertices()\n\t\tself.assertTrue(result == [graph.vertex[5]], result)\n\n", "description": null, "category": "simple", "imports": ["import unittest", "from simple_graph import Vertex, SimpleGraph"]}], [{"term": "def", "name": "fwith_tp_del", "data": "\tdef with_tp_del(cls):\n\t\tclass C(object):\n\t\t\tdef __new__(cls, *args, **kwargs):\n\t\t\t\traise TypeError('requires _testcapi.with_tp_del')\n\t\treturn C\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "classNonGCSimpleBase:", "data": "class NonGCSimpleBase:\n\t\"\"\"\n\tThe base class for all the objects under test, equipped with various\n\ttesting features.\n\t\"\"\"\n\n\tsurvivors = []\n\tdel_calls = []\n\ttp_del_calls = []\n\terrors = []\n\n\t_cleaning = False\n\n\t__slots__ = ()\n\n\t@classmethod\n\tdef _cleanup(cls):\n\t\tcls.survivors.clear()\n\t\tcls.errors.clear()\n\t\tgc.garbage.clear()\n\t\tgc.collect()\n\t\tcls.del_calls.clear()\n\t\tcls.tp_del_calls.clear()\n\n\t@classmethod\n\t@contextlib.contextmanager\n\tdef test(cls):\n\t\t\"\"\"\n\t\tA context manager to use around all finalization tests.\n\t\t\"\"\"\n\t\twith support.disable_gc():\n\t\t\tcls.del_calls.clear()\n\t\t\tcls.tp_del_calls.clear()\n\t\t\tNonGCSimpleBase._cleaning = False\n\t\t\ttry:\n\t\t\t\tyield\n\t\t\t\tif cls.errors:\n\t\t\t\t\traise cls.errors[0]\n\t\t\tfinally:\n\t\t\t\tNonGCSimpleBase._cleaning = True\n\t\t\t\tcls._cleanup()\n\n\tdef check_sanity(self):\n\t\t\"\"\"\n\t\tCheck the object is sane (non-broken).\n\t\t\"\"\"\n\n\tdef __del__(self):\n\t\t\"\"\"\n\t\tPEP 442 finalizer.  Record that this was called, check the\n\t\tobject is in a sane state, and invoke a side effect.\n\t\t\"\"\"\n\t\ttry:\n\t\t\tif not self._cleaning:\n\t\t\t\tself.del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\t\t\tself.side_effect()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tA side effect called on destruction.\n\t\t\"\"\"\n\n", "description": "\n\tThe base class for all the objects under test, equipped with various\n\ttesting features.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleBase", "data": "class SimpleBase(NonGCSimpleBase):\n\n\tdef __init__(self):\n\t\tself.id_ = id(self)\n\n\tdef check_sanity(self):\n\t\tassert self.id_ == id(self)\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "NonGC", "data": "class NonGC(NonGCSimpleBase):\n\t__slots__ = ()\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "NonGCResurrector", "data": "class NonGCResurrector(NonGCSimpleBase):\n\t__slots__ = ()\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tResurrect self by storing self in a class-wide list.\n\t\t\"\"\"\n\t\tself.survivors.append(self)\n", "description": "\n\t\tResurrect self by storing self in a class-wide list.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "Simple", "data": "class Simple(SimpleBase):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleResurrector", "data": "class SimpleResurrector(NonGCResurrector, SimpleBase):\n\tpass\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "classTestBase:", "data": "class TestBase:\n\n\tdef setUp(self):\n\t\tself.old_garbage = gc.garbage[:]\n\t\tgc.garbage[:] = []\n\n\tdef tearDown(self):\n\t\t# None of the tests here should put anything in gc.garbage\n\t\ttry:\n\t\t\tself.assertEqual(gc.garbage, [])\n\t\tfinally:\n\t\t\tdel self.old_garbage\n\t\t\tgc.collect()\n\n\tdef assert_del_calls(self, ids):\n\t\tself.assertEqual(sorted(SimpleBase.del_calls), sorted(ids))\n\n\tdef assert_tp_del_calls(self, ids):\n\t\tself.assertEqual(sorted(SimpleBase.tp_del_calls), sorted(ids))\n\n\tdef assert_survivors(self, ids):\n\t\tself.assertEqual(sorted(id(x) for x in SimpleBase.survivors), sorted(ids))\n\n\tdef assert_garbage(self, ids):\n\t\tself.assertEqual(sorted(id(x) for x in gc.garbage), sorted(ids))\n\n\tdef clear_survivors(self):\n\t\tSimpleBase.survivors.clear()\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleFinalizationTest", "data": "class SimpleFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization without refcycles.\n\t\"\"\"\n\n\tdef test_simple(self):\n\t\twith SimpleBase.test():\n\t\t\ts = Simple()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_simple_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = SimpleResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\tself.assertIsNot(wr(), None)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\tself.assertIs(wr(), None)\n\n\tdef test_non_gc(self):\n\t\twith SimpleBase.test():\n\t\t\ts = NonGC()\n\t\t\tself.assertFalse(gc.is_tracked(s))\n\t\t\tids = [id(s)]\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_non_gc_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = NonGCResurrector()\n\t\t\tself.assertFalse(gc.is_tracked(s))\n\t\t\tids = [id(s)]\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids * 2)\n\t\t\tself.assert_survivors(ids)\n\n", "description": "\n\tTest finalization without refcycles.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "classSelfCycleBase:", "data": "class SelfCycleBase:\n\n\tdef __init__(self):\n\t\tsuper().__init__()\n\t\tself.ref = self\n\n\tdef check_sanity(self):\n\t\tsuper().check_sanity()\n\t\tassert self.ref is self\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleSelfCycle", "data": "class SimpleSelfCycle(SelfCycleBase, Simple):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SelfCycleResurrector", "data": "class SelfCycleResurrector(SelfCycleBase, SimpleResurrector):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SuicidalSelfCycle", "data": "class SuicidalSelfCycle(SelfCycleBase, Simple):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tExplicitly break the reference cycle.\n\t\t\"\"\"\n\t\tself.ref = None\n\n", "description": "\n\t\tExplicitly break the reference cycle.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SelfCycleFinalizationTest", "data": "class SelfCycleFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of an object having a single cyclic reference to\n\titself.\n\t\"\"\"\n\n\tdef test_simple(self):\n\t\twith SimpleBase.test():\n\t\t\ts = SimpleSelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_simple_resurrect(self):\n\t\t# Test that __del__ can resurrect the object being finalized.\n\t\twith SimpleBase.test():\n\t\t\ts = SelfCycleResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\t# XXX is this desirable?\n\t\t\tself.assertIs(wr(), None)\n\t\t\t# When trying to destroy the object a second time, __del__\n\t\t\t# isn't called anymore (and the object isn't resurrected).\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\n\tdef test_simple_suicide(self):\n\t\t# Test the GC is able to deal with an object that kills its last\n\t\t# reference during __del__.\n\t\twith SimpleBase.test():\n\t\t\ts = SuicidalSelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\n", "description": "\n\tTest finalization of an object having a single cyclic reference to\n\titself.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "classChainedBase:", "data": "class ChainedBase:\n\n\tdef chain(self, left):\n\t\tself.suicided = False\n\t\tself.left = left\n\t\tleft.right = self\n\n\tdef check_sanity(self):\n\t\tsuper().check_sanity()\n\t\tif self.suicided:\n\t\t\tassert self.left is None\n\t\t\tassert self.right is None\n\t\telse:\n\t\t\tleft = self.left\n\t\t\tif left.suicided:\n\t\t\t\tassert left.right is None\n\t\t\telse:\n\t\t\t\tassert left.right is self\n\t\t\tright = self.right\n\t\t\tif right.suicided:\n\t\t\t\tassert right.left is None\n\t\t\telse:\n\t\t\t\tassert right.left is self\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleChained", "data": "class SimpleChained(ChainedBase, Simple):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "ChainedResurrector", "data": "class ChainedResurrector(ChainedBase, SimpleResurrector):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SuicidalChained", "data": "class SuicidalChained(ChainedBase, Simple):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tExplicitly break the reference cycle.\n\t\t\"\"\"\n\t\tself.suicided = True\n\t\tself.left = None\n\t\tself.right = None\n\n", "description": "\n\t\tExplicitly break the reference cycle.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "CycleChainFinalizationTest", "data": "class CycleChainFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of a cyclic chain.  These tests are similar in\n\tspirit to the self-cycle tests above, but the collectable object\n\tgraph isn't trivial anymore.\n\t\"\"\"\n\n\tdef build_chain(self, classes):\n\t\tnodes = [cls() for cls in classes]\n\t\tfor i in range(len(nodes)):\n\t\t\tnodes[i].chain(nodes[i-1])\n\t\treturn nodes\n\n\tdef check_non_resurrecting_chain(self, classes):\n\t\tN = len(classes)\n\t\twith SimpleBase.test():\n\t\t\tnodes = self.build_chain(classes)\n\t\t\tids = [id(s) for s in nodes]\n\t\t\twrs = [weakref.ref(s) for s in nodes]\n\t\t\tdel nodes\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertEqual([wr() for wr in wrs], [None] * N)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\n\tdef check_resurrecting_chain(self, classes):\n\t\tN = len(classes)\n\t\twith SimpleBase.test():\n\t\t\tnodes = self.build_chain(classes)\n\t\t\tN = len(nodes)\n\t\t\tids = [id(s) for s in nodes]\n\t\t\tsurvivor_ids = [id(s) for s in nodes if isinstance(s, SimpleResurrector)]\n\t\t\twrs = [weakref.ref(s) for s in nodes]\n\t\t\tdel nodes\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(survivor_ids)\n\t\t\t# XXX desirable?\n\t\t\tself.assertEqual([wr() for wr in wrs], [None] * N)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_homogenous(self):\n\t\tself.check_non_resurrecting_chain([SimpleChained] * 3)\n\n\tdef test_homogenous_resurrect(self):\n\t\tself.check_resurrecting_chain([ChainedResurrector] * 3)\n\n\tdef test_homogenous_suicidal(self):\n\t\tself.check_non_resurrecting_chain([SuicidalChained] * 3)\n\n\tdef test_heterogenous_suicidal_one(self):\n\t\tself.check_non_resurrecting_chain([SuicidalChained, SimpleChained] * 2)\n\n\tdef test_heterogenous_suicidal_two(self):\n\t\tself.check_non_resurrecting_chain(\n\t\t\t[SuicidalChained] * 2 + [SimpleChained] * 2)\n\n\tdef test_heterogenous_resurrect_one(self):\n\t\tself.check_resurrecting_chain([ChainedResurrector, SimpleChained] * 2)\n\n\tdef test_heterogenous_resurrect_two(self):\n\t\tself.check_resurrecting_chain(\n\t\t\t[ChainedResurrector, SimpleChained, SuicidalChained] * 2)\n\n\tdef test_heterogenous_resurrect_three(self):\n\t\tself.check_resurrecting_chain(\n\t\t\t[ChainedResurrector] * 2 + [SimpleChained] * 2 + [SuicidalChained] * 2)\n\n", "description": "\n\tTest finalization of a cyclic chain.  These tests are similar in\n\tspirit to the self-cycle tests above, but the collectable object\n\tgraph isn't trivial anymore.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "LegacyBase", "data": "class LegacyBase(SimpleBase):\n\n\tdef __del__(self):\n\t\ttry:\n\t\t\t# Do not invoke side_effect here, since we are now exercising\n\t\t\t# the tp_del slot.\n\t\t\tif not self._cleaning:\n\t\t\t\tself.del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n\n\tdef __tp_del__(self):\n\t\t\"\"\"\n\t\tLegacy (pre-PEP 442) finalizer, mapped to a tp_del slot.\n\t\t\"\"\"\n\t\ttry:\n\t\t\tif not self._cleaning:\n\t\t\t\tself.tp_del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\t\t\tself.side_effect()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n", "description": "\n\t\tLegacy (pre-PEP 442) finalizer, mapped to a tp_del slot.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "Legacy", "data": "class Legacy(LegacyBase):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "LegacyResurrector", "data": "class LegacyResurrector(LegacyBase):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tResurrect self by storing self in a class-wide list.\n\t\t\"\"\"\n\t\tself.survivors.append(self)\n", "description": "\n\t\tResurrect self by storing self in a class-wide list.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "LegacySelfCycle", "data": "class LegacySelfCycle(SelfCycleBase, LegacyBase):\n\tpass\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "LegacyFinalizationTest", "data": "class LegacyFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of objects with a tp_del.\n\t\"\"\"\n\n\tdef tearDown(self):\n\t\t# These tests need to clean up a bit more, since they create\n\t\t# uncollectable objects.\n\t\tgc.garbage.clear()\n\t\tgc.collect()\n\t\tsuper().tearDown()\n\n\tdef test_legacy(self):\n\t\twith SimpleBase.test():\n\t\t\ts = Legacy()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\n\tdef test_legacy_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = LegacyResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\t# weakrefs are cleared before tp_del is called.\n\t\t\tself.assertIs(wr(), None)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids * 2)\n\t\t\tself.assert_survivors(ids)\n\t\tself.assertIs(wr(), None)\n\n\tdef test_legacy_self_cycle(self):\n\t\t# Self-cycles with legacy finalizers end up in gc.garbage.\n\t\twith SimpleBase.test():\n\t\t\ts = LegacySelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls([])\n\t\t\tself.assert_tp_del_calls([])\n\t\t\tself.assert_survivors([])\n\t\t\tself.assert_garbage(ids)\n\t\t\tself.assertIsNot(wr(), None)\n\t\t\t# Break the cycle to allow collection\n\t\t\tgc.garbage[0].ref = None\n\t\tself.assert_garbage([])\n\t\tself.assertIs(wr(), None)\n\n", "description": "\n\tTest finalization of objects with a tp_del.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}], [{"term": "class", "name": "TestIsSimplePath", "data": "class TestIsSimplePath(object):\n\t\"\"\"Unit tests for the\n\t:func:`networkx.algorithms.simple_paths.is_simple_path` function.\n\n\t\"\"\"\n\n\tdef test_empty_list(self):\n\t\t\"\"\"Tests that the empty list is not a valid path, since there\n\t\tshould be a one-to-one correspondence between paths as lists of\n\t\tnodes and paths as lists of edges.\n\n\t\t\"\"\"\n\t\tG = nx.trivial_graph()\n\t\tassert_false(nx.is_simple_path(G, []))\n\n\tdef test_trivial_path(self):\n\t\t\"\"\"Tests that the trivial path, a path of length one, is\n\t\tconsidered a simple path in a graph.\n\n\t\t\"\"\"\n\t\tG = nx.trivial_graph()\n\t\tassert_true(nx.is_simple_path(G, [0]))\n\n\tdef test_trivial_nonpath(self):\n\t\t\"\"\"Tests that a list whose sole element is an object not in the\n\t\tgraph is not considered a simple path.\n\n\t\t\"\"\"\n\t\tG = nx.trivial_graph()\n\t\tassert_false(nx.is_simple_path(G, ['not a node']))\n\n\tdef test_simple_path(self):\n\t\tG = nx.path_graph(2)\n\t\tassert_true(nx.is_simple_path(G, [0, 1]))\n\n\tdef test_non_simple_path(self):\n\t\tG = nx.path_graph(2)\n\t\tassert_false(nx.is_simple_path(G, [0, 1, 0]))\n\n\tdef test_cycle(self):\n\t\tG = nx.cycle_graph(3)\n\t\tassert_false(nx.is_simple_path(G, [0, 1, 2, 0]))\n\n\tdef test_missing_node(self):\n\t\tG = nx.path_graph(2)\n\t\tassert_false(nx.is_simple_path(G, [0, 2]))\n\n\tdef test_directed_path(self):\n\t\tG = nx.DiGraph([(0, 1), (1, 2)])\n\t\tassert_true(nx.is_simple_path(G, [0, 1, 2]))\n\n\tdef test_directed_non_path(self):\n\t\tG = nx.DiGraph([(0, 1), (1, 2)])\n\t\tassert_false(nx.is_simple_path(G, [2, 1, 0]))\n\n\tdef test_directed_cycle(self):\n\t\tG = nx.DiGraph([(0, 1), (1, 2), (2, 0)])\n\t\tassert_false(nx.is_simple_path(G, [0, 1, 2, 0]))\n\n\tdef test_multigraph(self):\n\t\tG = nx.MultiGraph([(0, 1), (0, 1)])\n\t\tassert_true(nx.is_simple_path(G, [0, 1]))\n\n\tdef test_multidigraph(self):\n\t\tG = nx.MultiDiGraph([(0, 1), (0, 1), (1, 0), (1, 0)])\n\t\tassert_true(nx.is_simple_path(G, [0, 1]))\n\n", "description": "Unit tests for the\n\t:func:`networkx.algorithms.simple_paths.is_simple_path` function.\n\n\t", "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths", "data": "def test_all_simple_paths():\n\tG = nx.path_graph(4)\n\tpaths = nx.all_simple_paths(G, 0, 3)\n\tassert_equal(set(tuple(p) for p in paths), {(0, 1, 2, 3)})\n\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_cutoff", "data": "def test_all_simple_paths_cutoff():\n\tG = nx.complete_graph(4)\n\tpaths = nx.all_simple_paths(G, 0, 1, cutoff=1)\n\tassert_equal(set(tuple(p) for p in paths), {(0, 1)})\n\tpaths = nx.all_simple_paths(G, 0, 1, cutoff=2)\n\tassert_equal(set(tuple(p) for p in paths), {(0, 1), (0, 2, 1), (0, 3, 1)})\n\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_multigraph", "data": "def test_all_simple_paths_multigraph():\n\tG = nx.MultiGraph([(1, 2), (1, 2)])\n\tpaths = nx.all_simple_paths(G, 1, 2)\n\tassert_equal(set(tuple(p) for p in paths), {(1, 2), (1, 2)})\n\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_multigraph_with_cutoff", "data": "def test_all_simple_paths_multigraph_with_cutoff():\n\tG = nx.MultiGraph([(1, 2), (1, 2), (1, 10), (10, 2)])\n\tpaths = nx.all_simple_paths(G, 1, 2, cutoff=1)\n\tassert_equal(set(tuple(p) for p in paths), {(1, 2), (1, 2)})\n\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_directed", "data": "def test_all_simple_paths_directed():\n\tG = nx.DiGraph()\n\tnx.add_path(G, [1, 2, 3])\n\tnx.add_path(G, [3, 2, 1])\n\tpaths = nx.all_simple_paths(G, 1, 3)\n\tassert_equal(set(tuple(p) for p in paths), {(1, 2, 3)})\n\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_empty", "data": "def test_all_simple_paths_empty():\n\tG = nx.path_graph(4)\n\tpaths = nx.all_simple_paths(G, 0, 3, cutoff=2)\n\tassert_equal(list(list(p) for p in paths), [])\n\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "hamiltonian_path", "data": "def hamiltonian_path(G, source):\n\tsource = arbitrary_element(G)\n\tneighbors = set(G[source]) - set([source])\n\tn = len(G)\n\tfor target in neighbors:\n\t\tfor path in nx.all_simple_paths(G, source, target):\n\t\t\tif len(path) == n:\n\t\t\t\tyield path\n\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_hamiltonian_path", "data": "def test_hamiltonian_path():\n\tfrom itertools import permutations\n\tG = nx.complete_graph(4)\n\tpaths = [list(p) for p in hamiltonian_path(G, 0)]\n\texact = [[0] + list(p) for p in permutations([1, 2, 3], 3)]\n\tassert_equal(sorted(paths), sorted(exact))\n\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_cutoff_zero", "data": "def test_cutoff_zero():\n\tG = nx.complete_graph(4)\n\tpaths = nx.all_simple_paths(G, 0, 3, cutoff=0)\n\tassert_equal(list(list(p) for p in paths), [])\n\tpaths = nx.all_simple_paths(nx.MultiGraph(G), 0, 3, cutoff=0)\n\tassert_equal(list(list(p) for p in paths), [])\n\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_source_missing", "data": "def test_source_missing():\n\tG = nx.Graph()\n\tnx.add_path(G, [1, 2, 3])\n\tpaths = list(nx.all_simple_paths(nx.MultiGraph(G), 0, 3))\n\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_target_missing", "data": "def test_target_missing():\n\tG = nx.Graph()\n\tnx.add_path(G, [1, 2, 3])\n\tpaths = list(nx.all_simple_paths(nx.MultiGraph(G), 1, 4))\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_shortest_simple_paths", "data": "def test_shortest_simple_paths():\n\tG = cnlti(nx.grid_2d_graph(4, 4), first_label=1, ordering=\"sorted\")\n\tpaths = nx.shortest_simple_paths(G, 1, 12)\n\tassert_equal(next(paths), [1, 2, 3, 4, 8, 12])\n\tassert_equal(next(paths), [1, 5, 6, 7, 8, 12])\n\tassert_equal([len(path) for path in nx.shortest_simple_paths(G, 1, 12)],\n\t\t\t\t sorted([len(path) for path in nx.all_simple_paths(G, 1, 12)]))\n\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_shortest_simple_paths_directed", "data": "def test_shortest_simple_paths_directed():\n\tG = nx.cycle_graph(7, create_using=nx.DiGraph())\n\tpaths = nx.shortest_simple_paths(G, 0, 3)\n\tassert_equal([path for path in paths], [[0, 1, 2, 3]])\n\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_Greg_Bernstein", "data": "def test_Greg_Bernstein():\n\tg1 = nx.Graph()\n\tg1.add_nodes_from([\"N0\", \"N1\", \"N2\", \"N3\", \"N4\"])\n\tg1.add_edge(\"N4\", \"N1\", weight=10.0, capacity=50, name=\"L5\")\n\tg1.add_edge(\"N4\", \"N0\", weight=7.0, capacity=40, name=\"L4\")\n\tg1.add_edge(\"N0\", \"N1\", weight=10.0, capacity=45, name=\"L1\")\n\tg1.add_edge(\"N3\", \"N0\", weight=10.0, capacity=50, name=\"L0\")\n\tg1.add_edge(\"N2\", \"N3\", weight=12.0, capacity=30, name=\"L2\")\n\tg1.add_edge(\"N1\", \"N2\", weight=15.0, capacity=42, name=\"L3\")\n\tsolution = [['N1', 'N0', 'N3'], ['N1', 'N2', 'N3'], ['N1', 'N4', 'N0', 'N3']]\n\tresult = list(nx.shortest_simple_paths(g1, 'N1', 'N3', weight='weight'))\n\tassert_equal(result, solution)\n\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_weighted_shortest_simple_path", "data": "def test_weighted_shortest_simple_path():\n\tdef cost_func(path):\n\t\treturn sum(G.adj[u][v]['weight'] for (u, v) in zip(path, path[1:]))\n\tG = nx.complete_graph(5)\n\tweight = {(u, v): random.randint(1, 100) for (u, v) in G.edges()}\n\tnx.set_edge_attributes(G, weight, 'weight')\n\tcost = 0\n\tfor path in nx.shortest_simple_paths(G, 0, 3, weight='weight'):\n\t\tthis_cost = cost_func(path)\n\t\tassert_true(cost <= this_cost)\n\t\tcost = this_cost\n\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_directed_weighted_shortest_simple_path", "data": "def test_directed_weighted_shortest_simple_path():\n\tdef cost_func(path):\n\t\treturn sum(G.adj[u][v]['weight'] for (u, v) in zip(path, path[1:]))\n\tG = nx.complete_graph(5)\n\tG = G.to_directed()\n\tweight = {(u, v): random.randint(1, 100) for (u, v) in G.edges()}\n\tnx.set_edge_attributes(G, weight, 'weight')\n\tcost = 0\n\tfor path in nx.shortest_simple_paths(G, 0, 3, weight='weight'):\n\t\tthis_cost = cost_func(path)\n\t\tassert_true(cost <= this_cost)\n\t\tcost = this_cost\n\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_weight_name", "data": "def test_weight_name():\n\tG = nx.cycle_graph(7)\n\tnx.set_edge_attributes(G, 1, 'weight')\n\tnx.set_edge_attributes(G, 1, 'foo')\n\tG.adj[1][2]['foo'] = 7\n\tpaths = list(nx.shortest_simple_paths(G, 0, 3, weight='foo'))\n\tsolution = [[0, 6, 5, 4, 3], [0, 1, 2, 3]]\n\tassert_equal(paths, solution)\n\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_ssp_source_missing", "data": "def test_ssp_source_missing():\n\tG = nx.Graph()\n\tnx.add_path(G, [1, 2, 3])\n\tpaths = list(nx.shortest_simple_paths(G, 0, 3))\n\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_ssp_target_missing", "data": "def test_ssp_target_missing():\n\tG = nx.Graph()\n\tnx.add_path(G, [1, 2, 3])\n\tpaths = list(nx.shortest_simple_paths(G, 1, 4))\n\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_ssp_multigraph", "data": "def test_ssp_multigraph():\n\tG = nx.MultiGraph()\n\tnx.add_path(G, [1, 2, 3])\n\tpaths = list(nx.shortest_simple_paths(G, 1, 4))\n\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_ssp_source_missing", "data": "def test_ssp_source_missing():\n\tG = nx.Graph()\n\tnx.add_path(G, [0, 1, 2])\n\tnx.add_path(G, [3, 4, 5])\n\tpaths = list(nx.shortest_simple_paths(G, 0, 3))\n\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_bidirectional_shortest_path_restricted_cycle", "data": "def test_bidirectional_shortest_path_restricted_cycle():\n\tcycle = nx.cycle_graph(7)\n\tlength, path = _bidirectional_shortest_path(cycle, 0, 3)\n\tassert_equal(path, [0, 1, 2, 3])\n\tlength, path = _bidirectional_shortest_path(cycle, 0, 3, ignore_nodes=[1])\n\tassert_equal(path, [0, 6, 5, 4, 3])\n\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_bidirectional_shortest_path_restricted_wheel", "data": "def test_bidirectional_shortest_path_restricted_wheel():\n\twheel = nx.wheel_graph(6)\n\tlength, path = _bidirectional_shortest_path(wheel, 1, 3)\n\tassert_true(path in [[1, 0, 3], [1, 2, 3]])\n\tlength, path = _bidirectional_shortest_path(wheel, 1, 3, ignore_nodes=[0])\n\tassert_equal(path, [1, 2, 3])\n\tlength, path = _bidirectional_shortest_path(wheel, 1, 3, ignore_nodes=[0, 2])\n\tassert_equal(path, [1, 5, 4, 3])\n\tlength, path = _bidirectional_shortest_path(wheel, 1, 3,\n\t\t\t\t\t\t\t\t\t\t\t\tignore_edges=[(1, 0), (5, 0), (2, 3)])\n\tassert_true(path in [[1, 2, 0, 3], [1, 5, 4, 3]])\n\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_bidirectional_shortest_path_restricted_directed_cycle", "data": "def test_bidirectional_shortest_path_restricted_directed_cycle():\n\tdirected_cycle = nx.cycle_graph(7, create_using=nx.DiGraph())\n\tlength, path = _bidirectional_shortest_path(directed_cycle, 0, 3)\n\tassert_equal(path, [0, 1, 2, 3])\n\tassert_raises(\n\t\tnx.NetworkXNoPath,\n\t\t_bidirectional_shortest_path,\n\t\tdirected_cycle,\n\t\t0, 3,\n\t\tignore_nodes=[1],\n\t)\n\tlength, path = _bidirectional_shortest_path(directed_cycle, 0, 3,\n\t\t\t\t\t\t\t\t\t\t\t\tignore_edges=[(2, 1)])\n\tassert_equal(path, [0, 1, 2, 3])\n\tassert_raises(\n\t\tnx.NetworkXNoPath,\n\t\t_bidirectional_shortest_path,\n\t\tdirected_cycle,\n\t\t0, 3,\n\t\tignore_edges=[(1, 2)],\n\t)\n\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "validate_path", "data": "def validate_path(G, s, t, soln_len, path):\n\tassert_equal(path[0], s)\n\tassert_equal(path[-1], t)\n\tassert_equal(soln_len, sum(G[u][v].get('weight', 1)\n\t\t\t\t\t\t\t   for u, v in zip(path[:-1], path[1:])))\n\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "validate_length_path", "data": "def validate_length_path(G, s, t, soln_len, length, path):\n\tassert_equal(soln_len, length)\n\tvalidate_path(G, s, t, length, path)\n\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_bidirectional_dijksta_restricted", "data": "def test_bidirectional_dijksta_restricted():\n\tXG = nx.DiGraph()\n\tXG.add_weighted_edges_from([('s', 'u', 10), ('s', 'x', 5),\n\t\t\t\t\t\t\t\t('u', 'v', 1), ('u', 'x', 2),\n\t\t\t\t\t\t\t\t('v', 'y', 1), ('x', 'u', 3),\n\t\t\t\t\t\t\t\t('x', 'v', 5), ('x', 'y', 2),\n\t\t\t\t\t\t\t\t('y', 's', 7), ('y', 'v', 6)])\n\n\tXG3 = nx.Graph()\n\tXG3.add_weighted_edges_from([[0, 1, 2], [1, 2, 12],\n\t\t\t\t\t\t\t\t [2, 3, 1], [3, 4, 5],\n\t\t\t\t\t\t\t\t [4, 5, 1], [5, 0, 10]])\n\tvalidate_length_path(XG, 's', 'v', 9,\n\t\t\t\t\t\t *_bidirectional_dijkstra(XG, 's', 'v'))\n\tvalidate_length_path(XG, 's', 'v', 10,\n\t\t\t\t\t\t *_bidirectional_dijkstra(XG, 's', 'v', ignore_nodes=['u']))\n\tvalidate_length_path(XG, 's', 'v', 11,\n\t\t\t\t\t\t *_bidirectional_dijkstra(XG, 's', 'v', ignore_edges=[('s', 'x')]))\n\tassert_raises(\n\t\tnx.NetworkXNoPath,\n\t\t_bidirectional_dijkstra,\n\t\tXG,\n\t\t's', 'v',\n\t\tignore_nodes=['u'],\n\t\tignore_edges=[('s', 'x')],\n\t)\n\tvalidate_length_path(XG3, 0, 3, 15, *_bidirectional_dijkstra(XG3, 0, 3))\n\tvalidate_length_path(XG3, 0, 3, 16,\n\t\t\t\t\t\t *_bidirectional_dijkstra(XG3, 0, 3, ignore_nodes=[1]))\n\tvalidate_length_path(XG3, 0, 3, 16,\n\t\t\t\t\t\t *_bidirectional_dijkstra(XG3, 0, 3, ignore_edges=[(2, 3)]))\n\tassert_raises(\n\t\tnx.NetworkXNoPath,\n\t\t_bidirectional_dijkstra,\n\t\tXG3,\n\t\t0, 3,\n\t\tignore_nodes=[1],\n\t\tignore_edges=[(5, 4)],\n\t)\n\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_bidirectional_dijkstra_no_path", "data": "def test_bidirectional_dijkstra_no_path():\n\tG = nx.Graph()\n\tnx.add_path(G, [1, 2, 3])\n\tnx.add_path(G, [4, 5, 6])\n\tpath = _bidirectional_dijkstra(G, 1, 6)\n", "description": null, "category": "simple", "imports": ["import random", "from nose.tools import assert_equal", "from nose.tools import assert_false", "from nose.tools import assert_raises", "from nose.tools import assert_true", "from nose.tools import raises", "import networkx as nx", "from networkx import convert_node_labels_to_integers as cnlti", "from networkx.algorithms.simple_paths import _bidirectional_shortest_path", "from networkx.algorithms.simple_paths import _bidirectional_dijkstra", "from networkx.utils import arbitrary_element", "\tfrom itertools import permutations"]}], [], [{"term": "def", "name": "in_tree", "data": "def in_tree(response, name, uclass, drv, depth, last_child):\n\tlines = [x.strip() for x in response.splitlines()]\n\tleaf = ' ' * 4 * depth;\n\tif not last_child:\n\t\tleaf = leaf + '\\|'\n\telse:\n\t\tleaf = leaf + '`'\n\tleaf = leaf + '-- ' + name\n\tline = (' *{:10.10}   [0-9]*  \\[ [ +] \\]   {:20.20}  {}$'\n\t\t\t.format(uclass, drv, leaf))\n\tprog = re.compile(line)\n\tfor l in lines:\n\t\tif prog.match(l):\n\t\t\treturn True\n\treturn False\n\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}, {"term": "def", "name": "test_bind_unbind_with_node", "data": "def test_bind_unbind_with_node(u_boot_console):\n\n\t#bind /bind-test. Device should come up as well as its children\n\tresponse = u_boot_console.run_command('bind  /bind-test generic_simple_bus')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'generic_simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, False)\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'generic_simple_bus', 1, True)\n\n\t#Unbind child #1. No error expected and all devices should be there except for bind-test-child1\n\tresponse = u_boot_console.run_command('unbind  /bind-test/bind-test-child1')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'generic_simple_bus', 0, True)\n\tassert 'bind-test-child1' not in tree\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'generic_simple_bus', 1, True)\n\n\t#bind child #1. No error expected and all devices should be there\n\tresponse = u_boot_console.run_command('bind  /bind-test/bind-test-child1 phy_sandbox')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'generic_simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, True)\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'generic_simple_bus', 1, False)\n\n\t#Unbind child #2. No error expected and all devices should be there except for bind-test-child2\n\tresponse = u_boot_console.run_command('unbind  /bind-test/bind-test-child2')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'generic_simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, True)\n\tassert 'bind-test-child2' not in tree\n\n\n\t#Bind child #2. No error expected and all devices should be there\n\tresponse = u_boot_console.run_command('bind /bind-test/bind-test-child2 generic_simple_bus')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'generic_simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, False)\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'generic_simple_bus', 1, True)\n\n\t#Unbind parent. No error expected. All devices should be removed and unbound\n\tresponse = u_boot_console.run_command('unbind  /bind-test')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert 'bind-test' not in tree\n\tassert 'bind-test-child1' not in tree\n\tassert 'bind-test-child2' not in tree\n\n\t#try binding invalid node with valid driver\n\tresponse = u_boot_console.run_command('bind  /not-a-valid-node generic_simple_bus')\n\tassert response != ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert 'not-a-valid-node' not in tree\n\n\t#try binding valid node with invalid driver\n\tresponse = u_boot_console.run_command('bind  /bind-test not_a_driver')\n\tassert response != ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert 'bind-test' not in tree\n\n\t#bind /bind-test. Device should come up as well as its children\n\tresponse = u_boot_console.run_command('bind  /bind-test generic_simple_bus')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'generic_simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, False)\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'generic_simple_bus', 1, True)\n\n\tresponse = u_boot_console.run_command('unbind  /bind-test')\n\tassert response == ''\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}, {"term": "def", "name": "get_next_line", "data": "def get_next_line(tree, name):\n\ttreelines = [x.strip() for x in tree.splitlines() if x.strip()]\n\tchild_line = ''\n\tfor idx, line in enumerate(treelines):\n\t\tif ('-- ' + name) in line:\n\t\t\ttry:\n\t\t\t\tchild_line = treelines[idx+1]\n\t\t\texcept:\n\t\t\t\tpass\n\t\t\tbreak\n\treturn child_line\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}, {"term": "def", "name": "test_bind_unbind_with_uclass", "data": "def test_bind_unbind_with_uclass(u_boot_console):\n\t#bind /bind-test\n\tresponse = u_boot_console.run_command('bind  /bind-test generic_simple_bus')\n\tassert response == ''\n\n\t#make sure bind-test-child2 is there and get its uclass/index pair\n\ttree = u_boot_console.run_command('dm tree')\n\tchild2_line = [x.strip() for x in tree.splitlines() if '-- bind-test-child2' in x]\n\tassert len(child2_line) == 1\n\n\tchild2_uclass = child2_line[0].split()[0]\n\tchild2_index = int(child2_line[0].split()[1])\n\n\t#bind generic_simple_bus as a child of bind-test-child2\n\tresponse = u_boot_console.run_command('bind  {} {} generic_simple_bus'.format(child2_uclass, child2_index, 'generic_simple_bus'))\n\n\t#check that the child is there and its uclass/index pair is right\n\ttree = u_boot_console.run_command('dm tree')\n\n\tchild_of_child2_line = get_next_line(tree, 'bind-test-child2')\n\tassert child_of_child2_line\n\tchild_of_child2_index = int(child_of_child2_line.split()[1])\n\tassert in_tree(tree, 'generic_simple_bus', 'simple_bus', 'generic_simple_bus', 2, True)\n\tassert child_of_child2_index == child2_index + 1\n\n\t#unbind the child and check it has been removed\n\tresponse = u_boot_console.run_command('unbind  simple_bus {}'.format(child_of_child2_index))\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'generic_simple_bus', 1, True)\n\tassert not in_tree(tree, 'generic_simple_bus', 'simple_bus', 'generic_simple_bus', 2, True)\n\tchild_of_child2_line = get_next_line(tree, 'bind-test-child2')\n\tassert child_of_child2_line == ''\n\n\t#bind generic_simple_bus as a child of bind-test-child2\n\tresponse = u_boot_console.run_command('bind  {} {} generic_simple_bus'.format(child2_uclass, child2_index, 'generic_simple_bus'))\n\n\t#check that the child is there and its uclass/index pair is right\n\ttree = u_boot_console.run_command('dm tree')\n\ttreelines = [x.strip() for x in tree.splitlines() if x.strip()]\n\n\tchild_of_child2_line = get_next_line(tree, 'bind-test-child2')\n\tassert child_of_child2_line\n\tchild_of_child2_index = int(child_of_child2_line.split()[1])\n\tassert in_tree(tree, 'generic_simple_bus', 'simple_bus', 'generic_simple_bus', 2, True)\n\tassert child_of_child2_index == child2_index + 1\n\n\t#unbind the child and check it has been removed\n\tresponse = u_boot_console.run_command('unbind  {} {} generic_simple_bus'.format(child2_uclass, child2_index, 'generic_simple_bus'))\n\tassert response == ''\n\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'generic_simple_bus', 1, True)\n\n\tchild_of_child2_line = get_next_line(tree, 'bind-test-child2')\n\tassert child_of_child2_line == ''\n\n\t#unbind the child again and check it doesn't change the tree\n\ttree_old = u_boot_console.run_command('dm tree')\n\tresponse = u_boot_console.run_command('unbind  {} {} generic_simple_bus'.format(child2_uclass, child2_index, 'generic_simple_bus'))\n\ttree_new = u_boot_console.run_command('dm tree')\n\n\tassert response == ''\n\tassert tree_old == tree_new\n\n\tresponse = u_boot_console.run_command('unbind  /bind-test')\n\tassert response == ''\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}], [{"term": "def", "name": "in_tree", "data": "def in_tree(response, name, uclass, drv, depth, last_child):\n\tlines = [x.strip() for x in response.splitlines()]\n\tleaf = ' ' * 4 * depth;\n\tif not last_child:\n\t\tleaf = leaf + '\\|'\n\telse:\n\t\tleaf = leaf + '`'\n\tleaf = leaf + '-- ' + name\n\tline = ' *{:10.10}  [0-9]*  \\[ [ +] \\]   {:10.10}  {}$'.format(uclass, drv,leaf)\n\tprog = re.compile(line)\n\tfor l in lines:\n\t\tif prog.match(l):\n\t\t\treturn True\n\treturn False\n\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}, {"term": "def", "name": "test_bind_unbind_with_node", "data": "def test_bind_unbind_with_node(u_boot_console):\n\n\t#bind /bind-test. Device should come up as well as its children\n\tresponse = u_boot_console.run_command(\"bind  /bind-test generic_simple_bus\")\n\tassert response == ''\n\ttree = u_boot_console.run_command(\"dm tree\")\n\tassert in_tree(tree, \"bind-test\", \"simple_bus\", \"generic_simple\", 0, True)\n\tassert in_tree(tree, \"bind-test-child1\", \"phy\", \"phy_sandbox\", 1, False)\n\tassert in_tree(tree, \"bind-test-child2\", \"simple_bus\", \"generic_simple\", 1, True)\n\n\t#Unbind child #1. No error expected and all devices should be there except for bind-test-child1\n\tresponse = u_boot_console.run_command(\"unbind  /bind-test/bind-test-child1\")\n\tassert response == ''\n\ttree = u_boot_console.run_command(\"dm tree\")\n\tassert in_tree(tree, \"bind-test\", \"simple_bus\", \"generic_simple\", 0, True)\n\tassert \"bind-test-child1\" not in tree\n\tassert in_tree(tree, \"bind-test-child2\", \"simple_bus\", \"generic_simple\", 1, True)\n\n\t#bind child #1. No error expected and all devices should be there\n\tresponse = u_boot_console.run_command(\"bind  /bind-test/bind-test-child1 phy_sandbox\")\n\tassert response == ''\n\ttree = u_boot_console.run_command(\"dm tree\")\n\tassert in_tree(tree, \"bind-test\", \"simple_bus\", \"generic_simple\", 0, True)\n\tassert in_tree(tree, \"bind-test-child1\", \"phy\", \"phy_sandbox\", 1, True)\n\tassert in_tree(tree, \"bind-test-child2\", \"simple_bus\", \"generic_simple\", 1, False)\n\n\t#Unbind child #2. No error expected and all devices should be there except for bind-test-child2\n\tresponse = u_boot_console.run_command(\"unbind  /bind-test/bind-test-child2\")\n\tassert response == ''\n\ttree = u_boot_console.run_command(\"dm tree\")\n\tassert in_tree(tree, \"bind-test\", \"simple_bus\", \"generic_simple\", 0, True)\n\tassert in_tree(tree, \"bind-test-child1\", \"phy\", \"phy_sandbox\", 1, True)\n\tassert \"bind-test-child2\" not in tree\n\n\n\t#Bind child #2. No error expected and all devices should be there\n\tresponse = u_boot_console.run_command(\"bind /bind-test/bind-test-child2 generic_simple_bus\")\n\tassert response == ''\n\ttree = u_boot_console.run_command(\"dm tree\")\n\tassert in_tree(tree, \"bind-test\", \"simple_bus\", \"generic_simple\", 0, True)\n\tassert in_tree(tree, \"bind-test-child1\", \"phy\", \"phy_sandbox\", 1, False)\n\tassert in_tree(tree, \"bind-test-child2\", \"simple_bus\", \"generic_simple\", 1, True)\n\n\t#Unbind parent. No error expected. All devices should be removed and unbound\n\tresponse = u_boot_console.run_command(\"unbind  /bind-test\")\n\tassert response == ''\n\ttree = u_boot_console.run_command(\"dm tree\")\n\tassert \"bind-test\" not in tree\n\tassert \"bind-test-child1\" not in tree\n\tassert \"bind-test-child2\" not in tree\n\n\t#try binding invalid node with valid driver\n\tresponse = u_boot_console.run_command(\"bind  /not-a-valid-node generic_simple_bus\")\n\tassert response != ''\n\ttree = u_boot_console.run_command(\"dm tree\")\n\tassert \"not-a-valid-node\" not in tree\n\n\t#try binding valid node with invalid driver\n\tresponse = u_boot_console.run_command(\"bind  /bind-test not_a_driver\")\n\tassert response != ''\n\ttree = u_boot_console.run_command(\"dm tree\")\n\tassert \"bind-test\" not in tree\n\n\t#bind /bind-test. Device should come up as well as its children\n\tresponse = u_boot_console.run_command(\"bind  /bind-test generic_simple_bus\")\n\tassert response == ''\n\ttree = u_boot_console.run_command(\"dm tree\")\n\tassert in_tree(tree, \"bind-test\", \"simple_bus\", \"generic_simple\", 0, True)\n\tassert in_tree(tree, \"bind-test-child1\", \"phy\", \"phy_sandbox\", 1, False)\n\tassert in_tree(tree, \"bind-test-child2\", \"simple_bus\", \"generic_simple\", 1, True)\n\n\tresponse = u_boot_console.run_command(\"unbind  /bind-test\")\n\tassert response == ''\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}, {"term": "def", "name": "get_next_line", "data": "def get_next_line(tree, name):\n\ttreelines = [x.strip() for x in tree.splitlines() if x.strip()]\n\tchild_line = \"\"\n\tfor idx, line in enumerate(treelines):\n\t\tif (\"-- \" + name) in line:\n\t\t\ttry:\n\t\t\t\tchild_line = treelines[idx+1]\n\t\t\texcept:\n\t\t\t\tpass\n\t\t\tbreak\n\treturn child_line\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}, {"term": "def", "name": "test_bind_unbind_with_uclass", "data": "def test_bind_unbind_with_uclass(u_boot_console):\n\t#bind /bind-test\n\tresponse = u_boot_console.run_command(\"bind  /bind-test generic_simple_bus\")\n\tassert response == ''\n\n\t#make sure bind-test-child2 is there and get its uclass/index pair\n\ttree = u_boot_console.run_command(\"dm tree\")\n\tchild2_line = [x.strip() for x in tree.splitlines() if \"-- bind-test-child2\" in x]\n\tassert len(child2_line) == 1\n\n\tchild2_uclass = child2_line[0].split()[0]\n\tchild2_index = int(child2_line[0].split()[1])\n\n\t#bind generic_simple_bus as a child of bind-test-child2\n\tresponse = u_boot_console.run_command(\"bind  {} {} generic_simple_bus\".format(child2_uclass, child2_index, \"generic_simple_bus\"))\n\n\t#check that the child is there and its uclass/index pair is right\n\ttree = u_boot_console.run_command(\"dm tree\")\n\n\tchild_of_child2_line = get_next_line(tree, \"bind-test-child2\")\n\tassert child_of_child2_line\n\tchild_of_child2_index = int(child_of_child2_line.split()[1])\n\tassert in_tree(tree, \"generic_simple_bus\", \"simple_bus\", \"generic_simple_bus\", 2, True)\n\tassert child_of_child2_index == child2_index + 1\n\n\t#unbind the child and check it has been removed\n\tresponse = u_boot_console.run_command(\"unbind  simple_bus {}\".format(child_of_child2_index))\n\tassert response == ''\n\ttree = u_boot_console.run_command(\"dm tree\")\n\tassert in_tree(tree, \"bind-test-child2\", \"simple_bus\", \"generic_simple\", 1, True)\n\tassert not in_tree(tree, \"generic_simple_bus\", \"simple_bus\", \"generic_simple_bus\", 2, True)\n\tchild_of_child2_line = get_next_line(tree, \"bind-test-child2\")\n\tassert child_of_child2_line == \"\"\n\n\t#bind generic_simple_bus as a child of bind-test-child2\n\tresponse = u_boot_console.run_command(\"bind  {} {} generic_simple_bus\".format(child2_uclass, child2_index, \"generic_simple_bus\"))\n\n\t#check that the child is there and its uclass/index pair is right\n\ttree = u_boot_console.run_command(\"dm tree\")\n\ttreelines = [x.strip() for x in tree.splitlines() if x.strip()]\n\n\tchild_of_child2_line = get_next_line(tree, \"bind-test-child2\")\n\tassert child_of_child2_line\n\tchild_of_child2_index = int(child_of_child2_line.split()[1])\n\tassert in_tree(tree, \"generic_simple_bus\", \"simple_bus\", \"generic_simple_bus\", 2, True)\n\tassert child_of_child2_index == child2_index + 1\n\n\t#unbind the child and check it has been removed\n\tresponse = u_boot_console.run_command(\"unbind  {} {} generic_simple_bus\".format(child2_uclass, child2_index, \"generic_simple_bus\"))\n\tassert response == ''\n\n\ttree = u_boot_console.run_command(\"dm tree\")\n\tassert in_tree(tree, \"bind-test-child2\", \"simple_bus\", \"generic_simple\", 1, True)\n\n\tchild_of_child2_line = get_next_line(tree, \"bind-test-child2\")\n\tassert child_of_child2_line == \"\"\n\n\t#unbind the child again and check it doesn't change the tree\n\ttree_old = u_boot_console.run_command(\"dm tree\")\n\tresponse = u_boot_console.run_command(\"unbind  {} {} generic_simple_bus\".format(child2_uclass, child2_index, \"generic_simple_bus\"))\n\ttree_new = u_boot_console.run_command(\"dm tree\")\n\n\tassert response == ''\n\tassert tree_old == tree_new\n\n\tresponse = u_boot_console.run_command(\"unbind  /bind-test\")\n\tassert response == ''\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}], [{"term": "class", "name": "props_i", "data": "class props_i(props_base):\n\t\"\"\"\"\"\"\n\tdef initialize(self):\n\t\t\"\"\"\n\t\tThis is called by the framework immediately after your component registers with the NameService.\n\t\t\n\t\tIn general, you should add customization here and not in the __init__ constructor.  If you have \n\t\ta custom port implementation you can override the specific implementation here with a statement\n\t\tsimilar to the following:\n\t\t  self.some_port = MyPortImplementation()\n\t\t\"\"\"\n\t\tprops_base.initialize(self)\n\t\t# TODO add customization here.\n\t\t\n\tdef onconfigure_prop_stringSimple(self, oldvalue, newvalue):\n\t\tself.stringSimple = newvalue*2\n\t\t\n\tdef onconfigure_prop_boolSimple(self, oldvalue, newvalue):\n\t\tself.boolSimple = not newvalue\n\n\tdef onconfigure_prop_ulongSimple(self, oldvalue, newvalue):\n\t\tself.ulongSimple = newvalue*2\n\n\tdef onconfigure_prop_shortSimple(self, oldvalue, newvalue):\n\t\tself.shortSimple = newvalue*2\n\t\n\tdef onconfigure_prop_floatSimple(self, oldvalue, newvalue):\n\t\tself.floatSimple = newvalue*2\n\n\tdef onconfigure_prop_octetSimple(self, oldvalue, newvalue):\n\t\tself.octetSimple = newvalue*2\n\n\tdef onconfigure_prop_charSimple(self, oldvalue, newvalue):\n\t\tself.charSimple = newvalue.upper()\n\n\tdef onconfigure_prop_ushortSimple(self, oldvalue, newvalue):\n\t\tself.ushortSimple = newvalue*2\n\n\tdef onconfigure_prop_doubleSimple(self, oldvalue, newvalue):\n\t\tself.doubleSimple = newvalue*2\n\n\tdef onconfigure_prop_longSimple(self, oldvalue, newvalue):\n\t\tself.longSimple = newvalue*2\n\t\t\n\tdef onconfigure_prop_longlongSimple(self, oldvalue, newvalue):\n\t\tself.longlongSimple = newvalue*2\n\t\t\n\tdef onconfigure_prop_ulonglongSimple(self, oldvalue, newvalue):\n\t\tself.ulonglongSimple = newvalue*2\n\t\t\n\tdef onconfigure_prop_stringSeq(self, oldvalue, newvalue):\n\t\tif newvalue:\n\t\t\tnewvalue.reverse()\n\t\t\tself.stringSeq = newvalue\n\t\t\n\tdef onconfigure_prop_boolSeq(self, oldvalue, newvalue):\n\t\tif newvalue:\n\t\t\tnewvalue.reverse()\n\t\t\tself.boolSeq = newvalue\n\n\tdef onconfigure_prop_ulongSeq(self, oldvalue, newvalue):\n\t\tif newvalue:\n\t\t\tnewvalue.reverse()\n\t\t\tself.ulongSeq = newvalue\n\n\tdef onconfigure_prop_shortSeq(self, oldvalue, newvalue):\n\t\tif newvalue:\n\t\t\tnewvalue.reverse()\n\t\t\tself.shortSeq = newvalue\n\t\n\tdef onconfigure_prop_floatSeq(self, oldvalue, newvalue):\n\t\tif newvalue:\n\t\t\tnewvalue.reverse()\n\t\t\tself.floatSeq = newvalue\n\n\tdef onconfigure_prop_octetSeq(self, oldvalue, newvalue):\n\t\tif newvalue:\n\t\t\tlist = [x for x in newvalue]\n\t\t\tlist.reverse()\n\t\t\ttmp = ''\n\t\t\tfor x in list:\n\t\t\t\ttmp = tmp+x\n\t\t\tself.octetSeq = tmp\n\n\tdef onconfigure_prop_charSeq(self, oldvalue, newvalue):\n\t\tif newvalue:\n\t\t\tlist = [x for x in newvalue]\n\t\t\tlist.reverse()\n\t\t\tself.charSeq = list\n\t\t\ttmp = ''\n\t\t\tfor x in list:\n\t\t\t\ttmp = tmp+x\n\t\t\tself.charSeq = tmp\n\n\tdef onconfigure_prop_ushortSeq(self, oldvalue, newvalue):\n\t\tif newvalue:\n\t\t\tnewvalue.reverse()\n\t\t\tself.ushortSeq = newvalue\n\n\tdef onconfigure_prop_doubleSeq(self, oldvalue, newvalue):\n\t\tif newvalue:\n\t\t\tnewvalue.reverse()\n\t\t\tself.doubleSeq = newvalue\n\n\tdef onconfigure_prop_longSeq(self, oldvalue, newvalue):\n\t\tif newvalue:\n\t\t\tnewvalue.reverse()\n\t\t\tself.longSeq = newvalue\n\t\t\n\tdef onconfigure_prop_longlongSeq(self, oldvalue, newvalue):\n\t\tif newvalue:\n\t\t\tnewvalue.reverse()\n\t\t\tself.longlongSeq = newvalue\n\t\t\n\tdef onconfigure_prop_ulonglongSeq(self, oldvalue, newvalue):\n\t\tif newvalue:\n\t\t\tnewvalue.reverse()\n\t\t\tself.ulonglongSeq = newvalue\n\t\t\t\n\tdef onconfigure_prop_structProp(self, oldvalue, newvalue):\n\t\ttry:\n\t\t\tself.structProp.structShortSimple = newvalue.structShortSimple * 2\n\t\t\tself.structProp.structFloatSimple = newvalue.structFloatSimple * 2\n\t\t\tself.structProp.structOctetSimple = newvalue.structOctetSimple * 2\n\t\t\tself.structProp.structUlongSimple = newvalue.structUlongSimple * 2\n\t\t\tself.structProp.structUshortSimple = newvalue.structUshortSimple * 2\n\t\t\tself.structProp.structStringSimple = newvalue.structStringSimple * 2\n\t\t\tself.structProp.structDoubleSimple = newvalue.structDoubleSimple * 2\n\t\t\tself.structProp.structLonglongSimple = newvalue.structLonglongSimple * 2\n\t\t\tself.structProp.structBoolSimple = not newvalue.structBoolSimple\n\t\t\tself.structProp.structLongSimple = newvalue.structLongSimple * 2\n\t\t\tself.structProp.structUlonglongSimple = newvalue.structUlonglongSimple * 2\n\t\t\tself.structProp.structCharSimple = newvalue.structCharSimple.upper()\n\t\texcept:\n\t\t\tpass\n\n\tdef onconfigure_prop_structSeqProp(self, oldvalue, newvalue):\n\t\tfor x in newvalue:\n\t\t\tshortVal = x.structSeqShortSimple * 2\n\t\t\tfloatVal = x.structSeqFloatSimple * 2\n\t\t\tstringVal = x.structSeqStringSimple * 2\n\t\t\tboolVal = not x.structSeqBoolSimple\n\t\t\t\n\t\t\tself.structSeqProp.append(self.StructSeq(stringVal, boolVal, shortVal, floatVal)) \n\n\tdef process(self):\n\t\t\"\"\"\n\t\tBasic functionality:\n\t\t\n\t\t\tThe process method should process a single \"chunk\" of data and then return. This method\n\t\t\twill be called from the processing thread again, and again, and again until it returns\n\t\t\tFINISH or stop() is called on the component.  If no work is performed, then return NOOP.\n\t\t\t\n\t\tStreamSRI:\n\t\t\tTo create a StreamSRI object, use the following code (this generates a normalized SRI that does not flush the queue when full):\n\t\t\t\tself.sri = BULKIO.StreamSRI(1, 0.0, 0.0, BULKIO.UNITS_TIME, 0, 0.0, 0.0, BULKIO.UNITS_NONE, 0, self.stream_id, True, [])\n\n\t\tPrecisionUTCTime:\n\t\t\tTo create a PrecisionUTCTime object, use the following code:\n\t\t\t\ttmp_time = time.time()\n\t\t\t\twsec = math.modf(tmp_time)[1]\n\t\t\t\tfsec = math.modf(tmp_time)[0]\n\t\t\t\ttstamp = BULKIO.PrecisionUTCTime(BULKIO.TCM_CPU, BULKIO.TCS_VALID, 0, wsec, fsec)\n  \n\t\tPorts:\n\n\t\t\tEach port instance is accessed through members of the following form: self.port_\n\t\t\t\n\t\t\tData is obtained in the process function through the getPacket call (BULKIO only) on a\n\t\t\tprovides port member instance. The getPacket function call is non-blocking - if no data\n\t\t\tis available, it will return immediately with all values == None.\n\t\t\t\n\t\t\tTo send data, call the appropriate function in the port directly. In the case of BULKIO,\n\t\t\tconvenience functions have been added in the port classes that aid in output.\n\t\t\t\n\t\t\tInteractions with non-BULKIO ports are left up to the component developer's discretion.\n\t\t\t\n\t\tProperties:\n\t\t\n\t\t\tProperties are accessed directly as member variables. If the property name is baudRate,\n\t\t\tthen accessing it (for reading or writing) is achieved in the following way: self.baudRate.\n\t\t\t\n\t\tExample:\n\t\t\n\t\t\t# This example assumes that the component has two ports:\n\t\t\t#   - A provides (input) port of type BULKIO.dataShort called dataShort_in\n\t\t\t#   - A uses (output) port of type BULKIO.dataFloat called dataFloat_out\n\t\t\t# The mapping between the port and the class if found in the component\n\t\t\t# base class.\n\t\t\t# This example also makes use of the following Properties:\n\t\t\t#   - A float value called amplitude\n\t\t\t#   - A boolean called increaseAmplitude\n\t\t\t\n\t\t\tdata, T, EOS, streamID, sri, sriChanged, inputQueueFlushed = self.port_dataShort_in.getPacket()\n\t\t\t\n\t\t\tif data == None:\n\t\t\t\treturn NOOP\n\t\t\t\t\n\t\t\toutData = range(len(data))\n\t\t\tfor i in range(len(data)):\n\t\t\t\tif self.increaseAmplitude:\n\t\t\t\t\toutData[i] = float(data[i]) * self.amplitude\n\t\t\t\telse:\n\t\t\t\t\toutData[i] = float(data[i])\n\t\t\t\t\n\t\t\t# NOTE: You must make at least one valid pushSRI call\n\t\t\tif sriChanged:\n\t\t\t\tself.port_dataFloat_out.pushSRI(sri);\n\n\t\t\tself.port_dataFloat_out.pushPacket(outData, T, EOS, streamID)\n\t\t\treturn NORMAL\n\t\t\t\n\t\t\"\"\"\n\n\t\t# TODO fill in your code here\n\t\tself._log.debug(\"process() example log message\")\n\t\treturn NOOP\n\t\t\n", "description": "", "category": "simple", "imports": ["from ossie.resource import Resource, start_component", "import logging", "from props_base import *"]}], [], [], [], [], [], [{"term": "def", "name": "read_data", "data": "def read_data():\n\tprint(\"read data ...\")\n\ttrain_dingdan_data = pd.read_csv(config.dingdan_train_path, encoding=\"gb2312\")\n\ttrain_xuqiu_data = pd.read_csv(config.xuqiu_train_path, encoding=\"gb2312\")\n\n\ttest_dingdan_data = pd.read_csv(config.dingdan_test_path)\n\ttest_xuqiu_data = pd.read_csv(config.xuqiu_test_path)\n\n\tprint(\"transform data\")\n\t# \u65f6\u95f4\u7c7b\u578b\n\ttrain_xuqiu_data[\"date\"] = pd.to_datetime(train_xuqiu_data[\"date\"])\n\ttrain_xuqiu_data[\"year_month\"] = train_xuqiu_data[\"date\"].dt.strftime(\"%Y%m\")\n\ttrain_xuqiu_data[\"year\"] = train_xuqiu_data[\"date\"].dt.year\n\ttrain_xuqiu_data[\"month\"] = train_xuqiu_data[\"date\"].dt.month\n\t# train_xuqiu_data[\"quarter\"] = train_xuqiu_data[\"date\"].dt.quarter\n\n\ttest_xuqiu_data[\"date\"] = pd.to_datetime(test_xuqiu_data[\"date\"])\n\ttest_xuqiu_data[\"year_month\"] = test_xuqiu_data[\"date\"].dt.strftime(\"%Y%m\")\n\ttest_xuqiu_data[\"year\"] = test_xuqiu_data[\"date\"].dt.year\n\ttest_xuqiu_data[\"month\"] = test_xuqiu_data[\"date\"].dt.month\n\t# test_xuqiu_data[\"quarter\"] = test_xuqiu_data[\"date\"].dt.quarter\n\n\ttrain_data = train_xuqiu_data.merge(train_dingdan_data, how=\"left\", on=[\"product_id\", \"year\", \"month\"])\n\ttest_data = test_xuqiu_data.merge(test_dingdan_data, how=\"left\", on=[\"product_id\", \"year\", \"month\"])\n\n\tdata = pd.concat([train_data, test_data]).reset_index(drop=True)\n\tdata = data.sort_values(['product_id', 'year_month'])\n\n\tsimple = data[~data[\"label\"].isnull()]\n\tsimple[\"sale_count\"] = simple.groupby([\"product_id\", \"year_month\"])[\"is_sale_day\"].transform(\"sum\")\n\tsimple = simple.loc[:, [\"product_id\", \"year_month\", \"sale_count\"]].drop_duplicates([\"product_id\", \"year_month\"])\n\tdata = data.merge(simple, on=[\"product_id\", \"year_month\"], how=\"left\")\n\n\t# \u6708\u6c47\u96c6\n\tdata[\"label_month\"] = data.groupby([\"product_id\", \"year\", \"month\"])[\"label\"].transform(\"sum\")\n\tdata[\"sale_count\"] = data.groupby([\"product_id\", \"year_month\"])[\"is_sale_day\"].transform(\"sum\")\n\tdata = data.drop_duplicates([\"product_id\", \"year\", \"month\"]).reset_index(drop=True)\n\n\t# \u7edf\u8ba1\u552e\u5356\u6708\u4efd\u6570\n\t# \u83b7\u53d6\u7b2c\u4e00\u6b21\u552e\u5356\u7684\u6708\u4efd\n\tsimple = data[data[\"label_month\"] > 0]\n\tsimple[\"qty_first_month\"] = simple.groupby([\"product_id\"])[\"year_month\"].transform(\"first\")\n\tsimple = simple.loc[:, [\"product_id\", \"qty_first_month\"]].drop_duplicates()\n\tdata = data.merge(simple, on=[\"product_id\"], how=\"left\")\n\t# \u8fc7\u6ee4\u8fd8\u672a\u552e\u5356\u7684\u65f6\u95f4\n\tdata_first = data[data[\"qty_first_month\"] <= data[\"year_month\"]].reset_index(drop=True)\n\n\tsimple = data_first[~data_first[\"label\"].isnull()]\n\tsimple[\"qty_month_count\"] = simple.groupby([\"product_id\"])[\"year_month\"].transform(\"count\")\n\tsimple = simple.loc[:, [\"product_id\", \"qty_month_count\"]].drop_duplicates()\n\tdata = data.merge(simple, on=[\"product_id\"], how=\"left\")\n\n\t# \u6570\u636e\u6807\u51c6\u5316\n\tdata[\"all_qty\"] = data.groupby([\"product_id\"])[\"label_month\"].transform(\"sum\")\n\tdata[\"mean_qty\"] = data[\"all_qty\"] / data[\"qty_month_count\"]\n\tdata[\"scan_qty\"] = data[\"label_month\"] / data[\"mean_qty\"]\n\tdata[\"date_block_num\"] = (data[\"year\"] - 2018) * 12 + data[\"month\"]\n\tdata[\"scan_qty\"].fillna(0, inplace=True)\n\n\tsimple = data[data[\"year_month\"] == data[\"qty_first_month\"]]\n\tsimple[\"qty_first\"] = simple[\"date_block_num\"]\n\tsimple = simple.loc[:, [\"product_id\", \"qty_first\"]]\n\tdata = data.merge(simple, on=[\"product_id\"], how=\"left\")\n\tdata[\"qty_num\"] = data[\"date_block_num\"] - data[\"qty_first\"] + 1\n\tdata[\"qty_num\"] = data[\"qty_num\"].map(lambda x: x if x > 0 else 0)\n\n\tdel data[\"qty_first\"]\n\tdel data[\"label\"]\n\tdel data[\"is_sale_day\"]\n\tdel data[\"year_month\"]\n\tdel data[\"all_qty\"]\n\tdel data[\"qty_first_month\"]\n\tdel data[\"qty_month_count\"]\n\t# del data[\"qty_num\"]\n\treturn data\n\n", "description": null, "category": "simple", "imports": ["import pandas as pd", "from scipy import stats", "import config"]}], [{"term": "class", "name": "Attribute", "data": "class Attribute(object):\n\tdef __init__(self, name, swift_name=None):\n\t\tself.name = name\n\t\tself.swift_name = swift_name or name\n", "description": null, "category": "simple", "imports": ["from .Child import Child", "from .Node import Node  # noqa: I201", "from .Utils import error"]}, {"term": "class", "name": "TypeAttribute", "data": "class TypeAttribute(Attribute):\n\tdef __init__(self, name):\n\t\tsuper().__init__(name, name)\n", "description": null, "category": "simple", "imports": ["from .Child import Child", "from .Node import Node  # noqa: I201", "from .Utils import error"]}, {"term": "class", "name": "DeclAttribute", "data": "class DeclAttribute(Attribute):\n\tdef __init__(self, name, class_name, *options, code, swift_name=None):\n\t\tsuper().__init__(name, swift_name)\n\t\tself.class_name = class_name\n\t\tself.options = options\n\t\tself.code = code\n", "description": null, "category": "simple", "imports": ["from .Child import Child", "from .Node import Node  # noqa: I201", "from .Utils import error"]}, {"term": "class", "name": "SimpleDeclAttribute", "data": "class SimpleDeclAttribute(DeclAttribute):\n\tdef __init__(self, name, class_name, *options, code, swift_name=None):\n\t\tsuper().__init__(name, class_name, *options, code=code, swift_name=swift_name)\n", "description": null, "category": "simple", "imports": ["from .Child import Child", "from .Node import Node  # noqa: I201", "from .Utils import error"]}, {"term": "class", "name": "ContextualDeclAttribute", "data": "class ContextualDeclAttribute(DeclAttribute):\n\tdef __init__(self, name, class_name, *options, code):\n\t\tsuper().__init__(name, class_name, *options, code=code)\n", "description": null, "category": "simple", "imports": ["from .Child import Child", "from .Node import Node  # noqa: I201", "from .Utils import error"]}, {"term": "class", "name": "ContextualSimpleDeclAttribute", "data": "class ContextualSimpleDeclAttribute(SimpleDeclAttribute):\n\tdef __init__(self, name, class_name, *options, code):\n\t\tsuper().__init__(name, class_name, *options, code=code)\n", "description": null, "category": "simple", "imports": ["from .Child import Child", "from .Node import Node  # noqa: I201", "from .Utils import error"]}, {"term": "class", "name": "DeclAttributeAlias", "data": "class DeclAttributeAlias(Attribute):\n\tdef __init__(self, name, class_name, swift_name=None):\n\t\tsuper().__init__(name, swift_name)\n\t\tself.class_name = class_name\n", "description": null, "category": "simple", "imports": ["from .Child import Child", "from .Node import Node  # noqa: I201", "from .Utils import error"]}, {"term": "class", "name": "ContextualDeclAttributeAlias", "data": "class ContextualDeclAttributeAlias(DeclAttributeAlias):\n\tdef __init__(self, name, class_name, swift_name=None):\n\t\tsuper().__init__(name, class_name, swift_name)\n", "description": null, "category": "simple", "imports": ["from .Child import Child", "from .Node import Node  # noqa: I201", "from .Utils import error"]}, {"term": "class", "name": "BuiltinDeclModifier", "data": "class BuiltinDeclModifier(Attribute):\n\tdef __init__(self, name, swift_name=None):\n\t\tsuper().__init__(name, swift_name)\n", "description": null, "category": "simple", "imports": ["from .Child import Child", "from .Node import Node  # noqa: I201", "from .Utils import error"]}, {"term": "def", "name": "verify_attribute_serialization_codes", "data": "def verify_attribute_serialization_codes(nodes):\n\t# Verify that no serialization code is used twice\n\tused_codes = set()\n\tfor node in nodes:\n\t\tif isinstance(node, DeclAttribute):\n\t\t\tif node.code in used_codes:\n\t\t\t\terror(\"Serialization code %d used twice\" % node.code)\n\t\t\tused_codes.add(node.code)\n", "description": null, "category": "simple", "imports": ["from .Child import Child", "from .Node import Node  # noqa: I201", "from .Utils import error"]}], [], [{"term": "def", "name": "fget_names", "data": "\tdef get_names(tag, type):\r\n\t\tnames = []\r\n\t\tfor row in config:\r\n\t\t\tif row[0] == tag and row[1] == type:\r\n\t\t\t\tnames.append(row[2])\r\n", "description": null, "category": "simple", "imports": ["\timport openpyexcel\r", "\timport pyautogui\r", "\timport win32gui\r", "\timport PySimpleGUI\r"]}, {"term": "def", "name": "fget_pos", "data": "\tdef get_pos(type, name):\r\n\t\tx = 0\r\n\t\ty = 0\r\n\t\tfor row in config:\r\n\t\t\tif row[1] == type and row[2] == name:\r\n\t\t\t\tx = row[4]\r\n\t\t\t\ty = row[5]\r\n", "description": null, "category": "simple", "imports": ["\timport openpyexcel\r", "\timport pyautogui\r", "\timport win32gui\r", "\timport PySimpleGUI\r"]}, {"term": "def", "name": "fget_pos_sub", "data": "\tdef get_pos_sub(type, name):\r\n\t\tx = 0\r\n\t\ty = 0\r\n\t\tfor row in config:\r\n\t\t\tif row[1] == type and row[2] == name:\r\n\t\t\t\tx = row[6]\r\n\t\t\t\ty = row[7]\r\n\t\treturn x, y\r\n", "description": null, "category": "simple", "imports": ["\timport openpyexcel\r", "\timport pyautogui\r", "\timport win32gui\r", "\timport PySimpleGUI\r"]}, {"term": "def", "name": "fget_window", "data": "\tdef get_window():\r\n\t\tglobal window_x, window_y, window_loaded\r\n\t\tparent_handle = win32gui.FindWindow(None, \"League of Legends\")\r\n\t\t# print(parent_handle)\r\n\t\tif parent_handle > 0:\r\n\t\t\twin_x1, win_y1, win_x2, win_y2 = win32gui.GetWindowRect(parent_handle)\r\n\t\t\twindow_x = win_x1\r\n\t\t\twindow_y = win_y1\r\n\t\t\twindow_loaded = True\r\n\t\t\twin32gui.SetForegroundWindow(parent_handle)\r\n\t\telse:\r\n\t\t\twindow_loaded = False\r\n", "description": null, "category": "simple", "imports": ["\timport openpyexcel\r", "\timport pyautogui\r", "\timport win32gui\r", "\timport PySimpleGUI\r"]}, {"term": "def", "name": "fleft_click", "data": "\tdef left_click(x, y):\r\n\t\t# print(x, y)\r\n\t\t# print(window_loaded)\r\n\t\t# print(window_x, window_y)\r\n\t\tif window_loaded:\r\n\t\t\tpyautogui.click(window_x + x, window_y + y)\r\n\t\t\t# print(window_x + x, window_y + y)\r\n", "description": null, "category": "simple", "imports": ["\timport openpyexcel\r", "\timport pyautogui\r", "\timport win32gui\r", "\timport PySimpleGUI\r"]}], [{"term": "def", "name": "simple", "data": "def simple(e):\n\tcode = e.code\n\n\tif code.endswith('Exception'):\n\t\tcode = code.rstrip('Exception')\n\n\ttry:\n\t\t# Dynamically get the error class.\n\t\tsimple_e = getattr(sys.modules[__name__], code)(e)\n\texcept AttributeError:\n\t\t# Return original exception on failure.\n\t\treturn e\n\n\treturn simple_e\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "SimpleException", "data": "class SimpleException(BotoServerError):\n\tdef __init__(self, e):\n\t\tsuper(SimpleException, self).__init__(e.status, e.reason, e.body)\n\t\tself.error_message = self.message\n\n\tdef __repr__(self):\n\t\treturn self.__class__.__name__ + ': ' + self.error_message\n\tdef __str__(self):\n\t\treturn self.__class__.__name__ + ': ' + self.error_message\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "ValidationError", "data": "class ValidationError(SimpleException): pass\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "Throttling", "data": "class Throttling(SimpleException): pass\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "SourceBundleDeletion", "data": "class SourceBundleDeletion(SimpleException): pass\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}], [{"term": "def", "name": "SimplePoint", "data": "def SimplePoint():\n\tnewpoints = []\n\n\tnewpoints.append([0.0, 0.0, 0.0])\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "SimpleLine", "data": "def SimpleLine(c1=[0.0, 0.0, 0.0], c2=[2.0, 2.0, 2.0]):\n\tnewpoints = []\n\n\tc3 = Vector(c2) - Vector(c1)\n\tnewpoints.append([0.0, 0.0, 0.0])\n\tnewpoints.append([c3[0], c3[1], c3[2]])\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "SimpleAngle", "data": "def SimpleAngle(length=1.0, angle=45.0):\n\tnewpoints = []\n\n\tangle = radians(angle)\n\tnewpoints.append([length, 0.0, 0.0])\n\tnewpoints.append([0.0, 0.0, 0.0])\n\tnewpoints.append([length * cos(angle), length * sin(angle), 0.0])\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "SimpleDistance", "data": "def SimpleDistance(length=1.0, center=True):\n\tnewpoints = []\n\n\tif center:\n\t\tnewpoints.append([-length / 2, 0.0, 0.0])\n\t\tnewpoints.append([length / 2, 0.0, 0.0])\n\telse:\n\t\tnewpoints.append([0.0, 0.0, 0.0])\n\t\tnewpoints.append([length, 0.0, 0.0])\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "SimpleCircle", "data": "def SimpleCircle(sides=4, radius=1.0):\n\tnewpoints = []\n\n\tangle = radians(360) / sides\n\tnewpoints.append([radius, 0, 0])\n\tj = 1\n\twhile j < sides:\n\t\tt = angle * j\n\t\tx = cos(t) * radius\n\t\ty = sin(t) * radius\n\t\tnewpoints.append([x, y, 0])\n\t\tj += 1\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "SimpleEllipse", "data": "def SimpleEllipse(a=2.0, b=1.0):\n\tnewpoints = []\n\n\tnewpoints.append([a, 0.0, 0.0])\n\tnewpoints.append([0.0, b, 0.0])\n\tnewpoints.append([-a, 0.0, 0.0])\n\tnewpoints.append([0.0, -b, 0.0])\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "SimpleArc", "data": "def SimpleArc(sides=0, radius=1.0, startangle=0.0, endangle=45.0):\n\tnewpoints = []\n\n\tstartangle = radians(startangle)\n\tendangle = radians(endangle)\n\tsides += 1\n\n\tangle = (endangle - startangle) / sides\n\tx = cos(startangle) * radius\n\ty = sin(startangle) * radius\n\tnewpoints.append([x, y, 0])\n\tj = 1\n\twhile j < sides:\n\t\tt = angle * j\n\t\tx = cos(t + startangle) * radius\n\t\ty = sin(t + startangle) * radius\n\t\tnewpoints.append([x, y, 0])\n\t\tj += 1\n\tx = cos(endangle) * radius\n\ty = sin(endangle) * radius\n\tnewpoints.append([x, y, 0])\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "SimpleSector", "data": "def SimpleSector(sides=0, radius=1.0, startangle=0.0, endangle=45.0):\n\tnewpoints = []\n\n\tstartangle = radians(startangle)\n\tendangle = radians(endangle)\n\tsides += 1\n\n\tnewpoints.append([0, 0, 0])\n\tangle = (endangle - startangle) / sides\n\tx = cos(startangle) * radius\n\ty = sin(startangle) * radius\n\tnewpoints.append([x, y, 0])\n\tj = 1\n\twhile j < sides:\n\t\tt = angle * j\n\t\tx = cos(t + startangle) * radius\n\t\ty = sin(t + startangle) * radius\n\t\tnewpoints.append([x, y, 0])\n\t\tj += 1\n\tx = cos(endangle) * radius\n\ty = sin(endangle) * radius\n\tnewpoints.append([x, y, 0])\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "SimpleSegment", "data": "def SimpleSegment(sides=0, a=2.0, b=1.0, startangle=0.0, endangle=45.0):\n\tnewpoints = []\n\n\tstartangle = radians(startangle)\n\tendangle = radians(endangle)\n\tsides += 1\n\n\tangle = (endangle - startangle) / sides\n\tx = cos(startangle) * a\n\ty = sin(startangle) * a\n\tnewpoints.append([x, y, 0])\n\tj = 1\n\twhile j < sides:\n\t\tt = angle * j\n\t\tx = cos(t + startangle) * a\n\t\ty = sin(t + startangle) * a\n\t\tnewpoints.append([x, y, 0])\n\t\tj += 1\n\tx = cos(endangle) * a\n\ty = sin(endangle) * a\n\tnewpoints.append([x, y, 0])\n\n\tx = cos(endangle) * b\n\ty = sin(endangle) * b\n\tnewpoints.append([x, y, 0])\n\tj = sides\n\twhile j > 0:\n\t\tt = angle * j\n\t\tx = cos(t + startangle) * b\n\t\ty = sin(t + startangle) * b\n\t\tnewpoints.append([x, y, 0])\n\t\tj -= 1\n\tx = cos(startangle) * b\n\ty = sin(startangle) * b\n\tnewpoints.append([x, y, 0])\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "SimpleRectangle", "data": "def SimpleRectangle(width=2.0, length=2.0, rounded=0.0, center=True):\n\tnewpoints = []\n\n\tr = rounded / 2\n\n\tif center:\n\t\tx = width / 2\n\t\ty = length / 2\n\t\tif rounded != 0.0:\n\t\t\tnewpoints.append([-x + r, y, 0.0])\n\t\t\tnewpoints.append([x - r, y, 0.0])\n\t\t\tnewpoints.append([x, y - r, 0.0])\n\t\t\tnewpoints.append([x, -y + r, 0.0])\n\t\t\tnewpoints.append([x - r, -y, 0.0])\n\t\t\tnewpoints.append([-x + r, -y, 0.0])\n\t\t\tnewpoints.append([-x, -y + r, 0.0])\n\t\t\tnewpoints.append([-x, y - r, 0.0])\n\t\telse:\n\t\t\tnewpoints.append([-x, y, 0.0])\n\t\t\tnewpoints.append([x, y, 0.0])\n\t\t\tnewpoints.append([x, -y, 0.0])\n\t\t\tnewpoints.append([-x, -y, 0.0])\n\n\telse:\n\t\tx = width\n\t\ty = length\n\t\tif rounded != 0.0:\n\t\t\tnewpoints.append([r, y, 0.0])\n\t\t\tnewpoints.append([x - r, y, 0.0])\n\t\t\tnewpoints.append([x, y - r, 0.0])\n\t\t\tnewpoints.append([x, r, 0.0])\n\t\t\tnewpoints.append([x - r, 0.0, 0.0])\n\t\t\tnewpoints.append([r, 0.0, 0.0])\n\t\t\tnewpoints.append([0.0, r, 0.0])\n\t\t\tnewpoints.append([0.0, y - r, 0.0])\n\t\telse:\n\t\t\tnewpoints.append([0.0, 0.0, 0.0])\n\t\t\tnewpoints.append([0.0, y, 0.0])\n\t\t\tnewpoints.append([x, y, 0.0])\n\t\t\tnewpoints.append([x, 0.0, 0.0])\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "SimpleRhomb", "data": "def SimpleRhomb(width=2.0, length=2.0, center=True):\n\tnewpoints = []\n\tx = width / 2\n\ty = length / 2\n\n\tif center:\n\t\tnewpoints.append([-x, 0.0, 0.0])\n\t\tnewpoints.append([0.0, y, 0.0])\n\t\tnewpoints.append([x, 0.0, 0.0])\n\t\tnewpoints.append([0.0, -y, 0.0])\n\telse:\n\t\tnewpoints.append([x, 0.0, 0.0])\n\t\tnewpoints.append([0.0, y, 0.0])\n\t\tnewpoints.append([x, length, 0.0])\n\t\tnewpoints.append([width, y, 0.0])\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "SimplePolygon", "data": "def SimplePolygon(sides=3, radius=1.0):\n\tnewpoints = []\n\tangle = radians(360.0) / sides\n\tj = 0\n\n\twhile j < sides:\n\t\tt = angle * j\n\t\tx = sin(t) * radius\n\t\ty = cos(t) * radius\n\t\tnewpoints.append([x, y, 0.0])\n\t\tj += 1\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "SimplePolygon_ab", "data": "def SimplePolygon_ab(sides=3, a=2.0, b=1.0):\n\tnewpoints = []\n\tangle = radians(360.0) / sides\n\tj = 0\n\n\twhile j < sides:\n\t\tt = angle * j\n\t\tx = sin(t) * a\n\t\ty = cos(t) * b\n\t\tnewpoints.append([x, y, 0.0])\n\t\tj += 1\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "SimpleTrapezoid", "data": "def SimpleTrapezoid(a=2.0, b=1.0, h=1.0, center=True):\n\tnewpoints = []\n\tx = a / 2\n\ty = b / 2\n\tr = h / 2\n\n\tif center:\n\t\tnewpoints.append([-x, -r, 0.0])\n\t\tnewpoints.append([-y, r, 0.0])\n\t\tnewpoints.append([y, r, 0.0])\n\t\tnewpoints.append([x, -r, 0.0])\n\n\telse:\n\t\tnewpoints.append([0.0, 0.0, 0.0])\n\t\tnewpoints.append([x - y, h, 0.0])\n\t\tnewpoints.append([x + y, h, 0.0])\n\t\tnewpoints.append([a, 0.0, 0.0])\n\n\treturn newpoints\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "align_matrix", "data": "def align_matrix(context, location):\n\tloc = Matrix.Translation(location)\n\tobj_align = context.user_preferences.edit.object_align\n\tif (context.space_data.type == 'VIEW_3D' and\n\t\t\tobj_align == 'VIEW'):\n\t\trot = context.space_data.region_3d.view_matrix.to_3x3().inverted().to_4x4()\n\telse:\n\t\trot = Matrix()\n\talign_matrix = loc * rot\n\n\treturn align_matrix\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "main", "data": "def main(context, self, align_matrix):\n\t# deselect all objects\n\tbpy.ops.object.select_all(action='DESELECT')\n\n\t# create object\n\tname = self.Simple_Type  # Type as name\n\n\t# create curve\n\tscene = bpy.context.scene\n\tnewCurve = bpy.data.curves.new(name, type='CURVE')  # curvedatablock\n\tnewSpline = newCurve.splines.new('BEZIER')\t\t  # spline\n\n\t# set curveOptions\n\tnewCurve.dimensions = self.shape\n\tnewSpline.use_endpoint_u = True\n\n\tsides = abs(int((self.Simple_endangle - self.Simple_startangle) / 90))\n\n\t# get verts\n\tif self.Simple_Type == 'Point':\n\t\tverts = SimplePoint()\n\t\tnewSpline.use_cyclic_u = False\n\n\tif self.Simple_Type == 'Line':\n\t\tverts = SimpleLine(self.Simple_startlocation, self.Simple_endlocation)\n\t\tnewSpline.use_cyclic_u = False\n\t\tnewCurve.dimensions = '3D'\n\n\tif self.Simple_Type == 'Distance':\n\t\tverts = SimpleDistance(self.Simple_length, self.Simple_center)\n\t\tnewSpline.use_cyclic_u = False\n\n\tif self.Simple_Type == 'Angle':\n\t\tverts = SimpleAngle(self.Simple_length, self.Simple_angle)\n\t\tnewSpline.use_cyclic_u = False\n\n\tif self.Simple_Type == 'Circle':\n\t\tif self.Simple_sides < 4:\n\t\t\tself.Simple_sides = 4\n\t\tverts = SimpleCircle(self.Simple_sides, self.Simple_radius)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Ellipse':\n\t\tverts = SimpleEllipse(self.Simple_a, self.Simple_b)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Arc':\n\t\tif self.Simple_sides < sides:\n\t\t\tself.Simple_sides = sides\n\t\tif self.Simple_radius == 0:\n\t\t\treturn {'FINISHED'}\n\t\tverts = SimpleArc(\n\t\t\t\t\tself.Simple_sides, self.Simple_radius,\n\t\t\t\t\tself.Simple_startangle, self.Simple_endangle\n\t\t\t\t\t)\n\t\tnewSpline.use_cyclic_u = False\n\n\tif self.Simple_Type == 'Sector':\n\t\tif self.Simple_sides < sides:\n\t\t\tself.Simple_sides = sides\n\n\t\tif self.Simple_radius == 0:\n\t\t\treturn {'FINISHED'}\n\n\t\tverts = SimpleSector(\n\t\t\t\t\tself.Simple_sides, self.Simple_radius,\n\t\t\t\t\tself.Simple_startangle, self.Simple_endangle\n\t\t\t\t\t)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Segment':\n\t\tif self.Simple_sides < sides:\n\t\t\tself.Simple_sides = sides\n\t\tif self.Simple_a == 0 or self.Simple_b == 0:\n\t\t\treturn {'FINISHED'}\n\t\tverts = SimpleSegment(\n\t\t\t\t\tself.Simple_sides, self.Simple_a, self.Simple_b,\n\t\t\t\t\tself.Simple_startangle, self.Simple_endangle\n\t\t\t\t\t)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Rectangle':\n\t\tverts = SimpleRectangle(\n\t\t\t\t\tself.Simple_width, self.Simple_length,\n\t\t\t\t\tself.Simple_rounded, self.Simple_center\n\t\t\t\t\t)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Rhomb':\n\t\tverts = SimpleRhomb(\n\t\t\t\t\tself.Simple_width, self.Simple_length, self.Simple_center\n\t\t\t\t\t)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Polygon':\n\t\tif self.Simple_sides < 3:\n\t\t\tself.Simple_sides = 3\n\t\tverts = SimplePolygon(\n\t\t\t\t\tself.Simple_sides, self.Simple_radius\n\t\t\t\t\t)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Polygon_ab':\n\t\tif self.Simple_sides < 3:\n\t\t\tself.Simple_sides = 3\n\t\tverts = SimplePolygon_ab(\n\t\t\t\t\tself.Simple_sides, self.Simple_a, self.Simple_b\n\t\t\t\t\t)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Trapezoid':\n\t\tverts = SimpleTrapezoid(\n\t\t\t\t\tself.Simple_a, self.Simple_b, self.Simple_h, self.Simple_center\n\t\t\t\t\t)\n\t\tnewSpline.use_cyclic_u = True\n\n\tvertArray = []\n\tfor v in verts:\n\t\tvertArray += v\n\n\tnewSpline.bezier_points.add(int(len(vertArray) * 0.333333333))\n\tnewSpline.bezier_points.foreach_set('co', vertArray)\n\n\t# create object with newCurve\n\tSimpleCurve = bpy.data.objects.new(name, newCurve)  # object\n\tscene.objects.link(SimpleCurve)  # place in active scene\n\tSimpleCurve.select = True  # set as selected\n\tscene.objects.active = SimpleCurve  # set as active\n\tSimpleCurve.matrix_world = align_matrix  # apply matrix\n\tSimpleCurve.rotation_euler = self.Simple_rotation_euler\n\n\tall_points = [p for p in newSpline.bezier_points]\n\td = 2 * 0.27606262\n\tn = 0\n\tfor p in all_points:\n\t\tp.handle_right_type = 'VECTOR'\n\t\tp.handle_left_type = 'VECTOR'\n\t\tn += 1\n\n\tif self.Simple_Type == 'Circle' or self.Simple_Type == 'Arc' or \\\n\t\t\tself.Simple_Type == 'Sector' or self.Simple_Type == 'Segment' or \\\n\t\t\tself.Simple_Type == 'Ellipse':\n\n\t\tfor p in all_points:\n\t\t\tp.handle_right_type = 'FREE'\n\t\t\tp.handle_left_type = 'FREE'\n\n\tif self.Simple_Type == 'Circle':\n\t\ti = 0\n\t\tfor p1 in all_points:\n\t\t\tif i != n - 1:\n\t\t\t\tp2 = all_points[i + 1]\n\t\t\t\tu1 = asin(p1.co.y / self.Simple_radius)\n\t\t\t\tu2 = asin(p2.co.y / self.Simple_radius)\n\t\t\t\tif p1.co.x > 0 and p2.co.x < 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\telif p1.co.x < 0 and p2.co.x > 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\tu = u2 - u1\n\t\t\t\tif u < 0:\n\t\t\t\t\tu = -u\n\t\t\t\tl = 4 / 3 * tan(1 / 4 * u) * self.Simple_radius\n\t\t\t\tv1 = Vector((-p1.co.y, p1.co.x, 0))\n\t\t\t\tv1.normalize()\n\t\t\t\tv2 = Vector((-p2.co.y, p2.co.x, 0))\n\t\t\t\tv2.normalize()\n\t\t\t\tvh1 = v1 * l\n\t\t\t\tvh2 = v2 * l\n\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) + vh1\n\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) - vh2\n\t\t\t\tp1.handle_right = v1\n\t\t\t\tp2.handle_left = v2\n\t\t\tif i == n - 1:\n\t\t\t\tp2 = all_points[0]\n\t\t\t\tu1 = asin(p1.co.y / self.Simple_radius)\n\t\t\t\tu2 = asin(p2.co.y / self.Simple_radius)\n\t\t\t\tif p1.co.x > 0 and p2.co.x < 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\telif p1.co.x < 0 and p2.co.x > 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\tu = u2 - u1\n\t\t\t\tif u < 0:\n\t\t\t\t\tu = -u\n\t\t\t\tl = 4 / 3 * tan(1 / 4 * u) * self.Simple_radius\n\t\t\t\tv1 = Vector((-p1.co.y, p1.co.x, 0))\n\t\t\t\tv1.normalize()\n\t\t\t\tv2 = Vector((-p2.co.y, p2.co.x, 0))\n\t\t\t\tv2.normalize()\n\t\t\t\tvh1 = v1 * l\n\t\t\t\tvh2 = v2 * l\n\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) + vh1\n\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) - vh2\n\t\t\t\tp1.handle_right = v1\n\t\t\t\tp2.handle_left = v2\n\t\t\ti += 1\n\n\tif self.Simple_Type == 'Ellipse':\n\t\tall_points[0].handle_right = Vector((self.Simple_a, self.Simple_b * d, 0))\n\t\tall_points[0].handle_left = Vector((self.Simple_a, -self.Simple_b * d, 0))\n\t\tall_points[1].handle_right = Vector((-self.Simple_a * d, self.Simple_b, 0))\n\t\tall_points[1].handle_left = Vector((self.Simple_a * d, self.Simple_b, 0))\n\t\tall_points[2].handle_right = Vector((-self.Simple_a, -self.Simple_b * d, 0))\n\t\tall_points[2].handle_left = Vector((-self.Simple_a, self.Simple_b * d, 0))\n\t\tall_points[3].handle_right = Vector((self.Simple_a * d, -self.Simple_b, 0))\n\t\tall_points[3].handle_left = Vector((-self.Simple_a * d, -self.Simple_b, 0))\n\n\tif self.Simple_Type == 'Arc':\n\t\ti = 0\n\t\tfor p1 in all_points:\n\t\t\tif i != n - 1:\n\t\t\t\tp2 = all_points[i + 1]\n\t\t\t\tu1 = asin(p1.co.y / self.Simple_radius)\n\t\t\t\tu2 = asin(p2.co.y / self.Simple_radius)\n\t\t\t\tif p1.co.x > 0 and p2.co.x < 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\telif p1.co.x < 0 and p2.co.x > 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\tu = u2 - u1\n\t\t\t\tif u < 0:\n\t\t\t\t\tu = -u\n\t\t\t\tl = 4 / 3 * tan(1 / 4 * u) * self.Simple_radius\n\t\t\t\tv1 = Vector((-p1.co.y, p1.co.x, 0))\n\t\t\t\tv1.normalize()\n\t\t\t\tv2 = Vector((-p2.co.y, p2.co.x, 0))\n\t\t\t\tv2.normalize()\n\t\t\t\tvh1 = v1 * l\n\t\t\t\tvh2 = v2 * l\n\t\t\t\tif self.Simple_startangle < self.Simple_endangle:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) + vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) - vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\t\t\t\telse:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) - vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) + vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\t\t\ti += 1\n\n\tif self.Simple_Type == 'Sector':\n\t\ti = 0\n\t\tfor p1 in all_points:\n\t\t\tif i == 0:\n\t\t\t\tp1.handle_right_type = 'VECTOR'\n\t\t\t\tp1.handle_left_type = 'VECTOR'\n\t\t\telif i != n - 1:\n\t\t\t\tp2 = all_points[i + 1]\n\t\t\t\tu1 = asin(p1.co.y / self.Simple_radius)\n\t\t\t\tu2 = asin(p2.co.y / self.Simple_radius)\n\t\t\t\tif p1.co.x > 0 and p2.co.x < 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\telif p1.co.x < 0 and p2.co.x > 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\tu = u2 - u1\n\t\t\t\tif u < 0:\n\t\t\t\t\tu = -u\n\t\t\t\tl = 4 / 3 * tan(1 / 4 * u) * self.Simple_radius\n\t\t\t\tv1 = Vector((-p1.co.y, p1.co.x, 0))\n\t\t\t\tv1.normalize()\n\t\t\t\tv2 = Vector((-p2.co.y, p2.co.x, 0))\n\t\t\t\tv2.normalize()\n\t\t\t\tvh1 = v1 * l\n\t\t\t\tvh2 = v2 * l\n\t\t\t\tif self.Simple_startangle < self.Simple_endangle:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) + vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) - vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\t\t\t\telse:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) - vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) + vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\t\t\ti += 1\n\n\tif self.Simple_Type == 'Segment':\n\t\ti = 0\n\t\tfor p1 in all_points:\n\t\t\tif i < n / 2 - 1:\n\t\t\t\tp2 = all_points[i + 1]\n\t\t\t\tu1 = asin(p1.co.y / self.Simple_a)\n\t\t\t\tu2 = asin(p2.co.y / self.Simple_a)\n\t\t\t\tif p1.co.x > 0 and p2.co.x < 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_a)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_a)\n\t\t\t\telif p1.co.x < 0 and p2.co.x > 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_a)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_a)\n\t\t\t\tu = u2 - u1\n\t\t\t\tif u < 0:\n\t\t\t\t\tu = -u\n\t\t\t\tl = 4 / 3 * tan(1 / 4 * u) * self.Simple_a\n\t\t\t\tv1 = Vector((-p1.co.y, p1.co.x, 0))\n\t\t\t\tv1.normalize()\n\t\t\t\tv2 = Vector((-p2.co.y, p2.co.x, 0))\n\t\t\t\tv2.normalize()\n\t\t\t\tvh1 = v1 * l\n\t\t\t\tvh2 = v2 * l\n\t\t\t\tif self.Simple_startangle < self.Simple_endangle:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) + vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) - vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\t\t\t\telse:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) - vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) + vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\t\t\telif i != n / 2 - 1 and i != n - 1:\n\t\t\t\tp2 = all_points[i + 1]\n\t\t\t\tu1 = asin(p1.co.y / self.Simple_b)\n\t\t\t\tu2 = asin(p2.co.y / self.Simple_b)\n\t\t\t\tif p1.co.x > 0 and p2.co.x < 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_b)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_b)\n\t\t\t\telif p1.co.x < 0 and p2.co.x > 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_b)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_b)\n\t\t\t\tu = u2 - u1\n\t\t\t\tif u < 0:\n\t\t\t\t\tu = -u\n\t\t\t\tl = 4 / 3 * tan(1 / 4 * u) * self.Simple_b\n\t\t\t\tv1 = Vector((-p1.co.y, p1.co.x, 0))\n\t\t\t\tv1.normalize()\n\t\t\t\tv2 = Vector((-p2.co.y, p2.co.x, 0))\n\t\t\t\tv2.normalize()\n\t\t\t\tvh1 = v1 * l\n\t\t\t\tvh2 = v2 * l\n\t\t\t\tif self.Simple_startangle < self.Simple_endangle:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) - vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) + vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\t\t\t\telse:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) + vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) - vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\n\t\t\ti += 1\n\t\tall_points[0].handle_left_type = 'VECTOR'\n\t\tall_points[n - 1].handle_right_type = 'VECTOR'\n\t\tall_points[int(n / 2) - 1].handle_right_type = 'VECTOR'\n\t\tall_points[int(n / 2)].handle_left_type = 'VECTOR'\n\n\tSimpleCurve.s_curve.Simple = True\n\tSimpleCurve.s_curve.Simple_Change = False\n\tSimpleCurve.s_curve.Simple_Type = self.Simple_Type\n\tSimpleCurve.s_curve.Simple_startlocation = self.Simple_startlocation\n\tSimpleCurve.s_curve.Simple_endlocation = self.Simple_endlocation\n\tSimpleCurve.s_curve.Simple_a = self.Simple_a\n\tSimpleCurve.s_curve.Simple_b = self.Simple_b\n\tSimpleCurve.s_curve.Simple_h = self.Simple_h\n\tSimpleCurve.s_curve.Simple_angle = self.Simple_angle\n\tSimpleCurve.s_curve.Simple_startangle = self.Simple_startangle\n\tSimpleCurve.s_curve.Simple_endangle = self.Simple_endangle\n\tSimpleCurve.s_curve.Simple_rotation_euler = self.Simple_rotation_euler\n\tSimpleCurve.s_curve.Simple_sides = self.Simple_sides\n\tSimpleCurve.s_curve.Simple_radius = self.Simple_radius\n\tSimpleCurve.s_curve.Simple_center = self.Simple_center\n\tSimpleCurve.s_curve.Simple_width = self.Simple_width\n\tSimpleCurve.s_curve.Simple_length = self.Simple_length\n\tSimpleCurve.s_curve.Simple_rounded = self.Simple_rounded\n\n\tbpy.ops.object.mode_set(mode='EDIT', toggle=True)\n\tbpy.ops.curve.select_all(action='SELECT')\n\tbpy.ops.object.mode_set(mode='OBJECT', toggle=True)\n\n\treturn\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "SimpleDelete", "data": "def SimpleDelete(name):\n\tif bpy.ops.object.mode_set.poll():\n\t\tbpy.ops.object.mode_set(mode='OBJECT')\n\n\tbpy.context.scene.objects.active = bpy.data.objects[name]\n\tbpy.ops.object.delete()\n\n\treturn\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "class", "name": "Simple", "data": "class Simple(Operator):\n\tbl_idname = \"curve.simple\"\n\tbl_label = \"Simple Curve\"\n\tbl_description = \"Construct a Simple Curve\"\n\tbl_options = {'REGISTER', 'UNDO'}\n\n\t# align_matrix for the invoke\n\talign_matrix = Matrix()\n\n\t# change properties\n\tSimple = BoolProperty(\n\t\t\tname=\"Simple\",\n\t\t\tdefault=True,\n\t\t\tdescription=\"Simple Curve\"\n\t\t\t)\n\tSimple_Change = BoolProperty(\n\t\t\tname=\"Change\",\n\t\t\tdefault=False,\n\t\t\tdescription=\"Change Simple Curve\"\n\t\t\t)\n\tSimple_Delete = StringProperty(\n\t\t\tname=\"Delete\",\n\t\t\tdescription=\"Delete Simple Curve\"\n\t\t\t)\n\t# general properties\n\tTypes = [('Point', \"Point\", \"Construct a Point\"),\n\t\t\t ('Line', \"Line\", \"Construct a Line\"),\n\t\t\t ('Distance', \"Distance\", \"Contruct a two point Distance\"),\n\t\t\t ('Angle', \"Angle\", \"Construct an Angle\"),\n\t\t\t ('Circle', \"Circle\", \"Construct a Circle\"),\n\t\t\t ('Ellipse', \"Ellipse\", \"Construct an Ellipse\"),\n\t\t\t ('Arc', \"Arc\", \"Construct an Arc\"),\n\t\t\t ('Sector', \"Sector\", \"Construct a Sector\"),\n\t\t\t ('Segment', \"Segment\", \"Construct a Segment\"),\n\t\t\t ('Rectangle', \"Rectangle\", \"Construct a Rectangle\"),\n\t\t\t ('Rhomb', \"Rhomb\", \"Construct a Rhomb\"),\n\t\t\t ('Polygon', \"Polygon\", \"Construct a Polygon\"),\n\t\t\t ('Polygon_ab', \"Polygon ab\", \"Construct a Polygon ab\"),\n\t\t\t ('Trapezoid', \"Trapezoid\", \"Construct a Trapezoid\")\n\t\t\t]\n\tSimple_Type = EnumProperty(\n\t\t\tname=\"Type\",\n\t\t\tdescription=\"Form of Curve to create\",\n\t\t\titems=Types\n\t\t\t)\n\t# Line properties\n\tSimple_startlocation = FloatVectorProperty(\n\t\t\tname=\"\",\n\t\t\tdescription=\"Start location\",\n\t\t\tdefault=(0.0, 0.0, 0.0),\n\t\t\tsubtype='TRANSLATION'\n\t\t\t)\n\tSimple_endlocation = FloatVectorProperty(\n\t\t\tname=\"\",\n\t\t\tdescription=\"End location\",\n\t\t\tdefault=(2.0, 2.0, 2.0),\n\t\t\tsubtype='TRANSLATION'\n\t\t\t)\n\tSimple_rotation_euler = FloatVectorProperty(\n\t\t\tname=\"\",\n\t\t\tdescription=\"Rotation\",\n\t\t\tdefault=(0.0, 0.0, 0.0),\n\t\t\tsubtype='EULER'\n\t\t\t)\n\t# Trapezoid properties\n\tSimple_a = FloatProperty(\n\t\t\tname=\"Side a\",\n\t\t\tdefault=2.0,\n\t\t\tmin=0.0, soft_min=0.0,\n\t\t\tunit='LENGTH',\n\t\t\tdescription=\"a side Value\"\n\t\t\t)\n\tSimple_b = FloatProperty(\n\t\t\tname=\"Side b\",\n\t\t\tdefault=1.0,\n\t\t\tmin=0.0, soft_min=0.0,\n\t\t\tunit='LENGTH',\n\t\t\tdescription=\"b side Value\"\n\t\t\t)\n\tSimple_h = FloatProperty(\n\t\t\tname=\"Height\",\n\t\t\tdefault=1.0,\n\t\t\tunit='LENGTH',\n\t\t\tdescription=\"Height of the Trapezoid - distance between a and b\"\n\t\t\t)\n\tSimple_angle = FloatProperty(\n\t\t\tname=\"Angle\",\n\t\t\tdefault=45.0,\n\t\t\tdescription=\"Angle\"\n\t\t\t)\n\tSimple_startangle = FloatProperty(\n\t\t\tname=\"Start angle\",\n\t\t\tdefault=0.0,\n\t\t\tmin=-360.0, soft_min=-360.0,\n\t\t\tmax=360.0, soft_max=360.0,\n\t\t\tdescription=\"Start angle\"\n\t\t\t)\n\tSimple_endangle = FloatProperty(\n\t\t\tname=\"End angle\",\n\t\t\tdefault=45.0,\n\t\t\tmin=-360.0, soft_min=-360.0,\n\t\t\tmax=360.0, soft_max=360.0,\n\t\t\tdescription=\"End angle\"\n\t\t\t)\n\tSimple_sides = IntProperty(\n\t\t\tname=\"Sides\",\n\t\t\tdefault=3,\n\t\t\tmin=0, soft_min=0,\n\t\t\tdescription=\"Sides\"\n\t\t\t)\n\tSimple_radius = FloatProperty(\n\t\t\tname=\"Radius\",\n\t\t\tdefault=1.0,\n\t\t\tmin=0.0, soft_min=0.0,\n\t\t\tunit='LENGTH',\n\t\t\tdescription=\"Radius\"\n\t\t\t)\n\tSimple_center = BoolProperty(\n\t\t\tname=\"Length center\",\n\t\t\tdefault=True,\n\t\t\tdescription=\"Length center\"\n\t\t\t)\n\n\tAngle_types = [('Degrees', \"Degrees\", \"Use Degrees\"),\n\t\t\t\t   ('Radians', \"Radians\", \"Use Radians\")]\n\tSimple_degrees_or_radians = EnumProperty(\n\t\t\tname=\"Degrees or radians\",\n\t\t\tdescription=\"Degrees or radians\",\n\t\t\titems=Angle_types\n\t\t\t)\n\t# Rectangle properties\n\tSimple_width = FloatProperty(\n\t\t\tname=\"Width\",\n\t\t\tdefault=2.0,\n\t\t\tmin=0.0, soft_min=0,\n\t\t\tunit='LENGTH',\n\t\t\tdescription=\"Width\"\n\t\t\t)\n\tSimple_length = FloatProperty(\n\t\t\tname=\"Length\",\n\t\t\tdefault=2.0,\n\t\t\tmin=0.0, soft_min=0.0,\n\t\t\tunit='LENGTH',\n\t\t\tdescription=\"Length\"\n\t\t\t)\n\tSimple_rounded = FloatProperty(\n\t\t\tname=\"Rounded\",\n\t\t\tdefault=0.0,\n\t\t\tmin=0.0, soft_min=0.0,\n\t\t\tunit='LENGTH',\n\t\t\tdescription=\"Rounded corners\"\n\t\t\t)\n\t# Curve Options\n\tshapeItems = [\n\t\t('2D', \"2D\", \"2D shape Curve\"),\n\t\t('3D', \"3D\", \"3D shape Curve\")]\n\tshape = EnumProperty(\n\t\t\tname=\"2D / 3D\",\n\t\t\titems=shapeItems,\n\t\t\tdescription=\"2D or 3D Curve\"\n\t\t\t)\n\n\tdef draw(self, context):\n\t\tlayout = self.layout\n\n\t\t# general options\n\t\tcol = layout.column()\n\t\tcol.prop(self, \"Simple_Type\")\n\n\t\tl = 0\n\t\ts = 0\n\n\t\tif self.Simple_Type == 'Line':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=self.Simple_Type + \" Options:\")\n\t\t\tcol.prop(self, \"Simple_endlocation\")\n\t\t\tv = Vector(self.Simple_endlocation) - Vector(self.Simple_startlocation)\n\t\t\tl = v.length\n\n\t\tif self.Simple_Type == 'Distance':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=self.Simple_Type + \" Options:\")\n\t\t\tcol.prop(self, \"Simple_length\")\n\t\t\tcol.prop(self, \"Simple_center\")\n\t\t\tl = self.Simple_length\n\n\t\tif self.Simple_Type == 'Angle':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=self.Simple_Type + \" Options:\")\n\t\t\tcol.prop(self, \"Simple_length\")\n\t\t\tcol.prop(self, \"Simple_angle\")\n\n\t\t\trow = layout.row()\n\t\t\trow.prop(self, \"Simple_degrees_or_radians\", expand=True)\n\n\t\tif self.Simple_Type == 'Circle':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=self.Simple_Type + \" Options:\")\n\t\t\tcol.prop(self, \"Simple_sides\")\n\t\t\tcol.prop(self, \"Simple_radius\")\n\n\t\t\tl = 2 * pi * abs(self.Simple_radius)\n\t\t\ts = pi * self.Simple_radius * self.Simple_radius\n\n\t\tif self.Simple_Type == 'Ellipse':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=self.Simple_Type + \" Options:\")\n\t\t\tcol.prop(self, \"Simple_a\", text=\"Radius a\")\n\t\t\tcol.prop(self, \"Simple_b\", text=\"Radius b\")\n\n\t\t\tl = pi * (3 * (self.Simple_a + self.Simple_b) -\n\t\t\t\t\t\t  sqrt((3 * self.Simple_a + self.Simple_b) *\n\t\t\t\t\t\t  (self.Simple_a + 3 * self.Simple_b)))\n\n\t\t\ts = pi * abs(self.Simple_b) * abs(self.Simple_a)\n\n\t\tif self.Simple_Type == 'Arc':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=self.Simple_Type + \" Options:\")\n\t\t\tcol.prop(self, \"Simple_sides\")\n\t\t\tcol.prop(self, \"Simple_radius\")\n\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.prop(self, \"Simple_startangle\")\n\t\t\tcol.prop(self, \"Simple_endangle\")\n\t\t\trow = layout.row()\n\t\t\trow.prop(self, \"Simple_degrees_or_radians\", expand=True)\n\n\t\t\tl = abs(pi * self.Simple_radius * (self.Simple_endangle - self.Simple_startangle) / 180)\n\n\t\tif self.Simple_Type == 'Sector':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=self.Simple_Type + \" Options:\")\n\t\t\tcol.prop(self, \"Simple_sides\")\n\t\t\tcol.prop(self, \"Simple_radius\")\n\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.prop(self, \"Simple_startangle\")\n\t\t\tcol.prop(self, \"Simple_endangle\")\n\t\t\trow = layout.row()\n\t\t\trow.prop(self, \"Simple_degrees_or_radians\", expand=True)\n\n\t\t\tl = abs(pi * self.Simple_radius *\n\t\t\t\t   (self.Simple_endangle - self.Simple_startangle) / 180) + self.Simple_radius * 2\n\n\t\t\ts = pi * self.Simple_radius * self.Simple_radius * \\\n\t\t\t\tabs(self.Simple_endangle - self.Simple_startangle) / 360\n\n\t\tif self.Simple_Type == 'Segment':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=self.Simple_Type + \" Options:\")\n\t\t\tcol.prop(self, \"Simple_sides\")\n\t\t\tcol.prop(self, \"Simple_a\", text=\"Radius a\")\n\t\t\tcol.prop(self, \"Simple_b\", text=\"Radius b\")\n\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.prop(self, \"Simple_startangle\")\n\t\t\tcol.prop(self, \"Simple_endangle\")\n\n\t\t\trow = layout.row()\n\t\t\trow.prop(self, \"Simple_degrees_or_radians\", expand=True)\n\n\t\t\tla = abs(pi * self.Simple_a * (self.Simple_endangle - self.Simple_startangle) / 180)\n\t\t\tlb = abs(pi * self.Simple_b * (self.Simple_endangle - self.Simple_startangle) / 180)\n\t\t\tl = abs(self.Simple_a - self.Simple_b) * 2 + la + lb\n\n\t\t\tsa = pi * self.Simple_a * self.Simple_a * \\\n\t\t\t\tabs(self.Simple_endangle - self.Simple_startangle) / 360\n\n\t\t\tsb = pi * self.Simple_b * self.Simple_b * \\\n\t\t\t\tabs(self.Simple_endangle - self.Simple_startangle) / 360\n\n\t\t\ts = abs(sa - sb)\n\n\t\tif self.Simple_Type == 'Rectangle':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=self.Simple_Type + \" Options:\")\n\t\t\tcol.prop(self, \"Simple_width\")\n\t\t\tcol.prop(self, \"Simple_length\")\n\t\t\tcol.prop(self, \"Simple_rounded\")\n\n\t\t\tbox.prop(self, \"Simple_center\")\n\t\t\tl = 2 * abs(self.Simple_width) + 2 * abs(self.Simple_length)\n\t\t\ts = abs(self.Simple_width) * abs(self.Simple_length)\n\n\t\tif self.Simple_Type == 'Rhomb':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=self.Simple_Type + \" Options:\")\n\t\t\tcol.prop(self, \"Simple_width\")\n\t\t\tcol.prop(self, \"Simple_length\")\n\t\t\tcol.prop(self, \"Simple_center\")\n\n\t\t\tg = hypot(self.Simple_width / 2, self.Simple_length / 2)\n\t\t\tl = 4 * g\n\t\t\ts = self.Simple_width * self.Simple_length / 2\n\n\t\tif self.Simple_Type == 'Polygon':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=self.Simple_Type + \" Options:\")\n\t\t\tcol.prop(self, \"Simple_sides\")\n\t\t\tcol.prop(self, \"Simple_radius\")\n\n\t\tif self.Simple_Type == 'Polygon_ab':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=\"Polygon ab Options:\")\n\t\t\tcol.prop(self, \"Simple_sides\")\n\t\t\tcol.prop(self, \"Simple_a\")\n\t\t\tcol.prop(self, \"Simple_b\")\n\n\t\tif self.Simple_Type == 'Trapezoid':\n\t\t\tbox = layout.box()\n\t\t\tcol = box.column(align=True)\n\t\t\tcol.label(text=self.Simple_Type + \" Options:\")\n\t\t\tcol.prop(self, \"Simple_a\")\n\t\t\tcol.prop(self, \"Simple_b\")\n\t\t\tcol.prop(self, \"Simple_h\")\n\n\t\t\tbox.prop(self, \"Simple_center\")\n\t\t\tg = hypot(self.Simple_h, (self.Simple_a - self.Simple_b) / 2)\n\t\t\tl = self.Simple_a + self.Simple_b + g * 2\n\t\t\ts = (abs(self.Simple_a) + abs(self.Simple_b)) / 2 * self.Simple_h\n\n\t\trow = layout.row()\n\t\trow.prop(self, \"shape\", expand=True)\n\t\tbox = layout.box()\n\t\tbox.label(\"Location:\")\n\t\tbox.prop(self, \"Simple_startlocation\")\n\t\tbox = layout.box()\n\t\tbox.label(\"Rotation:\")\n\t\tbox.prop(self, \"Simple_rotation_euler\")\n\n\t\tif l != 0 or s != 0:\n\t\t\tbox = layout.box()\n\t\t\tbox.label(text=\"Statistics:\", icon=\"INFO\")\n\t\tif l != 0:\n\t\t\tl_str = str(round(l, 4))\n\t\t\tbox.label(\"Length: \" + l_str)\n\t\tif s != 0:\n\t\t\ts_str = str(round(s, 4))\n\t\t\tbox.label(\"Area: \" + s_str)\n\n\t@classmethod\n\tdef poll(cls, context):\n\t\treturn context.scene is not None\n\n\tdef execute(self, context):\n\t\tif self.Simple_Change:\n\t\t\tSimpleDelete(self.Simple_Delete)\n\n\t\t# go to object mode\n\t\tif bpy.ops.object.mode_set.poll():\n\t\t\tbpy.ops.object.mode_set(mode='OBJECT')\n\n\t\t# turn off undo\n\t\tundo = bpy.context.user_preferences.edit.use_global_undo\n\t\tbpy.context.user_preferences.edit.use_global_undo = False\n\n\t\t# main function\n\t\tself.align_matrix = align_matrix(context, self.Simple_startlocation)\n\t\tmain(context, self, self.align_matrix)\n\n\t\t# restore pre operator undo state\n\t\tbpy.context.user_preferences.edit.use_global_undo = undo\n\n\t\treturn {'FINISHED'}\n\n\tdef invoke(self, context, event):\n\t\t# store creation_matrix\n\t\tif self.Simple_Change:\n\t\t\tbpy.context.scene.cursor_location = self.Simple_startlocation\n\t\telse:\n\t\t\tself.Simple_startlocation = bpy.context.scene.cursor_location\n\n\t\tself.align_matrix = align_matrix(context, self.Simple_startlocation)\n\t\tself.execute(context)\n\n\t\treturn {'FINISHED'}\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "class", "name": "BezierPointsFillet", "data": "class BezierPointsFillet(Operator):\n\tbl_idname = \"curve.bezier_points_fillet\"\n\tbl_label = \"Bezier points Fillet\"\n\tbl_description = \"Bezier points Fillet\"\n\tbl_options = {'REGISTER', 'UNDO'}\n\n\tFillet_radius = FloatProperty(\n\t\t\tname=\"Radius\",\n\t\t\tdefault=0.25,\n\t\t\tunit='LENGTH',\n\t\t\tdescription=\"Radius\"\n\t\t\t)\n\tTypes = [('Round', \"Round\", \"Round\"),\n\t\t\t ('Chamfer', \"Chamfer\", \"Chamfer\")]\n\tFillet_Type = EnumProperty(\n\t\t\tname=\"Type\",\n\t\t\tdescription=\"Fillet type\",\n\t\t\titems=Types\n\t\t\t)\n\n\tdef draw(self, context):\n\t\tlayout = self.layout\n\n\t\t# general options\n\t\tcol = layout.column()\n\t\tcol.prop(self, \"Fillet_radius\")\n\t\tcol.prop(self, \"Fillet_Type\", expand=True)\n\n\t@classmethod\n\tdef poll(cls, context):\n\t\treturn context.scene is not None\n\n\tdef execute(self, context):\n\t\t# go to object mode\n\t\tif bpy.ops.object.mode_set.poll():\n\t\t\tbpy.ops.object.mode_set(mode='OBJECT')\n\t\t\tbpy.ops.object.mode_set(mode='EDIT')\n\n\t\t# turn off undo\n\t\tundo = bpy.context.user_preferences.edit.use_global_undo\n\t\tbpy.context.user_preferences.edit.use_global_undo = False\n\n\t\t# main function\n\t\tspline = bpy.context.object.data.splines.active\n\t\tselected = [p for p in spline.bezier_points if p.select_control_point]\n\n\t\tbpy.ops.curve.handle_type_set(type='VECTOR')\n\t\tn = 0\n\t\tii = []\n\t\tfor p in spline.bezier_points:\n\t\t\tif p.select_control_point:\n\t\t\t\tii.append(n)\n\t\t\t\tn += 1\n\t\t\telse:\n\t\t\t\tn += 1\n\n\t\tif n > 2:\n\t\t\tjn = 0\n\t\t\tfor j in ii:\n\n\t\t\t\tj += jn\n\n\t\t\t\tselected_all = [p for p in spline.bezier_points]\n\n\t\t\t\tbpy.ops.curve.select_all(action='DESELECT')\n\n\t\t\t\tif j != 0 and j != n - 1:\n\t\t\t\t\tselected_all[j].select_control_point = True\n\t\t\t\t\tselected_all[j + 1].select_control_point = True\n\t\t\t\t\tbpy.ops.curve.subdivide()\n\t\t\t\t\tselected_all = [p for p in spline.bezier_points]\n\t\t\t\t\tselected4 = [selected_all[j - 1], selected_all[j],\n\t\t\t\t\t\t\t\t selected_all[j + 1], selected_all[j + 2]]\n\t\t\t\t\tjn += 1\n\t\t\t\t\tn += 1\n\n\t\t\t\telif j == 0:\n\t\t\t\t\tselected_all[j].select_control_point = True\n\t\t\t\t\tselected_all[j + 1].select_control_point = True\n\t\t\t\t\tbpy.ops.curve.subdivide()\n\t\t\t\t\tselected_all = [p for p in spline.bezier_points]\n\t\t\t\t\tselected4 = [selected_all[n], selected_all[0],\n\t\t\t\t\t\t\t\t selected_all[1], selected_all[2]]\n\t\t\t\t\tjn += 1\n\t\t\t\t\tn += 1\n\n\t\t\t\telif j == n - 1:\n\t\t\t\t\tselected_all[j].select_control_point = True\n\t\t\t\t\tselected_all[j - 1].select_control_point = True\n\t\t\t\t\tbpy.ops.curve.subdivide()\n\t\t\t\t\tselected_all = [p for p in spline.bezier_points]\n\t\t\t\t\tselected4 = [selected_all[0], selected_all[n],\n\t\t\t\t\t\t\t\t selected_all[n - 1], selected_all[n - 2]]\n\n\t\t\t\tselected4[2].co = selected4[1].co\n\t\t\t\ts1 = Vector(selected4[0].co) - Vector(selected4[1].co)\n\t\t\t\ts2 = Vector(selected4[3].co) - Vector(selected4[2].co)\n\t\t\t\ts1.normalize()\n\t\t\t\ts11 = Vector(selected4[1].co) + s1 * self.Fillet_radius\n\t\t\t\tselected4[1].co = s11\n\t\t\t\ts2.normalize()\n\t\t\t\ts22 = Vector(selected4[2].co) + s2 * self.Fillet_radius\n\t\t\t\tselected4[2].co = s22\n\n\t\t\t\tif self.Fillet_Type == 'Round':\n\t\t\t\t\tif j != n - 1:\n\t\t\t\t\t\tselected4[2].handle_right_type = 'VECTOR'\n\t\t\t\t\t\tselected4[1].handle_left_type = 'VECTOR'\n\t\t\t\t\t\tselected4[1].handle_right_type = 'ALIGNED'\n\t\t\t\t\t\tselected4[2].handle_left_type = 'ALIGNED'\n\t\t\t\t\telse:\n\t\t\t\t\t\tselected4[1].handle_right_type = 'VECTOR'\n\t\t\t\t\t\tselected4[2].handle_left_type = 'VECTOR'\n\t\t\t\t\t\tselected4[2].handle_right_type = 'ALIGNED'\n\t\t\t\t\t\tselected4[1].handle_left_type = 'ALIGNED'\n\t\t\t\tif self.Fillet_Type == 'Chamfer':\n\t\t\t\t\tselected4[2].handle_right_type = 'VECTOR'\n\t\t\t\t\tselected4[1].handle_left_type = 'VECTOR'\n\t\t\t\t\tselected4[1].handle_right_type = 'VECTOR'\n\t\t\t\t\tselected4[2].handle_left_type = 'VECTOR'\n\n\t\tbpy.ops.curve.select_all(action='SELECT')\n\t\tbpy.ops.curve.spline_type_set(type='BEZIER')\n\n\t\t# restore pre operator undo state\n\t\tbpy.context.user_preferences.edit.use_global_undo = undo\n\n\t\treturn {'FINISHED'}\n\n\tdef invoke(self, context, event):\n\t\tself.execute(context)\n\n\t\treturn {'FINISHED'}\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "subdivide_cubic_bezier", "data": "def subdivide_cubic_bezier(p1, p2, p3, p4, t):\n\tp12 = (p2 - p1) * t + p1\n\tp23 = (p3 - p2) * t + p2\n\tp34 = (p4 - p3) * t + p3\n\tp123 = (p23 - p12) * t + p12\n\tp234 = (p34 - p23) * t + p23\n\tp1234 = (p234 - p123) * t + p123\n\treturn [p12, p123, p1234, p234, p34]\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "class", "name": "BezierDivide", "data": "class BezierDivide(Operator):\n\tbl_idname = \"curve.bezier_spline_divide\"\n\tbl_label = \"Bezier Spline Divide\"\n\tbl_description = \"Bezier Divide (enters edit mode) for Fillet Curves\"\n\tbl_options = {'REGISTER', 'UNDO'}\n\n\t# align_matrix for the invoke\n\talign_matrix = Matrix()\n\n\tBezier_t = FloatProperty(\n\t\t\tname=\"t (0% - 100%)\",\n\t\t\tdefault=50.0,\n\t\t\tmin=0.0, soft_min=0.0,\n\t\t\tmax=100.0, soft_max=100.0,\n\t\t\tdescription=\"t (0% - 100%)\"\n\t\t\t)\n\n\t@classmethod\n\tdef poll(cls, context):\n\t\treturn context.scene is not None\n\n\tdef execute(self, context):\n\t\t# go to object mode\n\t\tif bpy.ops.object.mode_set.poll():\n\t\t\tbpy.ops.object.mode_set(mode='OBJECT')\n\t\t\tbpy.ops.object.mode_set(mode='EDIT')\n\n\t\t# turn off undo\n\t\tundo = bpy.context.user_preferences.edit.use_global_undo\n\t\tbpy.context.user_preferences.edit.use_global_undo = False\n\n\t\t# main function\n\t\tspline = bpy.context.object.data.splines.active\n\t\tselected_all = [p for p in spline.bezier_points if p.select_control_point]\n\t\th = subdivide_cubic_bezier(\n\t\t\t\t\tselected_all[0].co, selected_all[0].handle_right,\n\t\t\t\t\tselected_all[1].handle_left, selected_all[1].co, self.Bezier_t / 100\n\t\t\t\t\t)\n\n\t\tselected_all[0].handle_right_type = 'FREE'\n\t\tselected_all[0].handle_left_type = 'FREE'\n\t\tselected_all[1].handle_right_type = 'FREE'\n\t\tselected_all[1].handle_left_type = 'FREE'\n\t\tbpy.ops.curve.subdivide(1)\n\t\tselected_all = [p for p in spline.bezier_points if p.select_control_point]\n\n\t\tselected_all[0].handle_right = h[0]\n\t\tselected_all[1].co = h[2]\n\t\tselected_all[1].handle_left = h[1]\n\t\tselected_all[1].handle_right = h[3]\n\t\tselected_all[2].handle_left = h[4]\n\n\t\t# restore pre operator undo state\n\t\tbpy.context.user_preferences.edit.use_global_undo = undo\n\n\t\treturn {'FINISHED'}\n\n\tdef invoke(self, context, event):\n\t\tself.execute(context)\n\n\t\treturn {'FINISHED'}\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "class", "name": "SimplePanel", "data": "class SimplePanel(Panel):\n\tbl_idname = \"VIEW3D_PT_simple_curve\"\n\tbl_label = \"Simple Curve\"\n\tbl_space_type = \"VIEW_3D\"\n\tbl_region_type = \"TOOLS\"\n\tbl_options = {'DEFAULT_CLOSED'}\n\tbl_category = \"Tools\"\n\n\t@classmethod\n\tdef poll(cls, context):\n\t\tif not context.active_object:\n\t\t\tpass\n\t\telif context.object.s_curve.Simple is True:\n\t\t\treturn (context.object)\n\n\tdef draw(self, context):\n\t\tif context.object.s_curve.Simple is True:\n\t\t\tlayout = self.layout\n\t\t\tobj = context.object\n\t\t\trow = layout.row()\n\n\t\t\tsimple_change = row.operator(\"curve.simple\", text=\"Change\",\n\t\t\t\t\t\t\t\t\t\ticon=\"OUTLINER_DATA_CURVE\")\n\t\t\tsimple_change.Simple_Change = True\n\t\t\tsimple_change.Simple_Delete = obj.name\n\t\t\tsimple_change.Simple_Type = obj.s_curve.Simple_Type\n\t\t\tsimple_change.Simple_startlocation = obj.location\n\t\t\tsimple_change.Simple_endlocation = obj.s_curve.Simple_endlocation\n\n\t\t\tsimple_change.Simple_a = obj.s_curve.Simple_a\n\t\t\tsimple_change.Simple_b = obj.s_curve.Simple_b\n\t\t\tsimple_change.Simple_h = obj.s_curve.Simple_h\n\n\t\t\tsimple_change.Simple_angle = obj.s_curve.Simple_angle\n\t\t\tsimple_change.Simple_startangle = obj.s_curve.Simple_startangle\n\t\t\tsimple_change.Simple_endangle = obj.s_curve.Simple_endangle\n\t\t\tsimple_change.Simple_rotation_euler = obj.rotation_euler\n\n\t\t\tsimple_change.Simple_sides = obj.s_curve.Simple_sides\n\t\t\tsimple_change.Simple_radius = obj.s_curve.Simple_radius\n\t\t\tsimple_change.Simple_center = obj.s_curve.Simple_center\n\t\t\tsimple_change.Simple_width = obj.s_curve.Simple_width\n\t\t\tsimple_change.Simple_length = obj.s_curve.Simple_length\n\t\t\tsimple_change.Simple_rounded = obj.s_curve.Simple_rounded\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "class", "name": "SimpleEdit", "data": "class SimpleEdit(Operator):\n\tbl_idname = \"object._simple_edit\"\n\tbl_label = \"Create Curves\"\n\tbl_description = \"Subdivide and Fillet Curves\"\n\tbl_options = {'REGISTER', 'UNDO'}\n\n\t@classmethod\n\tdef poll(cls, context):\n\t\tvertex = []\n\t\tnselected = []\n\t\tn = 0\n\t\tobj = context.active_object\n\t\tif obj is not None:\n\t\t\tif obj.type == 'CURVE':\n\t\t\t\tfor i in obj.data.splines:\n\t\t\t\t\tfor j in i.bezier_points:\n\t\t\t\t\t\tn += 1\n\t\t\t\t\t\tif j.select_control_point:\n\t\t\t\t\t\t\tnselected.append(n)\n\t\t\t\t\t\t\tvertex.append(obj.matrix_world * j.co)\n\n\t\t\tif len(vertex) > 0 and n > 2:\n\t\t\t\treturn (context.active_object)\n\t\t\tif len(vertex) == 2 and abs(nselected[0] - nselected[1]) == 1:\n\t\t\t\treturn (context.active_object)\n\n\t\tselected = 0\n\t\tfor obj in context.selected_objects:\n\t\t\tif obj.type == 'CURVE':\n\t\t\t\tselected += 1\n\n\t\tif selected >= 2:\n\t\t\treturn (context.selected_objects)\n\n\tdef draw(self, context):\n\t\tvertex = []\n\t\tselected = []\n\t\tn = 0\n\t\tobj = context.active_object\n\t\tif obj is not None:\n\t\t\tif obj.type == 'CURVE':\n\t\t\t\tfor i in obj.data.splines:\n\t\t\t\t\tfor j in i.bezier_points:\n\t\t\t\t\t\tn += 1\n\t\t\t\t\t\tif j.select_control_point:\n\t\t\t\t\t\t\tselected.append(n)\n\t\t\t\t\t\t\tvertex.append(obj.matrix_world * j.co)\n\n\t\t\tif len(vertex) > 0 and n > 2:\n\t\t\t\tlayout = self.layout\n\t\t\t\trow = layout.row()\n\t\t\t\trow.operator(\"curve.bezier_points_fillet\", text=\"Fillet\")\n\n\t\t\tif len(vertex) == 2 and abs(selected[0] - selected[1]) == 1:\n\t\t\t\tlayout = self.layout\n\t\t\t\trow = layout.row()\n\t\t\t\trow.operator(\"curve.bezier_spline_divide\", text=\"Divide\")\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "StartLocationUpdate", "data": "def StartLocationUpdate(self, context):\n\n\tbpy.context.scene.cursor_location = self.Simple_startlocation\n\treturn\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "class", "name": "SimpleVariables", "data": "class SimpleVariables(PropertyGroup):\n\n\tSimple = BoolProperty()\n\tSimple_Change = BoolProperty()\n\n\t# general properties\n\tTypes = [('Point', \"Point\", \"Construct a Point\"),\n\t\t\t ('Line', \"Line\", \"Construct a Line\"),\n\t\t\t ('Distance', \"Distance\", \"Contruct a two point Distance\"),\n\t\t\t ('Angle', \"Angle\", \"Construct an Angle\"),\n\t\t\t ('Circle', \"Circle\", \"Construct a Circle\"),\n\t\t\t ('Ellipse', \"Ellipse\", \"Construct an Ellipse\"),\n\t\t\t ('Arc', \"Arc\", \"Construct an Arc\"),\n\t\t\t ('Sector', \"Sector\", \"Construct a Sector\"),\n\t\t\t ('Segment', \"Segment\", \"Construct a Segment\"),\n\t\t\t ('Rectangle', \"Rectangle\", \"Construct a Rectangle\"),\n\t\t\t ('Rhomb', \"Rhomb\", \"Construct a Rhomb\"),\n\t\t\t ('Polygon', \"Polygon\", \"Construct a Polygon\"),\n\t\t\t ('Polygon_ab', \"Polygon ab\", \"Construct a Polygon ab\"),\n\t\t\t ('Trapezoid', \"Trapezoid\", \"Construct a Trapezoid\")\n\t\t\t]\n\tSimple_Type = EnumProperty(\n\t\t\tname=\"Type\",\n\t\t\tdescription=\"Form of Curve to create\",\n\t\t\titems=Types\n\t\t\t)\n\t# Line properties\n\tSimple_startlocation = FloatVectorProperty(\n\t\t\tname=\"Start location\",\n\t\t\tdescription=\"Start location\",\n\t\t\tdefault=(0.0, 0.0, 0.0),\n\t\t\tsubtype='TRANSLATION',\n\t\t\tupdate=StartLocationUpdate\n\t\t\t)\n\tSimple_endlocation = FloatVectorProperty(\n\t\t\tname=\"End location\",\n\t\t\tdescription=\"End location\",\n\t\t\tdefault=(2.0, 2.0, 2.0),\n\t\t\tsubtype='TRANSLATION'\n\t\t\t)\n\tSimple_rotation_euler = FloatVectorProperty(\n\t\t\tname=\"Rotation\",\n\t\t\tdescription=\"Rotation\",\n\t\t\tdefault=(0.0, 0.0, 0.0),\n\t\t\tsubtype='EULER'\n\t\t\t)\n\t# Trapezoid properties\n\tSimple_a = FloatProperty(\n\t\t\tname=\"Side a\",\n\t\t\tdefault=2.0,\n\t\t\tmin=0.0, soft_min=0.0,\n\t\t\tunit='LENGTH',\n\t\t\tdescription=\"a side Value\"\n\t\t\t)\n\tSimple_b = FloatProperty(\n\t\t\tname=\"Side b\",\n\t\t\tdefault=1.0,\n\t\t\tmin=0.0, soft_min=0.0,\n\t\t\tunit='LENGTH',\n\t\t\tdescription=\"b side Value\"\n\t\t\t)\n\tSimple_h = FloatProperty(\n\t\t\tname=\"Height\",\n\t\t\tdefault=1.0,\n\t\t\tunit='LENGTH',\n\t\t\tdescription=\"Height of the Trapezoid - distance between a and b\"\n\t\t\t)\n\tSimple_angle = FloatProperty(\n\t\t\tname=\"Angle\",\n\t\t\tdefault=45.0,\n\t\t\tdescription=\"Angle\"\n\t\t\t)\n\tSimple_startangle = FloatProperty(\n\t\t\tname=\"Start angle\",\n\t\t\tdefault=0.0,\n\t\t\tmin=-360.0, soft_min=-360.0,\n\t\t\tmax=360.0, soft_max=360.0,\n\t\t\tdescription=\"Start angle\"\n\t\t\t)\n\tSimple_endangle = FloatProperty(\n\t\t\tname=\"End angle\",\n\t\t\tdefault=45.0,\n\t\t\tmin=-360.0, soft_min=-360.0,\n\t\t\tmax=360.0, soft_max=360.0,\n\t\t\tdescription=\"End angle\"\n\t\t\t)\n\tSimple_sides = IntProperty(\n\t\t\tname=\"Sides\",\n\t\t\tdefault=3,\n\t\t\tmin=3, soft_min=3,\n\t\t\tdescription=\"Number of Sides\"\n\t\t\t)\n\tSimple_radius = FloatProperty(\n\t\t\tname=\"Radius\",\n\t\t\tdefault=1.0,\n\t\t\tmin=0.0, soft_min=0.0,\n\t\t\tunit='LENGTH',\n\t\t\tdescription=\"Radius\"\n\t\t\t)\n\tSimple_center = BoolProperty(\n\t\t\tname=\"Length center\",\n\t\t\tdefault=True,\n\t\t\tdescription=\"Length center\"\n\t\t\t)\n\t# Rectangle properties\n\tSimple_width = FloatProperty(\n\t\t\tname=\"Width\",\n\t\t\tdefault=2.0,\n\t\t\tmin=0.0, soft_min=0.0,\n\t\t\tunit='LENGTH',\n\t\t\tdescription=\"Width\"\n\t\t\t)\n\tSimple_length = FloatProperty(\n\t\t\tname=\"Length\",\n\t\t\tdefault=2.0,\n\t\t\tmin=0.0, soft_min=0.0,\n\t\t\tunit='LENGTH',\n\t\t\tdescription=\"Length\"\n\t\t\t)\n\tSimple_rounded = FloatProperty(\n\t\t\tname=\"Rounded\",\n\t\t\tdefault=0.0,\n\t\t\tunit='LENGTH',\n\t\t\tdescription=\"Rounded corners\"\n\t\t\t)\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "class", "name": "INFO_MT_simple_menu", "data": "class INFO_MT_simple_menu(Menu):\n\tbl_idname = \"INFO_MT_simple_menu\"\n\tbl_label = \"2D Objects\"\n\n\tdef draw(self, context):\n\t\tself.layout.operator_context = 'INVOKE_REGION_WIN'\n\n\t\toper1 = self.layout.operator(Simple.bl_idname, text=\"Angle\", icon=\"MOD_CURVE\")\n\t\toper1.Simple_Change = False\n\t\toper1.Simple_Type = \"Angle\"\n\n\t\toper2 = self.layout.operator(Simple.bl_idname, text=\"Arc\", icon=\"MOD_CURVE\")\n\t\toper2.Simple_Change = False\n\t\toper2.Simple_Type = \"Arc\"\n\n\t\toper3 = self.layout.operator(Simple.bl_idname, text=\"Circle\", icon=\"MOD_CURVE\")\n\t\toper3.Simple_Change = False\n\t\toper3.Simple_Type = \"Circle\"\n\n\t\toper4 = self.layout.operator(Simple.bl_idname, text=\"Distance\", icon=\"MOD_CURVE\")\n\t\toper4.Simple_Change = False\n\t\toper4.Simple_Type = \"Distance\"\n\n\t\toper5 = self.layout.operator(Simple.bl_idname, text=\"Ellipse\", icon=\"MOD_CURVE\")\n\t\toper5.Simple_Change = False\n\t\toper5.Simple_Type = \"Ellipse\"\n\n\t\toper6 = self.layout.operator(Simple.bl_idname, text=\"Line\", icon=\"MOD_CURVE\")\n\t\toper6.Simple_Change = False\n\t\toper6.Simple_Type = \"Line\"\n\n\t\toper7 = self.layout.operator(Simple.bl_idname, text=\"Point\", icon=\"MOD_CURVE\")\n\t\toper7.Simple_Change = False\n\t\toper7.Simple_Type = \"Point\"\n\n\t\toper8 = self.layout.operator(Simple.bl_idname, text=\"Polygon\", icon=\"MOD_CURVE\")\n\t\toper8.Simple_Change = False\n\t\toper8.Simple_Type = \"Polygon\"\n\n\t\toper9 = self.layout.operator(Simple.bl_idname, text=\"Polygon ab\", icon=\"MOD_CURVE\")\n\t\toper9.Simple_Change = False\n\t\toper9.Simple_Type = \"Polygon_ab\"\n\n\t\toper10 = self.layout.operator(Simple.bl_idname, text=\"Rectangle\", icon=\"MOD_CURVE\")\n\t\toper10.Simple_Change = False\n\t\toper10.Simple_Type = \"Rectangle\"\n\n\t\toper11 = self.layout.operator(Simple.bl_idname, text=\"Rhomb\", icon=\"MOD_CURVE\")\n\t\toper11.Simple_Change = False\n\t\toper11.Simple_Type = \"Rhomb\"\n\n\t\toper12 = self.layout.operator(Simple.bl_idname, text=\"Sector\", icon=\"MOD_CURVE\")\n\t\toper12.Simple_Change = False\n\t\toper12.Simple_Type = \"Sector\"\n\n\t\toper13 = self.layout.operator(Simple.bl_idname, text=\"Segment\", icon=\"MOD_CURVE\")\n\t\toper13.Simple_Change = False\n\t\toper13.Simple_Type = \"Segment\"\n\n\t\toper14 = self.layout.operator(Simple.bl_idname, text=\"Trapezoid\", icon=\"MOD_CURVE\")\n\t\toper14.Simple_Change = False\n\t\toper14.Simple_Type = \"Trapezoid\"\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "Simple_button", "data": "def Simple_button(self, context):\n\tlayout = self.layout\n\tlayout.separator()\n\tself.layout.menu(\"INFO_MT_simple_menu\", icon=\"MOD_CURVE\")\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "register", "data": "def register():\n\tbpy.utils.register_class(Simple)\n\tbpy.utils.register_class(BezierPointsFillet)\n\tbpy.utils.register_class(BezierDivide)\n\tbpy.utils.register_class(SimplePanel)\n\tbpy.utils.register_class(SimpleEdit)\n\tbpy.utils.register_class(INFO_MT_simple_menu)\n\tbpy.utils.register_class(SimpleVariables)\n\n\tbpy.types.INFO_MT_curve_add.append(Simple_button)\n\n\tbpy.types.Object.s_curve = PointerProperty(type=SimpleVariables)\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}, {"term": "def", "name": "unregister", "data": "def unregister():\n\tbpy.utils.unregister_class(Simple)\n\tbpy.utils.unregister_class(BezierPointsFillet)\n\tbpy.utils.unregister_class(BezierDivide)\n\tbpy.utils.unregister_class(SimplePanel)\n\tbpy.utils.unregister_class(SimpleEdit)\n\tbpy.utils.unregister_class(INFO_MT_simple_menu)\n\tbpy.utils.unregister_class(SimpleVariables)\n\n\tbpy.types.INFO_MT_curve_add.remove(Simple_button)\n\tdel bpy.types.Object.s_curve\n\n", "description": null, "category": "simple", "imports": ["import bpy", "from bpy.types import (", "from bpy.props import (", "from mathutils import (", "from math import (", "# from bpy_extras.object_utils import *"]}], [{"term": "def", "name": "test_jsonl2iso_simple_example_on_standard_streams", "data": "def test_jsonl2iso_simple_example_on_standard_streams():\n\trunner = CliRunner(mix_stderr=False)\n\tresult = runner.invoke(jsonl2iso, input=simple_example_jsonl)\n\tassert result.exit_code == 0\n\tassert result.stdout_bytes == simple_example_iso\n\tassert result.stderr_bytes == b\"\"\n\n", "description": null, "category": "simple", "imports": ["from click.testing import CliRunner", "from ioisis.__main__ import iso2jsonl, jsonl2iso"]}, {"term": "def", "name": "test_iso2jsonl_simple_example_on_standard_streams", "data": "def test_iso2jsonl_simple_example_on_standard_streams():\n\trunner = CliRunner(mix_stderr=False)\n\tresult = runner.invoke(iso2jsonl, input=simple_example_iso)\n\tassert result.exit_code == 0\n\tassert result.stdout_bytes == simple_example_jsonl\n\tassert result.stderr_bytes == b\"\"\n", "description": null, "category": "simple", "imports": ["from click.testing import CliRunner", "from ioisis.__main__ import iso2jsonl, jsonl2iso"]}], [{"term": "class", "name": "GLUtesselator", "data": "class GLUtesselator( glustruct.GLUStruct, simple.GLUtesselator):\n\t\"\"\"Implementation class for GLUTessellator structures in OpenGL-ctypes\"\"\"\n\tFUNCTION_TYPE = PLATFORM.functionTypeFor(PLATFORM.GLU)\n\tCALLBACK_TYPES = {\n\t\t# mapping from \"which\" GLU enumeration to a ctypes function type\n\t\tsimple.GLU_TESS_BEGIN: FUNCTION_TYPE( None, simple.GLenum ),\n\t\tsimple.GLU_TESS_BEGIN_DATA: FUNCTION_TYPE( \n\t\t\tNone, simple.GLenum, ctypes.c_void_p \n\t\t),\n\t\tsimple.GLU_TESS_EDGE_FLAG: FUNCTION_TYPE( None, simple.GLboolean),\n\t\tsimple.GLU_TESS_EDGE_FLAG_DATA: FUNCTION_TYPE( \n\t\t\tNone, simple.GLboolean, ctypes.c_void_p \n\t\t),\n\t\tsimple.GLU_TESS_VERTEX: FUNCTION_TYPE( None, ctypes.c_void_p ),\n\t\tsimple.GLU_TESS_VERTEX_DATA: FUNCTION_TYPE( \n\t\t\tNone, ctypes.c_void_p, ctypes.c_void_p\n\t\t),\n\t\tsimple.GLU_TESS_END: FUNCTION_TYPE( None ),\n\t\tsimple.GLU_TESS_END_DATA: FUNCTION_TYPE( None, ctypes.c_void_p), \n\t\tsimple.GLU_TESS_COMBINE: FUNCTION_TYPE( \n\t\t\tNone, \n\t\t\tctypes.POINTER(simple.GLdouble), \n\t\t\tctypes.POINTER(ctypes.c_void_p), \n\t\t\tctypes.POINTER(simple.GLfloat),\n\t\t\tctypes.POINTER(ctypes.c_void_p)\n\t\t),\n\t\tsimple.GLU_TESS_COMBINE_DATA: FUNCTION_TYPE( \n\t\t\tNone, \n\t\t\tctypes.POINTER(simple.GLdouble), \n\t\t\tctypes.POINTER(ctypes.c_void_p), \n\t\t\tctypes.POINTER(simple.GLfloat),\n\t\t\tctypes.POINTER(ctypes.c_void_p),\n\t\t\tctypes.c_void_p,\n\t\t),\n\t\tsimple.GLU_TESS_ERROR: FUNCTION_TYPE( None, simple.GLenum), \n\t\tsimple.GLU_TESS_ERROR_DATA: FUNCTION_TYPE( \n\t\t\tNone, simple.GLenum, ctypes.c_void_p\n\t\t), \n\t\tsimple.GLU_ERROR : FUNCTION_TYPE( None, simple.GLenum )\n\t}\n\tWRAPPER_METHODS = {\n\t\tsimple.GLU_TESS_BEGIN_DATA: 'dataWrapper',\n\t\tsimple.GLU_TESS_EDGE_FLAG_DATA: 'dataWrapper',\n\t\tsimple.GLU_TESS_VERTEX: 'vertexWrapper',\n\t\tsimple.GLU_TESS_VERTEX_DATA: 'vertexWrapper',\n\t\tsimple.GLU_TESS_END_DATA: 'dataWrapper', \n\t\tsimple.GLU_TESS_COMBINE: 'combineWrapper',\n\t\tsimple.GLU_TESS_COMBINE_DATA: 'combineWrapper',\n\t\tsimple.GLU_TESS_ERROR_DATA: 'dataWrapper', \n\t}\n\tdef gluTessVertex( self, location, data=None ):\n\t\t\"\"\"Add a vertex to this tessellator, storing data for later lookup\"\"\"\n\t\tvertexCache = getattr( self, 'vertexCache', None )\n\t\tif vertexCache is None:\n\t\t\tself.vertexCache = []\n\t\t\tvertexCache = self.vertexCache\n\t\tlocation = arrays.GLdoubleArray.asArray( location, constants.GL_DOUBLE )\n\t\tif arrays.GLdoubleArray.arraySize( location ) != 3:\n\t\t\traise ValueError( \"\"\"Require 3 doubles for array location, got: %s\"\"\"%(location,))\n\t\toorValue = self.noteObject(data)\n\t\tvp = ctypes.c_void_p( oorValue )\n\t\tself.vertexCache.append( location )\n\t\treturn gluTessVertexBase( self, location, vp )\n\tdef gluTessBeginPolygon( self, data ):\n\t\t\"\"\"Note the object pointer to return it as a Python object\"\"\"\n\t\treturn simple.gluTessBeginPolygon( \n\t\t\tself, ctypes.c_void_p(self.noteObject( data ))\n\t\t)\n\tdef combineWrapper( self, function ):\n\t\t\"\"\"Wrap a Python function with ctypes-compatible wrapper for combine callback\n\t\t\n\t\tFor a Python combine callback, the signature looks like this:\n\t\t\tdef combine(\n\t\t\t\tGLdouble coords[3], \n\t\t\t\tvoid *vertex_data[4], \n\t\t\t\tGLfloat weight[4]\n\t\t\t):\n\t\t\t\treturn data\n\t\tWhile the C signature looks like this:\n\t\t\tvoid combine( \n\t\t\t\tGLdouble coords[3], \n\t\t\t\tvoid *vertex_data[4], \n\t\t\t\tGLfloat weight[4], \n\t\t\t\tvoid **outData \n\t\t\t)\n\t\t\"\"\"\n\t\tif (function is not None) and (not hasattr( function,'__call__' )):\n\t\t\traise TypeError( \"\"\"Require a callable callback, got:  %s\"\"\"%(function,))\n\t\tdef wrap( coords, vertex_data, weight, outData, *args ):\n\t\t\t\"\"\"The run-time wrapper around the function\"\"\"\n\t\t\tcoords = self.ptrAsArray( coords, 3, arrays.GLdoubleArray )\n\t\t\tweight = self.ptrAsArray( weight, 4, arrays.GLfloatArray )\n\t\t\t# find the original python objects for vertex data\n\t\t\tvertex_data = [ self.originalObject( vertex_data[i] ) for i in range(4) ]\n\t\t\targs = tuple( [ self.originalObject( x ) for x in args ] )\n\t\t\ttry:\n\t\t\t\tresult = function( coords, vertex_data, weight, *args )\n\t\t\texcept Exception, err:\n\t\t\t\traise err.__class__(\n\t\t\t\t\t\"\"\"Failure during combine callback %r with args( %s,%s,%s,*%s):\\n%s\"\"\"%(\n\t\t\t\t\t\tfunction, coords, vertex_data, weight, args, str(err),\n\t\t\t\t\t)\n\t\t\t\t)\n\t\t\toutP = ctypes.c_void_p(self.noteObject(result))\n\t\t\toutData[0] = outP\n\t\t\treturn None\n\t\treturn wrap\n\tdef dataWrapper( self, function ):\n\t\t\"\"\"Wrap a function which only has the one data-pointer as last arg\"\"\"\n\t\tif (function is not None) and (not hasattr( function,'__call__' )):\n\t\t\traise TypeError( \"\"\"Require a callable callback, got:  %s\"\"\"%(function,))\n\t\tdef wrap( *args ):\n\t\t\t\"\"\"Just return the original object for polygon_data\"\"\"\n\t\t\targs = args[:-1] + ( self.originalObject(args[-1]), )\n\t\t\ttry:\n\t\t\t\treturn function( *args )\n\t\t\texcept Exception, err:\n\t\t\t\terr.args += (function,args)\n\t\t\t\traise\n\t\treturn wrap\n\tdef dataWrapper2( self, function ):\n\t\t\"\"\"Wrap a function which has two data-pointers as last args\"\"\"\n\t\tif (function is not None) and (not hasattr( function,'__call__' )):\n\t\t\traise TypeError( \"\"\"Require a callable callback, got:  %s\"\"\"%(function,))\n\t\tdef wrap( *args ):\n\t\t\t\"\"\"Just return the original object for polygon_data\"\"\"\n\t\t\targs = args[:-2] + ( self.originalObject(args[-2]), self.originalObject(args[-1]), )\n\t\t\ttry:\n\t\t\t\treturn function( *args )\n\t\t\texcept Exception, err:\n\t\t\t\terr.args += (function,args)\n\t\t\t\traise\n\t\treturn wrap\n\tdef vertexWrapper( self, function ):\n\t\t\"\"\"Converts a vertex-pointer into an OOR vertex for processing\"\"\"\n\t\tif (function is not None) and (not hasattr( function,'__call__' )):\n\t\t\traise TypeError( \"\"\"Require a callable callback, got:  %s\"\"\"%(function,))\n\t\tdef wrap( vertex, data=None ):\n\t\t\t\"\"\"Just return the original object for polygon_data\"\"\"\n\t\t\tvertex = self.originalObject(vertex)\n\t\t\ttry:\n\t\t\t\tif data is not None:\n\t\t\t\t\tdata = self.originalObject(data)\n\t\t\t\t\treturn function( vertex, data )\n\t\t\t\telse:\n\t\t\t\t\treturn function( vertex )\n\t\t\texcept Exception, err:\n\t\t\t\terr.args += (function,(vertex,data))\n\t\t\t\traise\n\t\treturn wrap\n", "description": "Implementation class for GLUTessellator structures in OpenGL-ctypes", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL.platform import GLU,createBaseFunction", "from OpenGL.GLU import glustruct", "from OpenGL import arrays, constants", "from OpenGL.platform import PLATFORM", "from OpenGL.lazywrapper import lazy", "import ctypes"]}, {"term": "def", "name": "gluTessCallback", "data": "def gluTessCallback( tess, which, function ):\n\t\"\"\"Set a given gluTessellator callback for the given tessellator\"\"\"\n", "description": "Set a given gluTessellator callback for the given tessellator", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL.platform import GLU,createBaseFunction", "from OpenGL.GLU import glustruct", "from OpenGL import arrays, constants", "from OpenGL.platform import PLATFORM", "from OpenGL.lazywrapper import lazy", "import ctypes"]}, {"term": "def", "name": "gluTessBeginPolygon", "data": "def gluTessBeginPolygon( tess, data ):\n\t\"\"\"Start definition of polygon in the tessellator\"\"\"\n", "description": "Start definition of polygon in the tessellator", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL.platform import GLU,createBaseFunction", "from OpenGL.GLU import glustruct", "from OpenGL import arrays, constants", "from OpenGL.platform import PLATFORM", "from OpenGL.lazywrapper import lazy", "import ctypes"]}, {"term": "def", "name": "gluTessVertex", "data": "def gluTessVertex( tess, location, data=None ):\n\t\"\"\"Add a vertex to the tessellator's current polygon\"\"\"\n\treturn tess.gluTessVertex( location, data )\n", "description": "Add a vertex to the tessellator's current polygon", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL.platform import GLU,createBaseFunction", "from OpenGL.GLU import glustruct", "from OpenGL import arrays, constants", "from OpenGL.platform import PLATFORM", "from OpenGL.lazywrapper import lazy", "import ctypes"]}, {"term": "def", "name": "gluNewTess", "data": "def gluNewTess( baseFunction ):\n\t\"\"\"Get a new tessellator object (just unpacks the pointer for you)\"\"\"\n\treturn baseFunction()[0]\n", "description": "Get a new tessellator object (just unpacks the pointer for you)", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL.platform import GLU,createBaseFunction", "from OpenGL.GLU import glustruct", "from OpenGL import arrays, constants", "from OpenGL.platform import PLATFORM", "from OpenGL.lazywrapper import lazy", "import ctypes"]}, {"term": "def", "name": "gluGetTessProperty", "data": "def gluGetTessProperty( baseFunction, tess, which, data=None ):\n\t\"\"\"Retrieve single double for a tessellator property\"\"\"\n\tif data is None:\n\t\tdata = simple.GLdouble( 0.0 )\n\t\tbaseFunction( tess, which, data )\n\t\treturn data.value \n\telse:\n\t\treturn baseFunction( tess, which, data )\n", "description": "Retrieve single double for a tessellator property", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL.platform import GLU,createBaseFunction", "from OpenGL.GLU import glustruct", "from OpenGL import arrays, constants", "from OpenGL.platform import PLATFORM", "from OpenGL.lazywrapper import lazy", "import ctypes"]}], [{"term": "class", "name": "SimpleSitemap", "data": "class SimpleSitemap(Sitemap):\n\tchangefreq = \"never\"\n\tpriority = 0.5\n\tlocation = '/location/'\n\tlastmod = datetime.now()\n\n\tdef items(self):\n\t\treturn [object()]\n", "description": null, "category": "simple", "imports": ["from datetime import datetime", "from django.conf.urls.defaults import *", "from django.contrib.sitemaps import Sitemap, GenericSitemap, FlatPageSitemap", "from django.contrib.auth.models import User"]}], [{"term": "def", "name": "ncdefasync_parse_motion_alarm", "data": "async def async_parse_motion_alarm(uid: str, msg) -> Event:\n\t\"\"\"Handle parsing event message.\n\n\tTopic: tns1:VideoSource/MotionAlarm\n\t\"\"\"\n\ttry:\n\t\tsource = msg.Message._value_1.Source.SimpleItem[0].Value\n\t\treturn Event(\n\t\t\tf\"{uid}_{msg.Topic._value_1}_{source}\",\n\t\t\tf\"{source} Motion Alarm\",\n\t\t\t\"binary_sensor\",\n\t\t\t\"motion\",\n\t\t\tNone,\n\t\t\tmsg.Message._value_1.Data.SimpleItem[0].Value == \"true\",\n\t\t)\n\texcept (AttributeError, KeyError):\n\t\treturn None\n\n", "description": "Handle parsing event message.\n\n\tTopic: tns1:VideoSource/MotionAlarm\n\t", "category": "simple", "imports": ["from collections.abc import Callable, Coroutine", "from typing import Any", "from homeassistant.util import dt as dt_util", "from homeassistant.util.decorator import Registry", "from .models import Event"]}, {"term": "def", "name": "ncdefasync_parse_image_too_blurry", "data": "async def async_parse_image_too_blurry(uid: str, msg) -> Event:\n\t\"\"\"Handle parsing event message.\n\n\tTopic: tns1:VideoSource/ImageTooBlurry/*\n\t\"\"\"\n\ttry:\n\t\tsource = msg.Message._value_1.Source.SimpleItem[0].Value\n\t\treturn Event(\n\t\t\tf\"{uid}_{msg.Topic._value_1}_{source}\",\n\t\t\tf\"{source} Image Too Blurry\",\n\t\t\t\"binary_sensor\",\n\t\t\t\"problem\",\n\t\t\tNone,\n\t\t\tmsg.Message._value_1.Data.SimpleItem[0].Value == \"true\",\n\t\t)\n\texcept (AttributeError, KeyError):\n\t\treturn None\n\n", "description": "Handle parsing event message.\n\n\tTopic: tns1:VideoSource/ImageTooBlurry/*\n\t", "category": "simple", "imports": ["from collections.abc import Callable, Coroutine", "from typing import Any", "from homeassistant.util import dt as dt_util", "from homeassistant.util.decorator import Registry", "from .models import Event"]}, {"term": "def", "name": "ncdefasync_parse_image_too_dark", "data": "async def async_parse_image_too_dark(uid: str, msg) -> Event:\n\t\"\"\"Handle parsing event message.\n\n\tTopic: tns1:VideoSource/ImageTooDark/*\n\t\"\"\"\n\ttry:\n\t\tsource = msg.Message._value_1.Source.SimpleItem[0].Value\n\t\treturn Event(\n\t\t\tf\"{uid}_{msg.Topic._value_1}_{source}\",\n\t\t\tf\"{source} Image Too Dark\",\n\t\t\t\"binary_sensor\",\n\t\t\t\"problem\",\n\t\t\tNone,\n\t\t\tmsg.Message._value_1.Data.SimpleItem[0].Value == \"true\",\n\t\t)\n\texcept (AttributeError, KeyError):\n\t\treturn None\n\n", "description": "Handle parsing event message.\n\n\tTopic: tns1:VideoSource/ImageTooDark/*\n\t", "category": "simple", "imports": ["from collections.abc import Callable, Coroutine", "from typing import Any", "from homeassistant.util import dt as dt_util", "from homeassistant.util.decorator import Registry", "from .models import Event"]}, {"term": "def", "name": "ncdefasync_parse_image_too_bright", "data": "async def async_parse_image_too_bright(uid: str, msg) -> Event:\n\t\"\"\"Handle parsing event message.\n\n\tTopic: tns1:VideoSource/ImageTooBright/*\n\t\"\"\"\n\ttry:\n\t\tsource = msg.Message._value_1.Source.SimpleItem[0].Value\n\t\treturn Event(\n\t\t\tf\"{uid}_{msg.Topic._value_1}_{source}\",\n\t\t\tf\"{source} Image Too Bright\",\n\t\t\t\"binary_sensor\",\n\t\t\t\"problem\",\n\t\t\tNone,\n\t\t\tmsg.Message._value_1.Data.SimpleItem[0].Value == \"true\",\n\t\t)\n\texcept (AttributeError, KeyError):\n\t\treturn None\n\n", "description": "Handle parsing event message.\n\n\tTopic: tns1:VideoSource/ImageTooBright/*\n\t", "category": "simple", "imports": ["from collections.abc import Callable, Coroutine", "from typing import Any", "from homeassistant.util import dt as dt_util", "from homeassistant.util.decorator import Registry", "from .models import Event"]}, {"term": "def", "name": "ncdefasync_parse_scene_change", "data": "async def async_parse_scene_change(uid: str, msg) -> Event:\n\t\"\"\"Handle parsing event message.\n\n\tTopic: tns1:VideoSource/GlobalSceneChange/*\n\t\"\"\"\n\ttry:\n\t\tsource = msg.Message._value_1.Source.SimpleItem[0].Value\n\t\treturn Event(\n\t\t\tf\"{uid}_{msg.Topic._value_1}_{source}\",\n\t\t\tf\"{source} Global Scene Change\",\n\t\t\t\"binary_sensor\",\n\t\t\t\"problem\",\n\t\t\tNone,\n\t\t\tmsg.Message._value_1.Data.SimpleItem[0].Value == \"true\",\n\t\t)\n\texcept (AttributeError, KeyError):\n\t\treturn None\n\n", "description": "Handle parsing event message.\n\n\tTopic: tns1:VideoSource/GlobalSceneChange/*\n\t", "category": "simple", "imports": ["from collections.abc import Callable, Coroutine", "from typing import Any", "from homeassistant.util import dt as dt_util", "from homeassistant.util.decorator import Registry", "from .models import Event"]}, {"term": "def", "name": "ncdefasync_parse_detected_sound", "data": "async def async_parse_detected_sound(uid: str, msg) -> Event:\n\t\"\"\"Handle parsing event message.\n\n\tTopic: tns1:AudioAnalytics/Audio/DetectedSound\n\t\"\"\"\n\ttry:\n\t\taudio_source = \"\"\n\t\taudio_analytics = \"\"\n\t\trule = \"\"\n\t\tfor source in msg.Message._value_1.Source.SimpleItem:\n\t\t\tif source.Name == \"AudioSourceConfigurationToken\":\n\t\t\t\taudio_source = source.Value\n\t\t\tif source.Name == \"AudioAnalyticsConfigurationToken\":\n\t\t\t\taudio_analytics = source.Value\n\t\t\tif source.Name == \"Rule\":\n\t\t\t\trule = source.Value\n\n\t\treturn Event(\n\t\t\tf\"{uid}_{msg.Topic._value_1}_{audio_source}_{audio_analytics}_{rule}\",\n\t\t\tf\"{rule} Detected Sound\",\n\t\t\t\"binary_sensor\",\n\t\t\t\"sound\",\n\t\t\tNone,\n\t\t\tmsg.Message._value_1.Data.SimpleItem[0].Value == \"true\",\n\t\t)\n\texcept (AttributeError, KeyError):\n\t\treturn None\n\n", "description": "Handle parsing event message.\n\n\tTopic: tns1:AudioAnalytics/Audio/DetectedSound\n\t", "category": "simple", "imports": ["from collections.abc import Callable, Coroutine", "from typing import Any", "from homeassistant.util import dt as dt_util", "from homeassistant.util.decorator import Registry", "from .models import Event"]}, {"term": "def", "name": "ncdefasync_parse_field_detector", "data": "async def async_parse_field_detector(uid: str, msg) -> Event:\n\t\"\"\"Handle parsing event message.\n\n\tTopic: tns1:RuleEngine/FieldDetector/ObjectsInside\n\t\"\"\"\n\ttry:\n\t\tvideo_source = \"\"\n\t\tvideo_analytics = \"\"\n\t\trule = \"\"\n\t\tfor source in msg.Message._value_1.Source.SimpleItem:\n\t\t\tif source.Name == \"VideoSourceConfigurationToken\":\n\t\t\t\tvideo_source = source.Value\n\t\t\tif source.Name == \"VideoAnalyticsConfigurationToken\":\n\t\t\t\tvideo_analytics = source.Value\n\t\t\tif source.Name == \"Rule\":\n\t\t\t\trule = source.Value\n\n\t\tevt = Event(\n\t\t\tf\"{uid}_{msg.Topic._value_1}_{video_source}_{video_analytics}_{rule}\",\n\t\t\tf\"{rule} Field Detection\",\n\t\t\t\"binary_sensor\",\n\t\t\t\"motion\",\n\t\t\tNone,\n\t\t\tmsg.Message._value_1.Data.SimpleItem[0].Value == \"true\",\n\t\t)\n\t\treturn evt\n\texcept (AttributeError, KeyError):\n\t\treturn None\n\n", "description": "Handle parsing event message.\n\n\tTopic: tns1:RuleEngine/FieldDetector/ObjectsInside\n\t", "category": "simple", "imports": ["from collections.abc import Callable, Coroutine", "from typing import Any", "from homeassistant.util import dt as dt_util", "from homeassistant.util.decorator import Registry", "from .models import Event"]}, {"term": "def", "name": "ncdefasync_parse_cell_motion_detector", "data": "async def async_parse_cell_motion_detector(uid: str, msg) -> Event:\n\t\"\"\"Handle parsing event message.\n\n\tTopic: tns1:RuleEngine/CellMotionDetector/Motion\n\t\"\"\"\n\ttry:\n\t\tvideo_source = \"\"\n\t\tvideo_analytics = \"\"\n\t\trule = \"\"\n\t\tfor source in msg.Message._value_1.Source.SimpleItem:\n\t\t\tif source.Name == \"VideoSourceConfigurationToken\":\n\t\t\t\tvideo_source = source.Value\n\t\t\tif source.Name == \"VideoAnalyticsConfigurationToken\":\n\t\t\t\tvideo_analytics = source.Value\n\t\t\tif source.Name == \"Rule\":\n\t\t\t\trule = source.Value\n\n\t\treturn Event(\n\t\t\tf\"{uid}_{msg.Topic._value_1}_{video_source}_{video_analytics}_{rule}\",\n\t\t\tf\"{rule} Cell Motion Detection\",\n\t\t\t\"binary_sensor\",\n\t\t\t\"motion\",\n\t\t\tNone,\n\t\t\tmsg.Message._value_1.Data.SimpleItem[0].Value == \"true\",\n\t\t)\n\texcept (AttributeError, KeyError):\n\t\treturn None\n\n", "description": "Handle parsing event message.\n\n\tTopic: tns1:RuleEngine/CellMotionDetector/Motion\n\t", "category": "simple", "imports": ["from collections.abc import Callable, Coroutine", "from typing import Any", "from homeassistant.util import dt as dt_util", "from homeassistant.util.decorator import Registry", "from .models import Event"]}, {"term": "def", "name": "ncdefasync_parse_motion_region_detector", "data": "async def async_parse_motion_region_detector(uid: str, msg) -> Event:\n\t\"\"\"Handle parsing event message.\n\n\tTopic: tns1:RuleEngine/MotionRegionDetector/Motion\n\t\"\"\"\n\ttry:\n\t\tvideo_source = \"\"\n\t\tvideo_analytics = \"\"\n\t\trule = \"\"\n\t\tfor source in msg.Message._value_1.Source.SimpleItem:\n\t\t\tif source.Name == \"VideoSourceConfigurationToken\":\n\t\t\t\tvideo_source = source.Value\n\t\t\tif source.Name == \"VideoAnalyticsConfigurationToken\":\n\t\t\t\tvideo_analytics = source.Value\n\t\t\tif source.Name == \"Rule\":\n\t\t\t\trule = source.Value\n\n\t\treturn Event(\n\t\t\tf\"{uid}_{msg.Topic._value_1}_{video_source}_{video_analytics}_{rule}\",\n\t\t\tf\"{rule} Motion Region Detection\",\n\t\t\t\"binary_sensor\",\n\t\t\t\"motion\",\n\t\t\tNone,\n\t\t\tmsg.Message._value_1.Data.SimpleItem[0].Value == \"true\",\n\t\t)\n\texcept (AttributeError, KeyError):\n\t\treturn None\n\n", "description": "Handle parsing event message.\n\n\tTopic: tns1:RuleEngine/MotionRegionDetector/Motion\n\t", "category": "simple", "imports": ["from collections.abc import Callable, Coroutine", "from typing import Any", "from homeassistant.util import dt as dt_util", "from homeassistant.util.decorator import Registry", "from .models import Event"]}, {"term": "def", "name": "ncdefasync_parse_tamper_detector", "data": "async def async_parse_tamper_detector(uid: str, msg) -> Event:\n\t\"\"\"Handle parsing event message.\n\n\tTopic: tns1:RuleEngine/TamperDetector/Tamper\n\t\"\"\"\n\ttry:\n\t\tvideo_source = \"\"\n\t\tvideo_analytics = \"\"\n\t\trule = \"\"\n\t\tfor source in msg.Message._value_1.Source.SimpleItem:\n\t\t\tif source.Name == \"VideoSourceConfigurationToken\":\n\t\t\t\tvideo_source = source.Value\n\t\t\tif source.Name == \"VideoAnalyticsConfigurationToken\":\n\t\t\t\tvideo_analytics = source.Value\n\t\t\tif source.Name == \"Rule\":\n\t\t\t\trule = source.Value\n\n\t\treturn Event(\n\t\t\tf\"{uid}_{msg.Topic._value_1}_{video_source}_{video_analytics}_{rule}\",\n\t\t\tf\"{rule} Tamper Detection\",\n\t\t\t\"binary_sensor\",\n\t\t\t\"problem\",\n\t\t\tNone,\n\t\t\tmsg.Message._value_1.Data.SimpleItem[0].Value == \"true\",\n\t\t)\n\texcept (AttributeError, KeyError):\n\t\treturn None\n\n", "description": "Handle parsing event message.\n\n\tTopic: tns1:RuleEngine/TamperDetector/Tamper\n\t", "category": "simple", "imports": ["from collections.abc import Callable, Coroutine", "from typing import Any", "from homeassistant.util import dt as dt_util", "from homeassistant.util.decorator import Registry", "from .models import Event"]}, {"term": "def", "name": "ncdefasync_parse_storage_failure", "data": "async def async_parse_storage_failure(uid: str, msg) -> Event:\n\t\"\"\"Handle parsing event message.\n\n\tTopic: tns1:Device/HardwareFailure/StorageFailure\n\t\"\"\"\n\ttry:\n\t\tsource = msg.Message._value_1.Source.SimpleItem[0].Value\n\t\treturn Event(\n\t\t\tf\"{uid}_{msg.Topic._value_1}_{source}\",\n\t\t\t\"Storage Failure\",\n\t\t\t\"binary_sensor\",\n\t\t\t\"problem\",\n\t\t\tNone,\n\t\t\tmsg.Message._value_1.Data.SimpleItem[0].Value == \"true\",\n\t\t)\n\texcept (AttributeError, KeyError):\n\t\treturn None\n\n", "description": "Handle parsing event message.\n\n\tTopic: tns1:Device/HardwareFailure/StorageFailure\n\t", "category": "simple", "imports": ["from collections.abc import Callable, Coroutine", "from typing import Any", "from homeassistant.util import dt as dt_util", "from homeassistant.util.decorator import Registry", "from .models import Event"]}, {"term": "def", "name": "ncdefasync_parse_processor_usage", "data": "async def async_parse_processor_usage(uid: str, msg) -> Event:\n\t\"\"\"Handle parsing event message.\n\n\tTopic: tns1:Monitoring/ProcessorUsage\n\t\"\"\"\n\ttry:\n\t\tusage = float(msg.Message._value_1.Data.SimpleItem[0].Value)\n\t\tif usage <= 1:\n\t\t\tusage *= 100\n\n\t\treturn Event(\n\t\t\tf\"{uid}_{msg.Topic._value_1}\",\n\t\t\t\"Processor Usage\",\n\t\t\t\"sensor\",\n\t\t\tNone,\n\t\t\t\"percent\",\n\t\t\tint(usage),\n\t\t)\n\texcept (AttributeError, KeyError):\n\t\treturn None\n\n", "description": "Handle parsing event message.\n\n\tTopic: tns1:Monitoring/ProcessorUsage\n\t", "category": "simple", "imports": ["from collections.abc import Callable, Coroutine", "from typing import Any", "from homeassistant.util import dt as dt_util", "from homeassistant.util.decorator import Registry", "from .models import Event"]}, {"term": "def", "name": "ncdefasync_parse_last_reboot", "data": "async def async_parse_last_reboot(uid: str, msg) -> Event:\n\t\"\"\"Handle parsing event message.\n\n\tTopic: tns1:Monitoring/OperatingTime/LastReboot\n\t\"\"\"\n\ttry:\n\t\treturn Event(\n\t\t\tf\"{uid}_{msg.Topic._value_1}\",\n\t\t\t\"Last Reboot\",\n\t\t\t\"sensor\",\n\t\t\t\"timestamp\",\n\t\t\tNone,\n\t\t\tdt_util.as_local(\n\t\t\t\tdt_util.parse_datetime(msg.Message._value_1.Data.SimpleItem[0].Value)\n\t\t\t),\n\t\t)\n\texcept (AttributeError, KeyError, ValueError):\n\t\treturn None\n\n", "description": "Handle parsing event message.\n\n\tTopic: tns1:Monitoring/OperatingTime/LastReboot\n\t", "category": "simple", "imports": ["from collections.abc import Callable, Coroutine", "from typing import Any", "from homeassistant.util import dt as dt_util", "from homeassistant.util.decorator import Registry", "from .models import Event"]}, {"term": "def", "name": "ncdefasync_parse_last_reset", "data": "async def async_parse_last_reset(uid: str, msg) -> Event:\n\t\"\"\"Handle parsing event message.\n\n\tTopic: tns1:Monitoring/OperatingTime/LastReset\n\t\"\"\"\n\ttry:\n\t\treturn Event(\n\t\t\tf\"{uid}_{msg.Topic._value_1}\",\n\t\t\t\"Last Reset\",\n\t\t\t\"sensor\",\n\t\t\t\"timestamp\",\n\t\t\tNone,\n\t\t\tdt_util.as_local(\n\t\t\t\tdt_util.parse_datetime(msg.Message._value_1.Data.SimpleItem[0].Value)\n\t\t\t),\n\t\t\tentity_enabled=False,\n\t\t)\n\texcept (AttributeError, KeyError, ValueError):\n\t\treturn None\n\n", "description": "Handle parsing event message.\n\n\tTopic: tns1:Monitoring/OperatingTime/LastReset\n\t", "category": "simple", "imports": ["from collections.abc import Callable, Coroutine", "from typing import Any", "from homeassistant.util import dt as dt_util", "from homeassistant.util.decorator import Registry", "from .models import Event"]}, {"term": "def", "name": "ncdefasync_parse_last_clock_sync", "data": "async def async_parse_last_clock_sync(uid: str, msg) -> Event:\n\t\"\"\"Handle parsing event message.\n\n\tTopic: tns1:Monitoring/OperatingTime/LastClockSynchronization\n\t\"\"\"\n\ttry:\n\t\treturn Event(\n\t\t\tf\"{uid}_{msg.Topic._value_1}\",\n\t\t\t\"Last Clock Synchronization\",\n\t\t\t\"sensor\",\n\t\t\t\"timestamp\",\n\t\t\tNone,\n\t\t\tdt_util.as_local(\n\t\t\t\tdt_util.parse_datetime(msg.Message._value_1.Data.SimpleItem[0].Value)\n\t\t\t),\n\t\t\tentity_enabled=False,\n\t\t)\n\texcept (AttributeError, KeyError, ValueError):\n\t\treturn None\n\n", "description": "Handle parsing event message.\n\n\tTopic: tns1:Monitoring/OperatingTime/LastClockSynchronization\n\t", "category": "simple", "imports": ["from collections.abc import Callable, Coroutine", "from typing import Any", "from homeassistant.util import dt as dt_util", "from homeassistant.util.decorator import Registry", "from .models import Event"]}, {"term": "def", "name": "ncdefasync_parse_jobstate", "data": "async def async_parse_jobstate(uid: str, msg) -> Event:\n\t\"\"\"Handle parsing event message.\n\n\tTopic: tns1:RecordingConfig/JobState*\n\t\"\"\"\n\n\ttry:\n\t\tsource = msg.Message._value_1.Source.SimpleItem[0].Value\n\t\treturn Event(\n\t\t\tf\"{uid}_{msg.Topic._value_1}_{source}\",\n\t\t\tf\"{source} JobState\",\n\t\t\t\"binary_sensor\",\n\t\t\tNone,\n\t\t\tNone,\n\t\t\tmsg.Message._value_1.Data.SimpleItem[0].Value == \"Active\",\n\t\t)\n\texcept (AttributeError, KeyError):\n\t\treturn None\n", "description": "Handle parsing event message.\n\n\tTopic: tns1:RecordingConfig/JobState*\n\t", "category": "simple", "imports": ["from collections.abc import Callable, Coroutine", "from typing import Any", "from homeassistant.util import dt as dt_util", "from homeassistant.util.decorator import Registry", "from .models import Event"]}], [], [], [], [], [{"term": "class", "name": "DocumentStore", "data": "class DocumentStore(object):\n\t\"\"\"\n\tLocal XML document content repository.\n\n\tEach XML document is identified by its location, i.e. URL without any\n\tprotocol identifier. Contained XML documents can be looked up using any URL\n\treferencing that same location.\n\n\t\"\"\"\n\n\tdef __init__(self, *args, **kwargs):\n\t\tself.__store = {\n\t\t\t'schemas.xmlsoap.org/soap/encoding/': soap5_encoding_schema}\n\t\tself.update = self.__store.update\n\t\tself.update(*args, **kwargs)\n\n\tdef __len__(self):\n\t\treturn len(self.__store)\n\n\tdef open(self, url):\n\t\t\"\"\"\n\t\tOpen a document at the specified URL.\n\n\t\tThe document URL's needs not contain a protocol identifier, and if it\n\t\tdoes, that protocol identifier is ignored when looking up the store\n\t\tcontent.\n\n\t\tMissing documents referenced using the internal 'suds' protocol are\n\t\treported by raising an exception. For other protocols, None is returned\n\t\tinstead.\n\n\t\t@param url: A document URL.\n\t\t@type url: str\n\t\t@return: Document content or None if not found.\n\t\t@rtype: bytes\n\n\t\t\"\"\"\n\t\tprotocol, location = self.__split(url)\n\t\tcontent = self.__find(location)\n\t\tif protocol == 'suds' and content is None:\n\t\t\traise Exception, 'location \"%s\" not in document store' % location\n\t\treturn content\n\n\tdef __find(self, location):\n\t\t\"\"\"\n\t\tFind the specified location in the store.\n\n\t\t@param location: The I{location} part of a URL.\n\t\t@type location: str\n\t\t@return: Document content or None if not found.\n\t\t@rtype: bytes\n\n\t\t\"\"\"\n\t\treturn self.__store.get(location)\n\n\tdef __split(self, url):\n\t\t\"\"\"\n\t\tSplit the given URL into its I{protocol} & I{location} components.\n\n\t\t@param url: A URL.\n\t\t@param url: str\n\t\t@return: (I{protocol}, I{location})\n\t\t@rtype: (str, str)\n\n\t\t\"\"\"\n\t\tparts = url.split('://', 1)\n\t\tif len(parts) == 2:\n\t\t\treturn parts\n\t\treturn None, url\n\n", "description": "\n\tLocal XML document content repository.\n\n\tEach XML document is identified by its location, i.e. URL without any\n\tprotocol identifier. Contained XML documents can be looked up using any URL\n\treferencing that same location.\n\n\t", "category": "simple", "imports": ["import suds"]}], [{"term": "def", "name": "trim", "data": "def trim(value, num):\n\treturn value[:num]\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "noop", "data": "def noop(value, param=None):\n\t\"\"\"A noop filter that always return its first argument and does nothing with\n\tits second (optional) one.\n\tUseful for testing out whitespace in filter arguments (see #19882).\"\"\"\n\treturn value\n\n", "description": "A noop filter that always return its first argument and does nothing with\n\tits second (optional) one.\n\tUseful for testing out whitespace in filter arguments (see #19882).", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "context_stack_length", "data": "def context_stack_length(context):\n\treturn len(context.dicts)\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "no_params", "data": "def no_params():\n\t\"\"\"Expected no_params __doc__\"\"\"\n\treturn \"no_params - Expected result\"\n\n", "description": "Expected no_params __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "one_param", "data": "def one_param(arg):\n\t\"\"\"Expected one_param __doc__\"\"\"\n\treturn \"one_param - Expected result: %s\" % arg\n\n", "description": "Expected one_param __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "explicit_no_context", "data": "def explicit_no_context(arg):\n\t\"\"\"Expected explicit_no_context __doc__\"\"\"\n\treturn \"explicit_no_context - Expected result: %s\" % arg\n\n", "description": "Expected explicit_no_context __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "no_params_with_context", "data": "def no_params_with_context(context):\n\t\"\"\"Expected no_params_with_context __doc__\"\"\"\n\treturn \"no_params_with_context - Expected result (context value: %s)\" % context['value']\n\n", "description": "Expected no_params_with_context __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "params_and_context", "data": "def params_and_context(context, arg):\n\t\"\"\"Expected params_and_context __doc__\"\"\"\n\treturn \"params_and_context - Expected result (context value: %s): %s\" % (context['value'], arg)\n\n", "description": "Expected params_and_context __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "simple_two_params", "data": "def simple_two_params(one, two):\n\t\"\"\"Expected simple_two_params __doc__\"\"\"\n\treturn \"simple_two_params - Expected result: %s, %s\" % (one, two)\n\n", "description": "Expected simple_two_params __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "simple_keyword_only_param", "data": "def simple_keyword_only_param(*, kwarg):\n\treturn \"simple_keyword_only_param - Expected result: %s\" % kwarg\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "simple_keyword_only_default", "data": "def simple_keyword_only_default(*, kwarg=42):\n\treturn \"simple_keyword_only_default - Expected result: %s\" % kwarg\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "simple_one_default", "data": "def simple_one_default(one, two='hi'):\n\t\"\"\"Expected simple_one_default __doc__\"\"\"\n\treturn \"simple_one_default - Expected result: %s, %s\" % (one, two)\n\n", "description": "Expected simple_one_default __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "simple_unlimited_args", "data": "def simple_unlimited_args(one, two='hi', *args):\n\t\"\"\"Expected simple_unlimited_args __doc__\"\"\"\n\treturn \"simple_unlimited_args - Expected result: %s\" % (\n\t\t', '.join(str(arg) for arg in [one, two] + list(args))\n\t)\n\n", "description": "Expected simple_unlimited_args __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "simple_only_unlimited_args", "data": "def simple_only_unlimited_args(*args):\n\t\"\"\"Expected simple_only_unlimited_args __doc__\"\"\"\n\treturn \"simple_only_unlimited_args - Expected result: %s\" % ', '.join(str(arg) for arg in args)\n\n", "description": "Expected simple_only_unlimited_args __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "simple_unlimited_args_kwargs", "data": "def simple_unlimited_args_kwargs(one, two='hi', *args, **kwargs):\n\t\"\"\"Expected simple_unlimited_args_kwargs __doc__\"\"\"\n\t# Sort the dictionary by key to guarantee the order for testing.\n\tsorted_kwarg = sorted(kwargs.items(), key=operator.itemgetter(0))\n\treturn \"simple_unlimited_args_kwargs - Expected result: %s / %s\" % (\n\t\t', '.join(str(arg) for arg in [one, two] + list(args)),\n\t\t', '.join('%s=%s' % (k, v) for (k, v) in sorted_kwarg)\n\t)\n\n", "description": "Expected simple_unlimited_args_kwargs __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "simple_tag_without_context_parameter", "data": "def simple_tag_without_context_parameter(arg):\n\t\"\"\"Expected simple_tag_without_context_parameter __doc__\"\"\"\n\treturn \"Expected result\"\n\n", "description": "Expected simple_tag_without_context_parameter __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "escape_naive", "data": "def escape_naive(context):\n\t\"\"\"A tag that doesn't even think about escaping issues\"\"\"\n\treturn \"Hello {0}!\".format(context['name'])\n\n", "description": "A tag that doesn't even think about escaping issues", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "escape_explicit", "data": "def escape_explicit(context):\n\t\"\"\"A tag that uses escape explicitly\"\"\"\n\treturn escape(\"Hello {0}!\".format(context['name']))\n\n", "description": "A tag that uses escape explicitly", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "escape_format_html", "data": "def escape_format_html(context):\n\t\"\"\"A tag that uses format_html\"\"\"\n\treturn format_html(\"Hello {0}!\", context['name'])\n\n", "description": "A tag that uses format_html", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "current_app", "data": "def current_app(context):\n\treturn \"%s\" % context.current_app\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "use_l10n", "data": "def use_l10n(context):\n\treturn \"%s\" % context.use_l10n\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "minustwo_overridden_name", "data": "def minustwo_overridden_name(value):\n\treturn value - 2\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "counter", "data": "def counter(parser, token):\n\treturn CounterNode()\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html"]}, {"term": "class", "name": "CounterNode", "data": "class CounterNode(template.Node):\n\tdef __init__(self):\n\t\tself.count = 0\n\n\tdef render(self, context):\n\t\tcount = self.count\n\t\tself.count = count + 1\n\t\treturn count\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html"]}], [{"term": "def", "name": "alldata", "data": "def alldata():\n\tfile_dir = \"data/\u7535\u5546\u9500\u91cf\u9884\u6d4b\u6311\u6218\u8d5b\u516c\u5f00\u6570\u636e/\u6570\u636e\u96c6/\"\n\tall_file_name = os.listdir(file_dir)\n\tdata = None\n\tfor _, file in enumerate(all_file_name):\n\t\tif _ == 0:\n\t\t\tdata = pd.read_csv(os.path.join(file_dir, file))\n\t\telse:\n\t\t\tdata_ = pd.read_csv(os.path.join(file_dir, file))\n\t\t\tdata = pd.concat([data, data_], ignore_index=True)\n\tdata.to_csv(\"output/all_data_week.csv\", encoding=\"utf_8_sig\", index=False)\n\treturn data\n\n", "description": null, "category": "simple", "imports": ["import copy", "import json", "import math", "import numpy as np", "import pandas as pd", "import os", "from tslearn.clustering import TimeSeriesKMeans", "from tqdm import tqdm", "import datetime"]}, {"term": "def", "name": "trans_data", "data": "def trans_data(data_, scaler=None):\n\n\t# \u65f6\u95f4\u57fa\u7840\u7279\u5f81\n\tdata_[\"\u65f6\u95f4\"] = pd.to_datetime(data_[\"\u65f6\u95f4\"])\n\tdata_[\"month\"] = data_[\"\u65f6\u95f4\"].dt.month\n\tdata_[\"week\"] = data_[\"\u65f6\u95f4\"].dt.isocalendar().week\n\tdata_[\"quarter\"] = data_[\"\u65f6\u95f4\"].dt.quarter\n\tfor column in [\"\u76f4\u64ad\u9500\u91cf\", \"\u89c6\u9891\u9500\u91cf\", \"\u76f4\u64ad\u4e2a\u6570\", \"\u89c6\u9891\u4e2a\u6570\", \"\u6d4f\u89c8\u91cf\", \"\u89c6\u9891\u8fbe\u4eba\", \"\u76f4\u64ad\u8fbe\u4eba\", \"\u603b\u9500\u91cf\"]:\n\t\tdata_[column+\"_week\"] = data_.groupby([\"\u5546\u54c1id\", \"week\"])[column].transform(\"mean\")\n\tdata_.drop_duplicates([\"\u5546\u54c1id\", \"week\"], inplace=True)\n\n\t# \u83b7\u53d6\u6bcf\u4e2a\u5546\u54c1\u7b2c\u4e00\u6b21\u51fa\u73b0\u9500\u91cf\u7684\u65f6\u95f4\n\tsimple = data_[data_[\"\u603b\u9500\u91cf\"] > 0]\n\tsimple[\"qty_size\"] = simple.groupby([\"\u5546\u54c1id\"])[\"\u603b\u9500\u91cf\"].transform(\"size\")\n\tsimple[\"first_day\"] = simple.groupby([\"\u5546\u54c1id\"])[\"week\"].transform(\"first\")\n\tdata_ = data_.merge(simple.loc[:, [\"\u5546\u54c1id\", \"first_day\", \"qty_size\"]].drop_duplicates(), on=[\"\u5546\u54c1id\"], how=\"left\")\n\tdata_.loc[data_[data_[\"first_day\"].isna()].index, [\"first_day\"]] = 361\n\tdata_[\"qty_shichang\"] = data_[\"week\"].astype(\"int\") - data_[\"first_day\"] + 1\n\tdata_[\"qty_shichang\"] = list(map(lambda x: x if x > 0 else 0, data_[\"qty_shichang\"]))\n\tsimple = data_[data_[\"\u603b\u9500\u91cf\"] > 1]\n\tif scaler == 0:\n\t\t# \u5206\u4f4d\u6570\u6807\u51c6\u5316\n\t\tsimple[\"Q3\"] = simple.groupby([\"\u5546\u54c1id\"])[\"\u603b\u9500\u91cf\"].transform(lambda x: np.percentile(x, 75))\n\t\tsimple[\"Q1\"] = simple.groupby([\"\u5546\u54c1id\"])[\"\u603b\u9500\u91cf\"].transform(lambda x: np.percentile(x, 25))\n\t\tdata_ = data_.merge(simple.loc[:, [\"\u5546\u54c1id\", \"Q3\", \"Q1\"]].drop_duplicates(), how=\"left\", on=[\"\u5546\u54c1id\"])\n\t\tdata_[\"scaler_qty\"] = (data_[\"\u603b\u9500\u91cf\"] - data_[\"Q1\"]) / (data_[\"Q3\"] - data_[\"Q1\"])\n\telif scaler == 1:\n\t\t# \u53bb\u5747\u503c\u6807\u51c6\u5316\n\t\tsimple[\"mean\"] = simple.groupby([\"\u5546\u54c1id\"])[\"\u603b\u9500\u91cf\"].transform(\"mean\")\n\t\tdata_ = data_.merge(simple.loc[:, [\"\u5546\u54c1id\", \"mean\"]].drop_duplicates(), how=\"left\", on=[\"\u5546\u54c1id\"])\n\t\tdata_[\"scaler_qty\"] = data_[\"\u603b\u9500\u91cf\"] / data_[\"mean\"]\n\telif scaler == 2:\n\t\t# log\u5e73\u6ed1\n\t\tdata_['scaler_qty'] = list(map(lambda x: math.log(x + 1, 2), data_['\u603b\u9500\u91cf']))\n\telif scaler == 3:\n\t\t# simple[\"Q3\"] = simple.groupby([\"\u5546\u54c1id\"])[\"\u603b\u9500\u91cf\"].transform(lambda x: np.percentile(x, 75))\n\t\t# simple[\"Q1\"] = simple.groupby([\"\u5546\u54c1id\"])[\"\u603b\u9500\u91cf\"].transform(lambda x: np.percentile(x, 25))\n\t\t# data_ = data_.merge(simple.loc[:, [\"\u5546\u54c1id\", \"Q3\", \"Q1\"]].drop_duplicates(), how=\"left\", on=[\"\u5546\u54c1id\"])\n\t\t# data_[\"scaler_qty\"] = (data_[\"\u603b\u9500\u91cf\"] - data_[\"Q1\"]) / (data_[\"Q3\"] - data_[\"Q1\"])\n\t\tsimple[\"mean\"] = simple.groupby([\"\u5546\u54c1id\"])[\"\u603b\u9500\u91cf\"].transform(\"mean\")\n\t\tsimple[\"std\"] = simple.groupby([\"\u5546\u54c1id\"])[\"\u603b\u9500\u91cf\"].transform(\"std\")\n\t\tdata_ = data_.merge(simple.loc[:, [\"\u5546\u54c1id\", \"mean\", \"std\"]].drop_duplicates(), how=\"left\", on=[\"\u5546\u54c1id\"])\n\t\tdata_[\"scaler_qty\"] = data_[\"\u603b\u9500\u91cf\"] / data_[\"mean\"]\n\t\tdata_.loc[data_[data_[\"\u603b\u9500\u91cf\"] == 0].index, [\"scaler_qty\"]] = 0\n\telif scaler is None:\n\t\tdata_['scaler_qty'] = data_['\u603b\u9500\u91cf']\n\n\tdel data_[\"first_day\"]\n\tdel data_[\"\u65f6\u95f4\"]\n\tdata_.fillna(0, inplace=True)\n\tdata_.to_csv(\"output/trans_data_week.csv\", encoding=\"utf_8_sig\", index=False)\n\treturn data_\n\n", "description": null, "category": "simple", "imports": ["import copy", "import json", "import math", "import numpy as np", "import pandas as pd", "import os", "from tslearn.clustering import TimeSeriesKMeans", "from tqdm import tqdm", "import datetime"]}, {"term": "def", "name": "corr_", "data": "def corr_(data):\n\tids = data[\"\u5546\u54c1id\"].unique()\n\tdf = []\n\tfor id in ids:\n\t\tdf_ = data[data[\"\u5546\u54c1id\"] == id]\n\t\tdf.append(df_[\"\u603b\u9500\u91cf\"].values.tolist())\n\tdf = pd.DataFrame(df)\n\tdf = df.T\n\tdf.columns = ids\n\tcorr_dict = {}\n\tfor id in tqdm(ids):\n\t\tcorr_df = df.corrwith(df[id])\n\t\tcorr_list = corr_df[abs(corr_df) > 0.6].index.tolist()\n\t\tcorr_dict[id] = corr_list\n\ttf = open(\"output/corr_dict.json\", \"w\")\n\tjson.dump(corr_dict, tf)\n\ttf.close()\n\n", "description": null, "category": "simple", "imports": ["import copy", "import json", "import math", "import numpy as np", "import pandas as pd", "import os", "from tslearn.clustering import TimeSeriesKMeans", "from tqdm import tqdm", "import datetime"]}], [], [], [], [], [], [], [], [], [], [], [{"term": "def", "name": "GenerateTopasScripts", "data": "def GenerateTopasScripts(BaseDirectory, iteration, **variable_dict):\n\t\"\"\"\n\tThis file simply returns a list object, where each list entry corresponds to\n\ta line in the topas script.\n\tWhen it is called from an Optimiser object,it will receive a dictionary that contains the current values of \n\tthe variables you set up in optimisation_params when you initialised the optimiser.\n\t\"\"\"\n\t\n\tSimpleCollimator = []\n\tSimpleCollimator.append('# Set threading self:')\n\tSimpleCollimator.append('------------------------------------------------------------')\n\tSimpleCollimator.append('i:Ts/NumberOfThreads = 0  ')\n\tSimpleCollimator.append('i:Ts/ShowHistoryCountAtInterval = 1000000')\n\tSimpleCollimator.append('b:Ts/ShowHistoryCountOnSingleLine = \"True\"')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('# Add World:')\n\tSimpleCollimator.append('------------------------------------------------------------')\n\tSimpleCollimator.append('s:Ge/World/Type = \"TsBox\"')\n\tSimpleCollimator.append('s:Ge/World/Material = \"Vacuum\"')\n\tSimpleCollimator.append('d:Ge/World/HLX = 250 mm ')\n\tSimpleCollimator.append('d:Ge/World/HLY = 250 mm')\n\tSimpleCollimator.append('d:Ge/World/HLZ = 1200.0 mm')\n\tSimpleCollimator.append('d:Ge/World/RotX = 0. deg')\n\tSimpleCollimator.append('d:Ge/World/RotY = 0. deg')\n\tSimpleCollimator.append('d:Ge/World/RotZ = 0. deg')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('d:Ge/SID = 1000 mm')\n\tSimpleCollimator.append('d:Ge/SecondaryCollimatorOffset = 20 mm')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('Target')\n\tSimpleCollimator.append('------------------------------------------------------------')\n\tSimpleCollimator.append('s:Ge/Target/Type \t\t\t= \"TsCylinder\"')\n\tSimpleCollimator.append('s:Ge/Target/Parent \t\t\t= \"World\"')\n\tSimpleCollimator.append('s:Ge/Target/Material \t\t\t= \"G4_W\"')\n\tSimpleCollimator.append('d:Ge/Target/RMax   \t\t\t= 50 mm')\n\tSimpleCollimator.append('d:Ge/Target/HL  \t\t\t= 2 mm')\n\tSimpleCollimator.append('d:Ge/Target/TransZ \t\t\t= Ge/SID + Ge/Target/HL mm')\n\tSimpleCollimator.append('sc:Ge/Target/DrawingStyle \t\t= \"Solid\"')\n\tSimpleCollimator.append('sc:Ge/Target/Color \t\t\t= \"magenta\"')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('# primary collimator (abuts target)')\n\tSimpleCollimator.append('------------------------------------------------------------')\n\tSimpleCollimator.append('s:Ge/PrimaryCollimator/Parent\t = \"World\" ')\n\tSimpleCollimator.append('s:Ge/PrimaryCollimator/Material   = \"G4_W\"')\n\tSimpleCollimator.append('s:Ge/PrimaryCollimator/Type\t   = \"G4Cons\"')\n\tSimpleCollimator.append('d:Ge/PrimaryCollimator/RMin1\t  = 5 mm')\n\tSimpleCollimator.append('d:Ge/PrimaryCollimator/RMax1\t  = 50 mm ')\n\tSimpleCollimator.append('d:Ge/PrimaryCollimator/RMin2\t  = 3 mm')\n\tSimpleCollimator.append('d:Ge/PrimaryCollimator/RMax2\t  = 50 mm')\n\tSimpleCollimator.append('d:Ge/PrimaryCollimator/HL\t\t = 48 mm')\n\tSimpleCollimator.append('d:Ge/PrimaryCollimator/Pos\t\t= 1.7 cm')\n\tSimpleCollimator.append('d:Ge/PrimaryCollimator/TransZ\t = Ge/SID - Ge/PrimaryCollimator/HL  mm')\n\tSimpleCollimator.append('sc:Ge/PrimaryCollimator/DrawingStyle \t\t= \"Solid\"')\n\tSimpleCollimator.append('s:Ge/PrimaryCollimator/Color\t  = \"Blue\"')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('# Secondary collimator')\n\tSimpleCollimator.append('------------------------------------------------------------')\n\tSimpleCollimator.append('s:Ge/SecondaryCollimator/Parent\t = \"World\" ')\n\tSimpleCollimator.append('s:Ge/SecondaryCollimator/Material   = \"G4_Pb\"')\n\tSimpleCollimator.append('s:Ge/SecondaryCollimator/Type\t   = \"G4Cons\"')\n\tSimpleCollimator.append('d:Ge/SecondaryCollimator/RMin1\t  = 2.5 mm')\n\tSimpleCollimator.append('d:Ge/SecondaryCollimator/RMax1\t  = 50 mm ')\n\tSimpleCollimator.append('d:Ge/SecondaryCollimator/RMin2\t  = 1.82 mm')\n\tSimpleCollimator.append('d:Ge/SecondaryCollimator/RMax2\t  = 50 mm')\n\tSimpleCollimator.append('d:Ge/SecondaryCollimator/HL\t\t = 27 mm')\n\tSimpleCollimator.append('d:Ge/SecondaryCollimator/Pos\t\t= 1.7 cm')\n\tSimpleCollimator.append('d:Ge/SecondaryCollimator/temp_TransZ1 = Ge/PrimaryCollimator/TransZ - Ge/PrimaryCollimator/HL  mm')\n\tSimpleCollimator.append('d:Ge/SecondaryCollimator/temp_TransZ2 = Ge/SecondaryCollimator/temp_TransZ1 - Ge/SecondaryCollimator/HL mm')\n\tSimpleCollimator.append('d:Ge/SecondaryCollimator/TransZ\t = Ge/SecondaryCollimator/temp_TransZ2 - Ge/SecondaryCollimatorOffset mm')\n\tSimpleCollimator.append('sc:Ge/SecondaryCollimator/DrawingStyle \t\t= \"Solid\"')\n\tSimpleCollimator.append('s:Ge/SecondaryCollimator/Color\t  = \"green\"')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('# # Beam parameters (paramterised source):')\n\tSimpleCollimator.append('------------------------------------------------------------')\n\tSimpleCollimator.append('s:So/Beam/Type\t\t\t\t\t = \"Beam\"')\n\tSimpleCollimator.append('sc:So/Beam/Component\t\t\t\t= \"ElectronSource\"')\n\tSimpleCollimator.append('sc:So/Beam/BeamParticle\t\t\t = \"e-\"')\n\tSimpleCollimator.append('dc:So/Beam/BeamEnergy\t\t\t   = 10.0 MeV')\n\tSimpleCollimator.append('uc:So/Beam/BeamEnergySpread\t\t = 0')\n\tSimpleCollimator.append('sc:So/Beam/BeamPositionDistribution = \"Gaussian\" ')\n\tSimpleCollimator.append('sc:So/Beam/BeamAngularDistribution  = \"Gaussian\" ')\n\tSimpleCollimator.append('sc:So/Beam/BeamPositionCutoffShape = \"Ellipse\"')\n\tSimpleCollimator.append('dc:So/Beam/BeamPositionCutoffX = 2 mm')\n\tSimpleCollimator.append('dc:So/Beam/BeamPositionCutoffY = 2 mm')\n\tSimpleCollimator.append('dc:So/Beam/BeamPositionSpreadX = 0.3 mm')\n\tSimpleCollimator.append('dc:So/Beam/BeamPositionSpreadY = 0.3 mm')\n\tSimpleCollimator.append('dc:So/Beam/BeamAngularCutoffX = 5 deg')\n\tSimpleCollimator.append('dc:So/Beam/BeamAngularCutoffY = 5 deg')\n\tSimpleCollimator.append('dc:So/Beam/BeamAngularSpreadX = 0.07 deg')\n\tSimpleCollimator.append('dc:So/Beam/BeamAngularSpreadY = 0.07 deg')\n\tSimpleCollimator.append('ic:So/Beam/NumberOfHistoriesInRun = 500000 ')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('# # Electron source position')\n\tSimpleCollimator.append('# ------------------------------------------------------------')\n\tSimpleCollimator.append('s:Ge/ElectronSource/Parent = \"World\"')\n\tSimpleCollimator.append('s:Ge/ElectronSource/Type=\"TsSPhere\"')\n\tSimpleCollimator.append('d:Ge/ElectronSource/Rmax = 5 mm')\n\tSimpleCollimator.append('d:Ge/ElectronSource/TransZ = 1100 mm')\n\tSimpleCollimator.append('d:Ge/ElectronSource/RotX = 180. deg')\n\tSimpleCollimator.append('s:Ge/ElectronSource/Material = Ge/World/Material')\n\tSimpleCollimator.append('s:Ge/ElectronSource/Color = \"yellow\"')\n\tSimpleCollimator.append('sc:Ge/ElectronSource/DrawingStyle = \"Solid\"')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('# Variance reduction in target')\n\tSimpleCollimator.append('# ------------------------------------------------------------')\n\tSimpleCollimator.append('b:Vr/UseVarianceReduction = \"True\"')\n\tSimpleCollimator.append('s:Ge/Target/AssignToRegionNamed = \"VarianceReduction\"')\n\tSimpleCollimator.append('s:Vr/ParticleSplit/Type = \"SecondaryBiasing\"')\n\tSimpleCollimator.append('sv:Vr/ParticleSplit/ForRegion/VarianceReduction/ProcessesNamed = 1 \"eBrem\"')\n\tSimpleCollimator.append('uv:Vr/ParticleSplit/ForRegion/VarianceReduction/SplitNumber = 1 1000 ')\n\tSimpleCollimator.append('dv:Vr/ParticleSplit/ForRegion/VarianceReduction/MaximumEnergies = 1 10.0 MeV')\n\tSimpleCollimator.append('s:Vr/ParticleSplit/ReferenceComponent = \"Target\"')\n\tSimpleCollimator.append('dv:Vr/ParticleSplit/ForRegion/VarianceReduction/DirectionalSplitLimits = 1 -1 * Ge/Target/TransZ mm')\n\tSimpleCollimator.append('dv:Vr/ParticleSplit/ForRegion/VarianceReduction/DirectionalSplitRadius = 1 50 mm')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('# # Add phase space scorer below collimator:')\n\tSimpleCollimator.append('# ------------------------------------------------------------')\n\tSimpleCollimator.append('s:Ge/PhaseSpaceScorer/Type\t = \"TsBox\"')\n\tSimpleCollimator.append('s:Ge/PhaseSpaceScorer/Parent   = \"World\"')\n\tSimpleCollimator.append('s:Ge/PhaseSpaceScorer/Material = \"Vacuum\"')\n\tSimpleCollimator.append('d:Ge/PhaseSpaceScorer/HLX\t  = Ge/SecondaryCollimator/RMax2 mm')\n\tSimpleCollimator.append('d:Ge/PhaseSpaceScorer/HLY\t  = Ge/SecondaryCollimator/RMax2 mm')\n\tSimpleCollimator.append('d:Ge/PhaseSpaceScorer/HLZ\t  = 1 mm')\n\tSimpleCollimator.append('d:Ge/PhaseSpaceScorer/TransX   = 0. cm')\n\tSimpleCollimator.append('d:Ge/PhaseSpaceScorer/TransY   = 0. cm')\n\tSimpleCollimator.append('d:Ge/PhaseSpaceScorer/temp_TranZ1   = Ge/SecondaryCollimator/TransZ mm')\n\tSimpleCollimator.append('d:Ge/PhaseSpaceScorer/temp_TranZ2   = Ge/PhaseSpaceScorer/temp_TranZ1 - Ge/SecondaryCollimator/HL   mm')\n\tSimpleCollimator.append('d:Ge/PhaseSpaceScorer/TransZ   = Ge/PhaseSpaceScorer/temp_TranZ2 - 10  mm')\n\tSimpleCollimator.append('d:Ge/PhaseSpaceScorer/RotX\t = 0. deg')\n\tSimpleCollimator.append('d:Ge/PhaseSpaceScorer/RotY\t = 0. deg')\n\tSimpleCollimator.append('d:Ge/PhaseSpaceScorer/RotZ\t = 0. deg')\n\tSimpleCollimator.append('s:Ge/PhaseSpaceScorer/Color\t= \"skyblue\"')\n\tSimpleCollimator.append('s:Ge/PhaseSpaceScorer/DrawingStyle = \"wireframe\"')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('s:Sc/PhaseSpaceFromColl/Quantity\t\t\t\t\t= \"PhaseSpace\"')\n\tSimpleCollimator.append('b:Sc/PhaseSpaceFromColl/OutputToConsole\t\t\t = \"False\"')\n\tSimpleCollimator.append('s:Sc/PhaseSpaceFromColl/Surface\t\t\t\t\t = \"PhaseSpaceScorer/ZMinusSurface\"')\n\tSimpleCollimator.append('s:Sc/PhaseSpaceFromColl/OutputType\t\t\t\t  = \"Binary\" ')\n\tSimpleCollimator.append('s:Sc/PhaseSpaceFromColl/OutputFile\t\t\t\t   =  \"../Results/coll_PhaseSpace_itt_' + str(iteration) + '\"')\n\tSimpleCollimator.append('i:Sc/PhaseSpaceFromColl/OutputBufferSize\t\t\t= 1000')\n\tSimpleCollimator.append('#s:Sc/PhaseSpaceFromColl/OnlyIncludeParticlesGoing  = \"In\"')\n\tSimpleCollimator.append('b:Sc/PhaseSpaceFromColl/IncludeTOPASTime\t\t\t= \"False\"')\n\tSimpleCollimator.append('b:Sc/PhaseSpaceFromColl/IncludeTimeOfFlight\t\t = \"False\"')\n\tSimpleCollimator.append('b:Sc/PhaseSpaceFromColl/IncludeRunID\t\t\t\t= \"False\"')\n\tSimpleCollimator.append('b:Sc/PhaseSpaceFromColl/IncludeEventID\t\t\t  = \"False\"')\n\tSimpleCollimator.append('b:Sc/PhaseSpaceFromColl/IncludeTrackID\t\t\t  = \"False\"')\n\tSimpleCollimator.append('b:Sc/PhaseSpaceFromColl/IncludeParentID\t\t\t = \"False\"')\n\tSimpleCollimator.append('b:Sc/PhaseSpaceFromColl/IncludeCreatorProcess\t   = \"False\"')\n\tSimpleCollimator.append('b:Sc/PhaseSpaceFromColl/IncludeVertexInfo\t\t   = \"False\"')\n\tSimpleCollimator.append('b:Sc/PhaseSpaceFromColl/IncludeSeed\t\t\t\t = \"False\"')\n\tSimpleCollimator.append('s:Sc/PhaseSpaceFromColl/IfOutputFileAlreadyExists   = \"Overwrite\"')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('# Graphics View and trajectory filters:')\n\tSimpleCollimator.append('------------------------------------------------------------')\n\tSimpleCollimator.append('b:Gr/Enable = \"False\"  ')\n\tSimpleCollimator.append('s:Gr/ViewA/Type\t\t\t  = \"OpenGL\"')\n\tSimpleCollimator.append('d:Gr/ViewA/Theta\t\t\t= 90 deg')\n\tSimpleCollimator.append('d:Gr/ViewA/Phi\t\t\t  = 0 deg')\n\tSimpleCollimator.append('u:Gr/ViewA/TransX\t\t   = 0')\n\tSimpleCollimator.append('u:Gr/ViewA/TransY\t\t   = 0.')\n\tSimpleCollimator.append('s:Gr/ViewA/Projection\t   = \"Orthogonal\"')\n\tSimpleCollimator.append('d:Gr/ViewA/PerspectiveAngle = 60 deg')\n\tSimpleCollimator.append('u:Gr/ViewA/Zoom\t\t\t = 1')\n\tSimpleCollimator.append('b:Gr/ViewA/IncludeStepPoints = \"False\"')\n\tSimpleCollimator.append('b:Gr/ViewA/HiddenLineRemovalForTrajectories = \"True\"')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('# Physics')\n\tSimpleCollimator.append('------------------------------------------------------------')\n\tSimpleCollimator.append('sv:Ph/Default/Modules = 1 \"g4em-standard_opt0\"')\n\tSimpleCollimator.append('b:Ph/ListProcesses = \"False\"')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('------------------------------------------------------------')\n\tSimpleCollimator.append('# QT')\n\tSimpleCollimator.append('# --')\n\tSimpleCollimator.append('Ts/UseQt = Gr/Enable')\n\tSimpleCollimator.append('Ts/PauseBeforeQuit = Gr/Enable')\n\tSimpleCollimator.append('Ts/IncludeDefaultGeant4QtWidgets = \"F\"')\n\t\n\tWaterTank = []\n\tWaterTank.append('# Set threading self:')\n\tWaterTank.append('------------------------------------------------------------')\n\tWaterTank.append('i:Ts/NumberOfThreads = 0  ')\n\tWaterTank.append('i:Ts/ShowHistoryCountAtInterval = 100000')\n\tWaterTank.append('')\n\tWaterTank.append('')\n\tWaterTank.append('# Add World:')\n\tWaterTank.append('------------------------------------------------------------')\n\tWaterTank.append('s:Ge/World/Type = \"TsBox\"')\n\tWaterTank.append('s:Ge/World/Material = \"Vacuum\"')\n\tWaterTank.append('d:Ge/World/HLX = 250 mm ')\n\tWaterTank.append('d:Ge/World/HLY = 250 mm')\n\tWaterTank.append('d:Ge/World/HLZ = 1200.0 mm')\n\tWaterTank.append('d:Ge/World/RotX = 0. deg')\n\tWaterTank.append('d:Ge/World/RotY = 0. deg')\n\tWaterTank.append('d:Ge/World/RotZ = 0. deg')\n\tWaterTank.append('')\n\tWaterTank.append('')\n\tWaterTank.append('# Phase Space source:')\n\tWaterTank.append('------------------------------------------------------------')\n\tWaterTank.append('s:So/Example/Type\t\t\t\t\t\t\t= \"PhaseSpace\"')\n\tWaterTank.append('s:So/Example/PhaseSpaceFileName\t\t\t   =  \"../Results/coll_PhaseSpace_itt_' + str(iteration) + '\"')\n\tWaterTank.append('s:So/Example/Component\t\t\t\t\t   = \"World\"')\n\tWaterTank.append('i:So/Example/PhaseSpaceMultipleUse\t\t  = 200')\n\tWaterTank.append('b:So/Example/PhaseSpaceIncludeEmptyHistories = \"False\"')\n\tWaterTank.append('# i:So/Example/NumberOfHistoriesInRun = 10 # set PhaseSpaceMultipleUse to 0 to enable this option')\n\tWaterTank.append('')\n\tWaterTank.append('# Add the phantom')\n\tWaterTank.append('------------------------------------------------------------')\n\tWaterTank.append('# Phantom')\n\tWaterTank.append('s:Ge/Phantom/Type = \"TsBox\"')\n\tWaterTank.append('s:Ge/Phantom/Parent = \"World\"')\n\tWaterTank.append('sc:Ge/Phantom/Material = \"G4_WATER\"')\n\tWaterTank.append('# We draw the phantom to be field size plus one beamlet')\n\tWaterTank.append('dc:Ge/Phantom/HLX = 75 mm')\n\tWaterTank.append('dc:Ge/Phantom/HLY = 75 mm')\n\tWaterTank.append('dc:Ge/Phantom/HLZ =  75 mm')\n\tWaterTank.append('dc:Ge/Phantom/TransX = 0. cm')\n\tWaterTank.append('dc:Ge/Phantom/TransY = 0. cm')\n\tWaterTank.append('dc:Ge/Phantom/TransZ = 0. cm')\n\tWaterTank.append('dc:Ge/Phantom/RotX = 0. deg')\n\tWaterTank.append('dc:Ge/Phantom/RotY = 0. deg')\n\tWaterTank.append('dc:Ge/Phantom/RotZ = 0. deg')\n\tWaterTank.append('ic:Ge/Phantom/XBins = 50')\n\tWaterTank.append('ic:Ge/Phantom/YBins = 50')\n\tWaterTank.append('ic:Ge/Phantom/ZBins = 60')\n\tWaterTank.append('sc:Ge/Phantom/Color\t= \"green\"')\n\tWaterTank.append('sc:Ge/Phantom/DrawingStyle = \"Solid\"')\n\tWaterTank.append('')\n\tWaterTank.append('')\n\tWaterTank.append('# Add Volume scorer to phantom:')\n\tWaterTank.append('------------------------------------------------------------')\n\tWaterTank.append('s:Sc/PhantomScorer/Component = \"Phantom\"')\n\tWaterTank.append('s:Sc/PhantomScorer/Material = \"Water\"')\n\tWaterTank.append('s:Sc/PhantomScorer/Quantity\t\t\t\t  = \"DoseToMedium\"')\n\tWaterTank.append('b:Sc/PhantomScorer/OutputToConsole\t\t   = \"FALSE\"')\n\tWaterTank.append('s:Sc/PhantomScorer/IfOutputFileAlreadyExists = \"Overwrite\"')\n\tWaterTank.append('s:Sc/PhantomScorer/OutputType = \"Binary\" ')\n\tWaterTank.append('s:Sc/PhantomScorer/OutputFile\t\t\t\t   =  \"../Results/WaterTank_itt_' + str(iteration) + '\"')\n\tWaterTank.append('')\n\tWaterTank.append('')\n\tWaterTank.append('# Graphics View and trajectory filters:')\n\tWaterTank.append('------------------------------------------------------------')\n\tWaterTank.append('b:Gr/Enable = \"False\"  ')\n\tWaterTank.append('s:Gr/ViewA/Type\t\t\t  = \"OpenGL\"')\n\tWaterTank.append('dc:Gr/ViewA/Theta\t\t\t= 90 deg')\n\tWaterTank.append('dc:Gr/ViewA/Phi\t\t\t  = 0 deg')\n\tWaterTank.append('uc:Gr/ViewA/TransX\t\t   = -0.5')\n\tWaterTank.append('uc:Gr/ViewA/TransY\t\t   = 0.')\n\tWaterTank.append('sc:Gr/ViewA/Projection\t   = \"Orthogonal\"')\n\tWaterTank.append('dc:Gr/ViewA/PerspectiveAngle = 30 deg')\n\tWaterTank.append('uc:Gr/ViewA/Zoom\t\t\t = 10')\n\tWaterTank.append('bc:Gr/ViewA/IncludeStepPoints = \"False\"')\n\tWaterTank.append('bc:Gr/ViewA/HiddenLineRemovalForTrajectories = \"True\"')\n\tWaterTank.append('# sv:Gr/OnlyIncludeParticlesFromVolume = 1 \"ElectronSource\" # one or more volume')\n\tWaterTank.append('# sv:Gr/OnlyIncludeParticlesFromComponentOrSubComponentsOf = 1 \"ElectronSource\"')\n\tWaterTank.append('# sv:Gr/OnlyIncludeParticlesFromComponent = 2 \"Target\" \"Sphinx\"  # one or more component')\n\tWaterTank.append('# sv:Gr/OnlyIncludeParticlesFromVolume = 1 \"Film1/Film1_Z_Division\"')\n\tWaterTank.append('# sv:Gr/OnlyIncludeParticlesFromComponent = 1 \"Film2\"')\n\tWaterTank.append('sv:Gr/OnlyIncludeParticlesFromProcess = 1 \"primary\"')\n\tWaterTank.append('')\n\tWaterTank.append('')\n\tWaterTank.append('# Physics')\n\tWaterTank.append('------------------------------------------------------------')\n\tWaterTank.append('sv:Ph/Default/Modules = 1 \"g4em-standard_opt0\"')\n\tWaterTank.append('b:Ph/ListProcesses = \"True\"')\n\tWaterTank.append('')\n\tWaterTank.append('')\n\tWaterTank.append('------------------------------------------------------------')\n\tWaterTank.append('# QT')\n\tWaterTank.append('# --')\n\tWaterTank.append('Ts/UseQt = Gr/Enable')\n\tWaterTank.append('Ts/PauseBeforeQuit = Gr/Enable')\n\tWaterTank.append('Ts/IncludeDefaultGeant4QtWidgets = \"T\"')\n\n\treturn [SimpleCollimator, WaterTank], ['SimpleCollimator', 'WaterTank']\n", "description": "\n\tThis file simply returns a list object, where each list entry corresponds to\n\ta line in the topas script.\n\tWhen it is called from an Optimiser object,it will receive a dictionary that contains the current values of \n\tthe variables you set up in optimisation_params when you initialised the optimiser.\n\t", "category": "simple", "imports": ["from pathlib import Path"]}], [{"term": "def", "name": "GenerateTopasScripts", "data": "def GenerateTopasScripts(BaseDirectory, iteration, **variable_dict):\n\t\"\"\"\n\tThis file simply returns a list object, where each list entry corresponds to\n\ta line in the topas script.\n\tWhen it is called from an Optimiser object,it will receive a dictionary that contains the current values of \n\tthe variables you set up in optimisation_params when you initialised the optimiser.\n\t\"\"\"\n\t\n\tSimpleCollimator = []\n\tSimpleCollimator.append('# Set threading self:')\n\tSimpleCollimator.append('------------------------------------------------------------')\n\tSimpleCollimator.append('i:Ts/NumberOfThreads = 0  ')\n\tSimpleCollimator.append('i:Ts/ShowHistoryCountAtInterval = 1000000')\n\tSimpleCollimator.append('b:Ts/ShowHistoryCountOnSingleLine = \"True\"')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('# Add World:')\n\tSimpleCollimator.append('------------------------------------------------------------')\n\tSimpleCollimator.append('s:Ge/World/Type = \"TsBox\"')\n\tSimpleCollimator.append('s:Ge/World/Material = \"Vacuum\"')\n\tSimpleCollimator.append('d:Ge/World/HLX = 250 mm ')\n\tSimpleCollimator.append('d:Ge/World/HLY = 250 mm')\n\tSimpleCollimator.append('d:Ge/World/HLZ = 1200.0 mm')\n\tSimpleCollimator.append('d:Ge/World/RotX = 0. deg')\n\tSimpleCollimator.append('d:Ge/World/RotY = 0. deg')\n\tSimpleCollimator.append('d:Ge/World/RotZ = 0. deg')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('d:Ge/SID = 1000 mm')\n\tSimpleCollimator.append('d:Ge/SecondaryCollimatorOffset = 20 mm')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('Target')\n\tSimpleCollimator.append('------------------------------------------------------------')\n\tSimpleCollimator.append('s:Ge/Target/Type \t\t\t= \"TsCylinder\"')\n\tSimpleCollimator.append('s:Ge/Target/Parent \t\t\t= \"World\"')\n\tSimpleCollimator.append('s:Ge/Target/Material \t\t\t= \"G4_W\"')\n\tSimpleCollimator.append('d:Ge/Target/RMax   \t\t\t= 50 mm')\n\tSimpleCollimator.append('d:Ge/Target/HL  \t\t\t= 2 mm')\n\tSimpleCollimator.append('d:Ge/Target/TransZ \t\t\t= Ge/SID + Ge/Target/HL mm')\n\tSimpleCollimator.append('sc:Ge/Target/DrawingStyle \t\t= \"Solid\"')\n\tSimpleCollimator.append('sc:Ge/Target/Color \t\t\t= \"magenta\"')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('# primary collimator (abuts target)')\n\tSimpleCollimator.append('------------------------------------------------------------')\n\tSimpleCollimator.append('s:Ge/PrimaryCollimator/Parent\t = \"World\" ')\n\tSimpleCollimator.append('s:Ge/PrimaryCollimator/Material   = \"G4_W\"')\n\tSimpleCollimator.append('s:Ge/PrimaryCollimator/Type\t   = \"G4Cons\"')\n\tSimpleCollimator.append('d:Ge/PrimaryCollimator/RMin1\t  = 5 mm')\n\tSimpleCollimator.append('d:Ge/PrimaryCollimator/RMax1\t  = 50 mm ')\n\tSimpleCollimator.append('d:Ge/PrimaryCollimator/RMin2\t  = 3 mm')\n\tSimpleCollimator.append('d:Ge/PrimaryCollimator/RMax2\t  = 50 mm')\n\tSimpleCollimator.append('d:Ge/PrimaryCollimator/HL\t\t = 48 mm')\n\tSimpleCollimator.append('d:Ge/PrimaryCollimator/Pos\t\t= 1.7 cm')\n\tSimpleCollimator.append('d:Ge/PrimaryCollimator/TransZ\t = Ge/SID - Ge/PrimaryCollimator/HL  mm')\n\tSimpleCollimator.append('sc:Ge/PrimaryCollimator/DrawingStyle \t\t= \"Solid\"')\n\tSimpleCollimator.append('s:Ge/PrimaryCollimator/Color\t  = \"Blue\"')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('# Secondary collimator')\n\tSimpleCollimator.append('------------------------------------------------------------')\n\tSimpleCollimator.append('s:Ge/SecondaryCollimator/Parent\t = \"World\" ')\n\tSimpleCollimator.append('s:Ge/SecondaryCollimator/Material   = \"G4_Pb\"')\n\tSimpleCollimator.append('s:Ge/SecondaryCollimator/Type\t   = \"G4Cons\"')\n\tSimpleCollimator.append('d:Ge/SecondaryCollimator/RMin1\t  = ' + str(variable_dict['UpStreamApertureRadius']) + ' mm')\n\tSimpleCollimator.append('d:Ge/SecondaryCollimator/RMax1\t  = 50 mm ')\n\tSimpleCollimator.append('d:Ge/SecondaryCollimator/RMin2\t  = ' + str(variable_dict['DownStreamApertureRadius']) + ' mm')\n\tSimpleCollimator.append('d:Ge/SecondaryCollimator/RMax2\t  = 50 mm')\n\tSimpleCollimator.append('d:Ge/SecondaryCollimator/HL\t  = ' + str(variable_dict['CollimatorThickness']) + ' mm')\n\tSimpleCollimator.append('d:Ge/SecondaryCollimator/Pos\t\t= 1.7 cm')\n\tSimpleCollimator.append('d:Ge/SecondaryCollimator/temp_TransZ1 = Ge/PrimaryCollimator/TransZ - Ge/PrimaryCollimator/HL  mm')\n\tSimpleCollimator.append('d:Ge/SecondaryCollimator/temp_TransZ2 = Ge/SecondaryCollimator/temp_TransZ1 - Ge/SecondaryCollimator/HL mm')\n\tSimpleCollimator.append('d:Ge/SecondaryCollimator/TransZ\t = Ge/SecondaryCollimator/temp_TransZ2 - Ge/SecondaryCollimatorOffset mm')\n\tSimpleCollimator.append('sc:Ge/SecondaryCollimator/DrawingStyle \t\t= \"Solid\"')\n\tSimpleCollimator.append('s:Ge/SecondaryCollimator/Color\t  = \"green\"')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('# # Beam parameters (paramterised source):')\n\tSimpleCollimator.append('------------------------------------------------------------')\n\tSimpleCollimator.append('s:So/Beam/Type\t\t\t\t\t = \"Beam\"')\n\tSimpleCollimator.append('sc:So/Beam/Component\t\t\t\t= \"ElectronSource\"')\n\tSimpleCollimator.append('sc:So/Beam/BeamParticle\t\t\t = \"e-\"')\n\tSimpleCollimator.append('dc:So/Beam/BeamEnergy\t\t\t   = 10.0 MeV')\n\tSimpleCollimator.append('uc:So/Beam/BeamEnergySpread\t\t = 0')\n\tSimpleCollimator.append('sc:So/Beam/BeamPositionDistribution = \"Gaussian\" ')\n\tSimpleCollimator.append('sc:So/Beam/BeamAngularDistribution  = \"Gaussian\" ')\n\tSimpleCollimator.append('sc:So/Beam/BeamPositionCutoffShape = \"Ellipse\"')\n\tSimpleCollimator.append('dc:So/Beam/BeamPositionCutoffX = 2 mm')\n\tSimpleCollimator.append('dc:So/Beam/BeamPositionCutoffY = 2 mm')\n\tSimpleCollimator.append('dc:So/Beam/BeamPositionSpreadX = 0.3 mm')\n\tSimpleCollimator.append('dc:So/Beam/BeamPositionSpreadY = 0.3 mm')\n\tSimpleCollimator.append('dc:So/Beam/BeamAngularCutoffX = 5 deg')\n\tSimpleCollimator.append('dc:So/Beam/BeamAngularCutoffY = 5 deg')\n\tSimpleCollimator.append('dc:So/Beam/BeamAngularSpreadX = 0.07 deg')\n\tSimpleCollimator.append('dc:So/Beam/BeamAngularSpreadY = 0.07 deg')\n\tSimpleCollimator.append('ic:So/Beam/NumberOfHistoriesInRun = 50')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('# # Electron source position')\n\tSimpleCollimator.append('# ------------------------------------------------------------')\n\tSimpleCollimator.append('s:Ge/ElectronSource/Parent = \"World\"')\n\tSimpleCollimator.append('s:Ge/ElectronSource/Type=\"TsSPhere\"')\n\tSimpleCollimator.append('d:Ge/ElectronSource/Rmax = 5 mm')\n\tSimpleCollimator.append('d:Ge/ElectronSource/TransZ = 1100 mm')\n\tSimpleCollimator.append('d:Ge/ElectronSource/RotX = 180. deg')\n\tSimpleCollimator.append('s:Ge/ElectronSource/Material = Ge/World/Material')\n\tSimpleCollimator.append('s:Ge/ElectronSource/Color = \"yellow\"')\n\tSimpleCollimator.append('sc:Ge/ElectronSource/DrawingStyle = \"Solid\"')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('# Variance reduction in target')\n\tSimpleCollimator.append('# ------------------------------------------------------------')\n\tSimpleCollimator.append('b:Vr/UseVarianceReduction = \"True\"')\n\tSimpleCollimator.append('s:Ge/Target/AssignToRegionNamed = \"VarianceReduction\"')\n\tSimpleCollimator.append('s:Vr/ParticleSplit/Type = \"SecondaryBiasing\"')\n\tSimpleCollimator.append('sv:Vr/ParticleSplit/ForRegion/VarianceReduction/ProcessesNamed = 1 \"eBrem\"')\n\tSimpleCollimator.append('uv:Vr/ParticleSplit/ForRegion/VarianceReduction/SplitNumber = 1 1000 ')\n\tSimpleCollimator.append('dv:Vr/ParticleSplit/ForRegion/VarianceReduction/MaximumEnergies = 1 10.0 MeV')\n\tSimpleCollimator.append('s:Vr/ParticleSplit/ReferenceComponent = \"Target\"')\n\tSimpleCollimator.append('dv:Vr/ParticleSplit/ForRegion/VarianceReduction/DirectionalSplitLimits = 1 -1 * Ge/Target/TransZ mm')\n\tSimpleCollimator.append('dv:Vr/ParticleSplit/ForRegion/VarianceReduction/DirectionalSplitRadius = 1 50 mm')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('# # Add phase space scorer below collimator:')\n\tSimpleCollimator.append('# ------------------------------------------------------------')\n\tSimpleCollimator.append('s:Ge/PhaseSpaceScorer/Type\t = \"TsBox\"')\n\tSimpleCollimator.append('s:Ge/PhaseSpaceScorer/Parent   = \"World\"')\n\tSimpleCollimator.append('s:Ge/PhaseSpaceScorer/Material = \"Vacuum\"')\n\tSimpleCollimator.append('d:Ge/PhaseSpaceScorer/HLX\t  = Ge/SecondaryCollimator/RMax2 mm')\n\tSimpleCollimator.append('d:Ge/PhaseSpaceScorer/HLY\t  = Ge/SecondaryCollimator/RMax2 mm')\n\tSimpleCollimator.append('d:Ge/PhaseSpaceScorer/HLZ\t  = 1 mm')\n\tSimpleCollimator.append('d:Ge/PhaseSpaceScorer/TransX   = 0. cm')\n\tSimpleCollimator.append('d:Ge/PhaseSpaceScorer/TransY   = 0. cm')\n\tSimpleCollimator.append('d:Ge/PhaseSpaceScorer/temp_TranZ1   = Ge/SecondaryCollimator/TransZ mm')\n\tSimpleCollimator.append('d:Ge/PhaseSpaceScorer/temp_TranZ2   = Ge/PhaseSpaceScorer/temp_TranZ1 - Ge/SecondaryCollimator/HL   mm')\n\tSimpleCollimator.append('d:Ge/PhaseSpaceScorer/TransZ   = Ge/PhaseSpaceScorer/temp_TranZ2 - 10  mm')\n\tSimpleCollimator.append('d:Ge/PhaseSpaceScorer/RotX\t = 0. deg')\n\tSimpleCollimator.append('d:Ge/PhaseSpaceScorer/RotY\t = 0. deg')\n\tSimpleCollimator.append('d:Ge/PhaseSpaceScorer/RotZ\t = 0. deg')\n\tSimpleCollimator.append('s:Ge/PhaseSpaceScorer/Color\t= \"skyblue\"')\n\tSimpleCollimator.append('s:Ge/PhaseSpaceScorer/DrawingStyle = \"wireframe\"')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('s:Sc/PhaseSpaceFromColl/Quantity\t\t\t\t\t= \"PhaseSpace\"')\n\tSimpleCollimator.append('b:Sc/PhaseSpaceFromColl/OutputToConsole\t\t\t = \"False\"')\n\tSimpleCollimator.append('s:Sc/PhaseSpaceFromColl/Surface\t\t\t\t\t = \"PhaseSpaceScorer/ZMinusSurface\"')\n\tSimpleCollimator.append('s:Sc/PhaseSpaceFromColl/OutputType\t\t\t\t  = \"Binary\" ')\n\tSimpleCollimator.append('s:Sc/PhaseSpaceFromColl/OutputFile\t\t\t\t   =  \"../Results/coll_PhaseSpace_itt_' + str(iteration) + '\"')\n\tSimpleCollimator.append('i:Sc/PhaseSpaceFromColl/OutputBufferSize\t\t\t= 1000')\n\tSimpleCollimator.append('#s:Sc/PhaseSpaceFromColl/OnlyIncludeParticlesGoing  = \"In\"')\n\tSimpleCollimator.append('b:Sc/PhaseSpaceFromColl/IncludeTOPASTime\t\t\t= \"False\"')\n\tSimpleCollimator.append('b:Sc/PhaseSpaceFromColl/IncludeTimeOfFlight\t\t = \"False\"')\n\tSimpleCollimator.append('b:Sc/PhaseSpaceFromColl/IncludeRunID\t\t\t\t= \"False\"')\n\tSimpleCollimator.append('b:Sc/PhaseSpaceFromColl/IncludeEventID\t\t\t  = \"False\"')\n\tSimpleCollimator.append('b:Sc/PhaseSpaceFromColl/IncludeTrackID\t\t\t  = \"False\"')\n\tSimpleCollimator.append('b:Sc/PhaseSpaceFromColl/IncludeParentID\t\t\t = \"False\"')\n\tSimpleCollimator.append('b:Sc/PhaseSpaceFromColl/IncludeCreatorProcess\t   = \"False\"')\n\tSimpleCollimator.append('b:Sc/PhaseSpaceFromColl/IncludeVertexInfo\t\t   = \"False\"')\n\tSimpleCollimator.append('b:Sc/PhaseSpaceFromColl/IncludeSeed\t\t\t\t = \"False\"')\n\tSimpleCollimator.append('s:Sc/PhaseSpaceFromColl/IfOutputFileAlreadyExists   = \"Overwrite\"')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('# Graphics View and trajectory filters:')\n\tSimpleCollimator.append('------------------------------------------------------------')\n\tSimpleCollimator.append('b:Gr/Enable = \"False\"  ')\n\tSimpleCollimator.append('s:Gr/ViewA/Type\t\t\t  = \"OpenGL\"')\n\tSimpleCollimator.append('d:Gr/ViewA/Theta\t\t\t= 90 deg')\n\tSimpleCollimator.append('d:Gr/ViewA/Phi\t\t\t  = 0 deg')\n\tSimpleCollimator.append('u:Gr/ViewA/TransX\t\t   = 0')\n\tSimpleCollimator.append('u:Gr/ViewA/TransY\t\t   = 0.')\n\tSimpleCollimator.append('s:Gr/ViewA/Projection\t   = \"Orthogonal\"')\n\tSimpleCollimator.append('d:Gr/ViewA/PerspectiveAngle = 60 deg')\n\tSimpleCollimator.append('u:Gr/ViewA/Zoom\t\t\t = 1')\n\tSimpleCollimator.append('b:Gr/ViewA/IncludeStepPoints = \"False\"')\n\tSimpleCollimator.append('b:Gr/ViewA/HiddenLineRemovalForTrajectories = \"True\"')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('# Physics')\n\tSimpleCollimator.append('------------------------------------------------------------')\n\tSimpleCollimator.append('sv:Ph/Default/Modules = 1 \"g4em-standard_opt0\"')\n\tSimpleCollimator.append('b:Ph/ListProcesses = \"False\"')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('------------------------------------------------------------')\n\tSimpleCollimator.append('# QT')\n\tSimpleCollimator.append('# --')\n\tSimpleCollimator.append('Ts/UseQt = Gr/Enable')\n\tSimpleCollimator.append('Ts/PauseBeforeQuit = Gr/Enable')\n\tSimpleCollimator.append('Ts/IncludeDefaultGeant4QtWidgets = \"F\"')\n\t\n\tWaterTank = []\n\tWaterTank.append('# Set threading self:')\n\tWaterTank.append('------------------------------------------------------------')\n\tWaterTank.append('i:Ts/NumberOfThreads = 0  ')\n\tWaterTank.append('i:Ts/ShowHistoryCountAtInterval = 100000')\n\tWaterTank.append('')\n\tWaterTank.append('')\n\tWaterTank.append('# Add World:')\n\tWaterTank.append('------------------------------------------------------------')\n\tWaterTank.append('s:Ge/World/Type = \"TsBox\"')\n\tWaterTank.append('s:Ge/World/Material = \"Vacuum\"')\n\tWaterTank.append('d:Ge/World/HLX = 250 mm ')\n\tWaterTank.append('d:Ge/World/HLY = 250 mm')\n\tWaterTank.append('d:Ge/World/HLZ = 1200.0 mm')\n\tWaterTank.append('d:Ge/World/RotX = 0. deg')\n\tWaterTank.append('d:Ge/World/RotY = 0. deg')\n\tWaterTank.append('d:Ge/World/RotZ = 0. deg')\n\tWaterTank.append('')\n\tWaterTank.append('')\n\tWaterTank.append('# Phase Space source:')\n\tWaterTank.append('------------------------------------------------------------')\n\tWaterTank.append('s:So/Example/Type\t\t\t\t\t\t\t= \"PhaseSpace\"')\n\tWaterTank.append('s:So/Example/PhaseSpaceFileName\t\t\t   =  \"../Results/coll_PhaseSpace_itt_' + str(iteration) + '\"')\n\tWaterTank.append('s:So/Example/Component\t\t\t\t\t   = \"World\"')\n\tWaterTank.append('i:So/Example/PhaseSpaceMultipleUse\t\t  = 200')\n\tWaterTank.append('b:So/Example/PhaseSpaceIncludeEmptyHistories = \"False\"')\n\tWaterTank.append('# i:So/Example/NumberOfHistoriesInRun = 10 # set PhaseSpaceMultipleUse to 0 to enable this option')\n\tWaterTank.append('')\n\tWaterTank.append('# Add the phantom')\n\tWaterTank.append('------------------------------------------------------------')\n\tWaterTank.append('# Phantom')\n\tWaterTank.append('s:Ge/Phantom/Type = \"TsBox\"')\n\tWaterTank.append('s:Ge/Phantom/Parent = \"World\"')\n\tWaterTank.append('sc:Ge/Phantom/Material = \"G4_WATER\"')\n\tWaterTank.append('# We draw the phantom to be field size plus one beamlet')\n\tWaterTank.append('dc:Ge/Phantom/HLX = 75 mm')\n\tWaterTank.append('dc:Ge/Phantom/HLY = 75 mm')\n\tWaterTank.append('dc:Ge/Phantom/HLZ =  75 mm')\n\tWaterTank.append('dc:Ge/Phantom/TransX = 0. cm')\n\tWaterTank.append('dc:Ge/Phantom/TransY = 0. cm')\n\tWaterTank.append('dc:Ge/Phantom/TransZ = 0. cm')\n\tWaterTank.append('dc:Ge/Phantom/RotX = 0. deg')\n\tWaterTank.append('dc:Ge/Phantom/RotY = 0. deg')\n\tWaterTank.append('dc:Ge/Phantom/RotZ = 0. deg')\n\tWaterTank.append('ic:Ge/Phantom/XBins = 50')\n\tWaterTank.append('ic:Ge/Phantom/YBins = 50')\n\tWaterTank.append('ic:Ge/Phantom/ZBins = 60')\n\tWaterTank.append('sc:Ge/Phantom/Color\t= \"green\"')\n\tWaterTank.append('sc:Ge/Phantom/DrawingStyle = \"Solid\"')\n\tWaterTank.append('')\n\tWaterTank.append('')\n\tWaterTank.append('# Add Volume scorer to phantom:')\n\tWaterTank.append('------------------------------------------------------------')\n\tWaterTank.append('s:Sc/PhantomScorer/Component = \"Phantom\"')\n\tWaterTank.append('s:Sc/PhantomScorer/Material = \"Water\"')\n\tWaterTank.append('s:Sc/PhantomScorer/Quantity\t\t\t\t  = \"DoseToMedium\"')\n\tWaterTank.append('b:Sc/PhantomScorer/OutputToConsole\t\t   = \"FALSE\"')\n\tWaterTank.append('s:Sc/PhantomScorer/IfOutputFileAlreadyExists = \"Overwrite\"')\n\tWaterTank.append('s:Sc/PhantomScorer/OutputType = \"Binary\" ')\n\tWaterTank.append('s:Sc/PhantomScorer/OutputFile\t\t\t\t   =  \"../Results/WaterTank_itt_' + str(iteration) + '\"')\n\tWaterTank.append('')\n\tWaterTank.append('')\n\tWaterTank.append('# Graphics View and trajectory filters:')\n\tWaterTank.append('------------------------------------------------------------')\n\tWaterTank.append('b:Gr/Enable = \"False\"  ')\n\tWaterTank.append('s:Gr/ViewA/Type\t\t\t  = \"OpenGL\"')\n\tWaterTank.append('dc:Gr/ViewA/Theta\t\t\t= 90 deg')\n\tWaterTank.append('dc:Gr/ViewA/Phi\t\t\t  = 0 deg')\n\tWaterTank.append('uc:Gr/ViewA/TransX\t\t   = -0.5')\n\tWaterTank.append('uc:Gr/ViewA/TransY\t\t   = 0.')\n\tWaterTank.append('sc:Gr/ViewA/Projection\t   = \"Orthogonal\"')\n\tWaterTank.append('dc:Gr/ViewA/PerspectiveAngle = 30 deg')\n\tWaterTank.append('uc:Gr/ViewA/Zoom\t\t\t = 10')\n\tWaterTank.append('bc:Gr/ViewA/IncludeStepPoints = \"False\"')\n\tWaterTank.append('bc:Gr/ViewA/HiddenLineRemovalForTrajectories = \"True\"')\n\tWaterTank.append('# sv:Gr/OnlyIncludeParticlesFromVolume = 1 \"ElectronSource\" # one or more volume')\n\tWaterTank.append('# sv:Gr/OnlyIncludeParticlesFromComponentOrSubComponentsOf = 1 \"ElectronSource\"')\n\tWaterTank.append('# sv:Gr/OnlyIncludeParticlesFromComponent = 2 \"Target\" \"Sphinx\"  # one or more component')\n\tWaterTank.append('# sv:Gr/OnlyIncludeParticlesFromVolume = 1 \"Film1/Film1_Z_Division\"')\n\tWaterTank.append('# sv:Gr/OnlyIncludeParticlesFromComponent = 1 \"Film2\"')\n\tWaterTank.append('sv:Gr/OnlyIncludeParticlesFromProcess = 1 \"primary\"')\n\tWaterTank.append('')\n\tWaterTank.append('')\n\tWaterTank.append('# Physics')\n\tWaterTank.append('------------------------------------------------------------')\n\tWaterTank.append('sv:Ph/Default/Modules = 1 \"g4em-standard_opt0\"')\n\tWaterTank.append('b:Ph/ListProcesses = \"True\"')\n\tWaterTank.append('')\n\tWaterTank.append('')\n\tWaterTank.append('------------------------------------------------------------')\n\tWaterTank.append('# QT')\n\tWaterTank.append('# --')\n\tWaterTank.append('Ts/UseQt = Gr/Enable')\n\tWaterTank.append('Ts/PauseBeforeQuit = Gr/Enable')\n\tWaterTank.append('Ts/IncludeDefaultGeant4QtWidgets = \"T\"')\n\n\treturn [SimpleCollimator, WaterTank], ['SimpleCollimator', 'WaterTank']\n", "description": "\n\tThis file simply returns a list object, where each list entry corresponds to\n\ta line in the topas script.\n\tWhen it is called from an Optimiser object,it will receive a dictionary that contains the current values of \n\tthe variables you set up in optimisation_params when you initialised the optimiser.\n\t", "category": "simple", "imports": ["from pathlib import Path"]}], [{"term": "class", "name": "SimpleFile2", "data": "class SimpleFile2 (SimpleFile):\n\tdef exists(self):\n\t\treturn \"Mooo\"\n", "description": null, "category": "simple", "imports": ["import os", "import sys", "import unittest", "from pathlib import Path", "from shiboken_paths import init_paths", "from sample import SimpleFile"]}, {"term": "class", "name": "SimpleFile3", "data": "class SimpleFile3 (SimpleFile):\n\tpass\n", "description": null, "category": "simple", "imports": ["import os", "import sys", "import unittest", "from pathlib import Path", "from shiboken_paths import init_paths", "from sample import SimpleFile"]}, {"term": "class", "name": "SimpleFile4", "data": "class SimpleFile4 (SimpleFile):\n\texists = 5\n", "description": null, "category": "simple", "imports": ["import os", "import sys", "import unittest", "from pathlib import Path", "from shiboken_paths import init_paths", "from sample import SimpleFile"]}, {"term": "class", "name": "StaticNonStaticMethodsTest", "data": "class StaticNonStaticMethodsTest(unittest.TestCase):\n\t'''Test cases for overloads involving static and non-static versions of a method.'''\n\n\tdef setUp(self):\n\t\tfilename = f'simplefile{os.getpid()}.txt'\n\t\tself.existing_filename = Path(filename)\n\t\tself.delete_file = False\n\t\tif not self.existing_filename.exists():\n\t\t\twith self.existing_filename.open('w') as f:\n\t\t\t\tfor line in range(10):\n\t\t\t\t\tf.write('sbrubbles\\n')\n\t\t\tself.delete_file = True\n\n\t\tself.non_existing_filename = Path('inexistingfile.txt')\n\t\ti = 0\n\t\twhile self.non_existing_filename.exists():\n\t\t\ti += 1\n\t\t\tfilename = 'inexistingfile-{i}.txt'\n\t\t\tself.non_existing_filename = Path(filename)\n\n\tdef tearDown(self):\n\t\tif self.delete_file:\n\t\t\tos.remove(self.existing_filename)\n\n\tdef testCallingStaticMethodWithClass(self):\n\t\t'''Call static method using class.'''\n\t\tself.assertTrue(SimpleFile.exists(os.fspath(self.existing_filename)))\n\t\tself.assertFalse(SimpleFile.exists(os.fspath(self.non_existing_filename)))\n\n\tdef testCallingStaticMethodWithInstance(self):\n\t\t'''Call static method using instance of class.'''\n\t\tf = SimpleFile(os.fspath(self.non_existing_filename))\n\t\tself.assertTrue(f.exists(os.fspath(self.existing_filename)))\n\t\tself.assertFalse(f.exists(os.fspath(self.non_existing_filename)))\n\n\tdef testCallingInstanceMethod(self):\n\t\t'''Call instance method.'''\n\t\tf1 = SimpleFile(os.fspath(self.non_existing_filename))\n\t\tself.assertFalse(f1.exists())\n\t\tf2 = SimpleFile(os.fspath(self.existing_filename))\n\t\tself.assertTrue(f2.exists())\n\n\tdef testOverridingStaticNonStaticMethod(self):\n\t\tf = SimpleFile2(os.fspath(self.existing_filename))\n\t\tself.assertEqual(f.exists(), \"Mooo\")\n\n\t\tf = SimpleFile3(os.fspath(self.existing_filename))\n\t\tself.assertTrue(f.exists())\n\n\t\tf = SimpleFile4(os.fspath(self.existing_filename))\n\t\tself.assertEqual(f.exists, 5)\n\n\tdef testDuckPunchingStaticNonStaticMethod(self):\n\t\tf = SimpleFile(os.fspath(self.existing_filename))\n\t\tf.exists = lambda : \"Meee\"\n\t\tself.assertEqual(f.exists(), \"Meee\")\n", "description": null, "category": "simple", "imports": ["import os", "import sys", "import unittest", "from pathlib import Path", "from shiboken_paths import init_paths", "from sample import SimpleFile"]}], [{"term": "def", "name": "fswig_import_helper", "data": "\tdef swig_import_helper():\n\t\timport importlib\n\t\tpkg = __name__.rpartition('.')[0]\n\t\tmname = '.'.join((pkg, '_param_BaseSimpleCPU')).lstrip('.')\n\t\ttry:\n\t\t\treturn importlib.import_module(mname)\n\t\texcept ImportError:\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_BaseSimpleCPU')", "\t_param_BaseSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_BaseSimpleCPU", "\t_param_BaseSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_BaseSimpleCPU", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BranchPredictor", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_BaseCPU", "import m5.internal.param_X86TLB", "import m5.internal.param_X86PagetableWalker", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BaseTLB", "import m5.internal.X86LocalApic_vector", "import m5.internal.param_X86LocalApic", "import m5.internal.param_BasicPioDevice", "import m5.internal.param_PioDevice", "import m5.internal.X86ISA_vector", "import m5.internal.param_X86ISA", "import m5.internal.Counter_vector", "import m5.internal.param_InstTracer", "import m5.internal.Process_vector", "import m5.internal.param_Process"]}, {"term": "def", "name": "fswig_import_helper", "data": "\tdef swig_import_helper():\n\t\tfrom os.path import dirname\n\t\timport imp\n\t\tfp = None\n\t\ttry:\n\t\t\tfp, pathname, description = imp.find_module('_param_BaseSimpleCPU', [dirname(__file__)])\n\t\texcept ImportError:\n\t\t\timport _param_BaseSimpleCPU\n\t\t\treturn _param_BaseSimpleCPU\n\t\ttry:\n\t\t\t_mod = imp.load_module('_param_BaseSimpleCPU', fp, pathname, description)\n\t\tfinally:\n\t\t\tif fp is not None:\n\t\t\t\tfp.close()\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_BaseSimpleCPU')", "\t_param_BaseSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_BaseSimpleCPU", "\t_param_BaseSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_BaseSimpleCPU", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BranchPredictor", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_BaseCPU", "import m5.internal.param_X86TLB", "import m5.internal.param_X86PagetableWalker", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BaseTLB", "import m5.internal.X86LocalApic_vector", "import m5.internal.param_X86LocalApic", "import m5.internal.param_BasicPioDevice", "import m5.internal.param_PioDevice", "import m5.internal.X86ISA_vector", "import m5.internal.param_X86ISA", "import m5.internal.Counter_vector", "import m5.internal.param_InstTracer", "import m5.internal.Process_vector", "import m5.internal.param_Process"]}, {"term": "def", "name": "_swig_setattr_nondynamic", "data": "def _swig_setattr_nondynamic(self, class_type, name, value, static=1):\n\tif (name == \"thisown\"):\n\t\treturn self.this.own(value)\n\tif (name == \"this\"):\n\t\tif type(value).__name__ == 'SwigPyObject':\n\t\t\tself.__dict__[name] = value\n\t\t\treturn\n\tmethod = class_type.__swig_setmethods__.get(name, None)\n\tif method:\n\t\treturn method(self, value)\n\tif (not static):\n\t\tobject.__setattr__(self, name, value)\n\telse:\n\t\traise AttributeError(\"You cannot add attributes to %s\" % self)\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_BaseSimpleCPU')", "\t_param_BaseSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_BaseSimpleCPU", "\t_param_BaseSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_BaseSimpleCPU", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BranchPredictor", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_BaseCPU", "import m5.internal.param_X86TLB", "import m5.internal.param_X86PagetableWalker", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BaseTLB", "import m5.internal.X86LocalApic_vector", "import m5.internal.param_X86LocalApic", "import m5.internal.param_BasicPioDevice", "import m5.internal.param_PioDevice", "import m5.internal.X86ISA_vector", "import m5.internal.param_X86ISA", "import m5.internal.Counter_vector", "import m5.internal.param_InstTracer", "import m5.internal.Process_vector", "import m5.internal.param_Process"]}, {"term": "def", "name": "_swig_setattr", "data": "def _swig_setattr(self, class_type, name, value):\n\treturn _swig_setattr_nondynamic(self, class_type, name, value, 0)\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_BaseSimpleCPU')", "\t_param_BaseSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_BaseSimpleCPU", "\t_param_BaseSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_BaseSimpleCPU", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BranchPredictor", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_BaseCPU", "import m5.internal.param_X86TLB", "import m5.internal.param_X86PagetableWalker", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BaseTLB", "import m5.internal.X86LocalApic_vector", "import m5.internal.param_X86LocalApic", "import m5.internal.param_BasicPioDevice", "import m5.internal.param_PioDevice", "import m5.internal.X86ISA_vector", "import m5.internal.param_X86ISA", "import m5.internal.Counter_vector", "import m5.internal.param_InstTracer", "import m5.internal.Process_vector", "import m5.internal.param_Process"]}, {"term": "def", "name": "_swig_getattr", "data": "def _swig_getattr(self, class_type, name):\n\tif (name == \"thisown\"):\n\t\treturn self.this.own()\n\tmethod = class_type.__swig_getmethods__.get(name, None)\n\tif method:\n\t\treturn method(self)\n\traise AttributeError(\"'%s' object has no attribute '%s'\" % (class_type.__name__, name))\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_BaseSimpleCPU')", "\t_param_BaseSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_BaseSimpleCPU", "\t_param_BaseSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_BaseSimpleCPU", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BranchPredictor", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_BaseCPU", "import m5.internal.param_X86TLB", "import m5.internal.param_X86PagetableWalker", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BaseTLB", "import m5.internal.X86LocalApic_vector", "import m5.internal.param_X86LocalApic", "import m5.internal.param_BasicPioDevice", "import m5.internal.param_PioDevice", "import m5.internal.X86ISA_vector", "import m5.internal.param_X86ISA", "import m5.internal.Counter_vector", "import m5.internal.param_InstTracer", "import m5.internal.Process_vector", "import m5.internal.param_Process"]}, {"term": "def", "name": "_swig_repr", "data": "def _swig_repr(self):\n\ttry:\n\t\tstrthis = \"proxy of \" + self.this.__repr__()\n\texcept __builtin__.Exception:\n\t\tstrthis = \"\"\n\treturn \"<%s.%s; %s >\" % (self.__class__.__module__, self.__class__.__name__, strthis,)\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_BaseSimpleCPU')", "\t_param_BaseSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_BaseSimpleCPU", "\t_param_BaseSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_BaseSimpleCPU", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BranchPredictor", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_BaseCPU", "import m5.internal.param_X86TLB", "import m5.internal.param_X86PagetableWalker", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BaseTLB", "import m5.internal.X86LocalApic_vector", "import m5.internal.param_X86LocalApic", "import m5.internal.param_BasicPioDevice", "import m5.internal.param_PioDevice", "import m5.internal.X86ISA_vector", "import m5.internal.param_X86ISA", "import m5.internal.Counter_vector", "import m5.internal.param_InstTracer", "import m5.internal.Process_vector", "import m5.internal.param_Process"]}, {"term": "def", "name": "_swig_setattr_nondynamic_method", "data": "def _swig_setattr_nondynamic_method(set):\n\tdef set_attr(self, name, value):\n\t\tif (name == \"thisown\"):\n\t\t\treturn self.this.own(value)\n\t\tif hasattr(self, name) or (name == \"this\"):\n\t\t\tset(self, name, value)\n\t\telse:\n\t\t\traise AttributeError(\"You cannot add attributes to %s\" % self)\n\treturn set_attr\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_BaseSimpleCPU')", "\t_param_BaseSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_BaseSimpleCPU", "\t_param_BaseSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_BaseSimpleCPU", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BranchPredictor", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_BaseCPU", "import m5.internal.param_X86TLB", "import m5.internal.param_X86PagetableWalker", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BaseTLB", "import m5.internal.X86LocalApic_vector", "import m5.internal.param_X86LocalApic", "import m5.internal.param_BasicPioDevice", "import m5.internal.param_PioDevice", "import m5.internal.X86ISA_vector", "import m5.internal.param_X86ISA", "import m5.internal.Counter_vector", "import m5.internal.param_InstTracer", "import m5.internal.Process_vector", "import m5.internal.param_Process"]}, {"term": "class", "name": "BaseSimpleCPU", "data": "class BaseSimpleCPU(m5.internal.param_BaseCPU.BaseCPU):\n\tthisown = _swig_property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc='The membership flag')\n\n\tdef __init__(self, *args, **kwargs):\n\t\traise AttributeError(\"No constructor defined - class is abstract\")\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_BaseSimpleCPU')", "\t_param_BaseSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_BaseSimpleCPU", "\t_param_BaseSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_BaseSimpleCPU", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BranchPredictor", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_BaseCPU", "import m5.internal.param_X86TLB", "import m5.internal.param_X86PagetableWalker", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BaseTLB", "import m5.internal.X86LocalApic_vector", "import m5.internal.param_X86LocalApic", "import m5.internal.param_BasicPioDevice", "import m5.internal.param_PioDevice", "import m5.internal.X86ISA_vector", "import m5.internal.param_X86ISA", "import m5.internal.Counter_vector", "import m5.internal.param_InstTracer", "import m5.internal.Process_vector", "import m5.internal.param_Process"]}, {"term": "class", "name": "BaseSimpleCPUParams", "data": "class BaseSimpleCPUParams(m5.internal.param_BaseCPU.BaseCPUParams):\n\tthisown = _swig_property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc='The membership flag')\n\t__repr__ = _swig_repr\n\tbranchPred = _swig_property(_param_BaseSimpleCPU.BaseSimpleCPUParams_branchPred_get, _param_BaseSimpleCPU.BaseSimpleCPUParams_branchPred_set)\n\n\tdef __init__(self):\n\t\tthis = _param_BaseSimpleCPU.new_BaseSimpleCPUParams()\n\t\ttry:\n\t\t\tself.this.append(this)\n\t\texcept __builtin__.Exception:\n\t\t\tself.this = this\n\t__swig_destroy__ = _param_BaseSimpleCPU.delete_BaseSimpleCPUParams\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_BaseSimpleCPU')", "\t_param_BaseSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_BaseSimpleCPU", "\t_param_BaseSimpleCPU = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_BaseSimpleCPU", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BranchPredictor", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_BaseCPU", "import m5.internal.param_X86TLB", "import m5.internal.param_X86PagetableWalker", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BaseTLB", "import m5.internal.X86LocalApic_vector", "import m5.internal.param_X86LocalApic", "import m5.internal.param_BasicPioDevice", "import m5.internal.param_PioDevice", "import m5.internal.X86ISA_vector", "import m5.internal.param_X86ISA", "import m5.internal.Counter_vector", "import m5.internal.param_InstTracer", "import m5.internal.Process_vector", "import m5.internal.param_Process"]}], [{"term": "class", "name": "classTestLibraryInfo:", "data": "class TestLibraryInfo:\n\tdef test_simple(self):\n\t\twith temppath('foo.ini') as path:\n\t\t\twith open(path,  'w') as f:\n\t\t\t\tf.write(simple)\n\t\t\tpkg = os.path.splitext(path)[0]\n\t\t\tout = read_config(pkg)\n\n\t\tassert_(out.cflags() == simple_d['cflags'])\n\t\tassert_(out.libs() == simple_d['libflags'])\n\t\tassert_(out.name == simple_d['name'])\n\t\tassert_(out.version == simple_d['version'])\n\n\tdef test_simple_variable(self):\n\t\twith temppath('foo.ini') as path:\n\t\t\twith open(path,  'w') as f:\n\t\t\t\tf.write(simple_variable)\n\t\t\tpkg = os.path.splitext(path)[0]\n\t\t\tout = read_config(pkg)\n\n\t\tassert_(out.cflags() == simple_variable_d['cflags'])\n\t\tassert_(out.libs() == simple_variable_d['libflags'])\n\t\tassert_(out.name == simple_variable_d['name'])\n\t\tassert_(out.version == simple_variable_d['version'])\n\t\tout.vars['prefix'] = '/Users/david'\n\t\tassert_(out.cflags() == '-I/Users/david/include')\n", "description": null, "category": "simple", "imports": ["import os", "from numpy.distutils.npy_pkg_config import read_config, parse_flags", "from numpy.testing import temppath, assert_"]}, {"term": "class", "name": "classTestParseFlags:", "data": "class TestParseFlags:\n\tdef test_simple_cflags(self):\n\t\td = parse_flags(\"-I/usr/include\")\n\t\tassert_(d['include_dirs'] == ['/usr/include'])\n\n\t\td = parse_flags(\"-I/usr/include -DFOO\")\n\t\tassert_(d['include_dirs'] == ['/usr/include'])\n\t\tassert_(d['macros'] == ['FOO'])\n\n\t\td = parse_flags(\"-I /usr/include -DFOO\")\n\t\tassert_(d['include_dirs'] == ['/usr/include'])\n\t\tassert_(d['macros'] == ['FOO'])\n\n\tdef test_simple_lflags(self):\n\t\td = parse_flags(\"-L/usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tassert_(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tassert_(d['libraries'] == ['foo', 'bar'])\n\n\t\td = parse_flags(\"-L /usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tassert_(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tassert_(d['libraries'] == ['foo', 'bar'])\n", "description": null, "category": "simple", "imports": ["import os", "from numpy.distutils.npy_pkg_config import read_config, parse_flags", "from numpy.testing import temppath, assert_"]}], [{"term": "class", "name": "classTestLibraryInfo:", "data": "class TestLibraryInfo:\n\tdef test_simple(self):\n\t\twith temppath('foo.ini') as path:\n\t\t\twith open(path,  'w') as f:\n\t\t\t\tf.write(simple)\n\t\t\tpkg = os.path.splitext(path)[0]\n\t\t\tout = read_config(pkg)\n\n\t\tassert_(out.cflags() == simple_d['cflags'])\n\t\tassert_(out.libs() == simple_d['libflags'])\n\t\tassert_(out.name == simple_d['name'])\n\t\tassert_(out.version == simple_d['version'])\n\n\tdef test_simple_variable(self):\n\t\twith temppath('foo.ini') as path:\n\t\t\twith open(path,  'w') as f:\n\t\t\t\tf.write(simple_variable)\n\t\t\tpkg = os.path.splitext(path)[0]\n\t\t\tout = read_config(pkg)\n\n\t\tassert_(out.cflags() == simple_variable_d['cflags'])\n\t\tassert_(out.libs() == simple_variable_d['libflags'])\n\t\tassert_(out.name == simple_variable_d['name'])\n\t\tassert_(out.version == simple_variable_d['version'])\n\t\tout.vars['prefix'] = '/Users/david'\n\t\tassert_(out.cflags() == '-I/Users/david/include')\n", "description": null, "category": "simple", "imports": ["import os", "from numpy.distutils.npy_pkg_config import read_config, parse_flags", "from numpy.testing import temppath, assert_"]}, {"term": "class", "name": "classTestParseFlags:", "data": "class TestParseFlags:\n\tdef test_simple_cflags(self):\n\t\td = parse_flags(\"-I/usr/include\")\n\t\tassert_(d['include_dirs'] == ['/usr/include'])\n\n\t\td = parse_flags(\"-I/usr/include -DFOO\")\n\t\tassert_(d['include_dirs'] == ['/usr/include'])\n\t\tassert_(d['macros'] == ['FOO'])\n\n\t\td = parse_flags(\"-I /usr/include -DFOO\")\n\t\tassert_(d['include_dirs'] == ['/usr/include'])\n\t\tassert_(d['macros'] == ['FOO'])\n\n\tdef test_simple_lflags(self):\n\t\td = parse_flags(\"-L/usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tassert_(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tassert_(d['libraries'] == ['foo', 'bar'])\n\n\t\td = parse_flags(\"-L /usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tassert_(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tassert_(d['libraries'] == ['foo', 'bar'])\n", "description": null, "category": "simple", "imports": ["import os", "from numpy.distutils.npy_pkg_config import read_config, parse_flags", "from numpy.testing import temppath, assert_"]}], [{"term": "class", "name": "TestLibraryInfo", "data": "class TestLibraryInfo(object):\n\tdef test_simple(self):\n\t\twith temppath('foo.ini') as path:\n\t\t\twith open(path,  'w') as f:\n\t\t\t\tf.write(simple)\n\t\t\tpkg = os.path.splitext(path)[0]\n\t\t\tout = read_config(pkg)\n\n\t\tassert_(out.cflags() == simple_d['cflags'])\n\t\tassert_(out.libs() == simple_d['libflags'])\n\t\tassert_(out.name == simple_d['name'])\n\t\tassert_(out.version == simple_d['version'])\n\n\tdef test_simple_variable(self):\n\t\twith temppath('foo.ini') as path:\n\t\t\twith open(path,  'w') as f:\n\t\t\t\tf.write(simple_variable)\n\t\t\tpkg = os.path.splitext(path)[0]\n\t\t\tout = read_config(pkg)\n\n\t\tassert_(out.cflags() == simple_variable_d['cflags'])\n\t\tassert_(out.libs() == simple_variable_d['libflags'])\n\t\tassert_(out.name == simple_variable_d['name'])\n\t\tassert_(out.version == simple_variable_d['version'])\n\t\tout.vars['prefix'] = '/Users/david'\n\t\tassert_(out.cflags() == '-I/Users/david/include')\n", "description": null, "category": "simple", "imports": ["from __future__ import division, absolute_import, print_function", "import os", "from numpy.distutils.npy_pkg_config import read_config, parse_flags", "from numpy.testing import temppath, assert_"]}, {"term": "class", "name": "TestParseFlags", "data": "class TestParseFlags(object):\n\tdef test_simple_cflags(self):\n\t\td = parse_flags(\"-I/usr/include\")\n\t\tassert_(d['include_dirs'] == ['/usr/include'])\n\n\t\td = parse_flags(\"-I/usr/include -DFOO\")\n\t\tassert_(d['include_dirs'] == ['/usr/include'])\n\t\tassert_(d['macros'] == ['FOO'])\n\n\t\td = parse_flags(\"-I /usr/include -DFOO\")\n\t\tassert_(d['include_dirs'] == ['/usr/include'])\n\t\tassert_(d['macros'] == ['FOO'])\n\n\tdef test_simple_lflags(self):\n\t\td = parse_flags(\"-L/usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tassert_(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tassert_(d['libraries'] == ['foo', 'bar'])\n\n\t\td = parse_flags(\"-L /usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tassert_(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tassert_(d['libraries'] == ['foo', 'bar'])\n", "description": null, "category": "simple", "imports": ["from __future__ import division, absolute_import, print_function", "import os", "from numpy.distutils.npy_pkg_config import read_config, parse_flags", "from numpy.testing import temppath, assert_"]}], [{"term": "def", "name": "deploy_simple_storage", "data": "def deploy_simple_storage():\n\taccount = get_account()\n\tprint(\"this account\", account)\n\t# print(accou / nt)\n\t# from bronwie\n\t# account = accounts.load(\"localtest\")\n\t# print(account)\n\t# Todo : check this method\n\t# account = accounts.add(config[\"wallets\"][\"from_key\"])\n\t# print(account)d\n\t# Anytime we deploy to a chaing we need to metion the from account\n\t# print(\"simple storage\", SimpleStorage.deploy())\n\n\tsimple_storage = SimpleStorage.deploy({\"from\": account})\n\tprint(\"simple storage\", simple_storage)\n\ttransaction = simple_storage.store(15, {\"from\": account})\n\ttransaction.wait(1)\n\tupdated_storage_value = simple_storage.retrieve()\n\t# print(updated_storage_value)\n\n", "description": null, "category": "simple", "imports": ["from brownie import accounts, config, SimpleStorage, network", "import os"]}, {"term": "def", "name": "get_account", "data": "def get_account():\n\tif network.show_active() == \"development\":\n\t\treturn accounts[0]\n\telse:\n\t\treturn accounts.add(config[\"wallets\"][\"from_key\"])\n\n", "description": null, "category": "simple", "imports": ["from brownie import accounts, config, SimpleStorage, network", "import os"]}, {"term": "def", "name": "main", "data": "def main():\n\tprint(\" helloo\")\n\tdeploy_simple_storage()\n", "description": null, "category": "simple", "imports": ["from brownie import accounts, config, SimpleStorage, network", "import os"]}], [{"term": "def", "name": "all_patterns", "data": "def all_patterns(name):\n\tu\"\"\"\n\tAccepts a string and returns a pattern of possible patterns involving that name\n\tCalled by simple_mapping_to_pattern for each name in the mapping it receives.\n\t\"\"\"\n\n\t# i_ denotes an import-like node\n\t# u_ denotes a node that appears to be a usage of the name\n\tif u'.' in name:\n\t\tname, attr = name.split(u'.', 1)\n\t\tsimple_name = simple_name_match % (name)\n\t\tsimple_attr = subname_match % (attr)\n\t\tdotted_name = dotted_name_match % (simple_name, simple_attr)\n\t\ti_from = from_import_match % (dotted_name)\n\t\ti_from_submod = from_import_submod_match % (simple_name, simple_attr, simple_attr, simple_attr, simple_attr)\n\t\ti_name = name_import_match % (dotted_name, dotted_name)\n\t\tu_name = power_twoname_match % (simple_name, simple_attr)\n\t\tu_subname = power_subname_match % (simple_attr)\n\t\treturn u' | \\n'.join((i_name, i_from, i_from_submod, u_name, u_subname))\n\telse:\n\t\tsimple_name = simple_name_match % (name)\n\t\ti_name = name_import_match % (simple_name, simple_name)\n\t\ti_from = from_import_match % (simple_name)\n\t\tu_name = power_onename_match % (simple_name)\n\t\treturn u' | \\n'.join((i_name, i_from, u_name))\n\n", "description": "\n\tAccepts a string and returns a pattern of possible patterns involving that name\n\tCalled by simple_mapping_to_pattern for each name in the mapping it receives.\n\t", "category": "simple", "imports": ["Fixer for standard library imports renamed in Python 3", "from lib2to3 import fixer_base", "from lib2to3.fixer_util import Name, is_probably_builtin, Newline, does_tree_import", "from lib2to3.pygram import python_symbols as syms", "from lib2to3.pgen2 import token", "from lib2to3.pytree import Node, Leaf", "from libfuturize.fixer_util import touch_import_top", "# from ..fixer_util import NameImport", "# helps match 'queue', as in 'from queue import ...'", "# helps match 'client', to be used if client has been imported from http", "# helps match 'http.client', as in 'import urllib.request'", "# helps match 'client.HTTPConnection', if 'client' has been imported from http", "# helps match 'from http.client import HTTPConnection'", "from_import_match = u\"from_import=import_from< 'from' %s 'import' imported=any >\"", "# helps match 'from http import client'", "from_import_submod_match = u\"from_import_submod=import_from< 'from' %s 'import' (%s | import_as_name< %s 'as' renamed=any > | import_as_names< any* (%s | import_as_name< %s 'as' renamed=any >) any* > ) >\"", "# helps match 'import urllib.request'", "name_import_match = u\"name_import=import_name< 'import' %s > | name_import=import_name< 'import' dotted_as_name< %s 'as' renamed=any > >\"", "# helps match 'import http.client, winreg'", "multiple_name_import_match = u\"name_import=import_name< 'import' dotted_as_names< names=any* > >\"", "\t# i_ denotes an import-like node", "\t\ti_from = from_import_match % (dotted_name)", "\t\ti_from_submod = from_import_submod_match % (simple_name, simple_attr, simple_attr, simple_attr, simple_attr)", "\t\ti_name = name_import_match % (dotted_name, dotted_name)", "\t\ti_name = name_import_match % (simple_name, simple_name)", "\t\ti_from = from_import_match % (simple_name)", "\tPATTERN = u' | \\n'.join((PATTERN, multiple_name_import_match))", "\t\ttouch_import_top(u'future', u'standard_library', node)"]}, {"term": "class", "name": "FixImports", "data": "class FixImports(fixer_base.BaseFix):\n\n\tPATTERN = u' | \\n'.join([all_patterns(name) for name in MAPPING])\n\tPATTERN = u' | \\n'.join((PATTERN, multiple_name_import_match))\n\n\tdef transform(self, node, results):\n\t\ttouch_import_top(u'future', u'standard_library', node)\n\n", "description": null, "category": "simple", "imports": ["Fixer for standard library imports renamed in Python 3", "from lib2to3 import fixer_base", "from lib2to3.fixer_util import Name, is_probably_builtin, Newline, does_tree_import", "from lib2to3.pygram import python_symbols as syms", "from lib2to3.pgen2 import token", "from lib2to3.pytree import Node, Leaf", "from libfuturize.fixer_util import touch_import_top", "# from ..fixer_util import NameImport", "# helps match 'queue', as in 'from queue import ...'", "# helps match 'client', to be used if client has been imported from http", "# helps match 'http.client', as in 'import urllib.request'", "# helps match 'client.HTTPConnection', if 'client' has been imported from http", "# helps match 'from http.client import HTTPConnection'", "from_import_match = u\"from_import=import_from< 'from' %s 'import' imported=any >\"", "# helps match 'from http import client'", "from_import_submod_match = u\"from_import_submod=import_from< 'from' %s 'import' (%s | import_as_name< %s 'as' renamed=any > | import_as_names< any* (%s | import_as_name< %s 'as' renamed=any >) any* > ) >\"", "# helps match 'import urllib.request'", "name_import_match = u\"name_import=import_name< 'import' %s > | name_import=import_name< 'import' dotted_as_name< %s 'as' renamed=any > >\"", "# helps match 'import http.client, winreg'", "multiple_name_import_match = u\"name_import=import_name< 'import' dotted_as_names< names=any* > >\"", "\t# i_ denotes an import-like node", "\t\ti_from = from_import_match % (dotted_name)", "\t\ti_from_submod = from_import_submod_match % (simple_name, simple_attr, simple_attr, simple_attr, simple_attr)", "\t\ti_name = name_import_match % (dotted_name, dotted_name)", "\t\ti_name = name_import_match % (simple_name, simple_name)", "\t\ti_from = from_import_match % (simple_name)", "\tPATTERN = u' | \\n'.join((PATTERN, multiple_name_import_match))", "\t\ttouch_import_top(u'future', u'standard_library', node)"]}], [{"term": "class", "name": "TagTestCaseBase", "data": "class TagTestCaseBase(unittest.TestCase):\n\tdef setUp(self):\n\t\tself.t1 = tag.Tag(tag.tagClassUniversal, tag.tagFormatSimple, 3)\n\t\tself.t2 = tag.Tag(tag.tagClassUniversal, tag.tagFormatSimple, 3)\n", "description": null, "category": "simple", "imports": ["from pyasn1.type import tag", "from pyasn1.error import PyAsn1Error", "from sys import version_info", "\t\timport unittest2 as unittest", "\t\timport unittest", "\timport unittest"]}, {"term": "class", "name": "TagCmpTestCase", "data": "class TagCmpTestCase(TagTestCaseBase):\n\tdef testCmp(self):\n\t\tassert self.t1 == self.t2, 'tag comparation fails'\n\n\tdef testHash(self):\n\t\tassert hash(self.t1) == hash(self.t2), 'tag hash comparation fails'\n\n\tdef testSequence(self):\n\t\tassert self.t1[0] == self.t2[0] and \\\n\t\t\t   self.t1[1] == self.t2[1] and \\\n\t\t\t   self.t1[2] == self.t2[2], 'tag sequence protocol fails'\n", "description": null, "category": "simple", "imports": ["from pyasn1.type import tag", "from pyasn1.error import PyAsn1Error", "from sys import version_info", "\t\timport unittest2 as unittest", "\t\timport unittest", "\timport unittest"]}, {"term": "class", "name": "TagSetTestCaseBase", "data": "class TagSetTestCaseBase(unittest.TestCase):\n\tdef setUp(self):\n\t\tself.ts1 = tag.initTagSet(\n\t\t\ttag.Tag(tag.tagClassUniversal, tag.tagFormatSimple, 12)\n\t\t\t)\n\t\tself.ts2 = tag.initTagSet(\n\t\t\ttag.Tag(tag.tagClassUniversal, tag.tagFormatSimple, 12)\n\t\t\t)\n", "description": null, "category": "simple", "imports": ["from pyasn1.type import tag", "from pyasn1.error import PyAsn1Error", "from sys import version_info", "\t\timport unittest2 as unittest", "\t\timport unittest", "\timport unittest"]}, {"term": "class", "name": "TagSetCmpTestCase", "data": "class TagSetCmpTestCase(TagSetTestCaseBase):\n\tdef testCmp(self):\n\t\tassert self.ts1 == self.ts2, 'tag set comparation fails'\n\n\tdef testHash(self):\n\t\tassert hash(self.ts1) == hash(self.ts2), 'tag set hash comp. fails'\n\n\tdef testLen(self):\n\t\tassert len(self.ts1) == len(self.ts2), 'tag length comparation fails'\n", "description": null, "category": "simple", "imports": ["from pyasn1.type import tag", "from pyasn1.error import PyAsn1Error", "from sys import version_info", "\t\timport unittest2 as unittest", "\t\timport unittest", "\timport unittest"]}, {"term": "class", "name": "TaggingTestSuite", "data": "class TaggingTestSuite(TagSetTestCaseBase):\n\tdef testImplicitTag(self):\n\t\tt = self.ts1.tagImplicitly(\n\t\t\ttag.Tag(tag.tagClassApplication, tag.tagFormatSimple, 14)\n\t\t\t)\n\t\tassert t == tag.TagSet(\n\t\t\ttag.Tag(tag.tagClassApplication, tag.tagFormatSimple, 12),\n\t\t\ttag.Tag(tag.tagClassApplication, tag.tagFormatSimple, 14)\n\t\t\t), 'implicit tagging went wrong'\n\n\tdef testExplicitTag(self):\n\t\tt = self.ts1.tagExplicitly(\n\t\t\ttag.Tag(tag.tagClassPrivate, tag.tagFormatSimple, 32)\n\t\t\t)\n\t\tassert t == tag.TagSet(\n\t\t\ttag.Tag(tag.tagClassUniversal, tag.tagFormatSimple, 12),\n\t\t\ttag.Tag(tag.tagClassUniversal, tag.tagFormatSimple, 12),\n\t\t\ttag.Tag(tag.tagClassPrivate, tag.tagFormatConstructed, 32)\n\t\t\t), 'explicit tagging went wrong'\n", "description": null, "category": "simple", "imports": ["from pyasn1.type import tag", "from pyasn1.error import PyAsn1Error", "from sys import version_info", "\t\timport unittest2 as unittest", "\t\timport unittest", "\timport unittest"]}, {"term": "class", "name": "TagSetAddTestSuite", "data": "class TagSetAddTestSuite(TagSetTestCaseBase):\n\tdef testAdd(self):\n\t\tt = self.ts1 + tag.Tag(tag.tagClassApplication, tag.tagFormatSimple, 2)\n\t\tassert t == tag.TagSet(\n\t\t\ttag.Tag(tag.tagClassUniversal, tag.tagFormatSimple, 12),\n\t\t\ttag.Tag(tag.tagClassUniversal, tag.tagFormatSimple, 12),\n\t\t\ttag.Tag(tag.tagClassApplication, tag.tagFormatSimple, 2)\n\t\t\t), 'TagSet.__add__() fails'\n\n\tdef testRadd(self):\n\t\tt = tag.Tag(tag.tagClassApplication, tag.tagFormatSimple, 2) + self.ts1\n\t\tassert t == tag.TagSet(\n\t\t\ttag.Tag(tag.tagClassUniversal, tag.tagFormatSimple, 12),\n\t\t\ttag.Tag(tag.tagClassApplication, tag.tagFormatSimple, 2),\n\t\t\ttag.Tag(tag.tagClassUniversal, tag.tagFormatSimple, 12)\n\t\t\t), 'TagSet.__radd__() fails'\n", "description": null, "category": "simple", "imports": ["from pyasn1.type import tag", "from pyasn1.error import PyAsn1Error", "from sys import version_info", "\t\timport unittest2 as unittest", "\t\timport unittest", "\timport unittest"]}, {"term": "class", "name": "SuperTagSetTestCase", "data": "class SuperTagSetTestCase(TagSetTestCaseBase):\n\tdef testSuperTagCheck1(self):\n\t\tassert self.ts1.isSuperTagSetOf(\n\t\t\ttag.TagSet(\n\t\t\ttag.Tag(tag.tagClassUniversal, tag.tagFormatSimple, 12),\n\t\t\ttag.Tag(tag.tagClassUniversal, tag.tagFormatSimple, 12)\n\t\t\t)), 'isSuperTagSetOf() fails'\n\n\tdef testSuperTagCheck2(self):\n\t\tassert not self.ts1.isSuperTagSetOf(\n\t\t\ttag.TagSet(\n\t\t\ttag.Tag(tag.tagClassUniversal, tag.tagFormatSimple, 12),\n\t\t\ttag.Tag(tag.tagClassUniversal, tag.tagFormatSimple, 13)\n\t\t\t)), 'isSuperTagSetOf() fails'\n\n\tdef testSuperTagCheck3(self):\n\t\tassert self.ts1.isSuperTagSetOf(\n\t\t\ttag.TagSet((), tag.Tag(tag.tagClassUniversal,\n\t\t\t\t\t\t\t\t   tag.tagFormatSimple, 12))\n\t\t\t), 'isSuperTagSetOf() fails'\n", "description": null, "category": "simple", "imports": ["from pyasn1.type import tag", "from pyasn1.error import PyAsn1Error", "from sys import version_info", "\t\timport unittest2 as unittest", "\t\timport unittest", "\timport unittest"]}], [], [{"term": "def", "name": "simple_dtype", "data": "def simple_dtype():\n\tld = np.dtype(\"longdouble\")\n\treturn np.dtype(\n\t\t{\n\t\t\t\"names\": [\"bool_\", \"uint_\", \"float_\", \"ldbl_\"],\n\t\t\t\"formats\": [\"?\", \"u4\", \"f4\", \"f{}\".format(ld.itemsize)],\n\t\t\t\"offsets\": [0, 4, 8, (16 if ld.alignment > 4 else 12)],\n\t\t}\n\t)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "packed_dtype", "data": "def packed_dtype():\n\treturn np.dtype([(\"bool_\", \"?\"), (\"uint_\", \"u4\"), (\"float_\", \"f4\"), (\"ldbl_\", \"g\")])\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "dt_fmt", "data": "def dt_fmt():\n\tfrom sys import byteorder\n\n\te = \"<\" if byteorder == \"little\" else \">\"\n\treturn (\n\t\t\"{{'names':['bool_','uint_','float_','ldbl_'],\"\n\t\t\" 'formats':['?','\" + e + \"u4','\" + e + \"f4','\" + e + \"f{}'],\"\n\t\t\" 'offsets':[0,4,8,{}], 'itemsize':{}}}\"\n\t)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "simple_dtype_fmt", "data": "def simple_dtype_fmt():\n\tld = np.dtype(\"longdouble\")\n\tsimple_ld_off = 12 + 4 * (ld.alignment > 4)\n\treturn dt_fmt().format(ld.itemsize, simple_ld_off, simple_ld_off + ld.itemsize)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "packed_dtype_fmt", "data": "def packed_dtype_fmt():\n\tfrom sys import byteorder\n\n\treturn \"[('bool_', '?'), ('uint_', '{e}u4'), ('float_', '{e}f4'), ('ldbl_', '{e}f{}')]\".format(\n\t\tnp.dtype(\"longdouble\").itemsize, e=\"<\" if byteorder == \"little\" else \">\"\n\t)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "partial_ld_offset", "data": "def partial_ld_offset():\n\treturn (\n\t\t12\n\t\t+ 4 * (np.dtype(\"uint64\").alignment > 4)\n\t\t+ 8\n\t\t+ 8 * (np.dtype(\"longdouble\").alignment > 8)\n\t)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "partial_dtype_fmt", "data": "def partial_dtype_fmt():\n\tld = np.dtype(\"longdouble\")\n\tpartial_ld_off = partial_ld_offset()\n\treturn dt_fmt().format(ld.itemsize, partial_ld_off, partial_ld_off + ld.itemsize)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "partial_nested_fmt", "data": "def partial_nested_fmt():\n\tld = np.dtype(\"longdouble\")\n\tpartial_nested_off = 8 + 8 * (ld.alignment > 8)\n\tpartial_ld_off = partial_ld_offset()\n\tpartial_nested_size = partial_nested_off * 2 + partial_ld_off + ld.itemsize\n\treturn \"{{'names':['a'], 'formats':[{}], 'offsets':[{}], 'itemsize':{}}}\".format(\n\t\tpartial_dtype_fmt(), partial_nested_off, partial_nested_size\n\t)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "assert_equal", "data": "def assert_equal(actual, expected_data, expected_dtype):\n\tnp.testing.assert_equal(actual, np.array(expected_data, dtype=expected_dtype))\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_format_descriptors", "data": "def test_format_descriptors():\n\twith pytest.raises(RuntimeError) as excinfo:\n\t\tm.get_format_unbound()\n\tassert re.match(\n\t\t\"^NumPy type info missing for .*UnboundStruct.*$\", str(excinfo.value)\n\t)\n\n\tld = np.dtype(\"longdouble\")\n\tldbl_fmt = (\"4x\" if ld.alignment > 4 else \"\") + ld.char\n\tss_fmt = \"^T{?:bool_:3xI:uint_:f:float_:\" + ldbl_fmt + \":ldbl_:}\"\n\tdbl = np.dtype(\"double\")\n\tpartial_fmt = (\n\t\t\"^T{?:bool_:3xI:uint_:f:float_:\"\n\t\t+ str(4 * (dbl.alignment > 4) + dbl.itemsize + 8 * (ld.alignment > 8))\n\t\t+ \"xg:ldbl_:}\"\n\t)\n\tnested_extra = str(max(8, ld.alignment))\n\tassert m.print_format_descriptors() == [\n\t\tss_fmt,\n\t\t\"^T{?:bool_:I:uint_:f:float_:g:ldbl_:}\",\n\t\t\"^T{\" + ss_fmt + \":a:^T{?:bool_:I:uint_:f:float_:g:ldbl_:}:b:}\",\n\t\tpartial_fmt,\n\t\t\"^T{\" + nested_extra + \"x\" + partial_fmt + \":a:\" + nested_extra + \"x}\",\n\t\t\"^T{3s:a:3s:b:}\",\n\t\t\"^T{(3)4s:a:(2)i:b:(3)B:c:1x(4, 2)f:d:}\",\n\t\t\"^T{q:e1:B:e2:}\",\n\t\t\"^T{Zf:cflt:Zd:cdbl:}\",\n\t]\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_dtype", "data": "def test_dtype(simple_dtype):\n\tfrom sys import byteorder\n\n\te = \"<\" if byteorder == \"little\" else \">\"\n\n\tassert m.print_dtypes() == [\n\t\tsimple_dtype_fmt(),\n\t\tpacked_dtype_fmt(),\n\t\t\"[('a', {}), ('b', {})]\".format(simple_dtype_fmt(), packed_dtype_fmt()),\n\t\tpartial_dtype_fmt(),\n\t\tpartial_nested_fmt(),\n\t\t\"[('a', 'S3'), ('b', 'S3')]\",\n\t\t(\n\t\t\t\"{{'names':['a','b','c','d'], \"\n\t\t\t+ \"'formats':[('S4', (3,)),('\"\n\t\t\t+ e\n\t\t\t+ \"i4', (2,)),('u1', (3,)),('\"\n\t\t\t+ e\n\t\t\t+ \"f4', (4, 2))], \"\n\t\t\t+ \"'offsets':[0,12,20,24], 'itemsize':56}}\"\n\t\t).format(e=e),\n\t\t\"[('e1', '\" + e + \"i8'), ('e2', 'u1')]\",\n\t\t\"[('x', 'i1'), ('y', '\" + e + \"u8')]\",\n\t\t\"[('cflt', '\" + e + \"c8'), ('cdbl', '\" + e + \"c16')]\",\n\t]\n\n\td1 = np.dtype(\n\t\t{\n\t\t\t\"names\": [\"a\", \"b\"],\n\t\t\t\"formats\": [\"int32\", \"float64\"],\n\t\t\t\"offsets\": [1, 10],\n\t\t\t\"itemsize\": 20,\n\t\t}\n\t)\n\td2 = np.dtype([(\"a\", \"i4\"), (\"b\", \"f4\")])\n\tassert m.test_dtype_ctors() == [\n\t\tnp.dtype(\"int32\"),\n\t\tnp.dtype(\"float64\"),\n\t\tnp.dtype(\"bool\"),\n\t\td1,\n\t\td1,\n\t\tnp.dtype(\"uint32\"),\n\t\td2,\n\t]\n\n\tassert m.test_dtype_methods() == [\n\t\tnp.dtype(\"int32\"),\n\t\tsimple_dtype,\n\t\tFalse,\n\t\tTrue,\n\t\tnp.dtype(\"int32\").itemsize,\n\t\tsimple_dtype.itemsize,\n\t]\n\n\tassert m.trailing_padding_dtype() == m.buffer_to_dtype(\n\t\tnp.zeros(1, m.trailing_padding_dtype())\n\t)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_recarray", "data": "def test_recarray(simple_dtype, packed_dtype):\n\telements = [(False, 0, 0.0, -0.0), (True, 1, 1.5, -2.5), (False, 2, 3.0, -5.0)]\n\n\tfor func, dtype in [\n\t\t(m.create_rec_simple, simple_dtype),\n\t\t(m.create_rec_packed, packed_dtype),\n\t]:\n\t\tarr = func(0)\n\t\tassert arr.dtype == dtype\n\t\tassert_equal(arr, [], simple_dtype)\n\t\tassert_equal(arr, [], packed_dtype)\n\n\t\tarr = func(3)\n\t\tassert arr.dtype == dtype\n\t\tassert_equal(arr, elements, simple_dtype)\n\t\tassert_equal(arr, elements, packed_dtype)\n\n\t\t# Show what recarray's look like in NumPy.\n\t\tassert type(arr[0]) == np.void\n\t\tassert type(arr[0].item()) == tuple\n\n\t\tif dtype == simple_dtype:\n\t\t\tassert m.print_rec_simple(arr) == [\n\t\t\t\t\"s:0,0,0,-0\",\n\t\t\t\t\"s:1,1,1.5,-2.5\",\n\t\t\t\t\"s:0,2,3,-5\",\n\t\t\t]\n\t\telse:\n\t\t\tassert m.print_rec_packed(arr) == [\n\t\t\t\t\"p:0,0,0,-0\",\n\t\t\t\t\"p:1,1,1.5,-2.5\",\n\t\t\t\t\"p:0,2,3,-5\",\n\t\t\t]\n\n\tnested_dtype = np.dtype([(\"a\", simple_dtype), (\"b\", packed_dtype)])\n\n\tarr = m.create_rec_nested(0)\n\tassert arr.dtype == nested_dtype\n\tassert_equal(arr, [], nested_dtype)\n\n\tarr = m.create_rec_nested(3)\n\tassert arr.dtype == nested_dtype\n\tassert_equal(\n\t\tarr,\n\t\t[\n\t\t\t((False, 0, 0.0, -0.0), (True, 1, 1.5, -2.5)),\n\t\t\t((True, 1, 1.5, -2.5), (False, 2, 3.0, -5.0)),\n\t\t\t((False, 2, 3.0, -5.0), (True, 3, 4.5, -7.5)),\n\t\t],\n\t\tnested_dtype,\n\t)\n\tassert m.print_rec_nested(arr) == [\n\t\t\"n:a=s:0,0,0,-0;b=p:1,1,1.5,-2.5\",\n\t\t\"n:a=s:1,1,1.5,-2.5;b=p:0,2,3,-5\",\n\t\t\"n:a=s:0,2,3,-5;b=p:1,3,4.5,-7.5\",\n\t]\n\n\tarr = m.create_rec_partial(3)\n\tassert str(arr.dtype) == partial_dtype_fmt()\n\tpartial_dtype = arr.dtype\n\tassert \"\" not in arr.dtype.fields\n\tassert partial_dtype.itemsize > simple_dtype.itemsize\n\tassert_equal(arr, elements, simple_dtype)\n\tassert_equal(arr, elements, packed_dtype)\n\n\tarr = m.create_rec_partial_nested(3)\n\tassert str(arr.dtype) == partial_nested_fmt()\n\tassert \"\" not in arr.dtype.fields\n\tassert \"\" not in arr.dtype.fields[\"a\"][0].fields\n\tassert arr.dtype.itemsize > partial_dtype.itemsize\n\tnp.testing.assert_equal(arr[\"a\"], m.create_rec_partial(3))\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_array_constructors", "data": "def test_array_constructors():\n\tdata = np.arange(1, 7, dtype=\"int32\")\n\tfor i in range(8):\n\t\tnp.testing.assert_array_equal(m.test_array_ctors(10 + i), data.reshape((3, 2)))\n\t\tnp.testing.assert_array_equal(m.test_array_ctors(20 + i), data.reshape((3, 2)))\n\tfor i in range(5):\n\t\tnp.testing.assert_array_equal(m.test_array_ctors(30 + i), data)\n\t\tnp.testing.assert_array_equal(m.test_array_ctors(40 + i), data)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_string_array", "data": "def test_string_array():\n\tarr = m.create_string_array(True)\n\tassert str(arr.dtype) == \"[('a', 'S3'), ('b', 'S3')]\"\n\tassert m.print_string_array(arr) == [\n\t\t\"a='',b=''\",\n\t\t\"a='a',b='a'\",\n\t\t\"a='ab',b='ab'\",\n\t\t\"a='abc',b='abc'\",\n\t]\n\tdtype = arr.dtype\n\tassert arr[\"a\"].tolist() == [b\"\", b\"a\", b\"ab\", b\"abc\"]\n\tassert arr[\"b\"].tolist() == [b\"\", b\"a\", b\"ab\", b\"abc\"]\n\tarr = m.create_string_array(False)\n\tassert dtype == arr.dtype\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_array_array", "data": "def test_array_array():\n\tfrom sys import byteorder\n\n\te = \"<\" if byteorder == \"little\" else \">\"\n\n\tarr = m.create_array_array(3)\n\tassert str(arr.dtype) == (\n\t\t\"{{'names':['a','b','c','d'], \"\n\t\t+ \"'formats':[('S4', (3,)),('\"\n\t\t+ e\n\t\t+ \"i4', (2,)),('u1', (3,)),('{e}f4', (4, 2))], \"\n\t\t+ \"'offsets':[0,12,20,24], 'itemsize':56}}\"\n\t).format(e=e)\n\tassert m.print_array_array(arr) == [\n\t\t\"a={{A,B,C,D},{K,L,M,N},{U,V,W,X}},b={0,1},\"\n\t\t+ \"c={0,1,2},d={{0,1},{10,11},{20,21},{30,31}}\",\n\t\t\"a={{W,X,Y,Z},{G,H,I,J},{Q,R,S,T}},b={1000,1001},\"\n\t\t+ \"c={10,11,12},d={{100,101},{110,111},{120,121},{130,131}}\",\n\t\t\"a={{S,T,U,V},{C,D,E,F},{M,N,O,P}},b={2000,2001},\"\n\t\t+ \"c={20,21,22},d={{200,201},{210,211},{220,221},{230,231}}\",\n\t]\n\tassert arr[\"a\"].tolist() == [\n\t\t[b\"ABCD\", b\"KLMN\", b\"UVWX\"],\n\t\t[b\"WXYZ\", b\"GHIJ\", b\"QRST\"],\n\t\t[b\"STUV\", b\"CDEF\", b\"MNOP\"],\n\t]\n\tassert arr[\"b\"].tolist() == [[0, 1], [1000, 1001], [2000, 2001]]\n\tassert m.create_array_array(0).dtype == arr.dtype\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_enum_array", "data": "def test_enum_array():\n\tfrom sys import byteorder\n\n\te = \"<\" if byteorder == \"little\" else \">\"\n\n\tarr = m.create_enum_array(3)\n\tdtype = arr.dtype\n\tassert dtype == np.dtype([(\"e1\", e + \"i8\"), (\"e2\", \"u1\")])\n\tassert m.print_enum_array(arr) == [\"e1=A,e2=X\", \"e1=B,e2=Y\", \"e1=A,e2=X\"]\n\tassert arr[\"e1\"].tolist() == [-1, 1, -1]\n\tassert arr[\"e2\"].tolist() == [1, 2, 1]\n\tassert m.create_enum_array(0).dtype == dtype\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_complex_array", "data": "def test_complex_array():\n\tfrom sys import byteorder\n\n\te = \"<\" if byteorder == \"little\" else \">\"\n\n\tarr = m.create_complex_array(3)\n\tdtype = arr.dtype\n\tassert dtype == np.dtype([(\"cflt\", e + \"c8\"), (\"cdbl\", e + \"c16\")])\n\tassert m.print_complex_array(arr) == [\n\t\t\"c:(0,0.25),(0.5,0.75)\",\n\t\t\"c:(1,1.25),(1.5,1.75)\",\n\t\t\"c:(2,2.25),(2.5,2.75)\",\n\t]\n\tassert arr[\"cflt\"].tolist() == [0.0 + 0.25j, 1.0 + 1.25j, 2.0 + 2.25j]\n\tassert arr[\"cdbl\"].tolist() == [0.5 + 0.75j, 1.5 + 1.75j, 2.5 + 2.75j]\n\tassert m.create_complex_array(0).dtype == dtype\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_signature", "data": "def test_signature(doc):\n\tassert (\n\t\tdoc(m.create_rec_nested)\n\t\t== \"create_rec_nested(arg0: int) -> numpy.ndarray[NestedStruct]\"\n\t)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_scalar_conversion", "data": "def test_scalar_conversion():\n\tn = 3\n\tarrays = [\n\t\tm.create_rec_simple(n),\n\t\tm.create_rec_packed(n),\n\t\tm.create_rec_nested(n),\n\t\tm.create_enum_array(n),\n\t]\n\tfuncs = [m.f_simple, m.f_packed, m.f_nested]\n\n\tfor i, func in enumerate(funcs):\n\t\tfor j, arr in enumerate(arrays):\n\t\t\tif i == j and i < 2:\n\t\t\t\tassert [func(arr[k]) for k in range(n)] == [k * 10 for k in range(n)]\n\t\t\telse:\n\t\t\t\twith pytest.raises(TypeError) as excinfo:\n\t\t\t\t\tfunc(arr[0])\n\t\t\t\tassert \"incompatible function arguments\" in str(excinfo.value)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_vectorize", "data": "def test_vectorize():\n\tn = 3\n\tarray = m.create_rec_simple(n)\n\tvalues = m.f_simple_vectorized(array)\n\tnp.testing.assert_array_equal(values, [0, 10, 20])\n\tarray_2 = m.f_simple_pass_thru_vectorized(array)\n\tnp.testing.assert_array_equal(array, array_2)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_cls_and_dtype_conversion", "data": "def test_cls_and_dtype_conversion(simple_dtype):\n\ts = m.SimpleStruct()\n\tassert s.astuple() == (False, 0, 0.0, 0.0)\n\tassert m.SimpleStruct.fromtuple(s.astuple()).astuple() == s.astuple()\n\n\ts.uint_ = 2\n\tassert m.f_simple(s) == 20\n\n\t# Try as recarray of shape==(1,).\n\ts_recarray = np.array([(False, 2, 0.0, 0.0)], dtype=simple_dtype)\n\t# Show that this will work for vectorized case.\n\tnp.testing.assert_array_equal(m.f_simple_vectorized(s_recarray), [20])\n\n\t# Show as a scalar that inherits from np.generic.\n\ts_scalar = s_recarray[0]\n\tassert isinstance(s_scalar, np.void)\n\tassert m.f_simple(s_scalar) == 20\n\n\t# Show that an *array* scalar (np.ndarray.shape == ()) does not convert.\n\t# More specifically, conversion to SimpleStruct is not implicit.\n\ts_recarray_scalar = s_recarray.reshape(())\n\tassert isinstance(s_recarray_scalar, np.ndarray)\n\tassert s_recarray_scalar.dtype == simple_dtype\n\twith pytest.raises(TypeError) as excinfo:\n\t\tm.f_simple(s_recarray_scalar)\n\tassert \"incompatible function arguments\" in str(excinfo.value)\n\t# Explicitly convert to m.SimpleStruct.\n\tassert m.f_simple(m.SimpleStruct.fromtuple(s_recarray_scalar.item())) == 20\n\n\t# Show that an array of dtype=object does *not* convert.\n\ts_array_object = np.array([s])\n\tassert s_array_object.dtype == object\n\twith pytest.raises(TypeError) as excinfo:\n\t\tm.f_simple_vectorized(s_array_object)\n\tassert \"incompatible function arguments\" in str(excinfo.value)\n\t# Explicitly convert to `np.array(..., dtype=simple_dtype)`\n\ts_array = np.array([s.astuple()], dtype=simple_dtype)\n\tnp.testing.assert_array_equal(m.f_simple_vectorized(s_array), [20])\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_register_dtype", "data": "def test_register_dtype():\n\twith pytest.raises(RuntimeError) as excinfo:\n\t\tm.register_dtype()\n\tassert \"dtype is already registered\" in str(excinfo.value)\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_str_leak", "data": "def test_str_leak():\n\tfrom sys import getrefcount\n\n\tfmt = \"f4\"\n\tpytest.gc_collect()\n\tstart = getrefcount(fmt)\n\td = m.dtype_wrapper(fmt)\n\tassert d is np.dtype(\"f4\")\n\tdel d\n\tpytest.gc_collect()\n\tassert getrefcount(fmt) == start\n\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}, {"term": "def", "name": "test_compare_buffer_info", "data": "def test_compare_buffer_info():\n\tassert all(m.compare_buffer_info())\n", "description": null, "category": "simple", "imports": ["import re", "import pytest", "import env  # noqa: F401", "from pybind11_tests import numpy_dtypes as m", "np = pytest.importorskip(\"numpy\")", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import byteorder", "\tfrom sys import getrefcount"]}], [{"term": "def", "name": "GenerateTopasScripts", "data": "def GenerateTopasScripts(BaseDirectory, iteration, **variable_dict):\n\t\"\"\"\n\tThis file simply returns a list object, where each list entry corresponds to\n\ta line in the topas script.\n\tWhen it is called from an Optimiser object,it will receive a dictionary that contains the current values of \n\tthe variables you set up in optimisation_params when you initialised the optimiser.\n\t\"\"\"\n\t\n\tSimpleCollimator = []\n\tSimpleCollimator.append('# Set threading self:')\n\tSimpleCollimator.append('------------------------------------------------------------')\n\tSimpleCollimator.append('i:Ts/NumberOfThreads = 0  ')\n\tSimpleCollimator.append('i:Ts/ShowHistoryCountAtInterval = 1000000')\n\tSimpleCollimator.append('b:Ts/ShowHistoryCountOnSingleLine = \"True\"')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('# Add World:')\n\tSimpleCollimator.append('------------------------------------------------------------')\n\tSimpleCollimator.append('s:Ge/World/Type = \"TsBox\"')\n\tSimpleCollimator.append('s:Ge/World/Material = \"Vacuum\"')\n\tSimpleCollimator.append('d:Ge/World/HLX = 250 mm ')\n\tSimpleCollimator.append('d:Ge/World/HLY = 250 mm')\n\tSimpleCollimator.append('d:Ge/World/HLZ = 1200.0 mm')\n\tSimpleCollimator.append('d:Ge/World/RotX = 0. deg')\n\tSimpleCollimator.append('d:Ge/World/RotY = 0. deg')\n\tSimpleCollimator.append('d:Ge/World/RotZ = 0. deg')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('d:Ge/SID = 1000 mm')\n\tSimpleCollimator.append('d:Ge/SecondaryCollimatorOffset = 20 mm')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('Target')\n\tSimpleCollimator.append('------------------------------------------------------------')\n\tSimpleCollimator.append('s:Ge/Target/Type \t\t\t= \"TsCylinder\"')\n\tSimpleCollimator.append('s:Ge/Target/Parent \t\t\t= \"World\"')\n\tSimpleCollimator.append('s:Ge/Target/Material \t\t\t= \"G4_W\"')\n\tSimpleCollimator.append('d:Ge/Target/RMax   \t\t\t= 50 mm')\n\tSimpleCollimator.append('d:Ge/Target/HL  \t\t\t= 2 mm')\n\tSimpleCollimator.append('d:Ge/Target/TransZ \t\t\t= Ge/SID + Ge/Target/HL mm')\n\tSimpleCollimator.append('sc:Ge/Target/DrawingStyle \t\t= \"Solid\"')\n\tSimpleCollimator.append('sc:Ge/Target/Color \t\t\t= \"magenta\"')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('# primary collimator (abuts target)')\n\tSimpleCollimator.append('------------------------------------------------------------')\n\tSimpleCollimator.append('s:Ge/PrimaryCollimator/Parent\t = \"World\" ')\n\tSimpleCollimator.append('s:Ge/PrimaryCollimator/Material   = \"G4_W\"')\n\tSimpleCollimator.append('s:Ge/PrimaryCollimator/Type\t   = \"G4Cons\"')\n\tSimpleCollimator.append('d:Ge/PrimaryCollimator/RMin1\t  = 5 mm')\n\tSimpleCollimator.append('d:Ge/PrimaryCollimator/RMax1\t  = 50 mm ')\n\tSimpleCollimator.append('d:Ge/PrimaryCollimator/RMin2\t  = 3 mm')\n\tSimpleCollimator.append('d:Ge/PrimaryCollimator/RMax2\t  = 50 mm')\n\tSimpleCollimator.append('d:Ge/PrimaryCollimator/HL\t\t = 48 mm')\n\tSimpleCollimator.append('d:Ge/PrimaryCollimator/Pos\t\t= 1.7 cm')\n\tSimpleCollimator.append('d:Ge/PrimaryCollimator/TransZ\t = Ge/SID - Ge/PrimaryCollimator/HL  mm')\n\tSimpleCollimator.append('sc:Ge/PrimaryCollimator/DrawingStyle \t\t= \"Solid\"')\n\tSimpleCollimator.append('s:Ge/PrimaryCollimator/Color\t  = \"Blue\"')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('# Secondary collimator')\n\tSimpleCollimator.append('------------------------------------------------------------')\n\tSimpleCollimator.append('s:Ge/SecondaryCollimator/Parent\t = \"World\" ')\n\tSimpleCollimator.append('s:Ge/SecondaryCollimator/Material   = \"G4_Pb\"')\n\tSimpleCollimator.append('s:Ge/SecondaryCollimator/Type\t   = \"G4Cons\"')\n\tSimpleCollimator.append('d:Ge/SecondaryCollimator/RMin1\t  = 2.5 mm')\n\tSimpleCollimator.append('d:Ge/SecondaryCollimator/RMax1\t  = 50 mm ')\n\tSimpleCollimator.append('d:Ge/SecondaryCollimator/RMin2\t  = 1.82 mm')\n\tSimpleCollimator.append('d:Ge/SecondaryCollimator/RMax2\t  = 50 mm')\n\tSimpleCollimator.append('d:Ge/SecondaryCollimator/HL\t\t = 27 mm')\n\tSimpleCollimator.append('d:Ge/SecondaryCollimator/Pos\t\t= 1.7 cm')\n\tSimpleCollimator.append('d:Ge/SecondaryCollimator/temp_TransZ1 = Ge/PrimaryCollimator/TransZ - Ge/PrimaryCollimator/HL  mm')\n\tSimpleCollimator.append('d:Ge/SecondaryCollimator/temp_TransZ2 = Ge/SecondaryCollimator/temp_TransZ1 - Ge/SecondaryCollimator/HL mm')\n\tSimpleCollimator.append('d:Ge/SecondaryCollimator/TransZ\t = Ge/SecondaryCollimator/temp_TransZ2 - Ge/SecondaryCollimatorOffset mm')\n\tSimpleCollimator.append('sc:Ge/SecondaryCollimator/DrawingStyle \t\t= \"Solid\"')\n\tSimpleCollimator.append('s:Ge/SecondaryCollimator/Color\t  = \"green\"')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('# # Beam parameters (paramterised source):')\n\tSimpleCollimator.append('------------------------------------------------------------')\n\tSimpleCollimator.append('s:So/Beam/Type\t\t\t\t\t = \"Beam\"')\n\tSimpleCollimator.append('sc:So/Beam/Component\t\t\t\t= \"ElectronSource\"')\n\tSimpleCollimator.append('sc:So/Beam/BeamParticle\t\t\t = \"e-\"')\n\tSimpleCollimator.append('dc:So/Beam/BeamEnergy\t\t\t   = ' + str(variable_dict['BeamEnergy']) + ' MeV')\n\tSimpleCollimator.append('uc:So/Beam/BeamEnergySpread\t\t = 0')\n\tSimpleCollimator.append('sc:So/Beam/BeamPositionDistribution = \"Gaussian\" ')\n\tSimpleCollimator.append('sc:So/Beam/BeamAngularDistribution  = \"Gaussian\" ')\n\tSimpleCollimator.append('sc:So/Beam/BeamPositionCutoffShape = \"Ellipse\"')\n\tSimpleCollimator.append('dc:So/Beam/BeamPositionCutoffX = ' + str(variable_dict['BeamPositionCutoff']) + ' mm')\n\tSimpleCollimator.append('dc:So/Beam/BeamPositionCutoffY = ' + str(variable_dict['BeamPositionCutoff']) + ' mm')\n\tSimpleCollimator.append('dc:So/Beam/BeamPositionSpreadX = ' + str(variable_dict['BeamPositionSpread']) + ' mm')\n\tSimpleCollimator.append('dc:So/Beam/BeamPositionSpreadY = ' + str(variable_dict['BeamPositionSpread']) + ' mm')\n\tSimpleCollimator.append('dc:So/Beam/BeamAngularCutoffX = ' + str(variable_dict['BeamAngularCutoff']) + ' deg')\n\tSimpleCollimator.append('dc:So/Beam/BeamAngularCutoffY = ' + str(variable_dict['BeamAngularCutoff']) + ' deg')\n\tSimpleCollimator.append('dc:So/Beam/BeamAngularSpreadX = ' + str(variable_dict['BeamAngularSpread']) + ' deg')\n\tSimpleCollimator.append('dc:So/Beam/BeamAngularSpreadY = ' + str(variable_dict['BeamAngularSpread']) + ' deg')\n\n\n\tSimpleCollimator.append('ic:So/Beam/NumberOfHistoriesInRun = 50')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('# # Electron source position')\n\tSimpleCollimator.append('# ------------------------------------------------------------')\n\tSimpleCollimator.append('s:Ge/ElectronSource/Parent = \"World\"')\n\tSimpleCollimator.append('s:Ge/ElectronSource/Type=\"TsSPhere\"')\n\tSimpleCollimator.append('d:Ge/ElectronSource/Rmax = 5 mm')\n\tSimpleCollimator.append('d:Ge/ElectronSource/TransZ = 1100 mm')\n\tSimpleCollimator.append('d:Ge/ElectronSource/RotX = 180. deg')\n\tSimpleCollimator.append('s:Ge/ElectronSource/Material = Ge/World/Material')\n\tSimpleCollimator.append('s:Ge/ElectronSource/Color = \"yellow\"')\n\tSimpleCollimator.append('sc:Ge/ElectronSource/DrawingStyle = \"Solid\"')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('# Variance reduction in target')\n\tSimpleCollimator.append('# ------------------------------------------------------------')\n\tSimpleCollimator.append('b:Vr/UseVarianceReduction = \"True\"')\n\tSimpleCollimator.append('s:Ge/Target/AssignToRegionNamed = \"VarianceReduction\"')\n\tSimpleCollimator.append('s:Vr/ParticleSplit/Type = \"SecondaryBiasing\"')\n\tSimpleCollimator.append('sv:Vr/ParticleSplit/ForRegion/VarianceReduction/ProcessesNamed = 1 \"eBrem\"')\n\tSimpleCollimator.append('uv:Vr/ParticleSplit/ForRegion/VarianceReduction/SplitNumber = 1 1000 ')\n\tSimpleCollimator.append('dv:Vr/ParticleSplit/ForRegion/VarianceReduction/MaximumEnergies = 1 10.0 MeV')\n\tSimpleCollimator.append('s:Vr/ParticleSplit/ReferenceComponent = \"Target\"')\n\tSimpleCollimator.append('dv:Vr/ParticleSplit/ForRegion/VarianceReduction/DirectionalSplitLimits = 1 -1 * Ge/Target/TransZ mm')\n\tSimpleCollimator.append('dv:Vr/ParticleSplit/ForRegion/VarianceReduction/DirectionalSplitRadius = 1 50 mm')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('# # Add phase space scorer below collimator:')\n\tSimpleCollimator.append('# ------------------------------------------------------------')\n\tSimpleCollimator.append('s:Ge/PhaseSpaceScorer/Type\t = \"TsBox\"')\n\tSimpleCollimator.append('s:Ge/PhaseSpaceScorer/Parent   = \"World\"')\n\tSimpleCollimator.append('s:Ge/PhaseSpaceScorer/Material = \"Vacuum\"')\n\tSimpleCollimator.append('d:Ge/PhaseSpaceScorer/HLX\t  = Ge/SecondaryCollimator/RMax2 mm')\n\tSimpleCollimator.append('d:Ge/PhaseSpaceScorer/HLY\t  = Ge/SecondaryCollimator/RMax2 mm')\n\tSimpleCollimator.append('d:Ge/PhaseSpaceScorer/HLZ\t  = 1 mm')\n\tSimpleCollimator.append('d:Ge/PhaseSpaceScorer/TransX   = 0. cm')\n\tSimpleCollimator.append('d:Ge/PhaseSpaceScorer/TransY   = 0. cm')\n\tSimpleCollimator.append('d:Ge/PhaseSpaceScorer/temp_TranZ1   = Ge/SecondaryCollimator/TransZ mm')\n\tSimpleCollimator.append('d:Ge/PhaseSpaceScorer/temp_TranZ2   = Ge/PhaseSpaceScorer/temp_TranZ1 - Ge/SecondaryCollimator/HL   mm')\n\tSimpleCollimator.append('d:Ge/PhaseSpaceScorer/TransZ   = Ge/PhaseSpaceScorer/temp_TranZ2 - 10  mm')\n\tSimpleCollimator.append('d:Ge/PhaseSpaceScorer/RotX\t = 0. deg')\n\tSimpleCollimator.append('d:Ge/PhaseSpaceScorer/RotY\t = 0. deg')\n\tSimpleCollimator.append('d:Ge/PhaseSpaceScorer/RotZ\t = 0. deg')\n\tSimpleCollimator.append('s:Ge/PhaseSpaceScorer/Color\t= \"skyblue\"')\n\tSimpleCollimator.append('s:Ge/PhaseSpaceScorer/DrawingStyle = \"wireframe\"')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('s:Sc/PhaseSpaceFromColl/Quantity\t\t\t\t\t= \"PhaseSpace\"')\n\tSimpleCollimator.append('b:Sc/PhaseSpaceFromColl/OutputToConsole\t\t\t = \"False\"')\n\tSimpleCollimator.append('s:Sc/PhaseSpaceFromColl/Surface\t\t\t\t\t = \"PhaseSpaceScorer/ZMinusSurface\"')\n\tSimpleCollimator.append('s:Sc/PhaseSpaceFromColl/OutputType\t\t\t\t  = \"Binary\" ')\n\tSimpleCollimator.append('s:Sc/PhaseSpaceFromColl/OutputFile\t\t\t\t   =  \"../Results/coll_PhaseSpace_itt_' + str(iteration) + '\"')\n\tSimpleCollimator.append('i:Sc/PhaseSpaceFromColl/OutputBufferSize\t\t\t= 1000')\n\tSimpleCollimator.append('#s:Sc/PhaseSpaceFromColl/OnlyIncludeParticlesGoing  = \"In\"')\n\tSimpleCollimator.append('b:Sc/PhaseSpaceFromColl/IncludeTOPASTime\t\t\t= \"False\"')\n\tSimpleCollimator.append('b:Sc/PhaseSpaceFromColl/IncludeTimeOfFlight\t\t = \"False\"')\n\tSimpleCollimator.append('b:Sc/PhaseSpaceFromColl/IncludeRunID\t\t\t\t= \"False\"')\n\tSimpleCollimator.append('b:Sc/PhaseSpaceFromColl/IncludeEventID\t\t\t  = \"False\"')\n\tSimpleCollimator.append('b:Sc/PhaseSpaceFromColl/IncludeTrackID\t\t\t  = \"False\"')\n\tSimpleCollimator.append('b:Sc/PhaseSpaceFromColl/IncludeParentID\t\t\t = \"False\"')\n\tSimpleCollimator.append('b:Sc/PhaseSpaceFromColl/IncludeCreatorProcess\t   = \"False\"')\n\tSimpleCollimator.append('b:Sc/PhaseSpaceFromColl/IncludeVertexInfo\t\t   = \"False\"')\n\tSimpleCollimator.append('b:Sc/PhaseSpaceFromColl/IncludeSeed\t\t\t\t = \"False\"')\n\tSimpleCollimator.append('s:Sc/PhaseSpaceFromColl/IfOutputFileAlreadyExists   = \"Overwrite\"')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('# Graphics View and trajectory filters:')\n\tSimpleCollimator.append('------------------------------------------------------------')\n\tSimpleCollimator.append('b:Gr/Enable = \"False\"  ')\n\tSimpleCollimator.append('s:Gr/ViewA/Type\t\t\t  = \"OpenGL\"')\n\tSimpleCollimator.append('d:Gr/ViewA/Theta\t\t\t= 90 deg')\n\tSimpleCollimator.append('d:Gr/ViewA/Phi\t\t\t  = 0 deg')\n\tSimpleCollimator.append('u:Gr/ViewA/TransX\t\t   = 0')\n\tSimpleCollimator.append('u:Gr/ViewA/TransY\t\t   = 0.')\n\tSimpleCollimator.append('s:Gr/ViewA/Projection\t   = \"Orthogonal\"')\n\tSimpleCollimator.append('d:Gr/ViewA/PerspectiveAngle = 60 deg')\n\tSimpleCollimator.append('u:Gr/ViewA/Zoom\t\t\t = 1')\n\tSimpleCollimator.append('b:Gr/ViewA/IncludeStepPoints = \"False\"')\n\tSimpleCollimator.append('b:Gr/ViewA/HiddenLineRemovalForTrajectories = \"True\"')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('# Physics')\n\tSimpleCollimator.append('------------------------------------------------------------')\n\tSimpleCollimator.append('sv:Ph/Default/Modules = 1 \"g4em-standard_opt0\"')\n\tSimpleCollimator.append('b:Ph/ListProcesses = \"False\"')\n\tSimpleCollimator.append('')\n\tSimpleCollimator.append('------------------------------------------------------------')\n\tSimpleCollimator.append('# QT')\n\tSimpleCollimator.append('# --')\n\tSimpleCollimator.append('Ts/UseQt = Gr/Enable')\n\tSimpleCollimator.append('Ts/PauseBeforeQuit = Gr/Enable')\n\tSimpleCollimator.append('Ts/IncludeDefaultGeant4QtWidgets = \"F\"')\n\t\n\tWaterTank = []\n\tWaterTank.append('# Set threading self:')\n\tWaterTank.append('------------------------------------------------------------')\n\tWaterTank.append('i:Ts/NumberOfThreads = 0  ')\n\tWaterTank.append('i:Ts/ShowHistoryCountAtInterval = 100000')\n\tWaterTank.append('')\n\tWaterTank.append('')\n\tWaterTank.append('# Add World:')\n\tWaterTank.append('------------------------------------------------------------')\n\tWaterTank.append('s:Ge/World/Type = \"TsBox\"')\n\tWaterTank.append('s:Ge/World/Material = \"Vacuum\"')\n\tWaterTank.append('d:Ge/World/HLX = 250 mm ')\n\tWaterTank.append('d:Ge/World/HLY = 250 mm')\n\tWaterTank.append('d:Ge/World/HLZ = 1200.0 mm')\n\tWaterTank.append('d:Ge/World/RotX = 0. deg')\n\tWaterTank.append('d:Ge/World/RotY = 0. deg')\n\tWaterTank.append('d:Ge/World/RotZ = 0. deg')\n\tWaterTank.append('')\n\tWaterTank.append('')\n\tWaterTank.append('# Phase Space source:')\n\tWaterTank.append('------------------------------------------------------------')\n\tWaterTank.append('s:So/Example/Type\t\t\t\t\t\t\t= \"PhaseSpace\"')\n\tWaterTank.append('s:So/Example/PhaseSpaceFileName\t\t\t   =  \"../Results/coll_PhaseSpace_itt_' + str(iteration) + '\"')\n\tWaterTank.append('s:So/Example/Component\t\t\t\t\t   = \"World\"')\n\tWaterTank.append('i:So/Example/PhaseSpaceMultipleUse\t\t  = 200')\n\tWaterTank.append('b:So/Example/PhaseSpaceIncludeEmptyHistories = \"False\"')\n\tWaterTank.append('# i:So/Example/NumberOfHistoriesInRun = 10 # set PhaseSpaceMultipleUse to 0 to enable this option')\n\tWaterTank.append('')\n\tWaterTank.append('# Add the phantom')\n\tWaterTank.append('------------------------------------------------------------')\n\tWaterTank.append('# Phantom')\n\tWaterTank.append('s:Ge/Phantom/Type = \"TsBox\"')\n\tWaterTank.append('s:Ge/Phantom/Parent = \"World\"')\n\tWaterTank.append('sc:Ge/Phantom/Material = \"G4_WATER\"')\n\tWaterTank.append('# We draw the phantom to be field size plus one beamlet')\n\tWaterTank.append('dc:Ge/Phantom/HLX = 75 mm')\n\tWaterTank.append('dc:Ge/Phantom/HLY = 75 mm')\n\tWaterTank.append('dc:Ge/Phantom/HLZ =  75 mm')\n\tWaterTank.append('dc:Ge/Phantom/TransX = 0. cm')\n\tWaterTank.append('dc:Ge/Phantom/TransY = 0. cm')\n\tWaterTank.append('dc:Ge/Phantom/TransZ = 0. cm')\n\tWaterTank.append('dc:Ge/Phantom/RotX = 0. deg')\n\tWaterTank.append('dc:Ge/Phantom/RotY = 0. deg')\n\tWaterTank.append('dc:Ge/Phantom/RotZ = 0. deg')\n\tWaterTank.append('ic:Ge/Phantom/XBins = 50')\n\tWaterTank.append('ic:Ge/Phantom/YBins = 50')\n\tWaterTank.append('ic:Ge/Phantom/ZBins = 60')\n\tWaterTank.append('sc:Ge/Phantom/Color\t= \"green\"')\n\tWaterTank.append('sc:Ge/Phantom/DrawingStyle = \"Solid\"')\n\tWaterTank.append('')\n\tWaterTank.append('')\n\tWaterTank.append('# Add Volume scorer to phantom:')\n\tWaterTank.append('------------------------------------------------------------')\n\tWaterTank.append('s:Sc/PhantomScorer/Component = \"Phantom\"')\n\tWaterTank.append('s:Sc/PhantomScorer/Material = \"Water\"')\n\tWaterTank.append('s:Sc/PhantomScorer/Quantity\t\t\t\t  = \"DoseToMedium\"')\n\tWaterTank.append('b:Sc/PhantomScorer/OutputToConsole\t\t   = \"FALSE\"')\n\tWaterTank.append('s:Sc/PhantomScorer/IfOutputFileAlreadyExists = \"Overwrite\"')\n\tWaterTank.append('s:Sc/PhantomScorer/OutputType = \"Binary\" ')\n\tWaterTank.append('s:Sc/PhantomScorer/OutputFile\t\t\t\t   =  \"../Results/WaterTank_itt_' + str(iteration) + '\"')\n\tWaterTank.append('')\n\tWaterTank.append('')\n\tWaterTank.append('# Graphics View and trajectory filters:')\n\tWaterTank.append('------------------------------------------------------------')\n\tWaterTank.append('b:Gr/Enable = \"False\"  ')\n\tWaterTank.append('s:Gr/ViewA/Type\t\t\t  = \"OpenGL\"')\n\tWaterTank.append('dc:Gr/ViewA/Theta\t\t\t= 90 deg')\n\tWaterTank.append('dc:Gr/ViewA/Phi\t\t\t  = 0 deg')\n\tWaterTank.append('uc:Gr/ViewA/TransX\t\t   = -0.5')\n\tWaterTank.append('uc:Gr/ViewA/TransY\t\t   = 0.')\n\tWaterTank.append('sc:Gr/ViewA/Projection\t   = \"Orthogonal\"')\n\tWaterTank.append('dc:Gr/ViewA/PerspectiveAngle = 30 deg')\n\tWaterTank.append('uc:Gr/ViewA/Zoom\t\t\t = 10')\n\tWaterTank.append('bc:Gr/ViewA/IncludeStepPoints = \"False\"')\n\tWaterTank.append('bc:Gr/ViewA/HiddenLineRemovalForTrajectories = \"True\"')\n\tWaterTank.append('# sv:Gr/OnlyIncludeParticlesFromVolume = 1 \"ElectronSource\" # one or more volume')\n\tWaterTank.append('# sv:Gr/OnlyIncludeParticlesFromComponentOrSubComponentsOf = 1 \"ElectronSource\"')\n\tWaterTank.append('# sv:Gr/OnlyIncludeParticlesFromComponent = 2 \"Target\" \"Sphinx\"  # one or more component')\n\tWaterTank.append('# sv:Gr/OnlyIncludeParticlesFromVolume = 1 \"Film1/Film1_Z_Division\"')\n\tWaterTank.append('# sv:Gr/OnlyIncludeParticlesFromComponent = 1 \"Film2\"')\n\tWaterTank.append('sv:Gr/OnlyIncludeParticlesFromProcess = 1 \"primary\"')\n\tWaterTank.append('')\n\tWaterTank.append('')\n\tWaterTank.append('# Physics')\n\tWaterTank.append('------------------------------------------------------------')\n\tWaterTank.append('sv:Ph/Default/Modules = 1 \"g4em-standard_opt0\"')\n\tWaterTank.append('b:Ph/ListProcesses = \"True\"')\n\tWaterTank.append('')\n\tWaterTank.append('')\n\tWaterTank.append('------------------------------------------------------------')\n\tWaterTank.append('# QT')\n\tWaterTank.append('# --')\n\tWaterTank.append('Ts/UseQt = Gr/Enable')\n\tWaterTank.append('Ts/PauseBeforeQuit = Gr/Enable')\n\tWaterTank.append('Ts/IncludeDefaultGeant4QtWidgets = \"T\"')\n\n\treturn [SimpleCollimator, WaterTank], ['SimpleCollimator', 'WaterTank']\n", "description": "\n\tThis file simply returns a list object, where each list entry corresponds to\n\ta line in the topas script.\n\tWhen it is called from an Optimiser object,it will receive a dictionary that contains the current values of \n\tthe variables you set up in optimisation_params when you initialised the optimiser.\n\t", "category": "simple", "imports": ["from pathlib import Path"]}], [{"term": "def", "name": "fswig_import_helper", "data": "\tdef swig_import_helper():\n\t\timport importlib\n\t\tpkg = __name__.rpartition('.')[0]\n\t\tmname = '.'.join((pkg, '_param_SimpleIntLink')).lstrip('.')\n\t\ttry:\n\t\t\treturn importlib.import_module(mname)\n\t\texcept ImportError:\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleIntLink')", "\t_param_SimpleIntLink = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleIntLink", "\t_param_SimpleIntLink = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleIntLink", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BasicIntLink", "import m5.internal.param_BasicRouter", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_BasicLink"]}, {"term": "def", "name": "fswig_import_helper", "data": "\tdef swig_import_helper():\n\t\tfrom os.path import dirname\n\t\timport imp\n\t\tfp = None\n\t\ttry:\n\t\t\tfp, pathname, description = imp.find_module('_param_SimpleIntLink', [dirname(__file__)])\n\t\texcept ImportError:\n\t\t\timport _param_SimpleIntLink\n\t\t\treturn _param_SimpleIntLink\n\t\ttry:\n\t\t\t_mod = imp.load_module('_param_SimpleIntLink', fp, pathname, description)\n\t\tfinally:\n\t\t\tif fp is not None:\n\t\t\t\tfp.close()\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleIntLink')", "\t_param_SimpleIntLink = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleIntLink", "\t_param_SimpleIntLink = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleIntLink", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BasicIntLink", "import m5.internal.param_BasicRouter", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_BasicLink"]}, {"term": "def", "name": "_swig_setattr_nondynamic", "data": "def _swig_setattr_nondynamic(self, class_type, name, value, static=1):\n\tif (name == \"thisown\"):\n\t\treturn self.this.own(value)\n\tif (name == \"this\"):\n\t\tif type(value).__name__ == 'SwigPyObject':\n\t\t\tself.__dict__[name] = value\n\t\t\treturn\n\tmethod = class_type.__swig_setmethods__.get(name, None)\n\tif method:\n\t\treturn method(self, value)\n\tif (not static):\n\t\tobject.__setattr__(self, name, value)\n\telse:\n\t\traise AttributeError(\"You cannot add attributes to %s\" % self)\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleIntLink')", "\t_param_SimpleIntLink = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleIntLink", "\t_param_SimpleIntLink = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleIntLink", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BasicIntLink", "import m5.internal.param_BasicRouter", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_BasicLink"]}, {"term": "def", "name": "_swig_setattr", "data": "def _swig_setattr(self, class_type, name, value):\n\treturn _swig_setattr_nondynamic(self, class_type, name, value, 0)\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleIntLink')", "\t_param_SimpleIntLink = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleIntLink", "\t_param_SimpleIntLink = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleIntLink", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BasicIntLink", "import m5.internal.param_BasicRouter", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_BasicLink"]}, {"term": "def", "name": "_swig_getattr", "data": "def _swig_getattr(self, class_type, name):\n\tif (name == \"thisown\"):\n\t\treturn self.this.own()\n\tmethod = class_type.__swig_getmethods__.get(name, None)\n\tif method:\n\t\treturn method(self)\n\traise AttributeError(\"'%s' object has no attribute '%s'\" % (class_type.__name__, name))\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleIntLink')", "\t_param_SimpleIntLink = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleIntLink", "\t_param_SimpleIntLink = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleIntLink", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BasicIntLink", "import m5.internal.param_BasicRouter", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_BasicLink"]}, {"term": "def", "name": "_swig_repr", "data": "def _swig_repr(self):\n\ttry:\n\t\tstrthis = \"proxy of \" + self.this.__repr__()\n\texcept __builtin__.Exception:\n\t\tstrthis = \"\"\n\treturn \"<%s.%s; %s >\" % (self.__class__.__module__, self.__class__.__name__, strthis,)\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleIntLink')", "\t_param_SimpleIntLink = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleIntLink", "\t_param_SimpleIntLink = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleIntLink", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BasicIntLink", "import m5.internal.param_BasicRouter", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_BasicLink"]}, {"term": "def", "name": "_swig_setattr_nondynamic_method", "data": "def _swig_setattr_nondynamic_method(set):\n\tdef set_attr(self, name, value):\n\t\tif (name == \"thisown\"):\n\t\t\treturn self.this.own(value)\n\t\tif hasattr(self, name) or (name == \"this\"):\n\t\t\tset(self, name, value)\n\t\telse:\n\t\t\traise AttributeError(\"You cannot add attributes to %s\" % self)\n\treturn set_attr\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleIntLink')", "\t_param_SimpleIntLink = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleIntLink", "\t_param_SimpleIntLink = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleIntLink", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BasicIntLink", "import m5.internal.param_BasicRouter", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_BasicLink"]}, {"term": "class", "name": "SimpleIntLink", "data": "class SimpleIntLink(m5.internal.param_BasicIntLink.BasicIntLink):\n\tthisown = _swig_property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc='The membership flag')\n\n\tdef __init__(self, *args, **kwargs):\n\t\traise AttributeError(\"No constructor defined - class is abstract\")\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleIntLink')", "\t_param_SimpleIntLink = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleIntLink", "\t_param_SimpleIntLink = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleIntLink", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BasicIntLink", "import m5.internal.param_BasicRouter", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_BasicLink"]}, {"term": "class", "name": "SimpleIntLinkParams", "data": "class SimpleIntLinkParams(m5.internal.param_BasicIntLink.BasicIntLinkParams):\n\tthisown = _swig_property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc='The membership flag')\n\t__repr__ = _swig_repr\n\n\tdef create(self):\n\t\treturn _param_SimpleIntLink.SimpleIntLinkParams_create(self)\n\n\tdef __init__(self):\n\t\tthis = _param_SimpleIntLink.new_SimpleIntLinkParams()\n\t\ttry:\n\t\t\tself.this.append(this)\n\t\texcept __builtin__.Exception:\n\t\t\tself.this = this\n\t__swig_destroy__ = _param_SimpleIntLink.delete_SimpleIntLinkParams\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleIntLink')", "\t_param_SimpleIntLink = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleIntLink", "\t_param_SimpleIntLink = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleIntLink", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BasicIntLink", "import m5.internal.param_BasicRouter", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_BasicLink"]}], [{"term": "class", "name": "ScannerError", "data": "class ScannerError(MarkedYAMLError):\n\tpass\n", "description": null, "category": "simple", "imports": ["from .error import MarkedYAMLError", "from .tokens import *"]}, {"term": "class", "name": "classSimpleKey:", "data": "class SimpleKey:\n\t# See below simple keys treatment.\n\n\tdef __init__(self, token_number, required, index, line, column, mark):\n\t\tself.token_number = token_number\n\t\tself.required = required\n\t\tself.index = index\n\t\tself.line = line\n\t\tself.column = column\n\t\tself.mark = mark\n", "description": null, "category": "simple", "imports": ["from .error import MarkedYAMLError", "from .tokens import *"]}, {"term": "class", "name": "classScanner:", "data": "class Scanner:\n\n\tdef __init__(self):\n\t\t\"\"\"Initialize the scanner.\"\"\"\n\t\t# It is assumed that Scanner and Reader will have a common descendant.\n\t\t# Reader do the dirty work of checking for BOM and converting the\n\t\t# input data to Unicode. It also adds NUL to the end.\n\t\t#\n\t\t# Reader supports the following methods\n\t\t#   self.peek(i=0)\t   # peek the next i-th character\n\t\t#   self.prefix(l=1)\t # peek the next l characters\n\t\t#   self.forward(l=1)\t# read the next l characters and move the pointer.\n\n\t\t# Had we reached the end of the stream?\n\t\tself.done = False\n\n\t\t# The number of unclosed '{' and '['. `flow_level == 0` means block\n\t\t# context.\n\t\tself.flow_level = 0\n\n\t\t# List of processed tokens that are not yet emitted.\n\t\tself.tokens = []\n\n\t\t# Add the STREAM-START token.\n\t\tself.fetch_stream_start()\n\n\t\t# Number of tokens that were emitted through the `get_token` method.\n\t\tself.tokens_taken = 0\n\n\t\t# The current indentation level.\n\t\tself.indent = -1\n\n\t\t# Past indentation levels.\n\t\tself.indents = []\n\n\t\t# Variables related to simple keys treatment.\n\n\t\t# A simple key is a key that is not denoted by the '?' indicator.\n\t\t# Example of simple keys:\n\t\t#   ---\n\t\t#   block simple key: value\n\t\t#   ? not a simple key:\n\t\t#   : { flow simple key: value }\n\t\t# We emit the KEY token before all keys, so when we find a potential\n\t\t# simple key, we try to locate the corresponding ':' indicator.\n\t\t# Simple keys should be limited to a single line and 1024 characters.\n\n\t\t# Can a simple key start at the current position? A simple key may\n\t\t# start:\n\t\t# - at the beginning of the line, not counting indentation spaces\n\t\t#\t   (in block context),\n\t\t# - after '{', '[', ',' (in the flow context),\n\t\t# - after '?', ':', '-' (in the block context).\n\t\t# In the block context, this flag also signifies if a block collection\n\t\t# may start at the current position.\n\t\tself.allow_simple_key = True\n\n\t\t# Keep track of possible simple keys. This is a dictionary. The key\n\t\t# is `flow_level`; there can be no more that one possible simple key\n\t\t# for each level. The value is a SimpleKey record:\n\t\t#   (token_number, required, index, line, column, mark)\n\t\t# A simple key may start with ALIAS, ANCHOR, TAG, SCALAR(flow),\n\t\t# '[', or '{' tokens.\n\t\tself.possible_simple_keys = {}\n\n\t# Public methods.\n\n\tdef check_token(self, *choices):\n\t\t# Check if the next token is one of the given types.\n\t\twhile self.need_more_tokens():\n\t\t\tself.fetch_more_tokens()\n\t\tif self.tokens:\n\t\t\tif not choices:\n\t\t\t\treturn True\n\t\t\tfor choice in choices:\n\t\t\t\tif isinstance(self.tokens[0], choice):\n\t\t\t\t\treturn True\n\t\treturn False\n\n\tdef peek_token(self):\n\t\t# Return the next token, but do not delete if from the queue.\n\t\t# Return None if no more tokens.\n\t\twhile self.need_more_tokens():\n\t\t\tself.fetch_more_tokens()\n\t\tif self.tokens:\n\t\t\treturn self.tokens[0]\n\t\telse:\n\t\t\treturn None\n\n\tdef get_token(self):\n\t\t# Return the next token.\n\t\twhile self.need_more_tokens():\n\t\t\tself.fetch_more_tokens()\n\t\tif self.tokens:\n\t\t\tself.tokens_taken += 1\n\t\t\treturn self.tokens.pop(0)\n\n\t# Private methods.\n\n\tdef need_more_tokens(self):\n\t\tif self.done:\n\t\t\treturn False\n\t\tif not self.tokens:\n\t\t\treturn True\n\t\t# The current token may be a potential simple key, so we\n\t\t# need to look further.\n\t\tself.stale_possible_simple_keys()\n\t\tif self.next_possible_simple_key() == self.tokens_taken:\n\t\t\treturn True\n\n\tdef fetch_more_tokens(self):\n\n\t\t# Eat whitespaces and comments until we reach the next token.\n\t\tself.scan_to_next_token()\n\n\t\t# Remove obsolete possible simple keys.\n\t\tself.stale_possible_simple_keys()\n\n\t\t# Compare the current indentation and column. It may add some tokens\n\t\t# and decrease the current indentation level.\n\t\tself.unwind_indent(self.column)\n\n\t\t# Peek the next character.\n\t\tch = self.peek()\n\n\t\t# Is it the end of stream?\n\t\tif ch == '\\0':\n\t\t\treturn self.fetch_stream_end()\n\n\t\t# Is it a directive?\n\t\tif ch == '%' and self.check_directive():\n\t\t\treturn self.fetch_directive()\n\n\t\t# Is it the document start?\n\t\tif ch == '-' and self.check_document_start():\n\t\t\treturn self.fetch_document_start()\n\n\t\t# Is it the document end?\n\t\tif ch == '.' and self.check_document_end():\n\t\t\treturn self.fetch_document_end()\n\n\t\t# TODO: support for BOM within a stream.\n\t\t#if ch == '\\uFEFF':\n\t\t#\treturn self.fetch_bom()\t<-- issue BOMToken\n\n\t\t# Note: the order of the following checks is NOT significant.\n\n\t\t# Is it the flow sequence start indicator?\n\t\tif ch == '[':\n\t\t\treturn self.fetch_flow_sequence_start()\n\n\t\t# Is it the flow mapping start indicator?\n\t\tif ch == '{':\n\t\t\treturn self.fetch_flow_mapping_start()\n\n\t\t# Is it the flow sequence end indicator?\n\t\tif ch == ']':\n\t\t\treturn self.fetch_flow_sequence_end()\n\n\t\t# Is it the flow mapping end indicator?\n\t\tif ch == '}':\n\t\t\treturn self.fetch_flow_mapping_end()\n\n\t\t# Is it the flow entry indicator?\n\t\tif ch == ',':\n\t\t\treturn self.fetch_flow_entry()\n\n\t\t# Is it the block entry indicator?\n\t\tif ch == '-' and self.check_block_entry():\n\t\t\treturn self.fetch_block_entry()\n\n\t\t# Is it the key indicator?\n\t\tif ch == '?' and self.check_key():\n\t\t\treturn self.fetch_key()\n\n\t\t# Is it the value indicator?\n\t\tif ch == ':' and self.check_value():\n\t\t\treturn self.fetch_value()\n\n\t\t# Is it an alias?\n\t\tif ch == '*':\n\t\t\treturn self.fetch_alias()\n\n\t\t# Is it an anchor?\n\t\tif ch == '&':\n\t\t\treturn self.fetch_anchor()\n\n\t\t# Is it a tag?\n\t\tif ch == '!':\n\t\t\treturn self.fetch_tag()\n\n\t\t# Is it a literal scalar?\n\t\tif ch == '|' and not self.flow_level:\n\t\t\treturn self.fetch_literal()\n\n\t\t# Is it a folded scalar?\n\t\tif ch == '>' and not self.flow_level:\n\t\t\treturn self.fetch_folded()\n\n\t\t# Is it a single quoted scalar?\n\t\tif ch == '\\'':\n\t\t\treturn self.fetch_single()\n\n\t\t# Is it a double quoted scalar?\n\t\tif ch == '\\\"':\n\t\t\treturn self.fetch_double()\n\n\t\t# It must be a plain scalar then.\n\t\tif self.check_plain():\n\t\t\treturn self.fetch_plain()\n\n\t\t# No? It's an error. Let's produce a nice error message.\n\t\traise ScannerError(\"while scanning for the next token\", None,\n\t\t\t\t\"found character %r that cannot start any token\" % ch,\n\t\t\t\tself.get_mark())\n\n\t# Simple keys treatment.\n\n\tdef next_possible_simple_key(self):\n\t\t# Return the number of the nearest possible simple key. Actually we\n\t\t# don't need to loop through the whole dictionary. We may replace it\n\t\t# with the following code:\n\t\t#   if not self.possible_simple_keys:\n\t\t#\t   return None\n\t\t#   return self.possible_simple_keys[\n\t\t#\t\t   min(self.possible_simple_keys.keys())].token_number\n\t\tmin_token_number = None\n\t\tfor level in self.possible_simple_keys:\n\t\t\tkey = self.possible_simple_keys[level]\n\t\t\tif min_token_number is None or key.token_number < min_token_number:\n\t\t\t\tmin_token_number = key.token_number\n\t\treturn min_token_number\n\n\tdef stale_possible_simple_keys(self):\n\t\t# Remove entries that are no longer possible simple keys. According to\n\t\t# the YAML specification, simple keys\n\t\t# - should be limited to a single line,\n\t\t# - should be no longer than 1024 characters.\n\t\t# Disabling this procedure will allow simple keys of any length and\n\t\t# height (may cause problems if indentation is broken though).\n\t\tfor level in list(self.possible_simple_keys):\n\t\t\tkey = self.possible_simple_keys[level]\n\t\t\tif key.line != self.line  \\\n\t\t\t\t\tor self.index-key.index > 1024:\n\t\t\t\tif key.required:\n\t\t\t\t\traise ScannerError(\"while scanning a simple key\", key.mark,\n\t\t\t\t\t\t\t\"could not find expected ':'\", self.get_mark())\n\t\t\t\tdel self.possible_simple_keys[level]\n\n\tdef save_possible_simple_key(self):\n\t\t# The next token may start a simple key. We check if it's possible\n\t\t# and save its position. This function is called for\n\t\t#   ALIAS, ANCHOR, TAG, SCALAR(flow), '[', and '{'.\n\n\t\t# Check if a simple key is required at the current position.\n\t\trequired = not self.flow_level and self.indent == self.column\n\n\t\t# The next token might be a simple key. Let's save it's number and\n\t\t# position.\n\t\tif self.allow_simple_key:\n\t\t\tself.remove_possible_simple_key()\n\t\t\ttoken_number = self.tokens_taken+len(self.tokens)\n\t\t\tkey = SimpleKey(token_number, required,\n\t\t\t\t\tself.index, self.line, self.column, self.get_mark())\n\t\t\tself.possible_simple_keys[self.flow_level] = key\n\n\tdef remove_possible_simple_key(self):\n\t\t# Remove the saved possible key position at the current flow level.\n\t\tif self.flow_level in self.possible_simple_keys:\n\t\t\tkey = self.possible_simple_keys[self.flow_level]\n\t\t\t\n\t\t\tif key.required:\n\t\t\t\traise ScannerError(\"while scanning a simple key\", key.mark,\n\t\t\t\t\t\t\"could not find expected ':'\", self.get_mark())\n\n\t\t\tdel self.possible_simple_keys[self.flow_level]\n\n\t# Indentation functions.\n\n\tdef unwind_indent(self, column):\n\n\t\t## In flow context, tokens should respect indentation.\n\t\t## Actually the condition should be `self.indent >= column` according to\n\t\t## the spec. But this condition will prohibit intuitively correct\n\t\t## constructions such as\n\t\t## key : {\n\t\t## }\n\t\t#if self.flow_level and self.indent > column:\n\t\t#\traise ScannerError(None, None,\n\t\t#\t\t\t\"invalid indentation or unclosed '[' or '{'\",\n\t\t#\t\t\tself.get_mark())\n\n\t\t# In the flow context, indentation is ignored. We make the scanner less\n\t\t# restrictive then specification requires.\n\t\tif self.flow_level:\n\t\t\treturn\n\n\t\t# In block context, we may need to issue the BLOCK-END tokens.\n\t\twhile self.indent > column:\n\t\t\tmark = self.get_mark()\n\t\t\tself.indent = self.indents.pop()\n\t\t\tself.tokens.append(BlockEndToken(mark, mark))\n\n\tdef add_indent(self, column):\n\t\t# Check if we need to increase indentation.\n\t\tif self.indent < column:\n\t\t\tself.indents.append(self.indent)\n\t\t\tself.indent = column\n\t\t\treturn True\n\t\treturn False\n\n\t# Fetchers.\n\n\tdef fetch_stream_start(self):\n\t\t# We always add STREAM-START as the first token and STREAM-END as the\n\t\t# last token.\n\n\t\t# Read the token.\n\t\tmark = self.get_mark()\n\t\t\n\t\t# Add STREAM-START.\n\t\tself.tokens.append(StreamStartToken(mark, mark,\n\t\t\tencoding=self.encoding))\n\t\t\n\n\tdef fetch_stream_end(self):\n\n\t\t# Set the current indentation to -1.\n\t\tself.unwind_indent(-1)\n\n\t\t# Reset simple keys.\n\t\tself.remove_possible_simple_key()\n\t\tself.allow_simple_key = False\n\t\tself.possible_simple_keys = {}\n\n\t\t# Read the token.\n\t\tmark = self.get_mark()\n\t\t\n\t\t# Add STREAM-END.\n\t\tself.tokens.append(StreamEndToken(mark, mark))\n\n\t\t# The steam is finished.\n\t\tself.done = True\n\n\tdef fetch_directive(self):\n\t\t\n\t\t# Set the current indentation to -1.\n\t\tself.unwind_indent(-1)\n\n\t\t# Reset simple keys.\n\t\tself.remove_possible_simple_key()\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add DIRECTIVE.\n\t\tself.tokens.append(self.scan_directive())\n\n\tdef fetch_document_start(self):\n\t\tself.fetch_document_indicator(DocumentStartToken)\n\n\tdef fetch_document_end(self):\n\t\tself.fetch_document_indicator(DocumentEndToken)\n\n\tdef fetch_document_indicator(self, TokenClass):\n\n\t\t# Set the current indentation to -1.\n\t\tself.unwind_indent(-1)\n\n\t\t# Reset simple keys. Note that there could not be a block collection\n\t\t# after '---'.\n\t\tself.remove_possible_simple_key()\n\t\tself.allow_simple_key = False\n\n\t\t# Add DOCUMENT-START or DOCUMENT-END.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward(3)\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(TokenClass(start_mark, end_mark))\n\n\tdef fetch_flow_sequence_start(self):\n\t\tself.fetch_flow_collection_start(FlowSequenceStartToken)\n\n\tdef fetch_flow_mapping_start(self):\n\t\tself.fetch_flow_collection_start(FlowMappingStartToken)\n\n\tdef fetch_flow_collection_start(self, TokenClass):\n\n\t\t# '[' and '{' may start a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# Increase the flow level.\n\t\tself.flow_level += 1\n\n\t\t# Simple keys are allowed after '[' and '{'.\n\t\tself.allow_simple_key = True\n\n\t\t# Add FLOW-SEQUENCE-START or FLOW-MAPPING-START.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(TokenClass(start_mark, end_mark))\n\n\tdef fetch_flow_sequence_end(self):\n\t\tself.fetch_flow_collection_end(FlowSequenceEndToken)\n\n\tdef fetch_flow_mapping_end(self):\n\t\tself.fetch_flow_collection_end(FlowMappingEndToken)\n\n\tdef fetch_flow_collection_end(self, TokenClass):\n\n\t\t# Reset possible simple key on the current level.\n\t\tself.remove_possible_simple_key()\n\n\t\t# Decrease the flow level.\n\t\tself.flow_level -= 1\n\n\t\t# No simple keys after ']' or '}'.\n\t\tself.allow_simple_key = False\n\n\t\t# Add FLOW-SEQUENCE-END or FLOW-MAPPING-END.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(TokenClass(start_mark, end_mark))\n\n\tdef fetch_flow_entry(self):\n\n\t\t# Simple keys are allowed after ','.\n\t\tself.allow_simple_key = True\n\n\t\t# Reset possible simple key on the current level.\n\t\tself.remove_possible_simple_key()\n\n\t\t# Add FLOW-ENTRY.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(FlowEntryToken(start_mark, end_mark))\n\n\tdef fetch_block_entry(self):\n\n\t\t# Block context needs additional checks.\n\t\tif not self.flow_level:\n\n\t\t\t# Are we allowed to start a new entry?\n\t\t\tif not self.allow_simple_key:\n\t\t\t\traise ScannerError(None, None,\n\t\t\t\t\t\t\"sequence entries are not allowed here\",\n\t\t\t\t\t\tself.get_mark())\n\n\t\t\t# We may need to add BLOCK-SEQUENCE-START.\n\t\t\tif self.add_indent(self.column):\n\t\t\t\tmark = self.get_mark()\n\t\t\t\tself.tokens.append(BlockSequenceStartToken(mark, mark))\n\n\t\t# It's an error for the block entry to occur in the flow context,\n\t\t# but we let the parser detect this.\n\t\telse:\n\t\t\tpass\n\n\t\t# Simple keys are allowed after '-'.\n\t\tself.allow_simple_key = True\n\n\t\t# Reset possible simple key on the current level.\n\t\tself.remove_possible_simple_key()\n\n\t\t# Add BLOCK-ENTRY.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(BlockEntryToken(start_mark, end_mark))\n\n\tdef fetch_key(self):\n\t\t\n\t\t# Block context needs additional checks.\n\t\tif not self.flow_level:\n\n\t\t\t# Are we allowed to start a key (not necessary a simple)?\n\t\t\tif not self.allow_simple_key:\n\t\t\t\traise ScannerError(None, None,\n\t\t\t\t\t\t\"mapping keys are not allowed here\",\n\t\t\t\t\t\tself.get_mark())\n\n\t\t\t# We may need to add BLOCK-MAPPING-START.\n\t\t\tif self.add_indent(self.column):\n\t\t\t\tmark = self.get_mark()\n\t\t\t\tself.tokens.append(BlockMappingStartToken(mark, mark))\n\n\t\t# Simple keys are allowed after '?' in the block context.\n\t\tself.allow_simple_key = not self.flow_level\n\n\t\t# Reset possible simple key on the current level.\n\t\tself.remove_possible_simple_key()\n\n\t\t# Add KEY.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(KeyToken(start_mark, end_mark))\n\n\tdef fetch_value(self):\n\n\t\t# Do we determine a simple key?\n\t\tif self.flow_level in self.possible_simple_keys:\n\n\t\t\t# Add KEY.\n\t\t\tkey = self.possible_simple_keys[self.flow_level]\n\t\t\tdel self.possible_simple_keys[self.flow_level]\n\t\t\tself.tokens.insert(key.token_number-self.tokens_taken,\n\t\t\t\t\tKeyToken(key.mark, key.mark))\n\n\t\t\t# If this key starts a new block mapping, we need to add\n\t\t\t# BLOCK-MAPPING-START.\n\t\t\tif not self.flow_level:\n\t\t\t\tif self.add_indent(key.column):\n\t\t\t\t\tself.tokens.insert(key.token_number-self.tokens_taken,\n\t\t\t\t\t\t\tBlockMappingStartToken(key.mark, key.mark))\n\n\t\t\t# There cannot be two simple keys one after another.\n\t\t\tself.allow_simple_key = False\n\n\t\t# It must be a part of a complex key.\n\t\telse:\n\t\t\t\n\t\t\t# Block context needs additional checks.\n\t\t\t# (Do we really need them? They will be caught by the parser\n\t\t\t# anyway.)\n\t\t\tif not self.flow_level:\n\n\t\t\t\t# We are allowed to start a complex value if and only if\n\t\t\t\t# we can start a simple key.\n\t\t\t\tif not self.allow_simple_key:\n\t\t\t\t\traise ScannerError(None, None,\n\t\t\t\t\t\t\t\"mapping values are not allowed here\",\n\t\t\t\t\t\t\tself.get_mark())\n\n\t\t\t# If this value starts a new block mapping, we need to add\n\t\t\t# BLOCK-MAPPING-START.  It will be detected as an error later by\n\t\t\t# the parser.\n\t\t\tif not self.flow_level:\n\t\t\t\tif self.add_indent(self.column):\n\t\t\t\t\tmark = self.get_mark()\n\t\t\t\t\tself.tokens.append(BlockMappingStartToken(mark, mark))\n\n\t\t\t# Simple keys are allowed after ':' in the block context.\n\t\t\tself.allow_simple_key = not self.flow_level\n\n\t\t\t# Reset possible simple key on the current level.\n\t\t\tself.remove_possible_simple_key()\n\n\t\t# Add VALUE.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(ValueToken(start_mark, end_mark))\n\n\tdef fetch_alias(self):\n\n\t\t# ALIAS could be a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# No simple keys after ALIAS.\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add ALIAS.\n\t\tself.tokens.append(self.scan_anchor(AliasToken))\n\n\tdef fetch_anchor(self):\n\n\t\t# ANCHOR could start a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# No simple keys after ANCHOR.\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add ANCHOR.\n\t\tself.tokens.append(self.scan_anchor(AnchorToken))\n\n\tdef fetch_tag(self):\n\n\t\t# TAG could start a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# No simple keys after TAG.\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add TAG.\n\t\tself.tokens.append(self.scan_tag())\n\n\tdef fetch_literal(self):\n\t\tself.fetch_block_scalar(style='|')\n\n\tdef fetch_folded(self):\n\t\tself.fetch_block_scalar(style='>')\n\n\tdef fetch_block_scalar(self, style):\n\n\t\t# A simple key may follow a block scalar.\n\t\tself.allow_simple_key = True\n\n\t\t# Reset possible simple key on the current level.\n\t\tself.remove_possible_simple_key()\n\n\t\t# Scan and add SCALAR.\n\t\tself.tokens.append(self.scan_block_scalar(style))\n\n\tdef fetch_single(self):\n\t\tself.fetch_flow_scalar(style='\\'')\n\n\tdef fetch_double(self):\n\t\tself.fetch_flow_scalar(style='\"')\n\n\tdef fetch_flow_scalar(self, style):\n\n\t\t# A flow scalar could be a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# No simple keys after flow scalars.\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add SCALAR.\n\t\tself.tokens.append(self.scan_flow_scalar(style))\n\n\tdef fetch_plain(self):\n\n\t\t# A plain scalar could be a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# No simple keys after plain scalars. But note that `scan_plain` will\n\t\t# change this flag if the scan is finished at the beginning of the\n\t\t# line.\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add SCALAR. May change `allow_simple_key`.\n\t\tself.tokens.append(self.scan_plain())\n\n\t# Checkers.\n\n\tdef check_directive(self):\n\n\t\t# DIRECTIVE:\t\t^ '%' ...\n\t\t# The '%' indicator is already checked.\n\t\tif self.column == 0:\n\t\t\treturn True\n\n\tdef check_document_start(self):\n\n\t\t# DOCUMENT-START:   ^ '---' (' '|'\\n')\n\t\tif self.column == 0:\n\t\t\tif self.prefix(3) == '---'  \\\n\t\t\t\t\tand self.peek(3) in '\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\treturn True\n\n\tdef check_document_end(self):\n\n\t\t# DOCUMENT-END:\t ^ '...' (' '|'\\n')\n\t\tif self.column == 0:\n\t\t\tif self.prefix(3) == '...'  \\\n\t\t\t\t\tand self.peek(3) in '\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\treturn True\n\n\tdef check_block_entry(self):\n\n\t\t# BLOCK-ENTRY:\t  '-' (' '|'\\n')\n\t\treturn self.peek(1) in '\\0 \\t\\r\\n\\x85\\u2028\\u2029'\n\n\tdef check_key(self):\n\n\t\t# KEY(flow context):\t'?'\n\t\tif self.flow_level:\n\t\t\treturn True\n\n\t\t# KEY(block context):   '?' (' '|'\\n')\n\t\telse:\n\t\t\treturn self.peek(1) in '\\0 \\t\\r\\n\\x85\\u2028\\u2029'\n\n\tdef check_value(self):\n\n\t\t# VALUE(flow context):  ':'\n\t\tif self.flow_level:\n\t\t\treturn True\n\n\t\t# VALUE(block context): ':' (' '|'\\n')\n\t\telse:\n\t\t\treturn self.peek(1) in '\\0 \\t\\r\\n\\x85\\u2028\\u2029'\n\n\tdef check_plain(self):\n\n\t\t# A plain scalar may start with any non-space character except:\n\t\t#   '-', '?', ':', ',', '[', ']', '{', '}',\n\t\t#   '#', '&', '*', '!', '|', '>', '\\'', '\\\"',\n\t\t#   '%', '@', '`'.\n\t\t#\n\t\t# It may also start with\n\t\t#   '-', '?', ':'\n\t\t# if it is followed by a non-space character.\n\t\t#\n\t\t# Note that we limit the last rule to the block context (except the\n\t\t# '-' character) because we want the flow context to be space\n\t\t# independent.\n\t\tch = self.peek()\n\t\treturn ch not in '\\0 \\t\\r\\n\\x85\\u2028\\u2029-?:,[]{}#&*!|>\\'\\\"%@`'  \\\n\t\t\t\tor (self.peek(1) not in '\\0 \\t\\r\\n\\x85\\u2028\\u2029'\n\t\t\t\t\t\tand (ch == '-' or (not self.flow_level and ch in '?:')))\n\n\t# Scanners.\n\n\tdef scan_to_next_token(self):\n\t\t# We ignore spaces, line breaks and comments.\n\t\t# If we find a line break in the block context, we set the flag\n\t\t# `allow_simple_key` on.\n\t\t# The byte order mark is stripped if it's the first character in the\n\t\t# stream. We do not yet support BOM inside the stream as the\n\t\t# specification requires. Any such mark will be considered as a part\n\t\t# of the document.\n\t\t#\n\t\t# TODO: We need to make tab handling rules more sane. A good rule is\n\t\t#   Tabs cannot precede tokens\n\t\t#   BLOCK-SEQUENCE-START, BLOCK-MAPPING-START, BLOCK-END,\n\t\t#   KEY(block), VALUE(block), BLOCK-ENTRY\n\t\t# So the checking code is\n\t\t#   if :\n\t\t#\t   self.allow_simple_keys = False\n\t\t# We also need to add the check for `allow_simple_keys == True` to\n\t\t# `unwind_indent` before issuing BLOCK-END.\n\t\t# Scanners for block, flow, and plain scalars need to be modified.\n\n\t\tif self.index == 0 and self.peek() == '\\uFEFF':\n\t\t\tself.forward()\n\t\tfound = False\n\t\twhile not found:\n\t\t\twhile self.peek() == ' ':\n\t\t\t\tself.forward()\n\t\t\tif self.peek() == '#':\n\t\t\t\twhile self.peek() not in '\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\t\tself.forward()\n\t\t\tif self.scan_line_break():\n\t\t\t\tif not self.flow_level:\n\t\t\t\t\tself.allow_simple_key = True\n\t\t\telse:\n\t\t\t\tfound = True\n\n\tdef scan_directive(self):\n\t\t# See the specification for details.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tname = self.scan_directive_name(start_mark)\n\t\tvalue = None\n\t\tif name == 'YAML':\n\t\t\tvalue = self.scan_yaml_directive_value(start_mark)\n\t\t\tend_mark = self.get_mark()\n\t\telif name == 'TAG':\n\t\t\tvalue = self.scan_tag_directive_value(start_mark)\n\t\t\tend_mark = self.get_mark()\n\t\telse:\n\t\t\tend_mark = self.get_mark()\n\t\t\twhile self.peek() not in '\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tself.forward()\n\t\tself.scan_directive_ignored_line(start_mark)\n\t\treturn DirectiveToken(name, value, start_mark, end_mark)\n\n\tdef scan_directive_name(self, start_mark):\n\t\t# See the specification for details.\n\t\tlength = 0\n\t\tch = self.peek(length)\n\t\twhile '0' <= ch <= '9' or 'A' <= ch <= 'Z' or 'a' <= ch <= 'z'  \\\n\t\t\t\tor ch in '-_':\n\t\t\tlength += 1\n\t\t\tch = self.peek(length)\n\t\tif not length:\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected alphabetic or numeric character, but found %r\"\n\t\t\t\t\t% ch, self.get_mark())\n\t\tvalue = self.prefix(length)\n\t\tself.forward(length)\n\t\tch = self.peek()\n\t\tif ch not in '\\0 \\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected alphabetic or numeric character, but found %r\"\n\t\t\t\t\t% ch, self.get_mark())\n\t\treturn value\n\n\tdef scan_yaml_directive_value(self, start_mark):\n\t\t# See the specification for details.\n\t\twhile self.peek() == ' ':\n\t\t\tself.forward()\n\t\tmajor = self.scan_yaml_directive_number(start_mark)\n\t\tif self.peek() != '.':\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected a digit or '.', but found %r\" % self.peek(),\n\t\t\t\t\tself.get_mark())\n\t\tself.forward()\n\t\tminor = self.scan_yaml_directive_number(start_mark)\n\t\tif self.peek() not in '\\0 \\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected a digit or ' ', but found %r\" % self.peek(),\n\t\t\t\t\tself.get_mark())\n\t\treturn (major, minor)\n\n\tdef scan_yaml_directive_number(self, start_mark):\n\t\t# See the specification for details.\n\t\tch = self.peek()\n\t\tif not ('0' <= ch <= '9'):\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected a digit, but found %r\" % ch, self.get_mark())\n\t\tlength = 0\n\t\twhile '0' <= self.peek(length) <= '9':\n\t\t\tlength += 1\n\t\tvalue = int(self.prefix(length))\n\t\tself.forward(length)\n\t\treturn value\n\n\tdef scan_tag_directive_value(self, start_mark):\n\t\t# See the specification for details.\n\t\twhile self.peek() == ' ':\n\t\t\tself.forward()\n\t\thandle = self.scan_tag_directive_handle(start_mark)\n\t\twhile self.peek() == ' ':\n\t\t\tself.forward()\n\t\tprefix = self.scan_tag_directive_prefix(start_mark)\n\t\treturn (handle, prefix)\n\n\tdef scan_tag_directive_handle(self, start_mark):\n\t\t# See the specification for details.\n\t\tvalue = self.scan_tag_handle('directive', start_mark)\n\t\tch = self.peek()\n\t\tif ch != ' ':\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected ' ', but found %r\" % ch, self.get_mark())\n\t\treturn value\n\n\tdef scan_tag_directive_prefix(self, start_mark):\n\t\t# See the specification for details.\n\t\tvalue = self.scan_tag_uri('directive', start_mark)\n\t\tch = self.peek()\n\t\tif ch not in '\\0 \\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected ' ', but found %r\" % ch, self.get_mark())\n\t\treturn value\n\n\tdef scan_directive_ignored_line(self, start_mark):\n\t\t# See the specification for details.\n\t\twhile self.peek() == ' ':\n\t\t\tself.forward()\n\t\tif self.peek() == '#':\n\t\t\twhile self.peek() not in '\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tself.forward()\n\t\tch = self.peek()\n\t\tif ch not in '\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected a comment or a line break, but found %r\"\n\t\t\t\t\t\t% ch, self.get_mark())\n\t\tself.scan_line_break()\n\n\tdef scan_anchor(self, TokenClass):\n\t\t# The specification does not restrict characters for anchors and\n\t\t# aliases. This may lead to problems, for instance, the document:\n\t\t#   [ *alias, value ]\n\t\t# can be interpreted in two ways, as\n\t\t#   [ \"value\" ]\n\t\t# and\n\t\t#   [ *alias , \"value\" ]\n\t\t# Therefore we restrict aliases to numbers and ASCII letters.\n\t\tstart_mark = self.get_mark()\n\t\tindicator = self.peek()\n\t\tif indicator == '*':\n\t\t\tname = 'alias'\n\t\telse:\n\t\t\tname = 'anchor'\n\t\tself.forward()\n\t\tlength = 0\n\t\tch = self.peek(length)\n\t\twhile '0' <= ch <= '9' or 'A' <= ch <= 'Z' or 'a' <= ch <= 'z'  \\\n\t\t\t\tor ch in '-_':\n\t\t\tlength += 1\n\t\t\tch = self.peek(length)\n\t\tif not length:\n\t\t\traise ScannerError(\"while scanning an %s\" % name, start_mark,\n\t\t\t\t\t\"expected alphabetic or numeric character, but found %r\"\n\t\t\t\t\t% ch, self.get_mark())\n\t\tvalue = self.prefix(length)\n\t\tself.forward(length)\n\t\tch = self.peek()\n\t\tif ch not in '\\0 \\t\\r\\n\\x85\\u2028\\u2029?:,]}%@`':\n\t\t\traise ScannerError(\"while scanning an %s\" % name, start_mark,\n\t\t\t\t\t\"expected alphabetic or numeric character, but found %r\"\n\t\t\t\t\t% ch, self.get_mark())\n\t\tend_mark = self.get_mark()\n\t\treturn TokenClass(value, start_mark, end_mark)\n\n\tdef scan_tag(self):\n\t\t# See the specification for details.\n\t\tstart_mark = self.get_mark()\n\t\tch = self.peek(1)\n\t\tif ch == '<':\n\t\t\thandle = None\n\t\t\tself.forward(2)\n\t\t\tsuffix = self.scan_tag_uri('tag', start_mark)\n\t\t\tif self.peek() != '>':\n\t\t\t\traise ScannerError(\"while parsing a tag\", start_mark,\n\t\t\t\t\t\t\"expected '>', but found %r\" % self.peek(),\n\t\t\t\t\t\tself.get_mark())\n\t\t\tself.forward()\n\t\telif ch in '\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\thandle = None\n\t\t\tsuffix = '!'\n\t\t\tself.forward()\n\t\telse:\n\t\t\tlength = 1\n\t\t\tuse_handle = False\n\t\t\twhile ch not in '\\0 \\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tif ch == '!':\n\t\t\t\t\tuse_handle = True\n\t\t\t\t\tbreak\n\t\t\t\tlength += 1\n\t\t\t\tch = self.peek(length)\n\t\t\thandle = '!'\n\t\t\tif use_handle:\n\t\t\t\thandle = self.scan_tag_handle('tag', start_mark)\n\t\t\telse:\n\t\t\t\thandle = '!'\n\t\t\t\tself.forward()\n\t\t\tsuffix = self.scan_tag_uri('tag', start_mark)\n\t\tch = self.peek()\n\t\tif ch not in '\\0 \\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a tag\", start_mark,\n\t\t\t\t\t\"expected ' ', but found %r\" % ch, self.get_mark())\n\t\tvalue = (handle, suffix)\n\t\tend_mark = self.get_mark()\n\t\treturn TagToken(value, start_mark, end_mark)\n\n\tdef scan_block_scalar(self, style):\n\t\t# See the specification for details.\n\n\t\tif style == '>':\n\t\t\tfolded = True\n\t\telse:\n\t\t\tfolded = False\n\n\t\tchunks = []\n\t\tstart_mark = self.get_mark()\n\n\t\t# Scan the header.\n\t\tself.forward()\n\t\tchomping, increment = self.scan_block_scalar_indicators(start_mark)\n\t\tself.scan_block_scalar_ignored_line(start_mark)\n\n\t\t# Determine the indentation level and go to the first non-empty line.\n\t\tmin_indent = self.indent+1\n\t\tif min_indent < 1:\n\t\t\tmin_indent = 1\n\t\tif increment is None:\n\t\t\tbreaks, max_indent, end_mark = self.scan_block_scalar_indentation()\n\t\t\tindent = max(min_indent, max_indent)\n\t\telse:\n\t\t\tindent = min_indent+increment-1\n\t\t\tbreaks, end_mark = self.scan_block_scalar_breaks(indent)\n\t\tline_break = ''\n\n\t\t# Scan the inner part of the block scalar.\n\t\twhile self.column == indent and self.peek() != '\\0':\n\t\t\tchunks.extend(breaks)\n\t\t\tleading_non_space = self.peek() not in ' \\t'\n\t\t\tlength = 0\n\t\t\twhile self.peek(length) not in '\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tlength += 1\n\t\t\tchunks.append(self.prefix(length))\n\t\t\tself.forward(length)\n\t\t\tline_break = self.scan_line_break()\n\t\t\tbreaks, end_mark = self.scan_block_scalar_breaks(indent)\n\t\t\tif self.column == indent and self.peek() != '\\0':\n\n\t\t\t\t# Unfortunately, folding rules are ambiguous.\n\t\t\t\t#\n\t\t\t\t# This is the folding according to the specification:\n\t\t\t\t\n\t\t\t\tif folded and line_break == '\\n'\t\\\n\t\t\t\t\t\tand leading_non_space and self.peek() not in ' \\t':\n\t\t\t\t\tif not breaks:\n\t\t\t\t\t\tchunks.append(' ')\n\t\t\t\telse:\n\t\t\t\t\tchunks.append(line_break)\n\t\t\t\t\n\t\t\t\t# This is Clark Evans's interpretation (also in the spec\n\t\t\t\t# examples):\n\t\t\t\t#\n\t\t\t\t#if folded and line_break == '\\n':\n\t\t\t\t#\tif not breaks:\n\t\t\t\t#\t\tif self.peek() not in ' \\t':\n\t\t\t\t#\t\t\tchunks.append(' ')\n\t\t\t\t#\t\telse:\n\t\t\t\t#\t\t\tchunks.append(line_break)\n\t\t\t\t#else:\n\t\t\t\t#\tchunks.append(line_break)\n\t\t\telse:\n\t\t\t\tbreak\n\n\t\t# Chomp the tail.\n\t\tif chomping is not False:\n\t\t\tchunks.append(line_break)\n\t\tif chomping is True:\n\t\t\tchunks.extend(breaks)\n\n\t\t# We are done.\n\t\treturn ScalarToken(''.join(chunks), False, start_mark, end_mark,\n\t\t\t\tstyle)\n\n\tdef scan_block_scalar_indicators(self, start_mark):\n\t\t# See the specification for details.\n\t\tchomping = None\n\t\tincrement = None\n\t\tch = self.peek()\n\t\tif ch in '+-':\n\t\t\tif ch == '+':\n\t\t\t\tchomping = True\n\t\t\telse:\n\t\t\t\tchomping = False\n\t\t\tself.forward()\n\t\t\tch = self.peek()\n\t\t\tif ch in '0123456789':\n\t\t\t\tincrement = int(ch)\n\t\t\t\tif increment == 0:\n\t\t\t\t\traise ScannerError(\"while scanning a block scalar\", start_mark,\n\t\t\t\t\t\t\t\"expected indentation indicator in the range 1-9, but found 0\",\n\t\t\t\t\t\t\tself.get_mark())\n\t\t\t\tself.forward()\n\t\telif ch in '0123456789':\n\t\t\tincrement = int(ch)\n\t\t\tif increment == 0:\n\t\t\t\traise ScannerError(\"while scanning a block scalar\", start_mark,\n\t\t\t\t\t\t\"expected indentation indicator in the range 1-9, but found 0\",\n\t\t\t\t\t\tself.get_mark())\n\t\t\tself.forward()\n\t\t\tch = self.peek()\n\t\t\tif ch in '+-':\n\t\t\t\tif ch == '+':\n\t\t\t\t\tchomping = True\n\t\t\t\telse:\n\t\t\t\t\tchomping = False\n\t\t\t\tself.forward()\n\t\tch = self.peek()\n\t\tif ch not in '\\0 \\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a block scalar\", start_mark,\n\t\t\t\t\t\"expected chomping or indentation indicators, but found %r\"\n\t\t\t\t\t% ch, self.get_mark())\n\t\treturn chomping, increment\n\n\tdef scan_block_scalar_ignored_line(self, start_mark):\n\t\t# See the specification for details.\n\t\twhile self.peek() == ' ':\n\t\t\tself.forward()\n\t\tif self.peek() == '#':\n\t\t\twhile self.peek() not in '\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tself.forward()\n\t\tch = self.peek()\n\t\tif ch not in '\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a block scalar\", start_mark,\n\t\t\t\t\t\"expected a comment or a line break, but found %r\" % ch,\n\t\t\t\t\tself.get_mark())\n\t\tself.scan_line_break()\n\n\tdef scan_block_scalar_indentation(self):\n\t\t# See the specification for details.\n\t\tchunks = []\n\t\tmax_indent = 0\n\t\tend_mark = self.get_mark()\n\t\twhile self.peek() in ' \\r\\n\\x85\\u2028\\u2029':\n\t\t\tif self.peek() != ' ':\n\t\t\t\tchunks.append(self.scan_line_break())\n\t\t\t\tend_mark = self.get_mark()\n\t\t\telse:\n\t\t\t\tself.forward()\n\t\t\t\tif self.column > max_indent:\n\t\t\t\t\tmax_indent = self.column\n\t\treturn chunks, max_indent, end_mark\n\n\tdef scan_block_scalar_breaks(self, indent):\n\t\t# See the specification for details.\n\t\tchunks = []\n\t\tend_mark = self.get_mark()\n\t\twhile self.column < indent and self.peek() == ' ':\n\t\t\tself.forward()\n\t\twhile self.peek() in '\\r\\n\\x85\\u2028\\u2029':\n\t\t\tchunks.append(self.scan_line_break())\n\t\t\tend_mark = self.get_mark()\n\t\t\twhile self.column < indent and self.peek() == ' ':\n\t\t\t\tself.forward()\n\t\treturn chunks, end_mark\n\n\tdef scan_flow_scalar(self, style):\n\t\t# See the specification for details.\n\t\t# Note that we loose indentation rules for quoted scalars. Quoted\n\t\t# scalars don't need to adhere indentation because \" and ' clearly\n\t\t# mark the beginning and the end of them. Therefore we are less\n\t\t# restrictive then the specification requires. We only need to check\n\t\t# that document separators are not included in scalars.\n\t\tif style == '\"':\n\t\t\tdouble = True\n\t\telse:\n\t\t\tdouble = False\n\t\tchunks = []\n\t\tstart_mark = self.get_mark()\n\t\tquote = self.peek()\n\t\tself.forward()\n\t\tchunks.extend(self.scan_flow_scalar_non_spaces(double, start_mark))\n\t\twhile self.peek() != quote:\n\t\t\tchunks.extend(self.scan_flow_scalar_spaces(double, start_mark))\n\t\t\tchunks.extend(self.scan_flow_scalar_non_spaces(double, start_mark))\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\treturn ScalarToken(''.join(chunks), False, start_mark, end_mark,\n\t\t\t\tstyle)\n\n\tESCAPE_REPLACEMENTS = {\n\t\t'0':\t'\\0',\n\t\t'a':\t'\\x07',\n\t\t'b':\t'\\x08',\n\t\t't':\t'\\x09',\n\t\t'\\t':   '\\x09',\n\t\t'n':\t'\\x0A',\n\t\t'v':\t'\\x0B',\n\t\t'f':\t'\\x0C',\n\t\t'r':\t'\\x0D',\n\t\t'e':\t'\\x1B',\n\t\t' ':\t'\\x20',\n\t\t'\\\"':   '\\\"',\n\t\t'\\\\':   '\\\\',\n\t\t'/':\t'/',\n\t\t'N':\t'\\x85',\n\t\t'_':\t'\\xA0',\n\t\t'L':\t'\\u2028',\n\t\t'P':\t'\\u2029',\n\t}\n\n\tESCAPE_CODES = {\n\t\t'x':\t2,\n\t\t'u':\t4,\n\t\t'U':\t8,\n\t}\n\n\tdef scan_flow_scalar_non_spaces(self, double, start_mark):\n\t\t# See the specification for details.\n\t\tchunks = []\n\t\twhile True:\n\t\t\tlength = 0\n\t\t\twhile self.peek(length) not in '\\'\\\"\\\\\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tlength += 1\n\t\t\tif length:\n\t\t\t\tchunks.append(self.prefix(length))\n\t\t\t\tself.forward(length)\n\t\t\tch = self.peek()\n\t\t\tif not double and ch == '\\'' and self.peek(1) == '\\'':\n\t\t\t\tchunks.append('\\'')\n\t\t\t\tself.forward(2)\n\t\t\telif (double and ch == '\\'') or (not double and ch in '\\\"\\\\'):\n\t\t\t\tchunks.append(ch)\n\t\t\t\tself.forward()\n\t\t\telif double and ch == '\\\\':\n\t\t\t\tself.forward()\n\t\t\t\tch = self.peek()\n\t\t\t\tif ch in self.ESCAPE_REPLACEMENTS:\n\t\t\t\t\tchunks.append(self.ESCAPE_REPLACEMENTS[ch])\n\t\t\t\t\tself.forward()\n\t\t\t\telif ch in self.ESCAPE_CODES:\n\t\t\t\t\tlength = self.ESCAPE_CODES[ch]\n\t\t\t\t\tself.forward()\n\t\t\t\t\tfor k in range(length):\n\t\t\t\t\t\tif self.peek(k) not in '0123456789ABCDEFabcdef':\n\t\t\t\t\t\t\traise ScannerError(\"while scanning a double-quoted scalar\", start_mark,\n\t\t\t\t\t\t\t\t\t\"expected escape sequence of %d hexdecimal numbers, but found %r\" %\n\t\t\t\t\t\t\t\t\t\t(length, self.peek(k)), self.get_mark())\n\t\t\t\t\tcode = int(self.prefix(length), 16)\n\t\t\t\t\tchunks.append(chr(code))\n\t\t\t\t\tself.forward(length)\n\t\t\t\telif ch in '\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\t\tself.scan_line_break()\n\t\t\t\t\tchunks.extend(self.scan_flow_scalar_breaks(double, start_mark))\n\t\t\t\telse:\n\t\t\t\t\traise ScannerError(\"while scanning a double-quoted scalar\", start_mark,\n\t\t\t\t\t\t\t\"found unknown escape character %r\" % ch, self.get_mark())\n\t\t\telse:\n\t\t\t\treturn chunks\n\n\tdef scan_flow_scalar_spaces(self, double, start_mark):\n\t\t# See the specification for details.\n\t\tchunks = []\n\t\tlength = 0\n\t\twhile self.peek(length) in ' \\t':\n\t\t\tlength += 1\n\t\twhitespaces = self.prefix(length)\n\t\tself.forward(length)\n\t\tch = self.peek()\n\t\tif ch == '\\0':\n\t\t\traise ScannerError(\"while scanning a quoted scalar\", start_mark,\n\t\t\t\t\t\"found unexpected end of stream\", self.get_mark())\n\t\telif ch in '\\r\\n\\x85\\u2028\\u2029':\n\t\t\tline_break = self.scan_line_break()\n\t\t\tbreaks = self.scan_flow_scalar_breaks(double, start_mark)\n\t\t\tif line_break != '\\n':\n\t\t\t\tchunks.append(line_break)\n\t\t\telif not breaks:\n\t\t\t\tchunks.append(' ')\n\t\t\tchunks.extend(breaks)\n\t\telse:\n\t\t\tchunks.append(whitespaces)\n\t\treturn chunks\n\n\tdef scan_flow_scalar_breaks(self, double, start_mark):\n\t\t# See the specification for details.\n\t\tchunks = []\n\t\twhile True:\n\t\t\t# Instead of checking indentation, we check for document\n\t\t\t# separators.\n\t\t\tprefix = self.prefix(3)\n\t\t\tif (prefix == '---' or prefix == '...')   \\\n\t\t\t\t\tand self.peek(3) in '\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\traise ScannerError(\"while scanning a quoted scalar\", start_mark,\n\t\t\t\t\t\t\"found unexpected document separator\", self.get_mark())\n\t\t\twhile self.peek() in ' \\t':\n\t\t\t\tself.forward()\n\t\t\tif self.peek() in '\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tchunks.append(self.scan_line_break())\n\t\t\telse:\n\t\t\t\treturn chunks\n\n\tdef scan_plain(self):\n\t\t# See the specification for details.\n\t\t# We add an additional restriction for the flow context:\n\t\t#   plain scalars in the flow context cannot contain ',' or '?'.\n\t\t# We also keep track of the `allow_simple_key` flag here.\n\t\t# Indentation rules are loosed for the flow context.\n\t\tchunks = []\n\t\tstart_mark = self.get_mark()\n\t\tend_mark = start_mark\n\t\tindent = self.indent+1\n\t\t# We allow zero indentation for scalars, but then we need to check for\n\t\t# document separators at the beginning of the line.\n\t\t#if indent == 0:\n\t\t#\tindent = 1\n\t\tspaces = []\n\t\twhile True:\n\t\t\tlength = 0\n\t\t\tif self.peek() == '#':\n\t\t\t\tbreak\n\t\t\twhile True:\n\t\t\t\tch = self.peek(length)\n\t\t\t\tif ch in '\\0 \\t\\r\\n\\x85\\u2028\\u2029'\t\\\n\t\t\t\t\t\tor (ch == ':' and\n\t\t\t\t\t\t\t\tself.peek(length+1) in '\\0 \\t\\r\\n\\x85\\u2028\\u2029'\n\t\t\t\t\t\t\t\t\t  + (u',[]{}' if self.flow_level else u''))\\\n\t\t\t\t\t\tor (self.flow_level and ch in ',?[]{}'):\n\t\t\t\t\tbreak\n\t\t\t\tlength += 1\n\t\t\tif length == 0:\n\t\t\t\tbreak\n\t\t\tself.allow_simple_key = False\n\t\t\tchunks.extend(spaces)\n\t\t\tchunks.append(self.prefix(length))\n\t\t\tself.forward(length)\n\t\t\tend_mark = self.get_mark()\n\t\t\tspaces = self.scan_plain_spaces(indent, start_mark)\n\t\t\tif not spaces or self.peek() == '#' \\\n\t\t\t\t\tor (not self.flow_level and self.column < indent):\n\t\t\t\tbreak\n\t\treturn ScalarToken(''.join(chunks), True, start_mark, end_mark)\n\n\tdef scan_plain_spaces(self, indent, start_mark):\n\t\t# See the specification for details.\n\t\t# The specification is really confusing about tabs in plain scalars.\n\t\t# We just forbid them completely. Do not use tabs in YAML!\n\t\tchunks = []\n\t\tlength = 0\n\t\twhile self.peek(length) in ' ':\n\t\t\tlength += 1\n\t\twhitespaces = self.prefix(length)\n\t\tself.forward(length)\n\t\tch = self.peek()\n\t\tif ch in '\\r\\n\\x85\\u2028\\u2029':\n\t\t\tline_break = self.scan_line_break()\n\t\t\tself.allow_simple_key = True\n\t\t\tprefix = self.prefix(3)\n\t\t\tif (prefix == '---' or prefix == '...')   \\\n\t\t\t\t\tand self.peek(3) in '\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\treturn\n\t\t\tbreaks = []\n\t\t\twhile self.peek() in ' \\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tif self.peek() == ' ':\n\t\t\t\t\tself.forward()\n\t\t\t\telse:\n\t\t\t\t\tbreaks.append(self.scan_line_break())\n\t\t\t\t\tprefix = self.prefix(3)\n\t\t\t\t\tif (prefix == '---' or prefix == '...')   \\\n\t\t\t\t\t\t\tand self.peek(3) in '\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\t\t\treturn\n\t\t\tif line_break != '\\n':\n\t\t\t\tchunks.append(line_break)\n\t\t\telif not breaks:\n\t\t\t\tchunks.append(' ')\n\t\t\tchunks.extend(breaks)\n\t\telif whitespaces:\n\t\t\tchunks.append(whitespaces)\n\t\treturn chunks\n\n\tdef scan_tag_handle(self, name, start_mark):\n\t\t# See the specification for details.\n\t\t# For some strange reasons, the specification does not allow '_' in\n\t\t# tag handles. I have allowed it anyway.\n\t\tch = self.peek()\n\t\tif ch != '!':\n\t\t\traise ScannerError(\"while scanning a %s\" % name, start_mark,\n\t\t\t\t\t\"expected '!', but found %r\" % ch, self.get_mark())\n\t\tlength = 1\n\t\tch = self.peek(length)\n\t\tif ch != ' ':\n\t\t\twhile '0' <= ch <= '9' or 'A' <= ch <= 'Z' or 'a' <= ch <= 'z'  \\\n\t\t\t\t\tor ch in '-_':\n\t\t\t\tlength += 1\n\t\t\t\tch = self.peek(length)\n\t\t\tif ch != '!':\n\t\t\t\tself.forward(length)\n\t\t\t\traise ScannerError(\"while scanning a %s\" % name, start_mark,\n\t\t\t\t\t\t\"expected '!', but found %r\" % ch, self.get_mark())\n\t\t\tlength += 1\n\t\tvalue = self.prefix(length)\n\t\tself.forward(length)\n\t\treturn value\n\n\tdef scan_tag_uri(self, name, start_mark):\n\t\t# See the specification for details.\n\t\t# Note: we do not check if URI is well-formed.\n\t\tchunks = []\n\t\tlength = 0\n\t\tch = self.peek(length)\n\t\twhile '0' <= ch <= '9' or 'A' <= ch <= 'Z' or 'a' <= ch <= 'z'  \\\n\t\t\t\tor ch in '-;/?:@&=+$,_.!~*\\'()[]%':\n\t\t\tif ch == '%':\n\t\t\t\tchunks.append(self.prefix(length))\n\t\t\t\tself.forward(length)\n\t\t\t\tlength = 0\n\t\t\t\tchunks.append(self.scan_uri_escapes(name, start_mark))\n\t\t\telse:\n\t\t\t\tlength += 1\n\t\t\tch = self.peek(length)\n\t\tif length:\n\t\t\tchunks.append(self.prefix(length))\n\t\t\tself.forward(length)\n\t\t\tlength = 0\n\t\tif not chunks:\n\t\t\traise ScannerError(\"while parsing a %s\" % name, start_mark,\n\t\t\t\t\t\"expected URI, but found %r\" % ch, self.get_mark())\n\t\treturn ''.join(chunks)\n\n\tdef scan_uri_escapes(self, name, start_mark):\n\t\t# See the specification for details.\n\t\tcodes = []\n\t\tmark = self.get_mark()\n\t\twhile self.peek() == '%':\n\t\t\tself.forward()\n\t\t\tfor k in range(2):\n\t\t\t\tif self.peek(k) not in '0123456789ABCDEFabcdef':\n\t\t\t\t\traise ScannerError(\"while scanning a %s\" % name, start_mark,\n\t\t\t\t\t\t\t\"expected URI escape sequence of 2 hexdecimal numbers, but found %r\"\n\t\t\t\t\t\t\t% self.peek(k), self.get_mark())\n\t\t\tcodes.append(int(self.prefix(2), 16))\n\t\t\tself.forward(2)\n\t\ttry:\n\t\t\tvalue = bytes(codes).decode('utf-8')\n\t\texcept UnicodeDecodeError as exc:\n\t\t\traise ScannerError(\"while scanning a %s\" % name, start_mark, str(exc), mark)\n\t\treturn value\n\n\tdef scan_line_break(self):\n\t\t# Transforms:\n\t\t#   '\\r\\n'\t  :   '\\n'\n\t\t#   '\\r'\t\t:   '\\n'\n\t\t#   '\\n'\t\t:   '\\n'\n\t\t#   '\\x85'\t  :   '\\n'\n\t\t#   '\\u2028'\t:   '\\u2028'\n\t\t#   '\\u2029\t :   '\\u2029'\n\t\t#   default\t :   ''\n\t\tch = self.peek()\n\t\tif ch in '\\r\\n\\x85':\n\t\t\tif self.prefix(2) == '\\r\\n':\n\t\t\t\tself.forward(2)\n\t\t\telse:\n\t\t\t\tself.forward()\n\t\t\treturn '\\n'\n\t\telif ch in '\\u2028\\u2029':\n\t\t\tself.forward()\n\t\t\treturn ch\n\t\treturn ''\n", "description": "Initialize the scanner.", "category": "simple", "imports": ["from .error import MarkedYAMLError", "from .tokens import *"]}], [{"term": "class", "name": "ScannerError", "data": "class ScannerError(MarkedYAMLError):\n\tpass\n", "description": null, "category": "simple", "imports": ["from .error import MarkedYAMLError", "from .tokens import *"]}, {"term": "class", "name": "classSimpleKey:", "data": "class SimpleKey:\n\t# See below simple keys treatment.\n\n\tdef __init__(self, token_number, required, index, line, column, mark):\n\t\tself.token_number = token_number\n\t\tself.required = required\n\t\tself.index = index\n\t\tself.line = line\n\t\tself.column = column\n\t\tself.mark = mark\n", "description": null, "category": "simple", "imports": ["from .error import MarkedYAMLError", "from .tokens import *"]}, {"term": "class", "name": "classScanner:", "data": "class Scanner:\n\n\tdef __init__(self):\n\t\t\"\"\"Initialize the scanner.\"\"\"\n\t\t# It is assumed that Scanner and Reader will have a common descendant.\n\t\t# Reader do the dirty work of checking for BOM and converting the\n\t\t# input data to Unicode. It also adds NUL to the end.\n\t\t#\n\t\t# Reader supports the following methods\n\t\t#   self.peek(i=0)\t   # peek the next i-th character\n\t\t#   self.prefix(l=1)\t # peek the next l characters\n\t\t#   self.forward(l=1)\t# read the next l characters and move the pointer.\n\n\t\t# Had we reached the end of the stream?\n\t\tself.done = False\n\n\t\t# The number of unclosed '{' and '['. `flow_level == 0` means block\n\t\t# context.\n\t\tself.flow_level = 0\n\n\t\t# List of processed tokens that are not yet emitted.\n\t\tself.tokens = []\n\n\t\t# Add the STREAM-START token.\n\t\tself.fetch_stream_start()\n\n\t\t# Number of tokens that were emitted through the `get_token` method.\n\t\tself.tokens_taken = 0\n\n\t\t# The current indentation level.\n\t\tself.indent = -1\n\n\t\t# Past indentation levels.\n\t\tself.indents = []\n\n\t\t# Variables related to simple keys treatment.\n\n\t\t# A simple key is a key that is not denoted by the '?' indicator.\n\t\t# Example of simple keys:\n\t\t#   ---\n\t\t#   block simple key: value\n\t\t#   ? not a simple key:\n\t\t#   : { flow simple key: value }\n\t\t# We emit the KEY token before all keys, so when we find a potential\n\t\t# simple key, we try to locate the corresponding ':' indicator.\n\t\t# Simple keys should be limited to a single line and 1024 characters.\n\n\t\t# Can a simple key start at the current position? A simple key may\n\t\t# start:\n\t\t# - at the beginning of the line, not counting indentation spaces\n\t\t#\t   (in block context),\n\t\t# - after '{', '[', ',' (in the flow context),\n\t\t# - after '?', ':', '-' (in the block context).\n\t\t# In the block context, this flag also signifies if a block collection\n\t\t# may start at the current position.\n\t\tself.allow_simple_key = True\n\n\t\t# Keep track of possible simple keys. This is a dictionary. The key\n\t\t# is `flow_level`; there can be no more that one possible simple key\n\t\t# for each level. The value is a SimpleKey record:\n\t\t#   (token_number, required, index, line, column, mark)\n\t\t# A simple key may start with ALIAS, ANCHOR, TAG, SCALAR(flow),\n\t\t# '[', or '{' tokens.\n\t\tself.possible_simple_keys = {}\n\n\t# Public methods.\n\n\tdef check_token(self, *choices):\n\t\t# Check if the next token is one of the given types.\n\t\twhile self.need_more_tokens():\n\t\t\tself.fetch_more_tokens()\n\t\tif self.tokens:\n\t\t\tif not choices:\n\t\t\t\treturn True\n\t\t\tfor choice in choices:\n\t\t\t\tif isinstance(self.tokens[0], choice):\n\t\t\t\t\treturn True\n\t\treturn False\n\n\tdef peek_token(self):\n\t\t# Return the next token, but do not delete if from the queue.\n\t\t# Return None if no more tokens.\n\t\twhile self.need_more_tokens():\n\t\t\tself.fetch_more_tokens()\n\t\tif self.tokens:\n\t\t\treturn self.tokens[0]\n\t\telse:\n\t\t\treturn None\n\n\tdef get_token(self):\n\t\t# Return the next token.\n\t\twhile self.need_more_tokens():\n\t\t\tself.fetch_more_tokens()\n\t\tif self.tokens:\n\t\t\tself.tokens_taken += 1\n\t\t\treturn self.tokens.pop(0)\n\n\t# Private methods.\n\n\tdef need_more_tokens(self):\n\t\tif self.done:\n\t\t\treturn False\n\t\tif not self.tokens:\n\t\t\treturn True\n\t\t# The current token may be a potential simple key, so we\n\t\t# need to look further.\n\t\tself.stale_possible_simple_keys()\n\t\tif self.next_possible_simple_key() == self.tokens_taken:\n\t\t\treturn True\n\n\tdef fetch_more_tokens(self):\n\n\t\t# Eat whitespaces and comments until we reach the next token.\n\t\tself.scan_to_next_token()\n\n\t\t# Remove obsolete possible simple keys.\n\t\tself.stale_possible_simple_keys()\n\n\t\t# Compare the current indentation and column. It may add some tokens\n\t\t# and decrease the current indentation level.\n\t\tself.unwind_indent(self.column)\n\n\t\t# Peek the next character.\n\t\tch = self.peek()\n\n\t\t# Is it the end of stream?\n\t\tif ch == '\\0':\n\t\t\treturn self.fetch_stream_end()\n\n\t\t# Is it a directive?\n\t\tif ch == '%' and self.check_directive():\n\t\t\treturn self.fetch_directive()\n\n\t\t# Is it the document start?\n\t\tif ch == '-' and self.check_document_start():\n\t\t\treturn self.fetch_document_start()\n\n\t\t# Is it the document end?\n\t\tif ch == '.' and self.check_document_end():\n\t\t\treturn self.fetch_document_end()\n\n\t\t# TODO: support for BOM within a stream.\n\t\t#if ch == '\\uFEFF':\n\t\t#\treturn self.fetch_bom()\t<-- issue BOMToken\n\n\t\t# Note: the order of the following checks is NOT significant.\n\n\t\t# Is it the flow sequence start indicator?\n\t\tif ch == '[':\n\t\t\treturn self.fetch_flow_sequence_start()\n\n\t\t# Is it the flow mapping start indicator?\n\t\tif ch == '{':\n\t\t\treturn self.fetch_flow_mapping_start()\n\n\t\t# Is it the flow sequence end indicator?\n\t\tif ch == ']':\n\t\t\treturn self.fetch_flow_sequence_end()\n\n\t\t# Is it the flow mapping end indicator?\n\t\tif ch == '}':\n\t\t\treturn self.fetch_flow_mapping_end()\n\n\t\t# Is it the flow entry indicator?\n\t\tif ch == ',':\n\t\t\treturn self.fetch_flow_entry()\n\n\t\t# Is it the block entry indicator?\n\t\tif ch == '-' and self.check_block_entry():\n\t\t\treturn self.fetch_block_entry()\n\n\t\t# Is it the key indicator?\n\t\tif ch == '?' and self.check_key():\n\t\t\treturn self.fetch_key()\n\n\t\t# Is it the value indicator?\n\t\tif ch == ':' and self.check_value():\n\t\t\treturn self.fetch_value()\n\n\t\t# Is it an alias?\n\t\tif ch == '*':\n\t\t\treturn self.fetch_alias()\n\n\t\t# Is it an anchor?\n\t\tif ch == '&':\n\t\t\treturn self.fetch_anchor()\n\n\t\t# Is it a tag?\n\t\tif ch == '!':\n\t\t\treturn self.fetch_tag()\n\n\t\t# Is it a literal scalar?\n\t\tif ch == '|' and not self.flow_level:\n\t\t\treturn self.fetch_literal()\n\n\t\t# Is it a folded scalar?\n\t\tif ch == '>' and not self.flow_level:\n\t\t\treturn self.fetch_folded()\n\n\t\t# Is it a single quoted scalar?\n\t\tif ch == '\\'':\n\t\t\treturn self.fetch_single()\n\n\t\t# Is it a double quoted scalar?\n\t\tif ch == '\\\"':\n\t\t\treturn self.fetch_double()\n\n\t\t# It must be a plain scalar then.\n\t\tif self.check_plain():\n\t\t\treturn self.fetch_plain()\n\n\t\t# No? It's an error. Let's produce a nice error message.\n\t\traise ScannerError(\"while scanning for the next token\", None,\n\t\t\t\t\"found character %r that cannot start any token\" % ch,\n\t\t\t\tself.get_mark())\n\n\t# Simple keys treatment.\n\n\tdef next_possible_simple_key(self):\n\t\t# Return the number of the nearest possible simple key. Actually we\n\t\t# don't need to loop through the whole dictionary. We may replace it\n\t\t# with the following code:\n\t\t#   if not self.possible_simple_keys:\n\t\t#\t   return None\n\t\t#   return self.possible_simple_keys[\n\t\t#\t\t   min(self.possible_simple_keys.keys())].token_number\n\t\tmin_token_number = None\n\t\tfor level in self.possible_simple_keys:\n\t\t\tkey = self.possible_simple_keys[level]\n\t\t\tif min_token_number is None or key.token_number < min_token_number:\n\t\t\t\tmin_token_number = key.token_number\n\t\treturn min_token_number\n\n\tdef stale_possible_simple_keys(self):\n\t\t# Remove entries that are no longer possible simple keys. According to\n\t\t# the YAML specification, simple keys\n\t\t# - should be limited to a single line,\n\t\t# - should be no longer than 1024 characters.\n\t\t# Disabling this procedure will allow simple keys of any length and\n\t\t# height (may cause problems if indentation is broken though).\n\t\tfor level in list(self.possible_simple_keys):\n\t\t\tkey = self.possible_simple_keys[level]\n\t\t\tif key.line != self.line  \\\n\t\t\t\t\tor self.index-key.index > 1024:\n\t\t\t\tif key.required:\n\t\t\t\t\traise ScannerError(\"while scanning a simple key\", key.mark,\n\t\t\t\t\t\t\t\"could not find expected ':'\", self.get_mark())\n\t\t\t\tdel self.possible_simple_keys[level]\n\n\tdef save_possible_simple_key(self):\n\t\t# The next token may start a simple key. We check if it's possible\n\t\t# and save its position. This function is called for\n\t\t#   ALIAS, ANCHOR, TAG, SCALAR(flow), '[', and '{'.\n\n\t\t# Check if a simple key is required at the current position.\n\t\trequired = not self.flow_level and self.indent == self.column\n\n\t\t# The next token might be a simple key. Let's save it's number and\n\t\t# position.\n\t\tif self.allow_simple_key:\n\t\t\tself.remove_possible_simple_key()\n\t\t\ttoken_number = self.tokens_taken+len(self.tokens)\n\t\t\tkey = SimpleKey(token_number, required,\n\t\t\t\t\tself.index, self.line, self.column, self.get_mark())\n\t\t\tself.possible_simple_keys[self.flow_level] = key\n\n\tdef remove_possible_simple_key(self):\n\t\t# Remove the saved possible key position at the current flow level.\n\t\tif self.flow_level in self.possible_simple_keys:\n\t\t\tkey = self.possible_simple_keys[self.flow_level]\n\t\t\t\n\t\t\tif key.required:\n\t\t\t\traise ScannerError(\"while scanning a simple key\", key.mark,\n\t\t\t\t\t\t\"could not find expected ':'\", self.get_mark())\n\n\t\t\tdel self.possible_simple_keys[self.flow_level]\n\n\t# Indentation functions.\n\n\tdef unwind_indent(self, column):\n\n\t\t## In flow context, tokens should respect indentation.\n\t\t## Actually the condition should be `self.indent >= column` according to\n\t\t## the spec. But this condition will prohibit intuitively correct\n\t\t## constructions such as\n\t\t## key : {\n\t\t## }\n\t\t#if self.flow_level and self.indent > column:\n\t\t#\traise ScannerError(None, None,\n\t\t#\t\t\t\"invalid indentation or unclosed '[' or '{'\",\n\t\t#\t\t\tself.get_mark())\n\n\t\t# In the flow context, indentation is ignored. We make the scanner less\n\t\t# restrictive then specification requires.\n\t\tif self.flow_level:\n\t\t\treturn\n\n\t\t# In block context, we may need to issue the BLOCK-END tokens.\n\t\twhile self.indent > column:\n\t\t\tmark = self.get_mark()\n\t\t\tself.indent = self.indents.pop()\n\t\t\tself.tokens.append(BlockEndToken(mark, mark))\n\n\tdef add_indent(self, column):\n\t\t# Check if we need to increase indentation.\n\t\tif self.indent < column:\n\t\t\tself.indents.append(self.indent)\n\t\t\tself.indent = column\n\t\t\treturn True\n\t\treturn False\n\n\t# Fetchers.\n\n\tdef fetch_stream_start(self):\n\t\t# We always add STREAM-START as the first token and STREAM-END as the\n\t\t# last token.\n\n\t\t# Read the token.\n\t\tmark = self.get_mark()\n\t\t\n\t\t# Add STREAM-START.\n\t\tself.tokens.append(StreamStartToken(mark, mark,\n\t\t\tencoding=self.encoding))\n\t\t\n\n\tdef fetch_stream_end(self):\n\n\t\t# Set the current indentation to -1.\n\t\tself.unwind_indent(-1)\n\n\t\t# Reset simple keys.\n\t\tself.remove_possible_simple_key()\n\t\tself.allow_simple_key = False\n\t\tself.possible_simple_keys = {}\n\n\t\t# Read the token.\n\t\tmark = self.get_mark()\n\t\t\n\t\t# Add STREAM-END.\n\t\tself.tokens.append(StreamEndToken(mark, mark))\n\n\t\t# The steam is finished.\n\t\tself.done = True\n\n\tdef fetch_directive(self):\n\t\t\n\t\t# Set the current indentation to -1.\n\t\tself.unwind_indent(-1)\n\n\t\t# Reset simple keys.\n\t\tself.remove_possible_simple_key()\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add DIRECTIVE.\n\t\tself.tokens.append(self.scan_directive())\n\n\tdef fetch_document_start(self):\n\t\tself.fetch_document_indicator(DocumentStartToken)\n\n\tdef fetch_document_end(self):\n\t\tself.fetch_document_indicator(DocumentEndToken)\n\n\tdef fetch_document_indicator(self, TokenClass):\n\n\t\t# Set the current indentation to -1.\n\t\tself.unwind_indent(-1)\n\n\t\t# Reset simple keys. Note that there could not be a block collection\n\t\t# after '---'.\n\t\tself.remove_possible_simple_key()\n\t\tself.allow_simple_key = False\n\n\t\t# Add DOCUMENT-START or DOCUMENT-END.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward(3)\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(TokenClass(start_mark, end_mark))\n\n\tdef fetch_flow_sequence_start(self):\n\t\tself.fetch_flow_collection_start(FlowSequenceStartToken)\n\n\tdef fetch_flow_mapping_start(self):\n\t\tself.fetch_flow_collection_start(FlowMappingStartToken)\n\n\tdef fetch_flow_collection_start(self, TokenClass):\n\n\t\t# '[' and '{' may start a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# Increase the flow level.\n\t\tself.flow_level += 1\n\n\t\t# Simple keys are allowed after '[' and '{'.\n\t\tself.allow_simple_key = True\n\n\t\t# Add FLOW-SEQUENCE-START or FLOW-MAPPING-START.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(TokenClass(start_mark, end_mark))\n\n\tdef fetch_flow_sequence_end(self):\n\t\tself.fetch_flow_collection_end(FlowSequenceEndToken)\n\n\tdef fetch_flow_mapping_end(self):\n\t\tself.fetch_flow_collection_end(FlowMappingEndToken)\n\n\tdef fetch_flow_collection_end(self, TokenClass):\n\n\t\t# Reset possible simple key on the current level.\n\t\tself.remove_possible_simple_key()\n\n\t\t# Decrease the flow level.\n\t\tself.flow_level -= 1\n\n\t\t# No simple keys after ']' or '}'.\n\t\tself.allow_simple_key = False\n\n\t\t# Add FLOW-SEQUENCE-END or FLOW-MAPPING-END.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(TokenClass(start_mark, end_mark))\n\n\tdef fetch_flow_entry(self):\n\n\t\t# Simple keys are allowed after ','.\n\t\tself.allow_simple_key = True\n\n\t\t# Reset possible simple key on the current level.\n\t\tself.remove_possible_simple_key()\n\n\t\t# Add FLOW-ENTRY.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(FlowEntryToken(start_mark, end_mark))\n\n\tdef fetch_block_entry(self):\n\n\t\t# Block context needs additional checks.\n\t\tif not self.flow_level:\n\n\t\t\t# Are we allowed to start a new entry?\n\t\t\tif not self.allow_simple_key:\n\t\t\t\traise ScannerError(None, None,\n\t\t\t\t\t\t\"sequence entries are not allowed here\",\n\t\t\t\t\t\tself.get_mark())\n\n\t\t\t# We may need to add BLOCK-SEQUENCE-START.\n\t\t\tif self.add_indent(self.column):\n\t\t\t\tmark = self.get_mark()\n\t\t\t\tself.tokens.append(BlockSequenceStartToken(mark, mark))\n\n\t\t# It's an error for the block entry to occur in the flow context,\n\t\t# but we let the parser detect this.\n\t\telse:\n\t\t\tpass\n\n\t\t# Simple keys are allowed after '-'.\n\t\tself.allow_simple_key = True\n\n\t\t# Reset possible simple key on the current level.\n\t\tself.remove_possible_simple_key()\n\n\t\t# Add BLOCK-ENTRY.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(BlockEntryToken(start_mark, end_mark))\n\n\tdef fetch_key(self):\n\t\t\n\t\t# Block context needs additional checks.\n\t\tif not self.flow_level:\n\n\t\t\t# Are we allowed to start a key (not necessary a simple)?\n\t\t\tif not self.allow_simple_key:\n\t\t\t\traise ScannerError(None, None,\n\t\t\t\t\t\t\"mapping keys are not allowed here\",\n\t\t\t\t\t\tself.get_mark())\n\n\t\t\t# We may need to add BLOCK-MAPPING-START.\n\t\t\tif self.add_indent(self.column):\n\t\t\t\tmark = self.get_mark()\n\t\t\t\tself.tokens.append(BlockMappingStartToken(mark, mark))\n\n\t\t# Simple keys are allowed after '?' in the block context.\n\t\tself.allow_simple_key = not self.flow_level\n\n\t\t# Reset possible simple key on the current level.\n\t\tself.remove_possible_simple_key()\n\n\t\t# Add KEY.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(KeyToken(start_mark, end_mark))\n\n\tdef fetch_value(self):\n\n\t\t# Do we determine a simple key?\n\t\tif self.flow_level in self.possible_simple_keys:\n\n\t\t\t# Add KEY.\n\t\t\tkey = self.possible_simple_keys[self.flow_level]\n\t\t\tdel self.possible_simple_keys[self.flow_level]\n\t\t\tself.tokens.insert(key.token_number-self.tokens_taken,\n\t\t\t\t\tKeyToken(key.mark, key.mark))\n\n\t\t\t# If this key starts a new block mapping, we need to add\n\t\t\t# BLOCK-MAPPING-START.\n\t\t\tif not self.flow_level:\n\t\t\t\tif self.add_indent(key.column):\n\t\t\t\t\tself.tokens.insert(key.token_number-self.tokens_taken,\n\t\t\t\t\t\t\tBlockMappingStartToken(key.mark, key.mark))\n\n\t\t\t# There cannot be two simple keys one after another.\n\t\t\tself.allow_simple_key = False\n\n\t\t# It must be a part of a complex key.\n\t\telse:\n\t\t\t\n\t\t\t# Block context needs additional checks.\n\t\t\t# (Do we really need them? They will be caught by the parser\n\t\t\t# anyway.)\n\t\t\tif not self.flow_level:\n\n\t\t\t\t# We are allowed to start a complex value if and only if\n\t\t\t\t# we can start a simple key.\n\t\t\t\tif not self.allow_simple_key:\n\t\t\t\t\traise ScannerError(None, None,\n\t\t\t\t\t\t\t\"mapping values are not allowed here\",\n\t\t\t\t\t\t\tself.get_mark())\n\n\t\t\t# If this value starts a new block mapping, we need to add\n\t\t\t# BLOCK-MAPPING-START.  It will be detected as an error later by\n\t\t\t# the parser.\n\t\t\tif not self.flow_level:\n\t\t\t\tif self.add_indent(self.column):\n\t\t\t\t\tmark = self.get_mark()\n\t\t\t\t\tself.tokens.append(BlockMappingStartToken(mark, mark))\n\n\t\t\t# Simple keys are allowed after ':' in the block context.\n\t\t\tself.allow_simple_key = not self.flow_level\n\n\t\t\t# Reset possible simple key on the current level.\n\t\t\tself.remove_possible_simple_key()\n\n\t\t# Add VALUE.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(ValueToken(start_mark, end_mark))\n\n\tdef fetch_alias(self):\n\n\t\t# ALIAS could be a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# No simple keys after ALIAS.\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add ALIAS.\n\t\tself.tokens.append(self.scan_anchor(AliasToken))\n\n\tdef fetch_anchor(self):\n\n\t\t# ANCHOR could start a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# No simple keys after ANCHOR.\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add ANCHOR.\n\t\tself.tokens.append(self.scan_anchor(AnchorToken))\n\n\tdef fetch_tag(self):\n\n\t\t# TAG could start a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# No simple keys after TAG.\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add TAG.\n\t\tself.tokens.append(self.scan_tag())\n\n\tdef fetch_literal(self):\n\t\tself.fetch_block_scalar(style='|')\n\n\tdef fetch_folded(self):\n\t\tself.fetch_block_scalar(style='>')\n\n\tdef fetch_block_scalar(self, style):\n\n\t\t# A simple key may follow a block scalar.\n\t\tself.allow_simple_key = True\n\n\t\t# Reset possible simple key on the current level.\n\t\tself.remove_possible_simple_key()\n\n\t\t# Scan and add SCALAR.\n\t\tself.tokens.append(self.scan_block_scalar(style))\n\n\tdef fetch_single(self):\n\t\tself.fetch_flow_scalar(style='\\'')\n\n\tdef fetch_double(self):\n\t\tself.fetch_flow_scalar(style='\"')\n\n\tdef fetch_flow_scalar(self, style):\n\n\t\t# A flow scalar could be a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# No simple keys after flow scalars.\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add SCALAR.\n\t\tself.tokens.append(self.scan_flow_scalar(style))\n\n\tdef fetch_plain(self):\n\n\t\t# A plain scalar could be a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# No simple keys after plain scalars. But note that `scan_plain` will\n\t\t# change this flag if the scan is finished at the beginning of the\n\t\t# line.\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add SCALAR. May change `allow_simple_key`.\n\t\tself.tokens.append(self.scan_plain())\n\n\t# Checkers.\n\n\tdef check_directive(self):\n\n\t\t# DIRECTIVE:\t\t^ '%' ...\n\t\t# The '%' indicator is already checked.\n\t\tif self.column == 0:\n\t\t\treturn True\n\n\tdef check_document_start(self):\n\n\t\t# DOCUMENT-START:   ^ '---' (' '|'\\n')\n\t\tif self.column == 0:\n\t\t\tif self.prefix(3) == '---'  \\\n\t\t\t\t\tand self.peek(3) in '\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\treturn True\n\n\tdef check_document_end(self):\n\n\t\t# DOCUMENT-END:\t ^ '...' (' '|'\\n')\n\t\tif self.column == 0:\n\t\t\tif self.prefix(3) == '...'  \\\n\t\t\t\t\tand self.peek(3) in '\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\treturn True\n\n\tdef check_block_entry(self):\n\n\t\t# BLOCK-ENTRY:\t  '-' (' '|'\\n')\n\t\treturn self.peek(1) in '\\0 \\t\\r\\n\\x85\\u2028\\u2029'\n\n\tdef check_key(self):\n\n\t\t# KEY(flow context):\t'?'\n\t\tif self.flow_level:\n\t\t\treturn True\n\n\t\t# KEY(block context):   '?' (' '|'\\n')\n\t\telse:\n\t\t\treturn self.peek(1) in '\\0 \\t\\r\\n\\x85\\u2028\\u2029'\n\n\tdef check_value(self):\n\n\t\t# VALUE(flow context):  ':'\n\t\tif self.flow_level:\n\t\t\treturn True\n\n\t\t# VALUE(block context): ':' (' '|'\\n')\n\t\telse:\n\t\t\treturn self.peek(1) in '\\0 \\t\\r\\n\\x85\\u2028\\u2029'\n\n\tdef check_plain(self):\n\n\t\t# A plain scalar may start with any non-space character except:\n\t\t#   '-', '?', ':', ',', '[', ']', '{', '}',\n\t\t#   '#', '&', '*', '!', '|', '>', '\\'', '\\\"',\n\t\t#   '%', '@', '`'.\n\t\t#\n\t\t# It may also start with\n\t\t#   '-', '?', ':'\n\t\t# if it is followed by a non-space character.\n\t\t#\n\t\t# Note that we limit the last rule to the block context (except the\n\t\t# '-' character) because we want the flow context to be space\n\t\t# independent.\n\t\tch = self.peek()\n\t\treturn ch not in '\\0 \\t\\r\\n\\x85\\u2028\\u2029-?:,[]{}#&*!|>\\'\\\"%@`'  \\\n\t\t\t\tor (self.peek(1) not in '\\0 \\t\\r\\n\\x85\\u2028\\u2029'\n\t\t\t\t\t\tand (ch == '-' or (not self.flow_level and ch in '?:')))\n\n\t# Scanners.\n\n\tdef scan_to_next_token(self):\n\t\t# We ignore spaces, line breaks and comments.\n\t\t# If we find a line break in the block context, we set the flag\n\t\t# `allow_simple_key` on.\n\t\t# The byte order mark is stripped if it's the first character in the\n\t\t# stream. We do not yet support BOM inside the stream as the\n\t\t# specification requires. Any such mark will be considered as a part\n\t\t# of the document.\n\t\t#\n\t\t# TODO: We need to make tab handling rules more sane. A good rule is\n\t\t#   Tabs cannot precede tokens\n\t\t#   BLOCK-SEQUENCE-START, BLOCK-MAPPING-START, BLOCK-END,\n\t\t#   KEY(block), VALUE(block), BLOCK-ENTRY\n\t\t# So the checking code is\n\t\t#   if :\n\t\t#\t   self.allow_simple_keys = False\n\t\t# We also need to add the check for `allow_simple_keys == True` to\n\t\t# `unwind_indent` before issuing BLOCK-END.\n\t\t# Scanners for block, flow, and plain scalars need to be modified.\n\n\t\tif self.index == 0 and self.peek() == '\\uFEFF':\n\t\t\tself.forward()\n\t\tfound = False\n\t\twhile not found:\n\t\t\twhile self.peek() == ' ':\n\t\t\t\tself.forward()\n\t\t\tif self.peek() == '#':\n\t\t\t\twhile self.peek() not in '\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\t\tself.forward()\n\t\t\tif self.scan_line_break():\n\t\t\t\tif not self.flow_level:\n\t\t\t\t\tself.allow_simple_key = True\n\t\t\telse:\n\t\t\t\tfound = True\n\n\tdef scan_directive(self):\n\t\t# See the specification for details.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tname = self.scan_directive_name(start_mark)\n\t\tvalue = None\n\t\tif name == 'YAML':\n\t\t\tvalue = self.scan_yaml_directive_value(start_mark)\n\t\t\tend_mark = self.get_mark()\n\t\telif name == 'TAG':\n\t\t\tvalue = self.scan_tag_directive_value(start_mark)\n\t\t\tend_mark = self.get_mark()\n\t\telse:\n\t\t\tend_mark = self.get_mark()\n\t\t\twhile self.peek() not in '\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tself.forward()\n\t\tself.scan_directive_ignored_line(start_mark)\n\t\treturn DirectiveToken(name, value, start_mark, end_mark)\n\n\tdef scan_directive_name(self, start_mark):\n\t\t# See the specification for details.\n\t\tlength = 0\n\t\tch = self.peek(length)\n\t\twhile '0' <= ch <= '9' or 'A' <= ch <= 'Z' or 'a' <= ch <= 'z'  \\\n\t\t\t\tor ch in '-_':\n\t\t\tlength += 1\n\t\t\tch = self.peek(length)\n\t\tif not length:\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected alphabetic or numeric character, but found %r\"\n\t\t\t\t\t% ch, self.get_mark())\n\t\tvalue = self.prefix(length)\n\t\tself.forward(length)\n\t\tch = self.peek()\n\t\tif ch not in '\\0 \\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected alphabetic or numeric character, but found %r\"\n\t\t\t\t\t% ch, self.get_mark())\n\t\treturn value\n\n\tdef scan_yaml_directive_value(self, start_mark):\n\t\t# See the specification for details.\n\t\twhile self.peek() == ' ':\n\t\t\tself.forward()\n\t\tmajor = self.scan_yaml_directive_number(start_mark)\n\t\tif self.peek() != '.':\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected a digit or '.', but found %r\" % self.peek(),\n\t\t\t\t\tself.get_mark())\n\t\tself.forward()\n\t\tminor = self.scan_yaml_directive_number(start_mark)\n\t\tif self.peek() not in '\\0 \\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected a digit or ' ', but found %r\" % self.peek(),\n\t\t\t\t\tself.get_mark())\n\t\treturn (major, minor)\n\n\tdef scan_yaml_directive_number(self, start_mark):\n\t\t# See the specification for details.\n\t\tch = self.peek()\n\t\tif not ('0' <= ch <= '9'):\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected a digit, but found %r\" % ch, self.get_mark())\n\t\tlength = 0\n\t\twhile '0' <= self.peek(length) <= '9':\n\t\t\tlength += 1\n\t\tvalue = int(self.prefix(length))\n\t\tself.forward(length)\n\t\treturn value\n\n\tdef scan_tag_directive_value(self, start_mark):\n\t\t# See the specification for details.\n\t\twhile self.peek() == ' ':\n\t\t\tself.forward()\n\t\thandle = self.scan_tag_directive_handle(start_mark)\n\t\twhile self.peek() == ' ':\n\t\t\tself.forward()\n\t\tprefix = self.scan_tag_directive_prefix(start_mark)\n\t\treturn (handle, prefix)\n\n\tdef scan_tag_directive_handle(self, start_mark):\n\t\t# See the specification for details.\n\t\tvalue = self.scan_tag_handle('directive', start_mark)\n\t\tch = self.peek()\n\t\tif ch != ' ':\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected ' ', but found %r\" % ch, self.get_mark())\n\t\treturn value\n\n\tdef scan_tag_directive_prefix(self, start_mark):\n\t\t# See the specification for details.\n\t\tvalue = self.scan_tag_uri('directive', start_mark)\n\t\tch = self.peek()\n\t\tif ch not in '\\0 \\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected ' ', but found %r\" % ch, self.get_mark())\n\t\treturn value\n\n\tdef scan_directive_ignored_line(self, start_mark):\n\t\t# See the specification for details.\n\t\twhile self.peek() == ' ':\n\t\t\tself.forward()\n\t\tif self.peek() == '#':\n\t\t\twhile self.peek() not in '\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tself.forward()\n\t\tch = self.peek()\n\t\tif ch not in '\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a directive\", start_mark,\n\t\t\t\t\t\"expected a comment or a line break, but found %r\"\n\t\t\t\t\t\t% ch, self.get_mark())\n\t\tself.scan_line_break()\n\n\tdef scan_anchor(self, TokenClass):\n\t\t# The specification does not restrict characters for anchors and\n\t\t# aliases. This may lead to problems, for instance, the document:\n\t\t#   [ *alias, value ]\n\t\t# can be interpreted in two ways, as\n\t\t#   [ \"value\" ]\n\t\t# and\n\t\t#   [ *alias , \"value\" ]\n\t\t# Therefore we restrict aliases to numbers and ASCII letters.\n\t\tstart_mark = self.get_mark()\n\t\tindicator = self.peek()\n\t\tif indicator == '*':\n\t\t\tname = 'alias'\n\t\telse:\n\t\t\tname = 'anchor'\n\t\tself.forward()\n\t\tlength = 0\n\t\tch = self.peek(length)\n\t\twhile '0' <= ch <= '9' or 'A' <= ch <= 'Z' or 'a' <= ch <= 'z'  \\\n\t\t\t\tor ch in '-_':\n\t\t\tlength += 1\n\t\t\tch = self.peek(length)\n\t\tif not length:\n\t\t\traise ScannerError(\"while scanning an %s\" % name, start_mark,\n\t\t\t\t\t\"expected alphabetic or numeric character, but found %r\"\n\t\t\t\t\t% ch, self.get_mark())\n\t\tvalue = self.prefix(length)\n\t\tself.forward(length)\n\t\tch = self.peek()\n\t\tif ch not in '\\0 \\t\\r\\n\\x85\\u2028\\u2029?:,]}%@`':\n\t\t\traise ScannerError(\"while scanning an %s\" % name, start_mark,\n\t\t\t\t\t\"expected alphabetic or numeric character, but found %r\"\n\t\t\t\t\t% ch, self.get_mark())\n\t\tend_mark = self.get_mark()\n\t\treturn TokenClass(value, start_mark, end_mark)\n\n\tdef scan_tag(self):\n\t\t# See the specification for details.\n\t\tstart_mark = self.get_mark()\n\t\tch = self.peek(1)\n\t\tif ch == '<':\n\t\t\thandle = None\n\t\t\tself.forward(2)\n\t\t\tsuffix = self.scan_tag_uri('tag', start_mark)\n\t\t\tif self.peek() != '>':\n\t\t\t\traise ScannerError(\"while parsing a tag\", start_mark,\n\t\t\t\t\t\t\"expected '>', but found %r\" % self.peek(),\n\t\t\t\t\t\tself.get_mark())\n\t\t\tself.forward()\n\t\telif ch in '\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\thandle = None\n\t\t\tsuffix = '!'\n\t\t\tself.forward()\n\t\telse:\n\t\t\tlength = 1\n\t\t\tuse_handle = False\n\t\t\twhile ch not in '\\0 \\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tif ch == '!':\n\t\t\t\t\tuse_handle = True\n\t\t\t\t\tbreak\n\t\t\t\tlength += 1\n\t\t\t\tch = self.peek(length)\n\t\t\thandle = '!'\n\t\t\tif use_handle:\n\t\t\t\thandle = self.scan_tag_handle('tag', start_mark)\n\t\t\telse:\n\t\t\t\thandle = '!'\n\t\t\t\tself.forward()\n\t\t\tsuffix = self.scan_tag_uri('tag', start_mark)\n\t\tch = self.peek()\n\t\tif ch not in '\\0 \\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a tag\", start_mark,\n\t\t\t\t\t\"expected ' ', but found %r\" % ch, self.get_mark())\n\t\tvalue = (handle, suffix)\n\t\tend_mark = self.get_mark()\n\t\treturn TagToken(value, start_mark, end_mark)\n\n\tdef scan_block_scalar(self, style):\n\t\t# See the specification for details.\n\n\t\tif style == '>':\n\t\t\tfolded = True\n\t\telse:\n\t\t\tfolded = False\n\n\t\tchunks = []\n\t\tstart_mark = self.get_mark()\n\n\t\t# Scan the header.\n\t\tself.forward()\n\t\tchomping, increment = self.scan_block_scalar_indicators(start_mark)\n\t\tself.scan_block_scalar_ignored_line(start_mark)\n\n\t\t# Determine the indentation level and go to the first non-empty line.\n\t\tmin_indent = self.indent+1\n\t\tif min_indent < 1:\n\t\t\tmin_indent = 1\n\t\tif increment is None:\n\t\t\tbreaks, max_indent, end_mark = self.scan_block_scalar_indentation()\n\t\t\tindent = max(min_indent, max_indent)\n\t\telse:\n\t\t\tindent = min_indent+increment-1\n\t\t\tbreaks, end_mark = self.scan_block_scalar_breaks(indent)\n\t\tline_break = ''\n\n\t\t# Scan the inner part of the block scalar.\n\t\twhile self.column == indent and self.peek() != '\\0':\n\t\t\tchunks.extend(breaks)\n\t\t\tleading_non_space = self.peek() not in ' \\t'\n\t\t\tlength = 0\n\t\t\twhile self.peek(length) not in '\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tlength += 1\n\t\t\tchunks.append(self.prefix(length))\n\t\t\tself.forward(length)\n\t\t\tline_break = self.scan_line_break()\n\t\t\tbreaks, end_mark = self.scan_block_scalar_breaks(indent)\n\t\t\tif self.column == indent and self.peek() != '\\0':\n\n\t\t\t\t# Unfortunately, folding rules are ambiguous.\n\t\t\t\t#\n\t\t\t\t# This is the folding according to the specification:\n\t\t\t\t\n\t\t\t\tif folded and line_break == '\\n'\t\\\n\t\t\t\t\t\tand leading_non_space and self.peek() not in ' \\t':\n\t\t\t\t\tif not breaks:\n\t\t\t\t\t\tchunks.append(' ')\n\t\t\t\telse:\n\t\t\t\t\tchunks.append(line_break)\n\t\t\t\t\n\t\t\t\t# This is Clark Evans's interpretation (also in the spec\n\t\t\t\t# examples):\n\t\t\t\t#\n\t\t\t\t#if folded and line_break == '\\n':\n\t\t\t\t#\tif not breaks:\n\t\t\t\t#\t\tif self.peek() not in ' \\t':\n\t\t\t\t#\t\t\tchunks.append(' ')\n\t\t\t\t#\t\telse:\n\t\t\t\t#\t\t\tchunks.append(line_break)\n\t\t\t\t#else:\n\t\t\t\t#\tchunks.append(line_break)\n\t\t\telse:\n\t\t\t\tbreak\n\n\t\t# Chomp the tail.\n\t\tif chomping is not False:\n\t\t\tchunks.append(line_break)\n\t\tif chomping is True:\n\t\t\tchunks.extend(breaks)\n\n\t\t# We are done.\n\t\treturn ScalarToken(''.join(chunks), False, start_mark, end_mark,\n\t\t\t\tstyle)\n\n\tdef scan_block_scalar_indicators(self, start_mark):\n\t\t# See the specification for details.\n\t\tchomping = None\n\t\tincrement = None\n\t\tch = self.peek()\n\t\tif ch in '+-':\n\t\t\tif ch == '+':\n\t\t\t\tchomping = True\n\t\t\telse:\n\t\t\t\tchomping = False\n\t\t\tself.forward()\n\t\t\tch = self.peek()\n\t\t\tif ch in '0123456789':\n\t\t\t\tincrement = int(ch)\n\t\t\t\tif increment == 0:\n\t\t\t\t\traise ScannerError(\"while scanning a block scalar\", start_mark,\n\t\t\t\t\t\t\t\"expected indentation indicator in the range 1-9, but found 0\",\n\t\t\t\t\t\t\tself.get_mark())\n\t\t\t\tself.forward()\n\t\telif ch in '0123456789':\n\t\t\tincrement = int(ch)\n\t\t\tif increment == 0:\n\t\t\t\traise ScannerError(\"while scanning a block scalar\", start_mark,\n\t\t\t\t\t\t\"expected indentation indicator in the range 1-9, but found 0\",\n\t\t\t\t\t\tself.get_mark())\n\t\t\tself.forward()\n\t\t\tch = self.peek()\n\t\t\tif ch in '+-':\n\t\t\t\tif ch == '+':\n\t\t\t\t\tchomping = True\n\t\t\t\telse:\n\t\t\t\t\tchomping = False\n\t\t\t\tself.forward()\n\t\tch = self.peek()\n\t\tif ch not in '\\0 \\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a block scalar\", start_mark,\n\t\t\t\t\t\"expected chomping or indentation indicators, but found %r\"\n\t\t\t\t\t% ch, self.get_mark())\n\t\treturn chomping, increment\n\n\tdef scan_block_scalar_ignored_line(self, start_mark):\n\t\t# See the specification for details.\n\t\twhile self.peek() == ' ':\n\t\t\tself.forward()\n\t\tif self.peek() == '#':\n\t\t\twhile self.peek() not in '\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tself.forward()\n\t\tch = self.peek()\n\t\tif ch not in '\\0\\r\\n\\x85\\u2028\\u2029':\n\t\t\traise ScannerError(\"while scanning a block scalar\", start_mark,\n\t\t\t\t\t\"expected a comment or a line break, but found %r\" % ch,\n\t\t\t\t\tself.get_mark())\n\t\tself.scan_line_break()\n\n\tdef scan_block_scalar_indentation(self):\n\t\t# See the specification for details.\n\t\tchunks = []\n\t\tmax_indent = 0\n\t\tend_mark = self.get_mark()\n\t\twhile self.peek() in ' \\r\\n\\x85\\u2028\\u2029':\n\t\t\tif self.peek() != ' ':\n\t\t\t\tchunks.append(self.scan_line_break())\n\t\t\t\tend_mark = self.get_mark()\n\t\t\telse:\n\t\t\t\tself.forward()\n\t\t\t\tif self.column > max_indent:\n\t\t\t\t\tmax_indent = self.column\n\t\treturn chunks, max_indent, end_mark\n\n\tdef scan_block_scalar_breaks(self, indent):\n\t\t# See the specification for details.\n\t\tchunks = []\n\t\tend_mark = self.get_mark()\n\t\twhile self.column < indent and self.peek() == ' ':\n\t\t\tself.forward()\n\t\twhile self.peek() in '\\r\\n\\x85\\u2028\\u2029':\n\t\t\tchunks.append(self.scan_line_break())\n\t\t\tend_mark = self.get_mark()\n\t\t\twhile self.column < indent and self.peek() == ' ':\n\t\t\t\tself.forward()\n\t\treturn chunks, end_mark\n\n\tdef scan_flow_scalar(self, style):\n\t\t# See the specification for details.\n\t\t# Note that we loose indentation rules for quoted scalars. Quoted\n\t\t# scalars don't need to adhere indentation because \" and ' clearly\n\t\t# mark the beginning and the end of them. Therefore we are less\n\t\t# restrictive then the specification requires. We only need to check\n\t\t# that document separators are not included in scalars.\n\t\tif style == '\"':\n\t\t\tdouble = True\n\t\telse:\n\t\t\tdouble = False\n\t\tchunks = []\n\t\tstart_mark = self.get_mark()\n\t\tquote = self.peek()\n\t\tself.forward()\n\t\tchunks.extend(self.scan_flow_scalar_non_spaces(double, start_mark))\n\t\twhile self.peek() != quote:\n\t\t\tchunks.extend(self.scan_flow_scalar_spaces(double, start_mark))\n\t\t\tchunks.extend(self.scan_flow_scalar_non_spaces(double, start_mark))\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\treturn ScalarToken(''.join(chunks), False, start_mark, end_mark,\n\t\t\t\tstyle)\n\n\tESCAPE_REPLACEMENTS = {\n\t\t'0':\t'\\0',\n\t\t'a':\t'\\x07',\n\t\t'b':\t'\\x08',\n\t\t't':\t'\\x09',\n\t\t'\\t':   '\\x09',\n\t\t'n':\t'\\x0A',\n\t\t'v':\t'\\x0B',\n\t\t'f':\t'\\x0C',\n\t\t'r':\t'\\x0D',\n\t\t'e':\t'\\x1B',\n\t\t' ':\t'\\x20',\n\t\t'\\\"':   '\\\"',\n\t\t'\\\\':   '\\\\',\n\t\t'/':\t'/',\n\t\t'N':\t'\\x85',\n\t\t'_':\t'\\xA0',\n\t\t'L':\t'\\u2028',\n\t\t'P':\t'\\u2029',\n\t}\n\n\tESCAPE_CODES = {\n\t\t'x':\t2,\n\t\t'u':\t4,\n\t\t'U':\t8,\n\t}\n\n\tdef scan_flow_scalar_non_spaces(self, double, start_mark):\n\t\t# See the specification for details.\n\t\tchunks = []\n\t\twhile True:\n\t\t\tlength = 0\n\t\t\twhile self.peek(length) not in '\\'\\\"\\\\\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tlength += 1\n\t\t\tif length:\n\t\t\t\tchunks.append(self.prefix(length))\n\t\t\t\tself.forward(length)\n\t\t\tch = self.peek()\n\t\t\tif not double and ch == '\\'' and self.peek(1) == '\\'':\n\t\t\t\tchunks.append('\\'')\n\t\t\t\tself.forward(2)\n\t\t\telif (double and ch == '\\'') or (not double and ch in '\\\"\\\\'):\n\t\t\t\tchunks.append(ch)\n\t\t\t\tself.forward()\n\t\t\telif double and ch == '\\\\':\n\t\t\t\tself.forward()\n\t\t\t\tch = self.peek()\n\t\t\t\tif ch in self.ESCAPE_REPLACEMENTS:\n\t\t\t\t\tchunks.append(self.ESCAPE_REPLACEMENTS[ch])\n\t\t\t\t\tself.forward()\n\t\t\t\telif ch in self.ESCAPE_CODES:\n\t\t\t\t\tlength = self.ESCAPE_CODES[ch]\n\t\t\t\t\tself.forward()\n\t\t\t\t\tfor k in range(length):\n\t\t\t\t\t\tif self.peek(k) not in '0123456789ABCDEFabcdef':\n\t\t\t\t\t\t\traise ScannerError(\"while scanning a double-quoted scalar\", start_mark,\n\t\t\t\t\t\t\t\t\t\"expected escape sequence of %d hexdecimal numbers, but found %r\" %\n\t\t\t\t\t\t\t\t\t\t(length, self.peek(k)), self.get_mark())\n\t\t\t\t\tcode = int(self.prefix(length), 16)\n\t\t\t\t\tchunks.append(chr(code))\n\t\t\t\t\tself.forward(length)\n\t\t\t\telif ch in '\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\t\tself.scan_line_break()\n\t\t\t\t\tchunks.extend(self.scan_flow_scalar_breaks(double, start_mark))\n\t\t\t\telse:\n\t\t\t\t\traise ScannerError(\"while scanning a double-quoted scalar\", start_mark,\n\t\t\t\t\t\t\t\"found unknown escape character %r\" % ch, self.get_mark())\n\t\t\telse:\n\t\t\t\treturn chunks\n\n\tdef scan_flow_scalar_spaces(self, double, start_mark):\n\t\t# See the specification for details.\n\t\tchunks = []\n\t\tlength = 0\n\t\twhile self.peek(length) in ' \\t':\n\t\t\tlength += 1\n\t\twhitespaces = self.prefix(length)\n\t\tself.forward(length)\n\t\tch = self.peek()\n\t\tif ch == '\\0':\n\t\t\traise ScannerError(\"while scanning a quoted scalar\", start_mark,\n\t\t\t\t\t\"found unexpected end of stream\", self.get_mark())\n\t\telif ch in '\\r\\n\\x85\\u2028\\u2029':\n\t\t\tline_break = self.scan_line_break()\n\t\t\tbreaks = self.scan_flow_scalar_breaks(double, start_mark)\n\t\t\tif line_break != '\\n':\n\t\t\t\tchunks.append(line_break)\n\t\t\telif not breaks:\n\t\t\t\tchunks.append(' ')\n\t\t\tchunks.extend(breaks)\n\t\telse:\n\t\t\tchunks.append(whitespaces)\n\t\treturn chunks\n\n\tdef scan_flow_scalar_breaks(self, double, start_mark):\n\t\t# See the specification for details.\n\t\tchunks = []\n\t\twhile True:\n\t\t\t# Instead of checking indentation, we check for document\n\t\t\t# separators.\n\t\t\tprefix = self.prefix(3)\n\t\t\tif (prefix == '---' or prefix == '...')   \\\n\t\t\t\t\tand self.peek(3) in '\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\traise ScannerError(\"while scanning a quoted scalar\", start_mark,\n\t\t\t\t\t\t\"found unexpected document separator\", self.get_mark())\n\t\t\twhile self.peek() in ' \\t':\n\t\t\t\tself.forward()\n\t\t\tif self.peek() in '\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tchunks.append(self.scan_line_break())\n\t\t\telse:\n\t\t\t\treturn chunks\n\n\tdef scan_plain(self):\n\t\t# See the specification for details.\n\t\t# We add an additional restriction for the flow context:\n\t\t#   plain scalars in the flow context cannot contain ',' or '?'.\n\t\t# We also keep track of the `allow_simple_key` flag here.\n\t\t# Indentation rules are loosed for the flow context.\n\t\tchunks = []\n\t\tstart_mark = self.get_mark()\n\t\tend_mark = start_mark\n\t\tindent = self.indent+1\n\t\t# We allow zero indentation for scalars, but then we need to check for\n\t\t# document separators at the beginning of the line.\n\t\t#if indent == 0:\n\t\t#\tindent = 1\n\t\tspaces = []\n\t\twhile True:\n\t\t\tlength = 0\n\t\t\tif self.peek() == '#':\n\t\t\t\tbreak\n\t\t\twhile True:\n\t\t\t\tch = self.peek(length)\n\t\t\t\tif ch in '\\0 \\t\\r\\n\\x85\\u2028\\u2029'\t\\\n\t\t\t\t\t\tor (ch == ':' and\n\t\t\t\t\t\t\t\tself.peek(length+1) in '\\0 \\t\\r\\n\\x85\\u2028\\u2029'\n\t\t\t\t\t\t\t\t\t  + (u',[]{}' if self.flow_level else u''))\\\n\t\t\t\t\t\tor (self.flow_level and ch in ',?[]{}'):\n\t\t\t\t\tbreak\n\t\t\t\tlength += 1\n\t\t\tif length == 0:\n\t\t\t\tbreak\n\t\t\tself.allow_simple_key = False\n\t\t\tchunks.extend(spaces)\n\t\t\tchunks.append(self.prefix(length))\n\t\t\tself.forward(length)\n\t\t\tend_mark = self.get_mark()\n\t\t\tspaces = self.scan_plain_spaces(indent, start_mark)\n\t\t\tif not spaces or self.peek() == '#' \\\n\t\t\t\t\tor (not self.flow_level and self.column < indent):\n\t\t\t\tbreak\n\t\treturn ScalarToken(''.join(chunks), True, start_mark, end_mark)\n\n\tdef scan_plain_spaces(self, indent, start_mark):\n\t\t# See the specification for details.\n\t\t# The specification is really confusing about tabs in plain scalars.\n\t\t# We just forbid them completely. Do not use tabs in YAML!\n\t\tchunks = []\n\t\tlength = 0\n\t\twhile self.peek(length) in ' ':\n\t\t\tlength += 1\n\t\twhitespaces = self.prefix(length)\n\t\tself.forward(length)\n\t\tch = self.peek()\n\t\tif ch in '\\r\\n\\x85\\u2028\\u2029':\n\t\t\tline_break = self.scan_line_break()\n\t\t\tself.allow_simple_key = True\n\t\t\tprefix = self.prefix(3)\n\t\t\tif (prefix == '---' or prefix == '...')   \\\n\t\t\t\t\tand self.peek(3) in '\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\treturn\n\t\t\tbreaks = []\n\t\t\twhile self.peek() in ' \\r\\n\\x85\\u2028\\u2029':\n\t\t\t\tif self.peek() == ' ':\n\t\t\t\t\tself.forward()\n\t\t\t\telse:\n\t\t\t\t\tbreaks.append(self.scan_line_break())\n\t\t\t\t\tprefix = self.prefix(3)\n\t\t\t\t\tif (prefix == '---' or prefix == '...')   \\\n\t\t\t\t\t\t\tand self.peek(3) in '\\0 \\t\\r\\n\\x85\\u2028\\u2029':\n\t\t\t\t\t\treturn\n\t\t\tif line_break != '\\n':\n\t\t\t\tchunks.append(line_break)\n\t\t\telif not breaks:\n\t\t\t\tchunks.append(' ')\n\t\t\tchunks.extend(breaks)\n\t\telif whitespaces:\n\t\t\tchunks.append(whitespaces)\n\t\treturn chunks\n\n\tdef scan_tag_handle(self, name, start_mark):\n\t\t# See the specification for details.\n\t\t# For some strange reasons, the specification does not allow '_' in\n\t\t# tag handles. I have allowed it anyway.\n\t\tch = self.peek()\n\t\tif ch != '!':\n\t\t\traise ScannerError(\"while scanning a %s\" % name, start_mark,\n\t\t\t\t\t\"expected '!', but found %r\" % ch, self.get_mark())\n\t\tlength = 1\n\t\tch = self.peek(length)\n\t\tif ch != ' ':\n\t\t\twhile '0' <= ch <= '9' or 'A' <= ch <= 'Z' or 'a' <= ch <= 'z'  \\\n\t\t\t\t\tor ch in '-_':\n\t\t\t\tlength += 1\n\t\t\t\tch = self.peek(length)\n\t\t\tif ch != '!':\n\t\t\t\tself.forward(length)\n\t\t\t\traise ScannerError(\"while scanning a %s\" % name, start_mark,\n\t\t\t\t\t\t\"expected '!', but found %r\" % ch, self.get_mark())\n\t\t\tlength += 1\n\t\tvalue = self.prefix(length)\n\t\tself.forward(length)\n\t\treturn value\n\n\tdef scan_tag_uri(self, name, start_mark):\n\t\t# See the specification for details.\n\t\t# Note: we do not check if URI is well-formed.\n\t\tchunks = []\n\t\tlength = 0\n\t\tch = self.peek(length)\n\t\twhile '0' <= ch <= '9' or 'A' <= ch <= 'Z' or 'a' <= ch <= 'z'  \\\n\t\t\t\tor ch in '-;/?:@&=+$,_.!~*\\'()[]%':\n\t\t\tif ch == '%':\n\t\t\t\tchunks.append(self.prefix(length))\n\t\t\t\tself.forward(length)\n\t\t\t\tlength = 0\n\t\t\t\tchunks.append(self.scan_uri_escapes(name, start_mark))\n\t\t\telse:\n\t\t\t\tlength += 1\n\t\t\tch = self.peek(length)\n\t\tif length:\n\t\t\tchunks.append(self.prefix(length))\n\t\t\tself.forward(length)\n\t\t\tlength = 0\n\t\tif not chunks:\n\t\t\traise ScannerError(\"while parsing a %s\" % name, start_mark,\n\t\t\t\t\t\"expected URI, but found %r\" % ch, self.get_mark())\n\t\treturn ''.join(chunks)\n\n\tdef scan_uri_escapes(self, name, start_mark):\n\t\t# See the specification for details.\n\t\tcodes = []\n\t\tmark = self.get_mark()\n\t\twhile self.peek() == '%':\n\t\t\tself.forward()\n\t\t\tfor k in range(2):\n\t\t\t\tif self.peek(k) not in '0123456789ABCDEFabcdef':\n\t\t\t\t\traise ScannerError(\"while scanning a %s\" % name, start_mark,\n\t\t\t\t\t\t\t\"expected URI escape sequence of 2 hexdecimal numbers, but found %r\"\n\t\t\t\t\t\t\t% self.peek(k), self.get_mark())\n\t\t\tcodes.append(int(self.prefix(2), 16))\n\t\t\tself.forward(2)\n\t\ttry:\n\t\t\tvalue = bytes(codes).decode('utf-8')\n\t\texcept UnicodeDecodeError as exc:\n\t\t\traise ScannerError(\"while scanning a %s\" % name, start_mark, str(exc), mark)\n\t\treturn value\n\n\tdef scan_line_break(self):\n\t\t# Transforms:\n\t\t#   '\\r\\n'\t  :   '\\n'\n\t\t#   '\\r'\t\t:   '\\n'\n\t\t#   '\\n'\t\t:   '\\n'\n\t\t#   '\\x85'\t  :   '\\n'\n\t\t#   '\\u2028'\t:   '\\u2028'\n\t\t#   '\\u2029\t :   '\\u2029'\n\t\t#   default\t :   ''\n\t\tch = self.peek()\n\t\tif ch in '\\r\\n\\x85':\n\t\t\tif self.prefix(2) == '\\r\\n':\n\t\t\t\tself.forward(2)\n\t\t\telse:\n\t\t\t\tself.forward()\n\t\t\treturn '\\n'\n\t\telif ch in '\\u2028\\u2029':\n\t\t\tself.forward()\n\t\t\treturn ch\n\t\treturn ''\n", "description": "Initialize the scanner.", "category": "simple", "imports": ["from .error import MarkedYAMLError", "from .tokens import *"]}], [], [{"term": "class", "name": "_AnonBase", "data": "class _AnonBase(_VimTest):\n\targs = \"\"\n\n\tdef _extra_vim_config(self, vim_config):\n\t\tvim_config.append(\n\t\t\t\"inoremap  %s =UltiSnips#Anon(%s)\" % (EA, self.args)\n\t\t)\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "Anon_NoTrigger_Simple", "data": "class Anon_NoTrigger_Simple(_AnonBase):\n\targs = '\"simple expand\"'\n\tkeys = \"abc\" + EA\n\twanted = \"abcsimple expand\"\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "Anon_NoTrigger_AfterSpace", "data": "class Anon_NoTrigger_AfterSpace(_AnonBase):\n\targs = '\"simple expand\"'\n\tkeys = \"abc \" + EA\n\twanted = \"abc simple expand\"\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "Anon_NoTrigger_BeginningOfLine", "data": "class Anon_NoTrigger_BeginningOfLine(_AnonBase):\n\targs = r\"':latex:\\`$1\\`$0'\"\n\tkeys = EA + \"Hello\" + JF + \"World\"\n\twanted = \":latex:`Hello`World\"\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "Anon_NoTrigger_FirstCharOfLine", "data": "class Anon_NoTrigger_FirstCharOfLine(_AnonBase):\n\targs = r\"':latex:\\`$1\\`$0'\"\n\tkeys = \" \" + EA + \"Hello\" + JF + \"World\"\n\twanted = \" :latex:`Hello`World\"\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "Anon_NoTrigger_Multi", "data": "class Anon_NoTrigger_Multi(_AnonBase):\n\targs = '\"simple $1 expand $1 $0\"'\n\tkeys = \"abc\" + EA + \"123\" + JF + \"456\"\n\twanted = \"abcsimple 123 expand 123 456\"\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "Anon_Trigger_Multi", "data": "class Anon_Trigger_Multi(_AnonBase):\n\targs = '\"simple $1 expand $1 $0\", \"abc\"'\n\tkeys = \"123 abc\" + EA + \"123\" + JF + \"456\"\n\twanted = \"123 simple 123 expand 123 456\"\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "Anon_Trigger_Simple", "data": "class Anon_Trigger_Simple(_AnonBase):\n\targs = '\"simple expand\", \"abc\"'\n\tkeys = \"abc\" + EA\n\twanted = \"simple expand\"\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "Anon_Trigger_Twice", "data": "class Anon_Trigger_Twice(_AnonBase):\n\targs = '\"simple expand\", \"abc\"'\n\tkeys = \"abc\" + EA + \"\\nabc\" + EX\n\twanted = \"simple expand\\nabc\" + EX\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "Anon_Trigger_Opts", "data": "class Anon_Trigger_Opts(_AnonBase):\n\targs = '\"simple expand\", \".*abc\", \"desc\", \"r\"'\n\tkeys = \"blah blah abc\" + EA\n\twanted = \"simple expand\"\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}], [{"term": "def", "name": "test_add_child", "data": "def test_add_child():\n\tsimple_tree = SimpleTree(SimpleTreeNode(0, None))\n\tassert simple_tree.Root.NodeValue == 0\n\n\tnew_node = SimpleTreeNode(777, None)\n\tsimple_tree.AddChild(simple_tree.Root, new_node)\n\n\tassert new_node in simple_tree.Root.Children\n\tassert new_node.Parent == simple_tree.Root\n\tassert len(simple_tree.Root.Children) == 1\n\n", "description": null, "category": "simple", "imports": ["from collections import namedtuple", "import pytest", "from project.forests.forest import SimpleTree, SimpleTreeNode"]}, {"term": "def", "name": "get_odd_tree", "data": "def get_odd_tree():\n\tsimple_tree = SimpleTree(SimpleTreeNode(1, None))\n\tnodes_to_add = [\n\t\tSimpleTreeNode(2, None),\n\t\tSimpleTreeNode(3, None),\n\t\tSimpleTreeNode(4, None),\n\t\tSimpleTreeNode(5, None),\n\t]\n\tsimple_tree.AddChild(simple_tree.Root, nodes_to_add[0])\n\tsimple_tree.AddChild(simple_tree.Root, nodes_to_add[1])\n\tsimple_tree.AddChild(nodes_to_add[0], nodes_to_add[2])\n\tsimple_tree.AddChild(nodes_to_add[1], nodes_to_add[3])\n\n\treturn simple_tree, nodes_to_add\n\n", "description": null, "category": "simple", "imports": ["from collections import namedtuple", "import pytest", "from project.forests.forest import SimpleTree, SimpleTreeNode"]}, {"term": "def", "name": "get_odd_tree_with_results", "data": "def get_odd_tree_with_results(get_odd_tree):\n\tsimple_tree, nodes_to_add = get_odd_tree\n\tadditional_nodes_to_add = [\n\t\tSimpleTreeNode(6, None),\n\t\tSimpleTreeNode(7, None),\n\t]\n\tsimple_tree.AddChild(nodes_to_add[3], additional_nodes_to_add[0])\n\tsimple_tree.AddChild(additional_nodes_to_add[0], additional_nodes_to_add[1])\n\n\treturn simple_tree, nodes_to_add\n\n", "description": null, "category": "simple", "imports": ["from collections import namedtuple", "import pytest", "from project.forests.forest import SimpleTree, SimpleTreeNode"]}, {"term": "def", "name": "get_even_tree", "data": "def get_even_tree():\n\tsimple_tree = SimpleTree(SimpleTreeNode(1, None))\n\tnodes_to_add = [\n\t\tSimpleTreeNode(2, None),\n\t\tSimpleTreeNode(3, None),\n\t\tSimpleTreeNode(4, None),\n\t\tSimpleTreeNode(5, None),\n\t\tSimpleTreeNode(6, None),\n\t\tSimpleTreeNode(7, None),\n\t\tSimpleTreeNode(8, None),\n\t\tSimpleTreeNode(9, None),\n\t\tSimpleTreeNode(10, None),\n\t\tSimpleTreeNode(11, None),\n\t\tSimpleTreeNode(12, None),\n\t\tSimpleTreeNode(13, None),\n\t\tSimpleTreeNode(14, None),\n\t]\n\n\tsimple_tree.AddChild(simple_tree.Root, nodes_to_add[0])\n\n\tsimple_tree.AddChild(nodes_to_add[0], nodes_to_add[1])\n\tsimple_tree.AddChild(nodes_to_add[0], nodes_to_add[2])\n\tsimple_tree.AddChild(nodes_to_add[0], nodes_to_add[3])\n\n\tsimple_tree.AddChild(nodes_to_add[1], nodes_to_add[4])\n\tsimple_tree.AddChild(nodes_to_add[1], nodes_to_add[5])\n\tsimple_tree.AddChild(nodes_to_add[2], nodes_to_add[6])\n\tsimple_tree.AddChild(nodes_to_add[3], nodes_to_add[7])\n\tsimple_tree.AddChild(nodes_to_add[3], nodes_to_add[8])\n\n\tsimple_tree.AddChild(nodes_to_add[4], nodes_to_add[9])\n\tsimple_tree.AddChild(nodes_to_add[4], nodes_to_add[10])\n\tsimple_tree.AddChild(nodes_to_add[4], nodes_to_add[11])\n\tsimple_tree.AddChild(nodes_to_add[5], nodes_to_add[12])\n\n\t# 1 - 2 - 3 - 6 - 11\n\t#\t\t\t   - 12\n\t#\t\t\t   - 13\n\t#\t\t   - 7 - 14\n\t#\t   - 4 - 8\n\t#\t   - 5 - 9\n\t#\t\t   - 10\n\treturn simple_tree, nodes_to_add\n\n", "description": null, "category": "simple", "imports": ["from collections import namedtuple", "import pytest", "from project.forests.forest import SimpleTree, SimpleTreeNode"]}, {"term": "def", "name": "get_even_tree_example", "data": "def get_even_tree_example():\n\tsimple_tree = SimpleTree(SimpleTreeNode(1, None))\n\tnodes_to_add = [\n\t\tSimpleTreeNode(2, None),\n\t\tSimpleTreeNode(3, None),\n\t\tSimpleTreeNode(4, None),\n\t\tSimpleTreeNode(5, None),\n\t\tSimpleTreeNode(6, None),\n\t\tSimpleTreeNode(7, None),\n\t\tSimpleTreeNode(8, None),\n\t\tSimpleTreeNode(9, None),\n\t\tSimpleTreeNode(10, None)\n\t]\n\n\tsimple_tree.AddChild(simple_tree.Root, nodes_to_add[0])\n\tsimple_tree.AddChild(simple_tree.Root, nodes_to_add[1])\n\tsimple_tree.AddChild(simple_tree.Root, nodes_to_add[4])\n\n\tsimple_tree.AddChild(nodes_to_add[0], nodes_to_add[3])\n\tsimple_tree.AddChild(nodes_to_add[0], nodes_to_add[5])\n\n\tsimple_tree.AddChild(nodes_to_add[1], nodes_to_add[2])\n\n\tsimple_tree.AddChild(nodes_to_add[4], nodes_to_add[6])\n\n\tsimple_tree.AddChild(nodes_to_add[6], nodes_to_add[7])\n\tsimple_tree.AddChild(nodes_to_add[6], nodes_to_add[8])\n\n\treturn simple_tree, nodes_to_add\n\n", "description": null, "category": "simple", "imports": ["from collections import namedtuple", "import pytest", "from project.forests.forest import SimpleTree, SimpleTreeNode"]}, {"term": "def", "name": "test_get_all_nodes", "data": "def test_get_all_nodes(get_even_tree):\n\tsimple_tree, nodes_to_add = get_even_tree\n\tall_nodes = simple_tree.GetAllNodes()\n\tassert len(all_nodes) == 14\n\n\tfor node in nodes_to_add:\n\t\tassert node in all_nodes\n\n", "description": null, "category": "simple", "imports": ["from collections import namedtuple", "import pytest", "from project.forests.forest import SimpleTree, SimpleTreeNode"]}, {"term": "def", "name": "test_sort_all_nodes", "data": "def test_sort_all_nodes(get_even_tree):\n\tsimple_tree, nodes_to_add = get_even_tree\n\tall_nodes = simple_tree.GetAllNodes()\n\tassert len(all_nodes) == 14\n\n\tsorted_nodes = sorted(all_nodes, key=lambda node: node.Level, reverse=True)\n\tlevels = [node.Level for node in sorted_nodes]\n\tvalues = [node.NodeValue for node in sorted_nodes]\n\n\tassert levels == [4, 4, 4, 4, 3, 3, 3, 3, 3, 2, 2, 2, 1, 0]\n\tassert values == [11, 12, 13, 14, 6, 7, 8, 9, 10, 3, 4, 5, 2, 1]\n\n", "description": null, "category": "simple", "imports": ["from collections import namedtuple", "import pytest", "from project.forests.forest import SimpleTree, SimpleTreeNode"]}, {"term": "def", "name": "test_even_trees", "data": "def test_even_trees(get_even_tree):\n\tsimple_tree, nodes_to_add = get_even_tree\n\teven_trees = simple_tree.EvenTrees()\n\n\tassert len(even_trees) == 6\n\tfor node_index in [0, 1, 2, 4, 5]:\n\t\tassert nodes_to_add[node_index] in even_trees\n\n", "description": null, "category": "simple", "imports": ["from collections import namedtuple", "import pytest", "from project.forests.forest import SimpleTree, SimpleTreeNode"]}, {"term": "def", "name": "test_odd_trees_single_root", "data": "def test_odd_trees_single_root(get_odd_tree):\n\tsimple_tree, nodes_to_add = get_odd_tree\n\teven_trees = simple_tree.EvenTrees()\n\n\tassert len(even_trees) == 0\n\n", "description": null, "category": "simple", "imports": ["from collections import namedtuple", "import pytest", "from project.forests.forest import SimpleTree, SimpleTreeNode"]}, {"term": "def", "name": "test_odd_trees_with_results", "data": "def test_odd_trees_with_results(get_odd_tree_with_results):\n\tsimple_tree, nodes_to_add = get_odd_tree_with_results\n\teven_trees = simple_tree.EvenTrees()\n\n\tassert len(even_trees) == 0\n\n", "description": null, "category": "simple", "imports": ["from collections import namedtuple", "import pytest", "from project.forests.forest import SimpleTree, SimpleTreeNode"]}, {"term": "def", "name": "test_odd_trees_example", "data": "def test_odd_trees_example(get_even_tree_example):\n\tsimple_tree, nodes_to_add = get_even_tree_example\n\tall_nodes = simple_tree.GetAllNodes()\n\tassert len(all_nodes) == 10\n\n\teven_trees = simple_tree.EvenTrees()\n\n\tassert len(even_trees) == 4\n", "description": null, "category": "simple", "imports": ["from collections import namedtuple", "import pytest", "from project.forests.forest import SimpleTree, SimpleTreeNode"]}], [{"term": "class", "name": "classTestCycles:", "data": "class TestCycles:\n\tdef setUp(self):\n\t\tG=networkx.Graph()\n\t\tnx.add_cycle(G, [0,1,2,3])\n\t\tnx.add_cycle(G, [0,3,4,5])\n\t\tnx.add_cycle(G, [0,1,6,7,8])\n\t\tG.add_edge(8,9)\n\t\tself.G=G\n\n\tdef is_cyclic_permutation(self,a,b):\n\t\tn=len(a)\n\t\tif len(b)!=n:\n\t\t\treturn False\n\t\tl=a+a\n\t\treturn any(l[i:i+n]==b for i in range(2*n-n+1))\n\n\tdef test_cycle_basis(self):\n\t\tG=self.G\n\t\tcy=networkx.cycle_basis(G,0)\n\t\tsort_cy= sorted( sorted(c) for c in cy )\n\t\tassert_equal(sort_cy, [[0,1,2,3],[0,1,6,7,8],[0,3,4,5]])\n\t\tcy=networkx.cycle_basis(G,1)\n\t\tsort_cy= sorted( sorted(c) for c in cy )\n\t\tassert_equal(sort_cy, [[0,1,2,3],[0,1,6,7,8],[0,3,4,5]])\n\t\tcy=networkx.cycle_basis(G,9)\n\t\tsort_cy= sorted( sorted(c) for c in cy )\n\t\tassert_equal(sort_cy, [[0,1,2,3],[0,1,6,7,8],[0,3,4,5]])\n\t\t# test disconnected graphs\n\t\tnx.add_cycle(G, \"ABC\")\n\t\tcy=networkx.cycle_basis(G,9)\n\t\tsort_cy= sorted(sorted(c) for c in cy[:-1]) + [sorted(cy[-1])]\n\t\tassert_equal(sort_cy, [[0,1,2,3],[0,1,6,7,8],[0,3,4,5],['A','B','C']])\n\n\t@raises(nx.NetworkXNotImplemented)\n\tdef test_cycle_basis(self):\n\t\tG=nx.DiGraph()\n\t\tcy=networkx.cycle_basis(G,0)\n\n\t@raises(nx.NetworkXNotImplemented)\n\tdef test_cycle_basis(self):\n\t\tG=nx.MultiGraph()\n\t\tcy=networkx.cycle_basis(G,0)\n\n\tdef test_simple_cycles(self):\n\t\tG = nx.DiGraph([(0, 0), (0, 1), (0, 2), (1, 2), (2, 0), (2, 1), (2, 2)])\n\t\tcc=sorted(nx.simple_cycles(G))\n\t\tca=[[0], [0, 1, 2], [0, 2], [1, 2], [2]]\n\t\tfor c in cc:\n\t\t\tassert_true(any(self.is_cyclic_permutation(c,rc) for rc in ca))\n\n\t@raises(nx.NetworkXNotImplemented)\n\tdef test_simple_cycles_graph(self):\n\t\tG = nx.Graph()\n\t\tc = sorted(nx.simple_cycles(G))\n\n\tdef test_unsortable(self):\n\t\t#  TODO What does this test do?  das 6/2013\n\t\tG=nx.DiGraph()\n\t\tnx.add_cycle(G, ['a',1])\n\t\tc=list(nx.simple_cycles(G))\n\n\tdef test_simple_cycles_small(self):\n\t\tG = nx.DiGraph()\n\t\tnx.add_cycle(G, [1,2,3])\n\t\tc=sorted(nx.simple_cycles(G))\n\t\tassert_equal(len(c),1)\n\t\tassert_true(self.is_cyclic_permutation(c[0],[1,2,3]))\n\t\tnx.add_cycle(G, [10,20,30])\n\t\tcc=sorted(nx.simple_cycles(G))\n\t\tca=[[1,2,3],[10,20,30]]\n\t\tfor c in cc:\n\t\t\tassert_true(any(self.is_cyclic_permutation(c,rc) for rc in ca))\n\n\tdef test_simple_cycles_empty(self):\n\t\tG = nx.DiGraph()\n\t\tassert_equal(list(nx.simple_cycles(G)),[])\n\n\tdef test_complete_directed_graph(self):\n\t\t# see table 2 in Johnson's paper\n\t\tncircuits=[1,5,20,84,409,2365,16064]\n\t\tfor n,c in zip(range(2,9),ncircuits):\n\t\t\tG=nx.DiGraph(nx.complete_graph(n))\n\t\t\tassert_equal(len(list(nx.simple_cycles(G))),c)\n\n\tdef worst_case_graph(self,k):\n\t\t# see figure 1 in Johnson's paper\n\t\t# this graph has excactly 3k simple cycles\n\t\tG=nx.DiGraph()\n\t\tfor n in range(2,k+2):\n\t\t\tG.add_edge(1,n)\n\t\t\tG.add_edge(n,k+2)\n\t\tG.add_edge(2*k+1,1)\n\t\tfor n in range(k+2,2*k+2):\n\t\t\tG.add_edge(n,2*k+2)\n\t\t\tG.add_edge(n,n+1)\n\t\tG.add_edge(2*k+3,k+2)\n\t\tfor n in range(2*k+3,3*k+3):\n\t\t\tG.add_edge(2*k+2,n)\n\t\t\tG.add_edge(n,3*k+3)\n\t\tG.add_edge(3*k+3,2*k+2)\n\t\treturn G\n\n\tdef test_worst_case_graph(self):\n\t\t# see figure 1 in Johnson's paper\n\t\tfor k in range(3,10):\n\t\t\tG=self.worst_case_graph(k)\n\t\t\tl=len(list(nx.simple_cycles(G)))\n\t\t\tassert_equal(l,3*k)\n\n\tdef test_recursive_simple_and_not(self):\n\t\tfor k in range(2,10):\n\t\t\tG=self.worst_case_graph(k)\n\t\t\tcc=sorted(nx.simple_cycles(G))\n\t\t\trcc=sorted(nx.recursive_simple_cycles(G))\n\t\t\tassert_equal(len(cc),len(rcc))\n\t\t\tfor c in cc:\n\t\t\t\tassert_true(any(self.is_cyclic_permutation(c,rc) for rc in rcc))\n\t\t\tfor rc in rcc:\n\t\t\t\tassert_true(any(self.is_cyclic_permutation(rc,c) for c in cc))\n\n\tdef test_simple_graph_with_reported_bug(self):\n\t\tG=nx.DiGraph()\n\t\tedges = [(0, 2), (0, 3), (1, 0), (1, 3), (2, 1), (2, 4), \\\n\t\t\t\t(3, 2), (3, 4), (4, 0), (4, 1), (4, 5), (5, 0), \\\n\t\t\t\t(5, 1), (5, 2), (5, 3)]\n\t\tG.add_edges_from(edges)\n\t\tcc=sorted(nx.simple_cycles(G))\n\t\tassert_equal(len(cc),26)\n\t\trcc=sorted(nx.recursive_simple_cycles(G))\n\t\tassert_equal(len(cc),len(rcc))\n\t\tfor c in cc:\n\t\t\tassert_true(any(self.is_cyclic_permutation(c,rc) for rc in rcc))\n\t\tfor rc in rcc:\n\t\t\tassert_true(any(self.is_cyclic_permutation(rc,c) for c in cc))\n", "description": null, "category": "simple", "imports": ["from nose.tools import *", "import networkx", "import networkx as nx", "from networkx.algorithms import find_cycle"]}, {"term": "class", "name": "TestFindCycle", "data": "class TestFindCycle(object):\n\tdef setUp(self):\n\t\tself.nodes = [0, 1, 2, 3]\n\t\tself.edges = [(-1, 0), (0, 1), (1, 0), (1, 0), (2, 1), (3, 1)]\n\n\tdef test_graph(self):\n\t\tG = nx.Graph(self.edges)\n\t\tassert_raises(nx.exception.NetworkXNoCycle, find_cycle, G, self.nodes)\n\n\tdef test_digraph(self):\n\t\tG = nx.DiGraph(self.edges)\n\t\tx = list(find_cycle(G, self.nodes))\n\t\tx_= [(0, 1), (1, 0)]\n\t\tassert_equal(x, x_)\n\n\tdef test_multigraph(self):\n\t\tG = nx.MultiGraph(self.edges)\n\t\tx = list(find_cycle(G, self.nodes))\n\t\tx_ = [(0, 1, 0), (1, 0, 1)] # or (1, 0, 2)\n\t\t# Hash randomization...could be any edge.\n\t\tassert_equal(x[0], x_[0])\n\t\tassert_equal(x[1][:2], x_[1][:2])\n\n\tdef test_multidigraph(self):\n\t\tG = nx.MultiDiGraph(self.edges)\n\t\tx = list(find_cycle(G, self.nodes))\n\t\tx_ = [(0, 1, 0), (1, 0, 0)] # (1, 0, 1)\n\t\tassert_equal(x[0], x_[0])\n\t\tassert_equal(x[1][:2], x_[1][:2])\n\n\tdef test_digraph_ignore(self):\n\t\tG = nx.DiGraph(self.edges)\n\t\tx = list(find_cycle(G, self.nodes, orientation='ignore'))\n\t\tx_ = [(0, 1, FORWARD), (1, 0, FORWARD)]\n\t\tassert_equal(x, x_)\n\n\tdef test_multidigraph_ignore(self):\n\t\tG = nx.MultiDiGraph(self.edges)\n\t\tx = list(find_cycle(G, self.nodes, orientation='ignore'))\n\t\tx_ = [(0, 1, 0, FORWARD), (1, 0, 0, FORWARD)] # or (1, 0, 1, 1)\n\t\tassert_equal(x[0], x_[0])\n\t\tassert_equal(x[1][:2], x_[1][:2])\n\t\tassert_equal(x[1][3], x_[1][3])\n\n\tdef test_multidigraph_ignore2(self):\n\t\t# Loop traversed an edge while ignoring its orientation.\n\t\tG = nx.MultiDiGraph([(0,1), (1,2), (1,2)])\n\t\tx = list(find_cycle(G, [0,1,2], orientation='ignore'))\n\t\tx_ = [(1,2,0,FORWARD), (1,2,1,REVERSE)]\n\t\tassert_equal(x, x_)\n\n\tdef test_multidigraph_ignore2(self):\n\t\t# Node 2 doesn't need to be searched again from visited from 4.\n\t\t# The goal here is to cover the case when 2 to be researched from 4,\n\t\t# when 4 is visited from the first time (so we must make sure that 4\n\t\t# is not visited from 2, and hence, we respect the edge orientation).\n\t\tG = nx.MultiDiGraph([(0,1), (1,2), (2,3), (4,2)])\n\t\tassert_raises(nx.exception.NetworkXNoCycle,\n\t\t\t\t\t  find_cycle, G, [0,1,2,3,4], orientation='original')\n\n\tdef test_dag(self):\n\t\tG = nx.DiGraph([(0,1), (0,2), (1,2)])\n\t\tassert_raises(nx.exception.NetworkXNoCycle,\n\t\t\t\t\t  find_cycle, G, orientation='original')\n\t\tx = list(find_cycle(G, orientation='ignore'))\n\t\tassert_equal(x, [(0,1,FORWARD), (1,2,FORWARD), (0,2,REVERSE)])\n\n\tdef test_prev_explored(self):\n\t\t# https://github.com/networkx/networkx/issues/2323\n\n\t\tG = nx.DiGraph()\n\t\tG.add_edges_from([(1,0), (2,0), (1,2), (2,1)])\n\t\tassert_raises(nx.exception.NetworkXNoCycle,\n\t\t\t\t\t  find_cycle, G, source=0)\n\t\tx = list(nx.find_cycle(G, 1))\n\t\tx_ = [(1, 2), (2, 1)]\n\t\tassert_equal(x, x_)\n\n\t\tx = list(nx.find_cycle(G, 2))\n\t\tx_ = [(2, 1), (1, 2)]\n\t\tassert_equal(x, x_)\n", "description": null, "category": "simple", "imports": ["from nose.tools import *", "import networkx", "import networkx as nx", "from networkx.algorithms import find_cycle"]}], [{"term": "class", "name": "SimpleFunc", "data": "class SimpleFunc(Func):\n\n\tdef __init__(self, field, *values, **extra):\n\t\tif not isinstance(field, Expression):\n\t\t\tfield  = F(field)\n\t\t\tif values and not isinstance(values[0], Expression):\n\t\t\t\tvalues = [V(v) for v in values]\n\t\tsuper(SimpleFunc, self).__init__(field, *values, **extra)\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "TooManyExpressionsError", "data": "class TooManyExpressionsError(Exception):\n\tpass\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "def", "name": "multi_func", "data": "def multi_func(func, expression, *args):\n\tif len(args) > GET_ITERATOR_CHUNK_SIZE:\n\t\traise TooManyExpressionsError('Multi-func given %s args. The limit is %s due to Python recursion depth risk' % (\n\t\tlen(args), GET_ITERATOR_CHUNK_SIZE))\n\targs = list(args)\n\tinitial_arg = args.pop(0)\n\tquery = func(expression, initial_arg)\n\tfor arg in args:\n\t\tquery = func(query, arg)\n\treturn query\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "def", "name": "multi_array_remove", "data": "def multi_array_remove(field, *args):\n\treturn multi_func(ArrayRemove, field, *args)\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "ArrayAppend", "data": "class ArrayAppend(SimpleFunc):\n\tfunction = 'ARRAY_APPEND'\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "ArrayPrepend", "data": "class ArrayPrepend(Func):\n\tfunction = 'ARRAY_PREPEND'\n\n\tdef __init__(self, value, field, **extra):\n\t\tif not isinstance(value, Expression):\n\t\t\tvalue = V(value)\n\t\t\tfield = F(field)\n\t\tsuper(ArrayPrepend, self).__init__(value, field, **extra)\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "ArrayRemove", "data": "class ArrayRemove(SimpleFunc):\n\tfunction = 'ARRAY_REMOVE'\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "ArrayReplace", "data": "class ArrayReplace(SimpleFunc):\n\tfunction = 'ARRAY_REPLACE'\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "ArrayPosition", "data": "class ArrayPosition(SimpleFunc):\n\tfunction = 'ARRAY_POSITION'\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "ArrayPositions", "data": "class ArrayPositions(SimpleFunc):\n\tfunction = 'ARRAY_POSITIONS'\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "ArrayCat", "data": "class ArrayCat(Func):\n\tfunction = 'ARRAY_CAT'\n\n\tdef __init__(self, field, value, prepend=False, output_field=None, **extra):\n\t\tif not isinstance(field, Expression):\n\t\t\tfield = F(field)\n\t\tif not isinstance(value, Expression):\n\t\t\tif isinstance(value, six.string_types):\n\t\t\t\tvalue = F(value)\n\t\t\telif output_field:\n\t\t\t\tvalue = V(value, output_field = output_field)\n\t\t\telse:\n\t\t\t\tvalue = V(value)\n\t\tif prepend:\n\t\t\tsuper(ArrayCat, self).__init__(value, field, **extra)\n\t\telse:\n\t\t\tsuper(ArrayCat, self).__init__(field, value, **extra)\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "ArrayLength", "data": "class ArrayLength(SimpleFunc):\n\tfunction = 'ARRAY_LENGTH'\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "ArrayDims", "data": "class ArrayDims(SimpleFunc):\n\tfunction = 'ARRAY_DIMS'\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "ArrayUpper", "data": "class ArrayUpper(SimpleFunc):\n\tfunction = 'ARRAY_UPPER'\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "ArrayLower", "data": "class ArrayLower(SimpleFunc):\n\tfunction = 'ARRAY_LOWER'\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "Cardinality", "data": "class Cardinality(SimpleFunc):\n\tfunction = 'CARDINALITY'\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "NonFieldFunc", "data": "class NonFieldFunc(Func):\n\tdef __init__(self, *values, **extra):\n\t\tvalues = list(values)\n\t\tfor i, value in enumerate(values):\n\t\t\tif not isinstance(value, Expression):\n\t\t\t\tvalues[i] = V(value)\n\t\tsuper(NonFieldFunc, self).__init__(*values, **extra)\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "HStore", "data": "class HStore(NonFieldFunc):\n\tfunction = 'HSTORE'\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "AKeys", "data": "class AKeys(SimpleFunc):\n\tfunction = 'AKEYS'\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "SKeys", "data": "class SKeys(SimpleFunc):\n\tfunction = 'SKEYS'\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "AVals", "data": "class AVals(SimpleFunc):\n\tfunction = 'AVALS'\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "SVals", "data": "class SVals(SimpleFunc):\n\tfunction = 'SVALS'\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "HStoreToArray", "data": "class HStoreToArray(SimpleFunc):\n\tfunction = 'HSTORE_TO_ARRAY'\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "HStoreToMatrix", "data": "class HStoreToMatrix(SimpleFunc):\n\tfunction = 'HSTORE_TO_MATRIX'\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "Slice", "data": "class Slice(SimpleFunc):\n\tfunction = 'SLICE'\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "Delete", "data": "class Delete(SimpleFunc):\n\tfunction = 'DELETE'\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "Each", "data": "class Each(SimpleFunc):\n\tfunction = 'EACH'\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "HstoreToJSONB", "data": "class HstoreToJSONB(SimpleFunc):\n\tfunction = 'HSTORE_TO_JSONB'\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "HstoreToJSONBLoose", "data": "class HstoreToJSONBLoose(SimpleFunc):\n\tfunction = 'HSTORE_TO_JSONB_LOOSE'\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "ToJSONB", "data": "class ToJSONB(NonFieldFunc):\n\tfunction = 'TO_JSONB'\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "RowToJSON", "data": "class RowToJSON(SimpleFunc):\n\tfunction = 'ROW_TO_JSON'\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "ArrayToJSON", "data": "class ArrayToJSON(SimpleFunc):\n\tfunction = 'ARRAY_TO_JSON'\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "JSONBBuildArray", "data": "class JSONBBuildArray(NonFieldFunc):\n\tfunction = 'JSONB_BUILD_ARRAY'\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "JSONBArrayElements", "data": "class JSONBArrayElements(SimpleFunc):\n\tfunction = 'JSONB_ARRAY_ELEMENTS'\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "JSONBBuildObject", "data": "class JSONBBuildObject(NonFieldFunc):\n\tfunction = 'JSONB_BUILD_OBJECT'\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "JSONBObject", "data": "class JSONBObject(NonFieldFunc):\n\tfunction = 'JOSNB_OBJECT'\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "JSONBSet", "data": "class JSONBSet(SimpleFunc):\n\tfunction = 'JSONB_SET'\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "JSONBArrayLength", "data": "class JSONBArrayLength(SimpleFunc):\n\tfunction = 'JSONB_ARRAY_length'\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "JSONBPretty", "data": "class JSONBPretty(SimpleFunc):\n\tfunction = 'JSONB_PRETTY'\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "JSONObjectKeys", "data": "class JSONObjectKeys(SimpleFunc):\n\tfunction = 'JSON_OBJECT_KEYS'\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "JSONStripNulls", "data": "class JSONStripNulls(SimpleFunc):\n\tfunction = 'JSON_STRIP_NULLS'\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}, {"term": "class", "name": "JSONTypeOf", "data": "class JSONTypeOf(SimpleFunc):\n", "description": null, "category": "simple", "imports": ["from django.db.models.expressions import Func, Expression", "from django.db.models.sql.constants import GET_ITERATOR_CHUNK_SIZE", "from django.utils import six", "from .expressions import F, Value as V"]}], [{"term": "class", "name": "_SimpleModel", "data": "class _SimpleModel(nn.Module):\n\t@configurable\n\tdef __init__(self, sleep_sec=0):\n\t\tsuper().__init__()\n\t\tself.mod = nn.Linear(10, 20)\n\t\tself.sleep_sec = sleep_sec\n\n\t@classmethod\n\tdef from_config(cls, cfg):\n\t\treturn {}\n\n\tdef forward(self, x):\n\t\tif self.sleep_sec > 0:\n\t\t\ttime.sleep(self.sleep_sec)\n\t\treturn {\"loss\": x.sum() + sum([x.mean() for x in self.parameters()])}\n\n", "description": null, "category": "simple", "imports": ["import json", "import math", "import os", "import tempfile", "import time", "import unittest", "from unittest import mock", "import torch", "from fvcore.common.checkpoint import Checkpointer", "from torch import nn", "from detectron2 import model_zoo", "from detectron2.config import configurable, get_cfg", "from detectron2.engine import DefaultTrainer, SimpleTrainer, default_setup, hooks", "from detectron2.modeling.meta_arch import META_ARCH_REGISTRY", "from detectron2.utils.events import CommonMetricPrinter, JSONWriter"]}, {"term": "class", "name": "TestTrainer", "data": "class TestTrainer(unittest.TestCase):\n\tdef _data_loader(self, device):\n\t\tdevice = torch.device(device)\n\t\twhile True:\n\t\t\tyield torch.rand(3, 3).to(device)\n\n\tdef test_simple_trainer(self, device=\"cpu\"):\n\t\tmodel = _SimpleModel().to(device=device)\n\t\ttrainer = SimpleTrainer(\n\t\t\tmodel, self._data_loader(device), torch.optim.SGD(model.parameters(), 0.1)\n\t\t)\n\t\ttrainer.train(0, 10)\n\n\t@unittest.skipIf(not torch.cuda.is_available(), \"CUDA not available\")\n\tdef test_simple_trainer_cuda(self):\n\t\tself.test_simple_trainer(device=\"cuda\")\n\n\tdef test_writer_hooks(self):\n\t\tmodel = _SimpleModel(sleep_sec=0.1)\n\t\ttrainer = SimpleTrainer(\n\t\t\tmodel, self._data_loader(\"cpu\"), torch.optim.SGD(model.parameters(), 0.1)\n\t\t)\n\n\t\tmax_iter = 50\n\n\t\twith tempfile.TemporaryDirectory(prefix=\"detectron2_test\") as d:\n\t\t\tjson_file = os.path.join(d, \"metrics.json\")\n\t\t\twriters = [CommonMetricPrinter(max_iter), JSONWriter(json_file)]\n\n\t\t\ttrainer.register_hooks(\n\t\t\t\t[hooks.EvalHook(0, lambda: {\"metric\": 100}), hooks.PeriodicWriter(writers)]\n\t\t\t)\n\t\t\twith self.assertLogs(writers[0].logger) as logs:\n\t\t\t\ttrainer.train(0, max_iter)\n\n\t\t\twith open(json_file, \"r\") as f:\n\t\t\t\tdata = [json.loads(line.strip()) for line in f]\n\t\t\t\tself.assertEqual([x[\"iteration\"] for x in data], [19, 39, 49, 50])\n\t\t\t\t# the eval metric is in the last line with iter 50\n\t\t\t\tself.assertIn(\"metric\", data[-1], \"Eval metric must be in last line of JSON!\")\n\n\t\t\t# test logged messages from CommonMetricPrinter\n\t\t\tself.assertEqual(len(logs.output), 3)\n\t\t\tfor log, iter in zip(logs.output, [19, 39, 49]):\n\t\t\t\tself.assertIn(f\"iter: {iter}\", log)\n\n\t\t\tself.assertIn(\"eta: 0:00:00\", logs.output[-1], \"Last ETA must be 0!\")\n\n\tdef test_default_trainer(self):\n\t\t# TODO: this test requires manifold access, so changed device to CPU. see: T88318502\n\t\tcfg = get_cfg()\n\t\tcfg.MODEL.DEVICE = \"cpu\"\n\t\tcfg.MODEL.META_ARCHITECTURE = \"_SimpleModel\"\n\t\tcfg.DATASETS.TRAIN = (\"coco_2017_val_100\",)\n\t\twith tempfile.TemporaryDirectory(prefix=\"detectron2_test\") as d:\n\t\t\tcfg.OUTPUT_DIR = d\n\t\t\ttrainer = DefaultTrainer(cfg)\n\n\t\t\t# test property\n\t\t\tself.assertIs(trainer.model, trainer._trainer.model)\n\t\t\ttrainer.model = _SimpleModel()\n\t\t\tself.assertIs(trainer.model, trainer._trainer.model)\n\n\tdef test_checkpoint_resume(self):\n\t\tmodel = _SimpleModel()\n\t\tdataloader = self._data_loader(\"cpu\")\n\t\topt = torch.optim.SGD(model.parameters(), 0.1)\n\t\tscheduler = torch.optim.lr_scheduler.StepLR(opt, 3)\n\n\t\twith tempfile.TemporaryDirectory(prefix=\"detectron2_test\") as d:\n\t\t\ttrainer = SimpleTrainer(model, dataloader, opt)\n\t\t\tcheckpointer = Checkpointer(model, d, opt=opt, trainer=trainer)\n\n\t\t\ttrainer.register_hooks(\n\t\t\t\t[\n\t\t\t\t\thooks.LRScheduler(scheduler=scheduler),\n\t\t\t\t\t# checkpoint after scheduler to properly save the state of scheduler\n\t\t\t\t\thooks.PeriodicCheckpointer(checkpointer, 10),\n\t\t\t\t]\n\t\t\t)\n\n\t\t\ttrainer.train(0, 12)\n\t\t\tself.assertAlmostEqual(opt.param_groups[0][\"lr\"], 1e-5)\n\t\t\tself.assertEqual(scheduler.last_epoch, 12)\n\t\t\tdel trainer\n\n\t\t\topt = torch.optim.SGD(model.parameters(), 999)  # lr will be loaded\n\t\t\ttrainer = SimpleTrainer(model, dataloader, opt)\n\t\t\tscheduler = torch.optim.lr_scheduler.StepLR(opt, 3)\n\t\t\ttrainer.register_hooks(\n\t\t\t\t[\n\t\t\t\t\thooks.LRScheduler(scheduler=scheduler),\n\t\t\t\t]\n\t\t\t)\n\t\t\tcheckpointer = Checkpointer(model, d, opt=opt, trainer=trainer)\n\t\t\tcheckpointer.resume_or_load(\"non_exist.pth\")\n\t\t\tself.assertEqual(trainer.iter, 11)  # last finished iter number (0-based in Trainer)\n\t\t\t# number of times `scheduler.step()` was called (1-based)\n\t\t\tself.assertEqual(scheduler.last_epoch, 12)\n\t\t\tself.assertAlmostEqual(opt.param_groups[0][\"lr\"], 1e-5)\n\n\tdef test_eval_hook(self):\n\t\tmodel = _SimpleModel()\n\t\tdataloader = self._data_loader(\"cpu\")\n\t\topt = torch.optim.SGD(model.parameters(), 0.1)\n\n\t\tfor total_iter, period, eval_count in [(30, 15, 2), (31, 15, 3), (20, 0, 1)]:\n\t\t\ttest_func = mock.Mock(return_value={\"metric\": 3.0})\n\t\t\ttrainer = SimpleTrainer(model, dataloader, opt)\n\t\t\ttrainer.register_hooks([hooks.EvalHook(period, test_func)])\n\t\t\ttrainer.train(0, total_iter)\n\t\t\tself.assertEqual(test_func.call_count, eval_count)\n\n\tdef test_best_checkpointer(self):\n\t\tmodel = _SimpleModel()\n\t\tdataloader = self._data_loader(\"cpu\")\n\t\topt = torch.optim.SGD(model.parameters(), 0.1)\n\t\tmetric_name = \"metric\"\n\t\ttotal_iter = 40\n\t\ttest_period = 10\n\t\ttest_cases = [\n\t\t\t(\"max\", iter([0.3, 0.4, 0.35, 0.5]), 3),\n\t\t\t(\"min\", iter([1.0, 0.8, 0.9, 0.9]), 2),\n\t\t\t(\"min\", iter([math.nan, 0.8, 0.9, 0.9]), 1),\n\t\t]\n\t\tfor mode, metrics, call_count in test_cases:\n\t\t\ttrainer = SimpleTrainer(model, dataloader, opt)\n\t\t\twith tempfile.TemporaryDirectory(prefix=\"detectron2_test\") as d:\n\t\t\t\tcheckpointer = Checkpointer(model, d, opt=opt, trainer=trainer)\n\t\t\t\ttrainer.register_hooks(\n\t\t\t\t\t[\n\t\t\t\t\t\thooks.EvalHook(test_period, lambda: {metric_name: next(metrics)}),\n\t\t\t\t\t\thooks.BestCheckpointer(test_period, checkpointer, metric_name, mode=mode),\n\t\t\t\t\t]\n\t\t\t\t)\n\t\t\t\twith mock.patch.object(checkpointer, \"save\") as mock_save_method:\n\t\t\t\t\ttrainer.train(0, total_iter)\n\t\t\t\t\tself.assertEqual(mock_save_method.call_count, call_count)\n\n\tdef test_setup_config(self):\n\t\twith tempfile.TemporaryDirectory(prefix=\"detectron2_test\") as d:\n\t\t\tcfg = get_cfg()\n\t\t\tcfg.OUTPUT_DIR = os.path.join(d, \"yacs\")\n\t\t\tdefault_setup(cfg, {})\n\n\t\t\tcfg = model_zoo.get_config(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.py\")\n\t\t\tcfg.train.output_dir = os.path.join(d, \"omegaconf\")\n\t\t\tdefault_setup(cfg, {})\n", "description": null, "category": "simple", "imports": ["import json", "import math", "import os", "import tempfile", "import time", "import unittest", "from unittest import mock", "import torch", "from fvcore.common.checkpoint import Checkpointer", "from torch import nn", "from detectron2 import model_zoo", "from detectron2.config import configurable, get_cfg", "from detectron2.engine import DefaultTrainer, SimpleTrainer, default_setup, hooks", "from detectron2.modeling.meta_arch import META_ARCH_REGISTRY", "from detectron2.utils.events import CommonMetricPrinter, JSONWriter"]}], [{"term": "def", "name": "test_all_simple_paths", "data": "def test_all_simple_paths():\n\tG = nx.path_graph(4)\n\tpaths = nx.all_simple_paths(G,0,3)\n\tassert_equal(list(list(p) for p in paths),[[0,1,2,3]])\n", "description": null, "category": "simple", "imports": ["from nose.tools import *", "import networkx as nx", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_cutoff", "data": "def test_all_simple_paths_cutoff():\n\tG = nx.complete_graph(4)\n\tpaths = nx.all_simple_paths(G,0,1,cutoff=1)\n\tassert_equal(list(list(p) for p in paths),[[0,1]])\n\tpaths = nx.all_simple_paths(G,0,1,cutoff=2)\n\tassert_equal(list(list(p) for p in paths),[[0,1],[0,2,1],[0,3,1]])\n", "description": null, "category": "simple", "imports": ["from nose.tools import *", "import networkx as nx", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_multigraph", "data": "def test_all_simple_paths_multigraph():\n\tG = nx.MultiGraph([(1,2),(1,2)])\n\tpaths = nx.all_simple_paths(G,1,2)\n\tassert_equal(list(list(p) for p in paths),[[1,2],[1,2]])\n", "description": null, "category": "simple", "imports": ["from nose.tools import *", "import networkx as nx", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_multigraph_with_cutoff", "data": "def test_all_simple_paths_multigraph_with_cutoff():\n\tG = nx.MultiGraph([(1,2),(1,2),(1,10),(10,2)])\n\tpaths = nx.all_simple_paths(G,1,2, cutoff=1)\n\tassert_equal(list(list(p) for p in paths),[[1,2],[1,2]])\n\n", "description": null, "category": "simple", "imports": ["from nose.tools import *", "import networkx as nx", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_directed", "data": "def test_all_simple_paths_directed():\n\tG = nx.DiGraph()\n\tG.add_path([1,2,3])\n\tG.add_path([3,2,1])\n\tpaths = nx.all_simple_paths(G,1,3)\n\tassert_equal(list(list(p) for p in paths),[[1,2,3]])\n", "description": null, "category": "simple", "imports": ["from nose.tools import *", "import networkx as nx", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_all_simple_paths_empty", "data": "def test_all_simple_paths_empty():\n\tG = nx.path_graph(4)\n\tpaths = nx.all_simple_paths(G,0,3,cutoff=2)\n\tassert_equal(list(list(p) for p in paths),[])\n", "description": null, "category": "simple", "imports": ["from nose.tools import *", "import networkx as nx", "\tfrom itertools import permutations"]}, {"term": "def", "name": "hamiltonian_path", "data": "def hamiltonian_path(G,source):\n\tsource = next(G.nodes_iter())\n\tneighbors = set(G[source])-set([source])\n\tn = len(G)\n\tfor target in neighbors:\n\t\tfor path in nx.all_simple_paths(G,source,target):\n\t\t\tif len(path) == n:\n\t\t\t\tyield path\n", "description": null, "category": "simple", "imports": ["from nose.tools import *", "import networkx as nx", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_hamiltonian_path", "data": "def test_hamiltonian_path():\n\tfrom itertools import permutations\n\tG=nx.complete_graph(4)\n\tpaths = [list(p) for p in hamiltonian_path(G,0)]\n\texact = [[0]+list(p) for p in permutations([1,2,3],3) ]\n\tassert_equal(sorted(paths),sorted(exact))\n", "description": null, "category": "simple", "imports": ["from nose.tools import *", "import networkx as nx", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_cutoff_zero", "data": "def test_cutoff_zero():\n\tG = nx.complete_graph(4)\n\tpaths = nx.all_simple_paths(G,0,3,cutoff=0)\n\tassert_equal(list(list(p) for p in paths),[])\n\tpaths = nx.all_simple_paths(nx.MultiGraph(G),0,3,cutoff=0)\n\tassert_equal(list(list(p) for p in paths),[])\n", "description": null, "category": "simple", "imports": ["from nose.tools import *", "import networkx as nx", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_source_missing", "data": "def test_source_missing():\n\tG = nx.Graph()\n\tG.add_path([1,2,3])\n\tpaths = list(nx.all_simple_paths(nx.MultiGraph(G),0,3))\n", "description": null, "category": "simple", "imports": ["from nose.tools import *", "import networkx as nx", "\tfrom itertools import permutations"]}, {"term": "def", "name": "test_target_missing", "data": "def test_target_missing():\n\tG = nx.Graph()\n\tG.add_path([1,2,3])\n\tpaths = list(nx.all_simple_paths(nx.MultiGraph(G),1,4))\n", "description": null, "category": "simple", "imports": ["from nose.tools import *", "import networkx as nx", "\tfrom itertools import permutations"]}], [{"term": "class", "name": "TestLibraryInfo", "data": "class TestLibraryInfo(object):\n\tdef test_simple(self):\n\t\twith temppath('foo.ini') as path:\n\t\t\twith open(path,  'w') as f:\n\t\t\t\tf.write(simple)\n\t\t\tpkg = os.path.splitext(path)[0]\n\t\t\tout = read_config(pkg)\n\n\t\tassert_(out.cflags() == simple_d['cflags'])\n\t\tassert_(out.libs() == simple_d['libflags'])\n\t\tassert_(out.name == simple_d['name'])\n\t\tassert_(out.version == simple_d['version'])\n\n\tdef test_simple_variable(self):\n\t\twith temppath('foo.ini') as path:\n\t\t\twith open(path,  'w') as f:\n\t\t\t\tf.write(simple_variable)\n\t\t\tpkg = os.path.splitext(path)[0]\n\t\t\tout = read_config(pkg)\n\n\t\tassert_(out.cflags() == simple_variable_d['cflags'])\n\t\tassert_(out.libs() == simple_variable_d['libflags'])\n\t\tassert_(out.name == simple_variable_d['name'])\n\t\tassert_(out.version == simple_variable_d['version'])\n\t\tout.vars['prefix'] = '/Users/david'\n\t\tassert_(out.cflags() == '-I/Users/david/include')\n", "description": null, "category": "simple", "imports": ["from __future__ import division, absolute_import, print_function", "import os", "from numpy.distutils.npy_pkg_config import read_config, parse_flags", "from numpy.testing import temppath, assert_"]}, {"term": "class", "name": "TestParseFlags", "data": "class TestParseFlags(object):\n\tdef test_simple_cflags(self):\n\t\td = parse_flags(\"-I/usr/include\")\n\t\tassert_(d['include_dirs'] == ['/usr/include'])\n\n\t\td = parse_flags(\"-I/usr/include -DFOO\")\n\t\tassert_(d['include_dirs'] == ['/usr/include'])\n\t\tassert_(d['macros'] == ['FOO'])\n\n\t\td = parse_flags(\"-I /usr/include -DFOO\")\n\t\tassert_(d['include_dirs'] == ['/usr/include'])\n\t\tassert_(d['macros'] == ['FOO'])\n\n\tdef test_simple_lflags(self):\n\t\td = parse_flags(\"-L/usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tassert_(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tassert_(d['libraries'] == ['foo', 'bar'])\n\n\t\td = parse_flags(\"-L /usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tassert_(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tassert_(d['libraries'] == ['foo', 'bar'])\n", "description": null, "category": "simple", "imports": ["from __future__ import division, absolute_import, print_function", "import os", "from numpy.distutils.npy_pkg_config import read_config, parse_flags", "from numpy.testing import temppath, assert_"]}], [{"term": "def", "name": "simple", "data": "def simple(e):\n\tcode = e.code\n\n\tif code.endswith('Exception'):\n\t\tcode = code.rstrip('Exception')\n\n\ttry:\n\t\t# Dynamically get the error class.\n\t\tsimple_e = getattr(sys.modules[__name__], code)(e)\n\texcept AttributeError:\n\t\t# Return original exception on failure.\n\t\treturn e\n\n\treturn simple_e\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "SimpleException", "data": "class SimpleException(BotoServerError):\n\tdef __init__(self, e):\n\t\tsuper(SimpleException, self).__init__(e.status, e.reason, e.body)\n\t\tself.error_message = self.message\n\n\tdef __repr__(self):\n\t\treturn self.__class__.__name__ + ': ' + self.error_message\n\tdef __str__(self):\n\t\treturn self.__class__.__name__ + ': ' + self.error_message\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "ValidationError", "data": "class ValidationError(SimpleException): pass\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "Throttling", "data": "class Throttling(SimpleException): pass\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "SourceBundleDeletion", "data": "class SourceBundleDeletion(SimpleException): pass\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}], [{"term": "def", "name": "simple", "data": "def simple(e):\n\tcode = e.code\n\n\tif code.endswith('Exception'):\n\t\tcode = code.rstrip('Exception')\n\n\ttry:\n\t\t# Dynamically get the error class.\n\t\tsimple_e = getattr(sys.modules[__name__], code)(e)\n\texcept AttributeError:\n\t\t# Return original exception on failure.\n\t\treturn e\n\n\treturn simple_e\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "SimpleException", "data": "class SimpleException(BotoServerError):\n\tdef __init__(self, e):\n\t\tsuper(SimpleException, self).__init__(e.status, e.reason, e.body)\n\t\tself.error_message = self.message\n\n\tdef __repr__(self):\n\t\treturn self.__class__.__name__ + ': ' + self.error_message\n\tdef __str__(self):\n\t\treturn self.__class__.__name__ + ': ' + self.error_message\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "ValidationError", "data": "class ValidationError(SimpleException): pass\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "Throttling", "data": "class Throttling(SimpleException): pass\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "SourceBundleDeletion", "data": "class SourceBundleDeletion(SimpleException): pass\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}], [{"term": "def", "name": "simple", "data": "def simple(e):\n\tcode = e.code\n\n\tif code.endswith('Exception'):\n\t\tcode = code.rstrip('Exception')\n\n\ttry:\n\t\t# Dynamically get the error class.\n\t\tsimple_e = getattr(sys.modules[__name__], code)(e)\n\texcept AttributeError:\n\t\t# Return original exception on failure.\n\t\treturn e\n\n\treturn simple_e\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "SimpleException", "data": "class SimpleException(BotoServerError):\n\tdef __init__(self, e):\n\t\tsuper(SimpleException, self).__init__(e.status, e.reason, e.body)\n\t\tself.error_message = self.message\n\n\tdef __repr__(self):\n\t\treturn self.__class__.__name__ + ': ' + self.error_message\n\tdef __str__(self):\n\t\treturn self.__class__.__name__ + ': ' + self.error_message\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "ValidationError", "data": "class ValidationError(SimpleException): pass\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "Throttling", "data": "class Throttling(SimpleException): pass\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "SourceBundleDeletion", "data": "class SourceBundleDeletion(SimpleException): pass\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}], [{"term": "def", "name": "test_from_op_no_args", "data": "def test_from_op_no_args():\n\top = TealOp(Op.int, 1)\n\n\texpected = TealSimpleBlock([op])\n\n\tactual, _ = TealBlock.FromOp(op)\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["from .. import *"]}, {"term": "def", "name": "test_from_op_1_arg", "data": "def test_from_op_1_arg():\n\top = TealOp(Op.pop)\n\targ_1 = Bytes(\"message\")\n\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.byte, \"\\\"message\\\"\"),\n\t\top\n\t])\n\n\tactual, _ = TealBlock.FromOp(op, arg_1)\n\tactual.addIncoming()\n\tactual = TealBlock.NormalizeBlocks(actual)\n\tactual.validate()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["from .. import *"]}, {"term": "def", "name": "test_from_op_2_args", "data": "def test_from_op_2_args():\n\top = TealOp(Op.app_global_put)\n\targ_1 = Bytes(\"key\")\n\targ_2 = Int(5)\n\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.byte, \"\\\"key\\\"\"),\n\t\tTealOp(Op.int, 5),\n\t\top\n\t])\n\n\tactual, _ = TealBlock.FromOp(op, arg_1, arg_2)\n\tactual.addIncoming()\n\tactual = TealBlock.NormalizeBlocks(actual)\n\tactual.validate()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["from .. import *"]}, {"term": "def", "name": "test_from_op_3_args", "data": "def test_from_op_3_args():\n\top = TealOp(Op.app_local_put)\n\targ_1 = Int(0)\n\targ_2 = Bytes(\"key\")\n\targ_3 = Int(1) + Int(2)\n\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.int, 0),\n\t\tTealOp(Op.byte, \"\\\"key\\\"\"),\n\t\tTealOp(Op.int, 1),\n\t\tTealOp(Op.int, 2),\n\t\tTealOp(Op.add),\n\t\top\n\t])\n\n\tactual, _ = TealBlock.FromOp(op, arg_1, arg_2, arg_3)\n\tactual.addIncoming()\n\tactual = TealBlock.NormalizeBlocks(actual)\n\tactual.validate()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["from .. import *"]}, {"term": "def", "name": "test_iterate_single", "data": "def test_iterate_single():\n\tblock = TealSimpleBlock([\n\t\tTealOp(Op.int, 1)\n\t])\n\n\tblocks = list(TealBlock.Iterate(block))\n\n\tassert blocks == [block]\n", "description": null, "category": "simple", "imports": ["from .. import *"]}, {"term": "def", "name": "test_iterate_sequence", "data": "def test_iterate_sequence():\n\tblock5 = TealSimpleBlock([TealOp(Op.int, 5)])\n\tblock4 = TealSimpleBlock([TealOp(Op.int, 4)])\n\tblock4.setNextBlock(block5)\n\tblock3 = TealSimpleBlock([TealOp(Op.int, 3)])\n\tblock3.setNextBlock(block4)\n\tblock2 = TealSimpleBlock([TealOp(Op.int, 2)])\n\tblock2.setNextBlock(block3)\n\tblock1 = TealSimpleBlock([TealOp(Op.int, 1)])\n\tblock1.setNextBlock(block2)\n\n\tblocks = list(TealBlock.Iterate(block1))\n\n\tassert blocks == [block1, block2, block3, block4, block5]\n", "description": null, "category": "simple", "imports": ["from .. import *"]}, {"term": "def", "name": "test_iterate_branch", "data": "def test_iterate_branch():\n\tblockTrue = TealSimpleBlock([TealOp(Op.byte, \"\\\"true\\\"\")])\n\tblockFalse = TealSimpleBlock([TealOp(Op.byte, \"\\\"false\\\"\")])\n\tblock = TealConditionalBlock([TealOp(Op.int, 1)])\n\tblock.setTrueBlock(blockTrue)\n\tblock.setFalseBlock(blockFalse)\n\n\tblocks = list(TealBlock.Iterate(block))\n\n\tassert blocks == [block, blockTrue, blockFalse]\n", "description": null, "category": "simple", "imports": ["from .. import *"]}, {"term": "def", "name": "test_iterate_multiple_branch", "data": "def test_iterate_multiple_branch():\n\tblockTrueTrue = TealSimpleBlock([TealOp(Op.byte, \"\\\"true true\\\"\")])\n\tblockTrueFalse = TealSimpleBlock([TealOp(Op.byte, \"\\\"true false\\\"\")])\n\tblockTrueBranch = TealConditionalBlock([])\n\tblockTrueBranch.setTrueBlock(blockTrueTrue)\n\tblockTrueBranch.setFalseBlock(blockTrueFalse)\n\tblockTrue = TealSimpleBlock([TealOp(Op.byte, \"\\\"true\\\"\")])\n\tblockTrue.setNextBlock(blockTrueBranch)\n\tblockFalse = TealSimpleBlock([TealOp(Op.byte, \"\\\"false\\\"\")])\n\tblock = TealConditionalBlock([TealOp(Op.int, 1)])\n\tblock.setTrueBlock(blockTrue)\n\tblock.setFalseBlock(blockFalse)\n\n\tblocks = list(TealBlock.Iterate(block))\n\n\tassert blocks == [block, blockTrue, blockFalse, blockTrueBranch, blockTrueTrue, blockTrueFalse]\n", "description": null, "category": "simple", "imports": ["from .. import *"]}, {"term": "def", "name": "test_iterate_branch_converge", "data": "def test_iterate_branch_converge():\n\tblockEnd = TealSimpleBlock([TealOp(Op.return_)])\n\tblockTrue = TealSimpleBlock([TealOp(Op.byte, \"\\\"true\\\"\")])\n\tblockTrue.setNextBlock(blockEnd)\n\tblockFalse = TealSimpleBlock([TealOp(Op.byte, \"\\\"false\\\"\")])\n\tblockFalse.setNextBlock(blockEnd)\n\tblock = TealConditionalBlock([TealOp(Op.int, 1)])\n\tblock.setTrueBlock(blockTrue)\n\tblock.setFalseBlock(blockFalse)\n\n\tblocks = list(TealBlock.Iterate(block))\n\n\tassert blocks == [block, blockTrue, blockFalse, blockEnd]\n", "description": null, "category": "simple", "imports": ["from .. import *"]}, {"term": "def", "name": "test_normalize_single", "data": "def test_normalize_single():\n\toriginal = TealSimpleBlock([\n\t\tTealOp(Op.int, 1)\n\t])\n\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.int, 1)\n\t])\n\n\toriginal.addIncoming()\n\tactual = TealBlock.NormalizeBlocks(original)\n\tactual.validate()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["from .. import *"]}, {"term": "def", "name": "test_normalize_sequence", "data": "def test_normalize_sequence():\n\tblock6 = TealSimpleBlock([])\n\tblock5 = TealSimpleBlock([TealOp(Op.int, 5)])\n\tblock5.setNextBlock(block6)\n\tblock4 = TealSimpleBlock([TealOp(Op.int, 4)])\n\tblock4.setNextBlock(block5)\n\tblock3 = TealSimpleBlock([TealOp(Op.int, 3)])\n\tblock3.setNextBlock(block4)\n\tblock2 = TealSimpleBlock([TealOp(Op.int, 2)])\n\tblock2.setNextBlock(block3)\n\tblock1 = TealSimpleBlock([TealOp(Op.int, 1)])\n\tblock1.setNextBlock(block2)\n\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.int, 1),\n\t\tTealOp(Op.int, 2),\n\t\tTealOp(Op.int, 3),\n\t\tTealOp(Op.int, 4),\n\t\tTealOp(Op.int, 5),\n\t])\n\n\tblock1.addIncoming()\n\tactual = TealBlock.NormalizeBlocks(block1)\n\tactual.validate()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["from .. import *"]}, {"term": "def", "name": "test_normalize_branch", "data": "def test_normalize_branch():\n\tblockTrueNext = TealSimpleBlock([TealOp(Op.int, 4)])\n\tblockTrue = TealSimpleBlock([TealOp(Op.byte, \"\\\"true\\\"\")])\n\tblockTrue.setNextBlock(blockTrueNext)\n\tblockFalse = TealSimpleBlock([TealOp(Op.byte, \"\\\"false\\\"\")])\n\tblockBranch = TealConditionalBlock([TealOp(Op.int, 1)])\n\tblockBranch.setTrueBlock(blockTrue)\n\tblockBranch.setFalseBlock(blockFalse)\n\toriginal = TealSimpleBlock([])\n\toriginal.setNextBlock(blockBranch)\n\n\texpectedTrue = TealSimpleBlock([\n\t\tTealOp(Op.byte, \"\\\"true\\\"\"),\n\t\tTealOp(Op.int, 4)\n\t])\n\texpectedFalse = TealSimpleBlock([\n\t\tTealOp(Op.byte, \"\\\"false\\\"\")\n\t])\n\texpected = TealConditionalBlock([TealOp(Op.int, 1)])\n\texpected.setTrueBlock(expectedTrue)\n\texpected.setFalseBlock(expectedFalse)\n\n\toriginal.addIncoming()\n\tactual = TealBlock.NormalizeBlocks(original)\n\tactual.validate()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["from .. import *"]}, {"term": "def", "name": "test_normalize_branch_converge", "data": "def test_normalize_branch_converge():\n\tblockEnd = TealSimpleBlock([])\n\tblockTrueNext = TealSimpleBlock([TealOp(Op.int, 4)])\n\tblockTrueNext.setNextBlock(blockEnd)\n\tblockTrue = TealSimpleBlock([TealOp(Op.byte, \"\\\"true\\\"\")])\n\tblockTrue.setNextBlock(blockTrueNext)\n\tblockFalse = TealSimpleBlock([TealOp(Op.byte, \"\\\"false\\\"\")])\n\tblockFalse.setNextBlock(blockEnd)\n\tblockBranch = TealConditionalBlock([TealOp(Op.int, 1)])\n\tblockBranch.setTrueBlock(blockTrue)\n\tblockBranch.setFalseBlock(blockFalse)\n\toriginal = TealSimpleBlock([])\n\toriginal.setNextBlock(blockBranch)\n\n\texpectedEnd = TealSimpleBlock([])\n\texpectedTrue = TealSimpleBlock([\n\t\tTealOp(Op.byte, \"\\\"true\\\"\"),\n\t\tTealOp(Op.int, 4)\n\t])\n\texpectedTrue.setNextBlock(expectedEnd)\n\texpectedFalse = TealSimpleBlock([\n\t\tTealOp(Op.byte, \"\\\"false\\\"\")\n\t])\n\texpectedFalse.setNextBlock(expectedEnd)\n\texpected = TealConditionalBlock([TealOp(Op.int, 1)])\n\texpected.setTrueBlock(expectedTrue)\n\texpected.setFalseBlock(expectedFalse)\n\n\toriginal.addIncoming()\n\tactual = TealBlock.NormalizeBlocks(original)\n\tactual.validate()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["from .. import *"]}], [{"term": "def", "name": "fswig_import_helper", "data": "\tdef swig_import_helper():\n\t\timport importlib\n\t\tpkg = __name__.rpartition('.')[0]\n\t\tmname = '.'.join((pkg, '_param_SimpleExtLink')).lstrip('.')\n\t\ttry:\n\t\t\treturn importlib.import_module(mname)\n\t\texcept ImportError:\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleExtLink')", "\t_param_SimpleExtLink = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleExtLink", "\t_param_SimpleExtLink = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleExtLink", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BasicExtLink", "import m5.internal.param_RubyController", "import m5.internal.param_RubySystem", "import m5.internal.param_SimpleMemory", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BasicRouter", "import m5.internal.param_BasicLink"]}, {"term": "def", "name": "fswig_import_helper", "data": "\tdef swig_import_helper():\n\t\tfrom os.path import dirname\n\t\timport imp\n\t\tfp = None\n\t\ttry:\n\t\t\tfp, pathname, description = imp.find_module('_param_SimpleExtLink', [dirname(__file__)])\n\t\texcept ImportError:\n\t\t\timport _param_SimpleExtLink\n\t\t\treturn _param_SimpleExtLink\n\t\ttry:\n\t\t\t_mod = imp.load_module('_param_SimpleExtLink', fp, pathname, description)\n\t\tfinally:\n\t\t\tif fp is not None:\n\t\t\t\tfp.close()\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleExtLink')", "\t_param_SimpleExtLink = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleExtLink", "\t_param_SimpleExtLink = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleExtLink", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BasicExtLink", "import m5.internal.param_RubyController", "import m5.internal.param_RubySystem", "import m5.internal.param_SimpleMemory", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BasicRouter", "import m5.internal.param_BasicLink"]}, {"term": "def", "name": "_swig_setattr_nondynamic", "data": "def _swig_setattr_nondynamic(self, class_type, name, value, static=1):\n\tif (name == \"thisown\"):\n\t\treturn self.this.own(value)\n\tif (name == \"this\"):\n\t\tif type(value).__name__ == 'SwigPyObject':\n\t\t\tself.__dict__[name] = value\n\t\t\treturn\n\tmethod = class_type.__swig_setmethods__.get(name, None)\n\tif method:\n\t\treturn method(self, value)\n\tif (not static):\n\t\tobject.__setattr__(self, name, value)\n\telse:\n\t\traise AttributeError(\"You cannot add attributes to %s\" % self)\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleExtLink')", "\t_param_SimpleExtLink = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleExtLink", "\t_param_SimpleExtLink = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleExtLink", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BasicExtLink", "import m5.internal.param_RubyController", "import m5.internal.param_RubySystem", "import m5.internal.param_SimpleMemory", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BasicRouter", "import m5.internal.param_BasicLink"]}, {"term": "def", "name": "_swig_setattr", "data": "def _swig_setattr(self, class_type, name, value):\n\treturn _swig_setattr_nondynamic(self, class_type, name, value, 0)\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleExtLink')", "\t_param_SimpleExtLink = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleExtLink", "\t_param_SimpleExtLink = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleExtLink", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BasicExtLink", "import m5.internal.param_RubyController", "import m5.internal.param_RubySystem", "import m5.internal.param_SimpleMemory", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BasicRouter", "import m5.internal.param_BasicLink"]}, {"term": "def", "name": "_swig_getattr", "data": "def _swig_getattr(self, class_type, name):\n\tif (name == \"thisown\"):\n\t\treturn self.this.own()\n\tmethod = class_type.__swig_getmethods__.get(name, None)\n\tif method:\n\t\treturn method(self)\n\traise AttributeError(\"'%s' object has no attribute '%s'\" % (class_type.__name__, name))\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleExtLink')", "\t_param_SimpleExtLink = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleExtLink", "\t_param_SimpleExtLink = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleExtLink", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BasicExtLink", "import m5.internal.param_RubyController", "import m5.internal.param_RubySystem", "import m5.internal.param_SimpleMemory", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BasicRouter", "import m5.internal.param_BasicLink"]}, {"term": "def", "name": "_swig_repr", "data": "def _swig_repr(self):\n\ttry:\n\t\tstrthis = \"proxy of \" + self.this.__repr__()\n\texcept __builtin__.Exception:\n\t\tstrthis = \"\"\n\treturn \"<%s.%s; %s >\" % (self.__class__.__module__, self.__class__.__name__, strthis,)\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleExtLink')", "\t_param_SimpleExtLink = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleExtLink", "\t_param_SimpleExtLink = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleExtLink", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BasicExtLink", "import m5.internal.param_RubyController", "import m5.internal.param_RubySystem", "import m5.internal.param_SimpleMemory", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BasicRouter", "import m5.internal.param_BasicLink"]}, {"term": "def", "name": "_swig_setattr_nondynamic_method", "data": "def _swig_setattr_nondynamic_method(set):\n\tdef set_attr(self, name, value):\n\t\tif (name == \"thisown\"):\n\t\t\treturn self.this.own(value)\n\t\tif hasattr(self, name) or (name == \"this\"):\n\t\t\tset(self, name, value)\n\t\telse:\n\t\t\traise AttributeError(\"You cannot add attributes to %s\" % self)\n\treturn set_attr\n\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleExtLink')", "\t_param_SimpleExtLink = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleExtLink", "\t_param_SimpleExtLink = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleExtLink", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BasicExtLink", "import m5.internal.param_RubyController", "import m5.internal.param_RubySystem", "import m5.internal.param_SimpleMemory", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BasicRouter", "import m5.internal.param_BasicLink"]}, {"term": "class", "name": "SimpleExtLink", "data": "class SimpleExtLink(m5.internal.param_BasicExtLink.BasicExtLink):\n\tthisown = _swig_property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc='The membership flag')\n\n\tdef __init__(self, *args, **kwargs):\n\t\traise AttributeError(\"No constructor defined - class is abstract\")\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleExtLink')", "\t_param_SimpleExtLink = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleExtLink", "\t_param_SimpleExtLink = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleExtLink", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BasicExtLink", "import m5.internal.param_RubyController", "import m5.internal.param_RubySystem", "import m5.internal.param_SimpleMemory", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BasicRouter", "import m5.internal.param_BasicLink"]}, {"term": "class", "name": "SimpleExtLinkParams", "data": "class SimpleExtLinkParams(m5.internal.param_BasicExtLink.BasicExtLinkParams):\n\tthisown = _swig_property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc='The membership flag')\n\t__repr__ = _swig_repr\n\n\tdef create(self):\n\t\treturn _param_SimpleExtLink.SimpleExtLinkParams_create(self)\n\n\tdef __init__(self):\n\t\tthis = _param_SimpleExtLink.new_SimpleExtLinkParams()\n\t\ttry:\n\t\t\tself.this.append(this)\n\t\texcept __builtin__.Exception:\n\t\t\tself.this = this\n\t__swig_destroy__ = _param_SimpleExtLink.delete_SimpleExtLinkParams\n", "description": null, "category": "simple", "imports": ["from sys import version_info as _swig_python_version_info", "\tdef swig_import_helper():", "\t\timport importlib", "\t\t\treturn importlib.import_module(mname)", "\t\t\treturn importlib.import_module('_param_SimpleExtLink')", "\t_param_SimpleExtLink = swig_import_helper()", "\tdel swig_import_helper", "\tdef swig_import_helper():", "\t\tfrom os.path import dirname", "\t\timport imp", "\t\t\timport _param_SimpleExtLink", "\t_param_SimpleExtLink = swig_import_helper()", "\tdel swig_import_helper", "\timport _param_SimpleExtLink", "\timport builtins as __builtin__", "\timport __builtin__", "import m5.internal.param_BasicExtLink", "import m5.internal.param_RubyController", "import m5.internal.param_RubySystem", "import m5.internal.param_SimpleMemory", "import m5.internal.param_AbstractMemory", "import m5.internal.param_MemObject", "import m5.internal.param_ClockedObject", "import m5.internal.param_ClockDomain", "import m5.internal.param_SimObject", "import m5.internal.drain", "import m5.internal.serialize", "import m5.internal.param_System", "import m5.internal.enum_MemoryMode", "import m5.internal.AddrRange_vector", "import m5.internal.AbstractMemory_vector", "import m5.internal.SimObject_vector", "import m5.internal.param_ThermalModel", "import m5.internal.param_BasicRouter", "import m5.internal.param_BasicLink"]}], [], [{"term": "class", "name": "VocabItem", "data": "class VocabItem(object):\n\tdef __init__(self, token, value):\n\t\tself.token = token\n\t\tself.value = value\n\n", "description": null, "category": "simple", "imports": ["# from plone import api", "from popolo.contenttypes import _", "from plone.dexterity.interfaces import IDexterityContent", "from zope.globalrequest import getRequest", "from zope.interface import implementer", "from zope.schema.interfaces import IVocabularyFactory", "from zope.schema.vocabulary import SimpleTerm", "from zope.schema.vocabulary import SimpleVocabulary"]}, {"term": "class", "name": "GeonameFeaturecodesVocab", "data": "class GeonameFeaturecodesVocab(object):\n\t\"\"\"\n\t\"\"\"\n\n\tdef __call__(self, context):\n\t\t# Just an example list of content for our vocabulary,\n\t\t# this can be any static or dynamic data, a catalog result for example.\n\t\tgeoname_featurecodes = SimpleVocabulary(\n\t\t\t[\n\t\t\t\tSimpleTerm(value=(u'A.ADM1'), title=_(u'first-order administrative division')),\n\t\t\t\tSimpleTerm(value=(u'A.ADM1H'), title=_(u'historical first-order administrative division')),\n\t\t\t\tSimpleTerm(value=(u'A.ADM2'), title=_(u'second-order administrative division')),\n\t\t\t\tSimpleTerm(value=(u'A.ADM2H'), title=_(u'historical second-order administrative division')),\n\t\t\t\tSimpleTerm(value=(u'A.ADM3'), title=_(u'third-order administrative division')),\n\t\t\t\tSimpleTerm(value=(u'A.ADM3H'), title=_(u'historical third-order administrative division')),\n\t\t\t\tSimpleTerm(value=(u'A.ADM4'), title=_(u'fourth-order administrative division')),\n\t\t\t\tSimpleTerm(value=(u'A.ADM4H'), title=_(u'historical fourth-order administrative division')),\n\t\t\t\tSimpleTerm(value=(u'A.ADM5'), title=_(u'fifth-order administrative division')),\n\t\t\t\tSimpleTerm(value=(u'A.ADM5H'), title=_(u'historical fifth-order administrative division')),\n\t\t\t\tSimpleTerm(value=(u'A.ADMD'), title=_(u'administrative division')),\n\t\t\t\tSimpleTerm(value=(u'A.ADMDH'), title=_(u'historical administrative division')),\n\t\t\t\tSimpleTerm(value=(u'A.LTER'), title=_(u'leased area')),\n\t\t\t\tSimpleTerm(value=(u'A.PCL'), title=_(u'political entity')),\n\t\t\t\tSimpleTerm(value=(u'A.PCLD'), title=_(u'dependent political entity')),\n\t\t\t\tSimpleTerm(value=(u'A.PCLF'), title=_(u'freely associated state')),\n\t\t\t\tSimpleTerm(value=(u'A.PCLH'), title=_(u'historical political entity')),\n\t\t\t\tSimpleTerm(value=(u'A.PCLI'), title=_(u'independent political entity')),\n\t\t\t\tSimpleTerm(value=(u'A.PCLIX'), title=_(u'section of independent political entity')),\n\t\t\t\tSimpleTerm(value=(u'A.PCLS'), title=_(u'semi-independent political entity')),\n\t\t\t\tSimpleTerm(value=(u'A.PRSH'), title=_(u'parish')),\n\t\t\t\tSimpleTerm(value=(u'A.TERR'), title=_(u'territory')),\n\t\t\t\tSimpleTerm(value=(u'A.ZN'), title=_(u'zone')),\n\t\t\t\tSimpleTerm(value=(u'A.ZNB'), title=_(u'buffer zone')),\n\t\t\t\tSimpleTerm(value=(u'H.AIRS'), title=_(u'seaplane landing area')),\n\t\t\t\tSimpleTerm(value=(u'H.ANCH'), title=_(u'anchorage')),\n\t\t\t\tSimpleTerm(value=(u'H.BAY'), title=_(u'bay')),\n\t\t\t\tSimpleTerm(value=(u'H.BAYS'), title=_(u'bays')),\n\t\t\t\tSimpleTerm(value=(u'H.BGHT'), title=_(u'bight(s)')),\n\t\t\t\tSimpleTerm(value=(u'H.BNK'), title=_(u'bank(s)')),\n\t\t\t\tSimpleTerm(value=(u'H.BNKR'), title=_(u'stream bank')),\n\t\t\t\tSimpleTerm(value=(u'H.BNKX'), title=_(u'section of bank')),\n\t\t\t\tSimpleTerm(value=(u'H.BOG'), title=_(u'bog(s)')),\n\t\t\t\tSimpleTerm(value=(u'H.CAPG'), title=_(u'icecap')),\n\t\t\t\tSimpleTerm(value=(u'H.CHN'), title=_(u'channel')),\n\t\t\t\tSimpleTerm(value=(u'H.CHNL'), title=_(u'lake channel(s)')),\n\t\t\t\tSimpleTerm(value=(u'H.CHNM'), title=_(u'marine channel')),\n\t\t\t\tSimpleTerm(value=(u'H.CHNN'), title=_(u'navigation channel')),\n\t\t\t\tSimpleTerm(value=(u'H.CNFL'), title=_(u'confluence')),\n\t\t\t\tSimpleTerm(value=(u'H.CNL'), title=_(u'canal')),\n\t\t\t\tSimpleTerm(value=(u'H.CNLA'), title=_(u'aqueduct')),\n\t\t\t\tSimpleTerm(value=(u'H.CNLB'), title=_(u'canal bend')),\n\t\t\t\tSimpleTerm(value=(u'H.CNLD'), title=_(u'drainage canal')),\n\t\t\t\tSimpleTerm(value=(u'H.CNLI'), title=_(u'irrigation canal')),\n\t\t\t\tSimpleTerm(value=(u'H.CNLN'), title=_(u'navigation canal(s)')),\n\t\t\t\tSimpleTerm(value=(u'H.CNLQ'), title=_(u'abandoned canal')),\n\t\t\t\tSimpleTerm(value=(u'H.CNLSB'), title=_(u'underground irrigation canal(s)')),\n\t\t\t\tSimpleTerm(value=(u'H.CNLX'), title=_(u'section of canal')),\n\t\t\t\tSimpleTerm(value=(u'H.COVE'), title=_(u'cove(s)')),\n\t\t\t\tSimpleTerm(value=(u'H.CRKT'), title=_(u'tidal creek(s)')),\n\t\t\t\tSimpleTerm(value=(u'H.CRNT'), title=_(u'current')),\n\t\t\t\tSimpleTerm(value=(u'H.CUTF'), title=_(u'cutoff')),\n\t\t\t\tSimpleTerm(value=(u'H.DCK'), title=_(u'dock(s)')),\n\t\t\t\tSimpleTerm(value=(u'H.DCKB'), title=_(u'docking basin')),\n\t\t\t\tSimpleTerm(value=(u'H.DOMG'), title=_(u'icecap dome')),\n\t\t\t\tSimpleTerm(value=(u'H.DPRG'), title=_(u'icecap depression')),\n\t\t\t\tSimpleTerm(value=(u'H.DTCH'), title=_(u'ditch')),\n\t\t\t\tSimpleTerm(value=(u'H.DTCHD'), title=_(u'drainage ditch')),\n\t\t\t\tSimpleTerm(value=(u'H.DTCHI'), title=_(u'irrigation ditch')),\n\t\t\t\tSimpleTerm(value=(u'H.DTCHM'), title=_(u'ditch mouth(s)')),\n\t\t\t\tSimpleTerm(value=(u'H.ESTY'), title=_(u'estuary')),\n\t\t\t\tSimpleTerm(value=(u'H.FISH'), title=_(u'fishing area')),\n\t\t\t\tSimpleTerm(value=(u'H.FJD'), title=_(u'fjord')),\n\t\t\t\tSimpleTerm(value=(u'H.FJDS'), title=_(u'fjords')),\n\t\t\t\tSimpleTerm(value=(u'H.FLLS'), title=_(u'waterfall(s)')),\n\t\t\t\tSimpleTerm(value=(u'H.FLLSX'), title=_(u'section of waterfall(s)')),\n\t\t\t\tSimpleTerm(value=(u'H.FLTM'), title=_(u'mud flat(s)')),\n\t\t\t\tSimpleTerm(value=(u'H.FLTT'), title=_(u'tidal flat(s)')),\n\t\t\t\tSimpleTerm(value=(u'H.GLCR'), title=_(u'glacier(s)')),\n\t\t\t\tSimpleTerm(value=(u'H.GULF'), title=_(u'gulf')),\n\t\t\t\tSimpleTerm(value=(u'H.GYSR'), title=_(u'geyser')),\n\t\t\t\tSimpleTerm(value=(u'H.HBR'), title=_(u'harbor(s)')),\n\t\t\t\tSimpleTerm(value=(u'H.HBRX'), title=_(u'section of harbor')),\n\t\t\t\tSimpleTerm(value=(u'H.INLT'), title=_(u'inlet')),\n\t\t\t\tSimpleTerm(value=(u'H.INLTQ'), title=_(u'former inlet')),\n\t\t\t\tSimpleTerm(value=(u'H.LBED'), title=_(u'lake bed(s)')),\n\t\t\t\tSimpleTerm(value=(u'H.LGN'), title=_(u'lagoon')),\n\t\t\t\tSimpleTerm(value=(u'H.LGNS'), title=_(u'lagoons')),\n\t\t\t\tSimpleTerm(value=(u'H.LGNX'), title=_(u'section of lagoon')),\n\t\t\t\tSimpleTerm(value=(u'H.LK'), title=_(u'lake')),\n\t\t\t\tSimpleTerm(value=(u'H.LKC'), title=_(u'crater lake')),\n\t\t\t\tSimpleTerm(value=(u'H.LKI'), title=_(u'intermittent lake')),\n\t\t\t\tSimpleTerm(value=(u'H.LKN'), title=_(u'salt lake')),\n\t\t\t\tSimpleTerm(value=(u'H.LKNI'), title=_(u'intermittent salt lake')),\n\t\t\t\tSimpleTerm(value=(u'H.LKO'), title=_(u'oxbow lake')),\n\t\t\t\tSimpleTerm(value=(u'H.LKOI'), title=_(u'intermittent oxbow lake')),\n\t\t\t\tSimpleTerm(value=(u'H.LKS'), title=_(u'lakes')),\n\t\t\t\tSimpleTerm(value=(u'H.LKSB'), title=_(u'underground lake')),\n\t\t\t\tSimpleTerm(value=(u'H.LKSC'), title=_(u'crater lakes')),\n\t\t\t\tSimpleTerm(value=(u'H.LKSI'), title=_(u'intermittent lakes')),\n\t\t\t\tSimpleTerm(value=(u'H.LKSN'), title=_(u'salt lakes')),\n\t\t\t\tSimpleTerm(value=(u'H.LKSNI'), title=_(u'intermittent salt lakes')),\n\t\t\t\tSimpleTerm(value=(u'H.LKX'), title=_(u'section of lake')),\n\t\t\t\tSimpleTerm(value=(u'H.MFGN'), title=_(u'salt evaporation ponds')),\n\t\t\t\tSimpleTerm(value=(u'H.MGV'), title=_(u'mangrove swamp')),\n\t\t\t\tSimpleTerm(value=(u'H.MOOR'), title=_(u'moor(s)')),\n\t\t\t\tSimpleTerm(value=(u'H.MRSH'), title=_(u'marsh(es)')),\n\t\t\t\tSimpleTerm(value=(u'H.MRSHN'), title=_(u'salt marsh')),\n\t\t\t\tSimpleTerm(value=(u'H.NRWS'), title=_(u'narrows')),\n\t\t\t\tSimpleTerm(value=(u'H.OCN'), title=_(u'ocean')),\n\t\t\t\tSimpleTerm(value=(u'H.OVF'), title=_(u'overfalls')),\n\t\t\t\tSimpleTerm(value=(u'H.PND'), title=_(u'pond')),\n\t\t\t\tSimpleTerm(value=(u'H.PNDI'), title=_(u'intermittent pond')),\n\t\t\t\tSimpleTerm(value=(u'H.PNDN'), title=_(u'salt pond')),\n\t\t\t\tSimpleTerm(value=(u'H.PNDNI'), title=_(u'intermittent salt pond(s)')),\n\t\t\t\tSimpleTerm(value=(u'H.PNDS'), title=_(u'ponds')),\n\t\t\t\tSimpleTerm(value=(u'H.PNDSF'), title=_(u'fishponds')),\n\t\t\t\tSimpleTerm(value=(u'H.PNDSI'), title=_(u'intermittent ponds')),\n\t\t\t\tSimpleTerm(value=(u'H.PNDSN'), title=_(u'salt ponds')),\n\t\t\t\tSimpleTerm(value=(u'H.POOL'), title=_(u'pool(s)')),\n\t\t\t\tSimpleTerm(value=(u'H.POOLI'), title=_(u'intermittent pool')),\n\t\t\t\tSimpleTerm(value=(u'H.RCH'), title=_(u'reach')),\n\t\t\t\tSimpleTerm(value=(u'H.RDGG'), title=_(u'icecap ridge')),\n\t\t\t\tSimpleTerm(value=(u'H.RDST'), title=_(u'roadstead')),\n\t\t\t\tSimpleTerm(value=(u'H.RF'), title=_(u'reef(s)')),\n\t\t\t\tSimpleTerm(value=(u'H.RFC'), title=_(u'coral reef(s)')),\n\t\t\t\tSimpleTerm(value=(u'H.RFX'), title=_(u'section of reef')),\n\t\t\t\tSimpleTerm(value=(u'H.RPDS'), title=_(u'rapids')),\n\t\t\t\tSimpleTerm(value=(u'H.RSV'), title=_(u'reservoir(s)')),\n\t\t\t\tSimpleTerm(value=(u'H.RSVI'), title=_(u'intermittent reservoir')),\n\t\t\t\tSimpleTerm(value=(u'H.RSVT'), title=_(u'water tank')),\n\t\t\t\tSimpleTerm(value=(u'H.RVN'), title=_(u'ravine(s)')),\n\t\t\t\tSimpleTerm(value=(u'H.SBKH'), title=_(u'sabkha(s)')),\n\t\t\t\tSimpleTerm(value=(u'H.SD'), title=_(u'sound')),\n\t\t\t\tSimpleTerm(value=(u'H.SEA'), title=_(u'sea')),\n\t\t\t\tSimpleTerm(value=(u'H.SHOL'), title=_(u'shoal(s)')),\n\t\t\t\tSimpleTerm(value=(u'H.SILL'), title=_(u'sill')),\n\t\t\t\tSimpleTerm(value=(u'H.SPNG'), title=_(u'spring(s)')),\n\t\t\t\tSimpleTerm(value=(u'H.SPNS'), title=_(u'sulphur spring(s)')),\n\t\t\t\tSimpleTerm(value=(u'H.SPNT'), title=_(u'hot spring(s)')),\n\t\t\t\tSimpleTerm(value=(u'H.STM'), title=_(u'stream')),\n\t\t\t\tSimpleTerm(value=(u'H.STMA'), title=_(u'anabranch')),\n\t\t\t\tSimpleTerm(value=(u'H.STMB'), title=_(u'stream bend')),\n\t\t\t\tSimpleTerm(value=(u'H.STMC'), title=_(u'canalized stream')),\n\t\t\t\tSimpleTerm(value=(u'H.STMD'), title=_(u'distributary(-ies)')),\n\t\t\t\tSimpleTerm(value=(u'H.STMH'), title=_(u'headwaters')),\n\t\t\t\tSimpleTerm(value=(u'H.STMI'), title=_(u'intermittent stream')),\n\t\t\t\tSimpleTerm(value=(u'H.STMIX'), title=_(u'section of intermittent stream')),\n\t\t\t\tSimpleTerm(value=(u'H.STMM'), title=_(u'stream mouth(s)')),\n\t\t\t\tSimpleTerm(value=(u'H.STMQ'), title=_(u'abandoned watercourse')),\n\t\t\t\tSimpleTerm(value=(u'H.STMS'), title=_(u'streams')),\n\t\t\t\tSimpleTerm(value=(u'H.STMSB'), title=_(u'lost river')),\n\t\t\t\tSimpleTerm(value=(u'H.STMX'), title=_(u'section of stream')),\n\t\t\t\tSimpleTerm(value=(u'H.STRT'), title=_(u'strait')),\n\t\t\t\tSimpleTerm(value=(u'H.SWMP'), title=_(u'swamp')),\n\t\t\t\tSimpleTerm(value=(u'H.SYSI'), title=_(u'irrigation system')),\n\t\t\t\tSimpleTerm(value=(u'H.TNLC'), title=_(u'canal tunnel')),\n\t\t\t\tSimpleTerm(value=(u'H.WAD'), title=_(u'wadi')),\n\t\t\t\tSimpleTerm(value=(u'H.WADB'), title=_(u'wadi bend')),\n\t\t\t\tSimpleTerm(value=(u'H.WADJ'), title=_(u'wadi junction')),\n\t\t\t\tSimpleTerm(value=(u'H.WADM'), title=_(u'wadi mouth')),\n\t\t\t\tSimpleTerm(value=(u'H.WADS'), title=_(u'wadies')),\n\t\t\t\tSimpleTerm(value=(u'H.WADX'), title=_(u'section of wadi')),\n\t\t\t\tSimpleTerm(value=(u'H.WHRL'), title=_(u'whirlpool')),\n\t\t\t\tSimpleTerm(value=(u'H.WLL'), title=_(u'well')),\n\t\t\t\tSimpleTerm(value=(u'H.WLLQ'), title=_(u'abandoned well')),\n\t\t\t\tSimpleTerm(value=(u'H.WLLS'), title=_(u'wells')),\n\t\t\t\tSimpleTerm(value=(u'H.WTLD'), title=_(u'wetland')),\n\t\t\t\tSimpleTerm(value=(u'H.WTLDI'), title=_(u'intermittent wetland')),\n\t\t\t\tSimpleTerm(value=(u'H.WTRC'), title=_(u'watercourse')),\n\t\t\t\tSimpleTerm(value=(u'H.WTRH'), title=_(u'waterhole(s)')),\n\t\t\t\tSimpleTerm(value=(u'L.AGRC'), title=_(u'agricultural colony')),\n\t\t\t\tSimpleTerm(value=(u'L.AMUS'), title=_(u'amusement park')),\n\t\t\t\tSimpleTerm(value=(u'L.AREA'), title=_(u'area')),\n\t\t\t\tSimpleTerm(value=(u'L.BSND'), title=_(u'drainage basin')),\n\t\t\t\tSimpleTerm(value=(u'L.BSNP'), title=_(u'petroleum basin')),\n\t\t\t\tSimpleTerm(value=(u'L.BTL'), title=_(u'battlefield')),\n\t\t\t\tSimpleTerm(value=(u'L.CLG'), title=_(u'clearing')),\n\t\t\t\tSimpleTerm(value=(u'L.CMN'), title=_(u'common')),\n\t\t\t\tSimpleTerm(value=(u'L.CNS'), title=_(u'concession area')),\n\t\t\t\tSimpleTerm(value=(u'L.COLF'), title=_(u'coalfield')),\n\t\t\t\tSimpleTerm(value=(u'L.CONT'), title=_(u'continent')),\n\t\t\t\tSimpleTerm(value=(u'L.CST'), title=_(u'coast')),\n\t\t\t\tSimpleTerm(value=(u'L.CTRB'), title=_(u'business center')),\n\t\t\t\tSimpleTerm(value=(u'L.DEVH'), title=_(u'housing development')),\n\t\t\t\tSimpleTerm(value=(u'L.FLD'), title=_(u'field(s)')),\n\t\t\t\tSimpleTerm(value=(u'L.FLDI'), title=_(u'irrigated field(s)')),\n\t\t\t\tSimpleTerm(value=(u'L.GASF'), title=_(u'gasfield')),\n\t\t\t\tSimpleTerm(value=(u'L.GRAZ'), title=_(u'grazing area')),\n\t\t\t\tSimpleTerm(value=(u'L.GVL'), title=_(u'gravel area')),\n\t\t\t\tSimpleTerm(value=(u'L.INDS'), title=_(u'industrial area')),\n\t\t\t\tSimpleTerm(value=(u'L.LAND'), title=_(u'arctic land')),\n\t\t\t\tSimpleTerm(value=(u'L.LCTY'), title=_(u'locality')),\n\t\t\t\tSimpleTerm(value=(u'L.MILB'), title=_(u'military base')),\n\t\t\t\tSimpleTerm(value=(u'L.MNA'), title=_(u'mining area')),\n\t\t\t\tSimpleTerm(value=(u'L.MVA'), title=_(u'maneuver area')),\n\t\t\t\tSimpleTerm(value=(u'L.NVB'), title=_(u'naval base')),\n\t\t\t\tSimpleTerm(value=(u'L.OAS'), title=_(u'oasis(-es)')),\n\t\t\t\tSimpleTerm(value=(u'L.OILF'), title=_(u'oilfield')),\n\t\t\t\tSimpleTerm(value=(u'L.PEAT'), title=_(u'peat cutting area')),\n\t\t\t\tSimpleTerm(value=(u'L.PRK'), title=_(u'park')),\n\t\t\t\tSimpleTerm(value=(u'L.PRT'), title=_(u'port')),\n\t\t\t\tSimpleTerm(value=(u'L.QCKS'), title=_(u'quicksand')),\n\t\t\t\tSimpleTerm(value=(u'L.RES'), title=_(u'reserve')),\n\t\t\t\tSimpleTerm(value=(u'L.RESA'), title=_(u'agricultural reserve')),\n\t\t\t\tSimpleTerm(value=(u'L.RESF'), title=_(u'forest reserve')),\n\t\t\t\tSimpleTerm(value=(u'L.RESH'), title=_(u'hunting reserve')),\n\t\t\t\tSimpleTerm(value=(u'L.RESN'), title=_(u'nature reserve')),\n\t\t\t\tSimpleTerm(value=(u'L.RESP'), title=_(u'palm tree reserve')),\n\t\t\t\tSimpleTerm(value=(u'L.RESV'), title=_(u'reservation')),\n\t\t\t\tSimpleTerm(value=(u'L.RESW'), title=_(u'wildlife reserve')),\n\t\t\t\tSimpleTerm(value=(u'L.RGN'), title=_(u'region')),\n\t\t\t\tSimpleTerm(value=(u'L.RGNE'), title=_(u'economic region')),\n\t\t\t\tSimpleTerm(value=(u'L.RGNH'), title=_(u'historical region')),\n\t\t\t\tSimpleTerm(value=(u'L.RGNL'), title=_(u'lake region')),\n\t\t\t\tSimpleTerm(value=(u'L.RNGA'), title=_(u'artillery range')),\n\t\t\t\tSimpleTerm(value=(u'L.SALT'), title=_(u'salt area')),\n\t\t\t\tSimpleTerm(value=(u'L.SNOW'), title=_(u'snowfield')),\n\t\t\t\tSimpleTerm(value=(u'L.TRB'), title=_(u'tribal area')),\n\t\t\t\tSimpleTerm(value=(u'P.PPL'), title=_(u'populated place')),\n\t\t\t\tSimpleTerm(value=(u'P.PPLA'), title=_(u'seat of a first-order administrative division')),\n\t\t\t\tSimpleTerm(value=(u'P.PPLA2'), title=_(u'seat of a second-order administrative division')),\n\t\t\t\tSimpleTerm(value=(u'P.PPLA3'), title=_(u'seat of a third-order administrative division')),\n\t\t\t\tSimpleTerm(value=(u'P.PPLA4'), title=_(u'seat of a fourth-order administrative division')),\n\t\t\t\tSimpleTerm(value=(u'P.PPLA5'), title=_(u'seat of a fifth-order administrative division')),\n\t\t\t\tSimpleTerm(value=(u'P.PPLC'), title=_(u'capital of a political entity')),\n\t\t\t\tSimpleTerm(value=(u'P.PPLCH'), title=_(u'historical capital of a political entity')),\n\t\t\t\tSimpleTerm(value=(u'P.PPLF'), title=_(u'farm village')),\n\t\t\t\tSimpleTerm(value=(u'P.PPLG'), title=_(u'seat of government of a political entity')),\n\t\t\t\tSimpleTerm(value=(u'P.PPLH'), title=_(u'historical populated place')),\n\t\t\t\tSimpleTerm(value=(u'P.PPLL'), title=_(u'populated locality')),\n\t\t\t\tSimpleTerm(value=(u'P.PPLQ'), title=_(u'abandoned populated place')),\n\t\t\t\tSimpleTerm(value=(u'P.PPLR'), title=_(u'religious populated place')),\n\t\t\t\tSimpleTerm(value=(u'P.PPLS'), title=_(u'populated places')),\n\t\t\t\tSimpleTerm(value=(u'P.PPLW'), title=_(u'destroyed populated place')),\n\t\t\t\tSimpleTerm(value=(u'P.PPLX'), title=_(u'section of populated place')),\n\t\t\t\tSimpleTerm(value=(u'P.STLMT'), title=_(u'israeli settlement')),\n\t\t\t\tSimpleTerm(value=(u'R.CSWY'), title=_(u'causeway')),\n\t\t\t\tSimpleTerm(value=(u'R.OILP'), title=_(u'oil pipeline')),\n\t\t\t\tSimpleTerm(value=(u'R.PRMN'), title=_(u'promenade')),\n\t\t\t\tSimpleTerm(value=(u'R.PTGE'), title=_(u'portage')),\n\t\t\t\tSimpleTerm(value=(u'R.RD'), title=_(u'road')),\n\t\t\t\tSimpleTerm(value=(u'R.RDA'), title=_(u'ancient road')),\n\t\t\t\tSimpleTerm(value=(u'R.RDB'), title=_(u'road bend')),\n\t\t\t\tSimpleTerm(value=(u'R.RDCUT'), title=_(u'road cut')),\n\t\t\t\tSimpleTerm(value=(u'R.RDJCT'), title=_(u'road junction')),\n\t\t\t\tSimpleTerm(value=(u'R.RJCT'), title=_(u'railroad junction')),\n\t\t\t\tSimpleTerm(value=(u'R.RR'), title=_(u'railroad')),\n\t\t\t\tSimpleTerm(value=(u'R.RRQ'), title=_(u'abandoned railroad')),\n\t\t\t\tSimpleTerm(value=(u'R.RTE'), title=_(u'caravan route')),\n\t\t\t\tSimpleTerm(value=(u'R.RYD'), title=_(u'railroad yard')),\n\t\t\t\tSimpleTerm(value=(u'R.ST'), title=_(u'street')),\n\t\t\t\tSimpleTerm(value=(u'R.STKR'), title=_(u'stock route')),\n\t\t\t\tSimpleTerm(value=(u'R.TNL'), title=_(u'tunnel')),\n\t\t\t\tSimpleTerm(value=(u'R.TNLN'), title=_(u'natural tunnel')),\n\t\t\t\tSimpleTerm(value=(u'R.TNLRD'), title=_(u'road tunnel')),\n\t\t\t\tSimpleTerm(value=(u'R.TNLRR'), title=_(u'railroad tunnel')),\n\t\t\t\tSimpleTerm(value=(u'R.TNLS'), title=_(u'tunnels')),\n\t\t\t\tSimpleTerm(value=(u'R.TRL'), title=_(u'trail')),\n\t\t\t\tSimpleTerm(value=(u'S.ADMF'), title=_(u'administrative facility')),\n\t\t\t\tSimpleTerm(value=(u'S.AGRF'), title=_(u'agricultural facility')),\n\t\t\t\tSimpleTerm(value=(u'S.AIRB'), title=_(u'airbase')),\n\t\t\t\tSimpleTerm(value=(u'S.AIRF'), title=_(u'airfield')),\n\t\t\t\tSimpleTerm(value=(u'S.AIRH'), title=_(u'heliport')),\n\t\t\t\tSimpleTerm(value=(u'S.AIRP'), title=_(u'airport')),\n\t\t\t\tSimpleTerm(value=(u'S.AIRQ'), title=_(u'abandoned airfield')),\n\t\t\t\tSimpleTerm(value=(u'S.AIRT'), title=_(u'terminal')),\n\t\t\t\tSimpleTerm(value=(u'S.AMTH'), title=_(u'amphitheater')),\n\t\t\t\tSimpleTerm(value=(u'S.ANS'), title=_(u'archaeological/prehistoric site')),\n\t\t\t\tSimpleTerm(value=(u'S.AQC'), title=_(u'aquaculture facility')),\n\t\t\t\tSimpleTerm(value=(u'S.ARCH'), title=_(u'arch')),\n\t\t\t\tSimpleTerm(value=(u'S.ARCHV'), title=_(u'archive')),\n\t\t\t\tSimpleTerm(value=(u'S.ART'), title=_(u'piece of art')),\n\t\t\t\tSimpleTerm(value=(u'S.ASTR'), title=_(u'astronomical station')),\n\t\t\t\tSimpleTerm(value=(u'S.ASYL'), title=_(u'asylum')),\n\t\t\t\tSimpleTerm(value=(u'S.ATHF'), title=_(u'athletic field')),\n\t\t\t\tSimpleTerm(value=(u'S.ATM'), title=_(u'automatic teller machine')),\n\t\t\t\tSimpleTerm(value=(u'S.BANK'), title=_(u'bank')),\n\t\t\t\tSimpleTerm(value=(u'S.BCN'), title=_(u'beacon')),\n\t\t\t\tSimpleTerm(value=(u'S.BDG'), title=_(u'bridge')),\n\t\t\t\tSimpleTerm(value=(u'S.BDGQ'), title=_(u'ruined bridge')),\n\t\t\t\tSimpleTerm(value=(u'S.BLDA'), title=_(u'apartment building')),\n\t\t\t\tSimpleTerm(value=(u'S.BLDG'), title=_(u'building(s)')),\n\t\t\t\tSimpleTerm(value=(u'S.BLDO'), title=_(u'office building')),\n\t\t\t\tSimpleTerm(value=(u'S.BP'), title=_(u'boundary marker')),\n\t\t\t\tSimpleTerm(value=(u'S.BRKS'), title=_(u'barracks')),\n\t\t\t\tSimpleTerm(value=(u'S.BRKW'), title=_(u'breakwater')),\n\t\t\t\tSimpleTerm(value=(u'S.BSTN'), title=_(u'baling station')),\n\t\t\t\tSimpleTerm(value=(u'S.BTYD'), title=_(u'boatyard')),\n\t\t\t\tSimpleTerm(value=(u'S.BUR'), title=_(u'burial cave(s)')),\n\t\t\t\tSimpleTerm(value=(u'S.BUSTN'), title=_(u'bus station')),\n\t\t\t\tSimpleTerm(value=(u'S.BUSTP'), title=_(u'bus stop')),\n\t\t\t\tSimpleTerm(value=(u'S.CARN'), title=_(u'cairn')),\n\t\t\t\tSimpleTerm(value=(u'S.CAVE'), title=_(u'cave(s)')),\n\t\t\t\tSimpleTerm(value=(u'S.CH'), title=_(u'church')),\n\t\t\t\tSimpleTerm(value=(u'S.CMP'), title=_(u'camp(s)')),\n\t\t\t\tSimpleTerm(value=(u'S.CMPL'), title=_(u'logging camp')),\n\t\t\t\tSimpleTerm(value=(u'S.CMPLA'), title=_(u'labor camp')),\n\t\t\t\tSimpleTerm(value=(u'S.CMPMN'), title=_(u'mining camp')),\n\t\t\t\tSimpleTerm(value=(u'S.CMPO'), title=_(u'oil camp')),\n\t\t\t\tSimpleTerm(value=(u'S.CMPQ'), title=_(u'abandoned camp')),\n\t\t\t\tSimpleTerm(value=(u'S.CMPRF'), title=_(u'refugee camp')),\n\t\t\t\tSimpleTerm(value=(u'S.CMTY'), title=_(u'cemetery')),\n\t\t\t\tSimpleTerm(value=(u'S.COMC'), title=_(u'communication center')),\n\t\t\t\tSimpleTerm(value=(u'S.CRRL'), title=_(u'corral(s)')),\n\t\t\t\tSimpleTerm(value=(u'S.CSNO'), title=_(u'casino')),\n\t\t\t\tSimpleTerm(value=(u'S.CSTL'), title=_(u'castle')),\n\t\t\t\tSimpleTerm(value=(u'S.CSTM'), title=_(u'customs house')),\n\t\t\t\tSimpleTerm(value=(u'S.CTHSE'), title=_(u'courthouse')),\n\t\t\t\tSimpleTerm(value=(u'S.CTRA'), title=_(u'atomic center')),\n\t\t\t\tSimpleTerm(value=(u'S.CTRCM'), title=_(u'community center')),\n\t\t\t\tSimpleTerm(value=(u'S.CTRF'), title=_(u'facility center')),\n\t\t\t\tSimpleTerm(value=(u'S.CTRM'), title=_(u'medical center')),\n\t\t\t\tSimpleTerm(value=(u'S.CTRR'), title=_(u'religious center')),\n\t\t\t\tSimpleTerm(value=(u'S.CTRS'), title=_(u'space center')),\n\t\t\t\tSimpleTerm(value=(u'S.CVNT'), title=_(u'convent')),\n\t\t\t\tSimpleTerm(value=(u'S.DAM'), title=_(u'dam')),\n\t\t\t\tSimpleTerm(value=(u'S.DAMQ'), title=_(u'ruined dam')),\n\t\t\t\tSimpleTerm(value=(u'S.DAMSB'), title=_(u'sub-surface dam')),\n\t\t\t\tSimpleTerm(value=(u'S.DARY'), title=_(u'dairy')),\n\t\t\t\tSimpleTerm(value=(u'S.DCKD'), title=_(u'dry dock')),\n\t\t\t\tSimpleTerm(value=(u'S.DCKY'), title=_(u'dockyard')),\n\t\t\t\tSimpleTerm(value=(u'S.DIKE'), title=_(u'dike')),\n\t\t\t\tSimpleTerm(value=(u'S.DIP'), title=_(u'diplomatic facility')),\n\t\t\t\tSimpleTerm(value=(u'S.DPOF'), title=_(u'fuel depot')),\n\t\t\t\tSimpleTerm(value=(u'S.EST'), title=_(u'estate(s)')),\n\t\t\t\tSimpleTerm(value=(u'S.ESTO'), title=_(u'oil palm plantation')),\n\t\t\t\tSimpleTerm(value=(u'S.ESTR'), title=_(u'rubber plantation')),\n\t\t\t\tSimpleTerm(value=(u'S.ESTSG'), title=_(u'sugar plantation')),\n\t\t\t\tSimpleTerm(value=(u'S.ESTT'), title=_(u'tea plantation')),\n\t\t\t\tSimpleTerm(value=(u'S.ESTX'), title=_(u'section of estate')),\n\t\t\t\tSimpleTerm(value=(u'S.FCL'), title=_(u'facility')),\n\t\t\t\tSimpleTerm(value=(u'S.FNDY'), title=_(u'foundry')),\n\t\t\t\tSimpleTerm(value=(u'S.FRM'), title=_(u'farm')),\n\t\t\t\tSimpleTerm(value=(u'S.FRMQ'), title=_(u'abandoned farm')),\n\t\t\t\tSimpleTerm(value=(u'S.FRMS'), title=_(u'farms')),\n\t\t\t\tSimpleTerm(value=(u'S.FRMT'), title=_(u'farmstead')),\n\t\t\t\tSimpleTerm(value=(u'S.FT'), title=_(u'fort')),\n\t\t\t\tSimpleTerm(value=(u'S.FY'), title=_(u'ferry')),\n\t\t\t\tSimpleTerm(value=(u'S.FYT'), title=_(u'ferry terminal')),\n\t\t\t\tSimpleTerm(value=(u'S.GATE'), title=_(u'gate')),\n\t\t\t\tSimpleTerm(value=(u'S.GDN'), title=_(u'garden(s)')),\n\t\t\t\tSimpleTerm(value=(u'S.GHAT'), title=_(u'ghat')),\n\t\t\t\tSimpleTerm(value=(u'S.GHSE'), title=_(u'guest house')),\n\t\t\t\tSimpleTerm(value=(u'S.GOSP'), title=_(u'gas-oil separator plant')),\n\t\t\t\tSimpleTerm(value=(u'S.GOVL'), title=_(u'local government office')),\n\t\t\t\tSimpleTerm(value=(u'S.GRVE'), title=_(u'grave')),\n\t\t\t\tSimpleTerm(value=(u'S.HERM'), title=_(u'hermitage')),\n\t\t\t\tSimpleTerm(value=(u'S.HLT'), title=_(u'halting place')),\n\t\t\t\tSimpleTerm(value=(u'S.HMSD'), title=_(u'homestead')),\n\t\t\t\tSimpleTerm(value=(u'S.HSE'), title=_(u'house(s)')),\n\t\t\t\tSimpleTerm(value=(u'S.HSEC'), title=_(u'country house')),\n\t\t\t\tSimpleTerm(value=(u'S.HSP'), title=_(u'hospital')),\n\t\t\t\tSimpleTerm(value=(u'S.HSPC'), title=_(u'clinic')),\n\t\t\t\tSimpleTerm(value=(u'S.HSPD'), title=_(u'dispensary')),\n\t\t\t\tSimpleTerm(value=(u'S.HSPL'), title=_(u'leprosarium')),\n\t\t\t\tSimpleTerm(value=(u'S.HSTS'), title=_(u'historical site')),\n\t\t\t\tSimpleTerm(value=(u'S.HTL'), title=_(u'hotel')),\n\t\t\t\tSimpleTerm(value=(u'S.HUT'), title=_(u'hut')),\n\t\t\t\tSimpleTerm(value=(u'S.HUTS'), title=_(u'huts')),\n\t\t\t\tSimpleTerm(value=(u'S.INSM'), title=_(u'military installation')),\n\t\t\t\tSimpleTerm(value=(u'S.ITTR'), title=_(u'research institute')),\n\t\t\t\tSimpleTerm(value=(u'S.JTY'), title=_(u'jetty')),\n\t\t\t\tSimpleTerm(value=(u'S.LDNG'), title=_(u'landing')),\n\t\t\t\tSimpleTerm(value=(u'S.LEPC'), title=_(u'leper colony')),\n\t\t\t\tSimpleTerm(value=(u'S.LIBR'), title=_(u'library')),\n\t\t\t\tSimpleTerm(value=(u'S.LNDF'), title=_(u'landfill')),\n\t\t\t\tSimpleTerm(value=(u'S.LOCK'), title=_(u'lock(s)')),\n\t\t\t\tSimpleTerm(value=(u'S.LTHSE'), title=_(u'lighthouse')),\n\t\t\t\tSimpleTerm(value=(u'S.MALL'), title=_(u'mall')),\n\t\t\t\tSimpleTerm(value=(u'S.MAR'), title=_(u'marina')),\n\t\t\t\tSimpleTerm(value=(u'S.MFG'), title=_(u'factory')),\n\t\t\t\tSimpleTerm(value=(u'S.MFGB'), title=_(u'brewery')),\n\t\t\t\tSimpleTerm(value=(u'S.MFGC'), title=_(u'cannery')),\n\t\t\t\tSimpleTerm(value=(u'S.MFGCU'), title=_(u'copper works')),\n\t\t\t\tSimpleTerm(value=(u'S.MFGLM'), title=_(u'limekiln')),\n\t\t\t\tSimpleTerm(value=(u'S.MFGM'), title=_(u'munitions plant')),\n\t\t\t\tSimpleTerm(value=(u'S.MFGPH'), title=_(u'phosphate works')),\n\t\t\t\tSimpleTerm(value=(u'S.MFGQ'), title=_(u'abandoned factory')),\n\t\t\t\tSimpleTerm(value=(u'S.MFGSG'), title=_(u'sugar refinery')),\n\t\t\t\tSimpleTerm(value=(u'S.MKT'), title=_(u'market')),\n\t\t\t\tSimpleTerm(value=(u'S.ML'), title=_(u'mill(s)')),\n\t\t\t\tSimpleTerm(value=(u'S.MLM'), title=_(u'ore treatment plant')),\n\t\t\t\tSimpleTerm(value=(u'S.MLO'), title=_(u'olive oil mill')),\n\t\t\t\tSimpleTerm(value=(u'S.MLSG'), title=_(u'sugar mill')),\n\t\t\t\tSimpleTerm(value=(u'S.MLSGQ'), title=_(u'former sugar mill')),\n\t\t\t\tSimpleTerm(value=(u'S.MLSW'), title=_(u'sawmill')),\n\t\t\t\tSimpleTerm(value=(u'S.MLWND'), title=_(u'windmill')),\n\t\t\t\tSimpleTerm(value=(u'S.MLWTR'), title=_(u'water mill')),\n\t\t\t\tSimpleTerm(value=(u'S.MN'), title=_(u'mine(s)')),\n\t\t\t\tSimpleTerm(value=(u'S.MNAU'), title=_(u'gold mine(s)')),\n\t\t\t\tSimpleTerm(value=(u'S.MNC'), title=_(u'coal mine(s)')),\n\t\t\t\tSimpleTerm(value=(u'S.MNCR'), title=_(u'chrome mine(s)')),\n\t\t\t\tSimpleTerm(value=(u'S.MNCU'), title=_(u'copper mine(s)')),\n\t\t\t\tSimpleTerm(value=(u'S.MNFE'), title=_(u'iron mine(s)')),\n\t\t\t\tSimpleTerm(value=(u'S.MNMT'), title=_(u'monument')),\n\t\t\t\tSimpleTerm(value=(u'S.MNN'), title=_(u'salt mine(s)')),\n\t\t\t\tSimpleTerm(value=(u'S.MNQ'), title=_(u'abandoned mine')),\n\t\t\t\tSimpleTerm(value=(u'S.MNQR'), title=_(u'quarry(-ies)')),\n\t\t\t\tSimpleTerm(value=(u'S.MOLE'), title=_(u'mole')),\n\t\t\t\tSimpleTerm(value=(u'S.MSQE'), title=_(u'mosque')),\n\t\t\t\tSimpleTerm(value=(u'S.MSSN'), title=_(u'mission')),\n\t\t\t\tSimpleTerm(value=(u'S.MSSNQ'), title=_(u'abandoned mission')),\n\t\t\t\tSimpleTerm(value=(u'S.MSTY'), title=_(u'monastery')),\n\t\t\t\tSimpleTerm(value=(u'S.MTRO'), title=_(u'metro station')),\n\t\t\t\tSimpleTerm(value=(u'S.MUS'), title=_(u'museum')),\n\t\t\t\tSimpleTerm(value=(u'S.NOV'), title=_(u'novitiate')),\n\t\t\t\tSimpleTerm(value=(u'S.NSY'), title=_(u'nursery(-ies)')),\n\t\t\t\tSimpleTerm(value=(u'S.OBPT'), title=_(u'observation point')),\n\t\t\t\tSimpleTerm(value=(u'S.OBS'), title=_(u'observatory')),\n\t\t\t\tSimpleTerm(value=(u'S.OBSR'), title=_(u'radio observatory')),\n\t\t\t\tSimpleTerm(value=(u'S.OILJ'), title=_(u'oil pipeline junction')),\n\t\t\t\tSimpleTerm(value=(u'S.OILQ'), title=_(u'abandoned oil well')),\n\t\t\t\tSimpleTerm(value=(u'S.OILR'), title=_(u'oil refinery')),\n\t\t\t\tSimpleTerm(value=(u'S.OILT'), title=_(u'tank farm')),\n\t\t\t\tSimpleTerm(value=(u'S.OILW'), title=_(u'oil well')),\n\t\t\t\tSimpleTerm(value=(u'S.OPRA'), title=_(u'opera house')),\n\t\t\t\tSimpleTerm(value=(u'S.PAL'), title=_(u'palace')),\n\t\t\t\tSimpleTerm(value=(u'S.PGDA'), title=_(u'pagoda')),\n\t\t\t\tSimpleTerm(value=(u'S.PIER'), title=_(u'pier')),\n\t\t\t\tSimpleTerm(value=(u'S.PKLT'), title=_(u'parking lot')),\n\t\t\t\tSimpleTerm(value=(u'S.PMPO'), title=_(u'oil pumping station')),\n\t\t\t\tSimpleTerm(value=(u'S.PMPW'), title=_(u'water pumping station')),\n\t\t\t\tSimpleTerm(value=(u'S.PO'), title=_(u'post office')),\n\t\t\t\tSimpleTerm(value=(u'S.PP'), title=_(u'police post')),\n\t\t\t\tSimpleTerm(value=(u'S.PPQ'), title=_(u'abandoned police post')),\n\t\t\t\tSimpleTerm(value=(u'S.PRKGT'), title=_(u'park gate')),\n\t\t\t\tSimpleTerm(value=(u'S.PRKHQ'), title=_(u'park headquarters')),\n\t\t\t\tSimpleTerm(value=(u'S.PRN'), title=_(u'prison')),\n\t\t\t\tSimpleTerm(value=(u'S.PRNJ'), title=_(u'reformatory')),\n\t\t\t\tSimpleTerm(value=(u'S.PRNQ'), title=_(u'abandoned prison')),\n\t\t\t\tSimpleTerm(value=(u'S.PS'), title=_(u'power station')),\n\t\t\t\tSimpleTerm(value=(u'S.PSH'), title=_(u'hydroelectric power station')),\n\t\t\t\tSimpleTerm(value=(u'S.PSN'), title=_(u'nuclear power station')),\n\t\t\t\tSimpleTerm(value=(u'S.PSTB'), title=_(u'border post')),\n\t\t\t\tSimpleTerm(value=(u'S.PSTC'), title=_(u'customs post')),\n\t\t\t\tSimpleTerm(value=(u'S.PSTP'), title=_(u'patrol post')),\n\t\t\t\tSimpleTerm(value=(u'S.PYR'), title=_(u'pyramid')),\n\t\t\t\tSimpleTerm(value=(u'S.PYRS'), title=_(u'pyramids')),\n\t\t\t\tSimpleTerm(value=(u'S.QUAY'), title=_(u'quay')),\n\t\t\t\tSimpleTerm(value=(u'S.RDCR'), title=_(u'traffic circle')),\n\t\t\t\tSimpleTerm(value=(u'S.RDIN'), title=_(u'intersection')),\n\t\t\t\tSimpleTerm(value=(u'S.RECG'), title=_(u'golf course')),\n\t\t\t\tSimpleTerm(value=(u'S.RECR'), title=_(u'racetrack')),\n\t\t\t\tSimpleTerm(value=(u'S.REST'), title=_(u'restaurant')),\n\t\t\t\tSimpleTerm(value=(u'S.RET'), title=_(u'store')),\n\t\t\t\tSimpleTerm(value=(u'S.RHSE'), title=_(u'resthouse')),\n\t\t\t\tSimpleTerm(value=(u'S.RKRY'), title=_(u'rookery')),\n\t\t\t\tSimpleTerm(value=(u'S.RLG'), title=_(u'religious site')),\n\t\t\t\tSimpleTerm(value=(u'S.RLGR'), title=_(u'retreat')),\n\t\t\t\tSimpleTerm(value=(u'S.RNCH'), title=_(u'ranch(es)')),\n\t\t\t\tSimpleTerm(value=(u'S.RSD'), title=_(u'railroad siding')),\n\t\t\t\tSimpleTerm(value=(u'S.RSGNL'), title=_(u'railroad signal')),\n\t\t\t\tSimpleTerm(value=(u'S.RSRT'), title=_(u'resort')),\n\t\t\t\tSimpleTerm(value=(u'S.RSTN'), title=_(u'railroad station')),\n\t\t\t\tSimpleTerm(value=(u'S.RSTNQ'), title=_(u'abandoned railroad station')),\n\t\t\t\tSimpleTerm(value=(u'S.RSTP'), title=_(u'railroad stop')),\n\t\t\t\tSimpleTerm(value=(u'S.RSTPQ'), title=_(u'abandoned railroad stop')),\n\t\t\t\tSimpleTerm(value=(u'S.RUIN'), title=_(u'ruin(s)')),\n\t\t\t\tSimpleTerm(value=(u'S.SCH'), title=_(u'school')),\n\t\t\t\tSimpleTerm(value=(u'S.SCHA'), title=_(u'agricultural school')),\n\t\t\t\tSimpleTerm(value=(u'S.SCHC'), title=_(u'college')),\n\t\t\t\tSimpleTerm(value=(u'S.SCHL'), title=_(u'language school')),\n\t\t\t\tSimpleTerm(value=(u'S.SCHM'), title=_(u'military school')),\n\t\t\t\tSimpleTerm(value=(u'S.SCHN'), title=_(u'maritime school')),\n\t\t\t\tSimpleTerm(value=(u'S.SCHT'), title=_(u'technical school')),\n\t\t\t\tSimpleTerm(value=(u'S.SECP'), title=_(u'State Exam Prep Centre')),\n\t\t\t\tSimpleTerm(value=(u'S.SHPF'), title=_(u'sheepfold')),\n\t\t\t\tSimpleTerm(value=(u'S.SHRN'), title=_(u'shrine')),\n\t\t\t\tSimpleTerm(value=(u'S.SHSE'), title=_(u'storehouse')),\n\t\t\t\tSimpleTerm(value=(u'S.SLCE'), title=_(u'sluice')),\n\t\t\t\tSimpleTerm(value=(u'S.SNTR'), title=_(u'sanatorium')),\n\t\t\t\tSimpleTerm(value=(u'S.SPA'), title=_(u'spa')),\n\t\t\t\tSimpleTerm(value=(u'S.SPLY'), title=_(u'spillway')),\n\t\t\t\tSimpleTerm(value=(u'S.SQR'), title=_(u'square')),\n\t\t\t\tSimpleTerm(value=(u'S.STBL'), title=_(u'stable')),\n\t\t\t\tSimpleTerm(value=(u'S.STDM'), title=_(u'stadium')),\n\t\t\t\tSimpleTerm(value=(u'S.STNB'), title=_(u'scientific research base')),\n\t\t\t\tSimpleTerm(value=(u'S.STNC'), title=_(u'coast guard station')),\n\t\t\t\tSimpleTerm(value=(u'S.STNE'), title=_(u'experiment station')),\n\t\t\t\tSimpleTerm(value=(u'S.STNF'), title=_(u'forest station')),\n\t\t\t\tSimpleTerm(value=(u'S.STNI'), title=_(u'inspection station')),\n\t\t\t\tSimpleTerm(value=(u'S.STNM'), title=_(u'meteorological station')),\n\t\t\t\tSimpleTerm(value=(u'S.STNR'), title=_(u'radio station')),\n\t\t\t\tSimpleTerm(value=(u'S.STNS'), title=_(u'satellite station')),\n\t\t\t\tSimpleTerm(value=(u'S.STNW'), title=_(u'whaling station')),\n\t\t\t\tSimpleTerm(value=(u'S.STPS'), title=_(u'steps')),\n\t\t\t\tSimpleTerm(value=(u'S.SWT'), title=_(u'sewage treatment plant')),\n\t\t\t\tSimpleTerm(value=(u'S.SYG'), title=_(u'synagogue')),\n\t\t\t\tSimpleTerm(value=(u'S.THTR'), title=_(u'theater')),\n\t\t\t\tSimpleTerm(value=(u'S.TMB'), title=_(u'tomb(s)')),\n\t\t\t\tSimpleTerm(value=(u'S.TMPL'), title=_(u'temple(s)')),\n\t\t\t\tSimpleTerm(value=(u'S.TNKD'), title=_(u'cattle dipping tank')),\n\t\t\t\tSimpleTerm(value=(u'S.TOLL'), title=_(u'toll gate/barrier')),\n\t\t\t\tSimpleTerm(value=(u'S.TOWR'), title=_(u'tower')),\n\t\t\t\tSimpleTerm(value=(u'S.TRAM'), title=_(u'tram')),\n\t\t\t\tSimpleTerm(value=(u'S.TRANT'), title=_(u'transit terminal')),\n\t\t\t\tSimpleTerm(value=(u'S.TRIG'), title=_(u'triangulation station')),\n\t\t\t\tSimpleTerm(value=(u'S.TRMO'), title=_(u'oil pipeline terminal')),\n\t\t\t\tSimpleTerm(value=(u'S.TWO'), title=_(u'temp work office')),\n\t\t\t\tSimpleTerm(value=(u'S.UNIP'), title=_(u'university prep school')),\n\t\t\t\tSimpleTerm(value=(u'S.UNIV'), title=_(u'university')),\n\t\t\t\tSimpleTerm(value=(u'S.USGE'), title=_(u'united states government establishment')),\n\t\t\t\tSimpleTerm(value=(u'S.VETF'), title=_(u'veterinary facility')),\n\t\t\t\tSimpleTerm(value=(u'S.WALL'), title=_(u'wall')),\n\t\t\t\tSimpleTerm(value=(u'S.WALLA'), title=_(u'ancient wall')),\n\t\t\t\tSimpleTerm(value=(u'S.WEIR'), title=_(u'weir(s)')),\n\t\t\t\tSimpleTerm(value=(u'S.WHRF'), title=_(u'wharf(-ves)')),\n\t\t\t\tSimpleTerm(value=(u'S.WRCK'), title=_(u'wreck')),\n\t\t\t\tSimpleTerm(value=(u'S.WTRW'), title=_(u'waterworks')),\n\t\t\t\tSimpleTerm(value=(u'S.ZNF'), title=_(u'free trade zone')),\n\t\t\t\tSimpleTerm(value=(u'S.ZOO'), title=_(u'zoo')),\n\t\t\t\tSimpleTerm(value=(u'T.ASPH'), title=_(u'asphalt lake')),\n\t\t\t\tSimpleTerm(value=(u'T.ATOL'), title=_(u'atoll(s)')),\n\t\t\t\tSimpleTerm(value=(u'T.BAR'), title=_(u'bar')),\n\t\t\t\tSimpleTerm(value=(u'T.BCH'), title=_(u'beach')),\n\t\t\t\tSimpleTerm(value=(u'T.BCHS'), title=_(u'beaches')),\n\t\t\t\tSimpleTerm(value=(u'T.BDLD'), title=_(u'badlands')),\n\t\t\t\tSimpleTerm(value=(u'T.BLDR'), title=_(u'boulder field')),\n\t\t\t\tSimpleTerm(value=(u'T.BLHL'), title=_(u'blowhole(s)')),\n\t\t\t\tSimpleTerm(value=(u'T.BLOW'), title=_(u'blowout(s)')),\n\t\t\t\tSimpleTerm(value=(u'T.BNCH'), title=_(u'bench')),\n\t\t\t\tSimpleTerm(value=(u'T.BUTE'), title=_(u'butte(s)')),\n\t\t\t\tSimpleTerm(value=(u'T.CAPE'), title=_(u'cape')),\n\t\t\t\tSimpleTerm(value=(u'T.CFT'), title=_(u'cleft(s)')),\n\t\t\t\tSimpleTerm(value=(u'T.CLDA'), title=_(u'caldera')),\n\t\t\t\tSimpleTerm(value=(u'T.CLF'), title=_(u'cliff(s)')),\n\t\t\t\tSimpleTerm(value=(u'T.CNYN'), title=_(u'canyon')),\n\t\t\t\tSimpleTerm(value=(u'T.CONE'), title=_(u'cone(s)')),\n\t\t\t\tSimpleTerm(value=(u'T.CRDR'), title=_(u'corridor')),\n\t\t\t\tSimpleTerm(value=(u'T.CRQ'), title=_(u'cirque')),\n\t\t\t\tSimpleTerm(value=(u'T.CRQS'), title=_(u'cirques')),\n\t\t\t\tSimpleTerm(value=(u'T.CRTR'), title=_(u'crater(s)')),\n\t\t\t\tSimpleTerm(value=(u'T.CUET'), title=_(u'cuesta(s)')),\n\t\t\t\tSimpleTerm(value=(u'T.DLTA'), title=_(u'delta')),\n\t\t\t\tSimpleTerm(value=(u'T.DPR'), title=_(u'depression(s)')),\n\t\t\t\tSimpleTerm(value=(u'T.DSRT'), title=_(u'desert')),\n\t\t\t\tSimpleTerm(value=(u'T.DUNE'), title=_(u'dune(s)')),\n\t\t\t\tSimpleTerm(value=(u'T.DVD'), title=_(u'divide')),\n\t\t\t\tSimpleTerm(value=(u'T.ERG'), title=_(u'sandy desert')),\n\t\t\t\tSimpleTerm(value=(u'T.FAN'), title=_(u'fan(s)')),\n\t\t\t\tSimpleTerm(value=(u'T.FORD'), title=_(u'ford')),\n\t\t\t\tSimpleTerm(value=(u'T.FSR'), title=_(u'fissure')),\n\t\t\t\tSimpleTerm(value=(u'T.GAP'), title=_(u'gap')),\n\t\t\t\tSimpleTerm(value=(u'T.GRGE'), title=_(u'gorge(s)')),\n\t\t\t\tSimpleTerm(value=(u'T.HDLD'), title=_(u'headland')),\n\t\t\t\tSimpleTerm(value=(u'T.HLL'), title=_(u'hill')),\n\t\t\t\tSimpleTerm(value=(u'T.HLLS'), title=_(u'hills')),\n\t\t\t\tSimpleTerm(value=(u'T.HMCK'), title=_(u'hammock(s)')),\n\t\t\t\tSimpleTerm(value=(u'T.HMDA'), title=_(u'rock desert')),\n\t\t\t\tSimpleTerm(value=(u'T.INTF'), title=_(u'interfluve')),\n\t\t\t\tSimpleTerm(value=(u'T.ISL'), title=_(u'island')),\n\t\t\t\tSimpleTerm(value=(u'T.ISLET'), title=_(u'islet')),\n\t\t\t\tSimpleTerm(value=(u'T.ISLF'), title=_(u'artificial island')),\n\t\t\t\tSimpleTerm(value=(u'T.ISLM'), title=_(u'mangrove island')),\n\t\t\t\tSimpleTerm(value=(u'T.ISLS'), title=_(u'islands')),\n\t\t\t\tSimpleTerm(value=(u'T.ISLT'), title=_(u'land-tied island')),\n\t\t\t\tSimpleTerm(value=(u'T.ISLX'), title=_(u'section of island')),\n\t\t\t\tSimpleTerm(value=(u'T.ISTH'), title=_(u'isthmus')),\n\t\t\t\tSimpleTerm(value=(u'T.KRST'), title=_(u'karst area')),\n\t\t\t\tSimpleTerm(value=(u'T.LAVA'), title=_(u'lava area')),\n\t\t\t\tSimpleTerm(value=(u'T.LEV'), title=_(u'levee')),\n\t\t\t\tSimpleTerm(value=(u'T.MESA'), title=_(u'mesa(s)')),\n\t\t\t\tSimpleTerm(value=(u'T.MND'), title=_(u'mound(s)')),\n\t\t\t\tSimpleTerm(value=(u'T.MRN'), title=_(u'moraine')),\n\t\t\t\tSimpleTerm(value=(u'T.MT'), title=_(u'mountain')),\n\t\t\t\tSimpleTerm(value=(u'T.MTS'), title=_(u'mountains')),\n\t\t\t\tSimpleTerm(value=(u'T.NKM'), title=_(u'meander neck')),\n\t\t\t\tSimpleTerm(value=(u'T.NTK'), title=_(u'nunatak')),\n\t\t\t\tSimpleTerm(value=(u'T.NTKS'), title=_(u'nunataks')),\n\t\t\t\tSimpleTerm(value=(u'T.PAN'), title=_(u'pan')),\n\t\t\t\tSimpleTerm(value=(u'T.PANS'), title=_(u'pans')),\n\t\t\t\tSimpleTerm(value=(u'T.PASS'), title=_(u'pass')),\n\t\t\t\tSimpleTerm(value=(u'T.PEN'), title=_(u'peninsula')),\n\t\t\t\tSimpleTerm(value=(u'T.PENX'), title=_(u'section of peninsula')),\n\t\t\t\tSimpleTerm(value=(u'T.PK'), title=_(u'peak')),\n\t\t\t\tSimpleTerm(value=(u'T.PKS'), title=_(u'peaks')),\n\t\t\t\tSimpleTerm(value=(u'T.PLAT'), title=_(u'plateau')),\n\t\t\t\tSimpleTerm(value=(u'T.PLATX'), title=_(u'section of plateau')),\n\t\t\t\tSimpleTerm(value=(u'T.PLDR'), title=_(u'polder')),\n\t\t\t\tSimpleTerm(value=(u'T.PLN'), title=_(u'plain(s)')),\n\t\t\t\tSimpleTerm(value=(u'T.PLNX'), title=_(u'section of plain')),\n\t\t\t\tSimpleTerm(value=(u'T.PROM'), title=_(u'promontory(-ies)')),\n\t\t\t\tSimpleTerm(value=(u'T.PT'), title=_(u'point')),\n\t\t\t\tSimpleTerm(value=(u'T.PTS'), title=_(u'points')),\n\t\t\t\tSimpleTerm(value=(u'T.RDGB'), title=_(u'beach ridge')),\n\t\t\t\tSimpleTerm(value=(u'T.RDGE'), title=_(u'ridge(s)')),\n\t\t\t\tSimpleTerm(value=(u'T.REG'), title=_(u'stony desert')),\n\t\t\t\tSimpleTerm(value=(u'T.RK'), title=_(u'rock')),\n\t\t\t\tSimpleTerm(value=(u'T.RKFL'), title=_(u'rockfall')),\n\t\t\t\tSimpleTerm(value=(u'T.RKS'), title=_(u'rocks')),\n\t\t\t\tSimpleTerm(value=(u'T.SAND'), title=_(u'sand area')),\n\t\t\t\tSimpleTerm(value=(u'T.SBED'), title=_(u'dry stream bed')),\n\t\t\t\tSimpleTerm(value=(u'T.SCRP'), title=_(u'escarpment')),\n\t\t\t\tSimpleTerm(value=(u'T.SDL'), title=_(u'saddle')),\n\t\t\t\tSimpleTerm(value=(u'T.SHOR'), title=_(u'shore')),\n\t\t\t\tSimpleTerm(value=(u'T.SINK'), title=_(u'sinkhole')),\n\t\t\t\tSimpleTerm(value=(u'T.SLID'), title=_(u'slide')),\n\t\t\t\tSimpleTerm(value=(u'T.SLP'), title=_(u'slope(s)')),\n\t\t\t\tSimpleTerm(value=(u'T.SPIT'), title=_(u'spit')),\n\t\t\t\tSimpleTerm(value=(u'T.SPUR'), title=_(u'spur(s)')),\n\t\t\t\tSimpleTerm(value=(u'T.TAL'), title=_(u'talus slope')),\n\t\t\t\tSimpleTerm(value=(u'T.TRGD'), title=_(u'interdune trough(s)')),\n\t\t\t\tSimpleTerm(value=(u'T.TRR'), title=_(u'terrace')),\n\t\t\t\tSimpleTerm(value=(u'T.UPLD'), title=_(u'upland')),\n\t\t\t\tSimpleTerm(value=(u'T.VAL'), title=_(u'valley')),\n\t\t\t\tSimpleTerm(value=(u'T.VALG'), title=_(u'hanging valley')),\n\t\t\t\tSimpleTerm(value=(u'T.VALS'), title=_(u'valleys')),\n\t\t\t\tSimpleTerm(value=(u'T.VALX'), title=_(u'section of valley')),\n\t\t\t\tSimpleTerm(value=(u'T.VLC'), title=_(u'volcano')),\n\t\t\t\tSimpleTerm(value=(u'U.APNU'), title=_(u'apron')),\n\t\t\t\tSimpleTerm(value=(u'U.ARCU'), title=_(u'arch')),\n\t\t\t\tSimpleTerm(value=(u'U.ARRU'), title=_(u'arrugado')),\n\t\t\t\tSimpleTerm(value=(u'U.BDLU'), title=_(u'borderland')),\n\t\t\t\tSimpleTerm(value=(u'U.BKSU'), title=_(u'banks')),\n\t\t\t\tSimpleTerm(value=(u'U.BNKU'), title=_(u'bank')),\n\t\t\t\tSimpleTerm(value=(u'U.BSNU'), title=_(u'basin')),\n\t\t\t\tSimpleTerm(value=(u'U.CDAU'), title=_(u'cordillera')),\n\t\t\t\tSimpleTerm(value=(u'U.CNSU'), title=_(u'canyons')),\n\t\t\t\tSimpleTerm(value=(u'U.CNYU'), title=_(u'canyon')),\n\t\t\t\tSimpleTerm(value=(u'U.CRSU'), title=_(u'continental rise')),\n\t\t\t\tSimpleTerm(value=(u'U.DEPU'), title=_(u'deep')),\n\t\t\t\tSimpleTerm(value=(u'U.EDGU'), title=_(u'shelf edge')),\n\t\t\t\tSimpleTerm(value=(u'U.ESCU'), title=_(u'escarpment (or scarp)')),\n\t\t\t\tSimpleTerm(value=(u'U.FANU'), title=_(u'fan')),\n\t\t\t\tSimpleTerm(value=(u'U.FLTU'), title=_(u'flat')),\n\t\t\t\tSimpleTerm(value=(u'U.FRZU'), title=_(u'fracture zone')),\n\t\t\t\tSimpleTerm(value=(u'U.FURU'), title=_(u'furrow')),\n\t\t\t\tSimpleTerm(value=(u'U.GAPU'), title=_(u'gap')),\n\t\t\t\tSimpleTerm(value=(u'U.GLYU'), title=_(u'gully')),\n\t\t\t\tSimpleTerm(value=(u'U.HLLU'), title=_(u'hill')),\n\t\t\t\tSimpleTerm(value=(u'U.HLSU'), title=_(u'hills')),\n\t\t\t\tSimpleTerm(value=(u'U.HOLU'), title=_(u'hole')),\n\t\t\t\tSimpleTerm(value=(u'U.KNLU'), title=_(u'knoll')),\n\t\t\t\tSimpleTerm(value=(u'U.KNSU'), title=_(u'knolls')),\n\t\t\t\tSimpleTerm(value=(u'U.LDGU'), title=_(u'ledge')),\n\t\t\t\tSimpleTerm(value=(u'U.LEVU'), title=_(u'levee')),\n\t\t\t\tSimpleTerm(value=(u'U.MESU'), title=_(u'mesa')),\n\t\t\t\tSimpleTerm(value=(u'U.MNDU'), title=_(u'mound')),\n\t\t\t\tSimpleTerm(value=(u'U.MOTU'), title=_(u'moat')),\n\t\t\t\tSimpleTerm(value=(u'U.MTU'), title=_(u'mountain')),\n\t\t\t\tSimpleTerm(value=(u'U.PKSU'), title=_(u'peaks')),\n\t\t\t\tSimpleTerm(value=(u'U.PKU'), title=_(u'peak')),\n\t\t\t\tSimpleTerm(value=(u'U.PLNU'), title=_(u'plain')),\n\t\t\t\tSimpleTerm(value=(u'U.PLTU'), title=_(u'plateau')),\n\t\t\t\tSimpleTerm(value=(u'U.PNLU'), title=_(u'pinnacle')),\n\t\t\t\tSimpleTerm(value=(u'U.PRVU'), title=_(u'province')),\n\t\t\t\tSimpleTerm(value=(u'U.RDGU'), title=_(u'ridge')),\n\t\t\t\tSimpleTerm(value=(u'U.RDSU'), title=_(u'ridges')),\n\t\t\t\tSimpleTerm(value=(u'U.RFSU'), title=_(u'reefs')),\n\t\t\t\tSimpleTerm(value=(u'U.RFU'), title=_(u'reef')),\n\t\t\t\tSimpleTerm(value=(u'U.RISU'), title=_(u'rise')),\n\t\t\t\tSimpleTerm(value=(u'U.SCNU'), title=_(u'seachannel')),\n\t\t\t\tSimpleTerm(value=(u'U.SCSU'), title=_(u'seachannels')),\n\t\t\t\tSimpleTerm(value=(u'U.SDLU'), title=_(u'saddle')),\n\t\t\t\tSimpleTerm(value=(u'U.SHFU'), title=_(u'shelf')),\n\t\t\t\tSimpleTerm(value=(u'U.SHLU'), title=_(u'shoal')),\n\t\t\t\tSimpleTerm(value=(u'U.SHSU'), title=_(u'shoals')),\n\t\t\t\tSimpleTerm(value=(u'U.SHVU'), title=_(u'shelf valley')),\n\t\t\t\tSimpleTerm(value=(u'U.SILU'), title=_(u'sill')),\n\t\t\t\tSimpleTerm(value=(u'U.SLPU'), title=_(u'slope')),\n\t\t\t\tSimpleTerm(value=(u'U.SMSU'), title=_(u'seamounts')),\n\t\t\t\tSimpleTerm(value=(u'U.SMU'), title=_(u'seamount')),\n\t\t\t\tSimpleTerm(value=(u'U.SPRU'), title=_(u'spur')),\n\t\t\t\tSimpleTerm(value=(u'U.TERU'), title=_(u'terrace')),\n\t\t\t\tSimpleTerm(value=(u'U.TMSU'), title=_(u'tablemounts (or guyots)')),\n\t\t\t\tSimpleTerm(value=(u'U.TMTU'), title=_(u'tablemount (or guyot)')),\n\t\t\t\tSimpleTerm(value=(u'U.TNGU'), title=_(u'tongue')),\n\t\t\t\tSimpleTerm(value=(u'U.TRGU'), title=_(u'trough')),\n\t\t\t\tSimpleTerm(value=(u'U.TRNU'), title=_(u'trench')),\n\t\t\t\tSimpleTerm(value=(u'U.VALU'), title=_(u'valley')),\n\t\t\t\tSimpleTerm(value=(u'U.VLSU'), title=_(u'valleys')),\n\t\t\t\tSimpleTerm(value=(u'V.BUSH'), title=_(u'bush(es)')),\n\t\t\t\tSimpleTerm(value=(u'V.CULT'), title=_(u'cultivated area')),\n\t\t\t\tSimpleTerm(value=(u'V.FRST'), title=_(u'forest(s)')),\n\t\t\t\tSimpleTerm(value=(u'V.FRSTF'), title=_(u'fossilized forest')),\n\t\t\t\tSimpleTerm(value=(u'V.GROVE'), title=_(u'grove')),\n\t\t\t\tSimpleTerm(value=(u'V.GRSLD'), title=_(u'grassland')),\n\t\t\t\tSimpleTerm(value=(u'V.GRVC'), title=_(u'coconut grove')),\n\t\t\t\tSimpleTerm(value=(u'V.GRVO'), title=_(u'olive grove')),\n\t\t\t\tSimpleTerm(value=(u'V.GRVP'), title=_(u'palm grove')),\n\t\t\t\tSimpleTerm(value=(u'V.GRVPN'), title=_(u'pine grove')),\n\t\t\t\tSimpleTerm(value=(u'V.HTH'), title=_(u'heath')),\n\t\t\t\tSimpleTerm(value=(u'V.MDW'), title=_(u'meadow')),\n\t\t\t\tSimpleTerm(value=(u'V.OCH'), title=_(u'orchard(s)')),\n\t\t\t\tSimpleTerm(value=(u'V.SCRB'), title=_(u'scrubland')),\n\t\t\t\tSimpleTerm(value=(u'V.TREE'), title=_(u'tree(s)')),\n\t\t\t\tSimpleTerm(value=(u'V.TUND'), title=_(u'tundra')),\n\t\t\t\tSimpleTerm(value=(u'V.VIN'), title=_(u'vineyard')),\n\t\t\t\tSimpleTerm(value=(u'V.VINS'), title=_(u'vineyards')),\n\t\t\t\tSimpleTerm(value=(u'null'), title=_(u'not available')),\n\t\t\t]\n\t\t)\n\n\t\treturn geoname_featurecodes\n", "description": "\n\t", "category": "simple", "imports": ["# from plone import api", "from popolo.contenttypes import _", "from plone.dexterity.interfaces import IDexterityContent", "from zope.globalrequest import getRequest", "from zope.interface import implementer", "from zope.schema.interfaces import IVocabularyFactory", "from zope.schema.vocabulary import SimpleTerm", "from zope.schema.vocabulary import SimpleVocabulary"]}], [{"term": "class", "name": "GLUnurbs", "data": "class GLUnurbs(glustruct.GLUStruct, simple.GLUnurbs):\n\t\"\"\"GLU Nurbs structure with oor and callback storage support\n\t\n\tIMPORTANT NOTE: the texture coordinate callback receives a raw ctypes \n\tdata-pointer, as without knowing what type of evaluation is being done \n\t(1D or 2D) we cannot safely determine the size of the array to convert \n\tit.  This is a limitation of the C implementation.  To convert to regular \n\tdata-pointer, just call yourNurb.ptrAsArray( ptr, size, arrays.GLfloatArray )\n\twith the size of data you expect.\n\t\"\"\"\n\tFUNCTION_TYPE = PLATFORM.functionTypeFor(PLATFORM.GLU)\n\tCALLBACK_FUNCTION_REGISTRARS = {\n\t\t# mapping from \"which\" to a function that should take 3 parameters,\n\t\t# the nurb, the which and the function pointer...\n\t}\n\tCALLBACK_TYPES = {\n\t\t# mapping from \"which\" GLU enumeration to a ctypes function type\n\t\tsimple.GLU_NURBS_BEGIN: FUNCTION_TYPE( \n\t\t\tNone, simple.GLenum \n\t\t),\n\t\tsimple.GLU_NURBS_BEGIN_DATA: FUNCTION_TYPE( \n\t\t\tNone, simple.GLenum, ctypes.POINTER(simple.GLvoid) \n\t\t),\n\t\tsimple.GLU_NURBS_VERTEX: FUNCTION_TYPE( \n\t\t\tNone, ctypes.POINTER(simple.GLfloat)\n\t\t),\n\t\tsimple.GLU_NURBS_VERTEX_DATA: FUNCTION_TYPE( \n\t\t\tNone, ctypes.POINTER(simple.GLfloat), ctypes.POINTER(simple.GLvoid) \n\t\t),\n\t\tsimple.GLU_NURBS_NORMAL: FUNCTION_TYPE( \n\t\t\tNone, ctypes.POINTER(simple.GLfloat)\n\t\t),\n\t\tsimple.GLU_NURBS_NORMAL_DATA: FUNCTION_TYPE( \n\t\t\tNone, ctypes.POINTER(simple.GLfloat), ctypes.POINTER(simple.GLvoid) \n\t\t),\n\t\tsimple.GLU_NURBS_COLOR: FUNCTION_TYPE( \n\t\t\tNone, ctypes.POINTER(simple.GLfloat)\n\t\t),\n\t\tsimple.GLU_NURBS_COLOR_DATA: FUNCTION_TYPE( \n\t\t\tNone, ctypes.POINTER(simple.GLfloat), ctypes.POINTER(simple.GLvoid) \n\t\t),\n\t\tsimple.GLU_NURBS_TEXTURE_COORD: FUNCTION_TYPE( \n\t\t\tNone, ctypes.POINTER(simple.GLfloat)\n\t\t),\n\t\tsimple.GLU_NURBS_TEXTURE_COORD_DATA: FUNCTION_TYPE( \n\t\t\tNone, ctypes.POINTER(simple.GLfloat), ctypes.POINTER(simple.GLvoid) \n\t\t),\n\t\tsimple.GLU_NURBS_END:FUNCTION_TYPE( \n\t\t\tNone\n\t\t),\n\t\tsimple.GLU_NURBS_END_DATA: FUNCTION_TYPE( \n\t\t\tNone, ctypes.POINTER(simple.GLvoid) \n\t\t),\n\t\tsimple.GLU_NURBS_ERROR:FUNCTION_TYPE( \n\t\t\tNone, simple.GLenum, \n\t\t),\n\t}\n\tWRAPPER_METHODS = {\n\t\tsimple.GLU_NURBS_BEGIN: None,\n\t\tsimple.GLU_NURBS_BEGIN_DATA: '_justOOR',\n\t\tsimple.GLU_NURBS_VERTEX: '_vec3',\n\t\tsimple.GLU_NURBS_VERTEX_DATA: '_vec3',\n\t\tsimple.GLU_NURBS_NORMAL: '_vec3',\n\t\tsimple.GLU_NURBS_NORMAL_DATA: '_vec3',\n\t\tsimple.GLU_NURBS_COLOR: '_vec4',\n\t\tsimple.GLU_NURBS_COLOR_DATA: '_vec4',\n\t\tsimple.GLU_NURBS_TEXTURE_COORD: '_tex',\n\t\tsimple.GLU_NURBS_TEXTURE_COORD_DATA: '_tex',\n\t\tsimple.GLU_NURBS_END: None,\n\t\tsimple.GLU_NURBS_END_DATA: '_justOOR',\n\t\tsimple.GLU_NURBS_ERROR: None,\n\t}\n\tdef _justOOR( self, function ):\n\t\t\"\"\"Just do OOR on the last argument...\"\"\"\n\t\tdef getOOR( *args ):\n\t\t\targs = args[:-1] + (self.originalObject(args[-1]),)\n\t\t\treturn function( *args )\n\t\treturn getOOR\n\tdef _vec3( self, function, size=3 ):\n\t\t\"\"\"Convert first arg to size-element array, do OOR on arg2 if present\"\"\"\n\t\tdef vec( *args ):\n\t\t\tvec = self.ptrAsArray(args[0],size,arrays.GLfloatArray)\n\t\t\tif len(args) > 1:\n\t\t\t\toor = self.originalObject(args[1])\n\t\t\t\treturn function( vec, oor )\n\t\t\telse:\n\t\t\t\treturn function( vec )\n\t\treturn vec\n\tdef _vec4( self, function ):\n\t\t\"\"\"Size-4 vector version...\"\"\"\n\t\treturn self._vec3( function, 4 )\n\tdef _tex( self, function ):\n\t\t\"\"\"Texture coordinate callback \n\t\t\n\t\tNOTE: there is no way for *us* to tell what size the array is, you will \n\t\tget back a raw data-point, not an array, as you do for all other callback \n\t\ttypes!!!\n\t\t\"\"\"\n\t\tdef oor( *args ):\n\t\t\tif len(args) > 1:\n\t\t\t\toor = self.originalObject(args[1])\n\t\t\t\treturn function( args[0], oor )\n\t\t\telse:\n\t\t\t\treturn function( args[0] )\n\t\treturn oor\n", "description": "GLU Nurbs structure with oor and callback storage support\n\t\n\tIMPORTANT NOTE: the texture coordinate callback receives a raw ctypes \n\tdata-pointer, as without knowing what type of evaluation is being done \n\t(1D or 2D) we cannot safely determine the size of the array to convert \n\tit.  This is a limitation of the C implementation.  To convert to regular \n\tdata-pointer, just call yourNurb.ptrAsArray( ptr, size, arrays.GLfloatArray )\n\twith the size of data you expect.\n\t", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL"]}, {"term": "def", "name": "_callbackWithType", "data": "def _callbackWithType( funcType ):\n\t\"\"\"Get gluNurbsCallback function with set last arg-type\"\"\"\n\tresult =  platform.copyBaseFunction(\n\t\tsimple.gluNurbsCallback\n\t)\n\tresult.argtypes = [ctypes.POINTER(GLUnurbs), simple.GLenum, funcType]\n\tassert result.argtypes[-1] == funcType\n\treturn result\n", "description": "Get gluNurbsCallback function with set last arg-type", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL"]}, {"term": "def", "name": "gluNurbsCallback", "data": "def gluNurbsCallback( nurb, which, CallBackFunc ):\n\t\"\"\"Dispatch to the nurb's addCallback operation\"\"\"\n\treturn nurb.addCallback( which, CallBackFunc )\n", "description": "Dispatch to the nurb's addCallback operation", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL"]}, {"term": "def", "name": "gluNewNurbsRenderer", "data": "def gluNewNurbsRenderer( baseFunction ):\n\t\"\"\"Return a new nurbs renderer for the system (dereferences pointer)\"\"\"\n\tnewSet = baseFunction()\n\tnew = newSet[0]\n\t#new.__class__ = GLUnurbs # yes, I know, ick\n\treturn new\n", "description": "Return a new nurbs renderer for the system (dereferences pointer)", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL"]}, {"term": "def", "name": "gluNurbsCallbackData", "data": "def gluNurbsCallbackData( baseFunction, nurb, userData ):\n\t\"\"\"Note the Python object for use as userData by the nurb\"\"\"\n\treturn baseFunction( \n\t\tnurb, nurb.noteObject( userData ) \n\t)\n", "description": "Note the Python object for use as userData by the nurb", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL"]}, {"term": "def", "name": "checkOrder", "data": "def checkOrder( order,knotCount,name ):\n\t\"\"\"Check that order is valid...\"\"\"\n\tif order < 1:\n\t\traise error.GLUError( \n\t\t\t\"\"\"%s should be 1 or more, is %s\"\"\"%( name,order,) \n\t\t)\n\telif order > MAX_ORDER:\n\t\traise error.GLUError( \n\t\t\t\"\"\"%s should be %s or less, is %s\"\"\"%( name, MAX_ORDER, order) \n\t\t)\n\telif knotCount < (2*order):\n\t\traise error.GLUError( \n\t\t\t\"\"\"Knotcount must be at least 2x %s is %s should be at least %s\"\"\"%( name, knotCount, 2*order) \n", "description": "Check that order is valid...", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL"]}, {"term": "def", "name": "checkKnots", "data": "def checkKnots( knots, name ):\n\t\"\"\"Check that knots are in ascending order\"\"\"\n\tif len(knots):\n\t\tknot = knots[0]\n\t\tfor next in knots[1:]:\n\t\t\tif next < knot:\n\t\t\t\traise error.GLUError(\n\t\t\t\t\t\"\"\"%s has decreasing knot %s after %s\"\"\"%( name, next, knot )\n\t\t\t\t)\n", "description": "Check that knots are in ascending order", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL"]}, {"term": "def", "name": "gluNurbsCallbackDataEXT", "data": "def gluNurbsCallbackDataEXT( baseFunction,nurb, userData ):\n\t\"\"\"Note the Python object for use as userData by the nurb\"\"\"\n\treturn baseFunction( \n\t\tnurb, nurb.noteObject( userData ) \n\t)\n", "description": "Note the Python object for use as userData by the nurb", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL"]}, {"term": "def", "name": "gluNurbsCurve", "data": "def gluNurbsCurve( baseFunction, nurb, knots, control, type ):\n\t\"\"\"Pythonic version of gluNurbsCurve\n\t\n\tCalculates knotCount, stride, and order automatically\n\t\"\"\"\n\tknots = arrays.GLfloatArray.asArray( knots )\n\tknotCount = arrays.GLfloatArray.arraySize( knots )\n\tcontrol = arrays.GLfloatArray.asArray( control )\n\ttry:\n\t\tlength,step = arrays.GLfloatArray.dimensions( control )\n\texcept ValueError, err:\n\t\traise error.GLUError( \"\"\"Need a 2-dimensional control array\"\"\" )\n\torder = knotCount - length\n\tif OpenGL.ERROR_CHECKING:\n\t\tcheckOrder( order, knotCount, 'order of NURBS curve')\n\t\tcheckKnots( knots, 'knots of NURBS curve')\n\treturn baseFunction(\n\t\tnurb, knotCount, knots, step, control, order, type,\n\t)\n", "description": "Pythonic version of gluNurbsCurve\n\t\n\tCalculates knotCount, stride, and order automatically\n\t", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL"]}, {"term": "def", "name": "gluNurbsSurface", "data": "def gluNurbsSurface( baseFunction, nurb, sKnots, tKnots, control, type ):\n\t\"\"\"Pythonic version of gluNurbsSurface\n\t\n\tCalculates knotCount, stride, and order automatically\n\t\"\"\"\n\tsKnots = arrays.GLfloatArray.asArray( sKnots )\n\tsKnotCount = arrays.GLfloatArray.arraySize( sKnots )\n\ttKnots = arrays.GLfloatArray.asArray( tKnots )\n\ttKnotCount = arrays.GLfloatArray.arraySize( tKnots )\n\tcontrol = arrays.GLfloatArray.asArray( control )\n\n\ttry:\n\t\tlength,width,step = arrays.GLfloatArray.dimensions( control )\n\texcept ValueError, err:\n\t\traise error.GLUError( \"\"\"Need a 3-dimensional control array\"\"\" )\n\tsOrder = sKnotCount - length \n\ttOrder = tKnotCount - width \n\tsStride = width*step\n\ttStride = step\n\tif OpenGL.ERROR_CHECKING:\n\t\tcheckOrder( sOrder, sKnotCount, 'sOrder of NURBS surface')\n\t\tcheckOrder( tOrder, tKnotCount, 'tOrder of NURBS surface')\n\t\tcheckKnots( sKnots, 'sKnots of NURBS surface')\n\t\tcheckKnots( tKnots, 'tKnots of NURBS surface')\n\tif not (sKnotCount-sOrder)*(tKnotCount-tOrder) == length*width:\n\t\traise error.GLUError(\n\t\t\t\"\"\"Invalid NURB structure\"\"\",\n\t\t\tnurb, sKnotCount, sKnots, tKnotCount, tKnots,\n\t\t\tsStride, tStride, control,\n\t\t\tsOrder,tOrder,\n\t\t\ttype\n\t\t)\n\n\tresult = baseFunction(\n\t\tnurb, sKnotCount, sKnots, tKnotCount, tKnots,\n\t\tsStride, tStride, control,\n\t\tsOrder,tOrder,\n\t\ttype\n\t)\n\treturn result\n", "description": "Pythonic version of gluNurbsSurface\n\t\n\tCalculates knotCount, stride, and order automatically\n\t", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL"]}, {"term": "def", "name": "gluPwlCurve", "data": "def gluPwlCurve( baseFunction, nurb, data, type ):\n\t\"\"\"gluPwlCurve -- piece-wise linear curve within GLU context\n\t\n\tdata -- the data-array \n\ttype -- determines number of elements/data-point\n\t\"\"\"\n\tdata = arrays.GLfloatArray.asArray( data )\n\tif type == simple.GLU_MAP1_TRIM_2:\n\t\tdivisor = 2\n\telif type == simple.GLU_MAP_TRIM_3:\n\t\tdivisor = 3\n\telse:\n\t\traise ValueError( \"\"\"Unrecognised type constant: %s\"\"\"%(type))\n\tsize = arrays.GLfloatArray.arraySize( data )\n\tsize = int(size//divisor)\n\treturn baseFunction( nurb, size, data, divisor, type )\n", "description": "gluPwlCurve -- piece-wise linear curve within GLU context\n\t\n\tdata -- the data-array \n\ttype -- determines number of elements/data-point\n\t", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL"]}], [{"term": "class", "name": "SimpleCookieJar", "data": "class SimpleCookieJar(object):\n\tdef __init__(self):\n\t\tself.jar = dict()\n\n\tdef add(self, set_cookie):\n\t\tif set_cookie:\n\t\t\ttry:\n\t\t\t\tsimpleCookie = Cookie.SimpleCookie(set_cookie)\n\t\t\texcept:\n\t\t\t\tsimpleCookie = Cookie.SimpleCookie(set_cookie.encode('ascii', 'ignore'))\n\n\t\t\tfor k, v in simpleCookie.items():\n\t\t\t\tdomain = v.get(\"domain\")\n\t\t\t\tif domain:\n\t\t\t\t\tif not domain.startswith(\".\"):\n\t\t\t\t\t\tdomain = \".\" + domain\n\t\t\t\t\tcookie = self.jar.get(domain) if self.jar.get(domain) else Cookie.SimpleCookie()\n\t\t\t\t\tcookie.update(simpleCookie)\n\t\t\t\t\tself.jar[domain.lower()] = cookie\n\n\tdef set(self, set_cookie):\n\t\tif set_cookie:\n\t\t\ttry:\n\t\t\t\tsimpleCookie = Cookie.SimpleCookie(set_cookie)\n\t\t\texcept:\n\t\t\t\tsimpleCookie = Cookie.SimpleCookie(set_cookie.encode('ascii', 'ignore'))\n\n\t\t\tfor k, v in simpleCookie.items():\n\t\t\t\tdomain = v.get(\"domain\")\n\t\t\t\tif domain:\n\t\t\t\t\tif not domain.startswith(\".\"):\n\t\t\t\t\t\tdomain = \".\" + domain\n\t\t\t\t\tself.jar[domain.lower()] = simpleCookie\n\n\tdef get(self, host):\n\t\tif not host:\n\t\t\treturn \"\"\n\n\t\tcookies = []\n\t\tfor domain, simpleCookie in self.jar.items():\n\t\t\thost = host.lower()\n\t\t\tif host.endswith(domain) or host == domain[1:]:\n\t\t\t\tcookies.append(self.jar.get(domain))\n\n\t\treturn \"; \".join(filter(None, [\"%s=%s\" % (k, v.value) for cookie in filter(None, sorted(cookies)) for k, v in\n\t\t\t\t\t\t\t\t\t   sorted(cookie.items())]))\n", "description": null, "category": "simple", "imports": ["\timport Cookie", "\timport http.cookies as Cookie"]}], [{"term": "class", "name": "SimpleModel", "data": "class SimpleModel(Model):\n\t\"\"\"Simple Test Model\"\"\"\n\tname = StringProperty()\n\tstrs = ListProperty(str)\n\tnum = IntegerProperty()\n", "description": "Simple Test Model", "category": "simple", "imports": ["from boto.sdb.db.property import ListProperty, StringProperty, ReferenceProperty, IntegerProperty", "from boto.sdb.db.model import Model", "import time"]}, {"term": "class", "name": "SubModel", "data": "class SubModel(SimpleModel):\n\t\"\"\"Simple Subclassed Model\"\"\"\n\tref = ReferenceProperty(SimpleModel, collection_name=\"reverse_ref\")\n\n", "description": "Simple Subclassed Model", "category": "simple", "imports": ["from boto.sdb.db.property import ListProperty, StringProperty, ReferenceProperty, IntegerProperty", "from boto.sdb.db.model import Model", "import time"]}, {"term": "class", "name": "TestQuerying", "data": "class TestQuerying(object):\n\t\"\"\"Test different querying capabilities\"\"\"\n\n\tdef setup_class(cls):\n\t\t\"\"\"Setup this class\"\"\"\n\t\tcls.objs = []\n\n\t\to = SimpleModel()\n\t\to.name = \"Simple Object\"\n\t\to.strs = [\"B\", \"A\", \"C\", \"Foo\"]\n\t\to.num = 1\n\t\to.put()\n\t\tcls.objs.append(o)\n\n\t\to2 = SimpleModel()\n\t\to2.name = \"Referenced Object\"\n\t\to2.num = 2\n\t\to2.put()\n\t\tcls.objs.append(o2)\n\n\t\to3 = SubModel()\n\t\to3.name = \"Sub Object\"\n\t\to3.num = 3\n\t\to3.ref = o2\n\t\to3.put()\n\t\tcls.objs.append(o3)\n\n\t\ttime.sleep(3)\n\n\n\n\tdef teardown_class(cls):\n\t\t\"\"\"Remove our objects\"\"\"\n\t\tfor o in cls.objs:\n\t\t\ttry:\n\t\t\t\to.delete()\n\t\t\texcept:\n\t\t\t\tpass\n\n\tdef test_find(self):\n\t\t\"\"\"Test using the \"Find\" method\"\"\"\n\t\tassert(SimpleModel.find(name=\"Simple Object\").next().id == self.objs[0].id)\n\t\tassert(SimpleModel.find(name=\"Referenced Object\").next().id == self.objs[1].id)\n\t\tassert(SimpleModel.find(name=\"Sub Object\").next().id == self.objs[2].id)\n\n\tdef test_like_filter(self):\n\t\t\"\"\"Test a \"like\" filter\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name like\", \"% Object\")\n\t\tassert(query.count() == 3)\n\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name not like\", \"% Object\")\n\t\tassert(query.count() == 0)\n\n\tdef test_equals_filter(self):\n\t\t\"\"\"Test an \"=\" and \"!=\" filter\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name =\", \"Simple Object\")\n\t\tassert(query.count() == 1)\n\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name !=\", \"Simple Object\")\n\t\tassert(query.count() == 2)\n\n\tdef test_or_filter(self):\n\t\t\"\"\"Test a filter function as an \"or\" \"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name =\", [\"Simple Object\", \"Sub Object\"])\n\t\tassert(query.count() == 2)\n\n\tdef test_and_filter(self):\n\t\t\"\"\"Test Multiple filters which are an \"and\" \"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name like\", \"% Object\")\n\t\tquery.filter(\"name like\", \"Simple %\")\n\t\tassert(query.count() == 1)\n\n\tdef test_none_filter(self):\n\t\t\"\"\"Test filtering for a value that's not set\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"ref =\", None)\n\t\tassert(query.count() == 2)\n\n\tdef test_greater_filter(self):\n\t\t\"\"\"Test filtering Using >, >=\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"num >\", 1)\n\t\tassert(query.count() == 2)\n\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"num >=\", 1)\n\t\tassert(query.count() == 3)\n\n\tdef test_less_filter(self):\n\t\t\"\"\"Test filtering Using <, <=\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"num <\", 3)\n\t\tassert(query.count() == 2)\n\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"num <=\", 3)\n\t\tassert(query.count() == 3)\n\n\tdef test_query_on_list(self):\n\t\t\"\"\"Test querying on a list\"\"\"\n\t\tassert(SimpleModel.find(strs=\"A\").next().id == self.objs[0].id)\n\t\tassert(SimpleModel.find(strs=\"B\").next().id == self.objs[0].id)\n\t\tassert(SimpleModel.find(strs=\"C\").next().id == self.objs[0].id)\n\n\tdef test_like(self):\n\t\t\"\"\"Test with a \"like\" expression\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"strs like\", \"%oo%\")\n\t\tprint query.get_query()\n\t\tassert(query.count() == 1)\n", "description": "Test different querying capabilities", "category": "simple", "imports": ["from boto.sdb.db.property import ListProperty, StringProperty, ReferenceProperty, IntegerProperty", "from boto.sdb.db.model import Model", "import time"]}], [{"term": "def", "name": "test_add_two_numbers", "data": "def test_add_two_numbers():\n\tcalculator = SimpleCalculator()\n\n\tresult = calculator.add(4, 5)\n\n\tassert result == 9\n\n", "description": null, "category": "simple", "imports": ["import pytest", "from simple_calculator.main import SimpleCalculator"]}, {"term": "def", "name": "test_add_three_numbers", "data": "def test_add_three_numbers():\n\tcalculator = SimpleCalculator()\n\n\tresult = calculator.add(4, 5, 6)\n\n\tassert result == 15\n\n", "description": null, "category": "simple", "imports": ["import pytest", "from simple_calculator.main import SimpleCalculator"]}, {"term": "def", "name": "test_add_many_numbers", "data": "def test_add_many_numbers():\n\tnumbers = range(100)\n\n\tcalculator = SimpleCalculator()\n\n\tresult = calculator.add(*numbers)\n\n\tassert result == 4950\n\n", "description": null, "category": "simple", "imports": ["import pytest", "from simple_calculator.main import SimpleCalculator"]}, {"term": "def", "name": "test_subtract_two_numbers", "data": "def test_subtract_two_numbers():\n\n\tcalculator = SimpleCalculator()\n\n\tresult = calculator.sub(10, 3)\n\n\tassert result == 7\n\n", "description": null, "category": "simple", "imports": ["import pytest", "from simple_calculator.main import SimpleCalculator"]}, {"term": "def", "name": "test_mul_two_numbers", "data": "def test_mul_two_numbers():\n\tcalculator = SimpleCalculator()\n\n\tresult = calculator.mul(6, 4)\n\n\tassert result == 24\n\n", "description": null, "category": "simple", "imports": ["import pytest", "from simple_calculator.main import SimpleCalculator"]}, {"term": "def", "name": "test_mul_many_numbers", "data": "def test_mul_many_numbers():\n\tnumbers = range(1, 10)\n\n\tcalculator = SimpleCalculator()\n\n\tresult = calculator.mul(*numbers)\n\n\tassert result == 362880\n\n", "description": null, "category": "simple", "imports": ["import pytest", "from simple_calculator.main import SimpleCalculator"]}, {"term": "def", "name": "test_div_two_numbers_float", "data": "def test_div_two_numbers_float():\n\tcalculator = SimpleCalculator()\n\n\tresult = calculator.div(13, 2)\n\n\tassert result == 6.5\n\n", "description": null, "category": "simple", "imports": ["import pytest", "from simple_calculator.main import SimpleCalculator"]}, {"term": "def", "name": "test_div_by_zero_returns_inf", "data": "def test_div_by_zero_returns_inf():\n\tcalculator = SimpleCalculator()\n\n\tresult = calculator.div(5, 0)\n\n\tassert result == float(\"inf\")\n\n", "description": null, "category": "simple", "imports": ["import pytest", "from simple_calculator.main import SimpleCalculator"]}, {"term": "def", "name": "test_mul_by_zero_raises_exception", "data": "def test_mul_by_zero_raises_exception():\n\tcalculator = SimpleCalculator()\n\n\twith pytest.raises(ValueError):\n\t\tcalculator.mul(3, 0)\n", "description": null, "category": "simple", "imports": ["import pytest", "from simple_calculator.main import SimpleCalculator"]}, {"term": "def", "name": "test_avg_1", "data": "def test_avg_1():\n\tcalculator = SimpleCalculator()\n\n\tresult = calculator.avg([2, 5, 12, 98])\n\n\tassert result == 29.25\n\n", "description": null, "category": "simple", "imports": ["import pytest", "from simple_calculator.main import SimpleCalculator"]}, {"term": "def", "name": "test_avg_2", "data": "def test_avg_2():\n\tcalculator = SimpleCalculator()\n\n\tresult = calculator.avg([2, 5, 12, 98], ut=90)\n\n\tassert result == calculator.avg([2, 5, 12])\n\n", "description": null, "category": "simple", "imports": ["import pytest", "from simple_calculator.main import SimpleCalculator"]}, {"term": "def", "name": "test_avg_3", "data": "def test_avg_3():\n\tcalculator = SimpleCalculator()\n\n\tresult = calculator.avg([2, 5, 12, 98], lt=10)\n\n\tassert result == calculator.avg([12, 98])\n\n", "description": null, "category": "simple", "imports": ["import pytest", "from simple_calculator.main import SimpleCalculator"]}, {"term": "def", "name": "test_avg_4", "data": "def test_avg_4():\n\tcalculator = SimpleCalculator()\n\n\tresult = calculator.avg([2, 5, 12, 98], ut=98)\n\n\tassert result == calculator.avg([2, 5, 12, 98])\n\n", "description": null, "category": "simple", "imports": ["import pytest", "from simple_calculator.main import SimpleCalculator"]}, {"term": "def", "name": "test_avg_5", "data": "def test_avg_5():\n\tcalculator = SimpleCalculator()\n\n\tresult = calculator.avg([2, 5, 12, 98], lt=5)\n\n\tassert result == calculator.avg([5, 12, 98])\n\n", "description": null, "category": "simple", "imports": ["import pytest", "from simple_calculator.main import SimpleCalculator"]}, {"term": "def", "name": "test_avg_6", "data": "def test_avg_6():\n\tcalculator = SimpleCalculator()\n\n\tresult = calculator.avg([])\n\n\tassert result == 0\n\n", "description": null, "category": "simple", "imports": ["import pytest", "from simple_calculator.main import SimpleCalculator"]}, {"term": "def", "name": "test_avg_7", "data": "def test_avg_7():\n\tcalculator = SimpleCalculator()\n\n\tresult = calculator.avg([12, 98], lt=15, ut=90)\n\n\tassert result == 0\n\n", "description": null, "category": "simple", "imports": ["import pytest", "from simple_calculator.main import SimpleCalculator"]}, {"term": "def", "name": "test_avg_8", "data": "def test_avg_8():\n\tcalculator = SimpleCalculator()\n\n\tresult = calculator.avg([], lt=15, ut=90)\n\n\tassert result == 0\n\n", "description": null, "category": "simple", "imports": ["import pytest", "from simple_calculator.main import SimpleCalculator"]}, {"term": "def", "name": "test_avg_9", "data": "def test_avg_9():\n\tcalculator = SimpleCalculator()\n\n\tresult = calculator.avg([-1, 0, 1], lt=0)\n\n\tassert result == 0.5\n\n", "description": null, "category": "simple", "imports": ["import pytest", "from simple_calculator.main import SimpleCalculator"]}, {"term": "def", "name": "test_avg_10", "data": "def test_avg_10():\n\tcalculator = SimpleCalculator()\n\n\tresult = calculator.avg([-1, 0, 1], ut=0)\n\n\tassert result == -0.5\n", "description": null, "category": "simple", "imports": ["import pytest", "from simple_calculator.main import SimpleCalculator"]}], [{"term": "def", "name": "findtb", "data": "def findtb(source, start, end, tb, brace=0):\n\ti = j = 0\n\ttb[0] = start\n\ttb[1] = end\n\tfor i in range(start, end):\n\t\tif source[i] == '{':\n\t\t\tbrace += 1\n\t\t\tif brace > 0:\n\t\t\t\ttb[0] = i + 1\n\t\t\t\tfor j in range(i + 1, tb[1]):\n\t\t\t\t\tif source[j] == '{':\n\t\t\t\t\t\tbrace += 1\n\t\t\t\t\telif source[j] == '}':\n\t\t\t\t\t\tbrace -= 1\n\t\t\t\t\t\tif brace == 0:\n\t\t\t\t\t\t\ttb[1] = j - 1\n\t\t\t\t\t\t\treturn True\n\t\telif source[i] == '}':\n\t\t\treturn False\n\treturn False\n\n", "description": null, "category": "simple", "imports": ["import json", "import hashlib", "import re", "import copy", "from xpinyin import Pinyin", "from text_to_json import ability", "from text_to_json.WikiError import editerror"]}, {"term": "def", "name": "findheroname", "data": "def findheroname(source, tb):\n\ti = source.rfind('\\\"', 0, tb[0])\n\tj = source.rfind('\\\"', 0, i - 1)\n\treturn source[j + 15:i]\n\n", "description": null, "category": "simple", "imports": ["import json", "import hashlib", "import re", "import copy", "from xpinyin import Pinyin", "from text_to_json import ability", "from text_to_json.WikiError import editerror"]}, {"term": "def", "name": "findheropro", "data": "def findheropro(source, data, tb, pro, inherit=True, number=True, splitit=False):\n\tif pro[0] in data:\n\t\treturn\n\telse:\n\t\ti = source.find('\\\"' + pro[1] + '\\\"', tb[0], tb[1])\n\t\tif i == -1:\n\t\t\tif inherit:\n\t\t\t\tdata[pro[1]] = hero_default[pro[1]]\n\t\telse:\n\t\t\tj = source.find('\\\"', i + 1, tb[1])\n\t\t\tj = source.find('\\\"', j + 1, tb[1])\n\t\t\tk = source.find('\\\"', j + 1, tb[1])\n\t\t\tif splitit:\n\t\t\t\trolesplit = source[j + 1:k].split(',')\n\t\t\t\tdata[pro[1]] = {}\n\t\t\t\tif number:\n\t\t\t\t\tfor j in range(len(rolesplit)):\n\t\t\t\t\t\tdata[pro[1]][str(j + 1)] = float(rolesplit[j])\n\t\t\t\telse:\n\t\t\t\t\tfor j in range(len(rolesplit)):\n\t\t\t\t\t\tdata[pro[1]][str(j + 1)] = pro[2][rolesplit[j]]\n\t\t\telif len(pro) == 3:\n\t\t\t\tdata[pro[1]] = {\"1\": pro[2][source[j + 1:k]]}\n\t\t\telif len(pro) == 4:\n\t\t\t\tdata[pro[3]] = {\"1\": pro[2][source[j + 1:k]]}\n\t\t\telse:\n\t\t\t\tif number:\n\t\t\t\t\tdata[pro[1]] = {\"1\": float(source[j + 1:k])}\n\t\t\t\telse:\n\t\t\t\t\tdata[pro[1]] = {\"1\": source[j + 1:k]}\n\treturn\n\n", "description": null, "category": "simple", "imports": ["import json", "import hashlib", "import re", "import copy", "from xpinyin import Pinyin", "from text_to_json import ability", "from text_to_json.WikiError import editerror"]}, {"term": "def", "name": "get_lore_data_from_vpk", "data": "def get_lore_data_from_vpk(base_txt, ffile):\n\tthis_string = ffile.read().decode('utf8')\n\talltext = re.finditer('\"npc_dota_hero_(.*?)_bio\".*?\"((.|\\n)*?)\"', this_string,re.I)\n\tfor i in alltext:\n\t\tname = i.group(1)\n\t\tif name in base_txt:\n\t\t\tbase_txt[name]['lore'] = {'1': i.group(2)}\n\n", "description": null, "category": "simple", "imports": ["import json", "import hashlib", "import re", "import copy", "from xpinyin import Pinyin", "from text_to_json import ability", "from text_to_json.WikiError import editerror"]}, {"term": "def", "name": "get_dota_data_from_vpk", "data": "def get_dota_data_from_vpk(base_txt, ffile):\n\tthis_string = ffile.read().decode('utf8')\n\talltext = re.finditer('\"npc_dota_hero_(.*?)_hype\".*?\"(.*?)\"', this_string,re.I)\n\tfor i in alltext:\n\t\tname = i.group(1)\n\t\tif name in base_txt:\n\t\t\tbase_txt[name]['hype'] = {'1': i.group(2)}\n\n", "description": null, "category": "simple", "imports": ["import json", "import hashlib", "import re", "import copy", "from xpinyin import Pinyin", "from text_to_json import ability", "from text_to_json.WikiError import editerror"]}, {"term": "def", "name": "get_hero_data_from_txt", "data": "def get_hero_data_from_txt(base_txt, ffile):\n\tthis_string = ffile.read().decode('utf8')\n\talltext = re.finditer('\"npc_dota_hero_(.*?)\".*?\\n\\t{(.|\\n)*?\\n\\t}', this_string)\n\tfor i in alltext:\n\t\tname = i.group(1)\n\t\tif name == 'base':\n\t\t\tbase_txt[name] = copy.deepcopy(hero_default)\n\t\telse:\n\t\t\tbase_txt[name] = copy.deepcopy(base_txt['base'])\n\t\tall_pro = re.finditer('\\t*?\"(.*?)\".*?\"(.*?)\"', i.group(0))\n\t\tbase_txt[name]['ability'] = []\n\t\tfor j in all_pro:\n\t\t\ttemp_name = j.group(1)\n\t\t\ttemp_value = j.group(2)\n\t\t\tif re.match('Ability[0-9]+', temp_name) == None:\n\t\t\t\tbase_txt[name][temp_name] = {}\n\t\t\t\ttemp_list = temp_value.split(',')\n\t\t\t\tfor k in range(len(temp_list)):\n\t\t\t\t\ttemp_valuek = temp_list[k].strip()\n\t\t\t\t\ttry:\n\t\t\t\t\t\tbase_txt[name][temp_name][str(k + 1)] = int(temp_valuek)\n\t\t\t\t\texcept ValueError:\n\t\t\t\t\t\ttry:\n\t\t\t\t\t\t\tbase_txt[name][temp_name][str(k + 1)] = float(temp_valuek)\n\t\t\t\t\t\texcept ValueError:\n\t\t\t\t\t\t\tfor l in heropro_txt:\n\t\t\t\t\t\t\t\tif temp_name == l[1]:\n\t\t\t\t\t\t\t\t\tif len(l) == 3 and temp_valuek in l[2]:\n\t\t\t\t\t\t\t\t\t\tbase_txt[name][temp_name][str(k + 1)] = l[2][temp_valuek]\n\t\t\t\t\t\t\t\t\telif len(l) == 4 and temp_valuek in l[2]:\n\t\t\t\t\t\t\t\t\t\tbase_txt[name][l[3]] = {}\n\t\t\t\t\t\t\t\t\t\tbase_txt[name][l[3]][str(k + 1)] = l[2][temp_valuek]\n\t\t\t\t\t\t\tif str(k + 1) not in base_txt[name][temp_name]:\n\t\t\t\t\t\t\t\tbase_txt[name][temp_name][str(k + 1)] = temp_valuek\n\t\t\telse:\n\t\t\t\twhile len(base_txt[name]['ability']) <= int(temp_name[7:]):\n\t\t\t\t\tbase_txt[name]['ability'].append('')\n\t\t\t\tbase_txt[name]['ability'][int(temp_name[7:]) - 1] = temp_value\n\t\ti = 0\n\t\twhile i < len(base_txt[name]['ability']):\n\t\t\tif base_txt[name]['ability'][i] == '':\n\t\t\t\tbase_txt[name]['ability'].pop(i)\n\t\t\telse:\n\t\t\t\ti += 1\n\n", "description": null, "category": "simple", "imports": ["import json", "import hashlib", "import re", "import copy", "from xpinyin import Pinyin", "from text_to_json import ability", "from text_to_json.WikiError import editerror"]}, {"term": "def", "name": "fulfill_hero_json", "data": "def fulfill_hero_json(base_txt, all_json, version, name_base):\n\tfor i in all_json:\n\t\tif all_json[i][\"\u4ee3\u7801\u540d\"] in base_txt[\"\u82f1\u96c4\"]:\n\t\t\tall_json[i][\"\u5206\u7c7b\"] = \"\u82f1\u96c4\"\n\t\t\tall_json[i][\"\u7248\u672c\"] = version\n\t\t\tall_json[i]['\u56fe\u7247'] = 'Heroes_' + all_json[i][\"\u4ee3\u7801\u540d\"] + '.png'\n\t\t\tall_json[i]['\u8ff7\u4f60\u56fe\u7247'] = 'Miniheroes_' + all_json[i][\"\u4ee3\u7801\u540d\"] + '.png'\n\t\t\tall_json[i]['\u653b\u51fb\u540e\u6447'] = float(all_json[i]['\u653b\u51fb\u540e\u6447'])\n\t\t\tall_json[i]['\u80cc\u666f'] = base_txt[\"\u82f1\u96c4\"][all_json[i][\"\u4ee3\u7801\u540d\"]]['lore']['1']\n\t\t\tall_json[i]['\u7b80\u4ecb'] = base_txt[\"\u82f1\u96c4\"][all_json[i][\"\u4ee3\u7801\u540d\"]]['hype']['1']\n\t\t\tif '\u624b\u586b\u6807\u7b7e' not in all_json[i]:\n\t\t\t\tall_json[i]['\u624b\u586b\u6807\u7b7e']={}\n\t\t\tif '\u6807\u7b7e' not in all_json[i]:\n\t\t\t\tall_json[i]['\u6807\u7b7e']=[]\n\t\t\tfor j in heropro_txt:\n\t\t\t\tif len(j) == 4 and j[3] in base_txt[\"\u82f1\u96c4\"][all_json[i][\"\u4ee3\u7801\u540d\"]]:\n\t\t\t\t\tproname = j[3]\n\t\t\t\telif j[1] in base_txt[\"\u82f1\u96c4\"][all_json[i][\"\u4ee3\u7801\u540d\"]]:\n\t\t\t\t\tproname = j[1]\n\t\t\t\tall_json[i][j[0]] = {\"\u4ee3\u7801\": proname}\n\t\t\t\tfor k in base_txt[\"\u82f1\u96c4\"][all_json[i][\"\u4ee3\u7801\u540d\"]][proname]:\n\t\t\t\t\tall_json[i][j[0]][k] = base_txt[\"\u82f1\u96c4\"][all_json[i][\"\u4ee3\u7801\u540d\"]][proname][k]\n\t\t\tfor j in heropro_num:\n\t\t\t\tif j[1] in base_txt[\"\u82f1\u96c4\"][all_json[i][\"\u4ee3\u7801\u540d\"]]:\n\t\t\t\t\tall_json[i][j[0]] = {\"\u4ee3\u7801\": j[1]}\n\t\t\t\t\tfor k in base_txt[\"\u82f1\u96c4\"][all_json[i][\"\u4ee3\u7801\u540d\"]][j[1]]:\n\t\t\t\t\t\tall_json[i][j[0]][k] = base_txt[\"\u82f1\u96c4\"][all_json[i][\"\u4ee3\u7801\u540d\"]][j[1]][k]\n\t\t\tall_json[i]['\u524d\u6447\u51b7\u5374'] = round(all_json[i]['\u653b\u51fb\u95f4\u9694']['1'] - all_json[i]['\u653b\u51fb\u524d\u6447']['1'], 3)\n\t\t\tall_json[i]['\u603b\u524d\u540e\u6447'] = round(all_json[i]['\u653b\u51fb\u524d\u6447']['1'] + all_json[i]['\u653b\u51fb\u540e\u6447'], 3)\n\t\t\tall_json[i]['\u540e\u6447\u7a7a\u95f2'] = round(all_json[i]['\u653b\u51fb\u95f4\u9694']['1'] - all_json[i]['\u603b\u524d\u540e\u6447'], 3)\n\t\t\tall_json[i]['\u66fe\u7528\u540d'] = []\n\t\t\tif i in name_base:\n\t\t\t\tfor namej in name_base[i]:\n\t\t\t\t\tif namej != i:\n\t\t\t\t\t\tall_json[i]['\u66fe\u7528\u540d'].append(namej)\n\n", "description": null, "category": "simple", "imports": ["import json", "import hashlib", "import re", "import copy", "from xpinyin import Pinyin", "from text_to_json import ability", "from text_to_json.WikiError import editerror"]}, {"term": "def", "name": "fulfil_talent_show", "data": "def fulfil_talent_show(all_json, html_function):\n\tfor i in all_json['\u82f1\u96c4']:\n\t\tdb = all_json['\u82f1\u96c4'][i]\n\t\ttalent = {}\n\t\ttalent['\u5168\u5929\u8d4b'] = ''\n\t\tfor jj in [25, 20, 15, 10]:\n\t\t\tj = str(jj)\n\t\t\tcolorcontent = str(160 - 4 * jj) + ',' + str(160 - 4 * jj) + ',' + str(160 - 4 * jj)\n\t\t\tcolorlevel = '0,' + str(250 - 5 * jj) + ',' + str(8 * jj)\n\t\t\ttalent[j] = ''\n\t\t\ttalent[j] += '' \\\n\t\t\t\t\t\t + all_json['\u6280\u80fd'][i + j + '\u7ea7\u5de6\u5929\u8d4b']['\u4e2d\u6587\u540d'] + '' \\\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   '' \\\n\t\t\t\t\t\t + all_json['\u6280\u80fd'][i + j + '\u7ea7\u53f3\u5929\u8d4b']['\u4e2d\u6587\u540d'] + ''\n\t\t\ttalent[j] = html_function(talent[j])\n\t\t\ttalent['\u5168\u5929\u8d4b'] += talent[j]\n\t\ttalent['\u5168\u5929\u8d4b'] += ''\n\t\tdb['\u5929\u8d4b\u5c55\u793a'] = talent\n\n", "description": null, "category": "simple", "imports": ["import json", "import hashlib", "import re", "import copy", "from xpinyin import Pinyin", "from text_to_json import ability", "from text_to_json.WikiError import editerror"]}, {"term": "def", "name": "create_file", "data": "def create_file(all_json):\n\tfor i in all_json:\n\t\tfile = open(\"E:/json/pythonupload/\" + i + '.json', mode=\"w\")\n\t\tfile.write(json.dumps(all_json[i]))\n\t\tfile.close()\n\n", "description": null, "category": "simple", "imports": ["import json", "import hashlib", "import re", "import copy", "from xpinyin import Pinyin", "from text_to_json import ability", "from text_to_json.WikiError import editerror"]}, {"term": "def", "name": "fulfil_complex_and_simple_show_attri_0", "data": "def fulfil_complex_and_simple_show_attri_0(name, value):\n\treturn '' + name + '' + value + ''\n", "description": null, "category": "simple", "imports": ["import json", "import hashlib", "import re", "import copy", "from xpinyin import Pinyin", "from text_to_json import ability", "from text_to_json.WikiError import editerror"]}, {"term": "def", "name": "fulfil_complex_and_simple_show_attri_1", "data": "def fulfil_complex_and_simple_show_attri_1(name, value):\n\treturn '' + name + '' + value + ''\n\n", "description": null, "category": "simple", "imports": ["import json", "import hashlib", "import re", "import copy", "from xpinyin import Pinyin", "from text_to_json import ability", "from text_to_json.WikiError import editerror"]}, {"term": "def", "name": "fulfil_complex_and_simple_show_attri_2", "data": "def fulfil_complex_and_simple_show_attri_2(name, value, prepost=''):\n\tretxt = '' + value + ''\n\treturn retxt\n\n", "description": null, "category": "simple", "imports": ["import json", "import hashlib", "import re", "import copy", "from xpinyin import Pinyin", "from text_to_json import ability", "from text_to_json.WikiError import editerror"]}, {"term": "def", "name": "fulfil_complex_and_simple_show", "data": "def fulfil_complex_and_simple_show(all_json, html_function):\n\tfor i in all_json['\u82f1\u96c4']:\n\t\tdb = all_json['\u82f1\u96c4'][i]\n\t\t#\u4e0b\u9762\u662f\u751f\u6210\u6807\u7b7e\u529f\u80fd\n\t\tdb['\u6807\u7b7e']=[]\n\t\tfor k in db['\u624b\u586b\u6807\u7b7e']:\n\t\t\tif db['\u624b\u586b\u6807\u7b7e'][k]!='':\n\t\t\t\tdb['\u6807\u7b7e'].append(db['\u624b\u586b\u6807\u7b7e'][k])\n\t\tdb['\u6807\u7b7e'].append('\u82f1\u96c4')\n\t\tdb['\u6807\u7b7e'].append(db['\u4e3b\u5c5e\u6027']['1']+'\u82f1\u96c4')\n\t\tdb['\u6807\u7b7e'].append(db['\u8fd1\u6218\u8fdc\u7a0b']['1'])\n\t\tdb['\u6807\u7b7e'].append(db['\u9635\u8425']['1'])\n\t\tmain_color = ''\n\t\tif db[\"\u4e3b\u5c5e\u6027\"]['1'] == '\u529b\u91cf':\n\t\t\tmain_color = 'background-color:#822;'\n\t\telif db[\"\u4e3b\u5c5e\u6027\"]['1'] == '\u654f\u6377':\n\t\t\tmain_color = 'background-color:#282;'\n\t\telif db[\"\u4e3b\u5c5e\u6027\"]['1'] == '\u667a\u529b':\n\t\t\tmain_color = 'background-color:#228;'\n\t\tmain_attri_1 = {'\u529b\u91cf': '', '\u654f\u6377': '', '\u667a\u529b': ''}\n\t\tmain_attri_1[db[\"\u4e3b\u5c5e\u6027\"]['1']] = main_color\n\t\tmain_attri_2 = {'\u529b\u91cf': '', '\u654f\u6377': '', '\u667a\u529b': ''}\n\t\tmain_attri_2[db[\"\u4e3b\u5c5e\u6027\"]['1']] = '_Main'\n\t\tmain_attri = {'\u529b\u91cf': '', '\u654f\u6377': '', '\u667a\u529b': ''}\n\t\tmain_attri[db[\"\u4e3b\u5c5e\u6027\"]['1']] = 'background-color:#ff6;'\n\t\tall_attri = {}\n\t\tfor ii in ['\u529b\u91cf', '\u654f\u6377', '\u667a\u529b', '\u4e3b\u5c5e\u6027', '\u751f\u547d\u503c', '\u751f\u547d\u6062\u590d', '\u9b54\u6cd5\u503c', '\u9b54\u6cd5\u6062\u590d', '\u653b\u51fb\u4e0a\u9650', '\u653b\u51fb\u4e0b\u9650', '\u62a4\u7532', '\u653b\u51fb\u901f\u5ea6', '\u653b\u51fb\u95f4\u9694', '\u653b\u51fb\u524d\u6447']:\n\t\t\tall_attri[ii] = db[ii]['1']\n\t\tall_attri['\u751f\u547d\u503c'] += 20 * all_attri['\u529b\u91cf']\n\t\tall_attri['\u751f\u547d\u6062\u590d'] += 0.1 * all_attri['\u529b\u91cf']\n\t\tall_attri['\u9b54\u6cd5\u503c'] += 12 * all_attri['\u667a\u529b']\n\t\tall_attri['\u9b54\u6cd5\u6062\u590d'] += 0.05 * all_attri['\u667a\u529b']\n\t\tall_attri['\u653b\u51fb\u901f\u5ea6'] += all_attri['\u654f\u6377']\n\t\tall_attri['\u62a4\u7532'] += all_attri['\u654f\u6377'] / 6\n\t\tall_attri['\u653b\u51fb\u4e0a\u9650'] += all_attri[all_attri['\u4e3b\u5c5e\u6027']]\n\t\tall_attri['\u653b\u51fb\u4e0b\u9650'] += all_attri[all_attri['\u4e3b\u5c5e\u6027']]\n\t\tall_attri['\u653b\u51fb\u529b'] = (all_attri['\u653b\u51fb\u4e0a\u9650'] + all_attri['\u653b\u51fb\u4e0b\u9650']) / 2\n\t\tall_attri['\u653b\u51fb\u95f4\u9694'] = all_attri['\u653b\u51fb\u95f4\u9694'] / all_attri['\u653b\u51fb\u901f\u5ea6'] * 100\n\t\tall_attri['\u653b\u51fb\u524d\u6447'] = all_attri['\u653b\u51fb\u524d\u6447'] / all_attri['\u653b\u51fb\u901f\u5ea6'] * 100\n\t\tall_attri['\u653b\u51fb\u540e\u6447'] = db['\u653b\u51fb\u540e\u6447']/ all_attri['\u653b\u51fb\u901f\u5ea6'] * 100\n\t\tall_attri['\u7269\u7406\u6297\u6027'] = 6 * all_attri['\u62a4\u7532'] / (1 + abs(0.06 * all_attri['\u62a4\u7532']))\n\t\tall_attri['\u7269\u7406\u8840\u91cf'] =all_attri['\u751f\u547d\u503c']/(100-all_attri['\u7269\u7406\u6297\u6027'])*100\n\t\tall_attri['\u9b54\u6cd5\u8840\u91cf'] =all_attri['\u751f\u547d\u503c']/(100-db['\u9b54\u6cd5\u6297\u6027']['1'])*100\n\t\tfor ii in all_attri:\n\t\t\tif not isinstance(all_attri[ii], str):\n\t\t\t\tall_attri[ii] = round(all_attri[ii], 2)\n\t\tagha=['']\n\t\tshard=['']\n\t\tfor ii in db['\u6280\u80fd']:\n\t\t\tif int(all_json['\u6280\u80fd'][ii]['\u5e94\u7528'])==1:\n\t\t\t\tif all_json['\u6280\u80fd'][ii]['\u6b21\u7ea7\u5206\u7c7b'] == '\u9b54\u6676\u6280\u80fd':\n\t\t\t\t\tshard.append(ii)\n\t\t\t\tif all_json['\u6280\u80fd'][ii]['\u6b21\u7ea7\u5206\u7c7b'] == '\u795e\u6756\u6280\u80fd':\n\t\t\t\t\tagha.append(ii)\n\t\t\t\tif all_json['\u6280\u80fd'][ii]['\u795e\u6756\u4fe1\u606f'] != '':\n\t\t\t\t\tif agha[0] != '':\n\t\t\t\t\t\tagha[0] += ''\n\t\t\t\t\tagha[0] += all_json['\u6280\u80fd'][ii]['\u795e\u6756\u4fe1\u606f']\n\t\t\t\tif all_json['\u6280\u80fd'][ii]['\u9b54\u6676\u4fe1\u606f'] != '':\n\t\t\t\t\tif shard[0] != '':\n\t\t\t\t\t\tshard[0] += ''\n\t\t\t\t\tshard[0] += all_json['\u6280\u80fd'][ii]['\u9b54\u6676\u4fe1\u606f']\n\t\taghashard ='{{\u56fe\u7247|agha.png|h18}}\uff1a'\n\t\tif len(agha)>1:\n\t\t\taghashard+='\u63d0\u4f9b\u6280\u80fd'\n\t\t\tfor ii in range(1,len(agha)):\n\t\t\t\tif ii>1:\n\t\t\t\t\taghashard +='\u3001'\n\t\t\t\taghashard+='{{H|'+agha[ii]+'}}'\n\t\t\taghashard+=''\n\t\taghashard +=agha[0]+''\n\t\taghashard +='{{\u56fe\u7247|shard.png|w18}}\uff1a'\n\t\tif len(shard)>1:\n\t\t\taghashard+='\u63d0\u4f9b\u6280\u80fd'\n\t\t\tfor ii in range(1,len(shard)):\n\t\t\t\tif ii>1:\n\t\t\t\t\taghashard +='\u3001'\n\t\t\t\taghashard+='{{H|'+shard[ii]+'}}'\n\t\t\taghashard+=''\n\t\taghashard +=shard[0]+''\n\t\tbt = '' \\\n\t\t\t +'' \\\n\t\t\t + '' + db['\u4e2d\u6587\u540d'] + '' \\\n\t\t\t + '' + db['\u82f1\u6587\u540d'] + '[[file:npc_dota_hero_' + db['\u4ee3\u7801\u540d'] + '.webm|center|360px|link=]]' \\\n\t\t\t + '' \\\n\t\t\t + '' \\\n\t\t\t + '' \\\n\t\t\t + '' \\\n\t\t\t + '\u7b49\u7ea7' \\\n\t\t\t + '' \\\n\t\t\t + '' + str(db['\u529b\u91cf']['1']) + '+' + str(db['\u529b\u91cf\u6210\u957f']['1']) \\\n\t\t\t + '{{\u56fe\u7247|Strength_Icon' + main_attri_2['\u529b\u91cf'] + '.png|w60|center}}' + fulfil_complex_and_simple_show_attri_2('\u603b\u529b\u91cf', '', '\uff0c') + '' \\\n\t\t\t + '' + str(db['\u654f\u6377']['1']) + '+' + str(db['\u654f\u6377\u6210\u957f']['1']) \\\n\t\t\t + '{{\u56fe\u7247|Agility_Icon' + main_attri_2['\u654f\u6377'] + '.png|w60|center}}' + fulfil_complex_and_simple_show_attri_2('\u603b\u654f\u6377', '', '\uff0c') + '' \\\n\t\t\t + '' + str(db['\u667a\u529b']['1']) + '+' + str(db['\u667a\u529b\u6210\u957f']['1']) \\\n\t\t\t + '{{\u56fe\u7247|Intelligence_Icon' + main_attri_2['\u667a\u529b'] + '.png|w60|center}}' + fulfil_complex_and_simple_show_attri_2('\u603b\u667a\u529b', '', '\uff0c') + ''\\\n\t\t\t +''\\\n\t\t\t + fulfil_complex_and_simple_show_attri_0('\u751f\u547d\u503c', fulfil_complex_and_simple_show_attri_2('\u603b\u751f\u547d\u503c', str(all_attri['\u751f\u547d\u503c']))) \\\n\t\t\t + fulfil_complex_and_simple_show_attri_0('\u751f\u547d\u6062\u590d', fulfil_complex_and_simple_show_attri_2('\u603b\u751f\u547d\u6062\u590d', str(all_attri['\u751f\u547d\u6062\u590d']))) \\\n\t\t\t + fulfil_complex_and_simple_show_attri_0('\u9b54\u6cd5\u503c', fulfil_complex_and_simple_show_attri_2('\u603b\u9b54\u6cd5\u503c', str(all_attri['\u9b54\u6cd5\u503c']))) \\\n\t\t\t + fulfil_complex_and_simple_show_attri_0('\u9b54\u6cd5\u6062\u590d', fulfil_complex_and_simple_show_attri_2('\u603b\u9b54\u6cd5\u6062\u590d', str(all_attri['\u9b54\u6cd5\u6062\u590d']))) \\\n\t\t\t + fulfil_complex_and_simple_show_attri_0('\u653b\u51fb\u529b', fulfil_complex_and_simple_show_attri_2('\u603b\u653b\u51fb\u529b', ability.better_float_to_text(all_attri['\u653b\u51fb\u529b'])) \\\n\t\t\t\t\t\t\t\t\t\t\t\t\t  + '(' + fulfil_complex_and_simple_show_attri_2('\u603b\u653b\u51fb\u4e0b\u9650', str(all_attri['\u653b\u51fb\u4e0b\u9650'])) \\\n\t\t\t\t\t\t\t\t\t\t\t\t\t  + '~' + fulfil_complex_and_simple_show_attri_2('\u603b\u653b\u51fb\u4e0a\u9650', str(all_attri['\u653b\u51fb\u4e0a\u9650'])) + ')') \\\n\t\t\t + fulfil_complex_and_simple_show_attri_0('\u653b\u51fb\u901f\u5ea6', fulfil_complex_and_simple_show_attri_2('\u603b\u653b\u51fb\u901f\u5ea6', str(all_attri['\u653b\u51fb\u901f\u5ea6'])) + '(' + str(db['\u653b\u51fb\u901f\u5ea6']['1']) + ')') \\\n\t\t\t + fulfil_complex_and_simple_show_attri_0('\u653b\u51fb\u95f4\u9694', fulfil_complex_and_simple_show_attri_2('\u603b\u653b\u51fb\u95f4\u9694', str(all_attri['\u653b\u51fb\u95f4\u9694'])) + '(' + str(db['\u653b\u51fb\u95f4\u9694']['1']) + ')') \\\n\t\t\t + fulfil_complex_and_simple_show_attri_0('\u653b\u51fb\u524d\u6447', fulfil_complex_and_simple_show_attri_2('\u603b\u653b\u51fb\u524d\u6447', str(all_attri['\u653b\u51fb\u524d\u6447'])) + '(' + str(db['\u653b\u51fb\u524d\u6447']['1']) + ')') \\\n\t\t\t + fulfil_complex_and_simple_show_attri_0('\u653b\u51fb\u540e\u6447', fulfil_complex_and_simple_show_attri_2('\u603b\u653b\u51fb\u540e\u6447', str(all_attri['\u653b\u51fb\u540e\u6447'])) + '(' + str(db['\u653b\u51fb\u540e\u6447']) + ')') \\\n\t\t\t + fulfil_complex_and_simple_show_attri_0('\u653b\u51fb\u8ddd\u79bb', fulfil_complex_and_simple_show_attri_2('\u603b\u653b\u51fb\u8ddd\u79bb', str(db['\u653b\u51fb\u8ddd\u79bb']['1']))) \\\n\t\t\t + fulfil_complex_and_simple_show_attri_0('\u8b66\u6212\u8303\u56f4', fulfil_complex_and_simple_show_attri_2('\u603b\u8b66\u6212\u8303\u56f4', str(db['\u8b66\u6212\u8303\u56f4']['1']))) \\\n\t\t\t + fulfil_complex_and_simple_show_attri_0('\u5f39\u9053\u901f\u5ea6', fulfil_complex_and_simple_show_attri_2('\u603b\u5f39\u9053\u901f\u5ea6', str(db['\u5f39\u9053\u901f\u5ea6']['1']))) \\\n\t\t\t + fulfil_complex_and_simple_show_attri_0('\u62a4\u7532(\u7269\u7406\u6297\u6027)', fulfil_complex_and_simple_show_attri_2('\u603b\u62a4\u7532', str(all_attri['\u62a4\u7532'])) \\\n\t\t\t\t\t\t\t\t\t\t\t\t\t  + '(' + fulfil_complex_and_simple_show_attri_2('\u603b\u7269\u7406\u6297\u6027', str(all_attri['\u7269\u7406\u6297\u6027']) + '%', '\uff0c%') + ')') \\\n\t\t\t + fulfil_complex_and_simple_show_attri_0('\u7269\u7406\u8840\u91cf', fulfil_complex_and_simple_show_attri_2('\u603b\u7269\u7406\u8840\u91cf',str(all_attri['\u7269\u7406\u8840\u91cf']))) \\\n\t\t\t + fulfil_complex_and_simple_show_attri_0('\u9b54\u6cd5\u6297\u6027', fulfil_complex_and_simple_show_attri_2('\u603b\u9b54\u6cd5\u6297\u6027', str(db['\u9b54\u6cd5\u6297\u6027']['1']) + '%', '\uff0c%')) \\\n\t\t\t + fulfil_complex_and_simple_show_attri_0('\u9b54\u6cd5\u8840\u91cf', fulfil_complex_and_simple_show_attri_2('\u603b\u9b54\u6cd5\u8840\u91cf',str(all_attri['\u9b54\u6cd5\u8840\u91cf']))) \\\n\t\t\t + fulfil_complex_and_simple_show_attri_0('\u79fb\u52a8\u901f\u5ea6', fulfil_complex_and_simple_show_attri_2('\u603b\u79fb\u52a8\u901f\u5ea6', str(db['\u79fb\u52a8\u901f\u5ea6']['1']))) \\\n\t\t\t + fulfil_complex_and_simple_show_attri_0('\u8f6c\u8eab\u901f\u7387', fulfil_complex_and_simple_show_attri_2('\u603b\u8f6c\u8eab\u901f\u7387', str(db['\u8f6c\u8eab\u901f\u7387']['1']))) \\\n\t\t\t + fulfil_complex_and_simple_show_attri_0('\u767d\u5929\u89c6\u91ce', fulfil_complex_and_simple_show_attri_2('\u603b\u767d\u5929\u89c6\u91ce', str(db['\u767d\u5929\u89c6\u91ce']['1']))) \\\n\t\t\t + fulfil_complex_and_simple_show_attri_0('\u591c\u665a\u89c6\u91ce', fulfil_complex_and_simple_show_attri_2('\u603b\u591c\u665a\u89c6\u91ce', str(db['\u591c\u665a\u89c6\u91ce']['1']))) \\\n\t\t\t + fulfil_complex_and_simple_show_attri_0('\u78b0\u649e\u4f53\u79ef', fulfil_complex_and_simple_show_attri_2('\u603b\u78b0\u649e\u4f53\u79ef',str(db['\u78b0\u649e\u4f53\u79ef']['1']))) \\\n\t\t\t + fulfil_complex_and_simple_show_attri_0('\u8fb9\u754c\u4f53\u79ef', fulfil_complex_and_simple_show_attri_2('\u603b\u8fb9\u754c\u4f53\u79ef',str(db['\u8fb9\u754c\u4f53\u79ef']['1']))) \\\n\t\t\t + fulfil_complex_and_simple_show_attri_0('\u817f\u6570\u91cf', fulfil_complex_and_simple_show_attri_2('\u603b\u817f\u6570\u91cf',str(db['\u817f\u6570\u91cf']['1']))) \\\n\t\t\t + ''\\\n\t\t\t +''# \u5b8c\u6574\u663e\u793a\n\t\tst = '' \\\n\t\t\t + '' \\\n\t\t\t + '' \\\n\t\t\t + '[[' + db[\"\u9875\u9762\u540d\"] + '|' + db[\"\u4e2d\u6587\u540d\"] + ']]' \\\n\t\t\t + '' + db[\"\u82f1\u6587\u540d\"] + '' \\\n\t\t\t + '' \\\n\t\t\t + '' \\\n\t\t\t + '' \\\n\t\t\t + '' \\\n\t\t\t + '' \\\n\t\t\t + '' + str(db['\u529b\u91cf']['1']) + '+' + str(db['\u529b\u91cf\u6210\u957f']['1']) \\\n\t\t\t + fulfil_complex_and_simple_show_attri_2('\u603b\u529b\u91cf', '', '=\uff0c') + '' + str(db['\u654f\u6377']['1']) + '+' + str(db['\u654f\u6377\u6210\u957f']['1']) \\\n\t\t\t + fulfil_complex_and_simple_show_attri_2('\u603b\u654f\u6377', '', '=\uff0c') + '' + str(db['\u667a\u529b']['1']) + '+' + str(db['\u667a\u529b\u6210\u957f']['1']) \\\n\t\t\t + fulfil_complex_and_simple_show_attri_2('\u603b\u667a\u529b', '', '=\uff0c') \\\n\t\t\t + '' \\\n\t\t\t + '' \\\n\t\t\t + fulfil_complex_and_simple_show_attri_1('\u751f\u547d\u503c', fulfil_complex_and_simple_show_attri_2('\u603b\u751f\u547d\u503c', str(all_attri['\u751f\u547d\u503c']))) \\\n\t\t\t + fulfil_complex_and_simple_show_attri_1('\u751f\u547d\u6062\u590d', fulfil_complex_and_simple_show_attri_2('\u603b\u751f\u547d\u6062\u590d', str(all_attri['\u751f\u547d\u6062\u590d']))) \\\n\t\t\t + fulfil_complex_and_simple_show_attri_1('\u9b54\u6cd5\u503c', fulfil_complex_and_simple_show_attri_2('\u603b\u9b54\u6cd5\u503c', str(all_attri['\u9b54\u6cd5\u503c']))) \\\n\t\t\t + fulfil_complex_and_simple_show_attri_1('\u9b54\u6cd5\u6062\u590d', fulfil_complex_and_simple_show_attri_2('\u603b\u9b54\u6cd5\u6062\u590d', str(all_attri['\u9b54\u6cd5\u6062\u590d']))) \\\n\t\t\t + fulfil_complex_and_simple_show_attri_1('\u653b\u51fb\u529b', fulfil_complex_and_simple_show_attri_2('\u603b\u653b\u51fb\u529b', ability.better_float_to_text(all_attri['\u653b\u51fb\u529b'])) \\\n\t\t\t\t\t\t\t\t\t\t\t\t\t  + '(' + fulfil_complex_and_simple_show_attri_2('\u603b\u653b\u51fb\u4e0b\u9650', str(all_attri['\u653b\u51fb\u4e0b\u9650'])) \\\n\t\t\t\t\t\t\t\t\t\t\t\t\t  + '~' + fulfil_complex_and_simple_show_attri_2('\u603b\u653b\u51fb\u4e0a\u9650', str(all_attri['\u653b\u51fb\u4e0a\u9650'])) + ')') \\\n\t\t\t + fulfil_complex_and_simple_show_attri_1('\u653b\u51fb\u901f\u5ea6', fulfil_complex_and_simple_show_attri_2('\u603b\u653b\u51fb\u901f\u5ea6', str(all_attri['\u653b\u51fb\u901f\u5ea6'])) + '(' + str(db['\u653b\u51fb\u901f\u5ea6']['1']) + ')') \\\n\t\t\t + fulfil_complex_and_simple_show_attri_1('\u653b\u51fb\u95f4\u9694', fulfil_complex_and_simple_show_attri_2('\u603b\u653b\u51fb\u95f4\u9694', str(all_attri['\u653b\u51fb\u95f4\u9694'])) + '(' + str(db['\u653b\u51fb\u95f4\u9694']['1']) + ')') \\\n\t\t\t + fulfil_complex_and_simple_show_attri_1('\u653b\u51fb\u524d\u6447', fulfil_complex_and_simple_show_attri_2('\u603b\u653b\u51fb\u524d\u6447', str(all_attri['\u653b\u51fb\u524d\u6447'])) + '(' + str(db['\u653b\u51fb\u524d\u6447']['1']) + ')') \\\n\t\t\t + fulfil_complex_and_simple_show_attri_1('\u653b\u51fb\u8ddd\u79bb', fulfil_complex_and_simple_show_attri_2('\u603b\u653b\u51fb\u8ddd\u79bb', str(db['\u653b\u51fb\u8ddd\u79bb']['1']))) \\\n\t\t\t + fulfil_complex_and_simple_show_attri_1('\u5f39\u9053\u901f\u5ea6', fulfil_complex_and_simple_show_attri_2('\u603b\u5f39\u9053\u901f\u5ea6', str(db['\u5f39\u9053\u901f\u5ea6']['1']))) \\\n\t\t\t + fulfil_complex_and_simple_show_attri_1('\u62a4\u7532', fulfil_complex_and_simple_show_attri_2('\u603b\u62a4\u7532', str(all_attri['\u62a4\u7532'])) \\\n\t\t\t\t\t\t\t\t\t\t\t\t\t  + '(' + fulfil_complex_and_simple_show_attri_2('\u603b\u7269\u7406\u6297\u6027', str(all_attri['\u7269\u7406\u6297\u6027']) + '%', '\uff0c%') + ')') \\\n\t\t\t + fulfil_complex_and_simple_show_attri_1('\u9b54\u6cd5\u6297\u6027', fulfil_complex_and_simple_show_attri_2('\u603b\u9b54\u6cd5\u6297\u6027', str(db['\u9b54\u6cd5\u6297\u6027']['1']) + '%', '\uff0c%')) \\\n\t\t\t + fulfil_complex_and_simple_show_attri_1('\u79fb\u52a8\u901f\u5ea6', fulfil_complex_and_simple_show_attri_2('\u603b\u79fb\u52a8\u901f\u5ea6', str(db['\u79fb\u52a8\u901f\u5ea6']['1']))) \\\n\t\t\t + fulfil_complex_and_simple_show_attri_1('\u8f6c\u8eab\u901f\u7387', fulfil_complex_and_simple_show_attri_2('\u603b\u8f6c\u8eab\u901f\u7387', str(db['\u8f6c\u8eab\u901f\u7387']['1']))) \\\n\t\t\t + fulfil_complex_and_simple_show_attri_1('\u767d\u5929\u89c6\u91ce', fulfil_complex_and_simple_show_attri_2('\u603b\u767d\u5929\u89c6\u91ce', str(db['\u767d\u5929\u89c6\u91ce']['1']))) \\\n\t\t\t + fulfil_complex_and_simple_show_attri_1('\u591c\u665a\u89c6\u91ce', fulfil_complex_and_simple_show_attri_2('\u603b\u591c\u665a\u89c6\u91ce', str(db['\u591c\u665a\u89c6\u91ce']['1']))) \\\n\t\t\t + '' \\\n\t\t\t +''\n\t\tfor ii in range(len(db['\u6280\u80fd']) - 8):\n\t\t\tv = db['\u6280\u80fd'][ii]\n\t\t\tbt += '[[#'+v+'|{{\u5927\u56fe\u7247|'+v+'|w36|text=0|center}}]]'\n\t\t\tst += '' \\\n\t\t\t\t  '' \\\n\t\t\t\t\t'' \\\n\t\t\t\t\t'\u70b9\u51fb\u663e\u793a\u300a' + v + '\u300b\u8be6\u7ec6\u4fe1\u606f'\n\t\tbt += '' \\\n\t\t\t  + '' + all_json['\u6280\u80fd'][i + '25\u7ea7\u5de6\u5929\u8d4b']['\u4e2d\u6587\u540d'] \\\n\t\t\t  + '25' + all_json['\u6280\u80fd'][i + '25\u7ea7\u53f3\u5929\u8d4b']['\u4e2d\u6587\u540d'] + '' \\\n\t\t\t  + '' + all_json['\u6280\u80fd'][i + '20\u7ea7\u5de6\u5929\u8d4b']['\u4e2d\u6587\u540d'] \\\n\t\t\t  + '20' + all_json['\u6280\u80fd'][i + '20\u7ea7\u53f3\u5929\u8d4b']['\u4e2d\u6587\u540d'] + '' \\\n\t\t\t  + '' + all_json['\u6280\u80fd'][i + '15\u7ea7\u5de6\u5929\u8d4b']['\u4e2d\u6587\u540d'] \\\n\t\t\t  + '15' + all_json['\u6280\u80fd'][i + '15\u7ea7\u53f3\u5929\u8d4b']['\u4e2d\u6587\u540d'] + '' \\\n\t\t\t  +'' + all_json['\u6280\u80fd'][i + '10\u7ea7\u5de6\u5929\u8d4b']['\u4e2d\u6587\u540d'] \\\n\t\t\t  + '10' + all_json['\u6280\u80fd'][i + '10\u7ea7\u53f3\u5929\u8d4b']['\u4e2d\u6587\u540d'] + '' \\\n\t\t\t  + ''\n\t\tst += '' \\\n\t\t\t  + '' + all_json['\u6280\u80fd'][i + '25\u7ea7\u5de6\u5929\u8d4b']['\u4e2d\u6587\u540d'] \\\n\t\t\t  + '25' + all_json['\u6280\u80fd'][i + '25\u7ea7\u53f3\u5929\u8d4b']['\u4e2d\u6587\u540d'] + '' \\\n\t\t\t  + '' + all_json['\u6280\u80fd'][i + '20\u7ea7\u5de6\u5929\u8d4b']['\u4e2d\u6587\u540d'] \\\n\t\t\t  + '20' + all_json['\u6280\u80fd'][i + '20\u7ea7\u53f3\u5929\u8d4b']['\u4e2d\u6587\u540d'] + '' \\\n\t\t\t  + '' + all_json['\u6280\u80fd'][i + '15\u7ea7\u5de6\u5929\u8d4b']['\u4e2d\u6587\u540d'] \\\n\t\t\t  + '15' + all_json['\u6280\u80fd'][i + '15\u7ea7\u53f3\u5929\u8d4b']['\u4e2d\u6587\u540d'] + '' \\\n\t\t\t  +'' + all_json['\u6280\u80fd'][i + '10\u7ea7\u5de6\u5929\u8d4b']['\u4e2d\u6587\u540d'] \\\n\t\t\t  + '10' + all_json['\u6280\u80fd'][i + '10\u7ea7\u53f3\u5929\u8d4b']['\u4e2d\u6587\u540d'] + '' \\\n\t\t\t  + ''\n\t\tbt+=aghashard\n\t\tst+=aghashard\n\t\tif db['\u5168\u5c5e\u6027\u9ec4\u70b9'] > 0:\n\t\t\tbt += '+ 2 \u5168 \u5c5e \u6027'\n\t\t\tst += '+ 2 \u5168 \u5c5e \u6027'\n\t\tbt += '[[data:' + db[\"\u9875\u9762\u540d\"] + '.json|J]]'\\\n\t\t\t  +'[[#' + db[\"\u9875\u9762\u540d\"] + '|' + db[\"\u9875\u9762\u540d\"] + ']]'\n\t\tst += ''\n\t\t# \u7f29\u7565\u663e\u793a\n\t\tdb['\u7b80\u6613\u5c55\u793a'] = html_function(st)\n\t\tdb['\u5177\u4f53\u5c55\u793a'] = html_function(bt)\n\n", "description": null, "category": "simple", "imports": ["import json", "import hashlib", "import re", "import copy", "from xpinyin import Pinyin", "from text_to_json import ability", "from text_to_json.WikiError import editerror"]}, {"term": "def", "name": "create_html_data_page", "data": "def create_html_data_page(all_json):\n\tretxt = ''\n\treturn retxt\n\n", "description": null, "category": "simple", "imports": ["import json", "import hashlib", "import re", "import copy", "from xpinyin import Pinyin", "from text_to_json import ability", "from text_to_json.WikiError import editerror"]}], [{"term": "def", "name": "test_worker_producer", "data": "def test_worker_producer(app):\n\tt = GlobalTestData()\n\n\t@app.pipeline()\n\tdef simple_pipeline(pipeline, x):\n\t\treturn x.subscribe_func(t.save_multiple_items)\n\n\t@app.producer(simple_pipeline)\n\tdef batch_handler(x):\n\t\tyield dict(x=x)\n\n\t@app.batch_producer(batch_handler)\n\tdef worker_producer():\n\t\tfor i in range(10):\n\t\t\t# here we should yield batch of data\n\t\t\tyield dict(x=1)\n\n\tsimple_pipeline.compile()\n\tworker_producer()\n\ttry:\n\t\tworker_producer()\n\t\trun_jobs_processor(app.project,\n\t\t\t\t\t\t   [batch_handler],\n\t\t\t\t\t\t   die_when_empty=True)\n\texcept SystemExit:\n\t\tpass\n\n\trun_pipelines(app)\n\n\tassert len(t.get_result()) == 20  # 10 batches with 2 jobs\n\n", "description": null, "category": "simple", "imports": ["from utils import function_as_step, run_pipelines, GlobalTestData", "from stairs.core.producer import run_jobs_processor"]}, {"term": "def", "name": "test_multiple_pipelines_for_batch_producer", "data": "def test_multiple_pipelines_for_batch_producer(app):\n\tt = GlobalTestData()\n\n\t@app.pipeline()\n\tdef simple_pipeline(pipeline, x):\n\t\treturn x.subscribe_func(t.save_multiple_items)\n\n\t@app.pipeline()\n\tdef simple_pipeline2(pipeline, x):\n\t\treturn x.subscribe_func(t.save_multiple_items)\n\n\t@app.producer(simple_pipeline, simple_pipeline2)\n\tdef batch_handler(x):\n\t\tyield dict(x=x)\n\n\t@app.batch_producer(batch_handler)\n\tdef worker_producer():\n\t\tfor i in range(10):\n\t\t\t# here we should yield batch of data\n\t\t\tyield dict(x=1)\n\n\tsimple_pipeline.compile()\n\tsimple_pipeline2.compile()\n\n\tworker_producer()\n\ttry:\n\t\tworker_producer()\n\t\trun_jobs_processor(app.project,\n\t\t\t\t\t\t   [batch_handler],\n\t\t\t\t\t\t   die_when_empty=True)\n\texcept SystemExit:\n\t\tpass\n\n\trun_pipelines(app)\n\n", "description": null, "category": "simple", "imports": ["from utils import function_as_step, run_pipelines, GlobalTestData", "from stairs.core.producer import run_jobs_processor"]}], [{"term": "class", "name": "TestLibraryInfo", "data": "class TestLibraryInfo(TestCase):\n\tdef test_simple(self):\n\t\tfd, filename = mkstemp('foo.ini')\n\t\ttry:\n\t\t\tpkg = os.path.splitext(filename)[0]\n\t\t\ttry:\n\t\t\t\tos.write(fd, simple.encode('ascii'))\n\t\t\tfinally:\n\t\t\t\tos.close(fd)\n\n\t\t\tout = read_config(pkg)\n\t\t\tself.assertTrue(out.cflags() == simple_d['cflags'])\n\t\t\tself.assertTrue(out.libs() == simple_d['libflags'])\n\t\t\tself.assertTrue(out.name == simple_d['name'])\n\t\t\tself.assertTrue(out.version == simple_d['version'])\n\t\tfinally:\n\t\t\tos.remove(filename)\n\n\tdef test_simple_variable(self):\n\t\tfd, filename = mkstemp('foo.ini')\n\t\ttry:\n\t\t\tpkg = os.path.splitext(filename)[0]\n\t\t\ttry:\n\t\t\t\tos.write(fd, simple_variable.encode('ascii'))\n\t\t\tfinally:\n\t\t\t\tos.close(fd)\n\n\t\t\tout = read_config(pkg)\n\t\t\tself.assertTrue(out.cflags() == simple_variable_d['cflags'])\n\t\t\tself.assertTrue(out.libs() == simple_variable_d['libflags'])\n\t\t\tself.assertTrue(out.name == simple_variable_d['name'])\n\t\t\tself.assertTrue(out.version == simple_variable_d['version'])\n\n\t\t\tout.vars['prefix'] = '/Users/david'\n\t\t\tself.assertTrue(out.cflags() == '-I/Users/david/include')\n\t\tfinally:\n\t\t\tos.remove(filename)\n", "description": null, "category": "simple", "imports": ["import os", "from tempfile import mkstemp", "from numpy.testing import *", "from numpy.distutils.npy_pkg_config import read_config, parse_flags"]}, {"term": "class", "name": "TestParseFlags", "data": "class TestParseFlags(TestCase):\n\tdef test_simple_cflags(self):\n\t\td = parse_flags(\"-I/usr/include\")\n\t\tself.assertTrue(d['include_dirs'] == ['/usr/include'])\n\n\t\td = parse_flags(\"-I/usr/include -DFOO\")\n\t\tself.assertTrue(d['include_dirs'] == ['/usr/include'])\n\t\tself.assertTrue(d['macros'] == ['FOO'])\n\n\t\td = parse_flags(\"-I /usr/include -DFOO\")\n\t\tself.assertTrue(d['include_dirs'] == ['/usr/include'])\n\t\tself.assertTrue(d['macros'] == ['FOO'])\n\n\tdef test_simple_lflags(self):\n\t\td = parse_flags(\"-L/usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tself.assertTrue(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tself.assertTrue(d['libraries'] == ['foo', 'bar'])\n\n\t\td = parse_flags(\"-L /usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tself.assertTrue(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tself.assertTrue(d['libraries'] == ['foo', 'bar'])\n", "description": null, "category": "simple", "imports": ["import os", "from tempfile import mkstemp", "from numpy.testing import *", "from numpy.distutils.npy_pkg_config import read_config, parse_flags"]}], [{"term": "class", "name": "TestLibraryInfo", "data": "class TestLibraryInfo(TestCase):\n\tdef test_simple(self):\n\t\tfd, filename = mkstemp('foo.ini')\n\t\ttry:\n\t\t\tpkg = os.path.splitext(filename)[0]\n\t\t\ttry:\n\t\t\t\tos.write(fd, simple.encode('ascii'))\n\t\t\tfinally:\n\t\t\t\tos.close(fd)\n\n\t\t\tout = read_config(pkg)\n\t\t\tself.assertTrue(out.cflags() == simple_d['cflags'])\n\t\t\tself.assertTrue(out.libs() == simple_d['libflags'])\n\t\t\tself.assertTrue(out.name == simple_d['name'])\n\t\t\tself.assertTrue(out.version == simple_d['version'])\n\t\tfinally:\n\t\t\tos.remove(filename)\n\n\tdef test_simple_variable(self):\n\t\tfd, filename = mkstemp('foo.ini')\n\t\ttry:\n\t\t\tpkg = os.path.splitext(filename)[0]\n\t\t\ttry:\n\t\t\t\tos.write(fd, simple_variable.encode('ascii'))\n\t\t\tfinally:\n\t\t\t\tos.close(fd)\n\n\t\t\tout = read_config(pkg)\n\t\t\tself.assertTrue(out.cflags() == simple_variable_d['cflags'])\n\t\t\tself.assertTrue(out.libs() == simple_variable_d['libflags'])\n\t\t\tself.assertTrue(out.name == simple_variable_d['name'])\n\t\t\tself.assertTrue(out.version == simple_variable_d['version'])\n\n\t\t\tout.vars['prefix'] = '/Users/david'\n\t\t\tself.assertTrue(out.cflags() == '-I/Users/david/include')\n\t\tfinally:\n\t\t\tos.remove(filename)\n", "description": null, "category": "simple", "imports": ["import os", "from tempfile import mkstemp", "from numpy.testing import *", "from numpy.distutils.npy_pkg_config import read_config, parse_flags"]}, {"term": "class", "name": "TestParseFlags", "data": "class TestParseFlags(TestCase):\n\tdef test_simple_cflags(self):\n\t\td = parse_flags(\"-I/usr/include\")\n\t\tself.assertTrue(d['include_dirs'] == ['/usr/include'])\n\n\t\td = parse_flags(\"-I/usr/include -DFOO\")\n\t\tself.assertTrue(d['include_dirs'] == ['/usr/include'])\n\t\tself.assertTrue(d['macros'] == ['FOO'])\n\n\t\td = parse_flags(\"-I /usr/include -DFOO\")\n\t\tself.assertTrue(d['include_dirs'] == ['/usr/include'])\n\t\tself.assertTrue(d['macros'] == ['FOO'])\n\n\tdef test_simple_lflags(self):\n\t\td = parse_flags(\"-L/usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tself.assertTrue(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tself.assertTrue(d['libraries'] == ['foo', 'bar'])\n\n\t\td = parse_flags(\"-L /usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tself.assertTrue(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tself.assertTrue(d['libraries'] == ['foo', 'bar'])\n", "description": null, "category": "simple", "imports": ["import os", "from tempfile import mkstemp", "from numpy.testing import *", "from numpy.distutils.npy_pkg_config import read_config, parse_flags"]}], [{"term": "class", "name": "TestMWSResponse", "data": "class TestMWSResponse(AWSMockServiceTestCase):\n\tconnection_class = MWSConnection\n\tmws = True\n\n\tdef test_parsing_nested_elements(self):\n\t\tclass Test9one(ResponseElement):\n\t\t\tNest = Element()\n\t\t\tZoom = Element()\n\n\t\tclass Test9Result(ResponseElement):\n\t\t\tItem = Element(Test9one)\n\n\t\ttext = b\"\"\"\n", "description": "\n", "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_member_list_specification", "data": "\tdef test_parsing_member_list_specification(self):\n\t\tclass Test8extra(ResponseElement):\n\t\t\tFoo = SimpleList()\n\n\t\tclass Test8Result(ResponseElement):\n\t\t\tItem = MemberList(SimpleList)\n\t\t\tExtra = MemberList(Test8extra)\n\n\t\ttext = b\"\"\"\n", "description": "\n", "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_nested_lists", "data": "\tdef test_parsing_nested_lists(self):\n\t\tclass Test7Result(ResponseElement):\n\t\t\tItem = MemberList(Nest=MemberList(),\n\t\t\t\t\t\t\t  List=ElementList(Simple=SimpleList()))\n\n\t\ttext = b\"\"\"\n\n", "description": "\n\n", "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_member_list", "data": "\tdef test_parsing_member_list(self):\n\t\tclass Test6Result(ResponseElement):\n\t\t\tItem = MemberList()\n\n\t\ttext = b\"\"\"\n", "description": "\n", "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_empty_member_list", "data": "\tdef test_parsing_empty_member_list(self):\n\t\tclass Test5Result(ResponseElement):\n\t\t\tItem = MemberList(Nest=MemberList())\n\n\t\ttext = b\"\"\"\n", "description": "\n", "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_missing_member_list", "data": "\tdef test_parsing_missing_member_list(self):\n\t\tclass Test4Result(ResponseElement):\n\t\t\tItem = MemberList(NestedItem=MemberList())\n\n", "description": null, "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_element_lists", "data": "\tdef test_parsing_element_lists(self):\n\t\tclass Test1Result(ResponseElement):\n\t\t\tItem = ElementList()\n\n", "description": null, "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_missing_lists", "data": "\tdef test_parsing_missing_lists(self):\n\t\tclass Test2Result(ResponseElement):\n\t\t\tItem = ElementList()\n\n", "description": null, "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_simple_lists", "data": "\tdef test_parsing_simple_lists(self):\n\t\tclass Test3Result(ResponseElement):\n\t\t\tItem = SimpleList()\n\n", "description": null, "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "fcheck_issue", "data": "\tdef check_issue(self, klass, text):\n\t\taction = klass.__name__[:-len('Result')]\n\t\tfactory = ResponseFactory(scopes=[{klass.__name__: klass}])\n\t\tparser = factory(action, connection=self.service_connection)\n\t\treturn self.service_connection._parse_response(parser, 'text/xml', text)\n\n", "description": null, "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}], [{"term": "def", "name": "trim", "data": "def trim(value, num):\n\treturn value[:num]\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six"]}, {"term": "def", "name": "noop", "data": "def noop(value, param=None):\n\t\"\"\"A noop filter that always return its first argument and does nothing with\n\tits second (optional) one.\n\tUseful for testing out whitespace in filter arguments (see #19882).\"\"\"\n\treturn value\n\n", "description": "A noop filter that always return its first argument and does nothing with\n\tits second (optional) one.\n\tUseful for testing out whitespace in filter arguments (see #19882).", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six"]}, {"term": "def", "name": "context_stack_length", "data": "def context_stack_length(context):\n\treturn len(context.dicts)\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six"]}, {"term": "def", "name": "no_params", "data": "def no_params():\n\t\"\"\"Expected no_params __doc__\"\"\"\n", "description": "Expected no_params __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six"]}, {"term": "def", "name": "one_param", "data": "def one_param(arg):\n\t\"\"\"Expected one_param __doc__\"\"\"\n", "description": "Expected one_param __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six"]}, {"term": "def", "name": "explicit_no_context", "data": "def explicit_no_context(arg):\n\t\"\"\"Expected explicit_no_context __doc__\"\"\"\n", "description": "Expected explicit_no_context __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six"]}, {"term": "def", "name": "no_params_with_context", "data": "def no_params_with_context(context):\n\t\"\"\"Expected no_params_with_context __doc__\"\"\"\n", "description": "Expected no_params_with_context __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six"]}, {"term": "def", "name": "params_and_context", "data": "def params_and_context(context, arg):\n\t\"\"\"Expected params_and_context __doc__\"\"\"\n", "description": "Expected params_and_context __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six"]}, {"term": "def", "name": "simple_two_params", "data": "def simple_two_params(one, two):\n\t\"\"\"Expected simple_two_params __doc__\"\"\"\n", "description": "Expected simple_two_params __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six"]}, {"term": "def", "name": "simple_one_default", "data": "def simple_one_default(one, two='hi'):\n\t\"\"\"Expected simple_one_default __doc__\"\"\"\n", "description": "Expected simple_one_default __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six"]}, {"term": "def", "name": "simple_unlimited_args", "data": "def simple_unlimited_args(one, two='hi', *args):\n\t\"\"\"Expected simple_unlimited_args __doc__\"\"\"\n", "description": "Expected simple_unlimited_args __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six"]}, {"term": "def", "name": "simple_only_unlimited_args", "data": "def simple_only_unlimited_args(*args):\n\t\"\"\"Expected simple_only_unlimited_args __doc__\"\"\"\n", "description": "Expected simple_only_unlimited_args __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six"]}, {"term": "def", "name": "simple_unlimited_args_kwargs", "data": "def simple_unlimited_args_kwargs(one, two='hi', *args, **kwargs):\n\t\"\"\"Expected simple_unlimited_args_kwargs __doc__\"\"\"\n\t# Sort the dictionary by key to guarantee the order for testing.\n\tsorted_kwarg = sorted(six.iteritems(kwargs), key=operator.itemgetter(0))\n\treturn \"simple_unlimited_args_kwargs - Expected result: %s / %s\" % (\n\t\t', '.join(six.text_type(arg) for arg in [one, two] + list(args)),\n\t\t', '.join('%s=%s' % (k, v) for (k, v) in sorted_kwarg)\n", "description": "Expected simple_unlimited_args_kwargs __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six"]}, {"term": "def", "name": "simple_tag_without_context_parameter", "data": "def simple_tag_without_context_parameter(arg):\n\t\"\"\"Expected simple_tag_without_context_parameter __doc__\"\"\"\n", "description": "Expected simple_tag_without_context_parameter __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six"]}, {"term": "def", "name": "current_app", "data": "def current_app(context):\n\treturn \"%s\" % context.current_app\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six"]}, {"term": "def", "name": "use_l10n", "data": "def use_l10n(context):\n\treturn \"%s\" % context.use_l10n\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six"]}, {"term": "def", "name": "minustwo_overridden_name", "data": "def minustwo_overridden_name(value):\n\treturn value - 2\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six"]}, {"term": "def", "name": "assignment_no_params", "data": "def assignment_no_params():\n\t\"\"\"Expected assignment_no_params __doc__\"\"\"\n", "description": "Expected assignment_no_params __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six"]}, {"term": "def", "name": "assignment_one_param", "data": "def assignment_one_param(arg):\n\t\"\"\"Expected assignment_one_param __doc__\"\"\"\n", "description": "Expected assignment_one_param __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six"]}, {"term": "def", "name": "assignment_explicit_no_context", "data": "def assignment_explicit_no_context(arg):\n\t\"\"\"Expected assignment_explicit_no_context __doc__\"\"\"\n", "description": "Expected assignment_explicit_no_context __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six"]}, {"term": "def", "name": "assignment_no_params_with_context", "data": "def assignment_no_params_with_context(context):\n\t\"\"\"Expected assignment_no_params_with_context __doc__\"\"\"\n", "description": "Expected assignment_no_params_with_context __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six"]}, {"term": "def", "name": "assignment_params_and_context", "data": "def assignment_params_and_context(context, arg):\n\t\"\"\"Expected assignment_params_and_context __doc__\"\"\"\n", "description": "Expected assignment_params_and_context __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six"]}, {"term": "def", "name": "assignment_two_params", "data": "def assignment_two_params(one, two):\n\t\"\"\"Expected assignment_two_params __doc__\"\"\"\n", "description": "Expected assignment_two_params __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six"]}, {"term": "def", "name": "assignment_one_default", "data": "def assignment_one_default(one, two='hi'):\n\t\"\"\"Expected assignment_one_default __doc__\"\"\"\n", "description": "Expected assignment_one_default __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six"]}, {"term": "def", "name": "assignment_unlimited_args", "data": "def assignment_unlimited_args(one, two='hi', *args):\n\t\"\"\"Expected assignment_unlimited_args __doc__\"\"\"\n", "description": "Expected assignment_unlimited_args __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six"]}, {"term": "def", "name": "assignment_only_unlimited_args", "data": "def assignment_only_unlimited_args(*args):\n\t\"\"\"Expected assignment_only_unlimited_args __doc__\"\"\"\n", "description": "Expected assignment_only_unlimited_args __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six"]}, {"term": "def", "name": "assignment_unlimited_args_kwargs", "data": "def assignment_unlimited_args_kwargs(one, two='hi', *args, **kwargs):\n\t\"\"\"Expected assignment_unlimited_args_kwargs __doc__\"\"\"\n\t# Sort the dictionary by key to guarantee the order for testing.\n\tsorted_kwarg = sorted(six.iteritems(kwargs), key=operator.itemgetter(0))\n\treturn \"assignment_unlimited_args_kwargs - Expected result: %s / %s\" % (\n\t\t', '.join(six.text_type(arg) for arg in [one, two] + list(args)),\n\t\t', '.join('%s=%s' % (k, v) for (k, v) in sorted_kwarg)\n", "description": "Expected assignment_unlimited_args_kwargs __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six"]}, {"term": "def", "name": "assignment_tag_without_context_parameter", "data": "def assignment_tag_without_context_parameter(arg):\n\t\"\"\"Expected assignment_tag_without_context_parameter __doc__\"\"\"\n", "description": "Expected assignment_tag_without_context_parameter __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six"]}], [], [{"term": "def", "name": "simple", "data": "def simple(i):\n\t\"\"\"\u0411\u0435\u0437 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f \u00ab\u0420\u0435\u0448\u0435\u0442\u0430 \u042d\u0440\u0430\u0442\u043e\u0441\u0444\u0435\u043d\u0430\u00bb\"\"\"\n\tcount = 1\n\tn = 2\n\twhile count <= i:\n\t\tt = 1\n\t\tis_simple = True\n\t\twhile t <= n:\n\t\t\tif n % t == 0 and t != 1 and t != n:\n\t\t\t\tis_simple = False\n\t\t\t\tbreak\n\t\t\tt += 1\n\t\tif is_simple:\n\t\t\tif count == i:\n\t\t\t\tbreak\n\t\t\tcount += 1\n\t\tn += 1\n\treturn n\n\n", "description": "\u0411\u0435\u0437 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f \u00ab\u0420\u0435\u0448\u0435\u0442\u0430 \u042d\u0440\u0430\u0442\u043e\u0441\u0444\u0435\u043d\u0430\u00bb", "category": "simple", "imports": ["from timeit import timeit", "print('\u041e\u0431\u044b\u0447\u043d\u044b\u0439   ', timeit('simple_func(100)', 'from __main__ import simple_func', number=100))", "print('\u0421 \u0440\u0435\u0448\u0435\u0442\u043e\u043c ', timeit('eratosthenes(100)', 'from __main__ import eratosthenes', number=100))", "print('\u041e\u0431\u044b\u0447\u043d\u044b\u0439   ', timeit('simple_func(1000)', 'from __main__ import simple_func', number=100))", "print('\u0421 \u0440\u0435\u0448\u0435\u0442\u043e\u043c ', timeit('eratosthenes(1000)', 'from __main__ import eratosthenes', number=100))", "print('\u041e\u0431\u044b\u0447\u043d\u044b\u0439   ', timeit('simple_func(10000)', 'from __main__ import simple_func', number=100))", "print('\u0421 \u0440\u0435\u0448\u0435\u0442\u043e\u043c ', timeit('eratosthenes(10000)', 'from __main__ import eratosthenes', number=100))", "print('\u041e\u0431\u044b\u0447\u043d\u044b\u0439   ', timeit('simple(10)', 'from __main__ import simple', number=10))", "print('\u0421 \u0440\u0435\u0448\u0435\u0442\u043e\u043c ', timeit('num_simple_eratosthenes(10)', 'from __main__ import num_simple_eratosthenes', number=10))", "print('\u041e\u0431\u044b\u0447\u043d\u044b\u0439   ', timeit('simple(100)', 'from __main__ import simple', number=10))", "print('\u0421 \u0440\u0435\u0448\u0435\u0442\u043e\u043c ', timeit('num_simple_eratosthenes(100)', 'from __main__ import num_simple_eratosthenes', number=10))", "print('\u041e\u0431\u044b\u0447\u043d\u044b\u0439   ', timeit('simple(1000)', 'from __main__ import simple', number=10))", "print('\u0421 \u0440\u0435\u0448\u0435\u0442\u043e\u043c ', timeit('num_simple_eratosthenes(1000)', 'from __main__ import num_simple_eratosthenes', number=10))"]}, {"term": "def", "name": "simple_func", "data": "def simple_func(n):\n\ta = []\n\tfor i in range(n+1):\n\t\ta.append(i)\n\ta[1] = 0\n\ti = 2\n\twhile i <= n:\n\t\tif a[i] != 0:\n\t\t\tj = i + i\n\t\t\twhile j <= n:\n\t\t\t\ta[j] = 0\n\t\t\t\tj = j + i\n\t\ti += 1\n\tsimple_nums = [i for i in a if i != 0]\n\treturn simple_nums\n\n", "description": null, "category": "simple", "imports": ["from timeit import timeit", "print('\u041e\u0431\u044b\u0447\u043d\u044b\u0439   ', timeit('simple_func(100)', 'from __main__ import simple_func', number=100))", "print('\u0421 \u0440\u0435\u0448\u0435\u0442\u043e\u043c ', timeit('eratosthenes(100)', 'from __main__ import eratosthenes', number=100))", "print('\u041e\u0431\u044b\u0447\u043d\u044b\u0439   ', timeit('simple_func(1000)', 'from __main__ import simple_func', number=100))", "print('\u0421 \u0440\u0435\u0448\u0435\u0442\u043e\u043c ', timeit('eratosthenes(1000)', 'from __main__ import eratosthenes', number=100))", "print('\u041e\u0431\u044b\u0447\u043d\u044b\u0439   ', timeit('simple_func(10000)', 'from __main__ import simple_func', number=100))", "print('\u0421 \u0440\u0435\u0448\u0435\u0442\u043e\u043c ', timeit('eratosthenes(10000)', 'from __main__ import eratosthenes', number=100))", "print('\u041e\u0431\u044b\u0447\u043d\u044b\u0439   ', timeit('simple(10)', 'from __main__ import simple', number=10))", "print('\u0421 \u0440\u0435\u0448\u0435\u0442\u043e\u043c ', timeit('num_simple_eratosthenes(10)', 'from __main__ import num_simple_eratosthenes', number=10))", "print('\u041e\u0431\u044b\u0447\u043d\u044b\u0439   ', timeit('simple(100)', 'from __main__ import simple', number=10))", "print('\u0421 \u0440\u0435\u0448\u0435\u0442\u043e\u043c ', timeit('num_simple_eratosthenes(100)', 'from __main__ import num_simple_eratosthenes', number=10))", "print('\u041e\u0431\u044b\u0447\u043d\u044b\u0439   ', timeit('simple(1000)', 'from __main__ import simple', number=10))", "print('\u0421 \u0440\u0435\u0448\u0435\u0442\u043e\u043c ', timeit('num_simple_eratosthenes(1000)', 'from __main__ import num_simple_eratosthenes', number=10))"]}, {"term": "def", "name": "eratosthenes", "data": "def eratosthenes(n):\t # n - \u0447\u0438\u0441\u043b\u043e, \u0434\u043e \u043a\u043e\u0442\u043e\u0440\u043e\u0433\u043e \u0445\u043e\u0442\u0438\u043c \u043d\u0430\u0439\u0442\u0438 \u043f\u0440\u043e\u0441\u0442\u044b\u0435 \u0447\u0438\u0441\u043b\u0430\n\tsieve = list(range(n + 1))\n\tsieve[1] = 0\n\tfor i in sieve:\n\t\tif i > 1:\n\t\t\tfor j in range(i + i, len(sieve), i):\n\t\t\t\tsieve[j] = 0\n\tsieve1 = [x for x in sieve if sieve[x] != 0]\n\treturn sieve1\n\n", "description": null, "category": "simple", "imports": ["from timeit import timeit", "print('\u041e\u0431\u044b\u0447\u043d\u044b\u0439   ', timeit('simple_func(100)', 'from __main__ import simple_func', number=100))", "print('\u0421 \u0440\u0435\u0448\u0435\u0442\u043e\u043c ', timeit('eratosthenes(100)', 'from __main__ import eratosthenes', number=100))", "print('\u041e\u0431\u044b\u0447\u043d\u044b\u0439   ', timeit('simple_func(1000)', 'from __main__ import simple_func', number=100))", "print('\u0421 \u0440\u0435\u0448\u0435\u0442\u043e\u043c ', timeit('eratosthenes(1000)', 'from __main__ import eratosthenes', number=100))", "print('\u041e\u0431\u044b\u0447\u043d\u044b\u0439   ', timeit('simple_func(10000)', 'from __main__ import simple_func', number=100))", "print('\u0421 \u0440\u0435\u0448\u0435\u0442\u043e\u043c ', timeit('eratosthenes(10000)', 'from __main__ import eratosthenes', number=100))", "print('\u041e\u0431\u044b\u0447\u043d\u044b\u0439   ', timeit('simple(10)', 'from __main__ import simple', number=10))", "print('\u0421 \u0440\u0435\u0448\u0435\u0442\u043e\u043c ', timeit('num_simple_eratosthenes(10)', 'from __main__ import num_simple_eratosthenes', number=10))", "print('\u041e\u0431\u044b\u0447\u043d\u044b\u0439   ', timeit('simple(100)', 'from __main__ import simple', number=10))", "print('\u0421 \u0440\u0435\u0448\u0435\u0442\u043e\u043c ', timeit('num_simple_eratosthenes(100)', 'from __main__ import num_simple_eratosthenes', number=10))", "print('\u041e\u0431\u044b\u0447\u043d\u044b\u0439   ', timeit('simple(1000)', 'from __main__ import simple', number=10))", "print('\u0421 \u0440\u0435\u0448\u0435\u0442\u043e\u043c ', timeit('num_simple_eratosthenes(1000)', 'from __main__ import num_simple_eratosthenes', number=10))"]}, {"term": "def", "name": "num_simple_eratosthenes", "data": "def num_simple_eratosthenes(n):  # n-\u043e\u0435 \u043f\u043e \u0441\u0447\u0435\u0442\u0443 \u043f\u0440\u043e\u0441\u0442\u043e\u0435 \u0447\u0438\u0441\u043b\u043e\n\ti = 2\n\tl = 10000\n\tsieve = list(range(l))\n\tsieve[1] = 0\n\twhile i < l:\n\t\tif sieve[i] != 0:\n\t\t\tm = i * 2\n\t\t\twhile m < l:\n\t\t\t\tsieve[m] = 0\n\t\t\t\tm += i\n\t\ti += 1\n\treturn [x for x in sieve if x != 0][n-1]\n\n", "description": null, "category": "simple", "imports": ["from timeit import timeit", "print('\u041e\u0431\u044b\u0447\u043d\u044b\u0439   ', timeit('simple_func(100)', 'from __main__ import simple_func', number=100))", "print('\u0421 \u0440\u0435\u0448\u0435\u0442\u043e\u043c ', timeit('eratosthenes(100)', 'from __main__ import eratosthenes', number=100))", "print('\u041e\u0431\u044b\u0447\u043d\u044b\u0439   ', timeit('simple_func(1000)', 'from __main__ import simple_func', number=100))", "print('\u0421 \u0440\u0435\u0448\u0435\u0442\u043e\u043c ', timeit('eratosthenes(1000)', 'from __main__ import eratosthenes', number=100))", "print('\u041e\u0431\u044b\u0447\u043d\u044b\u0439   ', timeit('simple_func(10000)', 'from __main__ import simple_func', number=100))", "print('\u0421 \u0440\u0435\u0448\u0435\u0442\u043e\u043c ', timeit('eratosthenes(10000)', 'from __main__ import eratosthenes', number=100))", "print('\u041e\u0431\u044b\u0447\u043d\u044b\u0439   ', timeit('simple(10)', 'from __main__ import simple', number=10))", "print('\u0421 \u0440\u0435\u0448\u0435\u0442\u043e\u043c ', timeit('num_simple_eratosthenes(10)', 'from __main__ import num_simple_eratosthenes', number=10))", "print('\u041e\u0431\u044b\u0447\u043d\u044b\u0439   ', timeit('simple(100)', 'from __main__ import simple', number=10))", "print('\u0421 \u0440\u0435\u0448\u0435\u0442\u043e\u043c ', timeit('num_simple_eratosthenes(100)', 'from __main__ import num_simple_eratosthenes', number=10))", "print('\u041e\u0431\u044b\u0447\u043d\u044b\u0439   ', timeit('simple(1000)', 'from __main__ import simple', number=10))", "print('\u0421 \u0440\u0435\u0448\u0435\u0442\u043e\u043c ', timeit('num_simple_eratosthenes(1000)', 'from __main__ import num_simple_eratosthenes', number=10))"]}], [{"term": "def", "name": "test_add_child", "data": "def test_add_child():\n\tsimple_tree = SimpleTree(SimpleTreeNode(0, None))\n\tassert simple_tree.Root.NodeValue == 0\n\n\tnew_node = SimpleTreeNode(777, None)\n\tsimple_tree.AddChild(simple_tree.Root, new_node)\n\n\tassert new_node in simple_tree.Root.Children\n\tassert new_node.Parent == simple_tree.Root\n\tassert len(simple_tree.Root.Children) == 1\n\n", "description": null, "category": "simple", "imports": ["from collections import namedtuple", "import pytest", "from project.trees.tree import SimpleTree, SimpleTreeNode"]}, {"term": "def", "name": "get_sample", "data": "def get_sample():\n\tsimple_tree = SimpleTree(SimpleTreeNode(123, None))\n\tnodes_to_add = [\n\t\tSimpleTreeNode(000, None),\n\t\tSimpleTreeNode(111, None),\n\t\tSimpleTreeNode(222, None),\n\t\tSimpleTreeNode(333, None),\n\t\tSimpleTreeNode(444, None),\n\t\tSimpleTreeNode(555, None),\n\t]\n\n\tsimple_tree.AddChild(simple_tree.Root, nodes_to_add[0])\n\tsimple_tree.AddChild(simple_tree.Root, nodes_to_add[1])\n\tsimple_tree.AddChild(nodes_to_add[0], nodes_to_add[2])\n\tsimple_tree.AddChild(nodes_to_add[0], nodes_to_add[3])\n\tsimple_tree.AddChild(nodes_to_add[1], nodes_to_add[4])\n\tsimple_tree.AddChild(nodes_to_add[4], nodes_to_add[5])\n\n\t# 123 - 111 - 444 - 555\n\t#\t - 000 - 222\n\t#\t\t   - 333\n\treturn simple_tree, nodes_to_add\n\n", "description": null, "category": "simple", "imports": ["from collections import namedtuple", "import pytest", "from project.trees.tree import SimpleTree, SimpleTreeNode"]}, {"term": "def", "name": "test_get_all_nodes", "data": "def test_get_all_nodes(get_sample):\n\tsimple_tree, nodes_to_add = get_sample\n\tall_nodes = simple_tree.GetAllNodes()\n\tassert len(all_nodes) == 7\n\n\tfor node in nodes_to_add:\n\t\tassert node in all_nodes\n\n", "description": null, "category": "simple", "imports": ["from collections import namedtuple", "import pytest", "from project.trees.tree import SimpleTree, SimpleTreeNode"]}, {"term": "def", "name": "test_get_all_nodes_one", "data": "def test_get_all_nodes_one():\n\tsimple_tree = SimpleTree(SimpleTreeNode(0, None))\n\tassert len(simple_tree.GetAllNodes()) == 1\n\n", "description": null, "category": "simple", "imports": ["from collections import namedtuple", "import pytest", "from project.trees.tree import SimpleTree, SimpleTreeNode"]}, {"term": "def", "name": "test_get_all_nodes_none", "data": "def test_get_all_nodes_none():\n\tsimple_tree = SimpleTree(None)\n\tassert len(simple_tree.GetAllNodes()) == 0\n\n", "description": null, "category": "simple", "imports": ["from collections import namedtuple", "import pytest", "from project.trees.tree import SimpleTree, SimpleTreeNode"]}, {"term": "def", "name": "test_delete_node", "data": "def test_delete_node(get_sample):\n\tsimple_tree, nodes_to_add = get_sample\n\tassert len(simple_tree.GetAllNodes()) == 7\n\n\tsimple_tree.DeleteNode(nodes_to_add[4])\n\n\t# Delete actually two nodes\n\tassert len(simple_tree.GetAllNodes()) == 5\n\n", "description": null, "category": "simple", "imports": ["from collections import namedtuple", "import pytest", "from project.trees.tree import SimpleTree, SimpleTreeNode"]}, {"term": "def", "name": "test_delete_node_one", "data": "def test_delete_node_one():\n\tone_node = SimpleTreeNode(0, None)\n\tsimple_tree = SimpleTree(one_node)\n\tassert len(simple_tree.GetAllNodes()) == 1\n\n\tsimple_tree.DeleteNode(one_node)\n\tassert len(simple_tree.GetAllNodes()) == 0\n\n", "description": null, "category": "simple", "imports": ["from collections import namedtuple", "import pytest", "from project.trees.tree import SimpleTree, SimpleTreeNode"]}, {"term": "def", "name": "test_find_node_by_value", "data": "def test_find_node_by_value(get_sample):\n\tsimple_tree, nodes_to_add = get_sample\n\tassert len(simple_tree.GetAllNodes()) == 7\n\n\tresult = simple_tree.FindNodesByValue(111)\n\n\tassert nodes_to_add[1] in result\n\tassert len(result) == 1\n\n", "description": null, "category": "simple", "imports": ["from collections import namedtuple", "import pytest", "from project.trees.tree import SimpleTree, SimpleTreeNode"]}, {"term": "def", "name": "test_find_node_by_value_not_find", "data": "def test_find_node_by_value_not_find(get_sample):\n\tsimple_tree, nodes_to_add = get_sample\n\tassert len(simple_tree.GetAllNodes()) == 7\n\n\tresult = simple_tree.FindNodesByValue(999)\n\n\tassert len(result) == 0\n\n", "description": null, "category": "simple", "imports": ["from collections import namedtuple", "import pytest", "from project.trees.tree import SimpleTree, SimpleTreeNode"]}, {"term": "def", "name": "test_count", "data": "def test_count(get_sample):\n\tsimple_tree, nodes_to_add = get_sample\n\tassert len(simple_tree.GetAllNodes()) == 7\n\n\tassert simple_tree.Count() == 7\n\n", "description": null, "category": "simple", "imports": ["from collections import namedtuple", "import pytest", "from project.trees.tree import SimpleTree, SimpleTreeNode"]}, {"term": "def", "name": "test_leaf_count", "data": "def test_leaf_count(get_sample):\n\tsimple_tree, nodes_to_add = get_sample\n\tassert len(simple_tree.GetAllNodes()) == 7\n\n\tassert simple_tree.LeafCount() == 3\n\n", "description": null, "category": "simple", "imports": ["from collections import namedtuple", "import pytest", "from project.trees.tree import SimpleTree, SimpleTreeNode"]}, {"term": "def", "name": "test_move_node", "data": "def test_move_node(get_sample):\n\tsimple_tree, nodes_to_add = get_sample\n\tassert len(simple_tree.GetAllNodes()) == 7\n\n\tsimple_tree.MoveNode(nodes_to_add[0], nodes_to_add[5])\n\tassert len(simple_tree.GetAllNodes()) == 7\n", "description": null, "category": "simple", "imports": ["from collections import namedtuple", "import pytest", "from project.trees.tree import SimpleTree, SimpleTreeNode"]}], [{"term": "def", "name": "simple", "data": "def simple():\r\n\tprint('simple:', a + b)\r\n\r\n", "description": null, "category": "simple", "imports": []}, {"term": "def", "name": "simple", "data": "def simple():\r\n\t# \u041b\u043e\u043a\u0430\u043b\u044c\u043d\u043e\u0435 \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u043e \u0438\u043c\u0435\u043d  \u0438\u043c\u0435\u043d \u043f\u043e\u044f\u0432\u043b\u044f\u0435\u0442\u0441\u044f \u0432 \u043c\u043e\u043c\u0435\u043d\u0442 \u0432\u044b\u0437\u043e\u0432\u0430 \u0444\u0443\u043d\u043a\u0446\u0438\u0438\r\n\tc, d = 3, 4\r\n\tprint('simple:', c + d)\r\n\r\n", "description": null, "category": "simple", "imports": []}, {"term": "def", "name": "simple_2", "data": "def simple_2():\r\n\t# \u041b\u043e\u043a\u0430\u043b\u044c\u043d\u043e\u0435 \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u043e \u0438\u043c\u0435\u043d\r\n\tx, y = 3, 4\r\n\tprint('simple_2:', x + y)\r\n\t# print('simple_2:', c + d)\r\n", "description": null, "category": "simple", "imports": []}, {"term": "def", "name": "simple", "data": "def simple():\r\n\t# \u041b\u043e\u043a\u0430\u043b\u044c\u043d\u043e\u0435 \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u043e \u0438\u043c\u0435\u043d\r\n\ta, b = 3, 4\r\n\tprint('simple:', a + b)\r\n\r\n", "description": null, "category": "simple", "imports": []}, {"term": "def", "name": "simple", "data": "def simple():\r\n\t# \u041b\u043e\u043a\u0430\u043b\u044c\u043d\u043e\u0435 \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u043e \u0438\u043c\u0435\u043d\r\n\tb = 4\r\n\tprint('simple:', a + b)\r\n\r\n", "description": null, "category": "simple", "imports": []}, {"term": "def", "name": "simple", "data": "def simple():\r\n\t# \u041b\u043e\u043a\u0430\u043b\u044c\u043d\u043e\u0435 \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u043e \u0438\u043c\u0435\u043d\r\n\tprint('simple:', a + b)\r\n\ta = 9\r\n\tprint('simple:', a + b)\r\n\r\n", "description": null, "category": "simple", "imports": []}, {"term": "def", "name": "simple_3", "data": "def simple_3(a, b):\r\n\tprint('simple:', a + b)\r\n\r\n", "description": null, "category": "simple", "imports": []}], [{"term": "class", "name": "TestMWSResponse", "data": "class TestMWSResponse(AWSMockServiceTestCase):\n\tconnection_class = MWSConnection\n\tmws = True\n\n\tdef test_parsing_nested_elements(self):\n\t\tclass Test9one(ResponseElement):\n\t\t\tNest = Element()\n\t\t\tZoom = Element()\n\n\t\tclass Test9Result(ResponseElement):\n\t\t\tItem = Element(Test9one)\n\n\t\ttext = b\"\"\"\n", "description": "\n", "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_member_list_specification", "data": "\tdef test_parsing_member_list_specification(self):\n\t\tclass Test8extra(ResponseElement):\n\t\t\tFoo = SimpleList()\n\n\t\tclass Test8Result(ResponseElement):\n\t\t\tItem = MemberList(SimpleList)\n\t\t\tExtra = MemberList(Test8extra)\n\n\t\ttext = b\"\"\"\n", "description": "\n", "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_nested_lists", "data": "\tdef test_parsing_nested_lists(self):\n\t\tclass Test7Result(ResponseElement):\n\t\t\tItem = MemberList(Nest=MemberList(),\n\t\t\t\t\t\t\t  List=ElementList(Simple=SimpleList()))\n\n\t\ttext = b\"\"\"\n\n", "description": "\n\n", "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_member_list", "data": "\tdef test_parsing_member_list(self):\n\t\tclass Test6Result(ResponseElement):\n\t\t\tItem = MemberList()\n\n\t\ttext = b\"\"\"\n", "description": "\n", "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_empty_member_list", "data": "\tdef test_parsing_empty_member_list(self):\n\t\tclass Test5Result(ResponseElement):\n\t\t\tItem = MemberList(Nest=MemberList())\n\n\t\ttext = b\"\"\"\n", "description": "\n", "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_missing_member_list", "data": "\tdef test_parsing_missing_member_list(self):\n\t\tclass Test4Result(ResponseElement):\n\t\t\tItem = MemberList(NestedItem=MemberList())\n\n", "description": null, "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_element_lists", "data": "\tdef test_parsing_element_lists(self):\n\t\tclass Test1Result(ResponseElement):\n\t\t\tItem = ElementList()\n\n", "description": null, "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_missing_lists", "data": "\tdef test_parsing_missing_lists(self):\n\t\tclass Test2Result(ResponseElement):\n\t\t\tItem = ElementList()\n\n", "description": null, "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_simple_lists", "data": "\tdef test_parsing_simple_lists(self):\n\t\tclass Test3Result(ResponseElement):\n\t\t\tItem = SimpleList()\n\n", "description": null, "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "fcheck_issue", "data": "\tdef check_issue(self, klass, text):\n\t\taction = klass.__name__[:-len('Result')]\n\t\tfactory = ResponseFactory(scopes=[{klass.__name__: klass}])\n\t\tparser = factory(action, connection=self.service_connection)\n\t\treturn self.service_connection._parse_response(parser, 'text/xml', text)\n\n", "description": null, "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}], [{"term": "class", "name": "TestMWSResponse", "data": "class TestMWSResponse(AWSMockServiceTestCase):\n\tconnection_class = MWSConnection\n\tmws = True\n\n\tdef test_parsing_nested_elements(self):\n\t\tclass Test9one(ResponseElement):\n\t\t\tNest = Element()\n\t\t\tZoom = Element()\n\n\t\tclass Test9Result(ResponseElement):\n\t\t\tItem = Element(Test9one)\n\n\t\ttext = b\"\"\"\n", "description": "\n", "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_member_list_specification", "data": "\tdef test_parsing_member_list_specification(self):\n\t\tclass Test8extra(ResponseElement):\n\t\t\tFoo = SimpleList()\n\n\t\tclass Test8Result(ResponseElement):\n\t\t\tItem = MemberList(SimpleList)\n\t\t\tExtra = MemberList(Test8extra)\n\n\t\ttext = b\"\"\"\n", "description": "\n", "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_nested_lists", "data": "\tdef test_parsing_nested_lists(self):\n\t\tclass Test7Result(ResponseElement):\n\t\t\tItem = MemberList(Nest=MemberList(),\n\t\t\t\t\t\t\t  List=ElementList(Simple=SimpleList()))\n\n\t\ttext = b\"\"\"\n\n", "description": "\n\n", "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_member_list", "data": "\tdef test_parsing_member_list(self):\n\t\tclass Test6Result(ResponseElement):\n\t\t\tItem = MemberList()\n\n\t\ttext = b\"\"\"\n", "description": "\n", "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_empty_member_list", "data": "\tdef test_parsing_empty_member_list(self):\n\t\tclass Test5Result(ResponseElement):\n\t\t\tItem = MemberList(Nest=MemberList())\n\n\t\ttext = b\"\"\"\n", "description": "\n", "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_missing_member_list", "data": "\tdef test_parsing_missing_member_list(self):\n\t\tclass Test4Result(ResponseElement):\n\t\t\tItem = MemberList(NestedItem=MemberList())\n\n", "description": null, "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_element_lists", "data": "\tdef test_parsing_element_lists(self):\n\t\tclass Test1Result(ResponseElement):\n\t\t\tItem = ElementList()\n\n", "description": null, "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_missing_lists", "data": "\tdef test_parsing_missing_lists(self):\n\t\tclass Test2Result(ResponseElement):\n\t\t\tItem = ElementList()\n\n", "description": null, "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_simple_lists", "data": "\tdef test_parsing_simple_lists(self):\n\t\tclass Test3Result(ResponseElement):\n\t\t\tItem = SimpleList()\n\n", "description": null, "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "fcheck_issue", "data": "\tdef check_issue(self, klass, text):\n\t\taction = klass.__name__[:-len('Result')]\n\t\tfactory = ResponseFactory(scopes=[{klass.__name__: klass}])\n\t\tparser = factory(action, connection=self.service_connection)\n\t\treturn self.service_connection._parse_response(parser, 'text/xml', text)\n\n", "description": null, "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}], [{"term": "class", "name": "TestMWSResponse", "data": "class TestMWSResponse(AWSMockServiceTestCase):\n\tconnection_class = MWSConnection\n\tmws = True\n\n\tdef test_parsing_nested_elements(self):\n\t\tclass Test9one(ResponseElement):\n\t\t\tNest = Element()\n\t\t\tZoom = Element()\n\n\t\tclass Test9Result(ResponseElement):\n\t\t\tItem = Element(Test9one)\n\n\t\ttext = b\"\"\"\n", "description": "\n", "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_member_list_specification", "data": "\tdef test_parsing_member_list_specification(self):\n\t\tclass Test8extra(ResponseElement):\n\t\t\tFoo = SimpleList()\n\n\t\tclass Test8Result(ResponseElement):\n\t\t\tItem = MemberList(SimpleList)\n\t\t\tExtra = MemberList(Test8extra)\n\n\t\ttext = b\"\"\"\n", "description": "\n", "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_nested_lists", "data": "\tdef test_parsing_nested_lists(self):\n\t\tclass Test7Result(ResponseElement):\n\t\t\tItem = MemberList(Nest=MemberList(),\n\t\t\t\t\t\t\t  List=ElementList(Simple=SimpleList()))\n\n\t\ttext = b\"\"\"\n\n", "description": "\n\n", "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_member_list", "data": "\tdef test_parsing_member_list(self):\n\t\tclass Test6Result(ResponseElement):\n\t\t\tItem = MemberList()\n\n\t\ttext = b\"\"\"\n", "description": "\n", "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_empty_member_list", "data": "\tdef test_parsing_empty_member_list(self):\n\t\tclass Test5Result(ResponseElement):\n\t\t\tItem = MemberList(Nest=MemberList())\n\n\t\ttext = b\"\"\"\n", "description": "\n", "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_missing_member_list", "data": "\tdef test_parsing_missing_member_list(self):\n\t\tclass Test4Result(ResponseElement):\n\t\t\tItem = MemberList(NestedItem=MemberList())\n\n", "description": null, "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_element_lists", "data": "\tdef test_parsing_element_lists(self):\n\t\tclass Test1Result(ResponseElement):\n\t\t\tItem = ElementList()\n\n", "description": null, "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_missing_lists", "data": "\tdef test_parsing_missing_lists(self):\n\t\tclass Test2Result(ResponseElement):\n\t\t\tItem = ElementList()\n\n", "description": null, "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_simple_lists", "data": "\tdef test_parsing_simple_lists(self):\n\t\tclass Test3Result(ResponseElement):\n\t\t\tItem = SimpleList()\n\n", "description": null, "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "fcheck_issue", "data": "\tdef check_issue(self, klass, text):\n\t\taction = klass.__name__[:-len('Result')]\n\t\tfactory = ResponseFactory(scopes=[{klass.__name__: klass}])\n\t\tparser = factory(action, connection=self.service_connection)\n\t\treturn self.service_connection._parse_response(parser, 'text/xml', text)\n\n", "description": null, "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}], [{"term": "class", "name": "TestMWSResponse", "data": "class TestMWSResponse(AWSMockServiceTestCase):\n\tconnection_class = MWSConnection\n\tmws = True\n\n\tdef test_parsing_nested_elements(self):\n\t\tclass Test9one(ResponseElement):\n\t\t\tNest = Element()\n\t\t\tZoom = Element()\n\n\t\tclass Test9Result(ResponseElement):\n\t\t\tItem = Element(Test9one)\n\n\t\ttext = b\"\"\"\n", "description": "\n", "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_member_list_specification", "data": "\tdef test_parsing_member_list_specification(self):\n\t\tclass Test8extra(ResponseElement):\n\t\t\tFoo = SimpleList()\n\n\t\tclass Test8Result(ResponseElement):\n\t\t\tItem = MemberList(SimpleList)\n\t\t\tExtra = MemberList(Test8extra)\n\n\t\ttext = b\"\"\"\n", "description": "\n", "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_nested_lists", "data": "\tdef test_parsing_nested_lists(self):\n\t\tclass Test7Result(ResponseElement):\n\t\t\tItem = MemberList(Nest=MemberList(),\n\t\t\t\t\t\t\t  List=ElementList(Simple=SimpleList()))\n\n\t\ttext = b\"\"\"\n\n", "description": "\n\n", "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_member_list", "data": "\tdef test_parsing_member_list(self):\n\t\tclass Test6Result(ResponseElement):\n\t\t\tItem = MemberList()\n\n\t\ttext = b\"\"\"\n", "description": "\n", "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_empty_member_list", "data": "\tdef test_parsing_empty_member_list(self):\n\t\tclass Test5Result(ResponseElement):\n\t\t\tItem = MemberList(Nest=MemberList())\n\n\t\ttext = b\"\"\"\n", "description": "\n", "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_missing_member_list", "data": "\tdef test_parsing_missing_member_list(self):\n\t\tclass Test4Result(ResponseElement):\n\t\t\tItem = MemberList(NestedItem=MemberList())\n\n", "description": null, "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_element_lists", "data": "\tdef test_parsing_element_lists(self):\n\t\tclass Test1Result(ResponseElement):\n\t\t\tItem = ElementList()\n\n", "description": null, "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_missing_lists", "data": "\tdef test_parsing_missing_lists(self):\n\t\tclass Test2Result(ResponseElement):\n\t\t\tItem = ElementList()\n\n", "description": null, "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_simple_lists", "data": "\tdef test_parsing_simple_lists(self):\n\t\tclass Test3Result(ResponseElement):\n\t\t\tItem = SimpleList()\n\n", "description": null, "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "fcheck_issue", "data": "\tdef check_issue(self, klass, text):\n\t\taction = klass.__name__[:-len('Result')]\n\t\tfactory = ResponseFactory(scopes=[{klass.__name__: klass}])\n\t\tparser = factory(action, connection=self.service_connection)\n\t\treturn self.service_connection._parse_response(parser, 'text/xml', text)\n\n", "description": null, "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}], [{"term": "class", "name": "TestMWSResponse", "data": "class TestMWSResponse(AWSMockServiceTestCase):\n\tconnection_class = MWSConnection\n\tmws = True\n\n\tdef test_parsing_nested_elements(self):\n\t\tclass Test9one(ResponseElement):\n\t\t\tNest = Element()\n\t\t\tZoom = Element()\n\n\t\tclass Test9Result(ResponseElement):\n\t\t\tItem = Element(Test9one)\n\n\t\ttext = b\"\"\"\n", "description": "\n", "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_member_list_specification", "data": "\tdef test_parsing_member_list_specification(self):\n\t\tclass Test8extra(ResponseElement):\n\t\t\tFoo = SimpleList()\n\n\t\tclass Test8Result(ResponseElement):\n\t\t\tItem = MemberList(SimpleList)\n\t\t\tExtra = MemberList(Test8extra)\n\n\t\ttext = b\"\"\"\n", "description": "\n", "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_nested_lists", "data": "\tdef test_parsing_nested_lists(self):\n\t\tclass Test7Result(ResponseElement):\n\t\t\tItem = MemberList(Nest=MemberList(),\n\t\t\t\t\t\t\t  List=ElementList(Simple=SimpleList()))\n\n\t\ttext = b\"\"\"\n\n", "description": "\n\n", "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_member_list", "data": "\tdef test_parsing_member_list(self):\n\t\tclass Test6Result(ResponseElement):\n\t\t\tItem = MemberList()\n\n\t\ttext = b\"\"\"\n", "description": "\n", "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_empty_member_list", "data": "\tdef test_parsing_empty_member_list(self):\n\t\tclass Test5Result(ResponseElement):\n\t\t\tItem = MemberList(Nest=MemberList())\n\n\t\ttext = b\"\"\"\n", "description": "\n", "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_missing_member_list", "data": "\tdef test_parsing_missing_member_list(self):\n\t\tclass Test4Result(ResponseElement):\n\t\t\tItem = MemberList(NestedItem=MemberList())\n\n", "description": null, "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_element_lists", "data": "\tdef test_parsing_element_lists(self):\n\t\tclass Test1Result(ResponseElement):\n\t\t\tItem = ElementList()\n\n", "description": null, "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_missing_lists", "data": "\tdef test_parsing_missing_lists(self):\n\t\tclass Test2Result(ResponseElement):\n\t\t\tItem = ElementList()\n\n", "description": null, "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_simple_lists", "data": "\tdef test_parsing_simple_lists(self):\n\t\tclass Test3Result(ResponseElement):\n\t\t\tItem = SimpleList()\n\n", "description": null, "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "fcheck_issue", "data": "\tdef check_issue(self, klass, text):\n\t\taction = klass.__name__[:-len('Result')]\n\t\tfactory = ResponseFactory(scopes=[{klass.__name__: klass}])\n\t\tparser = factory(action, connection=self.service_connection)\n\t\treturn self.service_connection._parse_response(parser, 'text/xml', text)\n\n", "description": null, "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}], [{"term": "def", "name": "test_get_verbose_name", "data": "def test_get_verbose_name():\n\tl = get_verbose_name(SimpleDemoModel, 'char')\n\tassert l == 'Character'\n\n", "description": null, "category": "simple", "imports": ["from django.contrib.auth.models import Permission", "from django.core.exceptions import ImproperlyConfigured", "from django.contrib.auth.models import User", "from django.test.testcases import TestCase", "from django_dynamic_fixture import G", "import itertools", "import mock", "from ereports.engine.cache import DummyCacheManager, DatasourceCacheManager", "from ereports.engine.columns import Column, CalcColumn, ColumnCallable, BooleanColumn, OptionalColumn", "from ereports.engine.datasource import Datasource, RecordFilteredError", "from ereports.tests import app", "from ereports.tests.app.models import SimpleDemoModel, DemoOptionalModel", "from ereports.utils import get_verbose_name"]}, {"term": "class", "name": "TestDatasource", "data": "class TestDatasource(TestCase):\n\tdef test_inherit(self):\n\t\tTestDatasource = type('TestDatasource', (Datasource,), {'model': Permission, 'columns': ['id']})\n\t\tds = TestDatasource.as_datasource()\n\t\tself.assertIsInstance(list(ds), list)\n\n\tdef test_inherit_exception(self):\n\t\tTestDatasource = type('TestDatasource', (Datasource, ), {'model': Permission, 'columns': ['id']})\n\t\twith self.assertRaises(TypeError):\n\t\t\tkwargs = dict(wrong='oops')\n\t\t\tTestDatasource.as_datasource(**kwargs)\n\n\tdef test_inherit_improperlyconfigured(self):\n\t\tTestDatasource = type('TestDatasource', (Datasource, ), {'columns': ['id']})\n\t\twith self.assertRaises(ImproperlyConfigured):\n\t\t\tkwargs = dict(model=None)\n\t\t\tTestDatasource.as_datasource(**kwargs)\n\n\tdef test_create_from_model(self):\n\t\tinstances = G(SimpleDemoModel, n=2, char='1', integer1=1, integer2=2, boolean=True)\n\n\t\tself.assertEquals(len(instances), 2)\n\n\t\tds = Datasource.as_datasource(model=SimpleDemoModel)\n\n\t\tself.assertSequenceEqual([c.name for c in ds.columns], ['id', 'char', 'integer1', 'integer2', 'boolean'])\n\t\tself.assertSequenceEqual([c.title for c in ds.columns],\n\t\t\t\t\t\t\t\t ['ID', 'Character', 'Integer #1', 'Integer #2', 'Boolean'])\n\t\tself.assertSequenceEqual(ds, [(instances[0].pk, u'1', 1, 2, True), (instances[1].pk, u'1', 1, 2, True)])\n\n\tdef test_columns(self):\n\t\tG(SimpleDemoModel, n=2, char='abc', integer1=1)\n\t\tds = Datasource.as_datasource(model=SimpleDemoModel,\n\t\t\t\t\t\t\t\t\t  columns=[Column('char', 'AAA'), Column('integer1')])\n\n\t\tself.assertSequenceEqual([c.name for c in ds.columns], ['char', 'integer1'])\n\t\tself.assertSequenceEqual([c.title for c in ds.columns], ['AAA', 'Integer #1'])\n\t\tself.assertSequenceEqual(ds, [(u'abc', 1), (u'abc', 1)])\n\n\tdef test_list_columns(self):\n\t\tG(SimpleDemoModel, n=2, char='abc', integer1=1, integer2=3)\n\t\tds = Datasource.as_datasource(model=SimpleDemoModel,\n\t\t\t\t\t\t\t\t\t  columns=[('char', Column), ('integer1', Column)])\n\t\tself.assertSequenceEqual([c.name for c in ds.columns], ['char', 'integer1'])\n\t\tself.assertSequenceEqual([c.title for c in ds.columns], ['Character', 'Integer #1'])\n\t\tself.assertSequenceEqual(ds, [(u'abc', 1), (u'abc', 1)])\n\n\tdef test_manipulator(self):\n\t\tG(SimpleDemoModel, n=2, char='abc', integer1=1)\n\t\tds = Datasource.as_datasource(model=SimpleDemoModel,\n\t\t\t\t\t\t\t\t\t  columns=[Column('char', manipulator=lambda v: v.upper())])\n\t\tself.assertSequenceEqual(ds, [(u'ABC', ), (u'ABC', )])\n\n\tdef test_custom_column_from_string(self):\n\t\tG(SimpleDemoModel, n=2, char='abc', integer1=1, integer2=3)\n\t\tds = Datasource.as_datasource(model=SimpleDemoModel,\n\t\t\t\t\t\t\t\t\t  extra_column=lambda obj: 'extra_value',\n\t\t\t\t\t\t\t\t\t  columns=[Column('integer1'),\n\t\t\t\t\t\t\t\t\t\t\t   'integer2',\n\t\t\t\t\t\t\t\t\t\t\t   CalcColumn(['integer1', 'integer2'])])\n\t\tself.assertSequenceEqual(ds, [(1, 3, 4), (1, 3, 4)])\n\n\tdef test_create_from_queryset(self):\n\t\tinstances = G(SimpleDemoModel, n=2, char='abc')\n\n\t\tself.assertEquals(len(instances), 2)\n\n\t\tds = Datasource.as_datasource(queryset=SimpleDemoModel.objects.all(),\n\t\t\t\t\t\t\t\t\t  columns=['id', 'char'])\n\n\t\tself.assertSequenceEqual([c.name for c in ds.columns], ['id', 'char'])\n\t\tself.assertSequenceEqual([c.title for c in ds.columns], ['ID', 'Character'])\n\t\tself.assertSequenceEqual(ds, [(instances[0].pk, u'abc'), (instances[1].pk, u'abc')])\n\n\tdef test_get_col_by_name(self):\n\t\tG(SimpleDemoModel, n=2, char='abc')\n\t\tds = Datasource.as_datasource(queryset=SimpleDemoModel.objects.all())\n\t\tself.assertSequenceEqual([u'abc', u'abc'], [row.char for row in ds])\n\t\tself.assertSequenceEqual([u'abc', u'abc'], [row['char'] for row in ds])\n\n\tdef test_filter_queryset(self):\n\t\tinstances = G(SimpleDemoModel, n=5, char='abc')\n\n\t\tself.assertEquals(len(instances), 5)\n\n\t\tds = Datasource.as_datasource(queryset=SimpleDemoModel.objects.all(),\n\t\t\t\t\t\t\t\t\t  columns=['id', 'char'])\n\t\tds.add_filters(id__gt=instances[2].pk)\n\t\tself.assertSequenceEqual(ds, [(instances[3].pk, u'abc'), (instances[4].pk, u'abc')])\n\n\tdef test_post_filter(self):\n\t\tinstances = G(SimpleDemoModel, n=5, char='abc')\n\t\tds = Datasource.as_datasource(queryset=SimpleDemoModel.objects.all(),\n\t\t\t\t\t\t\t\t\t  columns=['id', 'char'])\n\t\tds.add_filters(id__gt=instances[2].pk)\n\t\tself.assertSequenceEqual(ds, [(instances[3].pk, u'abc'), (instances[4].pk, u'abc')])\n\n\tdef test_cachemanager(self):\n\t\tds = Datasource.as_datasource(model=SimpleDemoModel, use_cache=False)\n\t\tself.assertIsInstance(ds.cache_manager, DummyCacheManager)\n\n\t\tds = Datasource.as_datasource(model=SimpleDemoModel, use_cache=True)\n\t\tself.assertIsInstance(ds.cache_manager, DatasourceCacheManager)\n\n\t# def test_internal_cache(self):\n\t#\t G(SimpleDemoModel, n=10, char='abc')\n\t#\t ds = Datasource.as_datasource(model=SimpleDemoModel, columns=[Column('filter_source')])\n\n\tdef test_custom_filter(self):\n\t\tG(SimpleDemoModel, n=10, char='abc')\n\t\tapp.models.counter = itertools.count()\n\t\tds = Datasource.as_datasource(model=SimpleDemoModel, columns=[Column('filter_source')])\n\t\tds._get_queryset = mock.Mock(wraps=ds._get_queryset)\n\t\tds._create_result_cache = mock.Mock(wraps=ds._create_result_cache)\n\n\t\tdef filter_odd(row):\n\t\t\tif not row.filter_source.value % 2:\n\t\t\t\traise RecordFilteredError\n\n\t\tds.add_custom_filter(filter_odd)\n\t\tlist(ds)\n\t\tlist(ds)\n\t\tself.assertSequenceEqual(ds, [(1,), (3,), (5,), (7,), (9,)])\n\t\tassert ds._get_queryset.call_count == 1\n\t\tassert ds._create_result_cache.call_count == 1\n\n", "description": null, "category": "simple", "imports": ["from django.contrib.auth.models import Permission", "from django.core.exceptions import ImproperlyConfigured", "from django.contrib.auth.models import User", "from django.test.testcases import TestCase", "from django_dynamic_fixture import G", "import itertools", "import mock", "from ereports.engine.cache import DummyCacheManager, DatasourceCacheManager", "from ereports.engine.columns import Column, CalcColumn, ColumnCallable, BooleanColumn, OptionalColumn", "from ereports.engine.datasource import Datasource, RecordFilteredError", "from ereports.tests import app", "from ereports.tests.app.models import SimpleDemoModel, DemoOptionalModel", "from ereports.utils import get_verbose_name"]}, {"term": "class", "name": "TestColumns", "data": "class TestColumns(TestCase):\n\tdef test_custom_column_callable(self):\n\t\tG(SimpleDemoModel, n=2, char='abc', integer1=10, integer2=20)\n\n\t\tdef _custom_callable(obj, ds):\n\t\t\treturn obj.integer1 + 100\n\n\t\tds = Datasource.as_datasource(model=SimpleDemoModel,\n\t\t\t\t\t\t\t\t\t  columns=[Column('integer1'),\n\t\t\t\t\t\t\t\t\t\t\t   Column('integer2'),\n\t\t\t\t\t\t\t\t\t\t\t   ColumnCallable(_custom_callable)])\n\n\t\tself.assertSequenceEqual(ds, [(10, 20, 110), (10, 20, 110)])\n\n\tdef test_custom_column(self):\n\t\tG(SimpleDemoModel, n=2, char='abc', integer1=1, integer2=3)\n\t\tds = Datasource.as_datasource(model=SimpleDemoModel,\n\t\t\t\t\t\t\t\t\t  columns=[Column('integer1'), Column('integer2'),\n\t\t\t\t\t\t\t\t\t\t\t   CalcColumn(['integer1', 'integer2'])])\n\t\tself.assertSequenceEqual(ds, [(1, 3, 4), (1, 3, 4)])\n\n\tdef test_custom_column_from_datasource_method(self):\n\t\tG(SimpleDemoModel, n=2, char='abc', integer1=1, integer2=3)\n\t\tds = Datasource.as_datasource(model=SimpleDemoModel,\n\t\t\t\t\t\t\t\t\t  extra_column=lambda obj: 'extra_value',\n\t\t\t\t\t\t\t\t\t  columns=[Column('integer1'),\n\t\t\t\t\t\t\t\t\t\t\t   Column('integer2'),\n\t\t\t\t\t\t\t\t\t\t\t   Column('extra_column'),\n\t\t\t\t\t\t\t\t\t\t\t   CalcColumn(['integer1', 'integer2'])])\n\t\tself.assertSequenceEqual(ds, [(1, 3, 'extra_value', 4), (1, 3, 'extra_value', 4)])\n\n\tdef test_boolean_column_no(self):\n\t\tG(SimpleDemoModel, n=2, boolean=False)\n\t\tds = Datasource.as_datasource(model=SimpleDemoModel,\n\t\t\t\t\t\t\t\t\t  columns=[BooleanColumn('boolean')])\n\t\tself.assertSequenceEqual([c.title for c in ds.columns], ['Boolean'])\n\t\tself.assertSequenceEqual(ds, [(False,), (False,)])\n\n\tdef test_booleanyesno_column_yes(self):\n\t\tG(SimpleDemoModel, n=2, boolean=True)\n\t\tds = Datasource.as_datasource(model=SimpleDemoModel,\n\t\t\t\t\t\t\t\t\t  columns=[BooleanColumn('boolean')])\n\t\tself.assertSequenceEqual([c.title for c in ds.columns], ['Boolean'])\n\t\tself.assertSequenceEqual(ds, [(True,), (True,)])\n\n\tdef test_optional_column(self):\n\t\tG(DemoOptionalModel, n=2, name='abc', user=G(User, n=1, first_name='user1'))\n\t\tds = Datasource.as_datasource(model=DemoOptionalModel,\n\t\t\t\t\t\t\t\t\t  columns=[Column('name'), OptionalColumn('user.first_name')])\n\t\tself.assertSequenceEqual([c.title for c in ds.columns], ['name', 'first name'])\n\t\tself.assertSequenceEqual(ds, [('abc', 'user1',), ('abc', 'user1')])\n\n\tdef test_optional_column_optional(self):\n\t\tG(DemoOptionalModel, n=2, name='abc', user=None)\n\t\tds = Datasource.as_datasource(model=DemoOptionalModel,\n\t\t\t\t\t\t\t\t\t  columns=[Column('name'), OptionalColumn('user.first_name')])\n\t\tself.assertSequenceEqual([c.title for c in ds.columns], ['name', 'first name'])\n\t\tself.assertSequenceEqual(ds, [('abc', '',), ('abc', '')])\n", "description": null, "category": "simple", "imports": ["from django.contrib.auth.models import Permission", "from django.core.exceptions import ImproperlyConfigured", "from django.contrib.auth.models import User", "from django.test.testcases import TestCase", "from django_dynamic_fixture import G", "import itertools", "import mock", "from ereports.engine.cache import DummyCacheManager, DatasourceCacheManager", "from ereports.engine.columns import Column, CalcColumn, ColumnCallable, BooleanColumn, OptionalColumn", "from ereports.engine.datasource import Datasource, RecordFilteredError", "from ereports.tests import app", "from ereports.tests.app.models import SimpleDemoModel, DemoOptionalModel", "from ereports.utils import get_verbose_name"]}], [], [], [{"term": "def", "name": "test_largura_simple_1_path", "data": "def test_largura_simple_1_path():\n\tprint(\"\\n#### Largura Simples 1 ####\")\n\tfile_map_path = \"data/vacuum_simple_1.txt\"\n\tlin = 0\n\tcol = 0\n\tmapa = convert_file_to_map(file_map_path)\n\tprint(mapa)\n\tstate = VacuumWorldGeneric(mapa, lin, col, \"\")\n\talgorithm = BuscaLargura()\n\tresult = algorithm.search(state)\n\tprint(f\"Solu\u00e7\u00e3o = {result.show_path()}\")\n\tprint(\"\\n\")\n\tassert result.show_path() == \" ; limpar\"\n", "description": null, "category": "simple", "imports": ["from aicode.search.SearchAlgorithms import BuscaLargura", "from aicode.search.SearchAlgorithms import BuscaProfundidade", "from aicode.search.SearchAlgorithms import BuscaProfundidadeIterativa", "from VacuumWorldGeneric import *"]}, {"term": "def", "name": "test_largura_simple_2_path", "data": "def test_largura_simple_2_path():\n\tprint(\"\\n#### Largura Simples 2 Path ####\")\n\tfile_map_path = \"data/vacuum_simple_2.txt\"\n\tlin = 0\n\tcol = 0\n\tmapa = convert_file_to_map(file_map_path)\n\tprint(mapa)\n\tstate = VacuumWorldGeneric(mapa, lin, col, \"\")\n\talgorithm = BuscaLargura()\n\tresult = algorithm.search(state)\n\tprint(f\"Solu\u00e7\u00e3o = {result.show_path()}\")\n\tprint(\"\\n\")\n\tassert result.show_path() == \" ; dir ; dir ; baixo ; limpar\"\n", "description": null, "category": "simple", "imports": ["from aicode.search.SearchAlgorithms import BuscaLargura", "from aicode.search.SearchAlgorithms import BuscaProfundidade", "from aicode.search.SearchAlgorithms import BuscaProfundidadeIterativa", "from VacuumWorldGeneric import *"]}, {"term": "def", "name": "test_largura_simple_3_path", "data": "def test_largura_simple_3_path():\n\tprint(\"\\n#### Largura Simples 3 ####\")\n\n", "description": null, "category": "simple", "imports": ["from aicode.search.SearchAlgorithms import BuscaLargura", "from aicode.search.SearchAlgorithms import BuscaProfundidade", "from aicode.search.SearchAlgorithms import BuscaProfundidadeIterativa", "from VacuumWorldGeneric import *"]}, {"term": "def", "name": "test_largura_simple_0", "data": "def test_largura_simple_0():\n\tprint('\\n#### Largura Simples 0 ####')\n\tfile_map_path = 'data/vacuum_simple_0.txt'\n\tlin = 0\n\tcol = 0\n\tmapa = convert_file_to_map(file_map_path)\n\tprint(mapa)\n\tstate = VacuumWorldGeneric(mapa, lin, col, '')\n\talgorithm = BuscaLargura()\n\tresult = algorithm.search(state)\n\tprint(f'Solu\u00e7\u00e3o = {result.show_path()}')\n\tprint('\\n')\n\tassert result.show_path() == \"\"\n", "description": null, "category": "simple", "imports": ["from aicode.search.SearchAlgorithms import BuscaLargura", "from aicode.search.SearchAlgorithms import BuscaProfundidade", "from aicode.search.SearchAlgorithms import BuscaProfundidadeIterativa", "from VacuumWorldGeneric import *"]}, {"term": "def", "name": "test_largura_simple_1", "data": "def test_largura_simple_1():\n\tprint('\\n#### Largura Simples 1 ####')\n\tfile_map_path = 'data/vacuum_simple_1.txt'\n\tlin = 0\n\tcol = 0\n\tmapa = convert_file_to_map(file_map_path)\n\tprint(mapa)\n\tstate = VacuumWorldGeneric(mapa, lin, col, '')\n\talgorithm = BuscaLargura()\n\tresult = algorithm.search(state)\n\tprint(f'Solu\u00e7\u00e3o = {result.show_path()}')\n\tprint('\\n')\n\t#assert result.show_path() == \" ; limpar\"\n\tassert result.g == 1\n", "description": null, "category": "simple", "imports": ["from aicode.search.SearchAlgorithms import BuscaLargura", "from aicode.search.SearchAlgorithms import BuscaProfundidade", "from aicode.search.SearchAlgorithms import BuscaProfundidadeIterativa", "from VacuumWorldGeneric import *"]}, {"term": "def", "name": "test_largura_simple_2", "data": "def test_largura_simple_2():\n\tprint('\\n#### Largura Simples 2 ####')\n\tfile_map_path = 'data/vacuum_simple_2.txt'\n\tlin = 0\n\tcol = 0\n\tmapa = convert_file_to_map(file_map_path)\n\tprint(mapa)\n\tstate = VacuumWorldGeneric(mapa, lin, col, '')\n\talgorithm = BuscaLargura()\n\tresult = algorithm.search(state)\n\tprint(f'Solu\u00e7\u00e3o = {result.show_path()}')\n\tprint('\\n')\n\tassert result.g == 4\n", "description": null, "category": "simple", "imports": ["from aicode.search.SearchAlgorithms import BuscaLargura", "from aicode.search.SearchAlgorithms import BuscaProfundidade", "from aicode.search.SearchAlgorithms import BuscaProfundidadeIterativa", "from VacuumWorldGeneric import *"]}, {"term": "def", "name": "test_largura_simple_3", "data": "def test_largura_simple_3():\n\tprint('\\n#### Largura Simples 3 ####')\n\tfile_map_path = 'data/vacuum_simple_3.txt'\n\tlin = 0\n\tcol = 0\n\tmapa = convert_file_to_map(file_map_path)\n\tprint(mapa)\n\tstate = VacuumWorldGeneric(mapa, lin, col, '')\n\talgorithm = BuscaLargura()\n\tresult = algorithm.search(state)\n\tprint(f'Solu\u00e7\u00e3o = {result.show_path()}')\n\tprint('\\n')\n\tassert result.g == 8\n", "description": null, "category": "simple", "imports": ["from aicode.search.SearchAlgorithms import BuscaLargura", "from aicode.search.SearchAlgorithms import BuscaProfundidade", "from aicode.search.SearchAlgorithms import BuscaProfundidadeIterativa", "from VacuumWorldGeneric import *"]}, {"term": "def", "name": "test_largura_simple_4", "data": "def test_largura_simple_4():\n\tprint('\\n#### Largura Simples 4 ####')\n\tfile_map_path = 'data/vacuum_simple_4.txt'\n\tlin = 0\n\tcol = 0\n\tmapa = convert_file_to_map(file_map_path)\n\tprint(mapa)\n\tstate = VacuumWorldGeneric(mapa, lin, col, '')\n\talgorithm = BuscaLargura()\n\tresult = algorithm.search(state)\n\tprint(f'Solu\u00e7\u00e3o = {result.show_path()}')\n\tprint('\\n')\n\tassert result.g == 10\n", "description": null, "category": "simple", "imports": ["from aicode.search.SearchAlgorithms import BuscaLargura", "from aicode.search.SearchAlgorithms import BuscaProfundidade", "from aicode.search.SearchAlgorithms import BuscaProfundidadeIterativa", "from VacuumWorldGeneric import *"]}, {"term": "def", "name": "test_largura_simple_6", "data": "def test_largura_simple_6():\n\tprint('\\n#### Largura Simples 6 ####')\n\tfile_map_path = 'data/vacuum_simple_6.txt'\n\tlin = 0\n\tcol = 0\n\tmapa = convert_file_to_map(file_map_path)\n\tprint(mapa)\n\tstate = VacuumWorldGeneric(mapa, lin, col, '')\n\talgorithm = BuscaLargura()\n\tresult = algorithm.search(state)\n\tprint(f'Solu\u00e7\u00e3o = {result.show_path()}')\n\tprint('\\n')\n\tassert result.g == 23\n", "description": null, "category": "simple", "imports": ["from aicode.search.SearchAlgorithms import BuscaLargura", "from aicode.search.SearchAlgorithms import BuscaProfundidade", "from aicode.search.SearchAlgorithms import BuscaProfundidadeIterativa", "from VacuumWorldGeneric import *"]}, {"term": "def", "name": "test_largura_simple_7", "data": "def test_largura_simple_7():\n\tprint('\\n#### Largura Simples 7 ####')\n\tfile_map_path = 'data/vacuum_simple_7.txt'\n\tlin = 0\n\tcol = 0\n\tmapa = convert_file_to_map(file_map_path)\n\tprint(mapa)\n\tstate = VacuumWorldGeneric(mapa, lin, col, '')\n\talgorithm = BuscaLargura()\n\tresult = algorithm.search(state)\n\tprint(f'Solu\u00e7\u00e3o = {result.show_path()}')\n\tprint('\\n')\n\tassert result.g == 16\n", "description": null, "category": "simple", "imports": ["from aicode.search.SearchAlgorithms import BuscaLargura", "from aicode.search.SearchAlgorithms import BuscaProfundidade", "from aicode.search.SearchAlgorithms import BuscaProfundidadeIterativa", "from VacuumWorldGeneric import *"]}, {"term": "def", "name": "test_largura_simple_8", "data": "def test_largura_simple_8():\n\tprint('\\n#### Largura Simples 8 ####')\n\tfile_map_path = 'data/vacuum_simple_8.txt'\n\tlin = 0\n\tcol = 0\n\tmapa = convert_file_to_map(file_map_path)\n\tprint(mapa)\n\tstate = VacuumWorldGeneric(mapa, lin, col, '')\n\talgorithm = BuscaLargura()\n\tresult = algorithm.search(state)\n\tprint(f'Solu\u00e7\u00e3o = {result.show_path()}')\n\tprint('\\n')\n\tassert result.g == 14\n", "description": null, "category": "simple", "imports": ["from aicode.search.SearchAlgorithms import BuscaLargura", "from aicode.search.SearchAlgorithms import BuscaProfundidade", "from aicode.search.SearchAlgorithms import BuscaProfundidadeIterativa", "from VacuumWorldGeneric import *"]}, {"term": "def", "name": "test_profundidade_simple_0", "data": "def test_profundidade_simple_0():\n\tprint('\\n#### profundidade Simples 0 ####')\n\tfile_map_path = 'data/vacuum_simple_0.txt'\n\tlin = 0\n\tcol = 0\n\tmapa = convert_file_to_map(file_map_path)\n\tprint(mapa)\n\tstate = VacuumWorldGeneric(mapa, lin, col, '')\n\talgorithm = BuscaProfundidade()\n\tresult = algorithm.search(state, 25)\n\tprint(f'Solu\u00e7\u00e3o = {result.show_path()}')\n\tprint('\\n')\n\tassert result.show_path() == \"\"\n", "description": null, "category": "simple", "imports": ["from aicode.search.SearchAlgorithms import BuscaLargura", "from aicode.search.SearchAlgorithms import BuscaProfundidade", "from aicode.search.SearchAlgorithms import BuscaProfundidadeIterativa", "from VacuumWorldGeneric import *"]}, {"term": "def", "name": "test_profundidade_simple_1", "data": "def test_profundidade_simple_1():\n\tprint('\\n#### profundidade Simples 1 ####')\n\tfile_map_path = 'data/vacuum_simple_1.txt'\n\tlin = 0\n\tcol = 0\n\tmapa = convert_file_to_map(file_map_path)\n\tprint(mapa)\n\tstate = VacuumWorldGeneric(mapa, lin, col, '')\n\talgorithm = BuscaProfundidade()\n\tresult = algorithm.search(state, 25)\n\tprint(f'Solu\u00e7\u00e3o = {result.show_path()}')\n\tprint('\\n')\n\t#assert result.show_path() == \" ; limpar\"\n", "description": null, "category": "simple", "imports": ["from aicode.search.SearchAlgorithms import BuscaLargura", "from aicode.search.SearchAlgorithms import BuscaProfundidade", "from aicode.search.SearchAlgorithms import BuscaProfundidadeIterativa", "from VacuumWorldGeneric import *"]}, {"term": "def", "name": "test_profundidade_simple_2", "data": "def test_profundidade_simple_2():\n\tprint('\\n#### profundidade Simples 2 ####')\n\tfile_map_path = 'data/vacuum_simple_2.txt'\n\tlin = 0\n\tcol = 0\n\tmapa = convert_file_to_map(file_map_path)\n\tprint(mapa)\n\tstate = VacuumWorldGeneric(mapa, lin, col, '')\n\talgorithm = BuscaProfundidade()\n\tresult = algorithm.search(state, 25)\n\tprint(f'Solu\u00e7\u00e3o = {result.show_path()}')\n\tprint('\\n')\n\t#assert result.g == 24\n", "description": null, "category": "simple", "imports": ["from aicode.search.SearchAlgorithms import BuscaLargura", "from aicode.search.SearchAlgorithms import BuscaProfundidade", "from aicode.search.SearchAlgorithms import BuscaProfundidadeIterativa", "from VacuumWorldGeneric import *"]}, {"term": "def", "name": "test_profundidade_simple_3", "data": "def test_profundidade_simple_3():\n\tprint('\\n#### profundidade Simples 3 ####')\n\tfile_map_path = 'data/vacuum_simple_3.txt'\n\tlin = 0\n\tcol = 0\n\tmapa = convert_file_to_map(file_map_path)\n\tprint(mapa)\n\tstate = VacuumWorldGeneric(mapa, lin, col, '')\n\talgorithm = BuscaProfundidade()\n\tresult = algorithm.search(state, 25)\n\tprint(f'Solu\u00e7\u00e3o = {result.show_path()}')\n\tprint('\\n')\n\t#assert result.g == 25\n", "description": null, "category": "simple", "imports": ["from aicode.search.SearchAlgorithms import BuscaLargura", "from aicode.search.SearchAlgorithms import BuscaProfundidade", "from aicode.search.SearchAlgorithms import BuscaProfundidadeIterativa", "from VacuumWorldGeneric import *"]}, {"term": "def", "name": "test_profundidade_simple_4", "data": "def test_profundidade_simple_4():\n\tprint('\\n#### profundidade Simples 4 ####')\n\tfile_map_path = 'data/vacuum_simple_4.txt'\n\tlin = 0\n\tcol = 0\n\tmapa = convert_file_to_map(file_map_path)\n\tprint(mapa)\n\tstate = VacuumWorldGeneric(mapa, lin, col, '')\n\talgorithm = BuscaProfundidade()\n\tresult = algorithm.search(state, 25)\n\tprint(f'Solu\u00e7\u00e3o = {result.show_path()}')\n\tprint('\\n')\n\t#assert result.g == 25\n", "description": null, "category": "simple", "imports": ["from aicode.search.SearchAlgorithms import BuscaLargura", "from aicode.search.SearchAlgorithms import BuscaProfundidade", "from aicode.search.SearchAlgorithms import BuscaProfundidadeIterativa", "from VacuumWorldGeneric import *"]}, {"term": "def", "name": "test_profundidade_simple_5", "data": "def test_profundidade_simple_5():\n\tprint('\\n#### profundidade Simples 5 ####')\n\tfile_map_path = 'data/vacuum_simple_5.txt'\n\tlin = 0\n\tcol = 0\n\tmapa = convert_file_to_map(file_map_path)\n\tprint(mapa)\n\tstate = VacuumWorldGeneric(mapa, lin, col, '')\n\talgorithm = BuscaProfundidade()\n\tprint('Se prepara que este vai demorar! Vale a pena monitorar o consumo de mem\u00f3ria!!!')\n\tresult = algorithm.search(state, 25)\n\tprint(f'Solu\u00e7\u00e3o = {result.show_path()}')\n\tprint('\\n')\n\t#assert result.g == 25\n", "description": null, "category": "simple", "imports": ["from aicode.search.SearchAlgorithms import BuscaLargura", "from aicode.search.SearchAlgorithms import BuscaProfundidade", "from aicode.search.SearchAlgorithms import BuscaProfundidadeIterativa", "from VacuumWorldGeneric import *"]}, {"term": "def", "name": "test_profundidade_simple_6", "data": "def test_profundidade_simple_6():\n\tprint('\\n#### Profundidade Simples 6 ####')\n\tfile_map_path = 'data/vacuum_simple_6.txt'\n\tlin = 0\n\tcol = 0\n\tmapa = convert_file_to_map(file_map_path)\n\tprint(mapa)\n\tstate = VacuumWorldGeneric(mapa, lin, col, '')\n\talgorithm = BuscaProfundidade()\n\tresult = algorithm.search(state)\n\tprint(f'Solu\u00e7\u00e3o = {result.show_path()}')\n\tprint('\\n')\n\tassert result.g == 23\n", "description": null, "category": "simple", "imports": ["from aicode.search.SearchAlgorithms import BuscaLargura", "from aicode.search.SearchAlgorithms import BuscaProfundidade", "from aicode.search.SearchAlgorithms import BuscaProfundidadeIterativa", "from VacuumWorldGeneric import *"]}, {"term": "def", "name": "test_profundidade_simple_7", "data": "def test_profundidade_simple_7():\n\tprint('\\n#### Profundidade Simples 7 ####')\n\tfile_map_path = 'data/vacuum_simple_7.txt'\n\tlin = 0\n\tcol = 0\n\tmapa = convert_file_to_map(file_map_path)\n\tprint(mapa)\n\tstate = VacuumWorldGeneric(mapa, lin, col, '')\n\talgorithm = BuscaProfundidade()\n\tresult = algorithm.search(state)\n\tprint(f'Solu\u00e7\u00e3o = {result.show_path()}')\n\tprint('\\n')\n\tassert result.g == 16\n", "description": null, "category": "simple", "imports": ["from aicode.search.SearchAlgorithms import BuscaLargura", "from aicode.search.SearchAlgorithms import BuscaProfundidade", "from aicode.search.SearchAlgorithms import BuscaProfundidadeIterativa", "from VacuumWorldGeneric import *"]}, {"term": "def", "name": "test_profundidade_simple_8", "data": "def test_profundidade_simple_8():\n\tprint('\\n#### Largura Simples 8 ####')\n\tfile_map_path = 'data/vacuum_simple_8.txt'\n\tlin = 0\n\tcol = 0\n\tmapa = convert_file_to_map(file_map_path)\n\tprint(mapa)\n\tstate = VacuumWorldGeneric(mapa, lin, col, '')\n\talgorithm = BuscaLargura()\n\tresult = algorithm.search(state)\n\tprint(f'Solu\u00e7\u00e3o = {result.show_path()}')\n\tprint('\\n')\n\tassert result.g == 14\n\n", "description": null, "category": "simple", "imports": ["from aicode.search.SearchAlgorithms import BuscaLargura", "from aicode.search.SearchAlgorithms import BuscaProfundidade", "from aicode.search.SearchAlgorithms import BuscaProfundidadeIterativa", "from VacuumWorldGeneric import *"]}, {"term": "def", "name": "test_profundidade_xadrez", "data": "def test_profundidade_xadrez():\n\tprint('\\n#### profundidade Xadrez ####')\n\tfile_map_path = 'data/vacuum_xadrez.txt'\n\tlin = 0\n\tcol = 0\n\tmapa = convert_file_to_map(file_map_path)\n\tprint(mapa)\n\tstate = VacuumWorldGeneric(mapa, lin, col, '')\n\talgorithm = BuscaProfundidade()\n\tprint('Se prepara que este vai demorar! Vale a pena monitorar o consumo de mem\u00f3ria!!!')\n\tresult = algorithm.search(state, 25)\n\tprint(f'Solu\u00e7\u00e3o = {result.show_path()}')\n\tprint(f\"G = {result.g}\")\n\tprint('\\n')\n\tassert result.g == 25\n", "description": null, "category": "simple", "imports": ["from aicode.search.SearchAlgorithms import BuscaLargura", "from aicode.search.SearchAlgorithms import BuscaProfundidade", "from aicode.search.SearchAlgorithms import BuscaProfundidadeIterativa", "from VacuumWorldGeneric import *"]}, {"term": "def", "name": "test_profundidade_corners", "data": "def test_profundidade_corners():\n\tprint('\\n#### profundidade Corners ####')\n\tfile_map_path = 'data/vacuum_corners.txt'\n\tlin = 1\n\tcol = 2\n\tmapa = convert_file_to_map(file_map_path)\n\tprint(mapa)\n\tstate = VacuumWorldGeneric(mapa, lin, col, '')\n\talgorithm = BuscaProfundidade()\n\tprint('Se prepara que este vai demorar! Vale a pena monitorar o consumo de mem\u00f3ria!!!')\n\tresult = algorithm.search(state, 15)\n\tprint(f'Solu\u00e7\u00e3o = {result.show_path()}')\n\tprint('\\n')\n\tassert result.g == 15\n\n", "description": null, "category": "simple", "imports": ["from aicode.search.SearchAlgorithms import BuscaLargura", "from aicode.search.SearchAlgorithms import BuscaProfundidade", "from aicode.search.SearchAlgorithms import BuscaProfundidadeIterativa", "from VacuumWorldGeneric import *"]}, {"term": "def", "name": "test_BPI_simple_0", "data": "def test_BPI_simple_0():\n\tprint('\\n#### BPI Simples 0 ####')\n\tfile_map_path = 'data/vacuum_simple_0.txt'\n\tlin = 0\n\tcol = 0\n\tmapa = convert_file_to_map(file_map_path)\n\tprint(mapa)\n\tstate = VacuumWorldGeneric(mapa, lin, col, '')\n\talgorithm = BuscaProfundidadeIterativa()\n\tresult = algorithm.search(state)\n\tprint(f'Solu\u00e7\u00e3o = {result.show_path()}')\n\tprint('\\n')\n\tassert result.show_path() == \"\"\n", "description": null, "category": "simple", "imports": ["from aicode.search.SearchAlgorithms import BuscaLargura", "from aicode.search.SearchAlgorithms import BuscaProfundidade", "from aicode.search.SearchAlgorithms import BuscaProfundidadeIterativa", "from VacuumWorldGeneric import *"]}, {"term": "def", "name": "test_BPI_simple_1", "data": "def test_BPI_simple_1():\n\tprint('\\n#### BPI Simples 1 ####')\n\tfile_map_path = 'data/vacuum_simple_1.txt'\n\tlin = 0\n\tcol = 0\n\tmapa = convert_file_to_map(file_map_path)\n\tprint(mapa)\n\tstate = VacuumWorldGeneric(mapa, lin, col, '')\n\talgorithm = BuscaProfundidadeIterativa()\n\tresult = algorithm.search(state)\n\tprint(f'Solu\u00e7\u00e3o = {result.show_path()}')\n\tprint('\\n')\n\t#assert result.show_path() == \" ; limpar\"\n\tassert result.g == 1\n", "description": null, "category": "simple", "imports": ["from aicode.search.SearchAlgorithms import BuscaLargura", "from aicode.search.SearchAlgorithms import BuscaProfundidade", "from aicode.search.SearchAlgorithms import BuscaProfundidadeIterativa", "from VacuumWorldGeneric import *"]}, {"term": "def", "name": "test_BPI_simple_2", "data": "def test_BPI_simple_2():\n\tprint('\\n#### BPI Simples 2 ####')\n\tfile_map_path = 'data/vacuum_simple_2.txt'\n\tlin = 0\n\tcol = 0\n\tmapa = convert_file_to_map(file_map_path)\n\tprint(mapa)\n\tstate = VacuumWorldGeneric(mapa, lin, col, '')\n\talgorithm = BuscaProfundidadeIterativa()\n\tresult = algorithm.search(state)\n\tprint(f'Solu\u00e7\u00e3o = {result.show_path()}')\n\tprint('\\n')\n\tassert result.g == 4\n", "description": null, "category": "simple", "imports": ["from aicode.search.SearchAlgorithms import BuscaLargura", "from aicode.search.SearchAlgorithms import BuscaProfundidade", "from aicode.search.SearchAlgorithms import BuscaProfundidadeIterativa", "from VacuumWorldGeneric import *"]}, {"term": "def", "name": "test_BPI_simple_3", "data": "def test_BPI_simple_3():\n\tprint('\\n#### BPI Simples 3 ####')\n\tfile_map_path = 'data/vacuum_simple_3.txt'\n\tlin = 0\n\tcol = 0\n\tmapa = convert_file_to_map(file_map_path)\n\tprint(mapa)\n\tstate = VacuumWorldGeneric(mapa, lin, col, '')\n\talgorithm = BuscaProfundidadeIterativa()\n\tresult = algorithm.search(state)\n\tprint(f'Solu\u00e7\u00e3o = {result.show_path()}')\n\tprint('\\n')\n\tassert result.g == 8\n", "description": null, "category": "simple", "imports": ["from aicode.search.SearchAlgorithms import BuscaLargura", "from aicode.search.SearchAlgorithms import BuscaProfundidade", "from aicode.search.SearchAlgorithms import BuscaProfundidadeIterativa", "from VacuumWorldGeneric import *"]}, {"term": "def", "name": "test_BPI_simple_4", "data": "def test_BPI_simple_4():\n\tprint('\\n#### BPI Simples 4 ####')\n\tfile_map_path = 'data/vacuum_simple_4.txt'\n\tlin = 0\n\tcol = 0\n\tmapa = convert_file_to_map(file_map_path)\n\tprint(mapa)\n\tstate = VacuumWorldGeneric(mapa, lin, col, '')\n\talgorithm = BuscaProfundidadeIterativa()\n\tresult = algorithm.search(state)\n\tprint(f'Solu\u00e7\u00e3o = {result.show_path()}')\n\tprint('\\n')\n\tassert result.g == 10\n", "description": null, "category": "simple", "imports": ["from aicode.search.SearchAlgorithms import BuscaLargura", "from aicode.search.SearchAlgorithms import BuscaProfundidade", "from aicode.search.SearchAlgorithms import BuscaProfundidadeIterativa", "from VacuumWorldGeneric import *"]}, {"term": "def", "name": "test_BPI_simple_5", "data": "def test_BPI_simple_5():\n\tprint('\\n#### BPI Simples 5 ####')\n\tfile_map_path = 'data/vacuum_simple_5.txt'\n\tlin = 0\n\tcol = 0\n\tmapa = convert_file_to_map(file_map_path)\n\tprint(mapa)\n\tstate = VacuumWorldGeneric(mapa, lin, col, '')\n\talgorithm = BuscaProfundidadeIterativa()\n\tprint('Se prepara que este vai demorar! Vale a pena monitorar o consumo de mem\u00f3ria!!!')\n\tresult = algorithm.search(state)\n\tprint(f'Solu\u00e7\u00e3o = {result.show_path()}')\n\tprint('\\n')\n\tassert result.g == 15\n", "description": null, "category": "simple", "imports": ["from aicode.search.SearchAlgorithms import BuscaLargura", "from aicode.search.SearchAlgorithms import BuscaProfundidade", "from aicode.search.SearchAlgorithms import BuscaProfundidadeIterativa", "from VacuumWorldGeneric import *"]}, {"term": "def", "name": "test_BPI_simple_6", "data": "def test_BPI_simple_6():\n\tprint('\\n#### BPI Simples 6 ####')\n\tfile_map_path = 'data/vacuum_simple_6.txt'\n\tlin = 0\n\tcol = 0\n\tmapa = convert_file_to_map(file_map_path)\n\tprint(mapa)\n\tstate = VacuumWorldGeneric(mapa, lin, col, '')\n\talgorithm = BuscaProfundidadeIterativa()\n\tresult = algorithm.search(state)\n\tprint(f'Solu\u00e7\u00e3o = {result.show_path()}')\n\tprint('\\n')\n\tassert result.g == 23\n", "description": null, "category": "simple", "imports": ["from aicode.search.SearchAlgorithms import BuscaLargura", "from aicode.search.SearchAlgorithms import BuscaProfundidade", "from aicode.search.SearchAlgorithms import BuscaProfundidadeIterativa", "from VacuumWorldGeneric import *"]}, {"term": "def", "name": "test_BPI_simple_7", "data": "def test_BPI_simple_7():\n\tprint('\\n#### BPI Simples 7 ####')\n\tfile_map_path = 'data/vacuum_simple_7.txt'\n\tlin = 0\n\tcol = 0\n\tmapa = convert_file_to_map(file_map_path)\n\tprint(mapa)\n\tstate = VacuumWorldGeneric(mapa, lin, col, '')\n\talgorithm = BuscaProfundidadeIterativa()\n\tresult = algorithm.search(state)\n\tprint(f'Solu\u00e7\u00e3o = {result.show_path()}')\n\tprint('\\n')\n\tassert result.g == 16\n", "description": null, "category": "simple", "imports": ["from aicode.search.SearchAlgorithms import BuscaLargura", "from aicode.search.SearchAlgorithms import BuscaProfundidade", "from aicode.search.SearchAlgorithms import BuscaProfundidadeIterativa", "from VacuumWorldGeneric import *"]}, {"term": "def", "name": "test_BPI_simple_8", "data": "def test_BPI_simple_8():\n\tprint('\\n#### BPI Simples 8 ####')\n\tfile_map_path = 'data/vacuum_simple_8.txt'\n\tlin = 0\n\tcol = 0\n\tmapa = convert_file_to_map(file_map_path)\n\tprint(mapa)\n\tstate = VacuumWorldGeneric(mapa, lin, col, '')\n\talgorithm = BuscaProfundidadeIterativa()\n\tresult = algorithm.search(state)\n\tprint(f'Solu\u00e7\u00e3o = {result.show_path()}')\n\tprint('\\n')\n", "description": null, "category": "simple", "imports": ["from aicode.search.SearchAlgorithms import BuscaLargura", "from aicode.search.SearchAlgorithms import BuscaProfundidade", "from aicode.search.SearchAlgorithms import BuscaProfundidadeIterativa", "from VacuumWorldGeneric import *"]}], [{"term": "def", "name": "fwith_tp_del", "data": "\tdef with_tp_del(cls):\n\t\tclass C(object):\n\t\t\tdef __new__(cls, *args, **kwargs):\n\t\t\t\traise TypeError('requires _testcapi.with_tp_del')\n\t\treturn C\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "classNonGCSimpleBase:", "data": "class NonGCSimpleBase:\n\t\"\"\"\n\tThe base class for all the objects under test, equipped with various\n\ttesting features.\n\t\"\"\"\n\n\tsurvivors = []\n\tdel_calls = []\n\ttp_del_calls = []\n\terrors = []\n\n\t_cleaning = False\n\n\t__slots__ = ()\n\n\t@classmethod\n\tdef _cleanup(cls):\n\t\tcls.survivors.clear()\n\t\tcls.errors.clear()\n\t\tgc.garbage.clear()\n\t\tgc.collect()\n\t\tcls.del_calls.clear()\n\t\tcls.tp_del_calls.clear()\n\n\t@classmethod\n\t@contextlib.contextmanager\n\tdef test(cls):\n\t\t\"\"\"\n\t\tA context manager to use around all finalization tests.\n\t\t\"\"\"\n\t\twith support.disable_gc():\n\t\t\tcls.del_calls.clear()\n\t\t\tcls.tp_del_calls.clear()\n\t\t\tNonGCSimpleBase._cleaning = False\n\t\t\ttry:\n\t\t\t\tyield\n\t\t\t\tif cls.errors:\n\t\t\t\t\traise cls.errors[0]\n\t\t\tfinally:\n\t\t\t\tNonGCSimpleBase._cleaning = True\n\t\t\t\tcls._cleanup()\n\n\tdef check_sanity(self):\n\t\t\"\"\"\n\t\tCheck the object is sane (non-broken).\n\t\t\"\"\"\n\n\tdef __del__(self):\n\t\t\"\"\"\n\t\tPEP 442 finalizer.  Record that this was called, check the\n\t\tobject is in a sane state, and invoke a side effect.\n\t\t\"\"\"\n\t\ttry:\n\t\t\tif not self._cleaning:\n\t\t\t\tself.del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\t\t\tself.side_effect()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tA side effect called on destruction.\n\t\t\"\"\"\n\n", "description": "\n\tThe base class for all the objects under test, equipped with various\n\ttesting features.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleBase", "data": "class SimpleBase(NonGCSimpleBase):\n\n\tdef __init__(self):\n\t\tself.id_ = id(self)\n\n\tdef check_sanity(self):\n\t\tassert self.id_ == id(self)\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "NonGC", "data": "class NonGC(NonGCSimpleBase):\n\t__slots__ = ()\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "NonGCResurrector", "data": "class NonGCResurrector(NonGCSimpleBase):\n\t__slots__ = ()\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tResurrect self by storing self in a class-wide list.\n\t\t\"\"\"\n\t\tself.survivors.append(self)\n", "description": "\n\t\tResurrect self by storing self in a class-wide list.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "Simple", "data": "class Simple(SimpleBase):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleResurrector", "data": "class SimpleResurrector(NonGCResurrector, SimpleBase):\n\tpass\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "classTestBase:", "data": "class TestBase:\n\n\tdef setUp(self):\n\t\tself.old_garbage = gc.garbage[:]\n\t\tgc.garbage[:] = []\n\n\tdef tearDown(self):\n\t\t# None of the tests here should put anything in gc.garbage\n\t\ttry:\n\t\t\tself.assertEqual(gc.garbage, [])\n\t\tfinally:\n\t\t\tdel self.old_garbage\n\t\t\tgc.collect()\n\n\tdef assert_del_calls(self, ids):\n\t\tself.assertEqual(sorted(SimpleBase.del_calls), sorted(ids))\n\n\tdef assert_tp_del_calls(self, ids):\n\t\tself.assertEqual(sorted(SimpleBase.tp_del_calls), sorted(ids))\n\n\tdef assert_survivors(self, ids):\n\t\tself.assertEqual(sorted(id(x) for x in SimpleBase.survivors), sorted(ids))\n\n\tdef assert_garbage(self, ids):\n\t\tself.assertEqual(sorted(id(x) for x in gc.garbage), sorted(ids))\n\n\tdef clear_survivors(self):\n\t\tSimpleBase.survivors.clear()\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleFinalizationTest", "data": "class SimpleFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization without refcycles.\n\t\"\"\"\n\n\tdef test_simple(self):\n\t\twith SimpleBase.test():\n\t\t\ts = Simple()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_simple_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = SimpleResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\tself.assertIsNot(wr(), None)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\tself.assertIs(wr(), None)\n\n\tdef test_non_gc(self):\n\t\twith SimpleBase.test():\n\t\t\ts = NonGC()\n\t\t\tself.assertFalse(gc.is_tracked(s))\n\t\t\tids = [id(s)]\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_non_gc_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = NonGCResurrector()\n\t\t\tself.assertFalse(gc.is_tracked(s))\n\t\t\tids = [id(s)]\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids * 2)\n\t\t\tself.assert_survivors(ids)\n\n", "description": "\n\tTest finalization without refcycles.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "classSelfCycleBase:", "data": "class SelfCycleBase:\n\n\tdef __init__(self):\n\t\tsuper().__init__()\n\t\tself.ref = self\n\n\tdef check_sanity(self):\n\t\tsuper().check_sanity()\n\t\tassert self.ref is self\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleSelfCycle", "data": "class SimpleSelfCycle(SelfCycleBase, Simple):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SelfCycleResurrector", "data": "class SelfCycleResurrector(SelfCycleBase, SimpleResurrector):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SuicidalSelfCycle", "data": "class SuicidalSelfCycle(SelfCycleBase, Simple):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tExplicitly break the reference cycle.\n\t\t\"\"\"\n\t\tself.ref = None\n\n", "description": "\n\t\tExplicitly break the reference cycle.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SelfCycleFinalizationTest", "data": "class SelfCycleFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of an object having a single cyclic reference to\n\titself.\n\t\"\"\"\n\n\tdef test_simple(self):\n\t\twith SimpleBase.test():\n\t\t\ts = SimpleSelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_simple_resurrect(self):\n\t\t# Test that __del__ can resurrect the object being finalized.\n\t\twith SimpleBase.test():\n\t\t\ts = SelfCycleResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\t# XXX is this desirable?\n\t\t\tself.assertIs(wr(), None)\n\t\t\t# When trying to destroy the object a second time, __del__\n\t\t\t# isn't called anymore (and the object isn't resurrected).\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\n\tdef test_simple_suicide(self):\n\t\t# Test the GC is able to deal with an object that kills its last\n\t\t# reference during __del__.\n\t\twith SimpleBase.test():\n\t\t\ts = SuicidalSelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\n", "description": "\n\tTest finalization of an object having a single cyclic reference to\n\titself.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "classChainedBase:", "data": "class ChainedBase:\n\n\tdef chain(self, left):\n\t\tself.suicided = False\n\t\tself.left = left\n\t\tleft.right = self\n\n\tdef check_sanity(self):\n\t\tsuper().check_sanity()\n\t\tif self.suicided:\n\t\t\tassert self.left is None\n\t\t\tassert self.right is None\n\t\telse:\n\t\t\tleft = self.left\n\t\t\tif left.suicided:\n\t\t\t\tassert left.right is None\n\t\t\telse:\n\t\t\t\tassert left.right is self\n\t\t\tright = self.right\n\t\t\tif right.suicided:\n\t\t\t\tassert right.left is None\n\t\t\telse:\n\t\t\t\tassert right.left is self\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleChained", "data": "class SimpleChained(ChainedBase, Simple):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "ChainedResurrector", "data": "class ChainedResurrector(ChainedBase, SimpleResurrector):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SuicidalChained", "data": "class SuicidalChained(ChainedBase, Simple):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tExplicitly break the reference cycle.\n\t\t\"\"\"\n\t\tself.suicided = True\n\t\tself.left = None\n\t\tself.right = None\n\n", "description": "\n\t\tExplicitly break the reference cycle.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "CycleChainFinalizationTest", "data": "class CycleChainFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of a cyclic chain.  These tests are similar in\n\tspirit to the self-cycle tests above, but the collectable object\n\tgraph isn't trivial anymore.\n\t\"\"\"\n\n\tdef build_chain(self, classes):\n\t\tnodes = [cls() for cls in classes]\n\t\tfor i in range(len(nodes)):\n\t\t\tnodes[i].chain(nodes[i-1])\n\t\treturn nodes\n\n\tdef check_non_resurrecting_chain(self, classes):\n\t\tN = len(classes)\n\t\twith SimpleBase.test():\n\t\t\tnodes = self.build_chain(classes)\n\t\t\tids = [id(s) for s in nodes]\n\t\t\twrs = [weakref.ref(s) for s in nodes]\n\t\t\tdel nodes\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertEqual([wr() for wr in wrs], [None] * N)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\n\tdef check_resurrecting_chain(self, classes):\n\t\tN = len(classes)\n\t\twith SimpleBase.test():\n\t\t\tnodes = self.build_chain(classes)\n\t\t\tN = len(nodes)\n\t\t\tids = [id(s) for s in nodes]\n\t\t\tsurvivor_ids = [id(s) for s in nodes if isinstance(s, SimpleResurrector)]\n\t\t\twrs = [weakref.ref(s) for s in nodes]\n\t\t\tdel nodes\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(survivor_ids)\n\t\t\t# XXX desirable?\n\t\t\tself.assertEqual([wr() for wr in wrs], [None] * N)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_homogenous(self):\n\t\tself.check_non_resurrecting_chain([SimpleChained] * 3)\n\n\tdef test_homogenous_resurrect(self):\n\t\tself.check_resurrecting_chain([ChainedResurrector] * 3)\n\n\tdef test_homogenous_suicidal(self):\n\t\tself.check_non_resurrecting_chain([SuicidalChained] * 3)\n\n\tdef test_heterogenous_suicidal_one(self):\n\t\tself.check_non_resurrecting_chain([SuicidalChained, SimpleChained] * 2)\n\n\tdef test_heterogenous_suicidal_two(self):\n\t\tself.check_non_resurrecting_chain(\n\t\t\t[SuicidalChained] * 2 + [SimpleChained] * 2)\n\n\tdef test_heterogenous_resurrect_one(self):\n\t\tself.check_resurrecting_chain([ChainedResurrector, SimpleChained] * 2)\n\n\tdef test_heterogenous_resurrect_two(self):\n\t\tself.check_resurrecting_chain(\n\t\t\t[ChainedResurrector, SimpleChained, SuicidalChained] * 2)\n\n\tdef test_heterogenous_resurrect_three(self):\n\t\tself.check_resurrecting_chain(\n\t\t\t[ChainedResurrector] * 2 + [SimpleChained] * 2 + [SuicidalChained] * 2)\n\n", "description": "\n\tTest finalization of a cyclic chain.  These tests are similar in\n\tspirit to the self-cycle tests above, but the collectable object\n\tgraph isn't trivial anymore.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "LegacyBase", "data": "class LegacyBase(SimpleBase):\n\n\tdef __del__(self):\n\t\ttry:\n\t\t\t# Do not invoke side_effect here, since we are now exercising\n\t\t\t# the tp_del slot.\n\t\t\tif not self._cleaning:\n\t\t\t\tself.del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n\n\tdef __tp_del__(self):\n\t\t\"\"\"\n\t\tLegacy (pre-PEP 442) finalizer, mapped to a tp_del slot.\n\t\t\"\"\"\n\t\ttry:\n\t\t\tif not self._cleaning:\n\t\t\t\tself.tp_del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\t\t\tself.side_effect()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n", "description": "\n\t\tLegacy (pre-PEP 442) finalizer, mapped to a tp_del slot.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "Legacy", "data": "class Legacy(LegacyBase):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "LegacyResurrector", "data": "class LegacyResurrector(LegacyBase):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tResurrect self by storing self in a class-wide list.\n\t\t\"\"\"\n\t\tself.survivors.append(self)\n", "description": "\n\t\tResurrect self by storing self in a class-wide list.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "LegacySelfCycle", "data": "class LegacySelfCycle(SelfCycleBase, LegacyBase):\n\tpass\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "LegacyFinalizationTest", "data": "class LegacyFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of objects with a tp_del.\n\t\"\"\"\n\n\tdef tearDown(self):\n\t\t# These tests need to clean up a bit more, since they create\n\t\t# uncollectable objects.\n\t\tgc.garbage.clear()\n\t\tgc.collect()\n\t\tsuper().tearDown()\n\n\tdef test_legacy(self):\n\t\twith SimpleBase.test():\n\t\t\ts = Legacy()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\n\tdef test_legacy_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = LegacyResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\t# weakrefs are cleared before tp_del is called.\n\t\t\tself.assertIs(wr(), None)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids * 2)\n\t\t\tself.assert_survivors(ids)\n\t\tself.assertIs(wr(), None)\n\n\tdef test_legacy_self_cycle(self):\n\t\t# Self-cycles with legacy finalizers end up in gc.garbage.\n\t\twith SimpleBase.test():\n\t\t\ts = LegacySelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls([])\n\t\t\tself.assert_tp_del_calls([])\n\t\t\tself.assert_survivors([])\n\t\t\tself.assert_garbage(ids)\n\t\t\tself.assertIsNot(wr(), None)\n\t\t\t# Break the cycle to allow collection\n\t\t\tgc.garbage[0].ref = None\n\t\tself.assert_garbage([])\n\t\tself.assertIs(wr(), None)\n\n", "description": "\n\tTest finalization of objects with a tp_del.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}], [{"term": "def", "name": "fwith_tp_del", "data": "\tdef with_tp_del(cls):\n\t\tclass C(object):\n\t\t\tdef __new__(cls, *args, **kwargs):\n\t\t\t\traise TypeError('requires _testcapi.with_tp_del')\n\t\treturn C\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "classNonGCSimpleBase:", "data": "class NonGCSimpleBase:\n\t\"\"\"\n\tThe base class for all the objects under test, equipped with various\n\ttesting features.\n\t\"\"\"\n\n\tsurvivors = []\n\tdel_calls = []\n\ttp_del_calls = []\n\terrors = []\n\n\t_cleaning = False\n\n\t__slots__ = ()\n\n\t@classmethod\n\tdef _cleanup(cls):\n\t\tcls.survivors.clear()\n\t\tcls.errors.clear()\n\t\tgc.garbage.clear()\n\t\tgc.collect()\n\t\tcls.del_calls.clear()\n\t\tcls.tp_del_calls.clear()\n\n\t@classmethod\n\t@contextlib.contextmanager\n\tdef test(cls):\n\t\t\"\"\"\n\t\tA context manager to use around all finalization tests.\n\t\t\"\"\"\n\t\twith support.disable_gc():\n\t\t\tcls.del_calls.clear()\n\t\t\tcls.tp_del_calls.clear()\n\t\t\tNonGCSimpleBase._cleaning = False\n\t\t\ttry:\n\t\t\t\tyield\n\t\t\t\tif cls.errors:\n\t\t\t\t\traise cls.errors[0]\n\t\t\tfinally:\n\t\t\t\tNonGCSimpleBase._cleaning = True\n\t\t\t\tcls._cleanup()\n\n\tdef check_sanity(self):\n\t\t\"\"\"\n\t\tCheck the object is sane (non-broken).\n\t\t\"\"\"\n\n\tdef __del__(self):\n\t\t\"\"\"\n\t\tPEP 442 finalizer.  Record that this was called, check the\n\t\tobject is in a sane state, and invoke a side effect.\n\t\t\"\"\"\n\t\ttry:\n\t\t\tif not self._cleaning:\n\t\t\t\tself.del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\t\t\tself.side_effect()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tA side effect called on destruction.\n\t\t\"\"\"\n\n", "description": "\n\tThe base class for all the objects under test, equipped with various\n\ttesting features.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleBase", "data": "class SimpleBase(NonGCSimpleBase):\n\n\tdef __init__(self):\n\t\tself.id_ = id(self)\n\n\tdef check_sanity(self):\n\t\tassert self.id_ == id(self)\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "NonGC", "data": "class NonGC(NonGCSimpleBase):\n\t__slots__ = ()\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "NonGCResurrector", "data": "class NonGCResurrector(NonGCSimpleBase):\n\t__slots__ = ()\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tResurrect self by storing self in a class-wide list.\n\t\t\"\"\"\n\t\tself.survivors.append(self)\n", "description": "\n\t\tResurrect self by storing self in a class-wide list.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "Simple", "data": "class Simple(SimpleBase):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleResurrector", "data": "class SimpleResurrector(NonGCResurrector, SimpleBase):\n\tpass\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "classTestBase:", "data": "class TestBase:\n\n\tdef setUp(self):\n\t\tself.old_garbage = gc.garbage[:]\n\t\tgc.garbage[:] = []\n\n\tdef tearDown(self):\n\t\t# None of the tests here should put anything in gc.garbage\n\t\ttry:\n\t\t\tself.assertEqual(gc.garbage, [])\n\t\tfinally:\n\t\t\tdel self.old_garbage\n\t\t\tgc.collect()\n\n\tdef assert_del_calls(self, ids):\n\t\tself.assertEqual(sorted(SimpleBase.del_calls), sorted(ids))\n\n\tdef assert_tp_del_calls(self, ids):\n\t\tself.assertEqual(sorted(SimpleBase.tp_del_calls), sorted(ids))\n\n\tdef assert_survivors(self, ids):\n\t\tself.assertEqual(sorted(id(x) for x in SimpleBase.survivors), sorted(ids))\n\n\tdef assert_garbage(self, ids):\n\t\tself.assertEqual(sorted(id(x) for x in gc.garbage), sorted(ids))\n\n\tdef clear_survivors(self):\n\t\tSimpleBase.survivors.clear()\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleFinalizationTest", "data": "class SimpleFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization without refcycles.\n\t\"\"\"\n\n\tdef test_simple(self):\n\t\twith SimpleBase.test():\n\t\t\ts = Simple()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_simple_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = SimpleResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\tself.assertIsNot(wr(), None)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\tself.assertIs(wr(), None)\n\n\tdef test_non_gc(self):\n\t\twith SimpleBase.test():\n\t\t\ts = NonGC()\n\t\t\tself.assertFalse(gc.is_tracked(s))\n\t\t\tids = [id(s)]\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_non_gc_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = NonGCResurrector()\n\t\t\tself.assertFalse(gc.is_tracked(s))\n\t\t\tids = [id(s)]\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids * 2)\n\t\t\tself.assert_survivors(ids)\n\n", "description": "\n\tTest finalization without refcycles.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "classSelfCycleBase:", "data": "class SelfCycleBase:\n\n\tdef __init__(self):\n\t\tsuper().__init__()\n\t\tself.ref = self\n\n\tdef check_sanity(self):\n\t\tsuper().check_sanity()\n\t\tassert self.ref is self\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleSelfCycle", "data": "class SimpleSelfCycle(SelfCycleBase, Simple):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SelfCycleResurrector", "data": "class SelfCycleResurrector(SelfCycleBase, SimpleResurrector):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SuicidalSelfCycle", "data": "class SuicidalSelfCycle(SelfCycleBase, Simple):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tExplicitly break the reference cycle.\n\t\t\"\"\"\n\t\tself.ref = None\n\n", "description": "\n\t\tExplicitly break the reference cycle.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SelfCycleFinalizationTest", "data": "class SelfCycleFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of an object having a single cyclic reference to\n\titself.\n\t\"\"\"\n\n\tdef test_simple(self):\n\t\twith SimpleBase.test():\n\t\t\ts = SimpleSelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_simple_resurrect(self):\n\t\t# Test that __del__ can resurrect the object being finalized.\n\t\twith SimpleBase.test():\n\t\t\ts = SelfCycleResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\t# XXX is this desirable?\n\t\t\tself.assertIs(wr(), None)\n\t\t\t# When trying to destroy the object a second time, __del__\n\t\t\t# isn't called anymore (and the object isn't resurrected).\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\n\tdef test_simple_suicide(self):\n\t\t# Test the GC is able to deal with an object that kills its last\n\t\t# reference during __del__.\n\t\twith SimpleBase.test():\n\t\t\ts = SuicidalSelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\n", "description": "\n\tTest finalization of an object having a single cyclic reference to\n\titself.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "classChainedBase:", "data": "class ChainedBase:\n\n\tdef chain(self, left):\n\t\tself.suicided = False\n\t\tself.left = left\n\t\tleft.right = self\n\n\tdef check_sanity(self):\n\t\tsuper().check_sanity()\n\t\tif self.suicided:\n\t\t\tassert self.left is None\n\t\t\tassert self.right is None\n\t\telse:\n\t\t\tleft = self.left\n\t\t\tif left.suicided:\n\t\t\t\tassert left.right is None\n\t\t\telse:\n\t\t\t\tassert left.right is self\n\t\t\tright = self.right\n\t\t\tif right.suicided:\n\t\t\t\tassert right.left is None\n\t\t\telse:\n\t\t\t\tassert right.left is self\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleChained", "data": "class SimpleChained(ChainedBase, Simple):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "ChainedResurrector", "data": "class ChainedResurrector(ChainedBase, SimpleResurrector):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SuicidalChained", "data": "class SuicidalChained(ChainedBase, Simple):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tExplicitly break the reference cycle.\n\t\t\"\"\"\n\t\tself.suicided = True\n\t\tself.left = None\n\t\tself.right = None\n\n", "description": "\n\t\tExplicitly break the reference cycle.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "CycleChainFinalizationTest", "data": "class CycleChainFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of a cyclic chain.  These tests are similar in\n\tspirit to the self-cycle tests above, but the collectable object\n\tgraph isn't trivial anymore.\n\t\"\"\"\n\n\tdef build_chain(self, classes):\n\t\tnodes = [cls() for cls in classes]\n\t\tfor i in range(len(nodes)):\n\t\t\tnodes[i].chain(nodes[i-1])\n\t\treturn nodes\n\n\tdef check_non_resurrecting_chain(self, classes):\n\t\tN = len(classes)\n\t\twith SimpleBase.test():\n\t\t\tnodes = self.build_chain(classes)\n\t\t\tids = [id(s) for s in nodes]\n\t\t\twrs = [weakref.ref(s) for s in nodes]\n\t\t\tdel nodes\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertEqual([wr() for wr in wrs], [None] * N)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\n\tdef check_resurrecting_chain(self, classes):\n\t\tN = len(classes)\n\t\twith SimpleBase.test():\n\t\t\tnodes = self.build_chain(classes)\n\t\t\tN = len(nodes)\n\t\t\tids = [id(s) for s in nodes]\n\t\t\tsurvivor_ids = [id(s) for s in nodes if isinstance(s, SimpleResurrector)]\n\t\t\twrs = [weakref.ref(s) for s in nodes]\n\t\t\tdel nodes\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(survivor_ids)\n\t\t\t# XXX desirable?\n\t\t\tself.assertEqual([wr() for wr in wrs], [None] * N)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_homogenous(self):\n\t\tself.check_non_resurrecting_chain([SimpleChained] * 3)\n\n\tdef test_homogenous_resurrect(self):\n\t\tself.check_resurrecting_chain([ChainedResurrector] * 3)\n\n\tdef test_homogenous_suicidal(self):\n\t\tself.check_non_resurrecting_chain([SuicidalChained] * 3)\n\n\tdef test_heterogenous_suicidal_one(self):\n\t\tself.check_non_resurrecting_chain([SuicidalChained, SimpleChained] * 2)\n\n\tdef test_heterogenous_suicidal_two(self):\n\t\tself.check_non_resurrecting_chain(\n\t\t\t[SuicidalChained] * 2 + [SimpleChained] * 2)\n\n\tdef test_heterogenous_resurrect_one(self):\n\t\tself.check_resurrecting_chain([ChainedResurrector, SimpleChained] * 2)\n\n\tdef test_heterogenous_resurrect_two(self):\n\t\tself.check_resurrecting_chain(\n\t\t\t[ChainedResurrector, SimpleChained, SuicidalChained] * 2)\n\n\tdef test_heterogenous_resurrect_three(self):\n\t\tself.check_resurrecting_chain(\n\t\t\t[ChainedResurrector] * 2 + [SimpleChained] * 2 + [SuicidalChained] * 2)\n\n", "description": "\n\tTest finalization of a cyclic chain.  These tests are similar in\n\tspirit to the self-cycle tests above, but the collectable object\n\tgraph isn't trivial anymore.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "LegacyBase", "data": "class LegacyBase(SimpleBase):\n\n\tdef __del__(self):\n\t\ttry:\n\t\t\t# Do not invoke side_effect here, since we are now exercising\n\t\t\t# the tp_del slot.\n\t\t\tif not self._cleaning:\n\t\t\t\tself.del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n\n\tdef __tp_del__(self):\n\t\t\"\"\"\n\t\tLegacy (pre-PEP 442) finalizer, mapped to a tp_del slot.\n\t\t\"\"\"\n\t\ttry:\n\t\t\tif not self._cleaning:\n\t\t\t\tself.tp_del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\t\t\tself.side_effect()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n", "description": "\n\t\tLegacy (pre-PEP 442) finalizer, mapped to a tp_del slot.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "Legacy", "data": "class Legacy(LegacyBase):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "LegacyResurrector", "data": "class LegacyResurrector(LegacyBase):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tResurrect self by storing self in a class-wide list.\n\t\t\"\"\"\n\t\tself.survivors.append(self)\n", "description": "\n\t\tResurrect self by storing self in a class-wide list.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "LegacySelfCycle", "data": "class LegacySelfCycle(SelfCycleBase, LegacyBase):\n\tpass\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "LegacyFinalizationTest", "data": "class LegacyFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of objects with a tp_del.\n\t\"\"\"\n\n\tdef tearDown(self):\n\t\t# These tests need to clean up a bit more, since they create\n\t\t# uncollectable objects.\n\t\tgc.garbage.clear()\n\t\tgc.collect()\n\t\tsuper().tearDown()\n\n\tdef test_legacy(self):\n\t\twith SimpleBase.test():\n\t\t\ts = Legacy()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\n\tdef test_legacy_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = LegacyResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\t# weakrefs are cleared before tp_del is called.\n\t\t\tself.assertIs(wr(), None)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids * 2)\n\t\t\tself.assert_survivors(ids)\n\t\tself.assertIs(wr(), None)\n\n\tdef test_legacy_self_cycle(self):\n\t\t# Self-cycles with legacy finalizers end up in gc.garbage.\n\t\twith SimpleBase.test():\n\t\t\ts = LegacySelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls([])\n\t\t\tself.assert_tp_del_calls([])\n\t\t\tself.assert_survivors([])\n\t\t\tself.assert_garbage(ids)\n\t\t\tself.assertIsNot(wr(), None)\n\t\t\t# Break the cycle to allow collection\n\t\t\tgc.garbage[0].ref = None\n\t\tself.assert_garbage([])\n\t\tself.assertIs(wr(), None)\n\n", "description": "\n\tTest finalization of objects with a tp_del.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}], [{"term": "def", "name": "fwith_tp_del", "data": "\tdef with_tp_del(cls):\n\t\tclass C(object):\n\t\t\tdef __new__(cls, *args, **kwargs):\n\t\t\t\traise TypeError('requires _testcapi.with_tp_del')\n\t\treturn C\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "classNonGCSimpleBase:", "data": "class NonGCSimpleBase:\n\t\"\"\"\n\tThe base class for all the objects under test, equipped with various\n\ttesting features.\n\t\"\"\"\n\n\tsurvivors = []\n\tdel_calls = []\n\ttp_del_calls = []\n\terrors = []\n\n\t_cleaning = False\n\n\t__slots__ = ()\n\n\t@classmethod\n\tdef _cleanup(cls):\n\t\tcls.survivors.clear()\n\t\tcls.errors.clear()\n\t\tgc.garbage.clear()\n\t\tgc.collect()\n\t\tcls.del_calls.clear()\n\t\tcls.tp_del_calls.clear()\n\n\t@classmethod\n\t@contextlib.contextmanager\n\tdef test(cls):\n\t\t\"\"\"\n\t\tA context manager to use around all finalization tests.\n\t\t\"\"\"\n\t\twith support.disable_gc():\n\t\t\tcls.del_calls.clear()\n\t\t\tcls.tp_del_calls.clear()\n\t\t\tNonGCSimpleBase._cleaning = False\n\t\t\ttry:\n\t\t\t\tyield\n\t\t\t\tif cls.errors:\n\t\t\t\t\traise cls.errors[0]\n\t\t\tfinally:\n\t\t\t\tNonGCSimpleBase._cleaning = True\n\t\t\t\tcls._cleanup()\n\n\tdef check_sanity(self):\n\t\t\"\"\"\n\t\tCheck the object is sane (non-broken).\n\t\t\"\"\"\n\n\tdef __del__(self):\n\t\t\"\"\"\n\t\tPEP 442 finalizer.  Record that this was called, check the\n\t\tobject is in a sane state, and invoke a side effect.\n\t\t\"\"\"\n\t\ttry:\n\t\t\tif not self._cleaning:\n\t\t\t\tself.del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\t\t\tself.side_effect()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tA side effect called on destruction.\n\t\t\"\"\"\n\n", "description": "\n\tThe base class for all the objects under test, equipped with various\n\ttesting features.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleBase", "data": "class SimpleBase(NonGCSimpleBase):\n\n\tdef __init__(self):\n\t\tself.id_ = id(self)\n\n\tdef check_sanity(self):\n\t\tassert self.id_ == id(self)\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "NonGC", "data": "class NonGC(NonGCSimpleBase):\n\t__slots__ = ()\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "NonGCResurrector", "data": "class NonGCResurrector(NonGCSimpleBase):\n\t__slots__ = ()\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tResurrect self by storing self in a class-wide list.\n\t\t\"\"\"\n\t\tself.survivors.append(self)\n", "description": "\n\t\tResurrect self by storing self in a class-wide list.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "Simple", "data": "class Simple(SimpleBase):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleResurrector", "data": "class SimpleResurrector(NonGCResurrector, SimpleBase):\n\tpass\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "classTestBase:", "data": "class TestBase:\n\n\tdef setUp(self):\n\t\tself.old_garbage = gc.garbage[:]\n\t\tgc.garbage[:] = []\n\n\tdef tearDown(self):\n\t\t# None of the tests here should put anything in gc.garbage\n\t\ttry:\n\t\t\tself.assertEqual(gc.garbage, [])\n\t\tfinally:\n\t\t\tdel self.old_garbage\n\t\t\tgc.collect()\n\n\tdef assert_del_calls(self, ids):\n\t\tself.assertEqual(sorted(SimpleBase.del_calls), sorted(ids))\n\n\tdef assert_tp_del_calls(self, ids):\n\t\tself.assertEqual(sorted(SimpleBase.tp_del_calls), sorted(ids))\n\n\tdef assert_survivors(self, ids):\n\t\tself.assertEqual(sorted(id(x) for x in SimpleBase.survivors), sorted(ids))\n\n\tdef assert_garbage(self, ids):\n\t\tself.assertEqual(sorted(id(x) for x in gc.garbage), sorted(ids))\n\n\tdef clear_survivors(self):\n\t\tSimpleBase.survivors.clear()\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleFinalizationTest", "data": "class SimpleFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization without refcycles.\n\t\"\"\"\n\n\tdef test_simple(self):\n\t\twith SimpleBase.test():\n\t\t\ts = Simple()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_simple_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = SimpleResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\tself.assertIsNot(wr(), None)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\tself.assertIs(wr(), None)\n\n\tdef test_non_gc(self):\n\t\twith SimpleBase.test():\n\t\t\ts = NonGC()\n\t\t\tself.assertFalse(gc.is_tracked(s))\n\t\t\tids = [id(s)]\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_non_gc_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = NonGCResurrector()\n\t\t\tself.assertFalse(gc.is_tracked(s))\n\t\t\tids = [id(s)]\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids * 2)\n\t\t\tself.assert_survivors(ids)\n\n", "description": "\n\tTest finalization without refcycles.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "classSelfCycleBase:", "data": "class SelfCycleBase:\n\n\tdef __init__(self):\n\t\tsuper().__init__()\n\t\tself.ref = self\n\n\tdef check_sanity(self):\n\t\tsuper().check_sanity()\n\t\tassert self.ref is self\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleSelfCycle", "data": "class SimpleSelfCycle(SelfCycleBase, Simple):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SelfCycleResurrector", "data": "class SelfCycleResurrector(SelfCycleBase, SimpleResurrector):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SuicidalSelfCycle", "data": "class SuicidalSelfCycle(SelfCycleBase, Simple):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tExplicitly break the reference cycle.\n\t\t\"\"\"\n\t\tself.ref = None\n\n", "description": "\n\t\tExplicitly break the reference cycle.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SelfCycleFinalizationTest", "data": "class SelfCycleFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of an object having a single cyclic reference to\n\titself.\n\t\"\"\"\n\n\tdef test_simple(self):\n\t\twith SimpleBase.test():\n\t\t\ts = SimpleSelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_simple_resurrect(self):\n\t\t# Test that __del__ can resurrect the object being finalized.\n\t\twith SimpleBase.test():\n\t\t\ts = SelfCycleResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\t# XXX is this desirable?\n\t\t\tself.assertIs(wr(), None)\n\t\t\t# When trying to destroy the object a second time, __del__\n\t\t\t# isn't called anymore (and the object isn't resurrected).\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\n\tdef test_simple_suicide(self):\n\t\t# Test the GC is able to deal with an object that kills its last\n\t\t# reference during __del__.\n\t\twith SimpleBase.test():\n\t\t\ts = SuicidalSelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\n", "description": "\n\tTest finalization of an object having a single cyclic reference to\n\titself.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "classChainedBase:", "data": "class ChainedBase:\n\n\tdef chain(self, left):\n\t\tself.suicided = False\n\t\tself.left = left\n\t\tleft.right = self\n\n\tdef check_sanity(self):\n\t\tsuper().check_sanity()\n\t\tif self.suicided:\n\t\t\tassert self.left is None\n\t\t\tassert self.right is None\n\t\telse:\n\t\t\tleft = self.left\n\t\t\tif left.suicided:\n\t\t\t\tassert left.right is None\n\t\t\telse:\n\t\t\t\tassert left.right is self\n\t\t\tright = self.right\n\t\t\tif right.suicided:\n\t\t\t\tassert right.left is None\n\t\t\telse:\n\t\t\t\tassert right.left is self\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleChained", "data": "class SimpleChained(ChainedBase, Simple):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "ChainedResurrector", "data": "class ChainedResurrector(ChainedBase, SimpleResurrector):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SuicidalChained", "data": "class SuicidalChained(ChainedBase, Simple):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tExplicitly break the reference cycle.\n\t\t\"\"\"\n\t\tself.suicided = True\n\t\tself.left = None\n\t\tself.right = None\n\n", "description": "\n\t\tExplicitly break the reference cycle.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "CycleChainFinalizationTest", "data": "class CycleChainFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of a cyclic chain.  These tests are similar in\n\tspirit to the self-cycle tests above, but the collectable object\n\tgraph isn't trivial anymore.\n\t\"\"\"\n\n\tdef build_chain(self, classes):\n\t\tnodes = [cls() for cls in classes]\n\t\tfor i in range(len(nodes)):\n\t\t\tnodes[i].chain(nodes[i-1])\n\t\treturn nodes\n\n\tdef check_non_resurrecting_chain(self, classes):\n\t\tN = len(classes)\n\t\twith SimpleBase.test():\n\t\t\tnodes = self.build_chain(classes)\n\t\t\tids = [id(s) for s in nodes]\n\t\t\twrs = [weakref.ref(s) for s in nodes]\n\t\t\tdel nodes\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertEqual([wr() for wr in wrs], [None] * N)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\n\tdef check_resurrecting_chain(self, classes):\n\t\tN = len(classes)\n\t\twith SimpleBase.test():\n\t\t\tnodes = self.build_chain(classes)\n\t\t\tN = len(nodes)\n\t\t\tids = [id(s) for s in nodes]\n\t\t\tsurvivor_ids = [id(s) for s in nodes if isinstance(s, SimpleResurrector)]\n\t\t\twrs = [weakref.ref(s) for s in nodes]\n\t\t\tdel nodes\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(survivor_ids)\n\t\t\t# XXX desirable?\n\t\t\tself.assertEqual([wr() for wr in wrs], [None] * N)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_homogenous(self):\n\t\tself.check_non_resurrecting_chain([SimpleChained] * 3)\n\n\tdef test_homogenous_resurrect(self):\n\t\tself.check_resurrecting_chain([ChainedResurrector] * 3)\n\n\tdef test_homogenous_suicidal(self):\n\t\tself.check_non_resurrecting_chain([SuicidalChained] * 3)\n\n\tdef test_heterogenous_suicidal_one(self):\n\t\tself.check_non_resurrecting_chain([SuicidalChained, SimpleChained] * 2)\n\n\tdef test_heterogenous_suicidal_two(self):\n\t\tself.check_non_resurrecting_chain(\n\t\t\t[SuicidalChained] * 2 + [SimpleChained] * 2)\n\n\tdef test_heterogenous_resurrect_one(self):\n\t\tself.check_resurrecting_chain([ChainedResurrector, SimpleChained] * 2)\n\n\tdef test_heterogenous_resurrect_two(self):\n\t\tself.check_resurrecting_chain(\n\t\t\t[ChainedResurrector, SimpleChained, SuicidalChained] * 2)\n\n\tdef test_heterogenous_resurrect_three(self):\n\t\tself.check_resurrecting_chain(\n\t\t\t[ChainedResurrector] * 2 + [SimpleChained] * 2 + [SuicidalChained] * 2)\n\n", "description": "\n\tTest finalization of a cyclic chain.  These tests are similar in\n\tspirit to the self-cycle tests above, but the collectable object\n\tgraph isn't trivial anymore.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "LegacyBase", "data": "class LegacyBase(SimpleBase):\n\n\tdef __del__(self):\n\t\ttry:\n\t\t\t# Do not invoke side_effect here, since we are now exercising\n\t\t\t# the tp_del slot.\n\t\t\tif not self._cleaning:\n\t\t\t\tself.del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n\n\tdef __tp_del__(self):\n\t\t\"\"\"\n\t\tLegacy (pre-PEP 442) finalizer, mapped to a tp_del slot.\n\t\t\"\"\"\n\t\ttry:\n\t\t\tif not self._cleaning:\n\t\t\t\tself.tp_del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\t\t\tself.side_effect()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n", "description": "\n\t\tLegacy (pre-PEP 442) finalizer, mapped to a tp_del slot.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "Legacy", "data": "class Legacy(LegacyBase):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "LegacyResurrector", "data": "class LegacyResurrector(LegacyBase):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tResurrect self by storing self in a class-wide list.\n\t\t\"\"\"\n\t\tself.survivors.append(self)\n", "description": "\n\t\tResurrect self by storing self in a class-wide list.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "LegacySelfCycle", "data": "class LegacySelfCycle(SelfCycleBase, LegacyBase):\n\tpass\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "LegacyFinalizationTest", "data": "class LegacyFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of objects with a tp_del.\n\t\"\"\"\n\n\tdef tearDown(self):\n\t\t# These tests need to clean up a bit more, since they create\n\t\t# uncollectable objects.\n\t\tgc.garbage.clear()\n\t\tgc.collect()\n\t\tsuper().tearDown()\n\n\tdef test_legacy(self):\n\t\twith SimpleBase.test():\n\t\t\ts = Legacy()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\n\tdef test_legacy_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = LegacyResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\t# weakrefs are cleared before tp_del is called.\n\t\t\tself.assertIs(wr(), None)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids * 2)\n\t\t\tself.assert_survivors(ids)\n\t\tself.assertIs(wr(), None)\n\n\tdef test_legacy_self_cycle(self):\n\t\t# Self-cycles with legacy finalizers end up in gc.garbage.\n\t\twith SimpleBase.test():\n\t\t\ts = LegacySelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls([])\n\t\t\tself.assert_tp_del_calls([])\n\t\t\tself.assert_survivors([])\n\t\t\tself.assert_garbage(ids)\n\t\t\tself.assertIsNot(wr(), None)\n\t\t\t# Break the cycle to allow collection\n\t\t\tgc.garbage[0].ref = None\n\t\tself.assert_garbage([])\n\t\tself.assertIs(wr(), None)\n\n", "description": "\n\tTest finalization of objects with a tp_del.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}], [{"term": "def", "name": "SimplePoint", "data": "def SimplePoint():\n\tnewpoints = []\n\n\tnewpoints.append([0.0, 0.0, 0.0])\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleLine", "data": "def SimpleLine(c1=[0.0, 0.0, 0.0], c2=[2.0, 2.0, 2.0]):\n\tnewpoints = []\n\n\tc3 = Vector(c2) - Vector(c1)\n\tnewpoints.append([0.0, 0.0, 0.0])\n\tnewpoints.append([c3[0], c3[1], c3[2]])\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleAngle", "data": "def SimpleAngle(length=1.0, angle=45.0):\n\tnewpoints = []\n\n\tangle = radians(angle)\n\tnewpoints.append([length, 0.0, 0.0])\n\tnewpoints.append([0.0, 0.0, 0.0])\n\tnewpoints.append([length * cos(angle), length * sin(angle), 0.0])\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleDistance", "data": "def SimpleDistance(length=1.0, center=True):\n\tnewpoints = []\n\n\tif center:\n\t\tnewpoints.append([-length / 2, 0.0, 0.0])\n\t\tnewpoints.append([length / 2, 0.0, 0.0])\n\telse:\n\t\tnewpoints.append([0.0, 0.0, 0.0])\n\t\tnewpoints.append([length, 0.0, 0.0])\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleCircle", "data": "def SimpleCircle(sides=4, radius=1.0):\n\tnewpoints = []\n\n\tangle = radians(360) / sides\n\tnewpoints.append([radius, 0, 0])\n\tj = 1\n\twhile j < sides:\n\t\tt = angle * j\n\t\tx = cos(t) * radius\n\t\ty = sin(t) * radius\n\t\tnewpoints.append([x, y, 0])\n\t\tj += 1\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleEllipse", "data": "def SimpleEllipse(a=2.0, b=1.0):\n\tnewpoints = []\n\n\tnewpoints.append([a, 0.0, 0.0])\n\tnewpoints.append([0.0, b, 0.0])\n\tnewpoints.append([-a, 0.0, 0.0])\n\tnewpoints.append([0.0, -b, 0.0])\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleArc", "data": "def SimpleArc(sides=0, radius=1.0, startangle=0.0, endangle=45.0):\n\tnewpoints = []\n\n\tstartangle = radians(startangle)\n\tendangle = radians(endangle)\n\tsides += 1\n\n\tangle = (endangle - startangle) / sides\n\tx = cos(startangle) * radius\n\ty = sin(startangle) * radius\n\tnewpoints.append([x, y, 0])\n\tj = 1\n\twhile j < sides:\n\t\tt = angle * j\n\t\tx = cos(t + startangle) * radius\n\t\ty = sin(t + startangle) * radius\n\t\tnewpoints.append([x, y, 0])\n\t\tj += 1\n\tx = cos(endangle) * radius\n\ty = sin(endangle) * radius\n\tnewpoints.append([x, y, 0])\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleSector", "data": "def SimpleSector(sides=0, radius=1.0, startangle=0.0, endangle=45.0):\n\tnewpoints = []\n\n\tstartangle = radians(startangle)\n\tendangle = radians(endangle)\n\tsides += 1\n\n\tnewpoints.append([0, 0, 0])\n\tangle = (endangle - startangle) / sides\n\tx = cos(startangle) * radius\n\ty = sin(startangle) * radius\n\tnewpoints.append([x, y, 0])\n\tj = 1\n\twhile j < sides:\n\t\tt = angle * j\n\t\tx = cos(t + startangle) * radius\n\t\ty = sin(t + startangle) * radius\n\t\tnewpoints.append([x, y, 0])\n\t\tj += 1\n\tx = cos(endangle) * radius\n\ty = sin(endangle) * radius\n\tnewpoints.append([x, y, 0])\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleSegment", "data": "def SimpleSegment(sides=0, a=2.0, b=1.0, startangle=0.0, endangle=45.0):\n\tnewpoints = []\n\n\tstartangle = radians(startangle)\n\tendangle = radians(endangle)\n\tsides += 1\n\n\tangle = (endangle - startangle) / sides\n\tx = cos(startangle) * a\n\ty = sin(startangle) * a\n\tnewpoints.append([x, y, 0])\n\tj = 1\n\twhile j < sides:\n\t\tt = angle * j\n\t\tx = cos(t + startangle) * a\n\t\ty = sin(t + startangle) * a\n\t\tnewpoints.append([x, y, 0])\n\t\tj += 1\n\tx = cos(endangle) * a\n\ty = sin(endangle) * a\n\tnewpoints.append([x, y, 0])\n\n\tx = cos(endangle) * b\n\ty = sin(endangle) * b\n\tnewpoints.append([x, y, 0])\n\tj = sides\n\twhile j > 0:\n\t\tt = angle * j\n\t\tx = cos(t + startangle) * b\n\t\ty = sin(t + startangle) * b\n\t\tnewpoints.append([x, y, 0])\n\t\tj -= 1\n\tx = cos(startangle) * b\n\ty = sin(startangle) * b\n\tnewpoints.append([x, y, 0])\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleRectangle", "data": "def SimpleRectangle(width=2.0, length=2.0, rounded=0.0, center=True):\n\tnewpoints = []\n\n\tr = rounded / 2\n\n\tif center:\n\t\tx = width / 2\n\t\ty = length / 2\n\t\tif rounded != 0.0:\n\t\t\tnewpoints.append([-x + r, y, 0.0])\n\t\t\tnewpoints.append([x - r, y, 0.0])\n\t\t\tnewpoints.append([x, y - r, 0.0])\n\t\t\tnewpoints.append([x, -y + r, 0.0])\n\t\t\tnewpoints.append([x - r, -y, 0.0])\n\t\t\tnewpoints.append([-x + r, -y, 0.0])\n\t\t\tnewpoints.append([-x, -y + r, 0.0])\n\t\t\tnewpoints.append([-x, y - r, 0.0])\n\t\telse:\n\t\t\tnewpoints.append([-x, y, 0.0])\n\t\t\tnewpoints.append([x, y, 0.0])\n\t\t\tnewpoints.append([x, -y, 0.0])\n\t\t\tnewpoints.append([-x, -y, 0.0])\n\n\telse:\n\t\tx = width\n\t\ty = length\n\t\tif rounded != 0.0:\n\t\t\tnewpoints.append([r, y, 0.0])\n\t\t\tnewpoints.append([x - r, y, 0.0])\n\t\t\tnewpoints.append([x, y - r, 0.0])\n\t\t\tnewpoints.append([x, r, 0.0])\n\t\t\tnewpoints.append([x - r, 0.0, 0.0])\n\t\t\tnewpoints.append([r, 0.0, 0.0])\n\t\t\tnewpoints.append([0.0, r, 0.0])\n\t\t\tnewpoints.append([0.0, y - r, 0.0])\n\t\telse:\n\t\t\tnewpoints.append([0.0, 0.0, 0.0])\n\t\t\tnewpoints.append([0.0, y, 0.0])\n\t\t\tnewpoints.append([x, y, 0.0])\n\t\t\tnewpoints.append([x, 0.0, 0.0])\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleRhomb", "data": "def SimpleRhomb(width=2.0, length=2.0, center=True):\n\tnewpoints = []\n\tx = width / 2\n\ty = length / 2\n\n\tif center:\n\t\tnewpoints.append([-x, 0.0, 0.0])\n\t\tnewpoints.append([0.0, y, 0.0])\n\t\tnewpoints.append([x, 0.0, 0.0])\n\t\tnewpoints.append([0.0, -y, 0.0])\n\telse:\n\t\tnewpoints.append([x, 0.0, 0.0])\n\t\tnewpoints.append([0.0, y, 0.0])\n\t\tnewpoints.append([x, length, 0.0])\n\t\tnewpoints.append([width, y, 0.0])\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimplePolygon", "data": "def SimplePolygon(sides=3, radius=1.0):\n\tnewpoints = []\n\tangle = radians(360.0) / sides\n\tj = 0\n\n\twhile j < sides:\n\t\tt = angle * j\n\t\tx = sin(t) * radius\n\t\ty = cos(t) * radius\n\t\tnewpoints.append([x, y, 0.0])\n\t\tj += 1\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimplePolygon_ab", "data": "def SimplePolygon_ab(sides=3, a=2.0, b=1.0):\n\tnewpoints = []\n\tangle = radians(360.0) / sides\n\tj = 0\n\n\twhile j < sides:\n\t\tt = angle * j\n\t\tx = sin(t) * a\n\t\ty = cos(t) * b\n\t\tnewpoints.append([x, y, 0.0])\n\t\tj += 1\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleTrapezoid", "data": "def SimpleTrapezoid(a=2.0, b=1.0, h=1.0, center=True):\n\tnewpoints = []\n\tx = a / 2\n\ty = b / 2\n\tr = h / 2\n\n\tif center:\n\t\tnewpoints.append([-x, -r, 0.0])\n\t\tnewpoints.append([-y, r, 0.0])\n\t\tnewpoints.append([y, r, 0.0])\n\t\tnewpoints.append([x, -r, 0.0])\n\n\telse:\n\t\tnewpoints.append([0.0, 0.0, 0.0])\n\t\tnewpoints.append([x - y, h, 0.0])\n\t\tnewpoints.append([x + y, h, 0.0])\n\t\tnewpoints.append([a, 0.0, 0.0])\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "align_matrix", "data": "def align_matrix(context, location):\n\tloc = Matrix.Translation(location)\n\tobj_align = context.user_preferences.edit.object_align\n\tif (context.space_data.type == 'VIEW_3D'\n\t\t\tand obj_align == 'VIEW'):\n\t\trot = context.space_data.region_3d.view_matrix.to_3x3().inverted().to_4x4()\n\telse:\n\t\trot = Matrix()\n\talign_matrix = loc * rot\n\n\treturn align_matrix\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "main", "data": "def main(context, self, align_matrix):\n\t# deselect all objects\n\tbpy.ops.object.select_all(action='DESELECT')\n\n\t# create object\n\tname = self.Simple_Type\t\t # Type as name\n\n\t# create curve\n\tscene = bpy.context.scene\n\tnewCurve = bpy.data.curves.new(name, type='CURVE')  # curvedatablock\n\tnewSpline = newCurve.splines.new('BEZIER')  # spline\n\n\t# set curveOptions\n\tnewCurve.dimensions = self.shape\n\tnewSpline.use_endpoint_u = True\n\n\tsides = abs(int((self.Simple_endangle - self.Simple_startangle) / 90))\n\n\t# get verts\n\tif self.Simple_Type == 'Point':\n\t\tverts = SimplePoint()\n\t\tnewSpline.use_cyclic_u = False\n\n\tif self.Simple_Type == 'Line':\n\t\tverts = SimpleLine(self.Simple_startlocation, self.Simple_endlocation)\n\t\tnewSpline.use_cyclic_u = False\n\t\tnewCurve.dimensions = '3D'\n\n\tif self.Simple_Type == 'Distance':\n\t\tverts = SimpleDistance(self.Simple_length, self.Simple_center)\n\t\tnewSpline.use_cyclic_u = False\n\n\tif self.Simple_Type == 'Angle':\n\t\tverts = SimpleAngle(self.Simple_length, self.Simple_angle)\n\t\tnewSpline.use_cyclic_u = False\n\n\tif self.Simple_Type == 'Circle':\n\t\tif self.Simple_sides < 4:\n\t\t\tself.Simple_sides = 4\n\t\tverts = SimpleCircle(self.Simple_sides, self.Simple_radius)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Ellipse':\n\t\tverts = SimpleEllipse(self.Simple_a, self.Simple_b)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Arc':\n\t\tif self.Simple_sides < sides:\n\t\t\tself.Simple_sides = sides\n\t\tif self.Simple_radius == 0:\n\t\t\treturn {'FINISHED'}\n\t\tverts = SimpleArc(self.Simple_sides, self.Simple_radius, self.Simple_startangle, self.Simple_endangle)\n\t\tnewSpline.use_cyclic_u = False\n\n\tif self.Simple_Type == 'Sector':\n\t\tif self.Simple_sides < sides:\n\t\t\tself.Simple_sides = sides\n\t\tif self.Simple_radius == 0:\n\t\t\treturn {'FINISHED'}\n\t\tverts = SimpleSector(self.Simple_sides, self.Simple_radius, self.Simple_startangle, self.Simple_endangle)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Segment':\n\t\tif self.Simple_sides < sides:\n\t\t\tself.Simple_sides = sides\n\t\tif self.Simple_a == 0 or self.Simple_b == 0:\n\t\t\treturn {'FINISHED'}\n\t\tverts = SimpleSegment(self.Simple_sides, self.Simple_a, self.Simple_b, self.Simple_startangle, self.Simple_endangle)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Rectangle':\n\t\tverts = SimpleRectangle(self.Simple_width, self.Simple_length, self.Simple_rounded, self.Simple_center)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Rhomb':\n\t\tverts = SimpleRhomb(self.Simple_width, self.Simple_length, self.Simple_center)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Polygon':\n\t\tif self.Simple_sides < 3:\n\t\t\tself.Simple_sides = 3\n\t\tverts = SimplePolygon(self.Simple_sides, self.Simple_radius)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Polygon_ab':\n\t\tif self.Simple_sides < 3:\n\t\t\tself.Simple_sides = 3\n\t\tverts = SimplePolygon_ab(self.Simple_sides, self.Simple_a, self.Simple_b)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Trapezoid':\n\t\tverts = SimpleTrapezoid(self.Simple_a, self.Simple_b, self.Simple_h, self.Simple_center)\n\t\tnewSpline.use_cyclic_u = True\n\n\tvertArray = []\n\tfor v in verts:\n\t\tvertArray += v\n\n\tnewSpline.bezier_points.add(int(len(vertArray) * 0.333333333))\n\tnewSpline.bezier_points.foreach_set('co', vertArray)\n\n\t# create object with newCurve\n\tSimpleCurve = bpy.data.objects.new(name, newCurve)  # object\n\tscene.objects.link(SimpleCurve)  # place in active scene\n\tSimpleCurve.select = True  # set as selected\n\tscene.objects.active = SimpleCurve  # set as active\n\tSimpleCurve.matrix_world = align_matrix  # apply matrix\n\tSimpleCurve.rotation_euler = self.Simple_rotation_euler\n\n\tall_points = [p for p in newSpline.bezier_points]\n\td = 2 * 0.27606262\n\tn = 0\n\tfor p in all_points:\n\t\tp.handle_right_type = 'VECTOR'\n\t\tp.handle_left_type = 'VECTOR'\n\t\tn += 1\n\n\tif self.Simple_Type == 'Circle' or self.Simple_Type == 'Arc' or self.Simple_Type == 'Sector' or self.Simple_Type == 'Segment' or self.Simple_Type == 'Ellipse':\n\t\tfor p in all_points:\n\t\t\tp.handle_right_type = 'FREE'\n\t\t\tp.handle_left_type = 'FREE'\n\n\tif self.Simple_Type == 'Circle':\n\t\ti = 0\n\t\tfor p1 in all_points:\n\t\t\tif i != n - 1:\n\t\t\t\tp2 = all_points[i + 1]\n\t\t\t\tu1 = asin(p1.co.y / self.Simple_radius)\n\t\t\t\tu2 = asin(p2.co.y / self.Simple_radius)\n\t\t\t\tif p1.co.x > 0 and p2.co.x < 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\telif p1.co.x < 0 and p2.co.x > 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\tu = u2 - u1\n\t\t\t\tif u < 0:\n\t\t\t\t\tu = -u\n\t\t\t\tl = 4 / 3 * tan(1 / 4 * u) * self.Simple_radius\n\t\t\t\tv1 = Vector((-p1.co.y, p1.co.x, 0))\n\t\t\t\tv1.normalize()\n\t\t\t\tv2 = Vector((-p2.co.y, p2.co.x, 0))\n\t\t\t\tv2.normalize()\n\t\t\t\tvh1 = v1 * l\n\t\t\t\tvh2 = v2 * l\n\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) + vh1\n\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) - vh2\n\t\t\t\tp1.handle_right = v1\n\t\t\t\tp2.handle_left = v2\n\t\t\tif i == n - 1:\n\t\t\t\tp2 = all_points[0]\n\t\t\t\tu1 = asin(p1.co.y / self.Simple_radius)\n\t\t\t\tu2 = asin(p2.co.y / self.Simple_radius)\n\t\t\t\tif p1.co.x > 0 and p2.co.x < 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\telif p1.co.x < 0 and p2.co.x > 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\tu = u2 - u1\n\t\t\t\tif u < 0:\n\t\t\t\t\tu = -u\n\t\t\t\tl = 4 / 3 * tan(1 / 4 * u) * self.Simple_radius\n\t\t\t\tv1 = Vector((-p1.co.y, p1.co.x, 0))\n\t\t\t\tv1.normalize()\n\t\t\t\tv2 = Vector((-p2.co.y, p2.co.x, 0))\n\t\t\t\tv2.normalize()\n\t\t\t\tvh1 = v1 * l\n\t\t\t\tvh2 = v2 * l\n\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) + vh1\n\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) - vh2\n\t\t\t\tp1.handle_right = v1\n\t\t\t\tp2.handle_left = v2\n\t\t\ti += 1\n\n\tif self.Simple_Type == 'Ellipse':\n\t\tall_points[0].handle_right = Vector((self.Simple_a, self.Simple_b * d, 0))\n\t\tall_points[0].handle_left = Vector((self.Simple_a, -self.Simple_b * d, 0))\n\t\tall_points[1].handle_right = Vector((-self.Simple_a * d, self.Simple_b, 0))\n\t\tall_points[1].handle_left = Vector((self.Simple_a * d, self.Simple_b, 0))\n\t\tall_points[2].handle_right = Vector((-self.Simple_a, -self.Simple_b * d, 0))\n\t\tall_points[2].handle_left = Vector((-self.Simple_a, self.Simple_b * d, 0))\n\t\tall_points[3].handle_right = Vector((self.Simple_a * d, -self.Simple_b, 0))\n\t\tall_points[3].handle_left = Vector((-self.Simple_a * d, -self.Simple_b, 0))\n\n\tif self.Simple_Type == 'Arc':\n\t\ti = 0\n\t\tfor p1 in all_points:\n\t\t\tif i != n - 1:\n\t\t\t\tp2 = all_points[i + 1]\n\t\t\t\tu1 = asin(p1.co.y / self.Simple_radius)\n\t\t\t\tu2 = asin(p2.co.y / self.Simple_radius)\n\t\t\t\tif p1.co.x > 0 and p2.co.x < 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\telif p1.co.x < 0 and p2.co.x > 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\tu = u2 - u1\n\t\t\t\tif u < 0:\n\t\t\t\t\tu = -u\n\t\t\t\tl = 4 / 3 * tan(1 / 4 * u) * self.Simple_radius\n\t\t\t\tv1 = Vector((-p1.co.y, p1.co.x, 0))\n\t\t\t\tv1.normalize()\n\t\t\t\tv2 = Vector((-p2.co.y, p2.co.x, 0))\n\t\t\t\tv2.normalize()\n\t\t\t\tvh1 = v1 * l\n\t\t\t\tvh2 = v2 * l\n\t\t\t\tif self.Simple_startangle < self.Simple_endangle:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) + vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) - vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\t\t\t\telse:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) - vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) + vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\t\t\ti += 1\n\n\tif self.Simple_Type == 'Sector':\n\t\ti = 0\n\t\tfor p1 in all_points:\n\t\t\tif i == 0:\n\t\t\t\tp1.handle_right_type = 'VECTOR'\n\t\t\t\tp1.handle_left_type = 'VECTOR'\n\t\t\telif i != n - 1:\n\t\t\t\tp2 = all_points[i + 1]\n\t\t\t\tu1 = asin(p1.co.y / self.Simple_radius)\n\t\t\t\tu2 = asin(p2.co.y / self.Simple_radius)\n\t\t\t\tif p1.co.x > 0 and p2.co.x < 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\telif p1.co.x < 0 and p2.co.x > 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\tu = u2 - u1\n\t\t\t\tif u < 0:\n\t\t\t\t\tu = -u\n\t\t\t\tl = 4 / 3 * tan(1 / 4 * u) * self.Simple_radius\n\t\t\t\tv1 = Vector((-p1.co.y, p1.co.x, 0))\n\t\t\t\tv1.normalize()\n\t\t\t\tv2 = Vector((-p2.co.y, p2.co.x, 0))\n\t\t\t\tv2.normalize()\n\t\t\t\tvh1 = v1 * l\n\t\t\t\tvh2 = v2 * l\n\t\t\t\tif self.Simple_startangle < self.Simple_endangle:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) + vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) - vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\t\t\t\telse:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) - vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) + vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\t\t\ti += 1\n\n\tif self.Simple_Type == 'Segment':\n\t\ti = 0\n\t\tfor p1 in all_points:\n\t\t\tif i < n / 2 - 1:\n\t\t\t\tp2 = all_points[i + 1]\n\t\t\t\tu1 = asin(p1.co.y / self.Simple_a)\n\t\t\t\tu2 = asin(p2.co.y / self.Simple_a)\n\t\t\t\tif p1.co.x > 0 and p2.co.x < 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_a)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_a)\n\t\t\t\telif p1.co.x < 0 and p2.co.x > 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_a)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_a)\n\t\t\t\tu = u2 - u1\n\t\t\t\tif u < 0:\n\t\t\t\t\tu = -u\n\t\t\t\tl = 4 / 3 * tan(1 / 4 * u) * self.Simple_a\n\t\t\t\tv1 = Vector((-p1.co.y, p1.co.x, 0))\n\t\t\t\tv1.normalize()\n\t\t\t\tv2 = Vector((-p2.co.y, p2.co.x, 0))\n\t\t\t\tv2.normalize()\n\t\t\t\tvh1 = v1 * l\n\t\t\t\tvh2 = v2 * l\n\t\t\t\tif self.Simple_startangle < self.Simple_endangle:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) + vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) - vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\t\t\t\telse:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) - vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) + vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\t\t\telif i != n / 2 - 1 and i != n - 1:\n\t\t\t\tp2 = all_points[i + 1]\n\t\t\t\tu1 = asin(p1.co.y / self.Simple_b)\n\t\t\t\tu2 = asin(p2.co.y / self.Simple_b)\n\t\t\t\tif p1.co.x > 0 and p2.co.x < 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_b)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_b)\n\t\t\t\telif p1.co.x < 0 and p2.co.x > 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_b)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_b)\n\t\t\t\tu = u2 - u1\n\t\t\t\tif u < 0:\n\t\t\t\t\tu = -u\n\t\t\t\tl = 4 / 3 * tan(1 / 4 * u) * self.Simple_b\n\t\t\t\tv1 = Vector((-p1.co.y, p1.co.x, 0))\n\t\t\t\tv1.normalize()\n\t\t\t\tv2 = Vector((-p2.co.y, p2.co.x, 0))\n\t\t\t\tv2.normalize()\n\t\t\t\tvh1 = v1 * l\n\t\t\t\tvh2 = v2 * l\n\t\t\t\tif self.Simple_startangle < self.Simple_endangle:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) - vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) + vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\t\t\t\telse:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) + vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) - vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\n\t\t\ti += 1\n\t\tall_points[0].handle_left_type = 'VECTOR'\n\t\tall_points[n - 1].handle_right_type = 'VECTOR'\n\t\tall_points[int(n / 2) - 1].handle_right_type = 'VECTOR'\n\t\tall_points[int(n / 2)].handle_left_type = 'VECTOR'\n\n\tSimpleCurve.Simple = True\n\tSimpleCurve.Simple_Change = False\n\tSimpleCurve.Simple_Type = self.Simple_Type\n\tSimpleCurve.Simple_startlocation = self.Simple_startlocation\n\tSimpleCurve.Simple_endlocation = self.Simple_endlocation\n\tSimpleCurve.Simple_a = self.Simple_a\n\tSimpleCurve.Simple_b = self.Simple_b\n\tSimpleCurve.Simple_h = self.Simple_h\n\tSimpleCurve.Simple_angle = self.Simple_angle\n\tSimpleCurve.Simple_startangle = self.Simple_startangle\n\tSimpleCurve.Simple_endangle = self.Simple_endangle\n\tSimpleCurve.Simple_rotation_euler = self.Simple_rotation_euler\n\tSimpleCurve.Simple_sides = self.Simple_sides\n\tSimpleCurve.Simple_radius = self.Simple_radius\n\tSimpleCurve.Simple_center = self.Simple_center\n\tSimpleCurve.Simple_width = self.Simple_width\n\tSimpleCurve.Simple_length = self.Simple_length\n\tSimpleCurve.Simple_rounded = self.Simple_rounded\n\n\tbpy.ops.object.mode_set(mode='EDIT', toggle=True)\n\tbpy.ops.curve.select_all(action='SELECT')\n\tbpy.ops.object.mode_set(mode='OBJECT', toggle=True)\n\n\treturn\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleDelete", "data": "def SimpleDelete(name):\n\tif bpy.ops.object.mode_set.poll():\n\t\tbpy.ops.object.mode_set(mode='OBJECT')\n\n\tbpy.context.scene.objects.active = bpy.data.objects[name]\n\tbpy.ops.object.delete()\n\n\treturn\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "class", "name": "Simple", "data": "class Simple(bpy.types.Operator):\n\t''''''\n\tbl_idname = \"curve.simple\"\n\tbl_label = \"Simple curve\"\n\tbl_options = {'REGISTER', 'UNDO'}\n\tbl_description = \"adds simple curve\"\n\n\t# align_matrix for the invoke\n\talign_matrix = Matrix()\n\n\t# change properties\n\tSimple = BoolProperty(name=\"Simple\",\n\t\t\t\t\t\t  default=True,\n\t\t\t\t\t\t  description=\"simple curve\")\n\n\tSimple_Change = BoolProperty(name=\"Change\",\n\t\t\t\t\t\t\t\t default=False,\n\t\t\t\t\t\t\t\t description=\"change simple curve\")\n\n\tSimple_Delete = StringProperty(name=\"Delete\",\n\t\t\t\t\t\t\t\t   description=\"Delete simple curve\")\n\n\t# general properties\n\tTypes = [('Point', 'Point', 'Point'),\n\t\t\t ('Line', 'Line', 'Line'),\n\t\t\t ('Distance', 'Distance', 'Distance'),\n\t\t\t ('Angle', 'Angle', 'Angle'),\n\t\t\t ('Circle', 'Circle', 'Circle'),\n\t\t\t ('Ellipse', 'Ellipse', 'Ellipse'),\n\t\t\t ('Arc', 'Arc', 'Arc'),\n\t\t\t ('Sector', 'Sector', 'Sector'),\n\t\t\t ('Segment', 'Segment', 'Segment'),\n\t\t\t ('Rectangle', 'Rectangle', 'Rectangle'),\n\t\t\t ('Rhomb', 'Rhomb', 'Rhomb'),\n\t\t\t ('Polygon', 'Polygon', 'Polygon'),\n\t\t\t ('Polygon_ab', 'Polygon_ab', 'Polygon_ab'),\n\t\t\t ('Trapezoid', 'Trapezoid', 'Trapezoid')]\n\tSimple_Type = EnumProperty(name=\"Type\",\n\t\t\t\t\t\t\t   description=\"Form of Curve to create\",\n\t\t\t\t\t\t\t   items=Types)\n\n\t# Line properties\n\tSimple_startlocation = FloatVectorProperty(name=\"\",\n\t\t\t\t\t\t\t\t\t\t\t   description=\"Start location\",\n\t\t\t\t\t\t\t\t\t\t\t   default=(0.0, 0.0, 0.0),\n\t\t\t\t\t\t\t\t\t\t\t   subtype='TRANSLATION')\n\tSimple_endlocation = FloatVectorProperty(name=\"\",\n\t\t\t\t\t\t\t\t\t\t\t description=\"End location\",\n\t\t\t\t\t\t\t\t\t\t\t default=(2.0, 2.0, 2.0),\n\t\t\t\t\t\t\t\t\t\t\t subtype='TRANSLATION')\n\tSimple_rotation_euler = FloatVectorProperty(name=\"\",\n\t\t\t\t\t\t\t\t\t\t\t\tdescription=\"Rotation\",\n\t\t\t\t\t\t\t\t\t\t\t\tdefault=(0.0, 0.0, 0.0),\n\t\t\t\t\t\t\t\t\t\t\t\tsubtype='EULER')\n\n\t# Trapezoid properties\n\tSimple_a = FloatProperty(name=\"a\",\n\t\t\t\t\t\t\t default=2.0,\n\t\t\t\t\t\t\t min=0.0, soft_min=0.0,\n\t\t\t\t\t\t\t unit='LENGTH',\n\t\t\t\t\t\t\t description=\"a\")\n\tSimple_b = FloatProperty(name=\"b\",\n\t\t\t\t\t\t\t default=1.0,\n\t\t\t\t\t\t\t min=0.0, soft_min=0.0,\n\t\t\t\t\t\t\t unit='LENGTH',\n\t\t\t\t\t\t\t description=\"b\")\n\tSimple_h = FloatProperty(name=\"h\",\n\t\t\t\t\t\t\t default=1.0,\n\t\t\t\t\t\t\t unit='LENGTH',\n\t\t\t\t\t\t\t description=\"h\")\n\n\tSimple_angle = FloatProperty(name=\"Angle\",\n\t\t\t\t\t\t\t\t default=45.0,\n\t\t\t\t\t\t\t\t description=\"Angle\")\n\tSimple_startangle = FloatProperty(name=\"Start angle\",\n\t\t\t\t\t\t\t\t\t  default=0.0,\n\t\t\t\t\t\t\t\t\t  min=-360.0, soft_min=-360.0,\n\t\t\t\t\t\t\t\t\t  max=360.0, soft_max=360.0,\n\t\t\t\t\t\t\t\t\t  description=\"Start angle\")\n\tSimple_endangle = FloatProperty(name=\"End angle\",\n\t\t\t\t\t\t\t\t\tdefault=45.0,\n\t\t\t\t\t\t\t\t\tmin=-360.0, soft_min=-360.0,\n\t\t\t\t\t\t\t\t\tmax=360.0, soft_max=360.0,\n\t\t\t\t\t\t\t\t\tdescription=\"End angle\")\n\n\tSimple_sides = IntProperty(name=\"sides\",\n\t\t\t\t\t\t\t   default=3,\n\t\t\t\t\t\t\t   min=0, soft_min=0,\n\t\t\t\t\t\t\t   description=\"sides\")\n\n\tSimple_radius = FloatProperty(name=\"radius\",\n\t\t\t\t\t\t\t\t  default=1.0,\n\t\t\t\t\t\t\t\t  min=0.0, soft_min=0.0,\n\t\t\t\t\t\t\t\t  unit='LENGTH',\n\t\t\t\t\t\t\t\t  description=\"radius\")\n\n\tSimple_center = BoolProperty(name=\"Length center\",\n\t\t\t\t\t\t\t\t default=True,\n\t\t\t\t\t\t\t\t description=\"Length center\")\n\n\tAngle_types = [('Degrees', 'Degrees', 'Degrees'),\n\t\t\t\t   ('Radians', 'Radians', 'Radians')]\n\tSimple_degrees_or_radians = EnumProperty(name=\"Degrees or radians\",\n\t\t\t\t\t\t\t\t\t\t\t description=\"Degrees or radians\",\n\t\t\t\t\t\t\t\t\t\t\t items=Angle_types)\n\n\t# Rectangle properties\n\tSimple_width = FloatProperty(name=\"Width\",\n\t\t\t\t\t\t\t\t default=2.0,\n\t\t\t\t\t\t\t\t min=0.0, soft_min=0,\n\t\t\t\t\t\t\t\t unit='LENGTH',\n\t\t\t\t\t\t\t\t description=\"Width\")\n\tSimple_length = FloatProperty(name=\"Length\",\n\t\t\t\t\t\t\t\t  default=2.0,\n\t\t\t\t\t\t\t\t  min=0.0, soft_min=0.0,\n\t\t\t\t\t\t\t\t  unit='LENGTH',\n\t\t\t\t\t\t\t\t  description=\"Length\")\n\tSimple_rounded = FloatProperty(name=\"Rounded\",\n\t\t\t\t\t\t\t\t   default=0.0,\n\t\t\t\t\t\t\t\t   min=0.0, soft_min=0.0,\n\t\t\t\t\t\t\t\t   unit='LENGTH',\n\t\t\t\t\t\t\t\t   description=\"Rounded\")\n\n\t# Curve Options\n\tshapeItems = [\n\t\t('2D', '2D', '2D'),\n\t\t('3D', '3D', '3D')]\n\tshape = EnumProperty(name=\"2D / 3D\",\n\t\t\t\t\t\t items=shapeItems,\n\t\t\t\t\t\t description=\"2D or 3D Curve\")\n\n\t##### DRAW #####\n\tdef draw(self, context):\n\t\tlayout = self.layout\n\n\t\t# general options\n\t\tcol = layout.column()\n\t\tcol.prop(self, 'Simple_Type')\n\n\t\tl = 0\n\t\ts = 0\n\n\t\tif self.Simple_Type == 'Line':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_endlocation')\n\t\t\tv = Vector(self.Simple_endlocation) - Vector(self.Simple_startlocation)\n\t\t\tl = v.length\n\n\t\tif self.Simple_Type == 'Distance':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_length')\n\t\t\tbox.prop(self, 'Simple_center')\n\t\t\tl = self.Simple_length\n\n\t\tif self.Simple_Type == 'Angle':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_length')\n\t\t\tbox.prop(self, 'Simple_angle')\n\t\t\trow = layout.row()\n\t\t\trow.prop(self, 'Simple_degrees_or_radians', expand=True)\n\n\t\tif self.Simple_Type == 'Circle':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_sides')\n\t\t\tbox.prop(self, 'Simple_radius')\n\t\t\tl = 2 * pi * abs(self.Simple_radius)\n\t\t\ts = pi * self.Simple_radius * self.Simple_radius\n\n\t\tif self.Simple_Type == 'Ellipse':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_a')\n\t\t\tbox.prop(self, 'Simple_b')\n\t\t\tl = pi * (3 * (self.Simple_a + self.Simple_b) - sqrt((3 * self.Simple_a + self.Simple_b) * (self.Simple_a + 3 * self.Simple_b)))\n\t\t\ts = pi * abs(self.Simple_b) * abs(self.Simple_a)\n\n\t\tif self.Simple_Type == 'Arc':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_sides')\n\t\t\tbox.prop(self, 'Simple_radius')\n\t\t\tbox.prop(self, 'Simple_startangle')\n\t\t\tbox.prop(self, 'Simple_endangle')\n\t\t\trow = layout.row()\n\t\t\trow.prop(self, 'Simple_degrees_or_radians', expand=True)\n\t\t\tl = abs(pi * self.Simple_radius * (self.Simple_endangle - self.Simple_startangle) / 180)\n\n\t\tif self.Simple_Type == 'Sector':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_sides')\n\t\t\tbox.prop(self, 'Simple_radius')\n\t\t\tbox.prop(self, 'Simple_startangle')\n\t\t\tbox.prop(self, 'Simple_endangle')\n\t\t\trow = layout.row()\n\t\t\trow.prop(self, 'Simple_degrees_or_radians', expand=True)\n\t\t\tl = abs(pi * self.Simple_radius * (self.Simple_endangle - self.Simple_startangle) / 180) + self.Simple_radius * 2\n\t\t\ts = pi * self.Simple_radius * self.Simple_radius * abs(self.Simple_endangle - self.Simple_startangle) / 360\n\n\t\tif self.Simple_Type == 'Segment':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_sides')\n\t\t\tbox.prop(self, 'Simple_a')\n\t\t\tbox.prop(self, 'Simple_b')\n\t\t\tbox.prop(self, 'Simple_startangle')\n\t\t\tbox.prop(self, 'Simple_endangle')\n\t\t\trow = layout.row()\n\t\t\trow.prop(self, 'Simple_degrees_or_radians', expand=True)\n\t\t\tla = abs(pi * self.Simple_a * (self.Simple_endangle - self.Simple_startangle) / 180)\n\t\t\tlb = abs(pi * self.Simple_b * (self.Simple_endangle - self.Simple_startangle) / 180)\n\t\t\tl = abs(self.Simple_a - self.Simple_b) * 2 + la + lb\n\t\t\tsa = pi * self.Simple_a * self.Simple_a * abs(self.Simple_endangle - self.Simple_startangle) / 360\n\t\t\tsb = pi * self.Simple_b * self.Simple_b * abs(self.Simple_endangle - self.Simple_startangle) / 360\n\t\t\ts = abs(sa - sb)\n\n\t\tif self.Simple_Type == 'Rectangle':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_width')\n\t\t\tbox.prop(self, 'Simple_length')\n\t\t\tbox.prop(self, 'Simple_rounded')\n\t\t\tbox.prop(self, 'Simple_center')\n\t\t\tl = 2 * abs(self.Simple_width) + 2 * abs(self.Simple_length)\n\t\t\ts = abs(self.Simple_width) * abs(self.Simple_length)\n\n\t\tif self.Simple_Type == 'Rhomb':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_width')\n\t\t\tbox.prop(self, 'Simple_length')\n\t\t\tbox.prop(self, 'Simple_center')\n\t\t\tg = hypot(self.Simple_width / 2, self.Simple_length / 2)\n\t\t\tl = 4 * g\n\t\t\ts = self.Simple_width * self.Simple_length / 2\n\n\t\tif self.Simple_Type == 'Polygon':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_sides')\n\t\t\tbox.prop(self, 'Simple_radius')\n\n\t\tif self.Simple_Type == 'Polygon_ab':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_sides')\n\t\t\tbox.prop(self, 'Simple_a')\n\t\t\tbox.prop(self, 'Simple_b')\n\n\t\tif self.Simple_Type == 'Trapezoid':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_a')\n\t\t\tbox.prop(self, 'Simple_b')\n\t\t\tbox.prop(self, 'Simple_h')\n\t\t\tbox.prop(self, 'Simple_center')\n\t\t\tg = hypot(self.Simple_h, (self.Simple_a - self.Simple_b) / 2)\n\t\t\tl = self.Simple_a + self.Simple_b + g * 2\n\t\t\ts = (abs(self.Simple_a) + abs(self.Simple_b)) / 2 * self.Simple_h\n\n\t\trow = layout.row()\n\t\trow.prop(self, 'shape', expand=True)\n\t\tbox = layout.box()\n\t\tbox.label(\"Location:\")\n\t\tbox.prop(self, 'Simple_startlocation')\n\t\tbox = layout.box()\n\t\tbox.label(\"Rotation:\")\n\t\tbox.prop(self, 'Simple_rotation_euler')\n\t\tif l != 0:\n\t\t\tl_str = str(round(l, 4))\n\t\t\trow = layout.row()\n\t\t\trow.label(\"Length: \" + l_str)\n\t\tif s != 0:\n\t\t\ts_str = str(round(s, 4))\n\t\t\trow = layout.row()\n\t\t\trow.label(\"Area: \" + s_str)\n\n\t##### POLL #####\n\t@classmethod\n\tdef poll(cls, context):\n\t\treturn context.scene != None\n\n\t##### EXECUTE #####\n\tdef execute(self, context):\n\t\tif self.Simple_Change:\n\t\t\tSimpleDelete(self.Simple_Delete)\n\n\t\t# go to object mode\n\t\tif bpy.ops.object.mode_set.poll():\n\t\t\tbpy.ops.object.mode_set(mode='OBJECT')\n\n\t\t# turn off undo\n\t\tundo = bpy.context.user_preferences.edit.use_global_undo\n\t\tbpy.context.user_preferences.edit.use_global_undo = False\n\n\t\t# main function\n\t\tself.align_matrix = align_matrix(context, self.Simple_startlocation)\n\t\tmain(context, self, self.align_matrix)\n\n\t\t# restore pre operator undo state\n\t\tbpy.context.user_preferences.edit.use_global_undo = undo\n\n\t\treturn {'FINISHED'}\n\n\t##### INVOKE #####\n\tdef invoke(self, context, event):\n\t\t# store creation_matrix\n\t\tif self.Simple_Change:\n\t\t\tbpy.context.scene.cursor_location = self.Simple_startlocation\n\t\telse:\n\t\t\tself.Simple_startlocation = bpy.context.scene.cursor_location\n\n\t\tself.align_matrix = align_matrix(context, self.Simple_startlocation)\n\t\tself.execute(context)\n\n\t\treturn {'FINISHED'}\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "class", "name": "BezierPointsFillet", "data": "class BezierPointsFillet(bpy.types.Operator):\n\t''''''\n\tbl_idname = \"curve.bezier_points_fillet\"\n\tbl_label = \"Bezier points fillet\"\n\tbl_options = {'REGISTER', 'UNDO'}\n\tbl_description = \"bezier points fillet\"\n\n\tFillet_radius = FloatProperty(name=\"Radius\",\n\t\t\t\t\t\t\t\t  default=0.25,\n\t\t\t\t\t\t\t\t  unit='LENGTH',\n\t\t\t\t\t\t\t\t  description=\"radius\")\n\n\tTypes = [('Round', 'Round', 'Round'),\n\t\t\t ('Chamfer', 'Chamfer', 'Chamfer')]\n\tFillet_Type = EnumProperty(name=\"Type\",\n\t\t\t\t\t\t\t   description=\"Fillet type\",\n\t\t\t\t\t\t\t   items=Types)\n\n\t##### DRAW #####\n\tdef draw(self, context):\n\t\tlayout = self.layout\n\n\t\t# general options\n\t\tcol = layout.column()\n\t\tcol.prop(self, 'Fillet_radius')\n\t\tcol.prop(self, 'Fillet_Type', expand=True)\n\n\t##### POLL #####\n\t@classmethod\n\tdef poll(cls, context):\n\t\treturn context.scene != None\n\n\t##### EXECUTE #####\n\tdef execute(self, context):\n\t\t# go to object mode\n\t\tif bpy.ops.object.mode_set.poll():\n\t\t\tbpy.ops.object.mode_set(mode='OBJECT')\n\t\t\tbpy.ops.object.mode_set(mode='EDIT')\n\n\t\t# turn off undo\n\t\tundo = bpy.context.user_preferences.edit.use_global_undo\n\t\tbpy.context.user_preferences.edit.use_global_undo = False\n\n\t\t# main function\n\t\tspline = bpy.context.object.data.splines.active\n\t\tselected = [p for p in spline.bezier_points if p.select_control_point]\n\n\t\tbpy.ops.curve.handle_type_set(type='VECTOR')\n\t\tn = 0\n\t\tii = []\n\t\tfor p in spline.bezier_points:\n\t\t\tif p.select_control_point:\n\t\t\t\tii.append(n)\n\t\t\t\tn += 1\n\t\t\telse:\n\t\t\t\tn += 1\n\n\t\tif n > 2:\n\n\t\t\tjn = 0\n\n\t\t\tfor j in ii:\n\n\t\t\t\tj += jn\n\n\t\t\t\tselected_all = [p for p in spline.bezier_points]\n\n\t\t\t\tbpy.ops.curve.select_all(action='DESELECT')\n\n\t\t\t\tif j != 0 and j != n - 1:\n\t\t\t\t\tselected_all[j].select_control_point = True\n\t\t\t\t\tselected_all[j + 1].select_control_point = True\n\t\t\t\t\tbpy.ops.curve.subdivide()\n\t\t\t\t\tselected_all = [p for p in spline.bezier_points]\n\t\t\t\t\tselected4 = [selected_all[j - 1], selected_all[j], selected_all[j + 1], selected_all[j + 2]]\n\t\t\t\t\tjn += 1\n\t\t\t\t\tn += 1\n\n\t\t\t\telif j == 0:\n\t\t\t\t\tselected_all[j].select_control_point = True\n\t\t\t\t\tselected_all[j + 1].select_control_point = True\n\t\t\t\t\tbpy.ops.curve.subdivide()\n\t\t\t\t\tselected_all = [p for p in spline.bezier_points]\n\t\t\t\t\tselected4 = [selected_all[n], selected_all[0], selected_all[1], selected_all[2]]\n\t\t\t\t\tjn += 1\n\t\t\t\t\tn += 1\n\n\t\t\t\telif j == n - 1:\n\t\t\t\t\tselected_all[j].select_control_point = True\n\t\t\t\t\tselected_all[j - 1].select_control_point = True\n\t\t\t\t\tbpy.ops.curve.subdivide()\n\t\t\t\t\tselected_all = [p for p in spline.bezier_points]\n\t\t\t\t\tselected4 = [selected_all[0], selected_all[n], selected_all[n - 1], selected_all[n - 2]]\n\n\t\t\t\tselected4[2].co = selected4[1].co\n\t\t\t\ts1 = Vector(selected4[0].co) - Vector(selected4[1].co)\n\t\t\t\ts2 = Vector(selected4[3].co) - Vector(selected4[2].co)\n\t\t\t\ts1.normalize()\n\t\t\t\ts11 = Vector(selected4[1].co) + s1 * self.Fillet_radius\n\t\t\t\tselected4[1].co = s11\n\t\t\t\ts2.normalize()\n\t\t\t\ts22 = Vector(selected4[2].co) + s2 * self.Fillet_radius\n\t\t\t\tselected4[2].co = s22\n\n\t\t\t\tif self.Fillet_Type == 'Round':\n\t\t\t\t\tif j != n - 1:\n\t\t\t\t\t\tselected4[2].handle_right_type = 'VECTOR'\n\t\t\t\t\t\tselected4[1].handle_left_type = 'VECTOR'\n\t\t\t\t\t\tselected4[1].handle_right_type = 'ALIGNED'\n\t\t\t\t\t\tselected4[2].handle_left_type = 'ALIGNED'\n\t\t\t\t\telse:\n\t\t\t\t\t\tselected4[1].handle_right_type = 'VECTOR'\n\t\t\t\t\t\tselected4[2].handle_left_type = 'VECTOR'\n\t\t\t\t\t\tselected4[2].handle_right_type = 'ALIGNED'\n\t\t\t\t\t\tselected4[1].handle_left_type = 'ALIGNED'\n\t\t\t\tif self.Fillet_Type == 'Chamfer':\n\t\t\t\t\tselected4[2].handle_right_type = 'VECTOR'\n\t\t\t\t\tselected4[1].handle_left_type = 'VECTOR'\n\t\t\t\t\tselected4[1].handle_right_type = 'VECTOR'\n\t\t\t\t\tselected4[2].handle_left_type = 'VECTOR'\n\n\t\tbpy.ops.curve.select_all(action='SELECT')\n\t\tbpy.ops.curve.spline_type_set(type='BEZIER')\n\n\t\t# restore pre operator undo state\n\t\tbpy.context.user_preferences.edit.use_global_undo = undo\n\n\t\treturn {'FINISHED'}\n\n\t##### INVOKE #####\n\tdef invoke(self, context, event):\n\t\tself.execute(context)\n\n\t\treturn {'FINISHED'}\n\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "subdivide_cubic_bezier", "data": "def subdivide_cubic_bezier(p1, p2, p3, p4, t):\n\tp12 = (p2 - p1) * t + p1\n\tp23 = (p3 - p2) * t + p2\n\tp34 = (p4 - p3) * t + p3\n\tp123 = (p23 - p12) * t + p12\n\tp234 = (p34 - p23) * t + p23\n\tp1234 = (p234 - p123) * t + p123\n\treturn [p12, p123, p1234, p234, p34]\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "class", "name": "BezierDivide", "data": "class BezierDivide(bpy.types.Operator):\n\t''''''\n\tbl_idname = \"curve.bezier_spline_divide\"\n\tbl_label = \"Bezier Divide (enters edit mode) for Fillet Curves\"\n\tbl_options = {'REGISTER', 'UNDO'}\n\tbl_description = \"bezier spline divide\"\n\n\t# align_matrix for the invoke\n\talign_matrix = Matrix()\n\n\tBezier_t = FloatProperty(name=\"t (0% - 100%)\",\n\t\t\t\t\t\t\t default=50.0,\n\t\t\t\t\t\t\t min=0.0, soft_min=0.0,\n\t\t\t\t\t\t\t max=100.0, soft_max=100.0,\n\t\t\t\t\t\t\t description=\"t (0% - 100%)\")\n\n\t##### POLL #####\n\t@classmethod\n\tdef poll(cls, context):\n\t\treturn context.scene != None\n\n\t##### EXECUTE #####\n\tdef execute(self, context):\n\t\t# go to object mode\n\t\tif bpy.ops.object.mode_set.poll():\n\t\t\tbpy.ops.object.mode_set(mode='OBJECT')\n\t\t\tbpy.ops.object.mode_set(mode='EDIT')\n\n\t\t# turn off undo\n\t\tundo = bpy.context.user_preferences.edit.use_global_undo\n\t\tbpy.context.user_preferences.edit.use_global_undo = False\n\n\t\t# main function\n\t\tspline = bpy.context.object.data.splines.active\n\t\tvertex = []\n\t\tselected_all = [p for p in spline.bezier_points if p.select_control_point]\n\t\th = subdivide_cubic_bezier(selected_all[0].co, selected_all[0].handle_right, selected_all[1].handle_left, selected_all[1].co, self.Bezier_t / 100)\n\n\t\tselected_all[0].handle_right_type = 'FREE'\n\t\tselected_all[0].handle_left_type = 'FREE'\n\t\tselected_all[1].handle_right_type = 'FREE'\n\t\tselected_all[1].handle_left_type = 'FREE'\n\t\tbpy.ops.curve.subdivide(1)\n\t\tselected_all = [p for p in spline.bezier_points if p.select_control_point]\n\n\t\tselected_all[0].handle_right = h[0]\n\t\tselected_all[1].co = h[2]\n\t\tselected_all[1].handle_left = h[1]\n\t\tselected_all[1].handle_right = h[3]\n\t\tselected_all[2].handle_left = h[4]\n\n\t\t# restore pre operator undo state\n\t\tbpy.context.user_preferences.edit.use_global_undo = undo\n\n\t\treturn {'FINISHED'}\n\n\t##### INVOKE #####\n\tdef invoke(self, context, event):\n\t\tself.execute(context)\n\n\t\treturn {'FINISHED'}\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "class", "name": "SimplePanel", "data": "class SimplePanel(bpy.types.Panel):\n\n\tbl_label = \"Simple change\"\n\tbl_space_type = \"VIEW_3D\"\n\tbl_region_type = \"TOOLS\"\n\tbl_options = {'DEFAULT_CLOSED'}\n\tbl_category = \"Tools\"\n\n\t##### POLL #####\n\t@classmethod\n\tdef poll(cls, context):\n\t\tif context.object.Simple == True:\n\t\t\treturn (context.object)\n\n\t##### DRAW #####\n\tdef draw(self, context):\n\t\tif context.object.Simple == True:\n\t\t\tlayout = self.layout\n\n\t\t\tobj = context.object\n\t\t\trow = layout.row()\n\t\t\tsimple_change = row.operator(\"curve.simple\", text='Change')\n\t\t\tsimple_change.Simple_Change = True\n\t\t\tsimple_change.Simple_Delete = obj.name\n\t\t\tsimple_change.Simple_Type = obj.Simple_Type\n\t\t\tsimple_change.Simple_startlocation = obj.location\n\t\t\tsimple_change.Simple_endlocation = obj.Simple_endlocation\n\t\t\tsimple_change.Simple_a = obj.Simple_a\n\t\t\tsimple_change.Simple_b = obj.Simple_b\n\t\t\tsimple_change.Simple_h = obj.Simple_h\n\t\t\tsimple_change.Simple_angle = obj.Simple_angle\n\t\t\tsimple_change.Simple_startangle = obj.Simple_startangle\n\t\t\tsimple_change.Simple_endangle = obj.Simple_endangle\n\t\t\tsimple_change.Simple_rotation_euler = obj.rotation_euler\n\t\t\tsimple_change.Simple_sides = obj.Simple_sides\n\t\t\tsimple_change.Simple_radius = obj.Simple_radius\n\t\t\tsimple_change.Simple_center = obj.Simple_center\n\t\t\tsimple_change.Simple_width = obj.Simple_width\n\t\t\tsimple_change.Simple_length = obj.Simple_length\n\t\t\tsimple_change.Simple_rounded = obj.Simple_rounded\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "class", "name": "SimpleEdit", "data": "class SimpleEdit(bpy.types.Operator):\n\n\t\"\"\"Curve Simple\"\"\"\n\tbl_idname = \"object._simple_edit\"\n\tbl_label = \"Create Curves\"\n\tbl_options = {'REGISTER', 'UNDO'}\n\tbl_description = \"Subdivide & Fillet Curves\"\n\n\t##### POLL #####\n\t@classmethod\n\tdef poll(cls, context):\n\t\tvertex = []\n\t\tnselected = []\n\t\tn = 0\n\t\tobj = context.active_object\n\t\tif obj != None:\n\t\t\tif obj.type == 'CURVE':\n\t\t\t\tfor i in obj.data.splines:\n\t\t\t\t\tfor j in i.bezier_points:\n\t\t\t\t\t\tn += 1\n\t\t\t\t\t\tif j.select_control_point:\n\t\t\t\t\t\t\tnselected.append(n)\n\t\t\t\t\t\t\tvertex.append(obj.matrix_world * j.co)\n\n\t\t\tif len(vertex) > 0 and n > 2:\n\t\t\t\treturn (context.active_object)\n\t\t\tif len(vertex) == 2 and abs(nselected[0] - nselected[1]) == 1:\n\t\t\t\treturn (context.active_object)\n\n\t\tselected = 0\n\t\tfor obj in context.selected_objects:\n\t\t\tif obj.type == 'CURVE':\n\t\t\t\tselected += 1\n\n\t\tif selected >= 2:\n\t\t\treturn (context.selected_objects)\n\n\t##### DRAW #####\n\tdef draw(self, context):\n\t\tvertex = []\n\t\tselected = []\n\t\tn = 0\n\t\tobj = context.active_object\n\t\tif obj != None:\n\t\t\tif obj.type == 'CURVE':\n\t\t\t\tfor i in obj.data.splines:\n\t\t\t\t\tfor j in i.bezier_points:\n\t\t\t\t\t\tn += 1\n\t\t\t\t\t\tif j.select_control_point:\n\t\t\t\t\t\t\tselected.append(n)\n\t\t\t\t\t\t\tvertex.append(obj.matrix_world * j.co)\n\n\t\t\tif len(vertex) > 0 and n > 2:\n\t\t\t\tlayout = self.layout\n\t\t\t\trow = layout.row()\n\t\t\t\tsimple_edit = row.operator(\"curve.bezier_points_fillet\", text='Fillet')\n\t\t\tif len(vertex) == 2 and abs(selected[0] - selected[1]) == 1:\n\t\t\t\tlayout = self.layout\n\t\t\t\trow = layout.row()\n\t\t\t\tsimple_divide = row.operator(\"curve.bezier_spline_divide\", text='Divide')\n", "description": "Curve Simple", "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "StartLocationUpdate", "data": "def StartLocationUpdate(self, context):\n\n\tbpy.context.scene.cursor_location = self.Simple_startlocation\n\n\treturn\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleVariables", "data": "def SimpleVariables():\n\n\tbpy.types.Object.Simple = bpy.props.BoolProperty()\n\tbpy.types.Object.Simple_Change = bpy.props.BoolProperty()\n\t# general properties\n\tTypes = [('Point', 'Point', 'Point'),\n\t\t\t ('Line', 'Line', 'Line'),\n\t\t\t ('Distance', 'Distance', 'Distance'),\n\t\t\t ('Angle', 'Angle', 'Angle'),\n\t\t\t ('Circle', 'Circle', 'Circle'),\n\t\t\t ('Ellipse', 'Ellipse', 'Ellipse'),\n\t\t\t ('Arc', 'Arc', 'Arc'),\n\t\t\t ('Sector', 'Sector', 'Sector'),\n\t\t\t ('Segment', 'Segment', 'Segment'),\n\t\t\t ('Rectangle', 'Rectangle', 'Rectangle'),\n\t\t\t ('Rhomb', 'Rhomb', 'Rhomb'),\n\t\t\t ('Polygon', 'Polygon', 'Polygon'),\n\t\t\t ('Polygon_ab', 'Polygon_ab', 'Polygon_ab'),\n\t\t\t ('Trapezoid', 'Trapezoid', 'Trapezoid')]\n\tbpy.types.Object.Simple_Type = bpy.props.EnumProperty(name=\"Type\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t  description=\"Form of Curve to create\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t  items=Types)\n\n\t# Line properties\n\tbpy.types.Object.Simple_startlocation = bpy.props.FloatVectorProperty(name=\"Start location\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  description=\"Start location\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  default=(0.0, 0.0, 0.0),\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  subtype='TRANSLATION',\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  update=StartLocationUpdate)\n\tbpy.types.Object.Simple_endlocation = bpy.props.FloatVectorProperty(name=\"End location\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdescription=\"End location\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdefault=(2.0, 2.0, 2.0),\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tsubtype='TRANSLATION')\n\tbpy.types.Object.Simple_rotation_euler = bpy.props.FloatVectorProperty(name=\"Rotation\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   description=\"Rotation\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   default=(0.0, 0.0, 0.0),\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   subtype='EULER')\n\n\t# Trapezoid properties\n\tbpy.types.Object.Simple_a = bpy.props.FloatProperty(name=\"a\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tdefault=2.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tmin=0.0, soft_min=0.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tunit='LENGTH',\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tdescription=\"a\")\n\tbpy.types.Object.Simple_b = bpy.props.FloatProperty(name=\"b\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tdefault=1.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tmin=0.0, soft_min=0.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tunit='LENGTH',\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tdescription=\"b\")\n\tbpy.types.Object.Simple_h = bpy.props.FloatProperty(name=\"h\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tdefault=1.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tunit='LENGTH',\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tdescription=\"h\")\n\n\tbpy.types.Object.Simple_angle = bpy.props.FloatProperty(name=\"Angle\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdefault=45.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdescription=\"Angle\")\n\tbpy.types.Object.Simple_startangle = bpy.props.FloatProperty(name=\"Start angle\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t default=0.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t min=-360.0, soft_min=-360.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t max=360.0, soft_max=360.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t description=\"Start angle\")\n\tbpy.types.Object.Simple_endangle = bpy.props.FloatProperty(name=\"End angle\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   default=45.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   min=-360.0, soft_min=-360.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   max=360.0, soft_max=360.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   description=\"End angle\")\n\n\tbpy.types.Object.Simple_sides = bpy.props.IntProperty(name=\"sides\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t  default=3,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t  min=3, soft_min=3,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t  description=\"sides\")\n\n\tbpy.types.Object.Simple_radius = bpy.props.FloatProperty(name=\"radius\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t default=1.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t min=0.0, soft_min=0.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t unit='LENGTH',\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t description=\"radius\")\n\n\tbpy.types.Object.Simple_center = bpy.props.BoolProperty(name=\"Length center\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdefault=True,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdescription=\"Length center\")\n\n\t# Rectangle properties\n\tbpy.types.Object.Simple_width = bpy.props.FloatProperty(name=\"Width\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdefault=2.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tmin=0.0, soft_min=0.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tunit='LENGTH',\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdescription=\"Width\")\n\tbpy.types.Object.Simple_length = bpy.props.FloatProperty(name=\"Length\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t default=2.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t min=0.0, soft_min=0.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t unit='LENGTH',\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t description=\"Length\")\n\tbpy.types.Object.Simple_rounded = bpy.props.FloatProperty(name=\"Rounded\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  default=0.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  unit='LENGTH',\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  description=\"Rounded\")\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "class", "name": "INFO_MT_simple_menu", "data": "class INFO_MT_simple_menu(bpy.types.Menu):\n\t# Define the \"Extras\" menu\n\tbl_idname = \"INFO_MT_simple_menu\"\n\tbl_label = \"Curve Objects\"\n\n\tdef draw(self, context):\n\t\tself.layout.operator_context = 'INVOKE_REGION_WIN'\n\n\t\toper2 = self.layout.operator(Simple.bl_idname, text=\"Point\", icon=\"PLUGIN\")\n\t\toper2.Simple_Change = False\n\t\toper2.Simple_Type = \"Point\"\n\n\t\toper3 = self.layout.operator(Simple.bl_idname, text=\"Line\", icon=\"PLUGIN\")\n\t\toper3.Simple_Change = False\n\t\toper3.Simple_Type = \"Line\"\n\n\t\toper4 = self.layout.operator(Simple.bl_idname, text=\"Distance\", icon=\"PLUGIN\")\n\t\toper4.Simple_Change = False\n\t\toper4.Simple_Type = \"Distance\"\n\n\t\toper5 = self.layout.operator(Simple.bl_idname, text=\"Angle\", icon=\"PLUGIN\")\n\t\toper5.Simple_Change = False\n\t\toper5.Simple_Type = \"Angle\"\n\n\t\toper6 = self.layout.operator(Simple.bl_idname, text=\"Circle\", icon=\"PLUGIN\")\n\t\toper6.Simple_Change = False\n\t\toper6.Simple_Type = \"Circle\"\n\n\t\toper7 = self.layout.operator(Simple.bl_idname, text=\"Ellipse\", icon=\"PLUGIN\")\n\t\toper7.Simple_Change = False\n\t\toper7.Simple_Type = \"Ellipse\"\n\n\t\toper8 = self.layout.operator(Simple.bl_idname, text=\"Arc\", icon=\"PLUGIN\")\n\t\toper8.Simple_Change = False\n\t\toper8.Simple_Type = \"Arc\"\n\n\t\toper9 = self.layout.operator(Simple.bl_idname, text=\"Sector\", icon=\"PLUGIN\")\n\t\toper9.Simple_Change = False\n\t\toper9.Simple_Type = \"Sector\"\n\n\t\toper10 = self.layout.operator(Simple.bl_idname, text=\"Segment\", icon=\"PLUGIN\")\n\t\toper10.Simple_Change = False\n\t\toper10.Simple_Type = \"Segment\"\n\n\t\toper11 = self.layout.operator(Simple.bl_idname, text=\"Rectangle\", icon=\"PLUGIN\")\n\t\toper11.Simple_Change = False\n\t\toper11.Simple_Type = \"Rectangle\"\n\n\t\toper12 = self.layout.operator(Simple.bl_idname, text=\"Rhomb\", icon=\"PLUGIN\")\n\t\toper12.Simple_Change = False\n\t\toper12.Simple_Type = \"Rhomb\"\n\n\t\toper13 = self.layout.operator(Simple.bl_idname, text=\"Polygon\", icon=\"PLUGIN\")\n\t\toper13.Simple_Change = False\n\t\toper13.Simple_Type = \"Polygon\"\n\n\t\toper14 = self.layout.operator(Simple.bl_idname, text=\"Polygon_ab\", icon=\"PLUGIN\")\n\t\toper14.Simple_Change = False\n\t\toper14.Simple_Type = \"Polygon_ab\"\n\n\t\toper15 = self.layout.operator(Simple.bl_idname, text=\"Trapezoid\", icon=\"PLUGIN\")\n\t\toper15.Simple_Change = False\n\t\toper15.Simple_Type = \"Trapezoid\"\n\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "Simple_button", "data": "def Simple_button(self, context):\n\toper11 = self.layout.operator(Simple.bl_idname, text=\"Rectangle\", icon=\"PLUGIN\")\n\toper11.Simple_Change = False\n\toper11.Simple_Type = \"Rectangle\"\n\n\tself.layout.menu(\"INFO_MT_simple_menu\", icon=\"PLUGIN\")\n\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "register", "data": "def register():\n\tbpy.utils.register_class(Simple)\n\tbpy.utils.register_class(BezierPointsFillet)\n\tbpy.utils.register_class(BezierDivide)\n\tbpy.utils.register_class(SimplePanel)\n\tbpy.utils.register_class(SimpleEdit)\n\tbpy.utils.register_class(INFO_MT_simple_menu)\n\n\tbpy.types.INFO_MT_curve_add.append(Simple_button)\n\n\tSimpleVariables()\n\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "unregister", "data": "def unregister():\n\tbpy.utils.unregister_class(Simple)\n\tbpy.utils.unregister_class(BezierPointsFillet)\n\tbpy.utils.unregister_class(BezierDivide)\n\tbpy.utils.unregister_class(SimplePanel)\n\tbpy.utils.unregister_class(SimpleEdit)\n\tbpy.utils.unregister_class(INFO_MT_simple_menu)\n\n\tbpy.types.INFO_MT_curve_add.remove(Simple_button)\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}], [{"term": "def", "name": "activity_view", "data": "def activity_view(request, pk, simple_layout=False):\n\t\"\"\"Displays an activity\n\n\t:param pk: The activity's primary key\n\t:param simple_layout: Whether the activity should be displayed in a basic way or with the header, buttons, etc.\n\t\"\"\"\n\n\tctx = {}\n\n\t# Checking that the current user is allowed to view this activity\n\tif 'user_id' in request.session:\n\t\ttry:\n\t\t\tstudent = Student.objects.get(pk=request.session['user_id'])\n\t\t\tctx['percentage'] = (student.current_activity/len(student.path_list()))*100\n\t\t\tif not student.get_current_activity() == Activity.objects.get(pk=pk):\n\t\t\t\tif request.user.is_staff:\n\t\t\t\t\tsimple_layout = True\n\t\t\t\telse:\n\t\t\t\t\treturn user_activity()\n\t\texcept ObjectDoesNotExist:\n\t\t\tif request.user.is_staff:\n\t\t\t\tsimple_layout = True\n\t\t\telse:\n\t\t\t\treturn HttpResponseRedirect('/student/register/')\n\telif request.user.is_staff:\n\t\tsimple_layout = True\n\telse:\n\t\treturn HttpResponseRedirect('/student/register/')\n\n\tactivity = Activity.objects.get(pk=pk)\n\ttpe = activity.type\n\tctx['source'] = activity.source\n\tctx['title'] = activity.name\n\tctx['instruction'] = activity.instruction\n\tbase_template = 'base.html'\n\n\tif simple_layout:\n\t\tbase_template = 'simple-base.html'\n\t\tctx['simple'] = True\n\n\tctx['base_template'] = base_template\n\n\tif tpe == 'text':\n\t\treturn render(request, 'text-activity.html', context=ctx)\n\telif tpe == 'quiz':\n\t\tif simple_layout:\n\t\t\treturn quiz_preview(request, activity)\n\t\telse:\n\t\t\treturn quiz_activity(request, activity, simple_layout)\n\telif tpe == 'link':\n\t\tif activity.source[-4:] == \".mp4\":\n\t\t\treturn render(request, 'video-activity.html', context=ctx)\n\t\telse:\n\t\t\treturn render(request, 'link-activity.html', context=ctx)\n\telif tpe == 'psycho':\n\t\tif simple_layout:\n\t\t\treturn quiz_preview(request, activity)\n\t\telse:\n\t\t\treturn psycho_activity(request, activity, simple_layout)\n\telse:\n\t\treturn render(request, 'text-activity.html', context=ctx)\n\n", "description": "Displays an activity\n\n\t:param pk: The activity's primary key\n\t:param simple_layout: Whether the activity should be displayed in a basic way or with the header, buttons, etc.\n\t", "category": "simple", "imports": ["from django.http import HttpResponseRedirect", "from django.utils import timezone", "from graphs.models import Student, Activity, TimeLog", "from graphs.forms import QuizForm, PsychoForm", "from django.core.exceptions import ObjectDoesNotExist", "from django.shortcuts import render"]}, {"term": "def", "name": "simple_activity", "data": "def simple_activity(request, pk):\n\treturn activity_view(request, pk, simple_layout=True)\n\n", "description": null, "category": "simple", "imports": ["from django.http import HttpResponseRedirect", "from django.utils import timezone", "from graphs.models import Student, Activity, TimeLog", "from graphs.forms import QuizForm, PsychoForm", "from django.core.exceptions import ObjectDoesNotExist", "from django.shortcuts import render"]}, {"term": "def", "name": "completion", "data": "def completion(request):\n\t\"\"\"Displays the completion page\"\"\"\n\ttry:\n\t\tstudent = Student.objects.get(pk=request.session['user_id'])\n\n\t\tresults = student.get_results().order_by('timestamp')\n\t\tpre_test = round(results.first().score * 100)\n\t\tpost_test = round(results.last().score * 100)\n\t\tctx = {'pretest': pre_test, 'posttest': post_test, 'diff': post_test - pre_test}\n\t\treturn render(request, 'completion.html', context=ctx)\n\n\texcept ObjectDoesNotExist:\n\t\treturn HttpResponseRedirect('/student/register/')\n\n", "description": "Displays the completion page", "category": "simple", "imports": ["from django.http import HttpResponseRedirect", "from django.utils import timezone", "from graphs.models import Student, Activity, TimeLog", "from graphs.forms import QuizForm, PsychoForm", "from django.core.exceptions import ObjectDoesNotExist", "from django.shortcuts import render"]}, {"term": "def", "name": "user_activity", "data": "def user_activity(request):\n\t\"\"\"Displays the current user's current activity\"\"\"\n\ttry:\n\t\tstudent = Student.objects.get(pk=request.session['user_id'])\n\t\tactivity = student.get_current_activity()\n\n\t\tif student.completion_date is not None:\n\t\t\treturn completion(request)\n\t\telse:\n\t\t\treturn activity_view(request, activity.pk)\n\n\texcept ObjectDoesNotExist:\n\t\treturn HttpResponseRedirect('/student/register/')\n\n", "description": "Displays the current user's current activity", "category": "simple", "imports": ["from django.http import HttpResponseRedirect", "from django.utils import timezone", "from graphs.models import Student, Activity, TimeLog", "from graphs.forms import QuizForm, PsychoForm", "from django.core.exceptions import ObjectDoesNotExist", "from django.shortcuts import render"]}, {"term": "def", "name": "next_activity", "data": "def next_activity(request):\n\t\"\"\"Makes the current user proceed to their next activity\"\"\"\n\ttry:\n\t\tstudent = Student.objects.get(pk=request.session['user_id'])\n\t\tlog = TimeLog.objects.get(student=student, activity=student.get_current_activity(), end_time__isnull=True)\n\t\tlog.end_time = timezone.now()\n\t\tlog.save()\n\n\t\tif student.current_activity + 1 >= len(student.path_list()):\n\t\t\tif student.completion_date is None:\n\t\t\t\tstudent.completion_date = timezone.now()\n\t\t\t\tstudent.save()\n\t\t\treturn completion(request)\n\n\t\telse:\n\t\t\t# We make sure we're not creating duplicate logs\n\t\t\tif not TimeLog.objects.filter(student=student, activity=student.get_current_activity(), end_time__isnull=True).exists():\n\t\t\t\tstudent.current_activity += 1\n\t\t\t\tstudent.save()\n\t\t\t\tlog = TimeLog.create(student=student, activity=student.get_current_activity())\n\t\t\t\tlog.save()\n\t\t\treturn HttpResponseRedirect('/student/')\n\n\texcept ObjectDoesNotExist:\n\t\treturn HttpResponseRedirect('/student/register/')\n\n", "description": "Makes the current user proceed to their next activity", "category": "simple", "imports": ["from django.http import HttpResponseRedirect", "from django.utils import timezone", "from graphs.models import Student, Activity, TimeLog", "from graphs.forms import QuizForm, PsychoForm", "from django.core.exceptions import ObjectDoesNotExist", "from django.shortcuts import render"]}, {"term": "def", "name": "quiz_activity", "data": "def quiz_activity(request, activity, simple_layout=False):\n\t\"\"\"Displays a submittable quiz form\n\n\t:param activity: The quiz activity to display\n\t:param simple_layout: If true, displays the quiz as plain text instead of a form (default false)\n\t\"\"\"\n\tstudent = Student.objects.get(pk=request.session['user_id'])\n\tctx = {'title': activity.name, 'instruction': activity.instruction}\n\tbase_template = 'base.html'\n\n\tif simple_layout:\n\t\tbase_template = 'simple-base.html'\n\t\tctx['simple'] = True\n\n\tctx['base_template'] = base_template\n\tctx['percentage'] = (student.current_activity/len(student.path_list()))*100\n\n\tif request.method == 'POST':\n\t\tform = QuizForm(request.POST, quiz=activity, student=student)\n\t\tctx['form'] = form\n\t\tif form.is_valid():\n\t\t\tform.save()\n\t\t\treturn next_activity(request)\n\telse:\n\t\tform = QuizForm(quiz=activity, student=student)\n\t\tctx['form'] = form\n\treturn render(request, 'quiz-activity.html', ctx)\n\n", "description": "Displays a submittable quiz form\n\n\t:param activity: The quiz activity to display\n\t:param simple_layout: If true, displays the quiz as plain text instead of a form (default false)\n\t", "category": "simple", "imports": ["from django.http import HttpResponseRedirect", "from django.utils import timezone", "from graphs.models import Student, Activity, TimeLog", "from graphs.forms import QuizForm, PsychoForm", "from django.core.exceptions import ObjectDoesNotExist", "from django.shortcuts import render"]}, {"term": "def", "name": "psycho_activity", "data": "def psycho_activity(request, activity, simple_layout=False):\n\t\"\"\"Displays a submittable psychological test form\n\n\t:param activity: The test activity to display\n\t:param simple_layout: If true, displays the test as plain text instead of a form (default false)\n\t\"\"\"\n\tstudent = Student.objects.get(pk=request.session['user_id'])\n\tctx = {'title': activity.name, 'instruction': activity.instruction}\n\tbase_template = 'base.html'\n\n\tif simple_layout:\n\t\tbase_template = 'simple-base.html'\n\t\tctx['simple'] = True\n\n\tctx['base_template'] = base_template\n\tctx['percentage'] = (student.current_activity/len(student.path_list()))*100\n\n\tif request.method == 'POST':\n\t\tform = PsychoForm(request.POST, test=activity, student=student)\n\t\tctx['form'] = form\n\t\tif form.is_valid():\n\t\t\tform.save()\n\t\t\treturn next_activity(request)\n\telse:\n\t\tform = PsychoForm(test=activity, student=student)\n\t\tctx['form'] = form\n\treturn render(request, 'quiz-activity.html', ctx)\n\n", "description": "Displays a submittable psychological test form\n\n\t:param activity: The test activity to display\n\t:param simple_layout: If true, displays the test as plain text instead of a form (default false)\n\t", "category": "simple", "imports": ["from django.http import HttpResponseRedirect", "from django.utils import timezone", "from graphs.models import Student, Activity, TimeLog", "from graphs.forms import QuizForm, PsychoForm", "from django.core.exceptions import ObjectDoesNotExist", "from django.shortcuts import render"]}, {"term": "def", "name": "quiz_preview", "data": "def quiz_preview(request, activity):\n\t\"\"\"Displays a quiz activity as text rather than as a radio button form\n\n\t:param activity: The quiz to display\"\"\"\n\tctx = {'title': activity.name, 'instruction': activity.instruction, 'questions': activity.get_questions()}\n\treturn render(request, 'quiz-preview.html', ctx)\n", "description": "Displays a quiz activity as text rather than as a radio button form\n\n\t:param activity: The quiz to display", "category": "simple", "imports": ["from django.http import HttpResponseRedirect", "from django.utils import timezone", "from graphs.models import Student, Activity, TimeLog", "from graphs.forms import QuizForm, PsychoForm", "from django.core.exceptions import ObjectDoesNotExist", "from django.shortcuts import render"]}], [{"term": "def", "name": "SimplePoint", "data": "def SimplePoint():\n\tnewpoints = []\n\n\tnewpoints.append([0.0, 0.0, 0.0])\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleLine", "data": "def SimpleLine(c1=[0.0, 0.0, 0.0], c2=[2.0, 2.0, 2.0]):\n\tnewpoints = []\n\n\tc3 = Vector(c2) - Vector(c1)\n\tnewpoints.append([0.0, 0.0, 0.0])\n\tnewpoints.append([c3[0], c3[1], c3[2]])\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleAngle", "data": "def SimpleAngle(length=1.0, angle=45.0):\n\tnewpoints = []\n\n\tangle = radians(angle)\n\tnewpoints.append([length, 0.0, 0.0])\n\tnewpoints.append([0.0, 0.0, 0.0])\n\tnewpoints.append([length * cos(angle), length * sin(angle), 0.0])\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleDistance", "data": "def SimpleDistance(length=1.0, center=True):\n\tnewpoints = []\n\n\tif center:\n\t\tnewpoints.append([-length / 2, 0.0, 0.0])\n\t\tnewpoints.append([length / 2, 0.0, 0.0])\n\telse:\n\t\tnewpoints.append([0.0, 0.0, 0.0])\n\t\tnewpoints.append([length, 0.0, 0.0])\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleCircle", "data": "def SimpleCircle(sides=4, radius=1.0):\n\tnewpoints = []\n\n\tangle = radians(360) / sides\n\tnewpoints.append([radius, 0, 0])\n\tj = 1\n\twhile j < sides:\n\t\tt = angle * j\n\t\tx = cos(t) * radius\n\t\ty = sin(t) * radius\n\t\tnewpoints.append([x, y, 0])\n\t\tj += 1\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleEllipse", "data": "def SimpleEllipse(a=2.0, b=1.0):\n\tnewpoints = []\n\n\tnewpoints.append([a, 0.0, 0.0])\n\tnewpoints.append([0.0, b, 0.0])\n\tnewpoints.append([-a, 0.0, 0.0])\n\tnewpoints.append([0.0, -b, 0.0])\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleArc", "data": "def SimpleArc(sides=0, radius=1.0, startangle=0.0, endangle=45.0):\n\tnewpoints = []\n\n\tstartangle = radians(startangle)\n\tendangle = radians(endangle)\n\tsides += 1\n\n\tangle = (endangle - startangle) / sides\n\tx = cos(startangle) * radius\n\ty = sin(startangle) * radius\n\tnewpoints.append([x, y, 0])\n\tj = 1\n\twhile j < sides:\n\t\tt = angle * j\n\t\tx = cos(t + startangle) * radius\n\t\ty = sin(t + startangle) * radius\n\t\tnewpoints.append([x, y, 0])\n\t\tj += 1\n\tx = cos(endangle) * radius\n\ty = sin(endangle) * radius\n\tnewpoints.append([x, y, 0])\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleSector", "data": "def SimpleSector(sides=0, radius=1.0, startangle=0.0, endangle=45.0):\n\tnewpoints = []\n\n\tstartangle = radians(startangle)\n\tendangle = radians(endangle)\n\tsides += 1\n\n\tnewpoints.append([0, 0, 0])\n\tangle = (endangle - startangle) / sides\n\tx = cos(startangle) * radius\n\ty = sin(startangle) * radius\n\tnewpoints.append([x, y, 0])\n\tj = 1\n\twhile j < sides:\n\t\tt = angle * j\n\t\tx = cos(t + startangle) * radius\n\t\ty = sin(t + startangle) * radius\n\t\tnewpoints.append([x, y, 0])\n\t\tj += 1\n\tx = cos(endangle) * radius\n\ty = sin(endangle) * radius\n\tnewpoints.append([x, y, 0])\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleSegment", "data": "def SimpleSegment(sides=0, a=2.0, b=1.0, startangle=0.0, endangle=45.0):\n\tnewpoints = []\n\n\tstartangle = radians(startangle)\n\tendangle = radians(endangle)\n\tsides += 1\n\n\tangle = (endangle - startangle) / sides\n\tx = cos(startangle) * a\n\ty = sin(startangle) * a\n\tnewpoints.append([x, y, 0])\n\tj = 1\n\twhile j < sides:\n\t\tt = angle * j\n\t\tx = cos(t + startangle) * a\n\t\ty = sin(t + startangle) * a\n\t\tnewpoints.append([x, y, 0])\n\t\tj += 1\n\tx = cos(endangle) * a\n\ty = sin(endangle) * a\n\tnewpoints.append([x, y, 0])\n\n\tx = cos(endangle) * b\n\ty = sin(endangle) * b\n\tnewpoints.append([x, y, 0])\n\tj = sides\n\twhile j > 0:\n\t\tt = angle * j\n\t\tx = cos(t + startangle) * b\n\t\ty = sin(t + startangle) * b\n\t\tnewpoints.append([x, y, 0])\n\t\tj -= 1\n\tx = cos(startangle) * b\n\ty = sin(startangle) * b\n\tnewpoints.append([x, y, 0])\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleRectangle", "data": "def SimpleRectangle(width=2.0, length=2.0, rounded=0.0, center=True):\n\tnewpoints = []\n\n\tr = rounded / 2\n\n\tif center:\n\t\tx = width / 2\n\t\ty = length / 2\n\t\tif rounded != 0.0:\n\t\t\tnewpoints.append([-x + r, y, 0.0])\n\t\t\tnewpoints.append([x - r, y, 0.0])\n\t\t\tnewpoints.append([x, y - r, 0.0])\n\t\t\tnewpoints.append([x, -y + r, 0.0])\n\t\t\tnewpoints.append([x - r, -y, 0.0])\n\t\t\tnewpoints.append([-x + r, -y, 0.0])\n\t\t\tnewpoints.append([-x, -y + r, 0.0])\n\t\t\tnewpoints.append([-x, y - r, 0.0])\n\t\telse:\n\t\t\tnewpoints.append([-x, y, 0.0])\n\t\t\tnewpoints.append([x, y, 0.0])\n\t\t\tnewpoints.append([x, -y, 0.0])\n\t\t\tnewpoints.append([-x, -y, 0.0])\n\n\telse:\n\t\tx = width\n\t\ty = length\n\t\tif rounded != 0.0:\n\t\t\tnewpoints.append([r, y, 0.0])\n\t\t\tnewpoints.append([x - r, y, 0.0])\n\t\t\tnewpoints.append([x, y - r, 0.0])\n\t\t\tnewpoints.append([x, r, 0.0])\n\t\t\tnewpoints.append([x - r, 0.0, 0.0])\n\t\t\tnewpoints.append([r, 0.0, 0.0])\n\t\t\tnewpoints.append([0.0, r, 0.0])\n\t\t\tnewpoints.append([0.0, y - r, 0.0])\n\t\telse:\n\t\t\tnewpoints.append([0.0, 0.0, 0.0])\n\t\t\tnewpoints.append([0.0, y, 0.0])\n\t\t\tnewpoints.append([x, y, 0.0])\n\t\t\tnewpoints.append([x, 0.0, 0.0])\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleRhomb", "data": "def SimpleRhomb(width=2.0, length=2.0, center=True):\n\tnewpoints = []\n\tx = width / 2\n\ty = length / 2\n\n\tif center:\n\t\tnewpoints.append([-x, 0.0, 0.0])\n\t\tnewpoints.append([0.0, y, 0.0])\n\t\tnewpoints.append([x, 0.0, 0.0])\n\t\tnewpoints.append([0.0, -y, 0.0])\n\telse:\n\t\tnewpoints.append([x, 0.0, 0.0])\n\t\tnewpoints.append([0.0, y, 0.0])\n\t\tnewpoints.append([x, length, 0.0])\n\t\tnewpoints.append([width, y, 0.0])\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimplePolygon", "data": "def SimplePolygon(sides=3, radius=1.0):\n\tnewpoints = []\n\tangle = radians(360.0) / sides\n\tj = 0\n\n\twhile j < sides:\n\t\tt = angle * j\n\t\tx = sin(t) * radius\n\t\ty = cos(t) * radius\n\t\tnewpoints.append([x, y, 0.0])\n\t\tj += 1\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimplePolygon_ab", "data": "def SimplePolygon_ab(sides=3, a=2.0, b=1.0):\n\tnewpoints = []\n\tangle = radians(360.0) / sides\n\tj = 0\n\n\twhile j < sides:\n\t\tt = angle * j\n\t\tx = sin(t) * a\n\t\ty = cos(t) * b\n\t\tnewpoints.append([x, y, 0.0])\n\t\tj += 1\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleTrapezoid", "data": "def SimpleTrapezoid(a=2.0, b=1.0, h=1.0, center=True):\n\tnewpoints = []\n\tx = a / 2\n\ty = b / 2\n\tr = h / 2\n\n\tif center:\n\t\tnewpoints.append([-x, -r, 0.0])\n\t\tnewpoints.append([-y, r, 0.0])\n\t\tnewpoints.append([y, r, 0.0])\n\t\tnewpoints.append([x, -r, 0.0])\n\n\telse:\n\t\tnewpoints.append([0.0, 0.0, 0.0])\n\t\tnewpoints.append([x - y, h, 0.0])\n\t\tnewpoints.append([x + y, h, 0.0])\n\t\tnewpoints.append([a, 0.0, 0.0])\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "align_matrix", "data": "def align_matrix(context, location):\n\tloc = Matrix.Translation(location)\n\tobj_align = context.user_preferences.edit.object_align\n\tif (context.space_data.type == 'VIEW_3D'\n\t\t\tand obj_align == 'VIEW'):\n\t\trot = context.space_data.region_3d.view_matrix.to_3x3().inverted().to_4x4()\n\telse:\n\t\trot = Matrix()\n\talign_matrix = loc * rot\n\n\treturn align_matrix\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "main", "data": "def main(context, self, align_matrix):\n\t# deselect all objects\n\tbpy.ops.object.select_all(action='DESELECT')\n\n\t# create object\n\tname = self.Simple_Type\t\t # Type as name\n\n\t# create curve\n\tscene = bpy.context.scene\n\tnewCurve = bpy.data.curves.new(name, type='CURVE')  # curvedatablock\n\tnewSpline = newCurve.splines.new('BEZIER')  # spline\n\n\t# set curveOptions\n\tnewCurve.dimensions = self.shape\n\tnewSpline.use_endpoint_u = True\n\n\tsides = abs(int((self.Simple_endangle - self.Simple_startangle) / 90))\n\n\t# get verts\n\tif self.Simple_Type == 'Point':\n\t\tverts = SimplePoint()\n\t\tnewSpline.use_cyclic_u = False\n\n\tif self.Simple_Type == 'Line':\n\t\tverts = SimpleLine(self.Simple_startlocation, self.Simple_endlocation)\n\t\tnewSpline.use_cyclic_u = False\n\t\tnewCurve.dimensions = '3D'\n\n\tif self.Simple_Type == 'Distance':\n\t\tverts = SimpleDistance(self.Simple_length, self.Simple_center)\n\t\tnewSpline.use_cyclic_u = False\n\n\tif self.Simple_Type == 'Angle':\n\t\tverts = SimpleAngle(self.Simple_length, self.Simple_angle)\n\t\tnewSpline.use_cyclic_u = False\n\n\tif self.Simple_Type == 'Circle':\n\t\tif self.Simple_sides < 4:\n\t\t\tself.Simple_sides = 4\n\t\tverts = SimpleCircle(self.Simple_sides, self.Simple_radius)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Ellipse':\n\t\tverts = SimpleEllipse(self.Simple_a, self.Simple_b)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Arc':\n\t\tif self.Simple_sides < sides:\n\t\t\tself.Simple_sides = sides\n\t\tif self.Simple_radius == 0:\n\t\t\treturn {'FINISHED'}\n\t\tverts = SimpleArc(self.Simple_sides, self.Simple_radius, self.Simple_startangle, self.Simple_endangle)\n\t\tnewSpline.use_cyclic_u = False\n\n\tif self.Simple_Type == 'Sector':\n\t\tif self.Simple_sides < sides:\n\t\t\tself.Simple_sides = sides\n\t\tif self.Simple_radius == 0:\n\t\t\treturn {'FINISHED'}\n\t\tverts = SimpleSector(self.Simple_sides, self.Simple_radius, self.Simple_startangle, self.Simple_endangle)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Segment':\n\t\tif self.Simple_sides < sides:\n\t\t\tself.Simple_sides = sides\n\t\tif self.Simple_a == 0 or self.Simple_b == 0:\n\t\t\treturn {'FINISHED'}\n\t\tverts = SimpleSegment(self.Simple_sides, self.Simple_a, self.Simple_b, self.Simple_startangle, self.Simple_endangle)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Rectangle':\n\t\tverts = SimpleRectangle(self.Simple_width, self.Simple_length, self.Simple_rounded, self.Simple_center)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Rhomb':\n\t\tverts = SimpleRhomb(self.Simple_width, self.Simple_length, self.Simple_center)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Polygon':\n\t\tif self.Simple_sides < 3:\n\t\t\tself.Simple_sides = 3\n\t\tverts = SimplePolygon(self.Simple_sides, self.Simple_radius)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Polygon_ab':\n\t\tif self.Simple_sides < 3:\n\t\t\tself.Simple_sides = 3\n\t\tverts = SimplePolygon_ab(self.Simple_sides, self.Simple_a, self.Simple_b)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Trapezoid':\n\t\tverts = SimpleTrapezoid(self.Simple_a, self.Simple_b, self.Simple_h, self.Simple_center)\n\t\tnewSpline.use_cyclic_u = True\n\n\tvertArray = []\n\tfor v in verts:\n\t\tvertArray += v\n\n\tnewSpline.bezier_points.add(int(len(vertArray) * 0.333333333))\n\tnewSpline.bezier_points.foreach_set('co', vertArray)\n\n\t# create object with newCurve\n\tSimpleCurve = bpy.data.objects.new(name, newCurve)  # object\n\tscene.objects.link(SimpleCurve)  # place in active scene\n\tSimpleCurve.select = True  # set as selected\n\tscene.objects.active = SimpleCurve  # set as active\n\tSimpleCurve.matrix_world = align_matrix  # apply matrix\n\tSimpleCurve.rotation_euler = self.Simple_rotation_euler\n\n\tall_points = [p for p in newSpline.bezier_points]\n\td = 2 * 0.27606262\n\tn = 0\n\tfor p in all_points:\n\t\tp.handle_right_type = 'VECTOR'\n\t\tp.handle_left_type = 'VECTOR'\n\t\tn += 1\n\n\tif self.Simple_Type == 'Circle' or self.Simple_Type == 'Arc' or self.Simple_Type == 'Sector' or self.Simple_Type == 'Segment' or self.Simple_Type == 'Ellipse':\n\t\tfor p in all_points:\n\t\t\tp.handle_right_type = 'FREE'\n\t\t\tp.handle_left_type = 'FREE'\n\n\tif self.Simple_Type == 'Circle':\n\t\ti = 0\n\t\tfor p1 in all_points:\n\t\t\tif i != n - 1:\n\t\t\t\tp2 = all_points[i + 1]\n\t\t\t\tu1 = asin(p1.co.y / self.Simple_radius)\n\t\t\t\tu2 = asin(p2.co.y / self.Simple_radius)\n\t\t\t\tif p1.co.x > 0 and p2.co.x < 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\telif p1.co.x < 0 and p2.co.x > 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\tu = u2 - u1\n\t\t\t\tif u < 0:\n\t\t\t\t\tu = -u\n\t\t\t\tl = 4 / 3 * tan(1 / 4 * u) * self.Simple_radius\n\t\t\t\tv1 = Vector((-p1.co.y, p1.co.x, 0))\n\t\t\t\tv1.normalize()\n\t\t\t\tv2 = Vector((-p2.co.y, p2.co.x, 0))\n\t\t\t\tv2.normalize()\n\t\t\t\tvh1 = v1 * l\n\t\t\t\tvh2 = v2 * l\n\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) + vh1\n\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) - vh2\n\t\t\t\tp1.handle_right = v1\n\t\t\t\tp2.handle_left = v2\n\t\t\tif i == n - 1:\n\t\t\t\tp2 = all_points[0]\n\t\t\t\tu1 = asin(p1.co.y / self.Simple_radius)\n\t\t\t\tu2 = asin(p2.co.y / self.Simple_radius)\n\t\t\t\tif p1.co.x > 0 and p2.co.x < 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\telif p1.co.x < 0 and p2.co.x > 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\tu = u2 - u1\n\t\t\t\tif u < 0:\n\t\t\t\t\tu = -u\n\t\t\t\tl = 4 / 3 * tan(1 / 4 * u) * self.Simple_radius\n\t\t\t\tv1 = Vector((-p1.co.y, p1.co.x, 0))\n\t\t\t\tv1.normalize()\n\t\t\t\tv2 = Vector((-p2.co.y, p2.co.x, 0))\n\t\t\t\tv2.normalize()\n\t\t\t\tvh1 = v1 * l\n\t\t\t\tvh2 = v2 * l\n\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) + vh1\n\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) - vh2\n\t\t\t\tp1.handle_right = v1\n\t\t\t\tp2.handle_left = v2\n\t\t\ti += 1\n\n\tif self.Simple_Type == 'Ellipse':\n\t\tall_points[0].handle_right = Vector((self.Simple_a, self.Simple_b * d, 0))\n\t\tall_points[0].handle_left = Vector((self.Simple_a, -self.Simple_b * d, 0))\n\t\tall_points[1].handle_right = Vector((-self.Simple_a * d, self.Simple_b, 0))\n\t\tall_points[1].handle_left = Vector((self.Simple_a * d, self.Simple_b, 0))\n\t\tall_points[2].handle_right = Vector((-self.Simple_a, -self.Simple_b * d, 0))\n\t\tall_points[2].handle_left = Vector((-self.Simple_a, self.Simple_b * d, 0))\n\t\tall_points[3].handle_right = Vector((self.Simple_a * d, -self.Simple_b, 0))\n\t\tall_points[3].handle_left = Vector((-self.Simple_a * d, -self.Simple_b, 0))\n\n\tif self.Simple_Type == 'Arc':\n\t\ti = 0\n\t\tfor p1 in all_points:\n\t\t\tif i != n - 1:\n\t\t\t\tp2 = all_points[i + 1]\n\t\t\t\tu1 = asin(p1.co.y / self.Simple_radius)\n\t\t\t\tu2 = asin(p2.co.y / self.Simple_radius)\n\t\t\t\tif p1.co.x > 0 and p2.co.x < 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\telif p1.co.x < 0 and p2.co.x > 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\tu = u2 - u1\n\t\t\t\tif u < 0:\n\t\t\t\t\tu = -u\n\t\t\t\tl = 4 / 3 * tan(1 / 4 * u) * self.Simple_radius\n\t\t\t\tv1 = Vector((-p1.co.y, p1.co.x, 0))\n\t\t\t\tv1.normalize()\n\t\t\t\tv2 = Vector((-p2.co.y, p2.co.x, 0))\n\t\t\t\tv2.normalize()\n\t\t\t\tvh1 = v1 * l\n\t\t\t\tvh2 = v2 * l\n\t\t\t\tif self.Simple_startangle < self.Simple_endangle:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) + vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) - vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\t\t\t\telse:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) - vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) + vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\t\t\ti += 1\n\n\tif self.Simple_Type == 'Sector':\n\t\ti = 0\n\t\tfor p1 in all_points:\n\t\t\tif i == 0:\n\t\t\t\tp1.handle_right_type = 'VECTOR'\n\t\t\t\tp1.handle_left_type = 'VECTOR'\n\t\t\telif i != n - 1:\n\t\t\t\tp2 = all_points[i + 1]\n\t\t\t\tu1 = asin(p1.co.y / self.Simple_radius)\n\t\t\t\tu2 = asin(p2.co.y / self.Simple_radius)\n\t\t\t\tif p1.co.x > 0 and p2.co.x < 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\telif p1.co.x < 0 and p2.co.x > 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\tu = u2 - u1\n\t\t\t\tif u < 0:\n\t\t\t\t\tu = -u\n\t\t\t\tl = 4 / 3 * tan(1 / 4 * u) * self.Simple_radius\n\t\t\t\tv1 = Vector((-p1.co.y, p1.co.x, 0))\n\t\t\t\tv1.normalize()\n\t\t\t\tv2 = Vector((-p2.co.y, p2.co.x, 0))\n\t\t\t\tv2.normalize()\n\t\t\t\tvh1 = v1 * l\n\t\t\t\tvh2 = v2 * l\n\t\t\t\tif self.Simple_startangle < self.Simple_endangle:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) + vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) - vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\t\t\t\telse:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) - vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) + vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\t\t\ti += 1\n\n\tif self.Simple_Type == 'Segment':\n\t\ti = 0\n\t\tfor p1 in all_points:\n\t\t\tif i < n / 2 - 1:\n\t\t\t\tp2 = all_points[i + 1]\n\t\t\t\tu1 = asin(p1.co.y / self.Simple_a)\n\t\t\t\tu2 = asin(p2.co.y / self.Simple_a)\n\t\t\t\tif p1.co.x > 0 and p2.co.x < 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_a)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_a)\n\t\t\t\telif p1.co.x < 0 and p2.co.x > 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_a)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_a)\n\t\t\t\tu = u2 - u1\n\t\t\t\tif u < 0:\n\t\t\t\t\tu = -u\n\t\t\t\tl = 4 / 3 * tan(1 / 4 * u) * self.Simple_a\n\t\t\t\tv1 = Vector((-p1.co.y, p1.co.x, 0))\n\t\t\t\tv1.normalize()\n\t\t\t\tv2 = Vector((-p2.co.y, p2.co.x, 0))\n\t\t\t\tv2.normalize()\n\t\t\t\tvh1 = v1 * l\n\t\t\t\tvh2 = v2 * l\n\t\t\t\tif self.Simple_startangle < self.Simple_endangle:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) + vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) - vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\t\t\t\telse:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) - vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) + vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\t\t\telif i != n / 2 - 1 and i != n - 1:\n\t\t\t\tp2 = all_points[i + 1]\n\t\t\t\tu1 = asin(p1.co.y / self.Simple_b)\n\t\t\t\tu2 = asin(p2.co.y / self.Simple_b)\n\t\t\t\tif p1.co.x > 0 and p2.co.x < 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_b)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_b)\n\t\t\t\telif p1.co.x < 0 and p2.co.x > 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_b)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_b)\n\t\t\t\tu = u2 - u1\n\t\t\t\tif u < 0:\n\t\t\t\t\tu = -u\n\t\t\t\tl = 4 / 3 * tan(1 / 4 * u) * self.Simple_b\n\t\t\t\tv1 = Vector((-p1.co.y, p1.co.x, 0))\n\t\t\t\tv1.normalize()\n\t\t\t\tv2 = Vector((-p2.co.y, p2.co.x, 0))\n\t\t\t\tv2.normalize()\n\t\t\t\tvh1 = v1 * l\n\t\t\t\tvh2 = v2 * l\n\t\t\t\tif self.Simple_startangle < self.Simple_endangle:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) - vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) + vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\t\t\t\telse:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) + vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) - vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\n\t\t\ti += 1\n\t\tall_points[0].handle_left_type = 'VECTOR'\n\t\tall_points[n - 1].handle_right_type = 'VECTOR'\n\t\tall_points[int(n / 2) - 1].handle_right_type = 'VECTOR'\n\t\tall_points[int(n / 2)].handle_left_type = 'VECTOR'\n\n\tSimpleCurve.Simple = True\n\tSimpleCurve.Simple_Change = False\n\tSimpleCurve.Simple_Type = self.Simple_Type\n\tSimpleCurve.Simple_startlocation = self.Simple_startlocation\n\tSimpleCurve.Simple_endlocation = self.Simple_endlocation\n\tSimpleCurve.Simple_a = self.Simple_a\n\tSimpleCurve.Simple_b = self.Simple_b\n\tSimpleCurve.Simple_h = self.Simple_h\n\tSimpleCurve.Simple_angle = self.Simple_angle\n\tSimpleCurve.Simple_startangle = self.Simple_startangle\n\tSimpleCurve.Simple_endangle = self.Simple_endangle\n\tSimpleCurve.Simple_rotation_euler = self.Simple_rotation_euler\n\tSimpleCurve.Simple_sides = self.Simple_sides\n\tSimpleCurve.Simple_radius = self.Simple_radius\n\tSimpleCurve.Simple_center = self.Simple_center\n\tSimpleCurve.Simple_width = self.Simple_width\n\tSimpleCurve.Simple_length = self.Simple_length\n\tSimpleCurve.Simple_rounded = self.Simple_rounded\n\n\tbpy.ops.object.mode_set(mode='EDIT', toggle=True)\n\tbpy.ops.curve.select_all(action='SELECT')\n\tbpy.ops.object.mode_set(mode='OBJECT', toggle=True)\n\n\treturn\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleDelete", "data": "def SimpleDelete(name):\n\tif bpy.ops.object.mode_set.poll():\n\t\tbpy.ops.object.mode_set(mode='OBJECT')\n\n\tbpy.context.scene.objects.active = bpy.data.objects[name]\n\tbpy.ops.object.delete()\n\n\treturn\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "class", "name": "Simple", "data": "class Simple(bpy.types.Operator):\n\t''''''\n\tbl_idname = \"curve.simple\"\n\tbl_label = \"Simple curve\"\n\tbl_options = {'REGISTER', 'UNDO'}\n\tbl_description = \"adds simple curve\"\n\n\t# align_matrix for the invoke\n\talign_matrix = Matrix()\n\n\t# change properties\n\tSimple = BoolProperty(name=\"Simple\",\n\t\t\t\t\t\t  default=True,\n\t\t\t\t\t\t  description=\"simple curve\")\n\n\tSimple_Change = BoolProperty(name=\"Change\",\n\t\t\t\t\t\t\t\t default=False,\n\t\t\t\t\t\t\t\t description=\"change simple curve\")\n\n\tSimple_Delete = StringProperty(name=\"Delete\",\n\t\t\t\t\t\t\t\t   description=\"Delete simple curve\")\n\n\t# general properties\n\tTypes = [('Point', 'Point', 'Point'),\n\t\t\t ('Line', 'Line', 'Line'),\n\t\t\t ('Distance', 'Distance', 'Distance'),\n\t\t\t ('Angle', 'Angle', 'Angle'),\n\t\t\t ('Circle', 'Circle', 'Circle'),\n\t\t\t ('Ellipse', 'Ellipse', 'Ellipse'),\n\t\t\t ('Arc', 'Arc', 'Arc'),\n\t\t\t ('Sector', 'Sector', 'Sector'),\n\t\t\t ('Segment', 'Segment', 'Segment'),\n\t\t\t ('Rectangle', 'Rectangle', 'Rectangle'),\n\t\t\t ('Rhomb', 'Rhomb', 'Rhomb'),\n\t\t\t ('Polygon', 'Polygon', 'Polygon'),\n\t\t\t ('Polygon_ab', 'Polygon_ab', 'Polygon_ab'),\n\t\t\t ('Trapezoid', 'Trapezoid', 'Trapezoid')]\n\tSimple_Type = EnumProperty(name=\"Type\",\n\t\t\t\t\t\t\t   description=\"Form of Curve to create\",\n\t\t\t\t\t\t\t   items=Types)\n\n\t# Line properties\n\tSimple_startlocation = FloatVectorProperty(name=\"\",\n\t\t\t\t\t\t\t\t\t\t\t   description=\"Start location\",\n\t\t\t\t\t\t\t\t\t\t\t   default=(0.0, 0.0, 0.0),\n\t\t\t\t\t\t\t\t\t\t\t   subtype='TRANSLATION')\n\tSimple_endlocation = FloatVectorProperty(name=\"\",\n\t\t\t\t\t\t\t\t\t\t\t description=\"End location\",\n\t\t\t\t\t\t\t\t\t\t\t default=(2.0, 2.0, 2.0),\n\t\t\t\t\t\t\t\t\t\t\t subtype='TRANSLATION')\n\tSimple_rotation_euler = FloatVectorProperty(name=\"\",\n\t\t\t\t\t\t\t\t\t\t\t\tdescription=\"Rotation\",\n\t\t\t\t\t\t\t\t\t\t\t\tdefault=(0.0, 0.0, 0.0),\n\t\t\t\t\t\t\t\t\t\t\t\tsubtype='EULER')\n\n\t# Trapezoid properties\n\tSimple_a = FloatProperty(name=\"a\",\n\t\t\t\t\t\t\t default=2.0,\n\t\t\t\t\t\t\t min=0.0, soft_min=0.0,\n\t\t\t\t\t\t\t unit='LENGTH',\n\t\t\t\t\t\t\t description=\"a\")\n\tSimple_b = FloatProperty(name=\"b\",\n\t\t\t\t\t\t\t default=1.0,\n\t\t\t\t\t\t\t min=0.0, soft_min=0.0,\n\t\t\t\t\t\t\t unit='LENGTH',\n\t\t\t\t\t\t\t description=\"b\")\n\tSimple_h = FloatProperty(name=\"h\",\n\t\t\t\t\t\t\t default=1.0,\n\t\t\t\t\t\t\t unit='LENGTH',\n\t\t\t\t\t\t\t description=\"h\")\n\n\tSimple_angle = FloatProperty(name=\"Angle\",\n\t\t\t\t\t\t\t\t default=45.0,\n\t\t\t\t\t\t\t\t description=\"Angle\")\n\tSimple_startangle = FloatProperty(name=\"Start angle\",\n\t\t\t\t\t\t\t\t\t  default=0.0,\n\t\t\t\t\t\t\t\t\t  min=-360.0, soft_min=-360.0,\n\t\t\t\t\t\t\t\t\t  max=360.0, soft_max=360.0,\n\t\t\t\t\t\t\t\t\t  description=\"Start angle\")\n\tSimple_endangle = FloatProperty(name=\"End angle\",\n\t\t\t\t\t\t\t\t\tdefault=45.0,\n\t\t\t\t\t\t\t\t\tmin=-360.0, soft_min=-360.0,\n\t\t\t\t\t\t\t\t\tmax=360.0, soft_max=360.0,\n\t\t\t\t\t\t\t\t\tdescription=\"End angle\")\n\n\tSimple_sides = IntProperty(name=\"sides\",\n\t\t\t\t\t\t\t   default=3,\n\t\t\t\t\t\t\t   min=0, soft_min=0,\n\t\t\t\t\t\t\t   description=\"sides\")\n\n\tSimple_radius = FloatProperty(name=\"radius\",\n\t\t\t\t\t\t\t\t  default=1.0,\n\t\t\t\t\t\t\t\t  min=0.0, soft_min=0.0,\n\t\t\t\t\t\t\t\t  unit='LENGTH',\n\t\t\t\t\t\t\t\t  description=\"radius\")\n\n\tSimple_center = BoolProperty(name=\"Length center\",\n\t\t\t\t\t\t\t\t default=True,\n\t\t\t\t\t\t\t\t description=\"Length center\")\n\n\tAngle_types = [('Degrees', 'Degrees', 'Degrees'),\n\t\t\t\t   ('Radians', 'Radians', 'Radians')]\n\tSimple_degrees_or_radians = EnumProperty(name=\"Degrees or radians\",\n\t\t\t\t\t\t\t\t\t\t\t description=\"Degrees or radians\",\n\t\t\t\t\t\t\t\t\t\t\t items=Angle_types)\n\n\t# Rectangle properties\n\tSimple_width = FloatProperty(name=\"Width\",\n\t\t\t\t\t\t\t\t default=2.0,\n\t\t\t\t\t\t\t\t min=0.0, soft_min=0,\n\t\t\t\t\t\t\t\t unit='LENGTH',\n\t\t\t\t\t\t\t\t description=\"Width\")\n\tSimple_length = FloatProperty(name=\"Length\",\n\t\t\t\t\t\t\t\t  default=2.0,\n\t\t\t\t\t\t\t\t  min=0.0, soft_min=0.0,\n\t\t\t\t\t\t\t\t  unit='LENGTH',\n\t\t\t\t\t\t\t\t  description=\"Length\")\n\tSimple_rounded = FloatProperty(name=\"Rounded\",\n\t\t\t\t\t\t\t\t   default=0.0,\n\t\t\t\t\t\t\t\t   min=0.0, soft_min=0.0,\n\t\t\t\t\t\t\t\t   unit='LENGTH',\n\t\t\t\t\t\t\t\t   description=\"Rounded\")\n\n\t# Curve Options\n\tshapeItems = [\n\t\t('2D', '2D', '2D'),\n\t\t('3D', '3D', '3D')]\n\tshape = EnumProperty(name=\"2D / 3D\",\n\t\t\t\t\t\t items=shapeItems,\n\t\t\t\t\t\t description=\"2D or 3D Curve\")\n\n\t##### DRAW #####\n\tdef draw(self, context):\n\t\tlayout = self.layout\n\n\t\t# general options\n\t\tcol = layout.column()\n\t\tcol.prop(self, 'Simple_Type')\n\n\t\tl = 0\n\t\ts = 0\n\n\t\tif self.Simple_Type == 'Line':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_endlocation')\n\t\t\tv = Vector(self.Simple_endlocation) - Vector(self.Simple_startlocation)\n\t\t\tl = v.length\n\n\t\tif self.Simple_Type == 'Distance':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_length')\n\t\t\tbox.prop(self, 'Simple_center')\n\t\t\tl = self.Simple_length\n\n\t\tif self.Simple_Type == 'Angle':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_length')\n\t\t\tbox.prop(self, 'Simple_angle')\n\t\t\trow = layout.row()\n\t\t\trow.prop(self, 'Simple_degrees_or_radians', expand=True)\n\n\t\tif self.Simple_Type == 'Circle':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_sides')\n\t\t\tbox.prop(self, 'Simple_radius')\n\t\t\tl = 2 * pi * abs(self.Simple_radius)\n\t\t\ts = pi * self.Simple_radius * self.Simple_radius\n\n\t\tif self.Simple_Type == 'Ellipse':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_a')\n\t\t\tbox.prop(self, 'Simple_b')\n\t\t\tl = pi * (3 * (self.Simple_a + self.Simple_b) - sqrt((3 * self.Simple_a + self.Simple_b) * (self.Simple_a + 3 * self.Simple_b)))\n\t\t\ts = pi * abs(self.Simple_b) * abs(self.Simple_a)\n\n\t\tif self.Simple_Type == 'Arc':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_sides')\n\t\t\tbox.prop(self, 'Simple_radius')\n\t\t\tbox.prop(self, 'Simple_startangle')\n\t\t\tbox.prop(self, 'Simple_endangle')\n\t\t\trow = layout.row()\n\t\t\trow.prop(self, 'Simple_degrees_or_radians', expand=True)\n\t\t\tl = abs(pi * self.Simple_radius * (self.Simple_endangle - self.Simple_startangle) / 180)\n\n\t\tif self.Simple_Type == 'Sector':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_sides')\n\t\t\tbox.prop(self, 'Simple_radius')\n\t\t\tbox.prop(self, 'Simple_startangle')\n\t\t\tbox.prop(self, 'Simple_endangle')\n\t\t\trow = layout.row()\n\t\t\trow.prop(self, 'Simple_degrees_or_radians', expand=True)\n\t\t\tl = abs(pi * self.Simple_radius * (self.Simple_endangle - self.Simple_startangle) / 180) + self.Simple_radius * 2\n\t\t\ts = pi * self.Simple_radius * self.Simple_radius * abs(self.Simple_endangle - self.Simple_startangle) / 360\n\n\t\tif self.Simple_Type == 'Segment':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_sides')\n\t\t\tbox.prop(self, 'Simple_a')\n\t\t\tbox.prop(self, 'Simple_b')\n\t\t\tbox.prop(self, 'Simple_startangle')\n\t\t\tbox.prop(self, 'Simple_endangle')\n\t\t\trow = layout.row()\n\t\t\trow.prop(self, 'Simple_degrees_or_radians', expand=True)\n\t\t\tla = abs(pi * self.Simple_a * (self.Simple_endangle - self.Simple_startangle) / 180)\n\t\t\tlb = abs(pi * self.Simple_b * (self.Simple_endangle - self.Simple_startangle) / 180)\n\t\t\tl = abs(self.Simple_a - self.Simple_b) * 2 + la + lb\n\t\t\tsa = pi * self.Simple_a * self.Simple_a * abs(self.Simple_endangle - self.Simple_startangle) / 360\n\t\t\tsb = pi * self.Simple_b * self.Simple_b * abs(self.Simple_endangle - self.Simple_startangle) / 360\n\t\t\ts = abs(sa - sb)\n\n\t\tif self.Simple_Type == 'Rectangle':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_width')\n\t\t\tbox.prop(self, 'Simple_length')\n\t\t\tbox.prop(self, 'Simple_rounded')\n\t\t\tbox.prop(self, 'Simple_center')\n\t\t\tl = 2 * abs(self.Simple_width) + 2 * abs(self.Simple_length)\n\t\t\ts = abs(self.Simple_width) * abs(self.Simple_length)\n\n\t\tif self.Simple_Type == 'Rhomb':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_width')\n\t\t\tbox.prop(self, 'Simple_length')\n\t\t\tbox.prop(self, 'Simple_center')\n\t\t\tg = hypot(self.Simple_width / 2, self.Simple_length / 2)\n\t\t\tl = 4 * g\n\t\t\ts = self.Simple_width * self.Simple_length / 2\n\n\t\tif self.Simple_Type == 'Polygon':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_sides')\n\t\t\tbox.prop(self, 'Simple_radius')\n\n\t\tif self.Simple_Type == 'Polygon_ab':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_sides')\n\t\t\tbox.prop(self, 'Simple_a')\n\t\t\tbox.prop(self, 'Simple_b')\n\n\t\tif self.Simple_Type == 'Trapezoid':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_a')\n\t\t\tbox.prop(self, 'Simple_b')\n\t\t\tbox.prop(self, 'Simple_h')\n\t\t\tbox.prop(self, 'Simple_center')\n\t\t\tg = hypot(self.Simple_h, (self.Simple_a - self.Simple_b) / 2)\n\t\t\tl = self.Simple_a + self.Simple_b + g * 2\n\t\t\ts = (abs(self.Simple_a) + abs(self.Simple_b)) / 2 * self.Simple_h\n\n\t\trow = layout.row()\n\t\trow.prop(self, 'shape', expand=True)\n\t\tbox = layout.box()\n\t\tbox.label(\"Location:\")\n\t\tbox.prop(self, 'Simple_startlocation')\n\t\tbox = layout.box()\n\t\tbox.label(\"Rotation:\")\n\t\tbox.prop(self, 'Simple_rotation_euler')\n\t\tif l != 0:\n\t\t\tl_str = str(round(l, 4))\n\t\t\trow = layout.row()\n\t\t\trow.label(\"Length: \" + l_str)\n\t\tif s != 0:\n\t\t\ts_str = str(round(s, 4))\n\t\t\trow = layout.row()\n\t\t\trow.label(\"Area: \" + s_str)\n\n\t##### POLL #####\n\t@classmethod\n\tdef poll(cls, context):\n\t\treturn context.scene != None\n\n\t##### EXECUTE #####\n\tdef execute(self, context):\n\t\tif self.Simple_Change:\n\t\t\tSimpleDelete(self.Simple_Delete)\n\n\t\t# go to object mode\n\t\tif bpy.ops.object.mode_set.poll():\n\t\t\tbpy.ops.object.mode_set(mode='OBJECT')\n\n\t\t# turn off undo\n\t\tundo = bpy.context.user_preferences.edit.use_global_undo\n\t\tbpy.context.user_preferences.edit.use_global_undo = False\n\n\t\t# main function\n\t\tself.align_matrix = align_matrix(context, self.Simple_startlocation)\n\t\tmain(context, self, self.align_matrix)\n\n\t\t# restore pre operator undo state\n\t\tbpy.context.user_preferences.edit.use_global_undo = undo\n\n\t\treturn {'FINISHED'}\n\n\t##### INVOKE #####\n\tdef invoke(self, context, event):\n\t\t# store creation_matrix\n\t\tif self.Simple_Change:\n\t\t\tbpy.context.scene.cursor_location = self.Simple_startlocation\n\t\telse:\n\t\t\tself.Simple_startlocation = bpy.context.scene.cursor_location\n\n\t\tself.align_matrix = align_matrix(context, self.Simple_startlocation)\n\t\tself.execute(context)\n\n\t\treturn {'FINISHED'}\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "class", "name": "BezierPointsFillet", "data": "class BezierPointsFillet(bpy.types.Operator):\n\t''''''\n\tbl_idname = \"curve.bezier_points_fillet\"\n\tbl_label = \"Bezier points fillet\"\n\tbl_options = {'REGISTER', 'UNDO'}\n\tbl_description = \"bezier points fillet\"\n\n\tFillet_radius = FloatProperty(name=\"Radius\",\n\t\t\t\t\t\t\t\t  default=0.25,\n\t\t\t\t\t\t\t\t  unit='LENGTH',\n\t\t\t\t\t\t\t\t  description=\"radius\")\n\n\tTypes = [('Round', 'Round', 'Round'),\n\t\t\t ('Chamfer', 'Chamfer', 'Chamfer')]\n\tFillet_Type = EnumProperty(name=\"Type\",\n\t\t\t\t\t\t\t   description=\"Fillet type\",\n\t\t\t\t\t\t\t   items=Types)\n\n\t##### DRAW #####\n\tdef draw(self, context):\n\t\tlayout = self.layout\n\n\t\t# general options\n\t\tcol = layout.column()\n\t\tcol.prop(self, 'Fillet_radius')\n\t\tcol.prop(self, 'Fillet_Type', expand=True)\n\n\t##### POLL #####\n\t@classmethod\n\tdef poll(cls, context):\n\t\treturn context.scene != None\n\n\t##### EXECUTE #####\n\tdef execute(self, context):\n\t\t# go to object mode\n\t\tif bpy.ops.object.mode_set.poll():\n\t\t\tbpy.ops.object.mode_set(mode='OBJECT')\n\t\t\tbpy.ops.object.mode_set(mode='EDIT')\n\n\t\t# turn off undo\n\t\tundo = bpy.context.user_preferences.edit.use_global_undo\n\t\tbpy.context.user_preferences.edit.use_global_undo = False\n\n\t\t# main function\n\t\tspline = bpy.context.object.data.splines.active\n\t\tselected = [p for p in spline.bezier_points if p.select_control_point]\n\n\t\tbpy.ops.curve.handle_type_set(type='VECTOR')\n\t\tn = 0\n\t\tii = []\n\t\tfor p in spline.bezier_points:\n\t\t\tif p.select_control_point:\n\t\t\t\tii.append(n)\n\t\t\t\tn += 1\n\t\t\telse:\n\t\t\t\tn += 1\n\n\t\tif n > 2:\n\n\t\t\tjn = 0\n\n\t\t\tfor j in ii:\n\n\t\t\t\tj += jn\n\n\t\t\t\tselected_all = [p for p in spline.bezier_points]\n\n\t\t\t\tbpy.ops.curve.select_all(action='DESELECT')\n\n\t\t\t\tif j != 0 and j != n - 1:\n\t\t\t\t\tselected_all[j].select_control_point = True\n\t\t\t\t\tselected_all[j + 1].select_control_point = True\n\t\t\t\t\tbpy.ops.curve.subdivide()\n\t\t\t\t\tselected_all = [p for p in spline.bezier_points]\n\t\t\t\t\tselected4 = [selected_all[j - 1], selected_all[j], selected_all[j + 1], selected_all[j + 2]]\n\t\t\t\t\tjn += 1\n\t\t\t\t\tn += 1\n\n\t\t\t\telif j == 0:\n\t\t\t\t\tselected_all[j].select_control_point = True\n\t\t\t\t\tselected_all[j + 1].select_control_point = True\n\t\t\t\t\tbpy.ops.curve.subdivide()\n\t\t\t\t\tselected_all = [p for p in spline.bezier_points]\n\t\t\t\t\tselected4 = [selected_all[n], selected_all[0], selected_all[1], selected_all[2]]\n\t\t\t\t\tjn += 1\n\t\t\t\t\tn += 1\n\n\t\t\t\telif j == n - 1:\n\t\t\t\t\tselected_all[j].select_control_point = True\n\t\t\t\t\tselected_all[j - 1].select_control_point = True\n\t\t\t\t\tbpy.ops.curve.subdivide()\n\t\t\t\t\tselected_all = [p for p in spline.bezier_points]\n\t\t\t\t\tselected4 = [selected_all[0], selected_all[n], selected_all[n - 1], selected_all[n - 2]]\n\n\t\t\t\tselected4[2].co = selected4[1].co\n\t\t\t\ts1 = Vector(selected4[0].co) - Vector(selected4[1].co)\n\t\t\t\ts2 = Vector(selected4[3].co) - Vector(selected4[2].co)\n\t\t\t\ts1.normalize()\n\t\t\t\ts11 = Vector(selected4[1].co) + s1 * self.Fillet_radius\n\t\t\t\tselected4[1].co = s11\n\t\t\t\ts2.normalize()\n\t\t\t\ts22 = Vector(selected4[2].co) + s2 * self.Fillet_radius\n\t\t\t\tselected4[2].co = s22\n\n\t\t\t\tif self.Fillet_Type == 'Round':\n\t\t\t\t\tif j != n - 1:\n\t\t\t\t\t\tselected4[2].handle_right_type = 'VECTOR'\n\t\t\t\t\t\tselected4[1].handle_left_type = 'VECTOR'\n\t\t\t\t\t\tselected4[1].handle_right_type = 'ALIGNED'\n\t\t\t\t\t\tselected4[2].handle_left_type = 'ALIGNED'\n\t\t\t\t\telse:\n\t\t\t\t\t\tselected4[1].handle_right_type = 'VECTOR'\n\t\t\t\t\t\tselected4[2].handle_left_type = 'VECTOR'\n\t\t\t\t\t\tselected4[2].handle_right_type = 'ALIGNED'\n\t\t\t\t\t\tselected4[1].handle_left_type = 'ALIGNED'\n\t\t\t\tif self.Fillet_Type == 'Chamfer':\n\t\t\t\t\tselected4[2].handle_right_type = 'VECTOR'\n\t\t\t\t\tselected4[1].handle_left_type = 'VECTOR'\n\t\t\t\t\tselected4[1].handle_right_type = 'VECTOR'\n\t\t\t\t\tselected4[2].handle_left_type = 'VECTOR'\n\n\t\tbpy.ops.curve.select_all(action='SELECT')\n\t\tbpy.ops.curve.spline_type_set(type='BEZIER')\n\n\t\t# restore pre operator undo state\n\t\tbpy.context.user_preferences.edit.use_global_undo = undo\n\n\t\treturn {'FINISHED'}\n\n\t##### INVOKE #####\n\tdef invoke(self, context, event):\n\t\tself.execute(context)\n\n\t\treturn {'FINISHED'}\n\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "subdivide_cubic_bezier", "data": "def subdivide_cubic_bezier(p1, p2, p3, p4, t):\n\tp12 = (p2 - p1) * t + p1\n\tp23 = (p3 - p2) * t + p2\n\tp34 = (p4 - p3) * t + p3\n\tp123 = (p23 - p12) * t + p12\n\tp234 = (p34 - p23) * t + p23\n\tp1234 = (p234 - p123) * t + p123\n\treturn [p12, p123, p1234, p234, p34]\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "class", "name": "BezierDivide", "data": "class BezierDivide(bpy.types.Operator):\n\t''''''\n\tbl_idname = \"curve.bezier_spline_divide\"\n\tbl_label = \"Bezier spline divide\"\n\tbl_options = {'REGISTER', 'UNDO'}\n\tbl_description = \"bezier spline divide\"\n\n\t# align_matrix for the invoke\n\talign_matrix = Matrix()\n\n\tBezier_t = FloatProperty(name=\"t (0% - 100%)\",\n\t\t\t\t\t\t\t default=50.0,\n\t\t\t\t\t\t\t min=0.0, soft_min=0.0,\n\t\t\t\t\t\t\t max=100.0, soft_max=100.0,\n\t\t\t\t\t\t\t description=\"t (0% - 100%)\")\n\n\t##### POLL #####\n\t@classmethod\n\tdef poll(cls, context):\n\t\treturn context.scene != None\n\n\t##### EXECUTE #####\n\tdef execute(self, context):\n\t\t# go to object mode\n\t\tif bpy.ops.object.mode_set.poll():\n\t\t\tbpy.ops.object.mode_set(mode='OBJECT')\n\t\t\tbpy.ops.object.mode_set(mode='EDIT')\n\n\t\t# turn off undo\n\t\tundo = bpy.context.user_preferences.edit.use_global_undo\n\t\tbpy.context.user_preferences.edit.use_global_undo = False\n\n\t\t# main function\n\t\tspline = bpy.context.object.data.splines.active\n\t\tvertex = []\n\t\tselected_all = [p for p in spline.bezier_points if p.select_control_point]\n\t\th = subdivide_cubic_bezier(selected_all[0].co, selected_all[0].handle_right, selected_all[1].handle_left, selected_all[1].co, self.Bezier_t / 100)\n\n\t\tselected_all[0].handle_right_type = 'FREE'\n\t\tselected_all[0].handle_left_type = 'FREE'\n\t\tselected_all[1].handle_right_type = 'FREE'\n\t\tselected_all[1].handle_left_type = 'FREE'\n\t\tbpy.ops.curve.subdivide(1)\n\t\tselected_all = [p for p in spline.bezier_points if p.select_control_point]\n\n\t\tselected_all[0].handle_right = h[0]\n\t\tselected_all[1].co = h[2]\n\t\tselected_all[1].handle_left = h[1]\n\t\tselected_all[1].handle_right = h[3]\n\t\tselected_all[2].handle_left = h[4]\n\n\t\t# restore pre operator undo state\n\t\tbpy.context.user_preferences.edit.use_global_undo = undo\n\n\t\treturn {'FINISHED'}\n\n\t##### INVOKE #####\n\tdef invoke(self, context, event):\n\t\tself.execute(context)\n\n\t\treturn {'FINISHED'}\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "class", "name": "SimplePanel", "data": "class SimplePanel(bpy.types.Panel):\n\t''''''\n\tbl_idname = \"OBJECT_PT_properties_simple\"\n\tbl_label = \"Simple change\"\n\tbl_description = \"Simple change\"\n\tbl_space_type = \"PROPERTIES\"\n\tbl_region_type = \"WINDOW\"\n\tbl_context = \"object\"\n\n\t##### POLL #####\n\t@classmethod\n\tdef poll(cls, context):\n\t\tif context.object.Simple == True:\n\t\t\treturn (context.object)\n\n\t##### DRAW #####\n\tdef draw(self, context):\n\t\tif context.object.Simple == True:\n\t\t\tlayout = self.layout\n\n\t\t\tobj = context.object\n\t\t\trow = layout.row()\n\t\t\tsimple_change = row.operator(\"curve.simple\", text='Change')\n\t\t\tsimple_change.Simple_Change = True\n\t\t\tsimple_change.Simple_Delete = obj.name\n\t\t\tsimple_change.Simple_Type = obj.Simple_Type\n\t\t\tsimple_change.Simple_startlocation = obj.location\n\t\t\tsimple_change.Simple_endlocation = obj.Simple_endlocation\n\t\t\tsimple_change.Simple_a = obj.Simple_a\n\t\t\tsimple_change.Simple_b = obj.Simple_b\n\t\t\tsimple_change.Simple_h = obj.Simple_h\n\t\t\tsimple_change.Simple_angle = obj.Simple_angle\n\t\t\tsimple_change.Simple_startangle = obj.Simple_startangle\n\t\t\tsimple_change.Simple_endangle = obj.Simple_endangle\n\t\t\tsimple_change.Simple_rotation_euler = obj.rotation_euler\n\t\t\tsimple_change.Simple_sides = obj.Simple_sides\n\t\t\tsimple_change.Simple_radius = obj.Simple_radius\n\t\t\tsimple_change.Simple_center = obj.Simple_center\n\t\t\tsimple_change.Simple_width = obj.Simple_width\n\t\t\tsimple_change.Simple_length = obj.Simple_length\n\t\t\tsimple_change.Simple_rounded = obj.Simple_rounded\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "class", "name": "SimpleEdit", "data": "class SimpleEdit(bpy.types.Panel):\n\t''''''\n\tbl_idname = \"OBJECT_PT_simple_edit\"\n\tbl_label = \"Simple edit\"\n\tbl_description = \"Simple edit\"\n\tbl_space_type = 'VIEW_3D'\n\tbl_region_type = 'TOOLS'\n\n\t##### POLL #####\n\t@classmethod\n\tdef poll(cls, context):\n\t\tvertex = []\n\t\tnselected = []\n\t\tn = 0\n\t\tobj = context.active_object\n\t\tif obj != None:\n\t\t\tif obj.type == 'CURVE':\n\t\t\t\tfor i in obj.data.splines:\n\t\t\t\t\tfor j in i.bezier_points:\n\t\t\t\t\t\tn += 1\n\t\t\t\t\t\tif j.select_control_point:\n\t\t\t\t\t\t\tnselected.append(n)\n\t\t\t\t\t\t\tvertex.append(obj.matrix_world * j.co)\n\n\t\t\tif len(vertex) > 0 and n > 2:\n\t\t\t\treturn (context.active_object)\n\t\t\tif len(vertex) == 2 and abs(nselected[0] - nselected[1]) == 1:\n\t\t\t\treturn (context.active_object)\n\n\t\tselected = 0\n\t\tfor obj in context.selected_objects:\n\t\t\tif obj.type == 'CURVE':\n\t\t\t\tselected += 1\n\n\t\tif selected >= 2:\n\t\t\treturn (context.selected_objects)\n\n\t##### DRAW #####\n\tdef draw(self, context):\n\t\tvertex = []\n\t\tselected = []\n\t\tn = 0\n\t\tobj = context.active_object\n\t\tif obj != None:\n\t\t\tif obj.type == 'CURVE':\n\t\t\t\tfor i in obj.data.splines:\n\t\t\t\t\tfor j in i.bezier_points:\n\t\t\t\t\t\tn += 1\n\t\t\t\t\t\tif j.select_control_point:\n\t\t\t\t\t\t\tselected.append(n)\n\t\t\t\t\t\t\tvertex.append(obj.matrix_world * j.co)\n\n\t\t\tif len(vertex) > 0 and n > 2:\n\t\t\t\tlayout = self.layout\n\t\t\t\trow = layout.row()\n\t\t\t\tsimple_edit = row.operator(\"curve.bezier_points_fillet\", text='Fillet')\n\t\t\tif len(vertex) == 2 and abs(selected[0] - selected[1]) == 1:\n\t\t\t\tlayout = self.layout\n\t\t\t\trow = layout.row()\n\t\t\t\tsimple_divide = row.operator(\"curve.bezier_spline_divide\", text='Divide')\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "StartLocationUpdate", "data": "def StartLocationUpdate(self, context):\n\n\tbpy.context.scene.cursor_location = self.Simple_startlocation\n\n\treturn\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleVariables", "data": "def SimpleVariables():\n\n\tbpy.types.Object.Simple = bpy.props.BoolProperty()\n\tbpy.types.Object.Simple_Change = bpy.props.BoolProperty()\n\t# general properties\n\tTypes = [('Point', 'Point', 'Point'),\n\t\t\t ('Line', 'Line', 'Line'),\n\t\t\t ('Distance', 'Distance', 'Distance'),\n\t\t\t ('Angle', 'Angle', 'Angle'),\n\t\t\t ('Circle', 'Circle', 'Circle'),\n\t\t\t ('Ellipse', 'Ellipse', 'Ellipse'),\n\t\t\t ('Arc', 'Arc', 'Arc'),\n\t\t\t ('Sector', 'Sector', 'Sector'),\n\t\t\t ('Segment', 'Segment', 'Segment'),\n\t\t\t ('Rectangle', 'Rectangle', 'Rectangle'),\n\t\t\t ('Rhomb', 'Rhomb', 'Rhomb'),\n\t\t\t ('Polygon', 'Polygon', 'Polygon'),\n\t\t\t ('Polygon_ab', 'Polygon_ab', 'Polygon_ab'),\n\t\t\t ('Trapezoid', 'Trapezoid', 'Trapezoid')]\n\tbpy.types.Object.Simple_Type = bpy.props.EnumProperty(name=\"Type\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t  description=\"Form of Curve to create\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t  items=Types)\n\n\t# Line properties\n\tbpy.types.Object.Simple_startlocation = bpy.props.FloatVectorProperty(name=\"Start location\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  description=\"Start location\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  default=(0.0, 0.0, 0.0),\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  subtype='TRANSLATION',\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  update=StartLocationUpdate)\n\tbpy.types.Object.Simple_endlocation = bpy.props.FloatVectorProperty(name=\"End location\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdescription=\"End location\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdefault=(2.0, 2.0, 2.0),\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tsubtype='TRANSLATION')\n\tbpy.types.Object.Simple_rotation_euler = bpy.props.FloatVectorProperty(name=\"Rotation\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   description=\"Rotation\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   default=(0.0, 0.0, 0.0),\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   subtype='EULER')\n\n\t# Trapezoid properties\n\tbpy.types.Object.Simple_a = bpy.props.FloatProperty(name=\"a\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tdefault=2.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tmin=0.0, soft_min=0.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tunit='LENGTH',\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tdescription=\"a\")\n\tbpy.types.Object.Simple_b = bpy.props.FloatProperty(name=\"b\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tdefault=1.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tmin=0.0, soft_min=0.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tunit='LENGTH',\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tdescription=\"b\")\n\tbpy.types.Object.Simple_h = bpy.props.FloatProperty(name=\"h\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tdefault=1.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tunit='LENGTH',\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tdescription=\"h\")\n\n\tbpy.types.Object.Simple_angle = bpy.props.FloatProperty(name=\"Angle\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdefault=45.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdescription=\"Angle\")\n\tbpy.types.Object.Simple_startangle = bpy.props.FloatProperty(name=\"Start angle\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t default=0.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t min=-360.0, soft_min=-360.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t max=360.0, soft_max=360.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t description=\"Start angle\")\n\tbpy.types.Object.Simple_endangle = bpy.props.FloatProperty(name=\"End angle\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   default=45.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   min=-360.0, soft_min=-360.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   max=360.0, soft_max=360.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   description=\"End angle\")\n\n\tbpy.types.Object.Simple_sides = bpy.props.IntProperty(name=\"sides\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t  default=3,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t  min=3, soft_min=3,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t  description=\"sides\")\n\n\tbpy.types.Object.Simple_radius = bpy.props.FloatProperty(name=\"radius\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t default=1.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t min=0.0, soft_min=0.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t unit='LENGTH',\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t description=\"radius\")\n\n\tbpy.types.Object.Simple_center = bpy.props.BoolProperty(name=\"Length center\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdefault=True,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdescription=\"Length center\")\n\n\t# Rectangle properties\n\tbpy.types.Object.Simple_width = bpy.props.FloatProperty(name=\"Width\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdefault=2.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tmin=0.0, soft_min=0.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tunit='LENGTH',\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdescription=\"Width\")\n\tbpy.types.Object.Simple_length = bpy.props.FloatProperty(name=\"Length\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t default=2.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t min=0.0, soft_min=0.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t unit='LENGTH',\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t description=\"Length\")\n\tbpy.types.Object.Simple_rounded = bpy.props.FloatProperty(name=\"Rounded\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  default=0.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  unit='LENGTH',\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  description=\"Rounded\")\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "class", "name": "INFO_MT_simple_menu", "data": "class INFO_MT_simple_menu(bpy.types.Menu):\n\t# Define the \"Extras\" menu\n\tbl_idname = \"INFO_MT_simple_menu\"\n\tbl_label = \"Simple\"\n\n\tdef draw(self, context):\n\t\tself.layout.operator_context = 'INVOKE_REGION_WIN'\n\n\t\toper2 = self.layout.operator(Simple.bl_idname, text=\"Point\", icon=\"PLUGIN\")\n\t\toper2.Simple_Change = False\n\t\toper2.Simple_Type = \"Point\"\n\n\t\toper3 = self.layout.operator(Simple.bl_idname, text=\"Line\", icon=\"PLUGIN\")\n\t\toper3.Simple_Change = False\n\t\toper3.Simple_Type = \"Line\"\n\n\t\toper4 = self.layout.operator(Simple.bl_idname, text=\"Distance\", icon=\"PLUGIN\")\n\t\toper4.Simple_Change = False\n\t\toper4.Simple_Type = \"Distance\"\n\n\t\toper5 = self.layout.operator(Simple.bl_idname, text=\"Angle\", icon=\"PLUGIN\")\n\t\toper5.Simple_Change = False\n\t\toper5.Simple_Type = \"Angle\"\n\n\t\toper6 = self.layout.operator(Simple.bl_idname, text=\"Circle\", icon=\"PLUGIN\")\n\t\toper6.Simple_Change = False\n\t\toper6.Simple_Type = \"Circle\"\n\n\t\toper7 = self.layout.operator(Simple.bl_idname, text=\"Ellipse\", icon=\"PLUGIN\")\n\t\toper7.Simple_Change = False\n\t\toper7.Simple_Type = \"Ellipse\"\n\n\t\toper8 = self.layout.operator(Simple.bl_idname, text=\"Arc\", icon=\"PLUGIN\")\n\t\toper8.Simple_Change = False\n\t\toper8.Simple_Type = \"Arc\"\n\n\t\toper9 = self.layout.operator(Simple.bl_idname, text=\"Sector\", icon=\"PLUGIN\")\n\t\toper9.Simple_Change = False\n\t\toper9.Simple_Type = \"Sector\"\n\n\t\toper10 = self.layout.operator(Simple.bl_idname, text=\"Segment\", icon=\"PLUGIN\")\n\t\toper10.Simple_Change = False\n\t\toper10.Simple_Type = \"Segment\"\n\n\t\toper11 = self.layout.operator(Simple.bl_idname, text=\"Rectangle\", icon=\"PLUGIN\")\n\t\toper11.Simple_Change = False\n\t\toper11.Simple_Type = \"Rectangle\"\n\n\t\toper12 = self.layout.operator(Simple.bl_idname, text=\"Rhomb\", icon=\"PLUGIN\")\n\t\toper12.Simple_Change = False\n\t\toper12.Simple_Type = \"Rhomb\"\n\n\t\toper13 = self.layout.operator(Simple.bl_idname, text=\"Polygon\", icon=\"PLUGIN\")\n\t\toper13.Simple_Change = False\n\t\toper13.Simple_Type = \"Polygon\"\n\n\t\toper14 = self.layout.operator(Simple.bl_idname, text=\"Polygon_ab\", icon=\"PLUGIN\")\n\t\toper14.Simple_Change = False\n\t\toper14.Simple_Type = \"Polygon_ab\"\n\n\t\toper15 = self.layout.operator(Simple.bl_idname, text=\"Trapezoid\", icon=\"PLUGIN\")\n\t\toper15.Simple_Change = False\n\t\toper15.Simple_Type = \"Trapezoid\"\n\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "Simple_button", "data": "def Simple_button(self, context):\n\toper11 = self.layout.operator(Simple.bl_idname, text=\"Rectangle\", icon=\"PLUGIN\")\n\toper11.Simple_Change = False\n\toper11.Simple_Type = \"Rectangle\"\n\n\tself.layout.menu(\"INFO_MT_simple_menu\", icon=\"PLUGIN\")\n\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "register", "data": "def register():\n\tbpy.utils.register_module(__name__)\n\n\tbpy.types.INFO_MT_curve_add.append(Simple_button)\n\n\tSimpleVariables()\n\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "unregister", "data": "def unregister():\n\tbpy.utils.unregister_module(__name__)\n\n\tbpy.types.INFO_MT_curve_add.remove(Simple_button)\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}], [{"term": "def", "name": "in_tree", "data": "def in_tree(response, name, uclass, drv, depth, last_child):\n\tlines = [x.strip() for x in response.splitlines()]\n\tleaf = ' ' * 4 * depth;\n\tif not last_child:\n\t\tleaf = leaf + r'\\|'\n\telse:\n\t\tleaf = leaf + '`'\n\tleaf = leaf + '-- ' + name\n\tline = (r' *{:10.10}\t[0-9]*  \\[ [ +] \\]   {:20.20}  {}$'\n\t\t\t.format(uclass, drv, leaf))\n\tprog = re.compile(line)\n\tfor l in lines:\n\t\tif prog.match(l):\n\t\t\treturn True\n\treturn False\n\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}, {"term": "def", "name": "test_bind_unbind_with_node", "data": "def test_bind_unbind_with_node(u_boot_console):\n\n\t#bind /bind-test. Device should come up as well as its children\n\tresponse = u_boot_console.run_command('bind  /bind-test generic_simple_bus')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'generic_simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, False)\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'generic_simple_bus', 1, True)\n\n\t#Unbind child #1. No error expected and all devices should be there except for bind-test-child1\n\tresponse = u_boot_console.run_command('unbind  /bind-test/bind-test-child1')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'generic_simple_bus', 0, True)\n\tassert 'bind-test-child1' not in tree\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'generic_simple_bus', 1, True)\n\n\t#bind child #1. No error expected and all devices should be there\n\tresponse = u_boot_console.run_command('bind  /bind-test/bind-test-child1 phy_sandbox')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'generic_simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, True)\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'generic_simple_bus', 1, False)\n\n\t#Unbind child #2. No error expected and all devices should be there except for bind-test-child2\n\tresponse = u_boot_console.run_command('unbind  /bind-test/bind-test-child2')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'generic_simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, True)\n\tassert 'bind-test-child2' not in tree\n\n\n\t#Bind child #2. No error expected and all devices should be there\n\tresponse = u_boot_console.run_command('bind /bind-test/bind-test-child2 generic_simple_bus')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'generic_simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, False)\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'generic_simple_bus', 1, True)\n\n\t#Unbind parent. No error expected. All devices should be removed and unbound\n\tresponse = u_boot_console.run_command('unbind  /bind-test')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert 'bind-test' not in tree\n\tassert 'bind-test-child1' not in tree\n\tassert 'bind-test-child2' not in tree\n\n\t#try binding invalid node with valid driver\n\tresponse = u_boot_console.run_command('bind  /not-a-valid-node generic_simple_bus')\n\tassert response != ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert 'not-a-valid-node' not in tree\n\n\t#try binding valid node with invalid driver\n\tresponse = u_boot_console.run_command('bind  /bind-test not_a_driver')\n\tassert response != ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert 'bind-test' not in tree\n\n\t#bind /bind-test. Device should come up as well as its children\n\tresponse = u_boot_console.run_command('bind  /bind-test generic_simple_bus')\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test', 'simple_bus', 'generic_simple_bus', 0, True)\n\tassert in_tree(tree, 'bind-test-child1', 'phy', 'phy_sandbox', 1, False)\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'generic_simple_bus', 1, True)\n\n\tresponse = u_boot_console.run_command('unbind  /bind-test')\n\tassert response == ''\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}, {"term": "def", "name": "get_next_line", "data": "def get_next_line(tree, name):\n\ttreelines = [x.strip() for x in tree.splitlines() if x.strip()]\n\tchild_line = ''\n\tfor idx, line in enumerate(treelines):\n\t\tif ('-- ' + name) in line:\n\t\t\ttry:\n\t\t\t\tchild_line = treelines[idx+1]\n\t\t\texcept:\n\t\t\t\tpass\n\t\t\tbreak\n\treturn child_line\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}, {"term": "def", "name": "test_bind_unbind_with_uclass", "data": "def test_bind_unbind_with_uclass(u_boot_console):\n\t#bind /bind-test\n\tresponse = u_boot_console.run_command('bind  /bind-test generic_simple_bus')\n\tassert response == ''\n\n\t#make sure bind-test-child2 is there and get its uclass/index pair\n\ttree = u_boot_console.run_command('dm tree')\n\tchild2_line = [x.strip() for x in tree.splitlines() if '-- bind-test-child2' in x]\n\tassert len(child2_line) == 1\n\n\tchild2_uclass = child2_line[0].split()[0]\n\tchild2_index = int(child2_line[0].split()[1])\n\n\t#bind generic_simple_bus as a child of bind-test-child2\n\tresponse = u_boot_console.run_command('bind  {} {} generic_simple_bus'.format(child2_uclass, child2_index, 'generic_simple_bus'))\n\n\t#check that the child is there and its uclass/index pair is right\n\ttree = u_boot_console.run_command('dm tree')\n\n\tchild_of_child2_line = get_next_line(tree, 'bind-test-child2')\n\tassert child_of_child2_line\n\tchild_of_child2_index = int(child_of_child2_line.split()[1])\n\tassert in_tree(tree, 'generic_simple_bus', 'simple_bus', 'generic_simple_bus', 2, True)\n\tassert child_of_child2_index == child2_index + 1\n\n\t#unbind the child and check it has been removed\n\tresponse = u_boot_console.run_command('unbind  simple_bus {}'.format(child_of_child2_index))\n\tassert response == ''\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'generic_simple_bus', 1, True)\n\tassert not in_tree(tree, 'generic_simple_bus', 'simple_bus', 'generic_simple_bus', 2, True)\n\tchild_of_child2_line = get_next_line(tree, 'bind-test-child2')\n\tassert child_of_child2_line == ''\n\n\t#bind generic_simple_bus as a child of bind-test-child2\n\tresponse = u_boot_console.run_command('bind  {} {} generic_simple_bus'.format(child2_uclass, child2_index, 'generic_simple_bus'))\n\n\t#check that the child is there and its uclass/index pair is right\n\ttree = u_boot_console.run_command('dm tree')\n\ttreelines = [x.strip() for x in tree.splitlines() if x.strip()]\n\n\tchild_of_child2_line = get_next_line(tree, 'bind-test-child2')\n\tassert child_of_child2_line\n\tchild_of_child2_index = int(child_of_child2_line.split()[1])\n\tassert in_tree(tree, 'generic_simple_bus', 'simple_bus', 'generic_simple_bus', 2, True)\n\tassert child_of_child2_index == child2_index + 1\n\n\t#unbind the child and check it has been removed\n\tresponse = u_boot_console.run_command('unbind  {} {} generic_simple_bus'.format(child2_uclass, child2_index, 'generic_simple_bus'))\n\tassert response == ''\n\n\ttree = u_boot_console.run_command('dm tree')\n\tassert in_tree(tree, 'bind-test-child2', 'simple_bus', 'generic_simple_bus', 1, True)\n\n\tchild_of_child2_line = get_next_line(tree, 'bind-test-child2')\n\tassert child_of_child2_line == ''\n\n\t#unbind the child again and check it doesn't change the tree\n\ttree_old = u_boot_console.run_command('dm tree')\n\tresponse = u_boot_console.run_command('unbind  {} {} generic_simple_bus'.format(child2_uclass, child2_index, 'generic_simple_bus'))\n\ttree_new = u_boot_console.run_command('dm tree')\n\n\tassert response == ''\n\tassert tree_old == tree_new\n\n\tresponse = u_boot_console.run_command('unbind  /bind-test')\n\tassert response == ''\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}], [{"term": "def", "name": "trim", "data": "def trim(value, num):\n\treturn value[:num]\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "make_data_div", "data": "def make_data_div(value):\n\t\"\"\"A filter that uses a decorator (@mark_safe).\"\"\"\n\treturn '' % value\n\n", "description": "A filter that uses a decorator (@mark_safe).", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "noop", "data": "def noop(value, param=None):\n\t\"\"\"A noop filter that always return its first argument and does nothing with\n\tits second (optional) one.\n\tUseful for testing out whitespace in filter arguments (see #19882).\"\"\"\n\treturn value\n\n", "description": "A noop filter that always return its first argument and does nothing with\n\tits second (optional) one.\n\tUseful for testing out whitespace in filter arguments (see #19882).", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "context_stack_length", "data": "def context_stack_length(context):\n\treturn len(context.dicts)\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "no_params", "data": "def no_params():\n\t\"\"\"Expected no_params __doc__\"\"\"\n\treturn \"no_params - Expected result\"\n\n", "description": "Expected no_params __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "one_param", "data": "def one_param(arg):\n\t\"\"\"Expected one_param __doc__\"\"\"\n\treturn \"one_param - Expected result: %s\" % arg\n\n", "description": "Expected one_param __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "explicit_no_context", "data": "def explicit_no_context(arg):\n\t\"\"\"Expected explicit_no_context __doc__\"\"\"\n\treturn \"explicit_no_context - Expected result: %s\" % arg\n\n", "description": "Expected explicit_no_context __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "no_params_with_context", "data": "def no_params_with_context(context):\n\t\"\"\"Expected no_params_with_context __doc__\"\"\"\n\treturn \"no_params_with_context - Expected result (context value: %s)\" % context['value']\n\n", "description": "Expected no_params_with_context __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "params_and_context", "data": "def params_and_context(context, arg):\n\t\"\"\"Expected params_and_context __doc__\"\"\"\n\treturn \"params_and_context - Expected result (context value: %s): %s\" % (context['value'], arg)\n\n", "description": "Expected params_and_context __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_two_params", "data": "def simple_two_params(one, two):\n\t\"\"\"Expected simple_two_params __doc__\"\"\"\n\treturn \"simple_two_params - Expected result: %s, %s\" % (one, two)\n\n", "description": "Expected simple_two_params __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_keyword_only_param", "data": "def simple_keyword_only_param(*, kwarg):\n\treturn \"simple_keyword_only_param - Expected result: %s\" % kwarg\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_keyword_only_default", "data": "def simple_keyword_only_default(*, kwarg=42):\n\treturn \"simple_keyword_only_default - Expected result: %s\" % kwarg\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_one_default", "data": "def simple_one_default(one, two='hi'):\n\t\"\"\"Expected simple_one_default __doc__\"\"\"\n\treturn \"simple_one_default - Expected result: %s, %s\" % (one, two)\n\n", "description": "Expected simple_one_default __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_unlimited_args", "data": "def simple_unlimited_args(one, two='hi', *args):\n\t\"\"\"Expected simple_unlimited_args __doc__\"\"\"\n\treturn \"simple_unlimited_args - Expected result: %s\" % (\n\t\t', '.join(str(arg) for arg in [one, two] + list(args))\n\t)\n\n", "description": "Expected simple_unlimited_args __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_only_unlimited_args", "data": "def simple_only_unlimited_args(*args):\n\t\"\"\"Expected simple_only_unlimited_args __doc__\"\"\"\n\treturn \"simple_only_unlimited_args - Expected result: %s\" % ', '.join(str(arg) for arg in args)\n\n", "description": "Expected simple_only_unlimited_args __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_unlimited_args_kwargs", "data": "def simple_unlimited_args_kwargs(one, two='hi', *args, **kwargs):\n\t\"\"\"Expected simple_unlimited_args_kwargs __doc__\"\"\"\n\t# Sort the dictionary by key to guarantee the order for testing.\n\tsorted_kwarg = sorted(kwargs.items(), key=operator.itemgetter(0))\n\treturn \"simple_unlimited_args_kwargs - Expected result: %s / %s\" % (\n\t\t', '.join(str(arg) for arg in [one, two] + list(args)),\n\t\t', '.join('%s=%s' % (k, v) for (k, v) in sorted_kwarg)\n\t)\n\n", "description": "Expected simple_unlimited_args_kwargs __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "simple_tag_without_context_parameter", "data": "def simple_tag_without_context_parameter(arg):\n\t\"\"\"Expected simple_tag_without_context_parameter __doc__\"\"\"\n\treturn \"Expected result\"\n\n", "description": "Expected simple_tag_without_context_parameter __doc__", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "escape_naive", "data": "def escape_naive(context):\n\t\"\"\"A tag that doesn't even think about escaping issues\"\"\"\n\treturn \"Hello {0}!\".format(context['name'])\n\n", "description": "A tag that doesn't even think about escaping issues", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "escape_explicit", "data": "def escape_explicit(context):\n\t\"\"\"A tag that uses escape explicitly\"\"\"\n\treturn escape(\"Hello {0}!\".format(context['name']))\n\n", "description": "A tag that uses escape explicitly", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "escape_format_html", "data": "def escape_format_html(context):\n\t\"\"\"A tag that uses format_html\"\"\"\n\treturn format_html(\"Hello {0}!\", context['name'])\n\n", "description": "A tag that uses format_html", "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "current_app", "data": "def current_app(context):\n\treturn \"%s\" % context.current_app\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "use_l10n", "data": "def use_l10n(context):\n\treturn \"%s\" % context.use_l10n\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "minustwo_overridden_name", "data": "def minustwo_overridden_name(value):\n\treturn value - 2\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "def", "name": "counter", "data": "def counter(parser, token):\n\treturn CounterNode()\n\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}, {"term": "class", "name": "CounterNode", "data": "class CounterNode(template.Node):\n\tdef __init__(self):\n\t\tself.count = 0\n\n\tdef render(self, context):\n\t\tcount = self.count\n\t\tself.count = count + 1\n\t\treturn count\n", "description": null, "category": "simple", "imports": ["import operator", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils.html import escape, format_html", "from django.utils.safestring import mark_safe"]}], [{"term": "class", "name": "GLUnurbs", "data": "class GLUnurbs(glustruct.GLUStruct, _simple.GLUnurbs):\n\t\"\"\"GLU Nurbs structure with oor and callback storage support\n\n\tIMPORTANT NOTE: the texture coordinate callback receives a raw ctypes\n\tdata-pointer, as without knowing what type of evaluation is being done\n\t(1D or 2D) we cannot safely determine the size of the array to convert\n\tit.  This is a limitation of the C implementation.  To convert to regular\n\tdata-pointer, just call yourNurb.ptrAsArray( ptr, size, arrays.GLfloatArray )\n\twith the size of data you expect.\n\t\"\"\"\n\tFUNCTION_TYPE = PLATFORM.functionTypeFor(PLATFORM.GLU)\n\tCALLBACK_FUNCTION_REGISTRARS = {\n\t\t# mapping from \"which\" to a function that should take 3 parameters,\n\t\t# the nurb, the which and the function pointer...\n\t}\n\tCALLBACK_TYPES = {\n\t\t# mapping from \"which\" GLU enumeration to a ctypes function type\n\t\t_simple.GLU_NURBS_BEGIN: FUNCTION_TYPE(\n\t\t\tNone, _simple.GLenum\n\t\t),\n\t\t_simple.GLU_NURBS_BEGIN_DATA: FUNCTION_TYPE(\n\t\t\tNone, _simple.GLenum, ctypes.POINTER(_simple.GLvoid)\n\t\t),\n\t\t_simple.GLU_NURBS_VERTEX: FUNCTION_TYPE(\n\t\t\tNone, ctypes.POINTER(_simple.GLfloat)\n\t\t),\n\t\t_simple.GLU_NURBS_VERTEX_DATA: FUNCTION_TYPE(\n\t\t\tNone, ctypes.POINTER(_simple.GLfloat), ctypes.POINTER(_simple.GLvoid)\n\t\t),\n\t\t_simple.GLU_NURBS_NORMAL: FUNCTION_TYPE(\n\t\t\tNone, ctypes.POINTER(_simple.GLfloat)\n\t\t),\n\t\t_simple.GLU_NURBS_NORMAL_DATA: FUNCTION_TYPE(\n\t\t\tNone, ctypes.POINTER(_simple.GLfloat), ctypes.POINTER(_simple.GLvoid)\n\t\t),\n\t\t_simple.GLU_NURBS_COLOR: FUNCTION_TYPE(\n\t\t\tNone, ctypes.POINTER(_simple.GLfloat)\n\t\t),\n\t\t_simple.GLU_NURBS_COLOR_DATA: FUNCTION_TYPE(\n\t\t\tNone, ctypes.POINTER(_simple.GLfloat), ctypes.POINTER(_simple.GLvoid)\n\t\t),\n\t\t_simple.GLU_NURBS_TEXTURE_COORD: FUNCTION_TYPE(\n\t\t\tNone, ctypes.POINTER(_simple.GLfloat)\n\t\t),\n\t\t_simple.GLU_NURBS_TEXTURE_COORD_DATA: FUNCTION_TYPE(\n\t\t\tNone, ctypes.POINTER(_simple.GLfloat), ctypes.POINTER(_simple.GLvoid)\n\t\t),\n\t\t_simple.GLU_NURBS_END:FUNCTION_TYPE(\n\t\t\tNone\n\t\t),\n\t\t_simple.GLU_NURBS_END_DATA: FUNCTION_TYPE(\n\t\t\tNone, ctypes.POINTER(_simple.GLvoid)\n\t\t),\n\t\t_simple.GLU_NURBS_ERROR:FUNCTION_TYPE(\n\t\t\tNone, _simple.GLenum,\n\t\t),\n\t}\n\tWRAPPER_METHODS = {\n\t\t_simple.GLU_NURBS_BEGIN: None,\n\t\t_simple.GLU_NURBS_BEGIN_DATA: '_justOOR',\n\t\t_simple.GLU_NURBS_VERTEX: '_vec3',\n\t\t_simple.GLU_NURBS_VERTEX_DATA: '_vec3',\n\t\t_simple.GLU_NURBS_NORMAL: '_vec3',\n\t\t_simple.GLU_NURBS_NORMAL_DATA: '_vec3',\n\t\t_simple.GLU_NURBS_COLOR: '_vec4',\n\t\t_simple.GLU_NURBS_COLOR_DATA: '_vec4',\n\t\t_simple.GLU_NURBS_TEXTURE_COORD: '_tex',\n\t\t_simple.GLU_NURBS_TEXTURE_COORD_DATA: '_tex',\n\t\t_simple.GLU_NURBS_END: None,\n\t\t_simple.GLU_NURBS_END_DATA: '_justOOR',\n\t\t_simple.GLU_NURBS_ERROR: None,\n\t}\n\tdef _justOOR( self, function ):\n\t\t\"\"\"Just do OOR on the last argument...\"\"\"\n\t\tdef getOOR( *args ):\n\t\t\targs = args[:-1] + (self.originalObject(args[-1]),)\n\t\t\treturn function( *args )\n\t\treturn getOOR\n\tdef _vec3( self, function, size=3 ):\n\t\t\"\"\"Convert first arg to size-element array, do OOR on arg2 if present\"\"\"\n\t\tdef vec( *args ):\n\t\t\tvec = self.ptrAsArray(args[0],size,arrays.GLfloatArray)\n\t\t\tif len(args) > 1:\n\t\t\t\toor = self.originalObject(args[1])\n\t\t\t\treturn function( vec, oor )\n\t\t\telse:\n\t\t\t\treturn function( vec )\n\t\treturn vec\n\tdef _vec4( self, function ):\n\t\t\"\"\"Size-4 vector version...\"\"\"\n\t\treturn self._vec3( function, 4 )\n\tdef _tex( self, function ):\n\t\t\"\"\"Texture coordinate callback\n\n\t\tNOTE: there is no way for *us* to tell what size the array is, you will\n\t\tget back a raw data-point, not an array, as you do for all other callback\n\t\ttypes!!!\n\t\t\"\"\"\n\t\tdef oor( *args ):\n\t\t\tif len(args) > 1:\n\t\t\t\toor = self.originalObject(args[1])\n\t\t\t\treturn function( args[0], oor )\n\t\t\telse:\n\t\t\t\treturn function( args[0] )\n\t\treturn oor\n", "description": "GLU Nurbs structure with oor and callback storage support\n\n\tIMPORTANT NOTE: the texture coordinate callback receives a raw ctypes\n\tdata-pointer, as without knowing what type of evaluation is being done\n\t(1D or 2D) we cannot safely determine the size of the array to convert\n\tit.  This is a limitation of the C implementation.  To convert to regular\n\tdata-pointer, just call yourNurb.ptrAsArray( ptr, size, arrays.GLfloatArray )\n\twith the size of data you expect.\n\t", "category": "simple", "imports": ["from OpenGL.raw import GLU as _simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy as _lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL", "from OpenGL import _configflags"]}, {"term": "def", "name": "_callbackWithType", "data": "def _callbackWithType( funcType ):\n\t\"\"\"Get gluNurbsCallback function with set last arg-type\"\"\"\n\tresult =  platform.copyBaseFunction(\n\t\t_simple.gluNurbsCallback\n\t)\n\tresult.argtypes = [ctypes.POINTER(GLUnurbs), _simple.GLenum, funcType]\n\tassert result.argtypes[-1] == funcType\n\treturn result\n", "description": "Get gluNurbsCallback function with set last arg-type", "category": "simple", "imports": ["from OpenGL.raw import GLU as _simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy as _lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL", "from OpenGL import _configflags"]}, {"term": "def", "name": "gluNurbsCallback", "data": "def gluNurbsCallback( nurb, which, CallBackFunc ):\n\t\"\"\"Dispatch to the nurb's addCallback operation\"\"\"\n\treturn nurb.addCallback( which, CallBackFunc )\n", "description": "Dispatch to the nurb's addCallback operation", "category": "simple", "imports": ["from OpenGL.raw import GLU as _simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy as _lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL", "from OpenGL import _configflags"]}, {"term": "def", "name": "gluNewNurbsRenderer", "data": "def gluNewNurbsRenderer( baseFunction ):\n\t\"\"\"Return a new nurbs renderer for the system (dereferences pointer)\"\"\"\n\tnewSet = baseFunction()\n\tnew = newSet[0]\n\t#new.__class__ = GLUnurbs # yes, I know, ick\n\treturn new\n", "description": "Return a new nurbs renderer for the system (dereferences pointer)", "category": "simple", "imports": ["from OpenGL.raw import GLU as _simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy as _lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL", "from OpenGL import _configflags"]}, {"term": "def", "name": "gluNurbsCallbackData", "data": "def gluNurbsCallbackData( baseFunction, nurb, userData ):\n\t\"\"\"Note the Python object for use as userData by the nurb\"\"\"\n\treturn baseFunction(\n\t\tnurb, nurb.noteObject( userData )\n\t)\n", "description": "Note the Python object for use as userData by the nurb", "category": "simple", "imports": ["from OpenGL.raw import GLU as _simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy as _lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL", "from OpenGL import _configflags"]}, {"term": "def", "name": "checkOrder", "data": "def checkOrder( order,knotCount,name ):\n\t\"\"\"Check that order is valid...\"\"\"\n\tif order < 1:\n\t\traise error.GLUError(\n\t\t\t\"\"\"%s should be 1 or more, is %s\"\"\"%( name,order,)\n\t\t)\n\telif order > MAX_ORDER:\n\t\traise error.GLUError(\n\t\t\t\"\"\"%s should be %s or less, is %s\"\"\"%( name, MAX_ORDER, order)\n\t\t)\n\telif knotCount < (2*order):\n\t\traise error.GLUError(\n\t\t\t\"\"\"Knotcount must be at least 2x %s is %s should be at least %s\"\"\"%( name, knotCount, 2*order)\n", "description": "Check that order is valid...", "category": "simple", "imports": ["from OpenGL.raw import GLU as _simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy as _lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL", "from OpenGL import _configflags"]}, {"term": "def", "name": "checkKnots", "data": "def checkKnots( knots, name ):\n\t\"\"\"Check that knots are in ascending order\"\"\"\n\tif len(knots):\n\t\tknot = knots[0]\n\t\tfor next in knots[1:]:\n\t\t\tif next < knot:\n\t\t\t\traise error.GLUError(\n\t\t\t\t\t\"\"\"%s has decreasing knot %s after %s\"\"\"%( name, next, knot )\n\t\t\t\t)\n", "description": "Check that knots are in ascending order", "category": "simple", "imports": ["from OpenGL.raw import GLU as _simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy as _lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL", "from OpenGL import _configflags"]}, {"term": "def", "name": "gluNurbsCallbackDataEXT", "data": "def gluNurbsCallbackDataEXT( baseFunction,nurb, userData ):\n\t\"\"\"Note the Python object for use as userData by the nurb\"\"\"\n\treturn baseFunction(\n\t\tnurb, nurb.noteObject( userData )\n\t)\n", "description": "Note the Python object for use as userData by the nurb", "category": "simple", "imports": ["from OpenGL.raw import GLU as _simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy as _lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL", "from OpenGL import _configflags"]}, {"term": "def", "name": "gluNurbsCurve", "data": "def gluNurbsCurve( baseFunction, nurb, knots, control, type ):\n\t\"\"\"Pythonic version of gluNurbsCurve\n\n\tCalculates knotCount, stride, and order automatically\n\t\"\"\"\n\tknots = arrays.GLfloatArray.asArray( knots )\n\tknotCount = arrays.GLfloatArray.arraySize( knots )\n\tcontrol = arrays.GLfloatArray.asArray( control )\n\ttry:\n\t\tlength,step = arrays.GLfloatArray.dimensions( control )\n\texcept ValueError as err:\n\t\traise error.GLUError( \"\"\"Need a 2-dimensional control array\"\"\" )\n\torder = knotCount - length\n\tif _configflags.ERROR_CHECKING:\n\t\tcheckOrder( order, knotCount, 'order of NURBS curve')\n\t\tcheckKnots( knots, 'knots of NURBS curve')\n\treturn baseFunction(\n\t\tnurb, knotCount, knots, step, control, order, type,\n\t)\n", "description": "Pythonic version of gluNurbsCurve\n\n\tCalculates knotCount, stride, and order automatically\n\t", "category": "simple", "imports": ["from OpenGL.raw import GLU as _simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy as _lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL", "from OpenGL import _configflags"]}, {"term": "def", "name": "gluNurbsSurface", "data": "def gluNurbsSurface( baseFunction, nurb, sKnots, tKnots, control, type ):\n\t\"\"\"Pythonic version of gluNurbsSurface\n\n\tCalculates knotCount, stride, and order automatically\n\t\"\"\"\n\tsKnots = arrays.GLfloatArray.asArray( sKnots )\n\tsKnotCount = arrays.GLfloatArray.arraySize( sKnots )\n\ttKnots = arrays.GLfloatArray.asArray( tKnots )\n\ttKnotCount = arrays.GLfloatArray.arraySize( tKnots )\n\tcontrol = arrays.GLfloatArray.asArray( control )\n\n\ttry:\n\t\tlength,width,step = arrays.GLfloatArray.dimensions( control )\n\texcept ValueError as err:\n\t\traise error.GLUError( \"\"\"Need a 3-dimensional control array\"\"\" )\n\tsOrder = sKnotCount - length\n\ttOrder = tKnotCount - width\n\tsStride = width*step\n\ttStride = step\n\tif _configflags.ERROR_CHECKING:\n\t\tcheckOrder( sOrder, sKnotCount, 'sOrder of NURBS surface')\n\t\tcheckOrder( tOrder, tKnotCount, 'tOrder of NURBS surface')\n\t\tcheckKnots( sKnots, 'sKnots of NURBS surface')\n\t\tcheckKnots( tKnots, 'tKnots of NURBS surface')\n\tif not (sKnotCount-sOrder)*(tKnotCount-tOrder) == length*width:\n\t\traise error.GLUError(\n\t\t\t\"\"\"Invalid NURB structure\"\"\",\n\t\t\tnurb, sKnotCount, sKnots, tKnotCount, tKnots,\n\t\t\tsStride, tStride, control,\n\t\t\tsOrder,tOrder,\n\t\t\ttype\n\t\t)\n\n\tresult = baseFunction(\n\t\tnurb, sKnotCount, sKnots, tKnotCount, tKnots,\n\t\tsStride, tStride, control,\n\t\tsOrder,tOrder,\n\t\ttype\n\t)\n\treturn result\n", "description": "Pythonic version of gluNurbsSurface\n\n\tCalculates knotCount, stride, and order automatically\n\t", "category": "simple", "imports": ["from OpenGL.raw import GLU as _simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy as _lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL", "from OpenGL import _configflags"]}, {"term": "def", "name": "gluPwlCurve", "data": "def gluPwlCurve( baseFunction, nurb, data, type ):\n\t\"\"\"gluPwlCurve -- piece-wise linear curve within GLU context\n\n\tdata -- the data-array\n\ttype -- determines number of elements/data-point\n\t\"\"\"\n\tdata = arrays.GLfloatArray.asArray( data )\n\tif type == _simple.GLU_MAP1_TRIM_2:\n\t\tdivisor = 2\n\telif type == _simple.GLU_MAP_TRIM_3:\n\t\tdivisor = 3\n\telse:\n\t\traise ValueError( \"\"\"Unrecognised type constant: %s\"\"\"%(type))\n\tsize = arrays.GLfloatArray.arraySize( data )\n\tsize = int(size//divisor)\n\treturn baseFunction( nurb, size, data, divisor, type )\n", "description": "gluPwlCurve -- piece-wise linear curve within GLU context\n\n\tdata -- the data-array\n\ttype -- determines number of elements/data-point\n\t", "category": "simple", "imports": ["from OpenGL.raw import GLU as _simple", "from OpenGL import platform, converters, wrapper", "from OpenGL.GLU import glustruct", "from OpenGL.lazywrapper import lazy as _lazy", "from OpenGL import arrays, error", "import ctypes", "import weakref", "from OpenGL.platform import PLATFORM", "import OpenGL", "from OpenGL import _configflags"]}], [{"term": "class", "name": "SimpleSitemap", "data": "class SimpleSitemap(Sitemap):\n\tchangefreq = \"never\"\n\tpriority = 0.5\n\tlocation = '/location/'\n\tlastmod = datetime.now()\n\n\tdef items(self):\n\t\treturn [object()]\n\n", "description": null, "category": "simple", "imports": ["from collections import OrderedDict", "from datetime import date, datetime", "from django.conf.urls import url", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "SimplePagedSitemap", "data": "class SimplePagedSitemap(Sitemap):\n\tdef items(self):\n\t\treturn [object() for x in range(Sitemap.limit + 1)]\n\n", "description": null, "category": "simple", "imports": ["from collections import OrderedDict", "from datetime import date, datetime", "from django.conf.urls import url", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "SimpleI18nSitemap", "data": "class SimpleI18nSitemap(Sitemap):\n\tchangefreq = \"never\"\n\tpriority = 0.5\n\ti18n = True\n\n\tdef items(self):\n\t\treturn I18nTestModel.objects.order_by('pk').all()\n\n", "description": null, "category": "simple", "imports": ["from collections import OrderedDict", "from datetime import date, datetime", "from django.conf.urls import url", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "EmptySitemap", "data": "class EmptySitemap(Sitemap):\n\tchangefreq = \"never\"\n\tpriority = 0.5\n\tlocation = '/location/'\n\n", "description": null, "category": "simple", "imports": ["from collections import OrderedDict", "from datetime import date, datetime", "from django.conf.urls import url", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "FixedLastmodSitemap", "data": "class FixedLastmodSitemap(SimpleSitemap):\n\tlastmod = datetime(2013, 3, 13, 10, 0, 0)\n\n", "description": null, "category": "simple", "imports": ["from collections import OrderedDict", "from datetime import date, datetime", "from django.conf.urls import url", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "FixedLastmodMixedSitemap", "data": "class FixedLastmodMixedSitemap(Sitemap):\n\tchangefreq = \"never\"\n\tpriority = 0.5\n\tlocation = '/location/'\n\tloop = 0\n\n\tdef items(self):\n\t\to1 = TestModel()\n\t\to1.lastmod = datetime(2013, 3, 13, 10, 0, 0)\n\t\to2 = TestModel()\n\t\treturn [o1, o2]\n\n", "description": null, "category": "simple", "imports": ["from collections import OrderedDict", "from datetime import date, datetime", "from django.conf.urls import url", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "FixedNewerLastmodSitemap", "data": "class FixedNewerLastmodSitemap(SimpleSitemap):\n\tlastmod = datetime(2013, 4, 20, 5, 0, 0)\n\n", "description": null, "category": "simple", "imports": ["from collections import OrderedDict", "from datetime import date, datetime", "from django.conf.urls import url", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "DateSiteMap", "data": "class DateSiteMap(SimpleSitemap):\n\tlastmod = date(2013, 3, 13)\n\n", "description": null, "category": "simple", "imports": ["from collections import OrderedDict", "from datetime import date, datetime", "from django.conf.urls import url", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "TimezoneSiteMap", "data": "class TimezoneSiteMap(SimpleSitemap):\n\tlastmod = datetime(2013, 3, 13, 10, 0, 0, tzinfo=timezone.get_fixed_timezone(-300))\n\n", "description": null, "category": "simple", "imports": ["from collections import OrderedDict", "from datetime import date, datetime", "from django.conf.urls import url", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "def", "name": "testmodelview", "data": "def testmodelview(request, id):\n\treturn HttpResponse()\n\n", "description": null, "category": "simple", "imports": ["from collections import OrderedDict", "from datetime import date, datetime", "from django.conf.urls import url", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}], [], [{"term": "class", "name": "SimpleGenerator", "data": "class SimpleGenerator(Generator):\n\tdef __init__(self, bboxes, labels, num_classes=0, image=None):\n\t\tassert(len(bboxes) == len(labels))\n\t\tself.bboxes\t   = bboxes\n\t\tself.labels\t   = labels\n\t\tself.num_classes_ = num_classes\n\t\tself.image\t\t= image\n\t\tsuper(SimpleGenerator, self).__init__(group_method='none', shuffle_groups=False)\n\n\tdef num_classes(self):\n\t\treturn self.num_classes_\n\n\tdef load_image(self, image_index):\n\t\treturn self.image\n\n\tdef size(self):\n\t\treturn len(self.bboxes)\n\n\tdef load_annotations(self, image_index):\n\t\tannotations = {'labels': self.labels[image_index], 'bboxes': self.bboxes[image_index]}\n\t\treturn annotations\n\n", "description": null, "category": "simple", "imports": ["from keras_retinanet.preprocessing.generator import Generator", "import numpy as np", "import pytest"]}, {"term": "class", "name": "TestLoadAnnotationsGroup", "data": "class TestLoadAnnotationsGroup(object):\n\tdef test_simple(self):\n\t\tinput_bboxes_group = [\n\t\t\tnp.array([\n\t\t\t\t[  0,   0,  10,  10],\n\t\t\t\t[150, 150, 350, 350]\n\t\t\t]),\n\t\t]\n\t\tinput_labels_group = [\n\t\t\tnp.array([\n\t\t\t\t1,\n\t\t\t\t3\n\t\t\t]),\n\t\t]\n\t\texpected_bboxes_group = input_bboxes_group\n\t\texpected_labels_group = input_labels_group\n\n\t\tsimple_generator = SimpleGenerator(input_bboxes_group, input_labels_group)\n\t\tannotations = simple_generator.load_annotations_group(simple_generator.groups[0])\n\n\t\tassert('bboxes' in annotations[0])\n\t\tassert('labels' in annotations[0])\n\t\tnp.testing.assert_equal(expected_bboxes_group[0], annotations[0]['bboxes'])\n\t\tnp.testing.assert_equal(expected_labels_group[0], annotations[0]['labels'])\n\n\tdef test_multiple(self):\n\t\tinput_bboxes_group = [\n\t\t\tnp.array([\n\t\t\t\t[  0,   0,  10,  10],\n\t\t\t\t[150, 150, 350, 350]\n\t\t\t]),\n\t\t\tnp.array([\n\t\t\t\t[0, 0, 50, 50],\n\t\t\t]),\n\t\t]\n\t\tinput_labels_group = [\n\t\t\tnp.array([\n\t\t\t\t1,\n\t\t\t\t0\n\t\t\t]),\n\t\t\tnp.array([\n\t\t\t\t3\n\t\t\t])\n\t\t]\n\t\texpected_bboxes_group = input_bboxes_group\n\t\texpected_labels_group = input_labels_group\n\n\t\tsimple_generator = SimpleGenerator(input_bboxes_group, input_labels_group)\n\t\tannotations_group_0 = simple_generator.load_annotations_group(simple_generator.groups[0])\n\t\tannotations_group_1 = simple_generator.load_annotations_group(simple_generator.groups[1])\n\n\t\tassert('bboxes' in annotations_group_0[0])\n\t\tassert('bboxes' in annotations_group_1[0])\n\t\tassert('labels' in annotations_group_0[0])\n\t\tassert('labels' in annotations_group_1[0])\n\t\tnp.testing.assert_equal(expected_bboxes_group[0], annotations_group_0[0]['bboxes'])\n\t\tnp.testing.assert_equal(expected_labels_group[0], annotations_group_0[0]['labels'])\n\t\tnp.testing.assert_equal(expected_bboxes_group[1], annotations_group_1[0]['bboxes'])\n\t\tnp.testing.assert_equal(expected_labels_group[1], annotations_group_1[0]['labels'])\n\n", "description": null, "category": "simple", "imports": ["from keras_retinanet.preprocessing.generator import Generator", "import numpy as np", "import pytest"]}, {"term": "class", "name": "TestFilterAnnotations", "data": "class TestFilterAnnotations(object):\n\tdef test_simple_filter(self):\n\t\tinput_bboxes_group = [\n\t\t\tnp.array([\n\t\t\t\t[  0,   0, 10, 10],\n\t\t\t\t[150, 150, 50, 50]\n\t\t\t]),\n\t\t]\n\t\tinput_labels_group = [\n\t\t\tnp.array([\n\t\t\t\t3,\n\t\t\t\t1\n\t\t\t]),\n\t\t]\n\n\t\tinput_image = np.zeros((500, 500, 3))\n\n\t\texpected_bboxes_group = [\n\t\t\tnp.array([\n\t\t\t\t[0, 0, 10, 10],\n\t\t\t]),\n\t\t]\n\t\texpected_labels_group = [\n\t\t\tnp.array([\n\t\t\t\t3,\n\t\t\t]),\n\t\t]\n\n\t\tsimple_generator = SimpleGenerator(input_bboxes_group, input_labels_group)\n\t\tannotations = simple_generator.load_annotations_group(simple_generator.groups[0])\n\t\t# expect a UserWarning\n\t\twith pytest.warns(UserWarning):\n\t\t\timage_group, annotations_group = simple_generator.filter_annotations([input_image], annotations, simple_generator.groups[0])\n\n\t\tnp.testing.assert_equal(expected_bboxes_group[0], annotations_group[0]['bboxes'])\n\t\tnp.testing.assert_equal(expected_labels_group[0], annotations_group[0]['labels'])\n\n\tdef test_multiple_filter(self):\n\t\tinput_bboxes_group = [\n\t\t\tnp.array([\n\t\t\t\t[  0,   0,  10,  10],\n\t\t\t\t[150, 150,  50,  50],\n\t\t\t\t[150, 150, 350, 350],\n\t\t\t\t[350, 350, 150, 150],\n\t\t\t\t[  1,   1,   2,   2],\n\t\t\t\t[  2,   2,   1,   1]\n\t\t\t]),\n\t\t\tnp.array([\n\t\t\t\t[0, 0, -1, -1]\n\t\t\t]),\n\t\t\tnp.array([\n\t\t\t\t[-10, -10,\t0,\t0],\n\t\t\t\t[-10, -10, -100, -100],\n\t\t\t\t[ 10,  10,  100,  100]\n\t\t\t]),\n\t\t\tnp.array([\n\t\t\t\t[ 10,  10,  100,  100],\n\t\t\t\t[ 10,  10,  600,  600]\n\t\t\t]),\n\t\t]\n\n\t\tinput_labels_group = [\n\t\t\tnp.array([\n\t\t\t\t6,\n\t\t\t\t5,\n\t\t\t\t4,\n\t\t\t\t3,\n\t\t\t\t2,\n\t\t\t\t1\n\t\t\t]),\n\t\t\tnp.array([\n\t\t\t\t0\n\t\t\t]),\n\t\t\tnp.array([\n\t\t\t\t10,\n\t\t\t\t11,\n\t\t\t\t12\n\t\t\t]),\n\t\t\tnp.array([\n\t\t\t\t105,\n\t\t\t\t107\n\t\t\t]),\n\t\t]\n\n\t\tinput_image = np.zeros((500, 500, 3))\n\n\t\texpected_bboxes_group = [\n\t\t\tnp.array([\n\t\t\t\t[  0,   0,  10,  10],\n\t\t\t\t[150, 150, 350, 350],\n\t\t\t\t[  1,   1,   2,   2]\n\t\t\t]),\n\t\t\tnp.zeros((0, 4)),\n\t\t\tnp.array([\n\t\t\t\t[10, 10, 100, 100]\n\t\t\t]),\n\t\t\tnp.array([\n\t\t\t\t[ 10,  10,  100,  100]\n\t\t\t]),\n\t\t]\n\t\texpected_labels_group = [\n\t\t\tnp.array([\n\t\t\t\t6,\n\t\t\t\t4,\n\t\t\t\t2\n\t\t\t]),\n\t\t\tnp.zeros((0,)),\n\t\t\tnp.array([\n\t\t\t\t12\n\t\t\t]),\n\t\t\tnp.array([\n\t\t\t\t105\n\t\t\t]),\n\t\t]\n\n\t\tsimple_generator = SimpleGenerator(input_bboxes_group, input_labels_group)\n\t\t# expect a UserWarning\n\t\tannotations_group_0 = simple_generator.load_annotations_group(simple_generator.groups[0])\n\t\twith pytest.warns(UserWarning):\n\t\t\timage_group, annotations_group_0 = simple_generator.filter_annotations([input_image], annotations_group_0, simple_generator.groups[0])\n\n\t\tannotations_group_1 = simple_generator.load_annotations_group(simple_generator.groups[1])\n\t\twith pytest.warns(UserWarning):\n\t\t\timage_group, annotations_group_1 = simple_generator.filter_annotations([input_image], annotations_group_1, simple_generator.groups[1])\n\n\t\tannotations_group_2 = simple_generator.load_annotations_group(simple_generator.groups[2])\n\t\twith pytest.warns(UserWarning):\n\t\t\timage_group, annotations_group_2 = simple_generator.filter_annotations([input_image], annotations_group_2, simple_generator.groups[2])\n\n\t\tnp.testing.assert_equal(expected_bboxes_group[0], annotations_group_0[0]['bboxes'])\n\t\tnp.testing.assert_equal(expected_labels_group[0], annotations_group_0[0]['labels'])\n\n\t\tnp.testing.assert_equal(expected_bboxes_group[1], annotations_group_1[0]['bboxes'])\n\t\tnp.testing.assert_equal(expected_labels_group[1], annotations_group_1[0]['labels'])\n\n\t\tnp.testing.assert_equal(expected_bboxes_group[2], annotations_group_2[0]['bboxes'])\n\t\tnp.testing.assert_equal(expected_labels_group[2], annotations_group_2[0]['labels'])\n\n\tdef test_complete(self):\n\t\tinput_bboxes_group = [\n\t\t\tnp.array([\n\t\t\t\t[  0,   0, 50, 50],\n\t\t\t\t[150, 150, 50, 50],  # invalid bbox\n\t\t\t], dtype=float)\n\t\t]\n\n\t\tinput_labels_group = [\n\t\t\tnp.array([\n\t\t\t\t5,  # one object of class 5\n\t\t\t\t3,  # one object of class 3 with an invalid box\n\t\t\t], dtype=float)\n\t\t]\n\n\t\tinput_image = np.zeros((500, 500, 3), dtype=np.uint8)\n\n\t\tsimple_generator = SimpleGenerator(input_bboxes_group, input_labels_group, image=input_image, num_classes=6)\n\t\t# expect a UserWarning\n\t\twith pytest.warns(UserWarning):\n\t\t\t_, [_, labels_batch] = simple_generator[0]\n\n\t\t# test that only object with class 5 is present in labels_batch\n\t\tlabels = np.unique(np.argmax(labels_batch == 5, axis=2))\n\t\tassert(len(labels) == 1 and labels[0] == 0), 'Expected only class 0 to be present, but got classes {}'.format(labels)\n", "description": null, "category": "simple", "imports": ["from keras_retinanet.preprocessing.generator import Generator", "import numpy as np", "import pytest"]}], [{"term": "class", "name": "TestMWSResponse", "data": "class TestMWSResponse(AWSMockServiceTestCase):\n\tconnection_class = MWSConnection\n\tmws = True\n\n\tdef test_parsing_nested_elements(self):\n\t\tclass Test9one(ResponseElement):\n\t\t\tNest = Element()\n\t\t\tZoom = Element()\n\n\t\tclass Test9Result(ResponseElement):\n\t\t\tItem = Element(Test9one)\n\n\t\ttext = b\"\"\"\n", "description": "\n", "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_member_list_specification", "data": "\tdef test_parsing_member_list_specification(self):\n\t\tclass Test8extra(ResponseElement):\n\t\t\tFoo = SimpleList()\n\n\t\tclass Test8Result(ResponseElement):\n\t\t\tItem = MemberList(SimpleList)\n\t\t\tExtra = MemberList(Test8extra)\n\n\t\ttext = b\"\"\"\n", "description": "\n", "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_nested_lists", "data": "\tdef test_parsing_nested_lists(self):\n\t\tclass Test7Result(ResponseElement):\n\t\t\tItem = MemberList(Nest=MemberList(),\n\t\t\t\t\t\t\t  List=ElementList(Simple=SimpleList()))\n\n\t\ttext = b\"\"\"\n\n", "description": "\n\n", "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_member_list", "data": "\tdef test_parsing_member_list(self):\n\t\tclass Test6Result(ResponseElement):\n\t\t\tItem = MemberList()\n\n\t\ttext = b\"\"\"\n", "description": "\n", "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_empty_member_list", "data": "\tdef test_parsing_empty_member_list(self):\n\t\tclass Test5Result(ResponseElement):\n\t\t\tItem = MemberList(Nest=MemberList())\n\n\t\ttext = b\"\"\"\n", "description": "\n", "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_missing_member_list", "data": "\tdef test_parsing_missing_member_list(self):\n\t\tclass Test4Result(ResponseElement):\n\t\t\tItem = MemberList(NestedItem=MemberList())\n\n", "description": null, "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_element_lists", "data": "\tdef test_parsing_element_lists(self):\n\t\tclass Test1Result(ResponseElement):\n\t\t\tItem = ElementList()\n\n", "description": null, "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_missing_lists", "data": "\tdef test_parsing_missing_lists(self):\n\t\tclass Test2Result(ResponseElement):\n\t\t\tItem = ElementList()\n\n", "description": null, "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "ftest_parsing_simple_lists", "data": "\tdef test_parsing_simple_lists(self):\n\t\tclass Test3Result(ResponseElement):\n\t\t\tItem = SimpleList()\n\n", "description": null, "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}, {"term": "def", "name": "fcheck_issue", "data": "\tdef check_issue(self, klass, text):\n\t\taction = klass.__name__[:-len('Result')]\n\t\tfactory = ResponseFactory(scopes=[{klass.__name__: klass}])\n\t\tparser = factory(action, connection=self.service_connection)\n\t\treturn self.service_connection._parse_response(parser, 'text/xml', text)\n\n", "description": null, "category": "simple", "imports": ["from boto.mws.connection import MWSConnection", "from boto.mws.response import (ResponseFactory, ResponseElement, Element,", "from tests.unit import AWSMockServiceTestCase", "from boto.compat import filter, map", "from tests.compat import unittest"]}], [], [{"term": "class", "name": "classMyPerfumeDao:\r", "data": "class MyPerfumeDao:\r\n\tdef __init__(self):\r\n\t\tpass\r\n\r\n\tdef deleteOne(self, target_id):\r\n\t\tdb = pymysql.connect(host='localhost', user='root', db='perfume', password='epqpvmqlqjs', charset='utf8', port=3306)\r\n\t\tcurs = db.cursor()\r\n\t\t\r\n\t\tsql = \"delete from perfume where id = {};\".format(target_id)\r\n\t\tcurs.execute(sql)\r\n\t\t\r\n\t\tdb.commit()\r\n\t\tdb.close()\r\n\r\n\tdef findOne(self, target_id):\r\n\t\tret = []\r\n\t\tdb = pymysql.connect(host='localhost', user='root', db='perfume', password='epqpvmqlqjs', charset='utf8', port=3306)\r\n\t\tcurs = db.cursor()\r\n\t\t\r\n\t\tsql = \"select * from perfume where id = {};\".format(target_id)\r\n\t\tcurs.execute(sql)\r\n\t\t\r\n\t\trows = curs.fetchall()\r\n\t\tfor p in rows:\r\n\t\t\ttemp = {'id':p[0],'perfume_name':p[1],'brand':p[2], 'brand_value' : p[3], 'gender':p[4], 'launch_year':p[5], 'main_accord1':p[6], 'main_accord2':p[7], 'main_accord3':p[8], 'top_note':p[9],\r\n\t\t\t'middle_note':p[10], 'base_note':p[11], 'season':p[12], 'day_or_night':p[13], 'longevity':p[14], 'sillage':p[15], \r\n\t\t\t'rating':p[16], 'voters_num':p[17], 'main_accord1_ratio':p[18], 'main_accord2_ratio':p[19], 'main_accord3_ratio':p[20]}\r\n\t\t\tret.append(temp)\r\n\t\t\r\n\t\tdb.commit()\r\n\t\tdb.close()\r\n\t\treturn ret\r\n\r\n\tdef findOneFromPP(self, target_id):\r\n\t\tret = []\r\n\t\tdb = pymysql.connect(host='localhost', user='root', db='perfume', password='epqpvmqlqjs', charset='utf8', port=3306)\r\n\t\tcurs = db.cursor()\r\n\t\t\r\n\t\tsql = \"select * from preprocessed_perfume where id = {};\".format(target_id)\r\n\t\tcurs.execute(sql)\r\n\t\t\r\n\t\trows = curs.fetchall()\r\n\t\tfor p in rows:\r\n\t\t\ttemp = {'id':p[0],'perfume_name':p[1], 'brand_value' : p[2], 'main_accord1':p[3], 'main_accord2':p[4], 'main_accord3':p[5], 'season':p[6], \r\n\t\t\t'longevity':p[7], 'rating':p[8], 'voters_num':p[9], \r\n\t\t\t'main_accord1_ratio':p[10], 'main_accord2_ratio':p[11], 'main_accord3_ratio':p[12]}\r\n\t\t\tret.append(temp)\r\n\t\t\r\n\t\tdb.commit()\r\n\t\tdb.close()\r\n\t\treturn ret\r\n\r\n\tdef findAll(self):\r\n\t\tret = []\r\n\t\tdb = pymysql.connect(host='localhost', user='root', db='perfume', password='epqpvmqlqjs', charset='utf8', port=3306)\r\n\t\tcurs = db.cursor()\r\n\t\t\r\n\t\tsql = \"select * from perfume;\"\r\n\t\tcurs.execute(sql)\r\n\t\t\r\n\t\trows = curs.fetchall()\r\n\t\tfor p in rows:\r\n\t\t\ttemp = {'id':p[0],'perfume_name':p[1],'brand':p[2], 'brand_value' : p[3], 'gender':p[4], 'launch_year':p[5], 'main_accord1':p[6], 'main_accord2':p[7], 'main_accord3':p[8], 'top_note':p[9],\r\n\t\t\t'middle_note':p[10], 'base_note':p[11], 'season':p[12], 'day_or_night':p[13], 'longevity':p[14], 'sillage':p[15], \r\n\t\t\t'rating':p[16], 'voters_num':p[17], 'main_accord1_ratio':p[18], 'main_accord2_ratio':p[19], 'main_accord3_ratio':p[20]}\r\n\t\t\tret.append(temp)\r\n\r\n\t\tdb.commit()\r\n\t\tdb.close()\r\n\t\treturn ret\r\n\r\n\tdef findAllPerfumeName(self):\r\n\t\tret = []\r\n\t\tdb = pymysql.connect(host='localhost', user='root', db='perfume', password='epqpvmqlqjs', charset='utf8', port=3306)\r\n\t\tcurs = db.cursor()\r\n\t\t\r\n\t\tsql = \"select perfume_name from perfume;\"\r\n\t\tcurs.execute(sql)\r\n\t\trows = curs.fetchall()\r\n\t\tfor p in rows:\r\n\t\t\tret.append(p[0])\r\n\r\n\t\tdb.commit()\r\n\t\tdb.close()\r\n\t\treturn ret\r\n\r\n\tdef findByName(self, perfume_name):\r\n\t\tret = []\r\n\t\tdb = pymysql.connect(host='localhost', user='root', db='perfume', password='epqpvmqlqjs', charset='utf8', port=3306)\r\n\t\tcurs = db.cursor()\r\n\t\t\r\n\t\tif perfume_name.find(\"\\'\"):\r\n\t\t\tperfume_name = perfume_name.replace('\\'', '\\\\\\'')\t\t\t\r\n\r\n\t\tperfume_name = \"\\'\" + perfume_name + \"\\'\"\r\n\t\tsql = \"select * from perfume where perfume_name = {};\".format(perfume_name)\r\n\t\tcurs.execute(sql)\r\n\t\t\r\n\t\trows = curs.fetchall()\r\n\t\tfor p in rows:\r\n\t\t\ttemp = {'id':p[0],'perfume_name':p[1],'brand':p[2], 'brand_value' : p[3], 'gender':p[4], 'launch_year':p[5], 'main_accord1':p[6], 'main_accord2':p[7], 'main_accord3':p[8], 'top_note':p[9],\r\n\t\t\t'middle_note':p[10], 'base_note':p[11], 'season':p[12], 'day_or_night':p[13], 'longevity':p[14], 'sillage':p[15], \r\n\t\t\t'rating':p[16], 'voters_num':p[17], 'main_accord1_ratio':p[18], 'main_accord2_ratio':p[19], 'main_accord3_ratio':p[20]}\r\n\t\t\tret.append(temp)\r\n\t\t\r\n\t\tdb.commit()\r\n\t\tdb.close()\r\n\t\treturn ret\r\n\r\n\tdef getInputVector(self, main_accord1, main_accord2, main_accord3, brand_value, longevity, season):\r\n\t\tdb = pymysql.connect(host='localhost', user='root', db='perfume', password='epqpvmqlqjs', charset='utf8', port=3306, cursorclass=pymysql.cursors.DictCursor)\r\n\t\tcurs = db.cursor()\r\n\t\tsql = \"select perfume_name, brand_value, main_accord1, main_accord2, main_accord3, season, longevity, rating, voters_num, main_accord1_ratio, main_accord2_ratio, main_accord3_ratio from preprocessed_perfume;\"\r\n\t\tcurs.execute(sql)\r\n\t\tperfume = pd.DataFrame(curs.fetchall())\r\n\r\n\t\tinput = f\"{main_accord1} {main_accord2} {main_accord3} {brand_value} {longevity} {season}\"\r\n\t\tvoca = \"brand_value longevity normal popular luxury season spices whiteflowers sweetsandgourmandsmells spring moderate muskamberanimalicsmells citrussmells winter long_lasting weak woodsandmosses summer greensherbsandfougeres fruitsvegetablesandnuts very_weak fall flowers naturalandsyntheticpopularandweird eternal resinsandbalsams beverages\"\r\n\t\tall = [input, voca]\r\n\r\n\t\tinput_list = input.split(\" \")\r\n\r\n\t\tcount_vector = CountVectorizer(min_df=1, ngram_range=(1,1))\r\n\t\tsimple_vector = count_vector.fit_transform(all)\r\n\t\tsimple_vector = simple_vector[0].toarray().astype(np.float64)\r\n\t\tsimple_vector = simple_vector[0]\r\n\r\n\t\treverse_vocabulary = dict(map(reversed, count_vector.vocabulary_.items()))\r\n\r\n\t\tfor i in range(0, simple_vector.size):\r\n\t\t\tif (simple_vector[i] == 1):\r\n\t\t\t\tif i == 0: #beverage\r\n\t\t\t\t\tif input_list[0].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.39\r\n\t\t\t\t\telif input_list[1].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.33\r\n\t\t\t\t\telif input_list[2].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.28\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t\r\n\t\t\t\telif i == 2: #citrus smells\r\n\t\t\t\t\tif input_list[0].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.39\r\n\t\t\t\t\telif input_list[1].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.33\r\n\t\t\t\t\telif input_list[2].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.28\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t\t\r\n\t\t\t\telif i == 3: #eternal\r\n\t\t\t\t\tsimple_vector[i] = 0\r\n\t\t\t\t\tsimple_vector[9] = 2.5 #9 = longevity\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t\t\r\n\t\t\t\telif i == 4: #fall\r\n\t\t\t\t\tsimple_vector[i] = 0\r\n\t\t\t\t\tif season == 'fall':\r\n\t\t\t\t\t\t# simple_vector[17] = 0.05 # 17 = season\r\n\t\t\t\t\t\tsimple_vector[17] = 0.46 # 17 = season\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t\t\r\n\t\t\t\telif i == 5: #flowers\r\n\t\t\t\t\tif input_list[0].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.39\r\n\t\t\t\t\telif input_list[1].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.33\r\n\t\t\t\t\telif input_list[2].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.28\r\n\t\t\t\t\tcontinue\r\n\r\n\t\t\t\telif i == 6: #fruitsvegetablesandnuts\r\n\t\t\t\t\tif input_list[0].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.39\r\n\t\t\t\t\telif input_list[1].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.33\r\n\t\t\t\t\telif input_list[2].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.28\r\n\t\t\t\t\tcontinue\r\n\r\n\t\t\t\telif i == 7: #greensherbsandfougeres\r\n\t\t\t\t\tif input_list[0].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.39\r\n\t\t\t\t\telif input_list[1].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.33\r\n\t\t\t\t\telif input_list[2].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.28\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t\t\r\n\t\t\t\telif i == 8: #long_lasting\r\n\t\t\t\t\tsimple_vector[i] = 0\r\n\t\t\t\t\tsimple_vector[9] = 2 #9 = longevity\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t\t\r\n\t\t\t\telif i == 10: #luxury\r\n\t\t\t\t\tsimple_vector[i] = 0\r\n\t\t\t\t\tsimple_vector[1] = 1.59\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t\t\t\r\n\t\t\t\telif i == 11: #moderate\r\n\t\t\t\t\tsimple_vector[i] = 0\r\n\t\t\t\t\tsimple_vector[9] = 1.5 #9 = longevity\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t\t\r\n\t\t\t\telif i == 12: #muskamberanimalicsmells\r\n\t\t\t\t\tif input_list[0].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.39\r\n\t\t\t\t\telif input_list[1].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.33\r\n\t\t\t\t\telif input_list[2].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.28\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t\t\r\n\t\t\t\telif i == 13: #naturalandsyntheticpopularandweird\r\n\t\t\t\t\tif input_list[0].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.39\r\n\t\t\t\t\telif input_list[1].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.33\r\n\t\t\t\t\telif input_list[2].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.28\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t\t\r\n\t\t\t\telif i == 14: #normal\r\n\t\t\t\t\tsimple_vector[i] = 0\r\n\t\t\t\t\tsimple_vector[1] = 0.53\r\n\t\t\t\t\tcontinue\r\n\r\n\t\t\t\telif i == 15: #popular\r\n\t\t\t\t\tsimple_vector[i] = 0\r\n\t\t\t\t\tsimple_vector[1] = 1.06\r\n\t\t\t\t\tcontinue\r\n\r\n\t\t\t\telif i == 16: #resinsandbalsams\r\n\t\t\t\t\tif input_list[0].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.39\r\n\t\t\t\t\telif input_list[1].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.33\r\n\t\t\t\t\telif input_list[2].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.28\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t\t\r\n\t\t\t\telif i == 18: #spices\r\n\t\t\t\t\tif input_list[0].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.39\r\n\t\t\t\t\telif input_list[1].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.33\r\n\t\t\t\t\telif input_list[2].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.28\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t\t\r\n\t\t\t\telif i == 19: #spring\r\n\t\t\t\t\tsimple_vector[i] = 0\r\n\t\t\t\t\tif season == 'spring':\r\n\t\t\t\t\t\t# simple_vector[17] = 0.05 # 17 = season\r\n\t\t\t\t\t\tsimple_vector[17] = 0.46 # 17 = season\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t\t\r\n\t\t\t\telif i == 20: #summer\r\n\t\t\t\t\tsimple_vector[i] = 0\r\n\t\t\t\t\tif season == 'summer':\r\n\t\t\t\t\t\t# simple_vector[17] = 0.05 # 17 = season\r\n\t\t\t\t\t\tsimple_vector[17] = 0.46 # 17 = season\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t\r\n\t\t\t\telif i == 21: #sweetsandgourmandsmells\r\n\t\t\t\t\tif input_list[0].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.39\r\n\t\t\t\t\telif input_list[1].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.33\r\n\t\t\t\t\telif input_list[2].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.28\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t\t\r\n\t\t\t\telif i == 22: #very_weak\r\n\t\t\t\t\tsimple_vector[i] = 0\r\n\t\t\t\t\tsimple_vector[9] = 0.5 #10 = longevity\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t\t\r\n\t\t\t\telif i == 23: #weak\r\n\t\t\t\t\tsimple_vector[i] = 0\r\n\t\t\t\t\tsimple_vector[9] = 1 #10 = longevity\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t\t\r\n\t\t\t\telif i == 24: #whiteflowers\r\n\t\t\t\t\tif input_list[0].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.39\r\n\t\t\t\t\telif input_list[1].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.33\r\n\t\t\t\t\telif input_list[2].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.28\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t\t\t\r\n\t\t\t\telif i == 25: #winter\r\n\t\t\t\t\tsimple_vector[i] = 0\r\n\t\t\t\t\tif season == 'winter':\r\n\t\t\t\t\t\t# simple_vector[17] = 0.05 # 17 = season\r\n\t\t\t\t\t\tsimple_vector[17] = 0.46 # 17 = season\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t\t\r\n\t\t\t\telif i == 26: #woodsandmosses\r\n\t\t\t\t\tif input_list[0].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.39\r\n\t\t\t\t\telif input_list[1].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.33\r\n\t\t\t\t\telif input_list[2].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.28\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t  \r\n\t\t\telif simple_vector[i] == 2: # \uba54\uc778 \uc5b4\ucf54\ub4dc\uac00 2\uac1c \uacb9\uce60 \uacbd\uc6b0\r\n\t\t\t\tif i == 0: #beverage\r\n\t\t\t\t\tif input_list[0].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\ttemp = 0.39\r\n\t\t\t\t\t\tif input_list[1].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\t\tsimple_vector[i] = 0.33 + temp\r\n\t\t\t\t\t\telif input_list[2].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\t\tsimple_vector[i] = 0.28 + temp\r\n\t\t\t\t\telse:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.61\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t\t\t\r\n\t\t\t\telif i == 2: #citrus smells\r\n\t\t\t\t\tif input_list[0].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\ttemp = 0.39\r\n\t\t\t\t\t\tif input_list[1].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\t\tsimple_vector[i] = 0.33 + temp\r\n\t\t\t\t\t\telif input_list[2].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\t\tsimple_vector[i] = 0.28 + temp\r\n\t\t\t\t\telse:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.61\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t\t\t\r\n\t\t\t\telif i == 5: #flowers\r\n\t\t\t\t\tif input_list[0].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\ttemp = 0.39\r\n\t\t\t\t\t\tif input_list[1].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\t\tsimple_vector[i] = 0.33 + temp\r\n\t\t\t\t\t\telif input_list[2].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\t\tsimple_vector[i] = 0.28 + temp\r\n\t\t\t\t\telse:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.61\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t\t\t\r\n\t\t\t\telif i == 6: #fruitsvegetablesandnuts\r\n\t\t\t\t\tif input_list[0].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\ttemp = 0.39\r\n\t\t\t\t\t\tif input_list[1].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\t\tsimple_vector[i] = 0.33 + temp\r\n\t\t\t\t\t\telif input_list[2].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\t\tsimple_vector[i] = 0.28 + temp\r\n\t\t\t\t\telse:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.61\r\n\t\t\t\t\tcontinue\r\n\r\n\t\t\t\telif i == 7: #greensherbsandfougeres\r\n\t\t\t\t\tif input_list[0].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\ttemp = 0.39\r\n\t\t\t\t\t\tif input_list[1].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\t\tsimple_vector[i] = 0.33 + temp\r\n\t\t\t\t\t\telif input_list[2].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\t\tsimple_vector[i] = 0.28 + temp\r\n\t\t\t\t\telse:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.61\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t\t\t\r\n\t\t\t\telif i == 12: #muskamberanimalicsmells\r\n\t\t\t\t\tif input_list[0].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\ttemp = 0.39\r\n\t\t\t\t\t\tif input_list[1].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\t\tsimple_vector[i] = 0.33 + temp\r\n\t\t\t\t\t\telif input_list[2].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\t\tsimple_vector[i] = 0.28 + temp\r\n\t\t\t\t\telse:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.61\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t\t\r\n\t\t\t\telif i == 13: #naturalandsyntheticpopularandweird\r\n\t\t\t\t\tif input_list[0].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\ttemp = 0.39\r\n\t\t\t\t\t\tif input_list[1].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\t\tsimple_vector[i] = 0.33 + temp\r\n\t\t\t\t\t\telif input_list[2].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\t\tsimple_vector[i] = 0.28 + temp\r\n\t\t\t\t\telse:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.61\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t\t\r\n\t\t\t\telif i == 16: #resinsandbalsams\r\n\t\t\t\t\tif input_list[0].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\ttemp = 0.39\r\n\t\t\t\t\t\tif input_list[1].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\t\tsimple_vector[i] = 0.33 + temp\r\n\t\t\t\t\t\telif input_list[2].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\t\tsimple_vector[i] = 0.28 + temp\r\n\t\t\t\t\telse:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.61\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t\t\r\n\t\t\t\telif i == 18: #spices\r\n\t\t\t\t\tif input_list[0].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\ttemp = 0.39\r\n\t\t\t\t\t\tif input_list[1].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\t\tsimple_vector[i] = 0.33 + temp\r\n\t\t\t\t\t\telif input_list[2].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\t\tsimple_vector[i] = 0.28 + temp\r\n\t\t\t\t\telse:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.61\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t\t\r\n\t\t\t\telif i == 21: #sweetsandgourmandsmells\r\n\t\t\t\t\tif input_list[0].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\ttemp = 0.39\r\n\t\t\t\t\t\tif input_list[1].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\t\tsimple_vector[i] = 0.33 + temp\r\n\t\t\t\t\t\telif input_list[2].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\t\tsimple_vector[i] = 0.28 + temp\r\n\t\t\t\t\telse:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.61\r\n\t\t\t\t\tcontinue\r\n\r\n\t\t\t\telif i == 24: #whiteflowers\r\n\t\t\t\t\tif input_list[0].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\ttemp = 0.39\r\n\t\t\t\t\t\tif input_list[1].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\t\tsimple_vector[i] = 0.33 + temp\r\n\t\t\t\t\t\telif input_list[2].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\t\tsimple_vector[i] = 0.28 + temp\r\n\t\t\t\t\telse:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.61\r\n\t\t\t\t\tcontinue\r\n\r\n\t\t\t\telif i == 26: #woodsandmosses\r\n\t\t\t\t\tif input_list[0].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\ttemp = 0.39\r\n\t\t\t\t\t\tif input_list[1].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\t\tsimple_vector[i] = 0.33 + temp\r\n\t\t\t\t\t\telif input_list[2].lower() == reverse_vocabulary[i]:\r\n\t\t\t\t\t\t\tsimple_vector[i] = 0.28 + temp\r\n\t\t\t\t\telse:\r\n\t\t\t\t\t\tsimple_vector[i] = 0.61\r\n\t\t\t\t\tcontinue\r\n \r\n\t\t\telif simple_vector[i] == 3: #\uba54\uc778 \uc5b4\ucf54\ub4dc \uce74\ud14c\uace0\ub9ac\uac00 3\uac1c \ub2e4 \uac19\uc744 \uacbd\uc6b0\r\n\t\t\t\tif i == 0: #beverage\r\n\t\t\t\t\tsimple_vector[i] = 1.00\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t\t\r\n\t\t\t\telif i == 2: #citrus smells\r\n\t\t\t\t\tsimple_vector[i] = 1.00\r\n\t\t\t\t\tcontinue\r\n \r\n\t\t\t\telif i == 5: #flowers\r\n\t\t\t\t\tsimple_vector[i] = 1.00\r\n\t\t\t\t\tcontinue  \r\n\r\n\t\t\t\telif i == 6: #fruitsvegetablesandnuts\r\n\t\t\t\t\tsimple_vector[i] = 1.00\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t\t\r\n\t\t\t\telif i == 7: #greensherbsandfougeres\r\n\t\t\t\t\tsimple_vector[i] = 1.00\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t\t\r\n\t\t\t\telif i == 12: #muskamberanimalicsmells\r\n\t\t\t\t\tsimple_vector[i] = 1.00\r\n\t\t\t\t\tcontinue\r\n\r\n\t\t\t\telif i == 13: #naturalandsyntheticpopularandweird\r\n\t\t\t\t\tsimple_vector[i] = 1.00\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t\t\r\n\t\t\t\telif i == 16: #resinsandbalsams\r\n\t\t\t\t\tsimple_vector[i] = 1.00\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t\r\n\t\t\t\telif i == 18: #spices\r\n\t\t\t\t\tsimple_vector[i] = 1.00\r\n\t\t\t\t\tcontinue\r\n\r\n\t\t\t\telif i == 21: #sweetsandgourmandsmells\r\n\t\t\t\t\tsimple_vector[i] = 1.00\r\n\t\t\t\t\tcontinue\r\n   \r\n\t\t\t\telif i == 24: #whiteflowers\r\n\t\t\t\t\tsimple_vector[i] = 1.00\r\n\t\t\t\t\tcontinue\r\n\r\n\t\t\t\telif i == 26: #woodsandmosses\r\n\t\t\t\t\tsimple_vector[i] = 1.00\r\n\t\t\t\t\tcontinue\t\t\r\n\t\tdb.commit()\r\n\t\tdb.close()\r\n\t\tprocessed_input_vector = simple_vector\r\n\t\treturn processed_input_vector\r\n\r\n\tdef find_sim_perfume(self, df, sorted_idx, target_perfume, perfume_sim):\r\n\t\t\tthreshold = None\r\n\r\n\t\t\ttarget = df[df['perfume_name'] == target_perfume]\r\n\t\t\ttarget_idx = target.index.values\r\n\r\n\t\t\t# \uc5ec\uae30\uc11c \ucd94\ucc9c \uc0d8\ud50c\r\n\t\t\t# similar_idxs = sorted_idx[sorted_idx != target_idx]\r\n\t\t\t# similar_idxs = similar_idxs[0:101]\r\n\t\t\t# df.iloc[similar_idxs].to_csv(\"2-1.csv\")\r\n\r\n\t\t\tsimilar_idxs = sorted_idx[sorted_idx != target_idx]\r\n\t   \r\n\t\t\tfor i in range(0, similar_idxs.size):\r\n\t\t\t\tif perfume_sim[-1][similar_idxs[i]] < 0.93:\r\n\t\t\t\t\tprint(perfume_sim[-1][similar_idxs[i]])\r\n\t\t\t\t\tthreshold = i\r\n\t\t\t\t\tbreak\r\n\r\n\t\t\t# \ud544\ud130\ub9c1 \ud558\uae30 \uc804 \uc804\uccb4 \r\n\t\t\t# print(type(similar_idxs))\r\n\t\t\t# print(similar_idxs)\r\n\t\t\t# print(similar_idxs.size)\r\n\t\t\t\r\n\t\t\tsimilar_idxs = similar_idxs[0:threshold]\r\n\r\n\t\t\t# \uc720\uc0ac\ub3c4 \uae30\uc900\uc73c\ub85c \ud544\ud130\ub9c1\ud55c \ud6c4\uc758 \ub0a8\uc740 \uac1c\uc218\r\n\t\t\t# print(type(similar_idxs))\r\n\t\t\t# print(similar_idxs)\r\n\t\t\t# print(threshold, \"++\uc4f0\ub808\uc26c\ud640\ub4dc++\")\r\n\t\t\t# print(similar_idxs.size)\r\n\t\t\t\r\n\t\t\tdf = df.iloc[similar_idxs].sort_values(\"weighted_rating\", ascending = False)\r\n\t\t\tsimilar_idxs = df.index.tolist()\r\n\r\n\t\t\treturn similar_idxs\r\n\r\n\tdef recommend(self, user_taste):\r\n\t\tstart = time.time()\r\n\r\n\t\tmyDao = MyPerfumeDao()\r\n\r\n\t\tdata_to_insert = {'perfume_name' : \"user_input\", 'main_accord1': user_taste[0][0], 'main_accord2' : user_taste[1][0], 'main_accord3' : user_taste[2][0], \"season\" : user_taste[5][0],\r\n\t\t\"longevity\" : user_taste[4][0], \"brand_value\" : user_taste[3][0], \"rating\" : None, \"voters_num\" : None, \"main_accord1_ratio\" : 0.39, \"main_accord2_ratio\" : 0.33, \"main_accord3_ratio\" : 0.28}\r\n\r\n\t\tdb = pymysql.connect(host='localhost', user='root', db='perfume', password='epqpvmqlqjs', charset='utf8', port=3306, cursorclass=pymysql.cursors.DictCursor)\r\n\t\tcurs = db.cursor()\r\n\t\tsql = \"select * from perfume_mat_{};\".format(data_to_insert['season'])\r\n\t\tcurs.execute(sql)\r\n\t\tperfume_mat = pd.DataFrame(curs.fetchall())\r\n\t\tdel perfume_mat['id']\r\n\t\tperfume_mat = perfume_mat.to_numpy()\r\n\r\n\t\tsql = \"select perfume_name, brand_value, main_accord1, main_accord2, main_accord3, season, longevity, rating, voters_num, main_accord1_ratio, main_accord2_ratio, main_accord3_ratio from preprocessed_perfume;\"\r\n\t\tcurs.execute(sql)\r\n\t\tperfume = pd.DataFrame(curs.fetchall())\r\n\t\tprint(\"\uc5ec\uae306? :\", time.time() - start) \r\n\t \r\n\t\tprocessed_input_vector = myDao.getInputVector(data_to_insert['main_accord1'], data_to_insert['main_accord2'], data_to_insert['main_accord3'], data_to_insert['brand_value'], data_to_insert['longevity'], data_to_insert['season'])\r\n\t\tprocessed_input_vector = processed_input_vector.reshape(1,27)\r\n\t\tperfume_mat = np.concatenate((perfume_mat, processed_input_vector), axis = 0)\r\n\t\tprint(\"\uc5ec\uae305? :\", time.time() - start) \r\n\t\r\n\t\tperfume_sim = cosine_similarity(perfume_mat, perfume_mat)\r\n\t\tprint(\"\uc5ec\uae304? :\", time.time() - start) \r\n\r\n\t\ttarget_perfume_sim = perfume_sim[-1].reshape(-1)\r\n\r\n\t\tperfume_sim_sorted_idx = target_perfume_sim.argsort()[::-1]\r\n\t\tprint(\"\uc5ec\uae303? :\", time.time() - start) \r\n\r\n\t\t# \uac00\uc911 \ud3c9\uc810(Weighted Rating) = (v/(v+m)) * R + (m/(v+m)) * C\r\n\t\tC = perfume['rating'].mean()\r\n\t\tm = perfume['voters_num'].quantile(0.6)\r\n\t\tprint(round(C, 3), round(m, 3))\r\n\r\n\t\tdef set_weighted_rating(row):\r\n\t\t\tv = row['voters_num']\r\n\t\t\tR = row['rating']\r\n\r\n\t\t\treturn ((v/(v+m)) * R + (m/(v+m)) * C)\r\n\r\n\t\tperfume['weighted_rating'] = perfume.apply(set_weighted_rating, axis=1)\r\n\t\tprint(\"\uc5ec\uae302? :\", time.time() - start) \r\n\t\tperfume = perfume.append(data_to_insert, ignore_index=True) # input data\ub97c perfumes\uc5d0 \ub2e4\uc2dc \ub123\uae30\r\n\r\n\t\tdb.commit()\r\n\t\tdb.close()\r\n\r\n\t\tprint(\"\uac78\ub9b0 \uc2dc\uac04 :\", time.time() - start) \r\n", "description": null, "category": "simple", "imports": ["from email.errors import MissingHeaderBodySeparatorDefect\r", "import pymysql\r", "import numpy as np\r", "import pandas as pd\r", "import random\r", "from scipy.sparse import csr_matrix\r", "from sklearn.feature_extraction.text import CountVectorizer\r", "from sklearn.metrics.pairwise import cosine_similarity\r", "import time\r"]}], [{"term": "def", "name": "SimplePoint", "data": "def SimplePoint():\n\tnewpoints = []\n\n\tnewpoints.append([0.0, 0.0, 0.0])\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleLine", "data": "def SimpleLine(c1=[0.0, 0.0, 0.0], c2=[2.0, 2.0, 2.0]):\n\tnewpoints = []\n\n\tc3 = Vector(c2) - Vector(c1)\n\tnewpoints.append([0.0, 0.0, 0.0])\n\tnewpoints.append([c3[0], c3[1], c3[2]])\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleAngle", "data": "def SimpleAngle(length=1.0, angle=45.0):\n\tnewpoints = []\n\n\tangle = radians(angle)\n\tnewpoints.append([length, 0.0, 0.0])\n\tnewpoints.append([0.0, 0.0, 0.0])\n\tnewpoints.append([length * cos(angle), length * sin(angle), 0.0])\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleDistance", "data": "def SimpleDistance(length=1.0, center=True):\n\tnewpoints = []\n\n\tif center:\n\t\tnewpoints.append([-length / 2, 0.0, 0.0])\n\t\tnewpoints.append([length / 2, 0.0, 0.0])\n\telse:\n\t\tnewpoints.append([0.0, 0.0, 0.0])\n\t\tnewpoints.append([length, 0.0, 0.0])\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleCircle", "data": "def SimpleCircle(sides=4, radius=1.0):\n\tnewpoints = []\n\n\tangle = radians(360) / sides\n\tnewpoints.append([radius, 0, 0])\n\tj = 1\n\twhile j < sides:\n\t\tt = angle * j\n\t\tx = cos(t) * radius\n\t\ty = sin(t) * radius\n\t\tnewpoints.append([x, y, 0])\n\t\tj += 1\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleEllipse", "data": "def SimpleEllipse(a=2.0, b=1.0):\n\tnewpoints = []\n\n\tnewpoints.append([a, 0.0, 0.0])\n\tnewpoints.append([0.0, b, 0.0])\n\tnewpoints.append([-a, 0.0, 0.0])\n\tnewpoints.append([0.0, -b, 0.0])\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleArc", "data": "def SimpleArc(sides=0, radius=1.0, startangle=0.0, endangle=45.0):\n\tnewpoints = []\n\n\tstartangle = radians(startangle)\n\tendangle = radians(endangle)\n\tsides += 1\n\n\tangle = (endangle - startangle) / sides\n\tx = cos(startangle) * radius\n\ty = sin(startangle) * radius\n\tnewpoints.append([x, y, 0])\n\tj = 1\n\twhile j < sides:\n\t\tt = angle * j\n\t\tx = cos(t + startangle) * radius\n\t\ty = sin(t + startangle) * radius\n\t\tnewpoints.append([x, y, 0])\n\t\tj += 1\n\tx = cos(endangle) * radius\n\ty = sin(endangle) * radius\n\tnewpoints.append([x, y, 0])\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleSector", "data": "def SimpleSector(sides=0, radius=1.0, startangle=0.0, endangle=45.0):\n\tnewpoints = []\n\n\tstartangle = radians(startangle)\n\tendangle = radians(endangle)\n\tsides += 1\n\n\tnewpoints.append([0, 0, 0])\n\tangle = (endangle - startangle) / sides\n\tx = cos(startangle) * radius\n\ty = sin(startangle) * radius\n\tnewpoints.append([x, y, 0])\n\tj = 1\n\twhile j < sides:\n\t\tt = angle * j\n\t\tx = cos(t + startangle) * radius\n\t\ty = sin(t + startangle) * radius\n\t\tnewpoints.append([x, y, 0])\n\t\tj += 1\n\tx = cos(endangle) * radius\n\ty = sin(endangle) * radius\n\tnewpoints.append([x, y, 0])\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleSegment", "data": "def SimpleSegment(sides=0, a=2.0, b=1.0, startangle=0.0, endangle=45.0):\n\tnewpoints = []\n\n\tstartangle = radians(startangle)\n\tendangle = radians(endangle)\n\tsides += 1\n\n\tangle = (endangle - startangle) / sides\n\tx = cos(startangle) * a\n\ty = sin(startangle) * a\n\tnewpoints.append([x, y, 0])\n\tj = 1\n\twhile j < sides:\n\t\tt = angle * j\n\t\tx = cos(t + startangle) * a\n\t\ty = sin(t + startangle) * a\n\t\tnewpoints.append([x, y, 0])\n\t\tj += 1\n\tx = cos(endangle) * a\n\ty = sin(endangle) * a\n\tnewpoints.append([x, y, 0])\n\n\tx = cos(endangle) * b\n\ty = sin(endangle) * b\n\tnewpoints.append([x, y, 0])\n\tj = sides\n\twhile j > 0:\n\t\tt = angle * j\n\t\tx = cos(t + startangle) * b\n\t\ty = sin(t + startangle) * b\n\t\tnewpoints.append([x, y, 0])\n\t\tj -= 1\n\tx = cos(startangle) * b\n\ty = sin(startangle) * b\n\tnewpoints.append([x, y, 0])\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleRectangle", "data": "def SimpleRectangle(width=2.0, length=2.0, rounded=0.0, center=True):\n\tnewpoints = []\n\n\tr = rounded / 2\n\n\tif center:\n\t\tx = width / 2\n\t\ty = length / 2\n\t\tif rounded != 0.0:\n\t\t\tnewpoints.append([-x + r, y, 0.0])\n\t\t\tnewpoints.append([x - r, y, 0.0])\n\t\t\tnewpoints.append([x, y - r, 0.0])\n\t\t\tnewpoints.append([x, -y + r, 0.0])\n\t\t\tnewpoints.append([x - r, -y, 0.0])\n\t\t\tnewpoints.append([-x + r, -y, 0.0])\n\t\t\tnewpoints.append([-x, -y + r, 0.0])\n\t\t\tnewpoints.append([-x, y - r, 0.0])\n\t\telse:\n\t\t\tnewpoints.append([-x, y, 0.0])\n\t\t\tnewpoints.append([x, y, 0.0])\n\t\t\tnewpoints.append([x, -y, 0.0])\n\t\t\tnewpoints.append([-x, -y, 0.0])\n\n\telse:\n\t\tx = width\n\t\ty = length\n\t\tif rounded != 0.0:\n\t\t\tnewpoints.append([r, y, 0.0])\n\t\t\tnewpoints.append([x - r, y, 0.0])\n\t\t\tnewpoints.append([x, y - r, 0.0])\n\t\t\tnewpoints.append([x, r, 0.0])\n\t\t\tnewpoints.append([x - r, 0.0, 0.0])\n\t\t\tnewpoints.append([r, 0.0, 0.0])\n\t\t\tnewpoints.append([0.0, r, 0.0])\n\t\t\tnewpoints.append([0.0, y - r, 0.0])\n\t\telse:\n\t\t\tnewpoints.append([0.0, 0.0, 0.0])\n\t\t\tnewpoints.append([0.0, y, 0.0])\n\t\t\tnewpoints.append([x, y, 0.0])\n\t\t\tnewpoints.append([x, 0.0, 0.0])\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleRhomb", "data": "def SimpleRhomb(width=2.0, length=2.0, center=True):\n\tnewpoints = []\n\tx = width / 2\n\ty = length / 2\n\n\tif center:\n\t\tnewpoints.append([-x, 0.0, 0.0])\n\t\tnewpoints.append([0.0, y, 0.0])\n\t\tnewpoints.append([x, 0.0, 0.0])\n\t\tnewpoints.append([0.0, -y, 0.0])\n\telse:\n\t\tnewpoints.append([x, 0.0, 0.0])\n\t\tnewpoints.append([0.0, y, 0.0])\n\t\tnewpoints.append([x, length, 0.0])\n\t\tnewpoints.append([width, y, 0.0])\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimplePolygon", "data": "def SimplePolygon(sides=3, radius=1.0):\n\tnewpoints = []\n\tangle = radians(360.0) / sides\n\tj = 0\n\n\twhile j < sides:\n\t\tt = angle * j\n\t\tx = sin(t) * radius\n\t\ty = cos(t) * radius\n\t\tnewpoints.append([x, y, 0.0])\n\t\tj += 1\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimplePolygon_ab", "data": "def SimplePolygon_ab(sides=3, a=2.0, b=1.0):\n\tnewpoints = []\n\tangle = radians(360.0) / sides\n\tj = 0\n\n\twhile j < sides:\n\t\tt = angle * j\n\t\tx = sin(t) * a\n\t\ty = cos(t) * b\n\t\tnewpoints.append([x, y, 0.0])\n\t\tj += 1\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleTrapezoid", "data": "def SimpleTrapezoid(a=2.0, b=1.0, h=1.0, center=True):\n\tnewpoints = []\n\tx = a / 2\n\ty = b / 2\n\tr = h / 2\n\n\tif center:\n\t\tnewpoints.append([-x, -r, 0.0])\n\t\tnewpoints.append([-y, r, 0.0])\n\t\tnewpoints.append([y, r, 0.0])\n\t\tnewpoints.append([x, -r, 0.0])\n\n\telse:\n\t\tnewpoints.append([0.0, 0.0, 0.0])\n\t\tnewpoints.append([x - y, h, 0.0])\n\t\tnewpoints.append([x + y, h, 0.0])\n\t\tnewpoints.append([a, 0.0, 0.0])\n\n\treturn newpoints\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "align_matrix", "data": "def align_matrix(context, location):\n\tloc = Matrix.Translation(location)\n\tobj_align = context.user_preferences.edit.object_align\n\tif (context.space_data.type == 'VIEW_3D'\n\t\t\tand obj_align == 'VIEW'):\n\t\trot = context.space_data.region_3d.view_matrix.to_3x3().inverted().to_4x4()\n\telse:\n\t\trot = Matrix()\n\talign_matrix = loc * rot\n\n\treturn align_matrix\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "main", "data": "def main(context, self, align_matrix):\n\t# deselect all objects\n\tbpy.ops.object.select_all(action='DESELECT')\n\n\t# create object\n\tname = self.Simple_Type\t\t # Type as name\n\n\t# create curve\n\tscene = bpy.context.scene\n\tnewCurve = bpy.data.curves.new(name, type='CURVE')  # curvedatablock\n\tnewSpline = newCurve.splines.new('BEZIER')  # spline\n\n\t# set curveOptions\n\tnewCurve.dimensions = self.shape\n\tnewSpline.use_endpoint_u = True\n\n\tsides = abs(int((self.Simple_endangle - self.Simple_startangle) / 90))\n\n\t# get verts\n\tif self.Simple_Type == 'Point':\n\t\tverts = SimplePoint()\n\t\tnewSpline.use_cyclic_u = False\n\n\tif self.Simple_Type == 'Line':\n\t\tverts = SimpleLine(self.Simple_startlocation, self.Simple_endlocation)\n\t\tnewSpline.use_cyclic_u = False\n\t\tnewCurve.dimensions = '3D'\n\n\tif self.Simple_Type == 'Distance':\n\t\tverts = SimpleDistance(self.Simple_length, self.Simple_center)\n\t\tnewSpline.use_cyclic_u = False\n\n\tif self.Simple_Type == 'Angle':\n\t\tverts = SimpleAngle(self.Simple_length, self.Simple_angle)\n\t\tnewSpline.use_cyclic_u = False\n\n\tif self.Simple_Type == 'Circle':\n\t\tif self.Simple_sides < 4:\n\t\t\tself.Simple_sides = 4\n\t\tverts = SimpleCircle(self.Simple_sides, self.Simple_radius)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Ellipse':\n\t\tverts = SimpleEllipse(self.Simple_a, self.Simple_b)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Arc':\n\t\tif self.Simple_sides < sides:\n\t\t\tself.Simple_sides = sides\n\t\tif self.Simple_radius == 0:\n\t\t\treturn {'FINISHED'}\n\t\tverts = SimpleArc(self.Simple_sides, self.Simple_radius, self.Simple_startangle, self.Simple_endangle)\n\t\tnewSpline.use_cyclic_u = False\n\n\tif self.Simple_Type == 'Sector':\n\t\tif self.Simple_sides < sides:\n\t\t\tself.Simple_sides = sides\n\t\tif self.Simple_radius == 0:\n\t\t\treturn {'FINISHED'}\n\t\tverts = SimpleSector(self.Simple_sides, self.Simple_radius, self.Simple_startangle, self.Simple_endangle)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Segment':\n\t\tif self.Simple_sides < sides:\n\t\t\tself.Simple_sides = sides\n\t\tif self.Simple_a == 0 or self.Simple_b == 0:\n\t\t\treturn {'FINISHED'}\n\t\tverts = SimpleSegment(self.Simple_sides, self.Simple_a, self.Simple_b, self.Simple_startangle, self.Simple_endangle)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Rectangle':\n\t\tverts = SimpleRectangle(self.Simple_width, self.Simple_length, self.Simple_rounded, self.Simple_center)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Rhomb':\n\t\tverts = SimpleRhomb(self.Simple_width, self.Simple_length, self.Simple_center)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Polygon':\n\t\tif self.Simple_sides < 3:\n\t\t\tself.Simple_sides = 3\n\t\tverts = SimplePolygon(self.Simple_sides, self.Simple_radius)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Polygon_ab':\n\t\tif self.Simple_sides < 3:\n\t\t\tself.Simple_sides = 3\n\t\tverts = SimplePolygon_ab(self.Simple_sides, self.Simple_a, self.Simple_b)\n\t\tnewSpline.use_cyclic_u = True\n\n\tif self.Simple_Type == 'Trapezoid':\n\t\tverts = SimpleTrapezoid(self.Simple_a, self.Simple_b, self.Simple_h, self.Simple_center)\n\t\tnewSpline.use_cyclic_u = True\n\n\tvertArray = []\n\tfor v in verts:\n\t\tvertArray += v\n\n\tnewSpline.bezier_points.add(int(len(vertArray) * 0.333333333))\n\tnewSpline.bezier_points.foreach_set('co', vertArray)\n\n\t# create object with newCurve\n\tSimpleCurve = bpy.data.objects.new(name, newCurve)  # object\n\tscene.objects.link(SimpleCurve)  # place in active scene\n\tSimpleCurve.select = True  # set as selected\n\tscene.objects.active = SimpleCurve  # set as active\n\tSimpleCurve.matrix_world = align_matrix  # apply matrix\n\tSimpleCurve.rotation_euler = self.Simple_rotation_euler\n\n\tall_points = [p for p in newSpline.bezier_points]\n\td = 2 * 0.27606262\n\tn = 0\n\tfor p in all_points:\n\t\tp.handle_right_type = 'VECTOR'\n\t\tp.handle_left_type = 'VECTOR'\n\t\tn += 1\n\n\tif self.Simple_Type == 'Circle' or self.Simple_Type == 'Arc' or self.Simple_Type == 'Sector' or self.Simple_Type == 'Segment' or self.Simple_Type == 'Ellipse':\n\t\tfor p in all_points:\n\t\t\tp.handle_right_type = 'FREE'\n\t\t\tp.handle_left_type = 'FREE'\n\n\tif self.Simple_Type == 'Circle':\n\t\ti = 0\n\t\tfor p1 in all_points:\n\t\t\tif i != n - 1:\n\t\t\t\tp2 = all_points[i + 1]\n\t\t\t\tu1 = asin(p1.co.y / self.Simple_radius)\n\t\t\t\tu2 = asin(p2.co.y / self.Simple_radius)\n\t\t\t\tif p1.co.x > 0 and p2.co.x < 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\telif p1.co.x < 0 and p2.co.x > 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\tu = u2 - u1\n\t\t\t\tif u < 0:\n\t\t\t\t\tu = -u\n\t\t\t\tl = 4 / 3 * tan(1 / 4 * u) * self.Simple_radius\n\t\t\t\tv1 = Vector((-p1.co.y, p1.co.x, 0))\n\t\t\t\tv1.normalize()\n\t\t\t\tv2 = Vector((-p2.co.y, p2.co.x, 0))\n\t\t\t\tv2.normalize()\n\t\t\t\tvh1 = v1 * l\n\t\t\t\tvh2 = v2 * l\n\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) + vh1\n\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) - vh2\n\t\t\t\tp1.handle_right = v1\n\t\t\t\tp2.handle_left = v2\n\t\t\tif i == n - 1:\n\t\t\t\tp2 = all_points[0]\n\t\t\t\tu1 = asin(p1.co.y / self.Simple_radius)\n\t\t\t\tu2 = asin(p2.co.y / self.Simple_radius)\n\t\t\t\tif p1.co.x > 0 and p2.co.x < 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\telif p1.co.x < 0 and p2.co.x > 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\tu = u2 - u1\n\t\t\t\tif u < 0:\n\t\t\t\t\tu = -u\n\t\t\t\tl = 4 / 3 * tan(1 / 4 * u) * self.Simple_radius\n\t\t\t\tv1 = Vector((-p1.co.y, p1.co.x, 0))\n\t\t\t\tv1.normalize()\n\t\t\t\tv2 = Vector((-p2.co.y, p2.co.x, 0))\n\t\t\t\tv2.normalize()\n\t\t\t\tvh1 = v1 * l\n\t\t\t\tvh2 = v2 * l\n\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) + vh1\n\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) - vh2\n\t\t\t\tp1.handle_right = v1\n\t\t\t\tp2.handle_left = v2\n\t\t\ti += 1\n\n\tif self.Simple_Type == 'Ellipse':\n\t\tall_points[0].handle_right = Vector((self.Simple_a, self.Simple_b * d, 0))\n\t\tall_points[0].handle_left = Vector((self.Simple_a, -self.Simple_b * d, 0))\n\t\tall_points[1].handle_right = Vector((-self.Simple_a * d, self.Simple_b, 0))\n\t\tall_points[1].handle_left = Vector((self.Simple_a * d, self.Simple_b, 0))\n\t\tall_points[2].handle_right = Vector((-self.Simple_a, -self.Simple_b * d, 0))\n\t\tall_points[2].handle_left = Vector((-self.Simple_a, self.Simple_b * d, 0))\n\t\tall_points[3].handle_right = Vector((self.Simple_a * d, -self.Simple_b, 0))\n\t\tall_points[3].handle_left = Vector((-self.Simple_a * d, -self.Simple_b, 0))\n\n\tif self.Simple_Type == 'Arc':\n\t\ti = 0\n\t\tfor p1 in all_points:\n\t\t\tif i != n - 1:\n\t\t\t\tp2 = all_points[i + 1]\n\t\t\t\tu1 = asin(p1.co.y / self.Simple_radius)\n\t\t\t\tu2 = asin(p2.co.y / self.Simple_radius)\n\t\t\t\tif p1.co.x > 0 and p2.co.x < 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\telif p1.co.x < 0 and p2.co.x > 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\tu = u2 - u1\n\t\t\t\tif u < 0:\n\t\t\t\t\tu = -u\n\t\t\t\tl = 4 / 3 * tan(1 / 4 * u) * self.Simple_radius\n\t\t\t\tv1 = Vector((-p1.co.y, p1.co.x, 0))\n\t\t\t\tv1.normalize()\n\t\t\t\tv2 = Vector((-p2.co.y, p2.co.x, 0))\n\t\t\t\tv2.normalize()\n\t\t\t\tvh1 = v1 * l\n\t\t\t\tvh2 = v2 * l\n\t\t\t\tif self.Simple_startangle < self.Simple_endangle:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) + vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) - vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\t\t\t\telse:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) - vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) + vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\t\t\ti += 1\n\n\tif self.Simple_Type == 'Sector':\n\t\ti = 0\n\t\tfor p1 in all_points:\n\t\t\tif i == 0:\n\t\t\t\tp1.handle_right_type = 'VECTOR'\n\t\t\t\tp1.handle_left_type = 'VECTOR'\n\t\t\telif i != n - 1:\n\t\t\t\tp2 = all_points[i + 1]\n\t\t\t\tu1 = asin(p1.co.y / self.Simple_radius)\n\t\t\t\tu2 = asin(p2.co.y / self.Simple_radius)\n\t\t\t\tif p1.co.x > 0 and p2.co.x < 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\telif p1.co.x < 0 and p2.co.x > 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_radius)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_radius)\n\t\t\t\tu = u2 - u1\n\t\t\t\tif u < 0:\n\t\t\t\t\tu = -u\n\t\t\t\tl = 4 / 3 * tan(1 / 4 * u) * self.Simple_radius\n\t\t\t\tv1 = Vector((-p1.co.y, p1.co.x, 0))\n\t\t\t\tv1.normalize()\n\t\t\t\tv2 = Vector((-p2.co.y, p2.co.x, 0))\n\t\t\t\tv2.normalize()\n\t\t\t\tvh1 = v1 * l\n\t\t\t\tvh2 = v2 * l\n\t\t\t\tif self.Simple_startangle < self.Simple_endangle:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) + vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) - vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\t\t\t\telse:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) - vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) + vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\t\t\ti += 1\n\n\tif self.Simple_Type == 'Segment':\n\t\ti = 0\n\t\tfor p1 in all_points:\n\t\t\tif i < n / 2 - 1:\n\t\t\t\tp2 = all_points[i + 1]\n\t\t\t\tu1 = asin(p1.co.y / self.Simple_a)\n\t\t\t\tu2 = asin(p2.co.y / self.Simple_a)\n\t\t\t\tif p1.co.x > 0 and p2.co.x < 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_a)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_a)\n\t\t\t\telif p1.co.x < 0 and p2.co.x > 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_a)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_a)\n\t\t\t\tu = u2 - u1\n\t\t\t\tif u < 0:\n\t\t\t\t\tu = -u\n\t\t\t\tl = 4 / 3 * tan(1 / 4 * u) * self.Simple_a\n\t\t\t\tv1 = Vector((-p1.co.y, p1.co.x, 0))\n\t\t\t\tv1.normalize()\n\t\t\t\tv2 = Vector((-p2.co.y, p2.co.x, 0))\n\t\t\t\tv2.normalize()\n\t\t\t\tvh1 = v1 * l\n\t\t\t\tvh2 = v2 * l\n\t\t\t\tif self.Simple_startangle < self.Simple_endangle:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) + vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) - vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\t\t\t\telse:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) - vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) + vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\t\t\telif i != n / 2 - 1 and i != n - 1:\n\t\t\t\tp2 = all_points[i + 1]\n\t\t\t\tu1 = asin(p1.co.y / self.Simple_b)\n\t\t\t\tu2 = asin(p2.co.y / self.Simple_b)\n\t\t\t\tif p1.co.x > 0 and p2.co.x < 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_b)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_b)\n\t\t\t\telif p1.co.x < 0 and p2.co.x > 0:\n\t\t\t\t\tu1 = acos(p1.co.x / self.Simple_b)\n\t\t\t\t\tu2 = acos(p2.co.x / self.Simple_b)\n\t\t\t\tu = u2 - u1\n\t\t\t\tif u < 0:\n\t\t\t\t\tu = -u\n\t\t\t\tl = 4 / 3 * tan(1 / 4 * u) * self.Simple_b\n\t\t\t\tv1 = Vector((-p1.co.y, p1.co.x, 0))\n\t\t\t\tv1.normalize()\n\t\t\t\tv2 = Vector((-p2.co.y, p2.co.x, 0))\n\t\t\t\tv2.normalize()\n\t\t\t\tvh1 = v1 * l\n\t\t\t\tvh2 = v2 * l\n\t\t\t\tif self.Simple_startangle < self.Simple_endangle:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) - vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) + vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\t\t\t\telse:\n\t\t\t\t\tv1 = Vector((p1.co.x, p1.co.y, 0)) + vh1\n\t\t\t\t\tv2 = Vector((p2.co.x, p2.co.y, 0)) - vh2\n\t\t\t\t\tp1.handle_right = v1\n\t\t\t\t\tp2.handle_left = v2\n\n\t\t\ti += 1\n\t\tall_points[0].handle_left_type = 'VECTOR'\n\t\tall_points[n - 1].handle_right_type = 'VECTOR'\n\t\tall_points[int(n / 2) - 1].handle_right_type = 'VECTOR'\n\t\tall_points[int(n / 2)].handle_left_type = 'VECTOR'\n\n\tSimpleCurve.Simple = True\n\tSimpleCurve.Simple_Change = False\n\tSimpleCurve.Simple_Type = self.Simple_Type\n\tSimpleCurve.Simple_startlocation = self.Simple_startlocation\n\tSimpleCurve.Simple_endlocation = self.Simple_endlocation\n\tSimpleCurve.Simple_a = self.Simple_a\n\tSimpleCurve.Simple_b = self.Simple_b\n\tSimpleCurve.Simple_h = self.Simple_h\n\tSimpleCurve.Simple_angle = self.Simple_angle\n\tSimpleCurve.Simple_startangle = self.Simple_startangle\n\tSimpleCurve.Simple_endangle = self.Simple_endangle\n\tSimpleCurve.Simple_rotation_euler = self.Simple_rotation_euler\n\tSimpleCurve.Simple_sides = self.Simple_sides\n\tSimpleCurve.Simple_radius = self.Simple_radius\n\tSimpleCurve.Simple_center = self.Simple_center\n\tSimpleCurve.Simple_width = self.Simple_width\n\tSimpleCurve.Simple_length = self.Simple_length\n\tSimpleCurve.Simple_rounded = self.Simple_rounded\n\n\tbpy.ops.object.mode_set(mode='EDIT', toggle=True)\n\tbpy.ops.curve.select_all(action='SELECT')\n\tbpy.ops.object.mode_set(mode='OBJECT', toggle=True)\n\n\treturn\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleDelete", "data": "def SimpleDelete(name):\n\tif bpy.ops.object.mode_set.poll():\n\t\tbpy.ops.object.mode_set(mode='OBJECT')\n\n\tbpy.context.scene.objects.active = bpy.data.objects[name]\n\tbpy.ops.object.delete()\n\n\treturn\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "class", "name": "Simple", "data": "class Simple(bpy.types.Operator):\n\t''''''\n\tbl_idname = \"curve.simple\"\n\tbl_label = \"Simple curve\"\n\tbl_options = {'REGISTER', 'UNDO'}\n\tbl_description = \"adds simple curve\"\n\n\t# align_matrix for the invoke\n\talign_matrix = Matrix()\n\n\t# change properties\n\tSimple = BoolProperty(name=\"Simple\",\n\t\t\t\t\t\t  default=True,\n\t\t\t\t\t\t  description=\"simple curve\")\n\n\tSimple_Change = BoolProperty(name=\"Change\",\n\t\t\t\t\t\t\t\t default=False,\n\t\t\t\t\t\t\t\t description=\"change simple curve\")\n\n\tSimple_Delete = StringProperty(name=\"Delete\",\n\t\t\t\t\t\t\t\t   description=\"Delete simple curve\")\n\n\t# general properties\n\tTypes = [('Point', 'Point', 'Point'),\n\t\t\t ('Line', 'Line', 'Line'),\n\t\t\t ('Distance', 'Distance', 'Distance'),\n\t\t\t ('Angle', 'Angle', 'Angle'),\n\t\t\t ('Circle', 'Circle', 'Circle'),\n\t\t\t ('Ellipse', 'Ellipse', 'Ellipse'),\n\t\t\t ('Arc', 'Arc', 'Arc'),\n\t\t\t ('Sector', 'Sector', 'Sector'),\n\t\t\t ('Segment', 'Segment', 'Segment'),\n\t\t\t ('Rectangle', 'Rectangle', 'Rectangle'),\n\t\t\t ('Rhomb', 'Rhomb', 'Rhomb'),\n\t\t\t ('Polygon', 'Polygon', 'Polygon'),\n\t\t\t ('Polygon_ab', 'Polygon_ab', 'Polygon_ab'),\n\t\t\t ('Trapezoid', 'Trapezoid', 'Trapezoid')]\n\tSimple_Type = EnumProperty(name=\"Type\",\n\t\t\t\t\t\t\t   description=\"Form of Curve to create\",\n\t\t\t\t\t\t\t   items=Types)\n\n\t# Line properties\n\tSimple_startlocation = FloatVectorProperty(name=\"\",\n\t\t\t\t\t\t\t\t\t\t\t   description=\"Start location\",\n\t\t\t\t\t\t\t\t\t\t\t   default=(0.0, 0.0, 0.0),\n\t\t\t\t\t\t\t\t\t\t\t   subtype='TRANSLATION')\n\tSimple_endlocation = FloatVectorProperty(name=\"\",\n\t\t\t\t\t\t\t\t\t\t\t description=\"End location\",\n\t\t\t\t\t\t\t\t\t\t\t default=(2.0, 2.0, 2.0),\n\t\t\t\t\t\t\t\t\t\t\t subtype='TRANSLATION')\n\tSimple_rotation_euler = FloatVectorProperty(name=\"\",\n\t\t\t\t\t\t\t\t\t\t\t\tdescription=\"Rotation\",\n\t\t\t\t\t\t\t\t\t\t\t\tdefault=(0.0, 0.0, 0.0),\n\t\t\t\t\t\t\t\t\t\t\t\tsubtype='EULER')\n\n\t# Trapezoid properties\n\tSimple_a = FloatProperty(name=\"a\",\n\t\t\t\t\t\t\t default=2.0,\n\t\t\t\t\t\t\t min=0.0, soft_min=0.0,\n\t\t\t\t\t\t\t unit='LENGTH',\n\t\t\t\t\t\t\t description=\"a\")\n\tSimple_b = FloatProperty(name=\"b\",\n\t\t\t\t\t\t\t default=1.0,\n\t\t\t\t\t\t\t min=0.0, soft_min=0.0,\n\t\t\t\t\t\t\t unit='LENGTH',\n\t\t\t\t\t\t\t description=\"b\")\n\tSimple_h = FloatProperty(name=\"h\",\n\t\t\t\t\t\t\t default=1.0,\n\t\t\t\t\t\t\t unit='LENGTH',\n\t\t\t\t\t\t\t description=\"h\")\n\n\tSimple_angle = FloatProperty(name=\"Angle\",\n\t\t\t\t\t\t\t\t default=45.0,\n\t\t\t\t\t\t\t\t description=\"Angle\")\n\tSimple_startangle = FloatProperty(name=\"Start angle\",\n\t\t\t\t\t\t\t\t\t  default=0.0,\n\t\t\t\t\t\t\t\t\t  min=-360.0, soft_min=-360.0,\n\t\t\t\t\t\t\t\t\t  max=360.0, soft_max=360.0,\n\t\t\t\t\t\t\t\t\t  description=\"Start angle\")\n\tSimple_endangle = FloatProperty(name=\"End angle\",\n\t\t\t\t\t\t\t\t\tdefault=45.0,\n\t\t\t\t\t\t\t\t\tmin=-360.0, soft_min=-360.0,\n\t\t\t\t\t\t\t\t\tmax=360.0, soft_max=360.0,\n\t\t\t\t\t\t\t\t\tdescription=\"End angle\")\n\n\tSimple_sides = IntProperty(name=\"sides\",\n\t\t\t\t\t\t\t   default=3,\n\t\t\t\t\t\t\t   min=0, soft_min=0,\n\t\t\t\t\t\t\t   description=\"sides\")\n\n\tSimple_radius = FloatProperty(name=\"radius\",\n\t\t\t\t\t\t\t\t  default=1.0,\n\t\t\t\t\t\t\t\t  min=0.0, soft_min=0.0,\n\t\t\t\t\t\t\t\t  unit='LENGTH',\n\t\t\t\t\t\t\t\t  description=\"radius\")\n\n\tSimple_center = BoolProperty(name=\"Length center\",\n\t\t\t\t\t\t\t\t default=True,\n\t\t\t\t\t\t\t\t description=\"Length center\")\n\n\tAngle_types = [('Degrees', 'Degrees', 'Degrees'),\n\t\t\t\t   ('Radians', 'Radians', 'Radians')]\n\tSimple_degrees_or_radians = EnumProperty(name=\"Degrees or radians\",\n\t\t\t\t\t\t\t\t\t\t\t description=\"Degrees or radians\",\n\t\t\t\t\t\t\t\t\t\t\t items=Angle_types)\n\n\t# Rectangle properties\n\tSimple_width = FloatProperty(name=\"Width\",\n\t\t\t\t\t\t\t\t default=2.0,\n\t\t\t\t\t\t\t\t min=0.0, soft_min=0,\n\t\t\t\t\t\t\t\t unit='LENGTH',\n\t\t\t\t\t\t\t\t description=\"Width\")\n\tSimple_length = FloatProperty(name=\"Length\",\n\t\t\t\t\t\t\t\t  default=2.0,\n\t\t\t\t\t\t\t\t  min=0.0, soft_min=0.0,\n\t\t\t\t\t\t\t\t  unit='LENGTH',\n\t\t\t\t\t\t\t\t  description=\"Length\")\n\tSimple_rounded = FloatProperty(name=\"Rounded\",\n\t\t\t\t\t\t\t\t   default=0.0,\n\t\t\t\t\t\t\t\t   min=0.0, soft_min=0.0,\n\t\t\t\t\t\t\t\t   unit='LENGTH',\n\t\t\t\t\t\t\t\t   description=\"Rounded\")\n\n\t# Curve Options\n\tshapeItems = [\n\t\t('2D', '2D', '2D'),\n\t\t('3D', '3D', '3D')]\n\tshape = EnumProperty(name=\"2D / 3D\",\n\t\t\t\t\t\t items=shapeItems,\n\t\t\t\t\t\t description=\"2D or 3D Curve\")\n\n\t##### DRAW #####\n\tdef draw(self, context):\n\t\tlayout = self.layout\n\n\t\t# general options\n\t\tcol = layout.column()\n\t\tcol.prop(self, 'Simple_Type')\n\n\t\tl = 0\n\t\ts = 0\n\n\t\tif self.Simple_Type == 'Line':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_endlocation')\n\t\t\tv = Vector(self.Simple_endlocation) - Vector(self.Simple_startlocation)\n\t\t\tl = v.length\n\n\t\tif self.Simple_Type == 'Distance':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_length')\n\t\t\tbox.prop(self, 'Simple_center')\n\t\t\tl = self.Simple_length\n\n\t\tif self.Simple_Type == 'Angle':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_length')\n\t\t\tbox.prop(self, 'Simple_angle')\n\t\t\trow = layout.row()\n\t\t\trow.prop(self, 'Simple_degrees_or_radians', expand=True)\n\n\t\tif self.Simple_Type == 'Circle':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_sides')\n\t\t\tbox.prop(self, 'Simple_radius')\n\t\t\tl = 2 * pi * abs(self.Simple_radius)\n\t\t\ts = pi * self.Simple_radius * self.Simple_radius\n\n\t\tif self.Simple_Type == 'Ellipse':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_a')\n\t\t\tbox.prop(self, 'Simple_b')\n\t\t\tl = pi * (3 * (self.Simple_a + self.Simple_b) - sqrt((3 * self.Simple_a + self.Simple_b) * (self.Simple_a + 3 * self.Simple_b)))\n\t\t\ts = pi * abs(self.Simple_b) * abs(self.Simple_a)\n\n\t\tif self.Simple_Type == 'Arc':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_sides')\n\t\t\tbox.prop(self, 'Simple_radius')\n\t\t\tbox.prop(self, 'Simple_startangle')\n\t\t\tbox.prop(self, 'Simple_endangle')\n\t\t\trow = layout.row()\n\t\t\trow.prop(self, 'Simple_degrees_or_radians', expand=True)\n\t\t\tl = abs(pi * self.Simple_radius * (self.Simple_endangle - self.Simple_startangle) / 180)\n\n\t\tif self.Simple_Type == 'Sector':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_sides')\n\t\t\tbox.prop(self, 'Simple_radius')\n\t\t\tbox.prop(self, 'Simple_startangle')\n\t\t\tbox.prop(self, 'Simple_endangle')\n\t\t\trow = layout.row()\n\t\t\trow.prop(self, 'Simple_degrees_or_radians', expand=True)\n\t\t\tl = abs(pi * self.Simple_radius * (self.Simple_endangle - self.Simple_startangle) / 180) + self.Simple_radius * 2\n\t\t\ts = pi * self.Simple_radius * self.Simple_radius * abs(self.Simple_endangle - self.Simple_startangle) / 360\n\n\t\tif self.Simple_Type == 'Segment':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_sides')\n\t\t\tbox.prop(self, 'Simple_a')\n\t\t\tbox.prop(self, 'Simple_b')\n\t\t\tbox.prop(self, 'Simple_startangle')\n\t\t\tbox.prop(self, 'Simple_endangle')\n\t\t\trow = layout.row()\n\t\t\trow.prop(self, 'Simple_degrees_or_radians', expand=True)\n\t\t\tla = abs(pi * self.Simple_a * (self.Simple_endangle - self.Simple_startangle) / 180)\n\t\t\tlb = abs(pi * self.Simple_b * (self.Simple_endangle - self.Simple_startangle) / 180)\n\t\t\tl = abs(self.Simple_a - self.Simple_b) * 2 + la + lb\n\t\t\tsa = pi * self.Simple_a * self.Simple_a * abs(self.Simple_endangle - self.Simple_startangle) / 360\n\t\t\tsb = pi * self.Simple_b * self.Simple_b * abs(self.Simple_endangle - self.Simple_startangle) / 360\n\t\t\ts = abs(sa - sb)\n\n\t\tif self.Simple_Type == 'Rectangle':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_width')\n\t\t\tbox.prop(self, 'Simple_length')\n\t\t\tbox.prop(self, 'Simple_rounded')\n\t\t\tbox.prop(self, 'Simple_center')\n\t\t\tl = 2 * abs(self.Simple_width) + 2 * abs(self.Simple_length)\n\t\t\ts = abs(self.Simple_width) * abs(self.Simple_length)\n\n\t\tif self.Simple_Type == 'Rhomb':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_width')\n\t\t\tbox.prop(self, 'Simple_length')\n\t\t\tbox.prop(self, 'Simple_center')\n\t\t\tg = hypot(self.Simple_width / 2, self.Simple_length / 2)\n\t\t\tl = 4 * g\n\t\t\ts = self.Simple_width * self.Simple_length / 2\n\n\t\tif self.Simple_Type == 'Polygon':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_sides')\n\t\t\tbox.prop(self, 'Simple_radius')\n\n\t\tif self.Simple_Type == 'Polygon_ab':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_sides')\n\t\t\tbox.prop(self, 'Simple_a')\n\t\t\tbox.prop(self, 'Simple_b')\n\n\t\tif self.Simple_Type == 'Trapezoid':\n\t\t\tcol.label(text=self.Simple_Type + \" Options\")\n\t\t\tbox = layout.box()\n\t\t\tbox.prop(self, 'Simple_a')\n\t\t\tbox.prop(self, 'Simple_b')\n\t\t\tbox.prop(self, 'Simple_h')\n\t\t\tbox.prop(self, 'Simple_center')\n\t\t\tg = hypot(self.Simple_h, (self.Simple_a - self.Simple_b) / 2)\n\t\t\tl = self.Simple_a + self.Simple_b + g * 2\n\t\t\ts = (abs(self.Simple_a) + abs(self.Simple_b)) / 2 * self.Simple_h\n\n\t\trow = layout.row()\n\t\trow.prop(self, 'shape', expand=True)\n\t\tbox = layout.box()\n\t\tbox.label(\"Location:\")\n\t\tbox.prop(self, 'Simple_startlocation')\n\t\tbox = layout.box()\n\t\tbox.label(\"Rotation:\")\n\t\tbox.prop(self, 'Simple_rotation_euler')\n\t\tif l != 0:\n\t\t\tl_str = str(round(l, 4))\n\t\t\trow = layout.row()\n\t\t\trow.label(\"Length: \" + l_str)\n\t\tif s != 0:\n\t\t\ts_str = str(round(s, 4))\n\t\t\trow = layout.row()\n\t\t\trow.label(\"Area: \" + s_str)\n\n\t##### POLL #####\n\t@classmethod\n\tdef poll(cls, context):\n\t\treturn context.scene != None\n\n\t##### EXECUTE #####\n\tdef execute(self, context):\n\t\tif self.Simple_Change:\n\t\t\tSimpleDelete(self.Simple_Delete)\n\n\t\t# go to object mode\n\t\tif bpy.ops.object.mode_set.poll():\n\t\t\tbpy.ops.object.mode_set(mode='OBJECT')\n\n\t\t# turn off undo\n\t\tundo = bpy.context.user_preferences.edit.use_global_undo\n\t\tbpy.context.user_preferences.edit.use_global_undo = False\n\n\t\t# main function\n\t\tself.align_matrix = align_matrix(context, self.Simple_startlocation)\n\t\tmain(context, self, self.align_matrix)\n\n\t\t# restore pre operator undo state\n\t\tbpy.context.user_preferences.edit.use_global_undo = undo\n\n\t\treturn {'FINISHED'}\n\n\t##### INVOKE #####\n\tdef invoke(self, context, event):\n\t\t# store creation_matrix\n\t\tif self.Simple_Change:\n\t\t\tbpy.context.scene.cursor_location = self.Simple_startlocation\n\t\telse:\n\t\t\tself.Simple_startlocation = bpy.context.scene.cursor_location\n\n\t\tself.align_matrix = align_matrix(context, self.Simple_startlocation)\n\t\tself.execute(context)\n\n\t\treturn {'FINISHED'}\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "class", "name": "BezierPointsFillet", "data": "class BezierPointsFillet(bpy.types.Operator):\n\t''''''\n\tbl_idname = \"curve.bezier_points_fillet\"\n\tbl_label = \"Bezier points fillet\"\n\tbl_options = {'REGISTER', 'UNDO'}\n\tbl_description = \"bezier points fillet\"\n\n\tFillet_radius = FloatProperty(name=\"Radius\",\n\t\t\t\t\t\t\t\t  default=0.25,\n\t\t\t\t\t\t\t\t  unit='LENGTH',\n\t\t\t\t\t\t\t\t  description=\"radius\")\n\n\tTypes = [('Round', 'Round', 'Round'),\n\t\t\t ('Chamfer', 'Chamfer', 'Chamfer')]\n\tFillet_Type = EnumProperty(name=\"Type\",\n\t\t\t\t\t\t\t   description=\"Fillet type\",\n\t\t\t\t\t\t\t   items=Types)\n\n\t##### DRAW #####\n\tdef draw(self, context):\n\t\tlayout = self.layout\n\n\t\t# general options\n\t\tcol = layout.column()\n\t\tcol.prop(self, 'Fillet_radius')\n\t\tcol.prop(self, 'Fillet_Type', expand=True)\n\n\t##### POLL #####\n\t@classmethod\n\tdef poll(cls, context):\n\t\treturn context.scene != None\n\n\t##### EXECUTE #####\n\tdef execute(self, context):\n\t\t# go to object mode\n\t\tif bpy.ops.object.mode_set.poll():\n\t\t\tbpy.ops.object.mode_set(mode='OBJECT')\n\t\t\tbpy.ops.object.mode_set(mode='EDIT')\n\n\t\t# turn off undo\n\t\tundo = bpy.context.user_preferences.edit.use_global_undo\n\t\tbpy.context.user_preferences.edit.use_global_undo = False\n\n\t\t# main function\n\t\tspline = bpy.context.object.data.splines.active\n\t\tselected = [p for p in spline.bezier_points if p.select_control_point]\n\n\t\tbpy.ops.curve.handle_type_set(type='VECTOR')\n\t\tn = 0\n\t\tii = []\n\t\tfor p in spline.bezier_points:\n\t\t\tif p.select_control_point:\n\t\t\t\tii.append(n)\n\t\t\t\tn += 1\n\t\t\telse:\n\t\t\t\tn += 1\n\n\t\tif n > 2:\n\n\t\t\tjn = 0\n\n\t\t\tfor j in ii:\n\n\t\t\t\tj += jn\n\n\t\t\t\tselected_all = [p for p in spline.bezier_points]\n\n\t\t\t\tbpy.ops.curve.select_all(action='DESELECT')\n\n\t\t\t\tif j != 0 and j != n - 1:\n\t\t\t\t\tselected_all[j].select_control_point = True\n\t\t\t\t\tselected_all[j + 1].select_control_point = True\n\t\t\t\t\tbpy.ops.curve.subdivide()\n\t\t\t\t\tselected_all = [p for p in spline.bezier_points]\n\t\t\t\t\tselected4 = [selected_all[j - 1], selected_all[j], selected_all[j + 1], selected_all[j + 2]]\n\t\t\t\t\tjn += 1\n\t\t\t\t\tn += 1\n\n\t\t\t\telif j == 0:\n\t\t\t\t\tselected_all[j].select_control_point = True\n\t\t\t\t\tselected_all[j + 1].select_control_point = True\n\t\t\t\t\tbpy.ops.curve.subdivide()\n\t\t\t\t\tselected_all = [p for p in spline.bezier_points]\n\t\t\t\t\tselected4 = [selected_all[n], selected_all[0], selected_all[1], selected_all[2]]\n\t\t\t\t\tjn += 1\n\t\t\t\t\tn += 1\n\n\t\t\t\telif j == n - 1:\n\t\t\t\t\tselected_all[j].select_control_point = True\n\t\t\t\t\tselected_all[j - 1].select_control_point = True\n\t\t\t\t\tbpy.ops.curve.subdivide()\n\t\t\t\t\tselected_all = [p for p in spline.bezier_points]\n\t\t\t\t\tselected4 = [selected_all[0], selected_all[n], selected_all[n - 1], selected_all[n - 2]]\n\n\t\t\t\tselected4[2].co = selected4[1].co\n\t\t\t\ts1 = Vector(selected4[0].co) - Vector(selected4[1].co)\n\t\t\t\ts2 = Vector(selected4[3].co) - Vector(selected4[2].co)\n\t\t\t\ts1.normalize()\n\t\t\t\ts11 = Vector(selected4[1].co) + s1 * self.Fillet_radius\n\t\t\t\tselected4[1].co = s11\n\t\t\t\ts2.normalize()\n\t\t\t\ts22 = Vector(selected4[2].co) + s2 * self.Fillet_radius\n\t\t\t\tselected4[2].co = s22\n\n\t\t\t\tif self.Fillet_Type == 'Round':\n\t\t\t\t\tif j != n - 1:\n\t\t\t\t\t\tselected4[2].handle_right_type = 'VECTOR'\n\t\t\t\t\t\tselected4[1].handle_left_type = 'VECTOR'\n\t\t\t\t\t\tselected4[1].handle_right_type = 'ALIGNED'\n\t\t\t\t\t\tselected4[2].handle_left_type = 'ALIGNED'\n\t\t\t\t\telse:\n\t\t\t\t\t\tselected4[1].handle_right_type = 'VECTOR'\n\t\t\t\t\t\tselected4[2].handle_left_type = 'VECTOR'\n\t\t\t\t\t\tselected4[2].handle_right_type = 'ALIGNED'\n\t\t\t\t\t\tselected4[1].handle_left_type = 'ALIGNED'\n\t\t\t\tif self.Fillet_Type == 'Chamfer':\n\t\t\t\t\tselected4[2].handle_right_type = 'VECTOR'\n\t\t\t\t\tselected4[1].handle_left_type = 'VECTOR'\n\t\t\t\t\tselected4[1].handle_right_type = 'VECTOR'\n\t\t\t\t\tselected4[2].handle_left_type = 'VECTOR'\n\n\t\tbpy.ops.curve.select_all(action='SELECT')\n\t\tbpy.ops.curve.spline_type_set(type='BEZIER')\n\n\t\t# restore pre operator undo state\n\t\tbpy.context.user_preferences.edit.use_global_undo = undo\n\n\t\treturn {'FINISHED'}\n\n\t##### INVOKE #####\n\tdef invoke(self, context, event):\n\t\tself.execute(context)\n\n\t\treturn {'FINISHED'}\n\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "subdivide_cubic_bezier", "data": "def subdivide_cubic_bezier(p1, p2, p3, p4, t):\n\tp12 = (p2 - p1) * t + p1\n\tp23 = (p3 - p2) * t + p2\n\tp34 = (p4 - p3) * t + p3\n\tp123 = (p23 - p12) * t + p12\n\tp234 = (p34 - p23) * t + p23\n\tp1234 = (p234 - p123) * t + p123\n\treturn [p12, p123, p1234, p234, p34]\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "class", "name": "BezierDivide", "data": "class BezierDivide(bpy.types.Operator):\n\t''''''\n\tbl_idname = \"curve.bezier_spline_divide\"\n\tbl_label = \"Bezier Divide (enters edit mode) for Fillet Curves\"\n\tbl_options = {'REGISTER', 'UNDO'}\n\tbl_description = \"bezier spline divide\"\n\n\t# align_matrix for the invoke\n\talign_matrix = Matrix()\n\n\tBezier_t = FloatProperty(name=\"t (0% - 100%)\",\n\t\t\t\t\t\t\t default=50.0,\n\t\t\t\t\t\t\t min=0.0, soft_min=0.0,\n\t\t\t\t\t\t\t max=100.0, soft_max=100.0,\n\t\t\t\t\t\t\t description=\"t (0% - 100%)\")\n\n\t##### POLL #####\n\t@classmethod\n\tdef poll(cls, context):\n\t\treturn context.scene != None\n\n\t##### EXECUTE #####\n\tdef execute(self, context):\n\t\t# go to object mode\n\t\tif bpy.ops.object.mode_set.poll():\n\t\t\tbpy.ops.object.mode_set(mode='OBJECT')\n\t\t\tbpy.ops.object.mode_set(mode='EDIT')\n\n\t\t# turn off undo\n\t\tundo = bpy.context.user_preferences.edit.use_global_undo\n\t\tbpy.context.user_preferences.edit.use_global_undo = False\n\n\t\t# main function\n\t\tspline = bpy.context.object.data.splines.active\n\t\tvertex = []\n\t\tselected_all = [p for p in spline.bezier_points if p.select_control_point]\n\t\th = subdivide_cubic_bezier(selected_all[0].co, selected_all[0].handle_right, selected_all[1].handle_left, selected_all[1].co, self.Bezier_t / 100)\n\n\t\tselected_all[0].handle_right_type = 'FREE'\n\t\tselected_all[0].handle_left_type = 'FREE'\n\t\tselected_all[1].handle_right_type = 'FREE'\n\t\tselected_all[1].handle_left_type = 'FREE'\n\t\tbpy.ops.curve.subdivide(1)\n\t\tselected_all = [p for p in spline.bezier_points if p.select_control_point]\n\n\t\tselected_all[0].handle_right = h[0]\n\t\tselected_all[1].co = h[2]\n\t\tselected_all[1].handle_left = h[1]\n\t\tselected_all[1].handle_right = h[3]\n\t\tselected_all[2].handle_left = h[4]\n\n\t\t# restore pre operator undo state\n\t\tbpy.context.user_preferences.edit.use_global_undo = undo\n\n\t\treturn {'FINISHED'}\n\n\t##### INVOKE #####\n\tdef invoke(self, context, event):\n\t\tself.execute(context)\n\n\t\treturn {'FINISHED'}\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "class", "name": "SimplePanel", "data": "class SimplePanel(bpy.types.Panel):\n\n\tbl_label = \"Simple change\"\n\tbl_space_type = \"VIEW_3D\"\n\tbl_region_type = \"TOOLS\"\n\tbl_options = {'DEFAULT_CLOSED'}\n\tbl_category = \"Tools\"\n\n\t##### POLL #####\n\t@classmethod\n\tdef poll(cls, context):\n\t\tif context.object.Simple == True:\n\t\t\treturn (context.object)\n\n\t##### DRAW #####\n\tdef draw(self, context):\n\t\tif context.object.Simple == True:\n\t\t\tlayout = self.layout\n\n\t\t\tobj = context.object\n\t\t\trow = layout.row()\n\t\t\tsimple_change = row.operator(\"curve.simple\", text='Change')\n\t\t\tsimple_change.Simple_Change = True\n\t\t\tsimple_change.Simple_Delete = obj.name\n\t\t\tsimple_change.Simple_Type = obj.Simple_Type\n\t\t\tsimple_change.Simple_startlocation = obj.location\n\t\t\tsimple_change.Simple_endlocation = obj.Simple_endlocation\n\t\t\tsimple_change.Simple_a = obj.Simple_a\n\t\t\tsimple_change.Simple_b = obj.Simple_b\n\t\t\tsimple_change.Simple_h = obj.Simple_h\n\t\t\tsimple_change.Simple_angle = obj.Simple_angle\n\t\t\tsimple_change.Simple_startangle = obj.Simple_startangle\n\t\t\tsimple_change.Simple_endangle = obj.Simple_endangle\n\t\t\tsimple_change.Simple_rotation_euler = obj.rotation_euler\n\t\t\tsimple_change.Simple_sides = obj.Simple_sides\n\t\t\tsimple_change.Simple_radius = obj.Simple_radius\n\t\t\tsimple_change.Simple_center = obj.Simple_center\n\t\t\tsimple_change.Simple_width = obj.Simple_width\n\t\t\tsimple_change.Simple_length = obj.Simple_length\n\t\t\tsimple_change.Simple_rounded = obj.Simple_rounded\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "class", "name": "SimpleEdit", "data": "class SimpleEdit(bpy.types.Operator):\n\n\t\"\"\"Curve Simple\"\"\"\n\tbl_idname = \"object._simple_edit\"\n\tbl_label = \"Create Curves\"\n\tbl_options = {'REGISTER', 'UNDO'}\n\tbl_description = \"Subdivide & Fillet Curves\"\n\n\t##### POLL #####\n\t@classmethod\n\tdef poll(cls, context):\n\t\tvertex = []\n\t\tnselected = []\n\t\tn = 0\n\t\tobj = context.active_object\n\t\tif obj != None:\n\t\t\tif obj.type == 'CURVE':\n\t\t\t\tfor i in obj.data.splines:\n\t\t\t\t\tfor j in i.bezier_points:\n\t\t\t\t\t\tn += 1\n\t\t\t\t\t\tif j.select_control_point:\n\t\t\t\t\t\t\tnselected.append(n)\n\t\t\t\t\t\t\tvertex.append(obj.matrix_world * j.co)\n\n\t\t\tif len(vertex) > 0 and n > 2:\n\t\t\t\treturn (context.active_object)\n\t\t\tif len(vertex) == 2 and abs(nselected[0] - nselected[1]) == 1:\n\t\t\t\treturn (context.active_object)\n\n\t\tselected = 0\n\t\tfor obj in context.selected_objects:\n\t\t\tif obj.type == 'CURVE':\n\t\t\t\tselected += 1\n\n\t\tif selected >= 2:\n\t\t\treturn (context.selected_objects)\n\n\t##### DRAW #####\n\tdef draw(self, context):\n\t\tvertex = []\n\t\tselected = []\n\t\tn = 0\n\t\tobj = context.active_object\n\t\tif obj != None:\n\t\t\tif obj.type == 'CURVE':\n\t\t\t\tfor i in obj.data.splines:\n\t\t\t\t\tfor j in i.bezier_points:\n\t\t\t\t\t\tn += 1\n\t\t\t\t\t\tif j.select_control_point:\n\t\t\t\t\t\t\tselected.append(n)\n\t\t\t\t\t\t\tvertex.append(obj.matrix_world * j.co)\n\n\t\t\tif len(vertex) > 0 and n > 2:\n\t\t\t\tlayout = self.layout\n\t\t\t\trow = layout.row()\n\t\t\t\tsimple_edit = row.operator(\"curve.bezier_points_fillet\", text='Fillet')\n\t\t\tif len(vertex) == 2 and abs(selected[0] - selected[1]) == 1:\n\t\t\t\tlayout = self.layout\n\t\t\t\trow = layout.row()\n\t\t\t\tsimple_divide = row.operator(\"curve.bezier_spline_divide\", text='Divide')\n", "description": "Curve Simple", "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "StartLocationUpdate", "data": "def StartLocationUpdate(self, context):\n\n\tbpy.context.scene.cursor_location = self.Simple_startlocation\n\n\treturn\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "SimpleVariables", "data": "def SimpleVariables():\n\n\tbpy.types.Object.Simple = bpy.props.BoolProperty()\n\tbpy.types.Object.Simple_Change = bpy.props.BoolProperty()\n\t# general properties\n\tTypes = [('Point', 'Point', 'Point'),\n\t\t\t ('Line', 'Line', 'Line'),\n\t\t\t ('Distance', 'Distance', 'Distance'),\n\t\t\t ('Angle', 'Angle', 'Angle'),\n\t\t\t ('Circle', 'Circle', 'Circle'),\n\t\t\t ('Ellipse', 'Ellipse', 'Ellipse'),\n\t\t\t ('Arc', 'Arc', 'Arc'),\n\t\t\t ('Sector', 'Sector', 'Sector'),\n\t\t\t ('Segment', 'Segment', 'Segment'),\n\t\t\t ('Rectangle', 'Rectangle', 'Rectangle'),\n\t\t\t ('Rhomb', 'Rhomb', 'Rhomb'),\n\t\t\t ('Polygon', 'Polygon', 'Polygon'),\n\t\t\t ('Polygon_ab', 'Polygon_ab', 'Polygon_ab'),\n\t\t\t ('Trapezoid', 'Trapezoid', 'Trapezoid')]\n\tbpy.types.Object.Simple_Type = bpy.props.EnumProperty(name=\"Type\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t  description=\"Form of Curve to create\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t  items=Types)\n\n\t# Line properties\n\tbpy.types.Object.Simple_startlocation = bpy.props.FloatVectorProperty(name=\"Start location\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  description=\"Start location\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  default=(0.0, 0.0, 0.0),\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  subtype='TRANSLATION',\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  update=StartLocationUpdate)\n\tbpy.types.Object.Simple_endlocation = bpy.props.FloatVectorProperty(name=\"End location\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdescription=\"End location\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdefault=(2.0, 2.0, 2.0),\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tsubtype='TRANSLATION')\n\tbpy.types.Object.Simple_rotation_euler = bpy.props.FloatVectorProperty(name=\"Rotation\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   description=\"Rotation\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   default=(0.0, 0.0, 0.0),\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   subtype='EULER')\n\n\t# Trapezoid properties\n\tbpy.types.Object.Simple_a = bpy.props.FloatProperty(name=\"a\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tdefault=2.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tmin=0.0, soft_min=0.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tunit='LENGTH',\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tdescription=\"a\")\n\tbpy.types.Object.Simple_b = bpy.props.FloatProperty(name=\"b\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tdefault=1.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tmin=0.0, soft_min=0.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tunit='LENGTH',\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tdescription=\"b\")\n\tbpy.types.Object.Simple_h = bpy.props.FloatProperty(name=\"h\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tdefault=1.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tunit='LENGTH',\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tdescription=\"h\")\n\n\tbpy.types.Object.Simple_angle = bpy.props.FloatProperty(name=\"Angle\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdefault=45.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdescription=\"Angle\")\n\tbpy.types.Object.Simple_startangle = bpy.props.FloatProperty(name=\"Start angle\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t default=0.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t min=-360.0, soft_min=-360.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t max=360.0, soft_max=360.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t description=\"Start angle\")\n\tbpy.types.Object.Simple_endangle = bpy.props.FloatProperty(name=\"End angle\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   default=45.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   min=-360.0, soft_min=-360.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   max=360.0, soft_max=360.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   description=\"End angle\")\n\n\tbpy.types.Object.Simple_sides = bpy.props.IntProperty(name=\"sides\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t  default=3,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t  min=3, soft_min=3,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t  description=\"sides\")\n\n\tbpy.types.Object.Simple_radius = bpy.props.FloatProperty(name=\"radius\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t default=1.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t min=0.0, soft_min=0.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t unit='LENGTH',\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t description=\"radius\")\n\n\tbpy.types.Object.Simple_center = bpy.props.BoolProperty(name=\"Length center\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdefault=True,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdescription=\"Length center\")\n\n\t# Rectangle properties\n\tbpy.types.Object.Simple_width = bpy.props.FloatProperty(name=\"Width\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdefault=2.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tmin=0.0, soft_min=0.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tunit='LENGTH',\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdescription=\"Width\")\n\tbpy.types.Object.Simple_length = bpy.props.FloatProperty(name=\"Length\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t default=2.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t min=0.0, soft_min=0.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t unit='LENGTH',\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t description=\"Length\")\n\tbpy.types.Object.Simple_rounded = bpy.props.FloatProperty(name=\"Rounded\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  default=0.0,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  unit='LENGTH',\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  description=\"Rounded\")\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "class", "name": "INFO_MT_simple_menu", "data": "class INFO_MT_simple_menu(bpy.types.Menu):\n\t# Define the \"Extras\" menu\n\tbl_idname = \"INFO_MT_simple_menu\"\n\tbl_label = \"Curve Objects\"\n\n\tdef draw(self, context):\n\t\tself.layout.operator_context = 'INVOKE_REGION_WIN'\n\n\t\toper2 = self.layout.operator(Simple.bl_idname, text=\"Point\", icon=\"PLUGIN\")\n\t\toper2.Simple_Change = False\n\t\toper2.Simple_Type = \"Point\"\n\n\t\toper3 = self.layout.operator(Simple.bl_idname, text=\"Line\", icon=\"PLUGIN\")\n\t\toper3.Simple_Change = False\n\t\toper3.Simple_Type = \"Line\"\n\n\t\toper4 = self.layout.operator(Simple.bl_idname, text=\"Distance\", icon=\"PLUGIN\")\n\t\toper4.Simple_Change = False\n\t\toper4.Simple_Type = \"Distance\"\n\n\t\toper5 = self.layout.operator(Simple.bl_idname, text=\"Angle\", icon=\"PLUGIN\")\n\t\toper5.Simple_Change = False\n\t\toper5.Simple_Type = \"Angle\"\n\n\t\toper6 = self.layout.operator(Simple.bl_idname, text=\"Circle\", icon=\"PLUGIN\")\n\t\toper6.Simple_Change = False\n\t\toper6.Simple_Type = \"Circle\"\n\n\t\toper7 = self.layout.operator(Simple.bl_idname, text=\"Ellipse\", icon=\"PLUGIN\")\n\t\toper7.Simple_Change = False\n\t\toper7.Simple_Type = \"Ellipse\"\n\n\t\toper8 = self.layout.operator(Simple.bl_idname, text=\"Arc\", icon=\"PLUGIN\")\n\t\toper8.Simple_Change = False\n\t\toper8.Simple_Type = \"Arc\"\n\n\t\toper9 = self.layout.operator(Simple.bl_idname, text=\"Sector\", icon=\"PLUGIN\")\n\t\toper9.Simple_Change = False\n\t\toper9.Simple_Type = \"Sector\"\n\n\t\toper10 = self.layout.operator(Simple.bl_idname, text=\"Segment\", icon=\"PLUGIN\")\n\t\toper10.Simple_Change = False\n\t\toper10.Simple_Type = \"Segment\"\n\n\t\toper11 = self.layout.operator(Simple.bl_idname, text=\"Rectangle\", icon=\"PLUGIN\")\n\t\toper11.Simple_Change = False\n\t\toper11.Simple_Type = \"Rectangle\"\n\n\t\toper12 = self.layout.operator(Simple.bl_idname, text=\"Rhomb\", icon=\"PLUGIN\")\n\t\toper12.Simple_Change = False\n\t\toper12.Simple_Type = \"Rhomb\"\n\n\t\toper13 = self.layout.operator(Simple.bl_idname, text=\"Polygon\", icon=\"PLUGIN\")\n\t\toper13.Simple_Change = False\n\t\toper13.Simple_Type = \"Polygon\"\n\n\t\toper14 = self.layout.operator(Simple.bl_idname, text=\"Polygon_ab\", icon=\"PLUGIN\")\n\t\toper14.Simple_Change = False\n\t\toper14.Simple_Type = \"Polygon_ab\"\n\n\t\toper15 = self.layout.operator(Simple.bl_idname, text=\"Trapezoid\", icon=\"PLUGIN\")\n\t\toper15.Simple_Change = False\n\t\toper15.Simple_Type = \"Trapezoid\"\n\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "Simple_button", "data": "def Simple_button(self, context):\n\toper11 = self.layout.operator(Simple.bl_idname, text=\"Rectangle\", icon=\"PLUGIN\")\n\toper11.Simple_Change = False\n\toper11.Simple_Type = \"Rectangle\"\n\n\tself.layout.menu(\"INFO_MT_simple_menu\", icon=\"PLUGIN\")\n\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "register", "data": "def register():\n\tbpy.utils.register_class(Simple)\n\tbpy.utils.register_class(BezierPointsFillet)\n\tbpy.utils.register_class(BezierDivide)\n\tbpy.utils.register_class(SimplePanel)\n\tbpy.utils.register_class(SimpleEdit)\n\tbpy.utils.register_class(INFO_MT_simple_menu)\n\n\tbpy.types.INFO_MT_curve_add.append(Simple_button)\n\n\tSimpleVariables()\n\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}, {"term": "def", "name": "unregister", "data": "def unregister():\n\tbpy.utils.unregister_class(Simple)\n\tbpy.utils.unregister_class(BezierPointsFillet)\n\tbpy.utils.unregister_class(BezierDivide)\n\tbpy.utils.unregister_class(SimplePanel)\n\tbpy.utils.unregister_class(SimpleEdit)\n\tbpy.utils.unregister_class(INFO_MT_simple_menu)\n\n\tbpy.types.INFO_MT_curve_add.remove(Simple_button)\n", "description": null, "category": "simple", "imports": ["#### import modules", "import bpy", "from bpy.props import *", "from mathutils import *", "from math import *", "from bpy_extras.object_utils import *", "from random import *"]}], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [{"term": "def", "name": "all_patterns", "data": "def all_patterns(name):\n\tu\"\"\"\n\tAccepts a string and returns a pattern of possible patterns involving that name\n\tCalled by simple_mapping_to_pattern for each name in the mapping it receives.\n\t\"\"\"\n\n\t# i_ denotes an import-like node\n\t# u_ denotes a node that appears to be a usage of the name\n\tif u'.' in name:\n\t\tname, attr = name.split(u'.', 1)\n\t\tsimple_name = simple_name_match % (name)\n\t\tsimple_attr = subname_match % (attr)\n\t\tdotted_name = dotted_name_match % (simple_name, simple_attr)\n\t\ti_from = from_import_match % (dotted_name)\n\t\ti_from_submod = from_import_submod_match % (simple_name, simple_attr, simple_attr, simple_attr, simple_attr)\n\t\ti_name = name_import_match % (dotted_name, dotted_name)\n\t\tu_name = power_twoname_match % (simple_name, simple_attr)\n\t\tu_subname = power_subname_match % (simple_attr)\n\t\treturn u' | \\n'.join((i_name, i_from, i_from_submod, u_name, u_subname))\n\telse:\n\t\tsimple_name = simple_name_match % (name)\n\t\ti_name = name_import_match % (simple_name, simple_name)\n\t\ti_from = from_import_match % (simple_name)\n\t\tu_name = power_onename_match % (simple_name)\n\t\treturn u' | \\n'.join((i_name, i_from, u_name))\n\n", "description": "\n\tAccepts a string and returns a pattern of possible patterns involving that name\n\tCalled by simple_mapping_to_pattern for each name in the mapping it receives.\n\t", "category": "simple", "imports": ["Fixer for standard library imports renamed in Python 3", "from lib2to3 import fixer_base", "from lib2to3.fixer_util import Name, is_probably_builtin, Newline, does_tree_import", "from lib2to3.pygram import python_symbols as syms", "from lib2to3.pgen2 import token", "from lib2to3.pytree import Node, Leaf", "from libfuturize.fixer_util import touch_import_top", "# from ..fixer_util import NameImport", "# helps match 'queue', as in 'from queue import ...'", "# helps match 'client', to be used if client has been imported from http", "# helps match 'http.client', as in 'import urllib.request'", "# helps match 'client.HTTPConnection', if 'client' has been imported from http", "# helps match 'from http.client import HTTPConnection'", "from_import_match = u\"from_import=import_from< 'from' %s 'import' imported=any >\"", "# helps match 'from http import client'", "from_import_submod_match = u\"from_import_submod=import_from< 'from' %s 'import' (%s | import_as_name< %s 'as' renamed=any > | import_as_names< any* (%s | import_as_name< %s 'as' renamed=any >) any* > ) >\"", "# helps match 'import urllib.request'", "name_import_match = u\"name_import=import_name< 'import' %s > | name_import=import_name< 'import' dotted_as_name< %s 'as' renamed=any > >\"", "# helps match 'import http.client, winreg'", "multiple_name_import_match = u\"name_import=import_name< 'import' dotted_as_names< names=any* > >\"", "\t# i_ denotes an import-like node", "\t\ti_from = from_import_match % (dotted_name)", "\t\ti_from_submod = from_import_submod_match % (simple_name, simple_attr, simple_attr, simple_attr, simple_attr)", "\t\ti_name = name_import_match % (dotted_name, dotted_name)", "\t\ti_name = name_import_match % (simple_name, simple_name)", "\t\ti_from = from_import_match % (simple_name)", "\tPATTERN = u' | \\n'.join((PATTERN, multiple_name_import_match))", "\t\ttouch_import_top(u'future', u'standard_library', node)"]}, {"term": "class", "name": "FixImports", "data": "class FixImports(fixer_base.BaseFix):\n\n\tPATTERN = u' | \\n'.join([all_patterns(name) for name in MAPPING])\n\tPATTERN = u' | \\n'.join((PATTERN, multiple_name_import_match))\n\n\tdef transform(self, node, results):\n\t\ttouch_import_top(u'future', u'standard_library', node)\n", "description": null, "category": "simple", "imports": ["Fixer for standard library imports renamed in Python 3", "from lib2to3 import fixer_base", "from lib2to3.fixer_util import Name, is_probably_builtin, Newline, does_tree_import", "from lib2to3.pygram import python_symbols as syms", "from lib2to3.pgen2 import token", "from lib2to3.pytree import Node, Leaf", "from libfuturize.fixer_util import touch_import_top", "# from ..fixer_util import NameImport", "# helps match 'queue', as in 'from queue import ...'", "# helps match 'client', to be used if client has been imported from http", "# helps match 'http.client', as in 'import urllib.request'", "# helps match 'client.HTTPConnection', if 'client' has been imported from http", "# helps match 'from http.client import HTTPConnection'", "from_import_match = u\"from_import=import_from< 'from' %s 'import' imported=any >\"", "# helps match 'from http import client'", "from_import_submod_match = u\"from_import_submod=import_from< 'from' %s 'import' (%s | import_as_name< %s 'as' renamed=any > | import_as_names< any* (%s | import_as_name< %s 'as' renamed=any >) any* > ) >\"", "# helps match 'import urllib.request'", "name_import_match = u\"name_import=import_name< 'import' %s > | name_import=import_name< 'import' dotted_as_name< %s 'as' renamed=any > >\"", "# helps match 'import http.client, winreg'", "multiple_name_import_match = u\"name_import=import_name< 'import' dotted_as_names< names=any* > >\"", "\t# i_ denotes an import-like node", "\t\ti_from = from_import_match % (dotted_name)", "\t\ti_from_submod = from_import_submod_match % (simple_name, simple_attr, simple_attr, simple_attr, simple_attr)", "\t\ti_name = name_import_match % (dotted_name, dotted_name)", "\t\ti_name = name_import_match % (simple_name, simple_name)", "\t\ti_from = from_import_match % (simple_name)", "\tPATTERN = u' | \\n'.join((PATTERN, multiple_name_import_match))", "\t\ttouch_import_top(u'future', u'standard_library', node)"]}], [{"term": "def", "name": "smile_draw", "data": "def smile_draw(x_coord, y_coord, color):\n\tcenter_point = simple_draw.get_point(x_coord,y_coord)\n\tsimple_draw.circle(center_position=center_point, radius=30, color=color, width=2)\n\tleft_eye_sp = simple_draw.get_point(center_point.x - 15, center_point.y + 10)\n\tleft_eye_ep = simple_draw.get_point(center_point.x - 5, center_point.y + 10)\n\tsimple_draw.line(left_eye_sp, left_eye_ep, color, width=2)\n\tright_eye_sp = simple_draw.get_point(center_point.x + 15, center_point.y + 10)\n\tright_eye_ep = simple_draw.get_point(center_point.x + 5, center_point.y + 10)\n\tsimple_draw.line(right_eye_sp, right_eye_ep, color, width=2)\n\tmouth_sp = simple_draw.get_point(center_point.x - 10, center_point.y - 10)\n\tmouth_ep = simple_draw.get_point(center_point.x + 10, center_point.y - 10)\n\tsimple_draw.line(mouth_sp, mouth_ep, color, width=2)\n\t#simple_draw.pause()\n", "description": null, "category": "simple", "imports": ["import simple_draw"]}, {"term": "def", "name": "sun", "data": "def sun(start_point):\n\tsimple_draw.circle(start_point, 50, simple_draw.COLOR_YELLOW, 0)\n\n\tfor i in range(0,361, 45):\n\t\tv1 = simple_draw.get_vector(start_point,i,100,3)\n\t\tv1.draw(color=simple_draw.COLOR_YELLOW)\n", "description": null, "category": "simple", "imports": ["import simple_draw"]}], [{"term": "class", "name": "SimpleModel", "data": "class SimpleModel(Model):\n\t\"\"\"Simple Test Model\"\"\"\n\tname = StringProperty()\n\tstrs = ListProperty(str)\n\tnum = IntegerProperty()\n", "description": "Simple Test Model", "category": "simple", "imports": ["from boto.sdb.db.property import ListProperty, StringProperty, ReferenceProperty, IntegerProperty", "from boto.sdb.db.model import Model", "import time"]}, {"term": "class", "name": "SubModel", "data": "class SubModel(SimpleModel):\n\t\"\"\"Simple Subclassed Model\"\"\"\n\tref = ReferenceProperty(SimpleModel, collection_name=\"reverse_ref\")\n\n", "description": "Simple Subclassed Model", "category": "simple", "imports": ["from boto.sdb.db.property import ListProperty, StringProperty, ReferenceProperty, IntegerProperty", "from boto.sdb.db.model import Model", "import time"]}, {"term": "class", "name": "TestQuerying", "data": "class TestQuerying(object):\n\t\"\"\"Test different querying capabilities\"\"\"\n\n\tdef setup_class(cls):\n\t\t\"\"\"Setup this class\"\"\"\n\t\tcls.objs = []\n\n\t\to = SimpleModel()\n\t\to.name = \"Simple Object\"\n\t\to.strs = [\"B\", \"A\", \"C\", \"Foo\"]\n\t\to.num = 1\n\t\to.put()\n\t\tcls.objs.append(o)\n\n\t\to2 = SimpleModel()\n\t\to2.name = \"Referenced Object\"\n\t\to2.num = 2\n\t\to2.put()\n\t\tcls.objs.append(o2)\n\n\t\to3 = SubModel()\n\t\to3.name = \"Sub Object\"\n\t\to3.num = 3\n\t\to3.ref = o2\n\t\to3.put()\n\t\tcls.objs.append(o3)\n\n\t\ttime.sleep(3)\n\n\n\n\tdef teardown_class(cls):\n\t\t\"\"\"Remove our objects\"\"\"\n\t\tfor o in cls.objs:\n\t\t\ttry:\n\t\t\t\to.delete()\n\t\t\texcept:\n\t\t\t\tpass\n\n\tdef test_find(self):\n\t\t\"\"\"Test using the \"Find\" method\"\"\"\n\t\tassert(SimpleModel.find(name=\"Simple Object\").next().id == self.objs[0].id)\n\t\tassert(SimpleModel.find(name=\"Referenced Object\").next().id == self.objs[1].id)\n\t\tassert(SimpleModel.find(name=\"Sub Object\").next().id == self.objs[2].id)\n\n\tdef test_like_filter(self):\n\t\t\"\"\"Test a \"like\" filter\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name like\", \"% Object\")\n\t\tassert(query.count() == 3)\n\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name not like\", \"% Object\")\n\t\tassert(query.count() == 0)\n\n\tdef test_equals_filter(self):\n\t\t\"\"\"Test an \"=\" and \"!=\" filter\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name =\", \"Simple Object\")\n\t\tassert(query.count() == 1)\n\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name !=\", \"Simple Object\")\n\t\tassert(query.count() == 2)\n\n\tdef test_or_filter(self):\n\t\t\"\"\"Test a filter function as an \"or\" \"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name =\", [\"Simple Object\", \"Sub Object\"])\n\t\tassert(query.count() == 2)\n\n\tdef test_and_filter(self):\n\t\t\"\"\"Test Multiple filters which are an \"and\" \"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"name like\", \"% Object\")\n\t\tquery.filter(\"name like\", \"Simple %\")\n\t\tassert(query.count() == 1)\n\n\tdef test_none_filter(self):\n\t\t\"\"\"Test filtering for a value that's not set\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"ref =\", None)\n\t\tassert(query.count() == 2)\n\n\tdef test_greater_filter(self):\n\t\t\"\"\"Test filtering Using >, >=\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"num >\", 1)\n\t\tassert(query.count() == 2)\n\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"num >=\", 1)\n\t\tassert(query.count() == 3)\n\n\tdef test_less_filter(self):\n\t\t\"\"\"Test filtering Using <, <=\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"num <\", 3)\n\t\tassert(query.count() == 2)\n\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"num <=\", 3)\n\t\tassert(query.count() == 3)\n\n\tdef test_query_on_list(self):\n\t\t\"\"\"Test querying on a list\"\"\"\n\t\tassert(SimpleModel.find(strs=\"A\").next().id == self.objs[0].id)\n\t\tassert(SimpleModel.find(strs=\"B\").next().id == self.objs[0].id)\n\t\tassert(SimpleModel.find(strs=\"C\").next().id == self.objs[0].id)\n\n\tdef test_like(self):\n\t\t\"\"\"Test with a \"like\" expression\"\"\"\n\t\tquery = SimpleModel.all()\n\t\tquery.filter(\"strs like\", \"%oo%\")\n\t\tprint query.get_query()\n\t\tassert(query.count() == 1)\n", "description": "Test different querying capabilities", "category": "simple", "imports": ["from boto.sdb.db.property import ListProperty, StringProperty, ReferenceProperty, IntegerProperty", "from boto.sdb.db.model import Model", "import time"]}], [{"term": "class", "name": "ScannerError", "data": "class ScannerError(MarkedError):\n\tpass\n\n", "description": null, "category": "simple", "imports": ["from .error import MarkedError", "from .tokens import *  # NOQA", "\tfrom __builtin__ import unicode"]}, {"term": "class", "name": "classSimpleKey:", "data": "class SimpleKey:\n\t# See below simple keys treatment.\n\tdef __init__(self, token_number, index, line, column, mark):\n\t\tself.token_number = token_number\n\t\tself.index = index\n\t\tself.line = line\n\t\tself.column = column\n\t\tself.mark = mark\n\n", "description": null, "category": "simple", "imports": ["from .error import MarkedError", "from .tokens import *  # NOQA", "\tfrom __builtin__ import unicode"]}, {"term": "class", "name": "classScanner:", "data": "class Scanner:\n\tdef __init__(self):\n\t\t\"\"\"Initialize the scanner.\"\"\"\n\t\t# It is assumed that Scanner and Reader will have a common descendant.\n\t\t# Reader do the dirty work of checking for BOM and converting the\n\t\t# input data to Unicode. It also adds NUL to the end.\n\t\t#\n\t\t# Reader supports the following methods\n\t\t#\tself.peek(i=0)\t\t # peek the next i-th character\n\t\t#\tself.prefix(l=1)\t # peek the next l characters\n\t\t#\tself.forward(l=1)\t # read the next l characters and move the pointer.\n\n\t\t# Had we reached the end of the stream?\n\t\tself.done = False\n\n\t\t# The number of unclosed '{' and '['. `flow_level == 0` means block\n\t\t# context.\n\t\tself.flow_level = 0\n\n\t\t# List of processed tokens that are not yet emitted.\n\t\tself.tokens = []\n\n\t\t# Add the STREAM-START token.\n\t\tself.fetch_stream_start()\n\n\t\t# Number of tokens that were emitted through the `get_token` method.\n\t\tself.tokens_taken = 0\n\n\t\t# Variables related to simple keys treatment.\n\n\t\t# A simple key is a key that is not denoted by the '?' indicator.\n\t\t# We emit the KEY token before all keys, so when we find a potential\n\t\t# simple key, we try to locate the corresponding ':' indicator.\n\t\t# Simple keys should be limited to a single line.\n\n\t\t# Can a simple key start at the current position? A simple key may\n\t\t# start:\n\t\t# - after '{', '[', ',' (in the flow context),\n\t\tself.allow_simple_key = False\n\n\t\t# Keep track of possible simple keys. This is a dictionary. The key\n\t\t# is `flow_level`; there can be no more that one possible simple key\n\t\t# for each level. The value is a SimpleKey record:\n\t\t#\t(token_number, index, line, column, mark)\n\t\t# A simple key may start with SCALAR(flow), '[', or '{' tokens.\n\t\tself.possible_simple_keys = {}\n\n\t# Public methods.\n\n\tdef check_token(self, *choices):\n\t\t# Check if the next token is one of the given types.\n\t\twhile self.need_more_tokens():\n\t\t\tself.fetch_more_tokens()\n\t\tif self.tokens:\n\t\t\tif not choices:\n\t\t\t\treturn True\n\t\t\tfor choice in choices:\n\t\t\t\tif isinstance(self.tokens[0], choice):\n\t\t\t\t\treturn True\n\t\treturn False\n\n\tdef peek_token(self):\n\t\t# Return the next token, but do not delete if from the queue.\n\t\twhile self.need_more_tokens():\n\t\t\tself.fetch_more_tokens()\n\t\tif self.tokens:\n\t\t\treturn self.tokens[0]\n\n\tdef get_token(self):\n\t\t# Return the next token.\n\t\twhile self.need_more_tokens():\n\t\t\tself.fetch_more_tokens()\n\t\tif self.tokens:\n\t\t\tself.tokens_taken += 1\n\t\t\treturn self.tokens.pop(0)\n\n\t# Private methods.\n\n\tdef need_more_tokens(self):\n\t\tif self.done:\n\t\t\treturn False\n\t\tif not self.tokens:\n\t\t\treturn True\n\t\t# The current token may be a potential simple key, so we\n\t\t# need to look further.\n\t\tself.stale_possible_simple_keys()\n\t\tif self.next_possible_simple_key() == self.tokens_taken:\n\t\t\treturn True\n\n\tdef fetch_more_tokens(self):\n\n\t\t# Eat whitespaces and comments until we reach the next token.\n\t\tself.scan_to_next_token()\n\n\t\t# Remove obsolete possible simple keys.\n\t\tself.stale_possible_simple_keys()\n\n\t\t# Peek the next character.\n\t\tch = self.peek()\n\n\t\t# Is it the end of stream?\n\t\tif ch == '\\0':\n\t\t\treturn self.fetch_stream_end()\n\n\t\t# Note: the order of the following checks is NOT significant.\n\n\t\t# Is it the flow sequence start indicator?\n\t\tif ch == '[':\n\t\t\treturn self.fetch_flow_sequence_start()\n\n\t\t# Is it the flow mapping start indicator?\n\t\tif ch == '{':\n\t\t\treturn self.fetch_flow_mapping_start()\n\n\t\t# Is it the flow sequence end indicator?\n\t\tif ch == ']':\n\t\t\treturn self.fetch_flow_sequence_end()\n\n\t\t# Is it the flow mapping end indicator?\n\t\tif ch == '}':\n\t\t\treturn self.fetch_flow_mapping_end()\n\n\t\t# Is it the flow entry indicator?\n\t\tif ch == ',':\n\t\t\treturn self.fetch_flow_entry()\n\n\t\t# Is it the value indicator?\n\t\tif ch == ':' and self.flow_level:\n\t\t\treturn self.fetch_value()\n\n\t\t# Is it a double quoted scalar?\n\t\tif ch == '\\\"':\n\t\t\treturn self.fetch_double()\n\n\t\t# It must be a plain scalar then.\n\t\tif self.check_plain():\n\t\t\treturn self.fetch_plain()\n\n\t\t# No? It's an error. Let's produce a nice error message.\n\t\traise ScannerError(\"while scanning for the next token\", None,\n\t\t\t\t\"found character %r that cannot start any token\" % ch,\n\t\t\t\tself.get_mark())\n\n\t# Simple keys treatment.\n\n\tdef next_possible_simple_key(self):\n\t\t# Return the number of the nearest possible simple key. Actually we\n\t\t# don't need to loop through the whole dictionary. We may replace it\n\t\t# with the following code:\n\t\t#\tif not self.possible_simple_keys:\n\t\t#\t\treturn None\n\t\t#\treturn self.possible_simple_keys[\n\t\t#\t\t\tmin(self.possible_simple_keys.keys())].token_number\n\t\tmin_token_number = None\n\t\tfor level in self.possible_simple_keys:\n\t\t\tkey = self.possible_simple_keys[level]\n\t\t\tif min_token_number is None or key.token_number < min_token_number:\n\t\t\t\tmin_token_number = key.token_number\n\t\treturn min_token_number\n\n\tdef stale_possible_simple_keys(self):\n\t\t# Remove entries that are no longer possible simple keys. According to\n\t\t# the YAML specification, simple keys\n\t\t# - should be limited to a single line,\n\t\t# Disabling this procedure will allow simple keys of any length and\n\t\t# height (may cause problems if indentation is broken though).\n\t\tfor level in list(self.possible_simple_keys):\n\t\t\tkey = self.possible_simple_keys[level]\n\t\t\tif key.line != self.line:\n\t\t\t\tdel self.possible_simple_keys[level]\n\n\tdef save_possible_simple_key(self):\n\t\t# The next token may start a simple key. We check if it's possible\n\t\t# and save its position. This function is called for\n\t\t#\tSCALAR(flow), '[', and '{'.\n\n\t\t# The next token might be a simple key. Let's save it's number and\n\t\t# position.\n\t\tif self.allow_simple_key:\n\t\t\tself.remove_possible_simple_key()\n\t\t\ttoken_number = self.tokens_taken + len(self.tokens)\n\t\t\tkey = SimpleKey(token_number,\n\t\t\t\t\tself.index, self.line, self.column, self.get_mark())\n\t\t\tself.possible_simple_keys[self.flow_level] = key\n\n\tdef remove_possible_simple_key(self):\n\t\t# Remove the saved possible key position at the current flow level.\n\t\tif self.flow_level in self.possible_simple_keys:\n\t\t\tdel self.possible_simple_keys[self.flow_level]\n\n\t# Fetchers.\n\n\tdef fetch_stream_start(self):\n\t\t# We always add STREAM-START as the first token and STREAM-END as the\n\t\t# last token.\n\n\t\t# Read the token.\n\t\tmark = self.get_mark()\n\n\t\t# Add STREAM-START.\n\t\tself.tokens.append(StreamStartToken(mark, mark,\n\t\t\tencoding=self.encoding))\n\n\tdef fetch_stream_end(self):\n\t\t# Reset simple keys.\n\t\tself.remove_possible_simple_key()\n\t\tself.allow_simple_key = False\n\t\tself.possible_simple_keys = {}\n\n\t\t# Read the token.\n\t\tmark = self.get_mark()\n\n\t\t# Add STREAM-END.\n\t\tself.tokens.append(StreamEndToken(mark, mark))\n\n\t\t# The steam is finished.\n\t\tself.done = True\n\n\tdef fetch_flow_sequence_start(self):\n\t\tself.fetch_flow_collection_start(FlowSequenceStartToken)\n\n\tdef fetch_flow_mapping_start(self):\n\t\tself.fetch_flow_collection_start(FlowMappingStartToken)\n\n\tdef fetch_flow_collection_start(self, TokenClass):\n\n\t\t# '[' and '{' may start a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# Increase the flow level.\n\t\tself.flow_level += 1\n\n\t\t# Simple keys are allowed after '[' and '{'.\n\t\tself.allow_simple_key = True\n\n\t\t# Add FLOW-SEQUENCE-START or FLOW-MAPPING-START.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(TokenClass(start_mark, end_mark))\n\n\tdef fetch_flow_sequence_end(self):\n\t\tself.fetch_flow_collection_end(FlowSequenceEndToken)\n\n\tdef fetch_flow_mapping_end(self):\n\t\tself.fetch_flow_collection_end(FlowMappingEndToken)\n\n\tdef fetch_flow_collection_end(self, TokenClass):\n\n\t\t# Reset possible simple key on the current level.\n\t\tself.remove_possible_simple_key()\n\n\t\t# Decrease the flow level.\n\t\tself.flow_level -= 1\n\n\t\t# No simple keys after ']' or '}'.\n\t\tself.allow_simple_key = False\n\n\t\t# Add FLOW-SEQUENCE-END or FLOW-MAPPING-END.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(TokenClass(start_mark, end_mark))\n\n\tdef fetch_value(self):\n\t\t# Do we determine a simple key?\n\t\tif self.flow_level in self.possible_simple_keys:\n\n\t\t\t# Add KEY.\n\t\t\tkey = self.possible_simple_keys[self.flow_level]\n\t\t\tdel self.possible_simple_keys[self.flow_level]\n\t\t\tself.tokens.insert(key.token_number - self.tokens_taken,\n\t\t\t\t\tKeyToken(key.mark, key.mark))\n\n\t\t\t# There cannot be two simple keys one after another.\n\t\t\tself.allow_simple_key = False\n\n\t\t# Add VALUE.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(ValueToken(start_mark, end_mark))\n\n\tdef fetch_flow_entry(self):\n\n\t\t# Simple keys are allowed after ','.\n\t\tself.allow_simple_key = True\n\n\t\t# Reset possible simple key on the current level.\n\t\tself.remove_possible_simple_key()\n\n\t\t# Add FLOW-ENTRY.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(FlowEntryToken(start_mark, end_mark))\n\n\tdef fetch_double(self):\n\t\t# A flow scalar could be a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# No simple keys after flow scalars.\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add SCALAR.\n\t\tself.tokens.append(self.scan_flow_scalar())\n\n\tdef fetch_plain(self):\n\n\t\tself.save_possible_simple_key()\n\n\t\t# No simple keys after plain scalars.\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add SCALAR. May change `allow_simple_key`.\n\t\tself.tokens.append(self.scan_plain())\n\n\t# Checkers.\n\n\tdef check_plain(self):\n\t\treturn self.peek() in '0123456789-ntf'\n\n\t# Scanners.\n\n\tdef scan_to_next_token(self):\n\t\twhile self.peek() in ' \\t\\n':\n\t\t\tself.forward()\n\n\tdef scan_flow_scalar(self):\n\t\t# See the specification for details.\n\t\t# Note that we loose indentation rules for quoted scalars. Quoted\n\t\t# scalars don't need to adhere indentation because \" and ' clearly\n\t\t# mark the beginning and the end of them. Therefore we are less\n\t\t# restrictive then the specification requires. We only need to check\n\t\t# that document separators are not included in scalars.\n\t\tchunks = []\n\t\tstart_mark = self.get_mark()\n\t\tquote = self.peek()\n\t\tself.forward()\n\t\tchunks.extend(self.scan_flow_scalar_non_spaces(start_mark))\n\t\twhile self.peek() != quote:\n\t\t\tchunks.extend(self.scan_flow_scalar_spaces(start_mark))\n\t\t\tchunks.extend(self.scan_flow_scalar_non_spaces(start_mark))\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\treturn ScalarToken(unicode().join(chunks), False, start_mark, end_mark, '\"')\n\n\tESCAPE_REPLACEMENTS = {\n\t\t'b': '\\x08',\n\t\t't': '\\x09',\n\t\t'n': '\\x0A',\n\t\t'f': '\\x0C',\n\t\t'r': '\\x0D',\n\t\t'\\\"': '\\\"',\n\t\t'\\\\': '\\\\',\n\t}\n\n\tESCAPE_CODES = {\n\t\t'u': 4,\n\t}\n\n\tdef scan_flow_scalar_non_spaces(self, start_mark):\n\t\t# See the specification for details.\n\t\tchunks = []\n\t\twhile True:\n\t\t\tlength = 0\n\t\t\twhile self.peek(length) not in '\\\"\\\\\\0 \\t\\n':\n\t\t\t\tlength += 1\n\t\t\tif length:\n\t\t\t\tchunks.append(self.prefix(length))\n\t\t\t\tself.forward(length)\n\t\t\tch = self.peek()\n\t\t\tif ch == '\\\\':\n\t\t\t\tself.forward()\n\t\t\t\tch = self.peek()\n\t\t\t\tif ch in self.ESCAPE_REPLACEMENTS:\n\t\t\t\t\tchunks.append(self.ESCAPE_REPLACEMENTS[ch])\n\t\t\t\t\tself.forward()\n\t\t\t\telif ch in self.ESCAPE_CODES:\n\t\t\t\t\tlength = self.ESCAPE_CODES[ch]\n\t\t\t\t\tself.forward()\n\t\t\t\t\tfor k in range(length):\n\t\t\t\t\t\tif self.peek(k) not in '0123456789ABCDEFabcdef':\n\t\t\t\t\t\t\traise ScannerError(\"while scanning a double-quoted scalar\", start_mark,\n\t\t\t\t\t\t\t\t\t\"expected escape sequence of %d hexdecimal numbers, but found %r\" %\n\t\t\t\t\t\t\t\t\t\t(length, self.peek(k)), self.get_mark())\n\t\t\t\t\tcode = int(self.prefix(length), 16)\n\t\t\t\t\tchunks.append(chr(code))\n\t\t\t\t\tself.forward(length)\n\t\t\t\telse:\n\t\t\t\t\traise ScannerError(\"while scanning a double-quoted scalar\", start_mark,\n\t\t\t\t\t\t\t\"found unknown escape character %r\" % ch, self.get_mark())\n\t\t\telse:\n\t\t\t\treturn chunks\n\n\tdef scan_flow_scalar_spaces(self, start_mark):\n\t\t# See the specification for details.\n\t\tchunks = []\n\t\tlength = 0\n\t\twhile self.peek(length) in ' \\t':\n\t\t\tlength += 1\n\t\twhitespaces = self.prefix(length)\n\t\tself.forward(length)\n\t\tch = self.peek()\n\t\tif ch == '\\0':\n\t\t\traise ScannerError(\"while scanning a quoted scalar\", start_mark,\n\t\t\t\t\t\"found unexpected end of stream\", self.get_mark())\n\t\telif ch == '\\n':\n\t\t\traise ScannerError(\"while scanning a quoted scalar\", start_mark,\n\t\t\t\t\t\"found unexpected line end\", self.get_mark())\n\t\telse:\n\t\t\tchunks.append(whitespaces)\n\t\treturn chunks\n\n\tdef scan_plain(self):\n\t\tchunks = []\n\t\tstart_mark = self.get_mark()\n\t\tspaces = []\n\t\twhile True:\n\t\t\tlength = 0\n\t\t\twhile True:\n\t\t\t\tif self.peek(length) not in 'eE.0123456789nul-tr+fas':\n\t\t\t\t\tbreak\n\t\t\t\tlength += 1\n\t\t\tif length == 0:\n\t\t\t\tbreak\n\t\t\tself.allow_simple_key = False\n\t\t\tchunks.extend(spaces)\n\t\t\tchunks.append(self.prefix(length))\n\t\t\tself.forward(length)\n\t\tend_mark = self.get_mark()\n\t\treturn ScalarToken(''.join(chunks), True, start_mark, end_mark)\n", "description": "Initialize the scanner.", "category": "simple", "imports": ["from .error import MarkedError", "from .tokens import *  # NOQA", "\tfrom __builtin__ import unicode"]}], [{"term": "class", "name": "TestLibraryInfo", "data": "class TestLibraryInfo(TestCase):\n\tdef test_simple(self):\n\t\tfd, filename = mkstemp('foo.ini')\n\t\ttry:\n\t\t\tpkg = os.path.splitext(filename)[0]\n\t\t\ttry:\n\t\t\t\tos.write(fd, simple.encode('ascii'))\n\t\t\tfinally:\n\t\t\t\tos.close(fd)\n\n\t\t\tout = read_config(pkg)\n\t\t\tself.assertTrue(out.cflags() == simple_d['cflags'])\n\t\t\tself.assertTrue(out.libs() == simple_d['libflags'])\n\t\t\tself.assertTrue(out.name == simple_d['name'])\n\t\t\tself.assertTrue(out.version == simple_d['version'])\n\t\tfinally:\n\t\t\tos.remove(filename)\n\n\tdef test_simple_variable(self):\n\t\tfd, filename = mkstemp('foo.ini')\n\t\ttry:\n\t\t\tpkg = os.path.splitext(filename)[0]\n\t\t\ttry:\n\t\t\t\tos.write(fd, simple_variable.encode('ascii'))\n\t\t\tfinally:\n\t\t\t\tos.close(fd)\n\n\t\t\tout = read_config(pkg)\n\t\t\tself.assertTrue(out.cflags() == simple_variable_d['cflags'])\n\t\t\tself.assertTrue(out.libs() == simple_variable_d['libflags'])\n\t\t\tself.assertTrue(out.name == simple_variable_d['name'])\n\t\t\tself.assertTrue(out.version == simple_variable_d['version'])\n\n\t\t\tout.vars['prefix'] = '/Users/david'\n\t\t\tself.assertTrue(out.cflags() == '-I/Users/david/include')\n\t\tfinally:\n\t\t\tos.remove(filename)\n", "description": null, "category": "simple", "imports": ["from __future__ import division, absolute_import, print_function", "import os", "from tempfile import mkstemp", "from numpy.testing import *", "from numpy.distutils.npy_pkg_config import read_config, parse_flags"]}, {"term": "class", "name": "TestParseFlags", "data": "class TestParseFlags(TestCase):\n\tdef test_simple_cflags(self):\n\t\td = parse_flags(\"-I/usr/include\")\n\t\tself.assertTrue(d['include_dirs'] == ['/usr/include'])\n\n\t\td = parse_flags(\"-I/usr/include -DFOO\")\n\t\tself.assertTrue(d['include_dirs'] == ['/usr/include'])\n\t\tself.assertTrue(d['macros'] == ['FOO'])\n\n\t\td = parse_flags(\"-I /usr/include -DFOO\")\n\t\tself.assertTrue(d['include_dirs'] == ['/usr/include'])\n\t\tself.assertTrue(d['macros'] == ['FOO'])\n\n\tdef test_simple_lflags(self):\n\t\td = parse_flags(\"-L/usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tself.assertTrue(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tself.assertTrue(d['libraries'] == ['foo', 'bar'])\n\n\t\td = parse_flags(\"-L /usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tself.assertTrue(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tself.assertTrue(d['libraries'] == ['foo', 'bar'])\n", "description": null, "category": "simple", "imports": ["from __future__ import division, absolute_import, print_function", "import os", "from tempfile import mkstemp", "from numpy.testing import *", "from numpy.distutils.npy_pkg_config import read_config, parse_flags"]}], [{"term": "class", "name": "SimpleXmlHandlerTag", "data": "class SimpleXmlHandlerTag(SimpleXmlHandlerBase):\n\t'''Define class where we override TAG_NAME'''\n\tTAG_NAME = \"simple_tag\"\n\n", "description": null, "category": "simple", "imports": ["import unittest", "from lxml import etree", "from solaris_install.data_object import \\", "from solaris_install.data_object.simple import \\", "from simple_data_object import SimpleDataObject", "\tdef test_data_object_simple_import_xml_default(self):", "\t\t'''Validate that from_xml() correctly imports XML'''", "\tdef test_data_object_simple_import_xml_with_name(self):", "\t\t'''Validate that from_xml() correctly imports XML'''"]}, {"term": "class", "name": "SimpleXmlHandlerBadTag", "data": "class SimpleXmlHandlerBadTag(SimpleXmlHandlerBase):\n\t'''Define class where we override TAG_NAME with a bad tag value'''\n\tTAG_NAME = \"bad tag\"\n\n", "description": null, "category": "simple", "imports": ["import unittest", "from lxml import etree", "from solaris_install.data_object import \\", "from solaris_install.data_object.simple import \\", "from simple_data_object import SimpleDataObject", "\tdef test_data_object_simple_import_xml_default(self):", "\t\t'''Validate that from_xml() correctly imports XML'''", "\tdef test_data_object_simple_import_xml_with_name(self):", "\t\t'''Validate that from_xml() correctly imports XML'''"]}, {"term": "class", "name": "TestSimpleXmlHandlerBase", "data": "class  TestSimpleXmlHandlerBase(unittest.TestCase):\n\t'''Tests to validate SimpleXmlHandlerBase functionality'''\n\n\tdef setUp(self):\n\t\tself.simple_tag_no_name = SimpleXmlHandlerTag()\n\t\tself.simple_tag_with_name = SimpleXmlHandlerTag('My Name')\n\n\tdef tearDown(self):\n\t\tself.simple_tag_no_name = None\n\t\tself.simple_tag_with_name = None\n\n\tdef test_data_object_simple_fail_not_subclass(self):\n\t\t'''Validate that direct instantaion of SimpleXmlHandlerBase will fail.\n\t\t'''\n\t\tself.assertRaises(ValueError, SimpleXmlHandlerBase)\n\n\tdef test_data_object_simple_xml_valid_tag_no_name(self):\n\t\t'''Validate that XML is generated using a valid TAG_NAME and no name'''\n\t\t# Set expected xml, and compensate for indent\n\t\texpected_xml = '\\n'\n\n\t\txml_str = self.simple_tag_no_name.get_xml_tree_str()\n\t\tself.assertEqual(xml_str, expected_xml, \"EXPECTED:\\n%s\\nGOT:\\n%s\" %\\\n\t\t\t(expected_xml, xml_str))\n\n\tdef test_data_object_simple_xml_valid_tag_with_name(self):\n\t\t'''Validate that XML is generated using a valid TAG_NAME and name'''\n\t\t# Set expected xml, and compensate for indent\n\t\texpected_xml = '\\n'\n\n\t\txml_str = self.simple_tag_with_name.get_xml_tree_str()\n\t\tself.assertEqual(xml_str, expected_xml, \"EXPECTED:\\n%s\\nGOT:\\n%s\" %\\\n\t\t\t(expected_xml, xml_str))\n\n\tdef test_data_object_simple_fail_invalid_tag(self):\n\t\t'''Validate that XML generation fails using an invalid TAG_NAME'''\n\t\ttry:\n\t\t\tdata_obj = SimpleXmlHandlerBadTag()\n\t\t\tdata_obj.to_xml()\n\t\t\tself.fail(\"Unexpected success creating obj with a bad tag name\")\n\t\texcept ValueError:\n\t\t\tpass\n\n\tdef test_data_object_simple_fail_can_handle_invalid_tag(self):\n\t\t'''Validate that can_handle fails using an invalid tag name'''\n\t\tTEST_XML = ''\n\n\t\t# Parse the XML into an XML tree.\n\t\txml_tree = etree.fromstring(TEST_XML)\n\n\t\tself.assertFalse(SimpleXmlHandlerBase.can_handle(xml_tree),\n\t\t\t\"can_handle returned True when given a bad tag: %s\" % (TEST_XML))\n\n\tdef test_data_object_simple_fail_from_xml_invalid_tag(self):\n\t\t'''Validate that from_xml() fails using an invalid XML tag'''\n\t\tTEST_XML = ''\n\n\t\t# Parse the XML into an XML tree.\n\t\txml_tree = etree.fromstring(TEST_XML)\n\n\t\t# can_handle tested seperately, just ensure from_xml will fail too.\n\t\tself.assertRaises(ParsingError,\n\t\t\tSimpleXmlHandlerTag.from_xml, xml_tree)\n\n\tdef test_data_object_simple_import_xml_default(self):\n\t\t'''Validate that from_xml() correctly imports XML'''\n\t\tTEST_XML = ''\n\n\t\t# Parse the XML into an XML tree.\n\t\txml_tree = etree.fromstring(TEST_XML)\n\n\t\tif SimpleXmlHandlerTag.can_handle(xml_tree):\n\t\t\tnew_obj = SimpleXmlHandlerTag.from_xml(xml_tree)\n\t\t\tself.assertTrue(new_obj is not None,\n\t\t\t\t\"Failed to create SimpleXmlHandlerTag from XML\")\n\t\t\tself.assertEquals(new_obj.name, SimpleXmlHandlerTag.TAG_NAME,\n\t\t\t\t\"Created SimpleXmlHandlerTag has wrong name.\")\n\t\telse:\n\t\t\tself.fail(\"can_handle returned False, expected True!\")\n\n\tdef test_data_object_simple_import_xml_with_name(self):\n\t\t'''Validate that from_xml() correctly imports XML'''\n\t\tTEST_XML = ''\n\n\t\t# Parse the XML into an XML tree.\n\t\txml_tree = etree.fromstring(TEST_XML)\n\n\t\tif SimpleXmlHandlerTag.can_handle(xml_tree):\n\t\t\tnew_obj = SimpleXmlHandlerTag.from_xml(xml_tree)\n\t\t\tself.assertTrue(new_obj is not None,\n\t\t\t\t\"Failed to create SimpleXmlHandlerTag from XML\")\n\t\t\tself.assertEquals(new_obj.name, \"My Name\",\n\t\t\t\t\"Created SimpleXmlHandlerTag has wrong name.\")\n\t\telse:\n\t\t\tself.fail(\"can_handle returned False, expected True!\")\n\n\tdef test_data_object_simple_can_insert_to_doc(self):\n\t\t'''Validate SimpleXmlHandlerBase can be inserted as child of DataObject\n\t\t'''\n\t\tdata_obj = SimpleDataObject(\"test_obj\")\n\t\tdata_obj.insert_children(SimpleXmlHandlerTag(\"test\"))\n", "description": null, "category": "simple", "imports": ["import unittest", "from lxml import etree", "from solaris_install.data_object import \\", "from solaris_install.data_object.simple import \\", "from simple_data_object import SimpleDataObject", "\tdef test_data_object_simple_import_xml_default(self):", "\t\t'''Validate that from_xml() correctly imports XML'''", "\tdef test_data_object_simple_import_xml_with_name(self):", "\t\t'''Validate that from_xml() correctly imports XML'''"]}], [{"term": "class", "name": "_SimpleExpands", "data": "class _SimpleExpands(_VimTest):\n\tsnippets = (\"hallo\", \"Hallo Welt!\")\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "SimpleExpand_ExpectCorrectResult", "data": "class SimpleExpand_ExpectCorrectResult(_SimpleExpands):\n\tkeys = \"hallo\" + EX\n\twanted = \"Hallo Welt!\"\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "SimpleExpandTwice_ExpectCorrectResult", "data": "class SimpleExpandTwice_ExpectCorrectResult(_SimpleExpands):\n\tkeys = \"hallo\" + EX + \"\\nhallo\" + EX\n\twanted = \"Hallo Welt!\\nHallo Welt!\"\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "SimpleExpandNewLineAndBackspae_ExpectCorrectResult", "data": "class SimpleExpandNewLineAndBackspae_ExpectCorrectResult(_SimpleExpands):\n\tkeys = \"hallo\" + EX + \"\\nHallo Welt!\\n\\n\\b\\b\\b\\b\\b\"\n\twanted = \"Hallo Welt!\\nHallo We\"\n\n\tdef _extra_vim_config(self, vim_config):\n\t\tvim_config.append(\"set backspace=eol,start\")\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "SimpleExpandTypeAfterExpand_ExpectCorrectResult", "data": "class SimpleExpandTypeAfterExpand_ExpectCorrectResult(_SimpleExpands):\n\tkeys = \"hallo\" + EX + \"and again\"\n\twanted = \"Hallo Welt!and again\"\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "SimpleExpandTypeAndDelete_ExpectCorrectResult", "data": "class SimpleExpandTypeAndDelete_ExpectCorrectResult(_SimpleExpands):\n\tkeys = \"na du hallo\" + EX + \"and again\\b\\b\\b\\b\\bblub\"\n\twanted = \"na du Hallo Welt!and blub\"\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "DoNotExpandAfterSpace_ExpectCorrectResult", "data": "class DoNotExpandAfterSpace_ExpectCorrectResult(_SimpleExpands):\n\tkeys = \"hallo \" + EX\n\twanted = \"hallo \" + EX\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "ExitSnippetModeAfterTabstopZero", "data": "class ExitSnippetModeAfterTabstopZero(_VimTest):\n\tsnippets = (\"test\", \"SimpleText\")\n\tkeys = \"test\" + EX + EX\n\twanted = \"SimpleText\" + EX\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "ExpandInTheMiddleOfLine_ExpectCorrectResult", "data": "class ExpandInTheMiddleOfLine_ExpectCorrectResult(_SimpleExpands):\n\tkeys = \"Wie hallo gehts\" + ESC + \"bhi\" + EX\n\twanted = \"Wie Hallo Welt! gehts\"\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "MultilineExpand_ExpectCorrectResult", "data": "class MultilineExpand_ExpectCorrectResult(_VimTest):\n\tsnippets = (\"hallo\", \"Hallo Welt!\\nUnd Wie gehts\")\n\tkeys = \"Wie hallo gehts\" + ESC + \"bhi\" + EX\n\twanted = \"Wie Hallo Welt!\\nUnd Wie gehts gehts\"\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "MultilineExpandTestTyping_ExpectCorrectResult", "data": "class MultilineExpandTestTyping_ExpectCorrectResult(_VimTest):\n\tsnippets = (\"hallo\", \"Hallo Welt!\\nUnd Wie gehts\")\n\twanted = \"Wie Hallo Welt!\\nUnd Wie gehtsHuiui! gehts\"\n\tkeys = \"Wie hallo gehts\" + ESC + \"bhi\" + EX + \"Huiui!\"\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "SimpleExpandEndingWithNewline_ExpectCorrectResult", "data": "class SimpleExpandEndingWithNewline_ExpectCorrectResult(_VimTest):\n\tsnippets = (\"hallo\", \"Hallo Welt\\n\")\n\tkeys = \"hallo\" + EX + \"\\nAnd more\"\n\twanted = \"Hallo Welt\\n\\nAnd more\"\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "SimpleExpand_DoNotClobberDefaultRegister", "data": "class SimpleExpand_DoNotClobberDefaultRegister(_VimTest):\n\tsnippets = (\"hallo\", \"Hallo ${1:Welt}\")\n\tkeys = \"hallo\" + EX + BS + ESC + \"o\" + ESC + \"P\"\n\twanted = \"Hallo \\n\"\n\n\tdef _extra_vim_config(self, vim_config):\n\t\tvim_config.append('let @\"=\"\"')\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}], [], [{"term": "class", "name": "TestLibraryInfo", "data": "class TestLibraryInfo(TestCase):\n\tdef test_simple(self):\n\t\tfd, filename = mkstemp('foo.ini')\n\t\ttry:\n\t\t\tpkg = os.path.splitext(filename)[0]\n\t\t\ttry:\n\t\t\t\tos.write(fd, simple.encode('ascii'))\n\t\t\tfinally:\n\t\t\t\tos.close(fd)\n\n\t\t\tout = read_config(pkg)\n\t\t\tself.assertTrue(out.cflags() == simple_d['cflags'])\n\t\t\tself.assertTrue(out.libs() == simple_d['libflags'])\n\t\t\tself.assertTrue(out.name == simple_d['name'])\n\t\t\tself.assertTrue(out.version == simple_d['version'])\n\t\tfinally:\n\t\t\tos.remove(filename)\n\n\tdef test_simple_variable(self):\n\t\tfd, filename = mkstemp('foo.ini')\n\t\ttry:\n\t\t\tpkg = os.path.splitext(filename)[0]\n\t\t\ttry:\n\t\t\t\tos.write(fd, simple_variable.encode('ascii'))\n\t\t\tfinally:\n\t\t\t\tos.close(fd)\n\n\t\t\tout = read_config(pkg)\n\t\t\tself.assertTrue(out.cflags() == simple_variable_d['cflags'])\n\t\t\tself.assertTrue(out.libs() == simple_variable_d['libflags'])\n\t\t\tself.assertTrue(out.name == simple_variable_d['name'])\n\t\t\tself.assertTrue(out.version == simple_variable_d['version'])\n\n\t\t\tout.vars['prefix'] = '/Users/david'\n\t\t\tself.assertTrue(out.cflags() == '-I/Users/david/include')\n\t\tfinally:\n\t\t\tos.remove(filename)\n", "description": null, "category": "simple", "imports": ["from __future__ import division, absolute_import, print_function", "import os", "from tempfile import mkstemp", "from numpy.testing import *", "from numpy.distutils.npy_pkg_config import read_config, parse_flags"]}, {"term": "class", "name": "TestParseFlags", "data": "class TestParseFlags(TestCase):\n\tdef test_simple_cflags(self):\n\t\td = parse_flags(\"-I/usr/include\")\n\t\tself.assertTrue(d['include_dirs'] == ['/usr/include'])\n\n\t\td = parse_flags(\"-I/usr/include -DFOO\")\n\t\tself.assertTrue(d['include_dirs'] == ['/usr/include'])\n\t\tself.assertTrue(d['macros'] == ['FOO'])\n\n\t\td = parse_flags(\"-I /usr/include -DFOO\")\n\t\tself.assertTrue(d['include_dirs'] == ['/usr/include'])\n\t\tself.assertTrue(d['macros'] == ['FOO'])\n\n\tdef test_simple_lflags(self):\n\t\td = parse_flags(\"-L/usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tself.assertTrue(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tself.assertTrue(d['libraries'] == ['foo', 'bar'])\n\n\t\td = parse_flags(\"-L /usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tself.assertTrue(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tself.assertTrue(d['libraries'] == ['foo', 'bar'])\n", "description": null, "category": "simple", "imports": ["from __future__ import division, absolute_import, print_function", "import os", "from tempfile import mkstemp", "from numpy.testing import *", "from numpy.distutils.npy_pkg_config import read_config, parse_flags"]}], [{"term": "def", "name": "home", "data": "def home():\n\t# render page\n\treturn render_template(\"index.html\")\n\n\n", "description": null, "category": "simple", "imports": ["from flask import render_template", "from flask import request", "from wheresious import app", "from get_scores import one_score", "import numpy as np", "import pandas as pd"]}, {"term": "def", "name": "test", "data": "def test():\n\t# render page\n\treturn render_template(\"test.html\")\n\n\n", "description": null, "category": "simple", "imports": ["from flask import render_template", "from flask import request", "from wheresious import app", "from get_scores import one_score", "import numpy as np", "import pandas as pd"]}, {"term": "def", "name": "about", "data": "def about():\n\t# render page\n\treturn render_template(\"about.html\")\n\n\n", "description": null, "category": "simple", "imports": ["from flask import render_template", "from flask import request", "from wheresious import app", "from get_scores import one_score", "import numpy as np", "import pandas as pd"]}, {"term": "def", "name": "contact", "data": "def contact():\n\t# render page\n\treturn render_template(\"contact.html\")\n\n\n", "description": null, "category": "simple", "imports": ["from flask import render_template", "from flask import request", "from wheresious import app", "from get_scores import one_score", "import numpy as np", "import pandas as pd"]}, {"term": "def", "name": "single_lookup", "data": "def single_lookup():\n\t# pull input fields and store them\n\taddress = request.args.get('address')\n\tnaics_code_simple = request.args.get('naics_code_simple')\n\n\t# get score for this address and code\n\tscore = one_score(address,naics_code_simple)\n\n\t# read in dataframe of tracts and scores for this code\n\tif naics_code_simple != 'all':\n\t\tdf_scores = pd.read_csv('/Users/jsilverman/insight/project/wheresious/static/tracts_scores_'+naics_code_simple+'.csv',index_col=0)\n\t\tblurb = 'Only businesses with Highest Level Business (NAICS) Code '+naics_code_simple+' were used to predict this score.'\n\telse:\n\t\tdf_scores = pd.read_csv('/Users/jsilverman/insight/project/wheresious/static/tracts_scores.csv',index_col=0)\n\t\tblurb = 'All businesses were used to predict this score.'\n\t\t\n\t# get average overall score for SD for this code\n\tmean_score = int(float(np.mean(df_scores.score)))\n\t\n\t# render page\n\treturn render_template(\"one_address.html\", address = address, naics_code_simple = naics_code_simple, score = score, mean = mean_score, code_blurb = blurb)\n\n\n", "description": null, "category": "simple", "imports": ["from flask import render_template", "from flask import request", "from wheresious import app", "from get_scores import one_score", "import numpy as np", "import pandas as pd"]}, {"term": "def", "name": "full_city_lookup", "data": "def full_city_lookup():\n\t# pull input field and store it\n\tnaics_code_simple = request.args.get('naics_code_simple')\n\n\tif naics_code_simple=='44':\n\t\tdescription = 'Highest Level Business (NAICS) Code: 44 - Retail Trade'\n\telif naics_code_simple=='45':\n\t\tdescription = 'Highest Level Business (NAICS) Code: 45 - Retail Trade'\n\telif naics_code_simple=='53':\n\t\tdescription = 'Highest Level Business (NAICS) Code: 53 - Real Estate and Rental and Leasing'\n\telif naics_code_simple=='54':\n\t\tdescription = 'Highest Level Business (NAICS) Code: 54 - Professional, Scientific, and Technical Services'\n\telif naics_code_simple=='56':\n\t\tdescription = 'Highest Level Business (NAICS) Code: 56 - Administrative and Support and Waste Management and Remediation Services'\n\telif naics_code_simple=='62':\n\t\tdescription = 'Highest Level Business (NAICS) Code: 62 - Health Care and Social Assistance'\n\telif naics_code_simple=='72':\n\t\tdescription = 'Highest Level Business (NAICS) Code: 72 - Accommodation and Food Services'\n\telif naics_code_simple=='81':\n\t\tdescription = 'Highest Level Business (NAICS) Code: 81 - Other Services (except Public Administration)'\n\telse:\n\t\tdescription = 'All Businesses'\n\t\t\n\t# render page\n\treturn render_template(\"all_city.html\", naics_code_simple = naics_code_simple, description = description)\n", "description": null, "category": "simple", "imports": ["from flask import render_template", "from flask import request", "from wheresious import app", "from get_scores import one_score", "import numpy as np", "import pandas as pd"]}], [{"term": "def", "name": "simple_vertex_shader", "data": "def simple_vertex_shader():\n\treturn \"\"\"#version 310 es\n\tvoid main() {\n\t\tgl_Position = vec4(1., 2., 3., 4.);\n\t}\"\"\"\n\n", "description": "#version 310 es\n\tvoid main() {\n\t\tgl_Position = vec4(1., 2., 3., 4.);\n\t}", "category": "simple", "imports": ["import expect", "from glslc_test_framework import inside_glslc_testsuite", "from placeholder import FileShader"]}, {"term": "def", "name": "simple_fragment_shader", "data": "def simple_fragment_shader():\n\treturn \"\"\"#version 310 es\n\tvoid main() {\n\t\tgl_FragDepth = 10.;\n\t}\"\"\"\n\n", "description": "#version 310 es\n\tvoid main() {\n\t\tgl_FragDepth = 10.;\n\t}", "category": "simple", "imports": ["import expect", "from glslc_test_framework import inside_glslc_testsuite", "from placeholder import FileShader"]}, {"term": "def", "name": "simple_tessellation_control_shader", "data": "def simple_tessellation_control_shader():\n\treturn \"\"\"#version 440 core\n\tlayout(vertices = 3) out;\n\tvoid main() { }\"\"\"\n\n", "description": "#version 440 core\n\tlayout(vertices = 3) out;\n\tvoid main() { }", "category": "simple", "imports": ["import expect", "from glslc_test_framework import inside_glslc_testsuite", "from placeholder import FileShader"]}, {"term": "def", "name": "simple_tessellation_evaluation_shader", "data": "def simple_tessellation_evaluation_shader():\n\treturn \"\"\"#version 440 core\n\tlayout(triangles) in;\n\tvoid main() { }\"\"\"\n\n", "description": "#version 440 core\n\tlayout(triangles) in;\n\tvoid main() { }", "category": "simple", "imports": ["import expect", "from glslc_test_framework import inside_glslc_testsuite", "from placeholder import FileShader"]}, {"term": "def", "name": "simple_geometry_shader", "data": "def simple_geometry_shader():\n\treturn \"\"\"#version 150 core\n\tlayout (triangles) in;\n\tlayout (line_strip, max_vertices = 4) out;\n\tvoid main() { }\"\"\"\n\n", "description": "#version 150 core\n\tlayout (triangles) in;\n\tlayout (line_strip, max_vertices = 4) out;\n\tvoid main() { }", "category": "simple", "imports": ["import expect", "from glslc_test_framework import inside_glslc_testsuite", "from placeholder import FileShader"]}, {"term": "def", "name": "simple_compute_shader", "data": "def simple_compute_shader():\n\treturn \"\"\"#version 310 es\n\tvoid main() {\n\t\tuvec3 temp = gl_WorkGroupID;\n\t}\"\"\"\n\n", "description": "#version 310 es\n\tvoid main() {\n\t\tuvec3 temp = gl_WorkGroupID;\n\t}", "category": "simple", "imports": ["import expect", "from glslc_test_framework import inside_glslc_testsuite", "from placeholder import FileShader"]}, {"term": "class", "name": "TestShaderStageWithGlslExtension", "data": "class TestShaderStageWithGlslExtension(expect.ValidObjectFile):\n\t\"\"\"Tests -fshader-stage with .glsl extension.\"\"\"\n\n\tshader = FileShader(simple_vertex_shader(), '.glsl')\n\tglslc_args = ['-c', '-fshader-stage=vertex', shader]\n\n", "description": "Tests -fshader-stage with .glsl extension.", "category": "simple", "imports": ["import expect", "from glslc_test_framework import inside_glslc_testsuite", "from placeholder import FileShader"]}, {"term": "class", "name": "TestShaderStageWithKnownExtension", "data": "class TestShaderStageWithKnownExtension(expect.ValidObjectFile):\n\t\"\"\"Tests -fshader-stage with known extension.\"\"\"\n\n\tshader = FileShader(simple_fragment_shader(), '.frag')\n\tglslc_args = ['-c', '-fshader-stage=fragment', shader]\n\n", "description": "Tests -fshader-stage with known extension.", "category": "simple", "imports": ["import expect", "from glslc_test_framework import inside_glslc_testsuite", "from placeholder import FileShader"]}, {"term": "class", "name": "TestShaderStageWithUnknownExtension", "data": "class TestShaderStageWithUnknownExtension(expect.ValidObjectFile):\n\t\"\"\"Tests -fshader-stage with unknown extension.\"\"\"\n\n\tshader = FileShader(simple_vertex_shader(), '.unknown')\n\tglslc_args = ['-c', '-fshader-stage=vertex', shader]\n\n", "description": "Tests -fshader-stage with unknown extension.", "category": "simple", "imports": ["import expect", "from glslc_test_framework import inside_glslc_testsuite", "from placeholder import FileShader"]}, {"term": "class", "name": "TestShaderStageWithNoExtension", "data": "class TestShaderStageWithNoExtension(expect.ValidObjectFile):\n\t\"\"\"Tests -fshader-stage with no extension.\"\"\"\n\n\tshader = FileShader(simple_vertex_shader(), '')\n\tglslc_args = ['-c', '-fshader-stage=vertex', shader]\n\n", "description": "Tests -fshader-stage with no extension.", "category": "simple", "imports": ["import expect", "from glslc_test_framework import inside_glslc_testsuite", "from placeholder import FileShader"]}, {"term": "class", "name": "TestAllShaderStages", "data": "class TestAllShaderStages(expect.ValidObjectFile):\n\t\"\"\"Tests all possible -fshader-stage values.\"\"\"\n\n\tshader1 = FileShader(simple_vertex_shader(), '.glsl')\n\tshader2 = FileShader(simple_fragment_shader(), '.glsl')\n\tshader3 = FileShader(simple_tessellation_control_shader(), '.glsl')\n\tshader4 = FileShader(simple_tessellation_evaluation_shader(), '.glsl')\n\tshader5 = FileShader(simple_geometry_shader(), '.glsl')\n\tshader6 = FileShader(simple_compute_shader(), '.glsl')\n\tglslc_args = [\n\t\t'-c',\n\t\t'-fshader-stage=vertex', shader1,\n\t\t'-fshader-stage=fragment', shader2,\n\t\t'-fshader-stage=tesscontrol', shader3,\n\t\t'-fshader-stage=tesseval', shader4,\n\t\t'-fshader-stage=geometry', shader5,\n\t\t'-fshader-stage=compute', shader6]\n\n", "description": "Tests all possible -fshader-stage values.", "category": "simple", "imports": ["import expect", "from glslc_test_framework import inside_glslc_testsuite", "from placeholder import FileShader"]}, {"term": "class", "name": "TestShaderStageOverwriteFileExtension", "data": "class TestShaderStageOverwriteFileExtension(expect.ValidObjectFile):\n\t\"\"\"Tests -fshader-stage has precedence over file extension.\"\"\"\n\n\t# a vertex shader camouflaged with .frag extension\n\tshader = FileShader(simple_vertex_shader(), '.frag')\n\t# Command line says it's vertex shader. Should compile successfully\n\t# as a vertex shader.\n\tglslc_args = ['-c', '-fshader-stage=vertex', shader]\n\n", "description": "Tests -fshader-stage has precedence over file extension.", "category": "simple", "imports": ["import expect", "from glslc_test_framework import inside_glslc_testsuite", "from placeholder import FileShader"]}, {"term": "class", "name": "TestShaderStageLatterOverwriteFormer", "data": "class TestShaderStageLatterOverwriteFormer(expect.ValidObjectFile):\n\t\"\"\"Tests a latter -fshader-stage overwrite a former one.\"\"\"\n\n\tshader = FileShader(simple_vertex_shader(), '.glsl')\n\tglslc_args = [\n\t\t'-c', '-fshader-stage=fragment', '-fshader-stage=vertex', shader]\n\n", "description": "Tests a latter -fshader-stage overwrite a former one.", "category": "simple", "imports": ["import expect", "from glslc_test_framework import inside_glslc_testsuite", "from placeholder import FileShader"]}, {"term": "class", "name": "TestShaderStageWithMultipleFiles", "data": "class TestShaderStageWithMultipleFiles(expect.ValidObjectFile):\n\t\"\"\"Tests -fshader-stage covers all subsequent files.\"\"\"\n\n\tshader1 = FileShader(simple_vertex_shader(), '.glsl')\n\t# a vertex shader with .frag extension\n\tshader2 = FileShader(simple_vertex_shader(), '.frag')\n\tshader3 = FileShader(simple_vertex_shader(), '.a_vert_shader')\n\tglslc_args = ['-c', '-fshader-stage=vertex', shader1, shader2, shader3]\n\n", "description": "Tests -fshader-stage covers all subsequent files.", "category": "simple", "imports": ["import expect", "from glslc_test_framework import inside_glslc_testsuite", "from placeholder import FileShader"]}, {"term": "class", "name": "TestShaderStageMultipleShaderStage", "data": "class TestShaderStageMultipleShaderStage(expect.ValidObjectFile):\n\t\"\"\"Tests multiple -fshader-stage.\"\"\"\n\n\tshader1 = FileShader(simple_vertex_shader(), '.glsl')\n\tshader2 = FileShader(simple_fragment_shader(), '.frag')\n\tshader3 = FileShader(simple_vertex_shader(), '.a_vert_shader')\n\tglslc_args = [\n\t\t'-c',\n\t\t'-fshader-stage=vertex', shader1,\n\t\t'-fshader-stage=fragment', shader2,\n\t\t'-fshader-stage=vertex', shader3]\n\n", "description": "Tests multiple -fshader-stage.", "category": "simple", "imports": ["import expect", "from glslc_test_framework import inside_glslc_testsuite", "from placeholder import FileShader"]}, {"term": "class", "name": "TestFileExtensionBeforeShaderStage", "data": "class TestFileExtensionBeforeShaderStage(expect.ValidObjectFile):\n\t\"\"\"Tests that file extensions before -fshader-stage are not affected.\"\"\"\n\n\t# before -fshader-stage\n\tshader1 = FileShader(simple_vertex_shader(), '.vert')\n\t# after -fshader-stage\n\tshader2 = FileShader(simple_fragment_shader(), '.frag')\n\tshader3 = FileShader(simple_fragment_shader(), '.vert')\n\tglslc_args = ['-c', shader1, '-fshader-stage=fragment', shader2, shader3]\n\n", "description": "Tests that file extensions before -fshader-stage are not affected.", "category": "simple", "imports": ["import expect", "from glslc_test_framework import inside_glslc_testsuite", "from placeholder import FileShader"]}, {"term": "class", "name": "TestShaderStageWrongShaderStageValue", "data": "class TestShaderStageWrongShaderStageValue(expect.ErrorMessage):\n\t\"\"\"Tests that wrong shader stage value results in an error.\"\"\"\n\n\tshader = FileShader(simple_vertex_shader(), '.glsl')\n\tglslc_args = ['-c', '-fshader-stage=unknown', shader]\n\texpected_error = [\"glslc: error: stage not recognized: 'unknown'\\n\"]\n\n", "description": "Tests that wrong shader stage value results in an error.", "category": "simple", "imports": ["import expect", "from glslc_test_framework import inside_glslc_testsuite", "from placeholder import FileShader"]}, {"term": "class", "name": "TestShaderStageGlslExtensionMissingShaderStage", "data": "class TestShaderStageGlslExtensionMissingShaderStage(expect.ErrorMessage):\n\t\"\"\"Tests that missing -fshader-stage for .glsl extension results in\n\tan error.\"\"\"\n\n\tshader = FileShader(simple_vertex_shader(), '.glsl')\n\tglslc_args = ['-c', shader]\n\texpected_error = [\n\t\t\"glslc: error: '\", shader,\n\t\t\"': .glsl file encountered but no -fshader-stage specified ahead\\n\"]\n\n", "description": "Tests that missing -fshader-stage for .glsl extension results in\n\tan error.", "category": "simple", "imports": ["import expect", "from glslc_test_framework import inside_glslc_testsuite", "from placeholder import FileShader"]}, {"term": "class", "name": "TestShaderStageUnknownExtensionMissingShaderStage", "data": "class TestShaderStageUnknownExtensionMissingShaderStage(expect.ErrorMessage):\n\t\"\"\"Tests that missing -fshader-stage for unknown extension results in\n\tan error.\"\"\"\n\n\tshader = FileShader(simple_vertex_shader(), '.a_vert_shader')\n\tglslc_args = ['-c', shader]\n\texpected_error = [\n\t\t\"glslc: error: '\", shader,\n\t\t\"': file not recognized: File format not recognized\\n\"]\n", "description": "Tests that missing -fshader-stage for unknown extension results in\n\tan error.", "category": "simple", "imports": ["import expect", "from glslc_test_framework import inside_glslc_testsuite", "from placeholder import FileShader"]}], [{"term": "class", "name": "TestLibraryInfo", "data": "class TestLibraryInfo(object):\n\tdef test_simple(self):\n\t\twith temppath('foo.ini') as path:\n\t\t\twith open(path,  'w') as f:\n\t\t\t\tf.write(simple)\n\t\t\tpkg = os.path.splitext(path)[0]\n\t\t\tout = read_config(pkg)\n\n\t\tassert_(out.cflags() == simple_d['cflags'])\n\t\tassert_(out.libs() == simple_d['libflags'])\n\t\tassert_(out.name == simple_d['name'])\n\t\tassert_(out.version == simple_d['version'])\n\n\tdef test_simple_variable(self):\n\t\twith temppath('foo.ini') as path:\n\t\t\twith open(path,  'w') as f:\n\t\t\t\tf.write(simple_variable)\n\t\t\tpkg = os.path.splitext(path)[0]\n\t\t\tout = read_config(pkg)\n\n\t\tassert_(out.cflags() == simple_variable_d['cflags'])\n\t\tassert_(out.libs() == simple_variable_d['libflags'])\n\t\tassert_(out.name == simple_variable_d['name'])\n\t\tassert_(out.version == simple_variable_d['version'])\n\t\tout.vars['prefix'] = '/Users/david'\n\t\tassert_(out.cflags() == '-I/Users/david/include')\n", "description": null, "category": "simple", "imports": ["from __future__ import division, absolute_import, print_function", "import os", "from numpy.distutils.npy_pkg_config import read_config, parse_flags", "from numpy.testing import temppath, assert_"]}, {"term": "class", "name": "TestParseFlags", "data": "class TestParseFlags(object):\n\tdef test_simple_cflags(self):\n\t\td = parse_flags(\"-I/usr/include\")\n\t\tassert_(d['include_dirs'] == ['/usr/include'])\n\n\t\td = parse_flags(\"-I/usr/include -DFOO\")\n\t\tassert_(d['include_dirs'] == ['/usr/include'])\n\t\tassert_(d['macros'] == ['FOO'])\n\n\t\td = parse_flags(\"-I /usr/include -DFOO\")\n\t\tassert_(d['include_dirs'] == ['/usr/include'])\n\t\tassert_(d['macros'] == ['FOO'])\n\n\tdef test_simple_lflags(self):\n\t\td = parse_flags(\"-L/usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tassert_(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tassert_(d['libraries'] == ['foo', 'bar'])\n\n\t\td = parse_flags(\"-L /usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tassert_(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tassert_(d['libraries'] == ['foo', 'bar'])\n", "description": null, "category": "simple", "imports": ["from __future__ import division, absolute_import, print_function", "import os", "from numpy.distutils.npy_pkg_config import read_config, parse_flags", "from numpy.testing import temppath, assert_"]}], [{"term": "class", "name": "TestLibraryInfo", "data": "class TestLibraryInfo(object):\n\tdef test_simple(self):\n\t\twith temppath('foo.ini') as path:\n\t\t\twith open(path,  'w') as f:\n\t\t\t\tf.write(simple)\n\t\t\tpkg = os.path.splitext(path)[0]\n\t\t\tout = read_config(pkg)\n\n\t\tassert_(out.cflags() == simple_d['cflags'])\n\t\tassert_(out.libs() == simple_d['libflags'])\n\t\tassert_(out.name == simple_d['name'])\n\t\tassert_(out.version == simple_d['version'])\n\n\tdef test_simple_variable(self):\n\t\twith temppath('foo.ini') as path:\n\t\t\twith open(path,  'w') as f:\n\t\t\t\tf.write(simple_variable)\n\t\t\tpkg = os.path.splitext(path)[0]\n\t\t\tout = read_config(pkg)\n\n\t\tassert_(out.cflags() == simple_variable_d['cflags'])\n\t\tassert_(out.libs() == simple_variable_d['libflags'])\n\t\tassert_(out.name == simple_variable_d['name'])\n\t\tassert_(out.version == simple_variable_d['version'])\n\t\tout.vars['prefix'] = '/Users/david'\n\t\tassert_(out.cflags() == '-I/Users/david/include')\n", "description": null, "category": "simple", "imports": ["from __future__ import division, absolute_import, print_function", "import os", "from numpy.distutils.npy_pkg_config import read_config, parse_flags", "from numpy.testing import temppath, assert_"]}, {"term": "class", "name": "TestParseFlags", "data": "class TestParseFlags(object):\n\tdef test_simple_cflags(self):\n\t\td = parse_flags(\"-I/usr/include\")\n\t\tassert_(d['include_dirs'] == ['/usr/include'])\n\n\t\td = parse_flags(\"-I/usr/include -DFOO\")\n\t\tassert_(d['include_dirs'] == ['/usr/include'])\n\t\tassert_(d['macros'] == ['FOO'])\n\n\t\td = parse_flags(\"-I /usr/include -DFOO\")\n\t\tassert_(d['include_dirs'] == ['/usr/include'])\n\t\tassert_(d['macros'] == ['FOO'])\n\n\tdef test_simple_lflags(self):\n\t\td = parse_flags(\"-L/usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tassert_(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tassert_(d['libraries'] == ['foo', 'bar'])\n\n\t\td = parse_flags(\"-L /usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tassert_(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tassert_(d['libraries'] == ['foo', 'bar'])\n", "description": null, "category": "simple", "imports": ["from __future__ import division, absolute_import, print_function", "import os", "from numpy.distutils.npy_pkg_config import read_config, parse_flags", "from numpy.testing import temppath, assert_"]}], [{"term": "class", "name": "_SimpleExpands", "data": "class _SimpleExpands(_VimTest):\n\tsnippets = (\"hallo\", \"Hallo Welt!\")\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "SimpleExpand_ExpectCorrectResult", "data": "class SimpleExpand_ExpectCorrectResult(_SimpleExpands):\n\tkeys = \"hallo\" + EX\n\twanted = \"Hallo Welt!\"\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "SimpleExpandTwice_ExpectCorrectResult", "data": "class SimpleExpandTwice_ExpectCorrectResult(_SimpleExpands):\n\tkeys = \"hallo\" + EX + \"\\nhallo\" + EX\n\twanted = \"Hallo Welt!\\nHallo Welt!\"\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "SimpleExpandNewLineAndBackspae_ExpectCorrectResult", "data": "class SimpleExpandNewLineAndBackspae_ExpectCorrectResult(_SimpleExpands):\n\tkeys = \"hallo\" + EX + \"\\nHallo Welt!\\n\\n\\b\\b\\b\\b\\b\"\n\twanted = \"Hallo Welt!\\nHallo We\"\n\n\tdef _extra_vim_config(self, vim_config):\n\t\tvim_config.append(\"set backspace=eol,start\")\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "SimpleExpandTypeAfterExpand_ExpectCorrectResult", "data": "class SimpleExpandTypeAfterExpand_ExpectCorrectResult(_SimpleExpands):\n\tkeys = \"hallo\" + EX + \"and again\"\n\twanted = \"Hallo Welt!and again\"\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "SimpleExpandTypeAndDelete_ExpectCorrectResult", "data": "class SimpleExpandTypeAndDelete_ExpectCorrectResult(_SimpleExpands):\n\tkeys = \"na du hallo\" + EX + \"and again\\b\\b\\b\\b\\bblub\"\n\twanted = \"na du Hallo Welt!and blub\"\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "DoNotExpandAfterSpace_ExpectCorrectResult", "data": "class DoNotExpandAfterSpace_ExpectCorrectResult(_SimpleExpands):\n\tkeys = \"hallo \" + EX\n\twanted = \"hallo \" + EX\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "ExitSnippetModeAfterTabstopZero", "data": "class ExitSnippetModeAfterTabstopZero(_VimTest):\n\tsnippets = (\"test\", \"SimpleText\")\n\tkeys = \"test\" + EX + EX\n\twanted = \"SimpleText\" + EX\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "ExpandInTheMiddleOfLine_ExpectCorrectResult", "data": "class ExpandInTheMiddleOfLine_ExpectCorrectResult(_SimpleExpands):\n\tkeys = \"Wie hallo gehts\" + ESC + \"bhi\" + EX\n\twanted = \"Wie Hallo Welt! gehts\"\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "MultilineExpand_ExpectCorrectResult", "data": "class MultilineExpand_ExpectCorrectResult(_VimTest):\n\tsnippets = (\"hallo\", \"Hallo Welt!\\nUnd Wie gehts\")\n\tkeys = \"Wie hallo gehts\" + ESC + \"bhi\" + EX\n\twanted = \"Wie Hallo Welt!\\nUnd Wie gehts gehts\"\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "MultilineExpandTestTyping_ExpectCorrectResult", "data": "class MultilineExpandTestTyping_ExpectCorrectResult(_VimTest):\n\tsnippets = (\"hallo\", \"Hallo Welt!\\nUnd Wie gehts\")\n\twanted = \"Wie Hallo Welt!\\nUnd Wie gehtsHuiui! gehts\"\n\tkeys = \"Wie hallo gehts\" + ESC + \"bhi\" + EX + \"Huiui!\"\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "SimpleExpandEndingWithNewline_ExpectCorrectResult", "data": "class SimpleExpandEndingWithNewline_ExpectCorrectResult(_VimTest):\n\tsnippets = (\"hallo\", \"Hallo Welt\\n\")\n\tkeys = \"hallo\" + EX + \"\\nAnd more\"\n\twanted = \"Hallo Welt\\n\\nAnd more\"\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "SimpleExpand_DoNotClobberDefaultRegister", "data": "class SimpleExpand_DoNotClobberDefaultRegister(_VimTest):\n\tsnippets = (\"hallo\", \"Hallo ${1:Welt}\")\n\tkeys = \"hallo\" + EX + BS + ESC + \"o\" + ESC + \"P\"\n\twanted = \"Hallo \\n\"\n\n\tdef _extra_vim_config(self, vim_config):\n\t\tvim_config.append('let @\"=\"\"')\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}], [{"term": "def", "name": "simple", "data": "def simple(e):\n\tcode = e.code\n\n\tif code.endswith('Exception'):\n\t\tcode = code.rstrip('Exception')\n\n\ttry:\n\t\t# Dynamically get the error class.\n\t\tsimple_e = getattr(sys.modules[__name__], code)(e)\n\texcept AttributeError:\n\t\t# Return original exception on failure.\n\t\treturn e\n\n\treturn simple_e\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "SimpleException", "data": "class SimpleException(BotoServerError):\n\tdef __init__(self, e):\n\t\tsuper(SimpleException, self).__init__(e.status, e.reason, e.body)\n\t\tself.error_message = self.message\n\n\tdef __repr__(self):\n\t\treturn self.__class__.__name__ + ': ' + self.error_message\n\tdef __str__(self):\n\t\treturn self.__class__.__name__ + ': ' + self.error_message\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "ValidationError", "data": "class ValidationError(SimpleException): pass\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "Throttling", "data": "class Throttling(SimpleException): pass\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "SourceBundleDeletion", "data": "class SourceBundleDeletion(SimpleException): pass\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}], [{"term": "def", "name": "simple", "data": "def simple(e):\n\tcode = e.code\n\n\tif code.endswith('Exception'):\n\t\tcode = code.rstrip('Exception')\n\n\ttry:\n\t\t# Dynamically get the error class.\n\t\tsimple_e = getattr(sys.modules[__name__], code)(e)\n\texcept AttributeError:\n\t\t# Return original exception on failure.\n\t\treturn e\n\n\treturn simple_e\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "SimpleException", "data": "class SimpleException(BotoServerError):\n\tdef __init__(self, e):\n\t\tsuper(SimpleException, self).__init__(e.status, e.reason, e.body)\n\t\tself.error_message = self.message\n\n\tdef __repr__(self):\n\t\treturn self.__class__.__name__ + ': ' + self.error_message\n\tdef __str__(self):\n\t\treturn self.__class__.__name__ + ': ' + self.error_message\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "ValidationError", "data": "class ValidationError(SimpleException): pass\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "Throttling", "data": "class Throttling(SimpleException): pass\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "SourceBundleDeletion", "data": "class SourceBundleDeletion(SimpleException): pass\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}], [{"term": "class", "name": "HTTPSitemapTests", "data": "class HTTPSitemapTests(SitemapTestsBase):\n\tuse_sitemap_err_msg = (\n\t\t'To use sitemaps, either enable the sites framework or pass a '\n\t\t'Site/RequestSite object in your view.'\n\t)\n\n\tdef test_simple_sitemap_index(self):\n\t\t\"A simple sitemap index can be rendered\"\n\t\tresponse = self.client.get('/simple/index.xml')\n\t\texpected_content = \"\"\"\n", "description": "\n", "category": "simple", "imports": ["import os", "from datetime import date", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import modify_settings, override_settings", "from django.utils import translation", "from django.utils.formats import localize", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_sitemap_not_callable", "data": "\tdef test_sitemap_not_callable(self):\n\t\t\"\"\"A sitemap may not be callable.\"\"\"\n\t\tresponse = self.client.get('/simple-not-callable/index.xml')\n\t\texpected_content = \"\"\"\n", "description": "A sitemap may not be callable.", "category": "simple", "imports": ["import os", "from datetime import date", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import modify_settings, override_settings", "from django.utils import translation", "from django.utils.formats import localize", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_paged_sitemap", "data": "\tdef test_paged_sitemap(self):\n\t\t\"\"\"A sitemap may have multiple pages.\"\"\"\n\t\tresponse = self.client.get('/simple-paged/index.xml')\n\t\texpected_content = \"\"\"\n", "description": "A sitemap may have multiple pages.", "category": "simple", "imports": ["import os", "from datetime import date", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import modify_settings, override_settings", "from django.utils import translation", "from django.utils.formats import localize", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_simple_sitemap_custom_index", "data": "\tdef test_simple_sitemap_custom_index(self):\n\t\t\"A simple sitemap index can be rendered with a custom template\"\n\t\tresponse = self.client.get('/simple/custom-index.xml')\n\t\texpected_content = \"\"\"\n\n", "description": "\n\n", "category": "simple", "imports": ["import os", "from datetime import date", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import modify_settings, override_settings", "from django.utils import translation", "from django.utils.formats import localize", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_simple_sitemap_section", "data": "\tdef test_simple_sitemap_section(self):\n\t\t\"A simple sitemap section can be rendered\"\n\t\tresponse = self.client.get('/simple/sitemap-simple.xml')\n\t\texpected_content = \"\"\"\n", "description": "\n", "category": "simple", "imports": ["import os", "from datetime import date", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import modify_settings, override_settings", "from django.utils import translation", "from django.utils.formats import localize", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_no_section", "data": "\tdef test_no_section(self):\n\t\tresponse = self.client.get('/simple/sitemap-simple2.xml')\n\t\tself.assertEqual(str(response.context['exception']), \"No sitemap available for section: 'simple2'\")\n\t\tself.assertEqual(response.status_code, 404)\n", "description": null, "category": "simple", "imports": ["import os", "from datetime import date", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import modify_settings, override_settings", "from django.utils import translation", "from django.utils.formats import localize", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_empty_page", "data": "\tdef test_empty_page(self):\n\t\tresponse = self.client.get('/simple/sitemap-simple.xml?p=0')\n\t\tself.assertEqual(str(response.context['exception']), 'Page 0 empty')\n\t\tself.assertEqual(response.status_code, 404)\n", "description": null, "category": "simple", "imports": ["import os", "from datetime import date", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import modify_settings, override_settings", "from django.utils import translation", "from django.utils.formats import localize", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_page_not_int", "data": "\tdef test_page_not_int(self):\n\t\tresponse = self.client.get('/simple/sitemap-simple.xml?p=test')\n\t\tself.assertEqual(str(response.context['exception']), \"No page 'test'\")\n\t\tself.assertEqual(response.status_code, 404)\n", "description": null, "category": "simple", "imports": ["import os", "from datetime import date", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import modify_settings, override_settings", "from django.utils import translation", "from django.utils.formats import localize", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_simple_sitemap", "data": "\tdef test_simple_sitemap(self):\n\t\t\"A simple sitemap can be rendered\"\n\t\tresponse = self.client.get('/simple/sitemap.xml')\n\t\texpected_content = \"\"\"\n", "description": "\n", "category": "simple", "imports": ["import os", "from datetime import date", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import modify_settings, override_settings", "from django.utils import translation", "from django.utils.formats import localize", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_simple_custom_sitemap", "data": "\tdef test_simple_custom_sitemap(self):\n\t\t\"A simple sitemap can be rendered with a custom template\"\n\t\tresponse = self.client.get('/simple/custom-sitemap.xml')\n\t\texpected_content = \"\"\"\n\n", "description": "\n\n", "category": "simple", "imports": ["import os", "from datetime import date", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import modify_settings, override_settings", "from django.utils import translation", "from django.utils.formats import localize", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_sitemap_last_modified", "data": "\tdef test_sitemap_last_modified(self):\n\t\t\"Last-Modified header is set correctly\"\n\t\tresponse = self.client.get('/lastmod/sitemap.xml')\n\t\tself.assertEqual(response['Last-Modified'], 'Wed, 13 Mar 2013 10:00:00 GMT')\n", "description": null, "category": "simple", "imports": ["import os", "from datetime import date", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import modify_settings, override_settings", "from django.utils import translation", "from django.utils.formats import localize", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_sitemap_last_modified_date", "data": "\tdef test_sitemap_last_modified_date(self):\n\t\t\"\"\"\n\t\tThe Last-Modified header should be support dates (without time).\n\t\t\"\"\"\n\t\tresponse = self.client.get('/lastmod/date-sitemap.xml')\n\t\tself.assertEqual(response['Last-Modified'], 'Wed, 13 Mar 2013 00:00:00 GMT')\n", "description": "\n\t\tThe Last-Modified header should be support dates (without time).\n\t\t", "category": "simple", "imports": ["import os", "from datetime import date", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import modify_settings, override_settings", "from django.utils import translation", "from django.utils.formats import localize", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_sitemap_last_modified_tz", "data": "\tdef test_sitemap_last_modified_tz(self):\n\t\t\"\"\"\n\t\tThe Last-Modified header should be converted from timezone aware dates\n\t\tto GMT.\n\t\t\"\"\"\n\t\tresponse = self.client.get('/lastmod/tz-sitemap.xml')\n\t\tself.assertEqual(response['Last-Modified'], 'Wed, 13 Mar 2013 15:00:00 GMT')\n", "description": "\n\t\tThe Last-Modified header should be converted from timezone aware dates\n\t\tto GMT.\n\t\t", "category": "simple", "imports": ["import os", "from datetime import date", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import modify_settings, override_settings", "from django.utils import translation", "from django.utils.formats import localize", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_sitemap_last_modified_missing", "data": "\tdef test_sitemap_last_modified_missing(self):\n\t\t\"Last-Modified header is missing when sitemap has no lastmod\"\n\t\tresponse = self.client.get('/generic/sitemap.xml')\n\t\tself.assertFalse(response.has_header('Last-Modified'))\n", "description": null, "category": "simple", "imports": ["import os", "from datetime import date", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import modify_settings, override_settings", "from django.utils import translation", "from django.utils.formats import localize", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_sitemap_last_modified_mixed", "data": "\tdef test_sitemap_last_modified_mixed(self):\n\t\t\"Last-Modified header is omitted when lastmod not on all items\"\n\t\tresponse = self.client.get('/lastmod-mixed/sitemap.xml')\n\t\tself.assertFalse(response.has_header('Last-Modified'))\n", "description": null, "category": "simple", "imports": ["import os", "from datetime import date", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import modify_settings, override_settings", "from django.utils import translation", "from django.utils.formats import localize", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_sitemaps_lastmod_mixed_ascending_last_modified_missing", "data": "\tdef test_sitemaps_lastmod_mixed_ascending_last_modified_missing(self):\n\t\t\"\"\"\n\t\tThe Last-Modified header is omitted when lastmod isn't found in all\n\t\tsitemaps. Test sitemaps are sorted by lastmod in ascending order.\n\t\t\"\"\"\n\t\tresponse = self.client.get('/lastmod-sitemaps/mixed-ascending.xml')\n\t\tself.assertFalse(response.has_header('Last-Modified'))\n", "description": "\n\t\tThe Last-Modified header is omitted when lastmod isn't found in all\n\t\tsitemaps. Test sitemaps are sorted by lastmod in ascending order.\n\t\t", "category": "simple", "imports": ["import os", "from datetime import date", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import modify_settings, override_settings", "from django.utils import translation", "from django.utils.formats import localize", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_sitemaps_lastmod_mixed_descending_last_modified_missing", "data": "\tdef test_sitemaps_lastmod_mixed_descending_last_modified_missing(self):\n\t\t\"\"\"\n\t\tThe Last-Modified header is omitted when lastmod isn't found in all\n\t\tsitemaps. Test sitemaps are sorted by lastmod in descending order.\n\t\t\"\"\"\n\t\tresponse = self.client.get('/lastmod-sitemaps/mixed-descending.xml')\n\t\tself.assertFalse(response.has_header('Last-Modified'))\n", "description": "\n\t\tThe Last-Modified header is omitted when lastmod isn't found in all\n\t\tsitemaps. Test sitemaps are sorted by lastmod in descending order.\n\t\t", "category": "simple", "imports": ["import os", "from datetime import date", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import modify_settings, override_settings", "from django.utils import translation", "from django.utils.formats import localize", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_sitemaps_lastmod_ascending", "data": "\tdef test_sitemaps_lastmod_ascending(self):\n\t\t\"\"\"\n\t\tThe Last-Modified header is set to the most recent sitemap lastmod.\n\t\tTest sitemaps are sorted by lastmod in ascending order.\n\t\t\"\"\"\n\t\tresponse = self.client.get('/lastmod-sitemaps/ascending.xml')\n\t\tself.assertEqual(response['Last-Modified'], 'Sat, 20 Apr 2013 05:00:00 GMT')\n", "description": "\n\t\tThe Last-Modified header is set to the most recent sitemap lastmod.\n\t\tTest sitemaps are sorted by lastmod in ascending order.\n\t\t", "category": "simple", "imports": ["import os", "from datetime import date", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import modify_settings, override_settings", "from django.utils import translation", "from django.utils.formats import localize", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_sitemaps_lastmod_descending", "data": "\tdef test_sitemaps_lastmod_descending(self):\n\t\t\"\"\"\n\t\tThe Last-Modified header is set to the most recent sitemap lastmod.\n\t\tTest sitemaps are sorted by lastmod in descending order.\n\t\t\"\"\"\n\t\tresponse = self.client.get('/lastmod-sitemaps/descending.xml')\n\t\tself.assertEqual(response['Last-Modified'], 'Sat, 20 Apr 2013 05:00:00 GMT')\n", "description": "\n\t\tThe Last-Modified header is set to the most recent sitemap lastmod.\n\t\tTest sitemaps are sorted by lastmod in descending order.\n\t\t", "category": "simple", "imports": ["import os", "from datetime import date", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import modify_settings, override_settings", "from django.utils import translation", "from django.utils.formats import localize", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_localized_priority", "data": "\tdef test_localized_priority(self):\n\t\t\"\"\"The priority value should not be localized.\"\"\"\n\t\twith translation.override('fr'):\n\t\t\tself.assertEqual('0,3', localize(0.3))\n\t\t\t# Priorities aren't rendered in localized format.\n\t\t\tresponse = self.client.get('/simple/sitemap.xml')\n\t\t\tself.assertContains(response, '0.5')\n\t\t\tself.assertContains(response, '%s' % date.today())\n", "description": "The priority value should not be localized.", "category": "simple", "imports": ["import os", "from datetime import date", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import modify_settings, override_settings", "from django.utils import translation", "from django.utils.formats import localize", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_requestsite_sitemap", "data": "\tdef test_requestsite_sitemap(self):\n\t\t# Hitting the flatpages sitemap without the sites framework installed\n\t\t# doesn't raise an exception.\n\t\tresponse = self.client.get('/simple/sitemap.xml')\n\t\texpected_content = \"\"\"\n", "description": "\n", "category": "simple", "imports": ["import os", "from datetime import date", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import modify_settings, override_settings", "from django.utils import translation", "from django.utils.formats import localize", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_sitemap_get_urls_no_site_1", "data": "\tdef test_sitemap_get_urls_no_site_1(self):\n\t\t\"\"\"\n\t\tCheck we get ImproperlyConfigured if we don't pass a site object to\n\t\tSitemap.get_urls and no Site objects exist\n\t\t\"\"\"\n\t\tSite.objects.all().delete()\n\t\twith self.assertRaisesMessage(ImproperlyConfigured, self.use_sitemap_err_msg):\n\t\t\tSitemap().get_urls()\n", "description": "\n\t\tCheck we get ImproperlyConfigured if we don't pass a site object to\n\t\tSitemap.get_urls and no Site objects exist\n\t\t", "category": "simple", "imports": ["import os", "from datetime import date", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import modify_settings, override_settings", "from django.utils import translation", "from django.utils.formats import localize", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_sitemap_get_urls_no_site_2", "data": "\tdef test_sitemap_get_urls_no_site_2(self):\n\t\t\"\"\"\n\t\tCheck we get ImproperlyConfigured when we don't pass a site object to\n\t\tSitemap.get_urls if Site objects exists, but the sites framework is not\n\t\tactually installed.\n\t\t\"\"\"\n\t\twith self.assertRaisesMessage(ImproperlyConfigured, self.use_sitemap_err_msg):\n\t\t\tSitemap().get_urls()\n", "description": "\n\t\tCheck we get ImproperlyConfigured when we don't pass a site object to\n\t\tSitemap.get_urls if Site objects exists, but the sites framework is not\n\t\tactually installed.\n\t\t", "category": "simple", "imports": ["import os", "from datetime import date", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import modify_settings, override_settings", "from django.utils import translation", "from django.utils.formats import localize", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_sitemap_item", "data": "\tdef test_sitemap_item(self):\n\t\t\"\"\"\n\t\tCheck to make sure that the raw item is included with each\n\t\tSitemap.get_url() url result.\n\t\t\"\"\"\n\t\ttest_sitemap = Sitemap()\n\t\ttest_sitemap.items = TestModel.objects.order_by('pk').all\n\n\t\tdef is_testmodel(url):\n\t\t\treturn isinstance(url['item'], TestModel)\n\t\titem_in_url_info = all(map(is_testmodel, test_sitemap.get_urls()))\n\t\tself.assertTrue(item_in_url_info)\n", "description": "\n\t\tCheck to make sure that the raw item is included with each\n\t\tSitemap.get_url() url result.\n\t\t", "category": "simple", "imports": ["import os", "from datetime import date", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import modify_settings, override_settings", "from django.utils import translation", "from django.utils.formats import localize", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_cached_sitemap_index", "data": "\tdef test_cached_sitemap_index(self):\n\t\t\"\"\"\n\t\tA cached sitemap index can be rendered (#2713).\n\t\t\"\"\"\n\t\tresponse = self.client.get('/cached/index.xml')\n\t\texpected_content = \"\"\"\n", "description": "\n\t\tA cached sitemap index can be rendered (#2713).\n\t\t", "category": "simple", "imports": ["import os", "from datetime import date", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import modify_settings, override_settings", "from django.utils import translation", "from django.utils.formats import localize", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_x_robots_sitemap", "data": "\tdef test_x_robots_sitemap(self):\n\t\tresponse = self.client.get('/simple/index.xml')\n\t\tself.assertEqual(response['X-Robots-Tag'], 'noindex, noodp, noarchive')\n\n\t\tresponse = self.client.get('/simple/sitemap.xml')\n\t\tself.assertEqual(response['X-Robots-Tag'], 'noindex, noodp, noarchive')\n", "description": null, "category": "simple", "imports": ["import os", "from datetime import date", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import modify_settings, override_settings", "from django.utils import translation", "from django.utils.formats import localize", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_empty_sitemap", "data": "\tdef test_empty_sitemap(self):\n\t\tresponse = self.client.get('/empty/sitemap.xml')\n\t\tself.assertEqual(response.status_code, 200)\n", "description": null, "category": "simple", "imports": ["import os", "from datetime import date", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import modify_settings, override_settings", "from django.utils import translation", "from django.utils.formats import localize", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_simple_i18n_sitemap_index", "data": "\tdef test_simple_i18n_sitemap_index(self):\n\t\t\"\"\"\n\t\tA simple i18n sitemap index can be rendered.\n\t\t\"\"\"\n\t\tresponse = self.client.get('/simple/i18n.xml')\n\t\texpected_content = \"\"\"\n", "description": "\n\t\tA simple i18n sitemap index can be rendered.\n\t\t", "category": "simple", "imports": ["import os", "from datetime import date", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import modify_settings, override_settings", "from django.utils import translation", "from django.utils.formats import localize", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_alternate_i18n_sitemap_index", "data": "\tdef test_alternate_i18n_sitemap_index(self):\n\t\t\"\"\"\n\t\tA i18n sitemap with alternate/hreflang links can be rendered.\n\t\t\"\"\"\n\t\tresponse = self.client.get('/alternates/i18n.xml')\n\t\turl, pk = self.base_url, self.i18n_model.pk\n", "description": "\n\t\tA i18n sitemap with alternate/hreflang links can be rendered.\n\t\t", "category": "simple", "imports": ["import os", "from datetime import date", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import modify_settings, override_settings", "from django.utils import translation", "from django.utils.formats import localize", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_alternate_i18n_sitemap_limited", "data": "\tdef test_alternate_i18n_sitemap_limited(self):\n\t\t\"\"\"\n\t\tA i18n sitemap index with limited languages can be rendered.\n\t\t\"\"\"\n\t\tresponse = self.client.get('/limited/i18n.xml')\n\t\turl, pk = self.base_url, self.i18n_model.pk\n", "description": "\n\t\tA i18n sitemap index with limited languages can be rendered.\n\t\t", "category": "simple", "imports": ["import os", "from datetime import date", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import modify_settings, override_settings", "from django.utils import translation", "from django.utils.formats import localize", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_alternate_i18n_sitemap_xdefault", "data": "\tdef test_alternate_i18n_sitemap_xdefault(self):\n\t\t\"\"\"\n\t\tA i18n sitemap index with x-default can be rendered.\n\t\t\"\"\"\n\t\tresponse = self.client.get('/x-default/i18n.xml')\n\t\turl, pk = self.base_url, self.i18n_model.pk\n", "description": "\n\t\tA i18n sitemap index with x-default can be rendered.\n\t\t", "category": "simple", "imports": ["import os", "from datetime import date", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import modify_settings, override_settings", "from django.utils import translation", "from django.utils.formats import localize", "from .base import SitemapTestsBase", "from .models import TestModel"]}, {"term": "def", "name": "ftest_sitemap_without_entries", "data": "\tdef test_sitemap_without_entries(self):\n\t\tresponse = self.client.get('/sitemap-without-entries/sitemap.xml')\n\t\texpected_content = \"\"\"\n", "description": "\n", "category": "simple", "imports": ["import os", "from datetime import date", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import modify_settings, override_settings", "from django.utils import translation", "from django.utils.formats import localize", "from .base import SitemapTestsBase", "from .models import TestModel"]}], [{"term": "class", "name": "L1Cache", "data": "class L1Cache(Cache):\n\t\"\"\"Simple L1 Cache with default values\"\"\"\n\n\tassoc = 8\n\ttag_latency = 1\n\tdata_latency = 1\n\tresponse_latency = 1\n\tmshrs = 16\n\ttgts_per_mshr = 20\n\n\tdef connectBus(self, bus):\n\t\t\"\"\"Connect this cache to a memory-side bus\"\"\"\n\t\tself.mem_side = bus.cpu_side_ports\n\n\tdef connectCPU(self, cpu):\n\t\t\"\"\"Connect this cache's port to a CPU-side port\n\t\t   This must be defined in a subclass\"\"\"\n\t\traise NotImplementedError\n", "description": "Simple L1 Cache with default values", "category": "simple", "imports": ["import os", "import argparse", "import m5", "from m5.objects import *"]}, {"term": "class", "name": "L1ICache", "data": "class L1ICache(L1Cache):\n\t\"\"\"Simple L1 instruction cache with default values\"\"\"\n\n\t# Set the default size\n\tsize = '32kB'\n\n\tdef connectCPU(self, cpu):\n\t\t\"\"\"Connect this cache's port to a CPU icache port\"\"\"\n\t\tself.cpu_side = cpu.icache_port\n", "description": "Simple L1 instruction cache with default values", "category": "simple", "imports": ["import os", "import argparse", "import m5", "from m5.objects import *"]}, {"term": "class", "name": "L1DCache", "data": "class L1DCache(L1Cache):\n\t\"\"\"Simple L1 data cache with default values\"\"\"\n\n\t# Set the default size\n\tsize = '32kB'\n\n\tdef connectCPU(self, cpu):\n\t\t\"\"\"Connect this cache's port to a CPU dcache port\"\"\"\n\t\tself.cpu_side = cpu.dcache_port\n", "description": "Simple L1 data cache with default values", "category": "simple", "imports": ["import os", "import argparse", "import m5", "from m5.objects import *"]}, {"term": "class", "name": "L2Cache", "data": "class L2Cache(Cache):\n\t\"\"\"Simple L2 Cache with default values\"\"\"\n\n\t# Default parameters\n\tsize = '512kB'\n\tassoc = 16\n\ttag_latency = 10\n\tdata_latency = 10\n\tresponse_latency = 1\n\tmshrs = 20\n\ttgts_per_mshr = 12\n\n\tdef connectCPUSideBus(self, bus):\n\t\tself.cpu_side = bus.mem_side_ports\n\n\tdef connectMemSideBus(self, bus):\n\t\tself.mem_side = bus.cpu_side_ports\n\n", "description": "Simple L2 Cache with default values", "category": "simple", "imports": ["import os", "import argparse", "import m5", "from m5.objects import *"]}, {"term": "class", "name": "MySimpleMemory", "data": "class MySimpleMemory(SimpleMemory):\n\tlatency = '1ns'\n", "description": null, "category": "simple", "imports": ["import os", "import argparse", "import m5", "from m5.objects import *"]}], [], [], [{"term": "def", "name": "get_domain_from_dataset_simple", "data": "def get_domain_from_dataset_simple(distinct_values):\n\treturn sorted(distinct_values),{}\n", "description": null, "category": "simple", "imports": ["from operator import is_not,or_", "from functools import partial", "#from intbitset import intbitset"]}, {"term": "def", "name": "get_starting_pattern_simple", "data": "def get_starting_pattern_simple(domain):\n\tstarting_pattern=domain[:]\n\tstarting_refinement=0\n\tdefault_widthmax=0\n\treturn starting_pattern,starting_refinement,default_widthmax\n\n", "description": null, "category": "simple", "imports": ["from operator import is_not,or_", "from functools import partial", "#from intbitset import intbitset"]}, {"term": "def", "name": "children_simple", "data": "def children_simple(domain,pattern,refinement_index,widthmax=0,others=None):\n\tif len(pattern)>1:\n\t\tfor i in range(refinement_index,len(pattern)):\n\t\t\tpossible_child=[pattern[i]]\n\t\t\tyield possible_child,len(domain)\n\t\t\n", "description": null, "category": "simple", "imports": ["from operator import is_not,or_", "from functools import partial", "#from intbitset import intbitset"]}, {"term": "def", "name": "children_withSupport_simple", "data": "def children_withSupport_simple(attr,wholeDataset,p_indices,p_indices_bitset,closed=True):\n\t\n\tpattern=attr['pattern']\n\tdomain=attr['domain']#tree\n\tindex_attr=attr['index_attr']\n\tindex_attr_bitset=attr['index_attr_bitset']\n\trefinement_index=attr['refinement_index']\n\twidthmax=attr['widthmax']\n\tlen_p=len(pattern)\n\n\tif len(pattern)>1:\n\t\tfor i in range(refinement_index,len(pattern)):\n\t\t\tpossible_child=[pattern[i]]\n\t\t\tindices_new,indices_bitset_new=compute_full_support_simple_with_bitset(p_indices,p_indices_bitset,attr,closed=closed)\n\t\t\tsupport_new=[wholeDataset[ind] for ind in indices_new]\n\t\t\tyield possible_child,len(domain),support_new,indices_new,indices_bitset_new\n\n\n", "description": null, "category": "simple", "imports": ["from operator import is_not,or_", "from functools import partial", "#from intbitset import intbitset"]}, {"term": "def", "name": "enumerator_simple", "data": "def enumerator_simple(domain,pattern,refinement_index,widthmax=0):\n\tyielded_pattern=value_to_yield_simple(domain,pattern,refinement_index,widthmax)\n\tif yielded_pattern is not None:\n\t\tyield yielded_pattern\n\tfor child,refin_child in children_simple(domain,pattern,refinement_index,widthmax):\n\t\tfor child_pattern in enumerator_simple(domain,child,refin_child,widthmax):\n\t\t\tyield child_pattern\n\t\t\t\n", "description": null, "category": "simple", "imports": ["from operator import is_not,or_", "from functools import partial", "#from intbitset import intbitset"]}, {"term": "def", "name": "pattern_cover_object_simple", "data": "def pattern_cover_object_simple(domain,pattern,refinement_index,record,attribute):\n\treturn record[attribute] in pattern\n", "description": null, "category": "simple", "imports": ["from operator import is_not,or_", "from functools import partial", "#from intbitset import intbitset"]}, {"term": "def", "name": "pattern_cover_object_simple_index", "data": "def pattern_cover_object_simple_index(pattern,record,attribute):\n\treturn record[attribute] in pattern\n", "description": null, "category": "simple", "imports": ["from operator import is_not,or_", "from functools import partial", "#from intbitset import intbitset"]}, {"term": "def", "name": "object_value_for_index_simple", "data": "def object_value_for_index_simple(domain,record,attribute):\n\treturn record[attribute]  \n", "description": null, "category": "simple", "imports": ["from operator import is_not,or_", "from functools import partial", "#from intbitset import intbitset"]}, {"term": "def", "name": "infimum_simple", "data": "def infimum_simple(domain,p1,p2):\n\treturn sorted(set(p1)|set(p2))\n\n", "description": null, "category": "simple", "imports": ["from operator import is_not,or_", "from functools import partial", "#from intbitset import intbitset"]}, {"term": "def", "name": "closed_simple", "data": "def closed_simple(domain,list_patterns):\n\tlist_set_patterns = [{item} for item in list_patterns]\n\tclos=reduce(set.union,list_set_patterns)\n\tres=domain[:]\n\tfor k in range(len(res)):\n\t\tif res[k] not in clos:\n\t\t\tres[k]=None\n\treturn res\n\n", "description": null, "category": "simple", "imports": ["from operator import is_not,or_", "from functools import partial", "#from intbitset import intbitset"]}, {"term": "def", "name": "closed_simple_index", "data": "def closed_simple_index(domain,datasetIndices,list_patterns,attr):\n\tattr_name=attr['name']\n\tlist_patterns=[x[attr_name] for x in list_patterns]\n\tlist_set_patterns = set(list_patterns)\n\t\n\treturn sorted(list_set_patterns)\n\n", "description": null, "category": "simple", "imports": ["from operator import is_not,or_", "from functools import partial", "#from intbitset import intbitset"]}, {"term": "def", "name": "respect_order_simple", "data": "def respect_order_simple(p1,p2,refinement_index):\n\t#return False if any(p1[i]!=p2[i] for i in range(0,refinement_index)) else True\n\treturn True\n", "description": null, "category": "simple", "imports": ["from operator import is_not,or_", "from functools import partial", "#from intbitset import intbitset"]}, {"term": "def", "name": "respect_order_simple_not_after_closure", "data": "def respect_order_simple_not_after_closure(p1,p2,refinement_index_1,refinement_index_2):\n\tif len(p1)>1:\n\t\treturn True\n\telif len(p1)==1 and len(p2)==1:\n\t\treturn p1[0]<=p2[0]\n\treturn False\n\t# if len(p1)>1 or len(p2)>1:\n\t#\t return (set(p2)<=set(p1))\n\n\n\t\n", "description": null, "category": "simple", "imports": ["from operator import is_not,or_", "from functools import partial", "#from intbitset import intbitset"]}, {"term": "def", "name": "closure_continueFrom_simple", "data": "def closure_continueFrom_simple(domain,pattern,closed,refinement_index): #what is the pattern which represent the one that we need to continue from after closing (it's none if the lexicographic order is not respected)\n\treturn closed[:]\n", "description": null, "category": "simple", "imports": ["from operator import is_not,or_", "from functools import partial", "#from intbitset import intbitset"]}, {"term": "def", "name": "equality_simple", "data": "def equality_simple(p1,p2):\n\tif (len(p1)>1 and len(p2)>1):\n\t\treturn True\n\t\t#return set(p2)<=set(p1)\n\telse:\n\t\treturn p1==p2\n\t\n", "description": null, "category": "simple", "imports": ["from operator import is_not,or_", "from functools import partial", "#from intbitset import intbitset"]}, {"term": "def", "name": "encode_sup", "data": "def encode_sup(arr_pos,len_map_keys):\n\tto_shift_in_last=len_map_keys-arr_pos[-1]\n\tfor i in range(len(arr_pos)-1,0,-1):#range(1,len(arr_pos))[::-1]:\n\t\tarr_pos[i]-=arr_pos[i-1]\n\tret=1\n\tfor i in arr_pos:\n\t\tret=(ret<1:\n\t\treturn set_indices_prec\n\telse:\n\t\treturn set_indices_prec&attr['index_attr'][attr_pattern[0]]\n\t#return set_indices_prec&reduce(set.union,[attr['index_attr'][p] for p in attr['pattern']]) \n", "description": null, "category": "simple", "imports": ["from operator import is_not,or_", "from functools import partial", "#from intbitset import intbitset"]}, {"term": "def", "name": "compute_full_support_simple_with_bitset", "data": "def compute_full_support_simple_with_bitset(set_indices_prec,datasetIndices_bitset,attr,closed=True):\n\t#print attr['pattern'],'aha'\n\tattr_pattern=attr['pattern']\n\t#if closed:\n\tif len(attr_pattern)>1:\n\t\treturn set_indices_prec,datasetIndices_bitset\n\telse:\n\t\t# print(attr['index_attr'].keys())\n\t\t# print (attr_pattern)\n\t\t# print (attr_pattern[0])\n\t\treturn set_indices_prec&attr['index_attr'][attr_pattern[0]],datasetIndices_bitset&attr['index_attr_bitset'][attr_pattern[0]]\n\t# else:\n\t#\t return set_indices_prec&reduce(set.union,[attr['index_attr'][p] for p in attr['pattern']])  , datasetIndices_bitset&reduce(or_,[attr['index_attr_bitset'][p] for p in attr['pattern']])\n\n\t#return set_indices_prec&reduce(set.union,[attr['index_attr'][p] for p in attr['pattern']]) \n\n", "description": null, "category": "simple", "imports": ["from operator import is_not,or_", "from functools import partial", "#from intbitset import intbitset"]}, {"term": "def", "name": "p1_subsume_p2_simple", "data": "def p1_subsume_p2_simple(p1,p2):\n\tif len(p1)>1:\n\t\treturn True\n\telse:\n\t\treturn p1==p2\n\t#return set(p2)<=set(p1)\n\n", "description": null, "category": "simple", "imports": ["from operator import is_not,or_", "from functools import partial", "#from intbitset import intbitset"]}], [], [], [], [], [], [], [{"term": "class", "name": "MWSTestCase", "data": "class MWSTestCase(unittest.TestCase):\n\n\tdef setUp(self):\n\t\tself.mws = MWSConnection(Merchant=simple, debug=0)\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_feedlist(self):\n\t\tself.mws.get_feed_submission_list()\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_inbound_status(self):\n\t\tresponse = self.mws.get_inbound_service_status()\n\t\tstatus = response.GetServiceStatusResult.Status\n\t\tself.assertIn(status, ('GREEN', 'GREEN_I', 'YELLOW', 'RED'))\n\n\t@property\n\tdef marketplace(self):\n\t\ttry:\n\t\t\treturn self._marketplace\n\t\texcept AttributeError:\n\t\t\tresponse = self.mws.list_marketplace_participations()\n\t\t\tresult = response.ListMarketplaceParticipationsResult\n\t\t\tself._marketplace = result.ListMarketplaces.Marketplace[0]\n\t\t\treturn self.marketplace\n\n\t@property\n\tdef marketplace_id(self):\n\t\treturn self.marketplace.MarketplaceId\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_marketplace_participations(self):\n\t\tresponse = self.mws.list_marketplace_participations()\n\t\tresult = response.ListMarketplaceParticipationsResult\n\t\tself.assertTrue(result.ListMarketplaces.Marketplace[0].MarketplaceId)\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_get_product_categories_for_asin(self):\n\t\tasin = '144930544X'\n\t\tresponse = self.mws.get_product_categories_for_asin(\n\t\t\tMarketplaceId=self.marketplace_id,\n\t\t\tASIN=asin)\n\t\tself.assertEqual(len(response._result.Self), 3)\n\t\tcategoryids = [x.ProductCategoryId for x in response._result.Self]\n\t\tself.assertSequenceEqual(categoryids, ['285856', '21', '491314'])\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_list_matching_products(self):\n\t\tresponse = self.mws.list_matching_products(\n\t\t\tMarketplaceId=self.marketplace_id,\n\t\t\tQuery='boto')\n\t\tproducts = response._result.Products\n\t\tself.assertTrue(len(products))\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_get_matching_product(self):\n\t\tasin = 'B001UDRNHO'\n\t\tresponse = self.mws.get_matching_product(\n\t\t\tMarketplaceId=self.marketplace_id,\n\t\t\tASINList=[asin])\n\t\tattributes = response._result[0].Product.AttributeSets.ItemAttributes\n\t\tself.assertEqual(attributes[0].Label, 'Serengeti')\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_get_matching_product_for_id(self):\n\t\tasins = ['B001UDRNHO', '144930544X']\n\t\tresponse = self.mws.get_matching_product_for_id(\n\t\t\tMarketplaceId=self.marketplace_id,\n\t\t\tIdType='ASIN',\n\t\t\tIdList=asins)\n\t\tself.assertEqual(len(response._result), 2)\n\t\tfor result in response._result:\n\t\t\tself.assertEqual(len(result.Products.Product), 1)\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_get_lowest_offer_listings_for_asin(self):\n\t\tasin = '144930544X'\n\t\tresponse = self.mws.get_lowest_offer_listings_for_asin(\n\t\t\tMarketplaceId=self.marketplace_id,\n\t\t\tItemCondition='New',\n\t\t\tASINList=[asin])\n\t\tlistings = response._result[0].Product.LowestOfferListings\n\t\tself.assertTrue(len(listings.LowestOfferListing))\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_list_inventory_supply(self):\n\t\tasof = (datetime.today() - timedelta(days=30)).isoformat()\n\t\tresponse = self.mws.list_inventory_supply(QueryStartDateTime=asof,\n\t\t\t\t\t\t\t\t\t\t\t\t  ResponseGroup='Basic')\n\t\tself.assertTrue(hasattr(response._result, 'InventorySupplyList'))\n", "description": null, "category": "simple", "imports": ["from __future__ import print_function", "import sys", "import os", "import os.path", "from datetime import datetime, timedelta", "from boto.mws.connection import MWSConnection", "from tests.compat import unittest"]}], [{"term": "class", "name": "MWSTestCase", "data": "class MWSTestCase(unittest.TestCase):\n\n\tdef setUp(self):\n\t\tself.mws = MWSConnection(Merchant=simple, debug=0)\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_feedlist(self):\n\t\tself.mws.get_feed_submission_list()\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_inbound_status(self):\n\t\tresponse = self.mws.get_inbound_service_status()\n\t\tstatus = response.GetServiceStatusResult.Status\n\t\tself.assertIn(status, ('GREEN', 'GREEN_I', 'YELLOW', 'RED'))\n\n\t@property\n\tdef marketplace(self):\n\t\ttry:\n\t\t\treturn self._marketplace\n\t\texcept AttributeError:\n\t\t\tresponse = self.mws.list_marketplace_participations()\n\t\t\tresult = response.ListMarketplaceParticipationsResult\n\t\t\tself._marketplace = result.ListMarketplaces.Marketplace[0]\n\t\t\treturn self.marketplace\n\n\t@property\n\tdef marketplace_id(self):\n\t\treturn self.marketplace.MarketplaceId\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_marketplace_participations(self):\n\t\tresponse = self.mws.list_marketplace_participations()\n\t\tresult = response.ListMarketplaceParticipationsResult\n\t\tself.assertTrue(result.ListMarketplaces.Marketplace[0].MarketplaceId)\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_get_product_categories_for_asin(self):\n\t\tasin = '144930544X'\n\t\tresponse = self.mws.get_product_categories_for_asin(\n\t\t\tMarketplaceId=self.marketplace_id,\n\t\t\tASIN=asin)\n\t\tself.assertEqual(len(response._result.Self), 3)\n\t\tcategoryids = [x.ProductCategoryId for x in response._result.Self]\n\t\tself.assertSequenceEqual(categoryids, ['285856', '21', '491314'])\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_list_matching_products(self):\n\t\tresponse = self.mws.list_matching_products(\n\t\t\tMarketplaceId=self.marketplace_id,\n\t\t\tQuery='boto')\n\t\tproducts = response._result.Products\n\t\tself.assertTrue(len(products))\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_get_matching_product(self):\n\t\tasin = 'B001UDRNHO'\n\t\tresponse = self.mws.get_matching_product(\n\t\t\tMarketplaceId=self.marketplace_id,\n\t\t\tASINList=[asin])\n\t\tattributes = response._result[0].Product.AttributeSets.ItemAttributes\n\t\tself.assertEqual(attributes[0].Label, 'Serengeti')\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_get_matching_product_for_id(self):\n\t\tasins = ['B001UDRNHO', '144930544X']\n\t\tresponse = self.mws.get_matching_product_for_id(\n\t\t\tMarketplaceId=self.marketplace_id,\n\t\t\tIdType='ASIN',\n\t\t\tIdList=asins)\n\t\tself.assertEqual(len(response._result), 2)\n\t\tfor result in response._result:\n\t\t\tself.assertEqual(len(result.Products.Product), 1)\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_get_lowest_offer_listings_for_asin(self):\n\t\tasin = '144930544X'\n\t\tresponse = self.mws.get_lowest_offer_listings_for_asin(\n\t\t\tMarketplaceId=self.marketplace_id,\n\t\t\tItemCondition='New',\n\t\t\tASINList=[asin])\n\t\tlistings = response._result[0].Product.LowestOfferListings\n\t\tself.assertTrue(len(listings.LowestOfferListing))\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_list_inventory_supply(self):\n\t\tasof = (datetime.today() - timedelta(days=30)).isoformat()\n\t\tresponse = self.mws.list_inventory_supply(QueryStartDateTime=asof,\n\t\t\t\t\t\t\t\t\t\t\t\t  ResponseGroup='Basic')\n\t\tself.assertTrue(hasattr(response._result, 'InventorySupplyList'))\n", "description": null, "category": "simple", "imports": ["from __future__ import print_function", "import sys", "import os", "import os.path", "from datetime import datetime, timedelta", "from boto.mws.connection import MWSConnection", "from tests.compat import unittest"]}], [{"term": "class", "name": "MWSTestCase", "data": "class MWSTestCase(unittest.TestCase):\n\n\tdef setUp(self):\n\t\tself.mws = MWSConnection(Merchant=simple, debug=0)\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_feedlist(self):\n\t\tself.mws.get_feed_submission_list()\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_inbound_status(self):\n\t\tresponse = self.mws.get_inbound_service_status()\n\t\tstatus = response.GetServiceStatusResult.Status\n\t\tself.assertIn(status, ('GREEN', 'GREEN_I', 'YELLOW', 'RED'))\n\n\t@property\n\tdef marketplace(self):\n\t\ttry:\n\t\t\treturn self._marketplace\n\t\texcept AttributeError:\n\t\t\tresponse = self.mws.list_marketplace_participations()\n\t\t\tresult = response.ListMarketplaceParticipationsResult\n\t\t\tself._marketplace = result.ListMarketplaces.Marketplace[0]\n\t\t\treturn self.marketplace\n\n\t@property\n\tdef marketplace_id(self):\n\t\treturn self.marketplace.MarketplaceId\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_marketplace_participations(self):\n\t\tresponse = self.mws.list_marketplace_participations()\n\t\tresult = response.ListMarketplaceParticipationsResult\n\t\tself.assertTrue(result.ListMarketplaces.Marketplace[0].MarketplaceId)\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_get_product_categories_for_asin(self):\n\t\tasin = '144930544X'\n\t\tresponse = self.mws.get_product_categories_for_asin(\n\t\t\tMarketplaceId=self.marketplace_id,\n\t\t\tASIN=asin)\n\t\tself.assertEqual(len(response._result.Self), 3)\n\t\tcategoryids = [x.ProductCategoryId for x in response._result.Self]\n\t\tself.assertSequenceEqual(categoryids, ['285856', '21', '491314'])\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_list_matching_products(self):\n\t\tresponse = self.mws.list_matching_products(\n\t\t\tMarketplaceId=self.marketplace_id,\n\t\t\tQuery='boto')\n\t\tproducts = response._result.Products\n\t\tself.assertTrue(len(products))\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_get_matching_product(self):\n\t\tasin = 'B001UDRNHO'\n\t\tresponse = self.mws.get_matching_product(\n\t\t\tMarketplaceId=self.marketplace_id,\n\t\t\tASINList=[asin])\n\t\tattributes = response._result[0].Product.AttributeSets.ItemAttributes\n\t\tself.assertEqual(attributes[0].Label, 'Serengeti')\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_get_matching_product_for_id(self):\n\t\tasins = ['B001UDRNHO', '144930544X']\n\t\tresponse = self.mws.get_matching_product_for_id(\n\t\t\tMarketplaceId=self.marketplace_id,\n\t\t\tIdType='ASIN',\n\t\t\tIdList=asins)\n\t\tself.assertEqual(len(response._result), 2)\n\t\tfor result in response._result:\n\t\t\tself.assertEqual(len(result.Products.Product), 1)\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_get_lowest_offer_listings_for_asin(self):\n\t\tasin = '144930544X'\n\t\tresponse = self.mws.get_lowest_offer_listings_for_asin(\n\t\t\tMarketplaceId=self.marketplace_id,\n\t\t\tItemCondition='New',\n\t\t\tASINList=[asin])\n\t\tlistings = response._result[0].Product.LowestOfferListings\n\t\tself.assertTrue(len(listings.LowestOfferListing))\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_list_inventory_supply(self):\n\t\tasof = (datetime.today() - timedelta(days=30)).isoformat()\n\t\tresponse = self.mws.list_inventory_supply(QueryStartDateTime=asof,\n\t\t\t\t\t\t\t\t\t\t\t\t  ResponseGroup='Basic')\n\t\tself.assertTrue(hasattr(response._result, 'InventorySupplyList'))\n", "description": null, "category": "simple", "imports": ["from __future__ import print_function", "import sys", "import os", "import os.path", "from datetime import datetime, timedelta", "from boto.mws.connection import MWSConnection", "from tests.compat import unittest"]}], [{"term": "class", "name": "TestLibraryInfo", "data": "class TestLibraryInfo(TestCase):\n\tdef test_simple(self):\n\t\tfd, filename = mkstemp('foo.ini')\n\t\ttry:\n\t\t\tpkg = os.path.splitext(filename)[0]\n\t\t\ttry:\n\t\t\t\tos.write(fd, simple.encode('ascii'))\n\t\t\tfinally:\n\t\t\t\tos.close(fd)\n\n\t\t\tout = read_config(pkg)\n\t\t\tself.assertTrue(out.cflags() == simple_d['cflags'])\n\t\t\tself.assertTrue(out.libs() == simple_d['libflags'])\n\t\t\tself.assertTrue(out.name == simple_d['name'])\n\t\t\tself.assertTrue(out.version == simple_d['version'])\n\t\tfinally:\n\t\t\tos.remove(filename)\n\n\tdef test_simple_variable(self):\n\t\tfd, filename = mkstemp('foo.ini')\n\t\ttry:\n\t\t\tpkg = os.path.splitext(filename)[0]\n\t\t\ttry:\n\t\t\t\tos.write(fd, simple_variable.encode('ascii'))\n\t\t\tfinally:\n\t\t\t\tos.close(fd)\n\n\t\t\tout = read_config(pkg)\n\t\t\tself.assertTrue(out.cflags() == simple_variable_d['cflags'])\n\t\t\tself.assertTrue(out.libs() == simple_variable_d['libflags'])\n\t\t\tself.assertTrue(out.name == simple_variable_d['name'])\n\t\t\tself.assertTrue(out.version == simple_variable_d['version'])\n\n\t\t\tout.vars['prefix'] = '/Users/david'\n\t\t\tself.assertTrue(out.cflags() == '-I/Users/david/include')\n\t\tfinally:\n\t\t\tos.remove(filename)\n", "description": null, "category": "simple", "imports": ["import os", "from tempfile import mkstemp", "from numpy.testing import *", "from numpy.distutils.npy_pkg_config import read_config, parse_flags"]}, {"term": "class", "name": "TestParseFlags", "data": "class TestParseFlags(TestCase):\n\tdef test_simple_cflags(self):\n\t\td = parse_flags(\"-I/usr/include\")\n\t\tself.assertTrue(d['include_dirs'] == ['/usr/include'])\n\n\t\td = parse_flags(\"-I/usr/include -DFOO\")\n\t\tself.assertTrue(d['include_dirs'] == ['/usr/include'])\n\t\tself.assertTrue(d['macros'] == ['FOO'])\n\n\t\td = parse_flags(\"-I /usr/include -DFOO\")\n\t\tself.assertTrue(d['include_dirs'] == ['/usr/include'])\n\t\tself.assertTrue(d['macros'] == ['FOO'])\n\n\tdef test_simple_lflags(self):\n\t\td = parse_flags(\"-L/usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tself.assertTrue(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tself.assertTrue(d['libraries'] == ['foo', 'bar'])\n\n\t\td = parse_flags(\"-L /usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tself.assertTrue(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tself.assertTrue(d['libraries'] == ['foo', 'bar'])\n", "description": null, "category": "simple", "imports": ["import os", "from tempfile import mkstemp", "from numpy.testing import *", "from numpy.distutils.npy_pkg_config import read_config, parse_flags"]}], [{"term": "class", "name": "TestLibraryInfo", "data": "class TestLibraryInfo(TestCase):\n\tdef test_simple(self):\n\t\tfd, filename = mkstemp('foo.ini')\n\t\ttry:\n\t\t\tpkg = os.path.splitext(filename)[0]\n\t\t\ttry:\n\t\t\t\tos.write(fd, simple.encode('ascii'))\n\t\t\tfinally:\n\t\t\t\tos.close(fd)\n\n\t\t\tout = read_config(pkg)\n\t\t\tself.assertTrue(out.cflags() == simple_d['cflags'])\n\t\t\tself.assertTrue(out.libs() == simple_d['libflags'])\n\t\t\tself.assertTrue(out.name == simple_d['name'])\n\t\t\tself.assertTrue(out.version == simple_d['version'])\n\t\tfinally:\n\t\t\tos.remove(filename)\n\n\tdef test_simple_variable(self):\n\t\tfd, filename = mkstemp('foo.ini')\n\t\ttry:\n\t\t\tpkg = os.path.splitext(filename)[0]\n\t\t\ttry:\n\t\t\t\tos.write(fd, simple_variable.encode('ascii'))\n\t\t\tfinally:\n\t\t\t\tos.close(fd)\n\n\t\t\tout = read_config(pkg)\n\t\t\tself.assertTrue(out.cflags() == simple_variable_d['cflags'])\n\t\t\tself.assertTrue(out.libs() == simple_variable_d['libflags'])\n\t\t\tself.assertTrue(out.name == simple_variable_d['name'])\n\t\t\tself.assertTrue(out.version == simple_variable_d['version'])\n\n\t\t\tout.vars['prefix'] = '/Users/david'\n\t\t\tself.assertTrue(out.cflags() == '-I/Users/david/include')\n\t\tfinally:\n\t\t\tos.remove(filename)\n", "description": null, "category": "simple", "imports": ["import os", "from tempfile import mkstemp", "from numpy.testing import *", "from numpy.distutils.npy_pkg_config import read_config, parse_flags"]}, {"term": "class", "name": "TestParseFlags", "data": "class TestParseFlags(TestCase):\n\tdef test_simple_cflags(self):\n\t\td = parse_flags(\"-I/usr/include\")\n\t\tself.assertTrue(d['include_dirs'] == ['/usr/include'])\n\n\t\td = parse_flags(\"-I/usr/include -DFOO\")\n\t\tself.assertTrue(d['include_dirs'] == ['/usr/include'])\n\t\tself.assertTrue(d['macros'] == ['FOO'])\n\n\t\td = parse_flags(\"-I /usr/include -DFOO\")\n\t\tself.assertTrue(d['include_dirs'] == ['/usr/include'])\n\t\tself.assertTrue(d['macros'] == ['FOO'])\n\n\tdef test_simple_lflags(self):\n\t\td = parse_flags(\"-L/usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tself.assertTrue(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tself.assertTrue(d['libraries'] == ['foo', 'bar'])\n\n\t\td = parse_flags(\"-L /usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tself.assertTrue(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tself.assertTrue(d['libraries'] == ['foo', 'bar'])\n", "description": null, "category": "simple", "imports": ["import os", "from tempfile import mkstemp", "from numpy.testing import *", "from numpy.distutils.npy_pkg_config import read_config, parse_flags"]}], [{"term": "def", "name": "ApTransN", "data": "def ApTransN(accur):\n\taccur = int(accur)\n\ts = []\n\tSquare = []\n\tcount = 0\n\tct = 0\n\t#The I and J for part adjacent to the runway strip.\n\tI = range(1+int(math.ceil((LatExt-(RSW/2))/(accur*(1-Slope)))))\n\tJ = range(int(1+math.ceil((RwyLen/2)/accur)))\n\tfor i in I:\n\t\tK = []\n\t\tU = []\n\t\tT = []\n\t\tfor j in J:\n\t\t\tpar  =   j*accur\n\t\t\tperp = LatExt - i*accur*(1-Slope)\n\t\t\tif par >= RwyLen/2:\n\t\t\t\tpar = RwyLen/2\n\t\t\tif perp <= RSW/2:\n\t\t\t\tperp = RSW/2\n\t\t\tZ = (NE-RED) + (par)*(SE-NE)/RwyLen + (perp-RSW/2)*Slope\n\t\t\tK.append([par,perp,Z])\n\t\t\tif perp == RSW/2:\n\t\t\t\tT.append(i)\n\t\t\tif par == RwyLen/2:\n\t\t\t\tU.append(j)\n\t\ts.append(K)\n\t\tif len(U) > 0:\n\t\t\tJ = range(U[0]+1)\n\t\tif len(T) > 0:\n\t\t\tI = range(T[0]+1)\n\n\t## I and J for the adjacent part of the approach surface.\n\tt = []\n\tSquare = []\n\tcount = 0\n\tct = 0\n\n\tD = []\n\tx = LatExt #  = perp of Outer Edge of Trans adjacent to NthTrsld\n\ty = RSW/2+(((LatExt-(RSW/2))*Slope )/.05 )* Div # = perp of TranMeetApp\n\tn1 = (x-y)/((LatExt-(RSW/2))*Slope /.05)\n\tn2 = Div\n\tI = range(1+int(math.ceil(x/(accur*(1-Slope)) )))\n\tJ = range(int(1+math.ceil(\\\n\t\t(((LatExt - RSW/2)/Div)/accur)\\\n\t\t)))\n\tfor i in I:\n\t\tK = []\n\t\tT = []\n\t\tfor j in J:\n\t\t   \n\t\t\tpar = j*accur\n\t\t\tif par >= ((LatExt - RSW/2)/Div):\n\t\t\t\tpar = ((LatExt - RSW/2)/Div)\n\t\t\tperp = x - accur*n1*j - i*(accur*(1-Slope))\n\t\t\tZ =(NE-RED) + (LatExt-(RSW/2))*Slope -  i*accur*(1-Slope)*(Slope)\n\t\t\tif perp <= (par*Div + RSW/2):\n\t\t\t\tperp = (par*Div + RSW/2)\n\t\t\t\tZ =(NE-RED) + par*0.05\n\t\t\tK.append([par,perp,Z])\n\t\t\tif perp == (par*Div + RSW/2):\n\t\t\t\tT.append(j)\n\t\tif len(T) > 0:\n\t\t\tJ = range(T[0]+1)\n\t\tt.append(K)\n\n\tF = [1,-1]\n\tfor n in range(4):\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( 'Runway: Code '+str(CN)+'\\n')\n\t\tf.write( '0\\n')\n\t\n\t\tf.write('\\n')\n\t\tf.write('\\n')\n\t\tf.write('\\n')\n\t\tf.write('\\n')\t\n\t\tf.write('#KMLStyler\\n')\n\t\tf.write('\\n')\t\t\t\t\n\t\tf.write('\\n')\n\t\tf.write('Dimensions\\n')\n\t\tf.write('-\\n')\n\t\tfor b in range(len(ToOls)):\n\t\t\tf.write(''+str(ToOls[1][b])+'\\n')\n\n\t\t\t\t\t\t\n\t\tf.write('\\n')\n\t\tf.write('\\n')\n\t\tf.write('\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tif n == 0:\n\t\t\tOlsSurf = 'NorthTransitional1'\n\t\tif n == 1:\n\t\t\tOlsSurf = 'NorthTransitional2'\n\t\tif n == 2:\n\t\t\tOlsSurf = 'NorthTransitional3'\n\t\tif n == 3:\n\t\t\tOlsSurf = 'NorthTransitional4'\n\t\tf.write( ''+OlsSurf+'\\n') \n\t\thero = []\n\t\tif n == 0 or n == 1:\n\t\t\tI = range(len(s))\n\t\tif n == 2 or n == 3:\n\t\t\tI = range(len(t))\n\t\tfor i in I:\n\t\t\tif n == 0 or n == 1:\n\t\t\t\tbip = range(len(s[i]))\n\t\t\tif n == 2 or n == 3:\n\t\t\t\tbip = range(len(t[i]))\n\t\t\tfor j in bip:\t\t\t\n\t\t\t\tif i < max(I):\n\t\t\t\t\tif n == 0 or n == 1:\n\t\t\t\t\t\tbap = (len(s[i+1])-1)\n\t\t\t\t\tif n == 2 or n == 3:\n\t\t\t\t\t\tbap = (len(t[i+1])-1)\n\t\t\t\t\tif j < bap:\n\t\t\t\t\t\tif n == 0: #adjacent to runway right\n\t\t\t\t\t\t\txx =[\n\t\t\t\t\t\t\t[s[i][j][0]*F[0],\ts[i][j][1]*F[0],\t\ts[i][j][2]],\n\t\t\t\t\t\t\t[s[i][j+1][0]*F[0],  s[i][j+1][1]*F[0],\t  s[i][j+1][2]],\n\t\t\t\t\t\t\t[s[i+1][j+1][0]*F[0],s[i+1][j+1][1]*F[0],\ts[i+1][j+1][2]],\n\t\t\t\t\t\t\t[s[i+1][j][0]*F[0],  s[i+1][j][1]*F[0],\t  s[i+1][j][2]],\n\t\t\t\t\t\t\t[s[i][j][0]*F[0],\ts[i][j][1]*F[0],\t\ts[i][j][2]]\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t\tns = 'n'\n\t\t\t\t\t\tif n == 1: #adjacent to runway left\n\t\t\t\t\t\t\txx =[\n\t\t\t\t\t\t\t[s[i][j][0]*F[0],\ts[i][j][1]*F[1],\t\ts[i][j][2]],\n\t\t\t\t\t\t\t[s[i][j+1][0]*F[0],  s[i][j+1][1]*F[1],\t  s[i][j+1][2]],\n\t\t\t\t\t\t\t[s[i+1][j+1][0]*F[0],s[i+1][j+1][1]*F[1],\ts[i+1][j+1][2]],\n\t\t\t\t\t\t\t[s[i+1][j][0]*F[0],  s[i+1][j][1]*F[1],\t  s[i+1][j][2]],\n\t\t\t\t\t\t\t[s[i][j][0]*F[0],\ts[i][j][1]*F[1],\t\ts[i][j][2]]\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t\tns = 'n'\n\t\t\t\t\t\tif n == 2: #converging parts right\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\txx =[\n\t\t\t\t\t\t\t[t[i][j][0]*F[1],\tt[i][j][1]*F[0],\t\tt[i][j][2]],\n\t\t\t\t\t\t\t[t[i][j+1][0]*F[1],  t[i][j+1][1]*F[0],\t  t[i][j+1][2]],\n\t\t\t\t\t\t\t[t[i+1][j+1][0]*F[1],t[i+1][j+1][1]*F[0],\tt[i+1][j+1][2]],\n\t\t\t\t\t\t\t[t[i+1][j][0]*F[1],  t[i+1][j][1]*F[0],\t  t[i+1][j][2]],\n\t\t\t\t\t\t\t[t[i][j][0]*F[1],\tt[i][j][1]*F[0],\t\tt[i][j][2]]\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t\tns = 'n'\n\t\t\t\t\t\tif n == 3:#converging parts left\n\t\t\t\t\t\t\txx =[\n\t\t\t\t\t\t\t[t[i][j][0]*F[1],\tt[i][j][1]*F[1],\t\tt[i][j][2]],\n\t\t\t\t\t\t\t[t[i][j+1][0]*F[1],  t[i][j+1][1]*F[1],\t  t[i][j+1][2]],\n\t\t\t\t\t\t\t[t[i+1][j+1][0]*F[1],t[i+1][j+1][1]*F[1],\tt[i+1][j+1][2]],\n\t\t\t\t\t\t\t[t[i+1][j][0]*F[1],  t[i+1][j][1]*F[1],\t  t[i+1][j][2]],\n\t\t\t\t\t\t\t[t[i][j][0]*F[1],\tt[i][j][1]*F[1],\t\tt[i][j][2]]\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t\tns = 'n'\n\t\t\t\t\t\tf.write(   \"\\n\")\n\t\t\t\t\t\tf.write(   \"n=\"+str(n)+\" i=\"+str(i)+\" j=\"+str(j)+\"\\n\")  \n\t\t\t\t\t\tf.write(   \"#m_ylw-pushpin\\n\")\n\t\t\t\t\t\t##extended data\n\t\t\t\t\t\tH = []\n\t\t\t\t\t\tfor h in range(len(xx)):\n\t\t\t\t\t\t\te = RED+xx[h][2]\n\t\t\t\t\t\t\tUtm = mdl.toUTM(NTE,NTN,STE,STN,ARP,SE,NE,xx[h][0],xx[h][1],xx[h][2],ns)\n\t\t\t\t\t\t\tWgs = list(mdl.U_W(Utm[0],Utm[1],zone, e))\n\t\t\t\t\t\t\tH.append(Wgs[2])\n\t\t\t\t\t\tHn = min(H)\n\t\t\t\t\t\tHm = max(H)\n\t\t\t\t\t\tf.write(   \"\")\n\t\t\t\t\t\tf.write(   '')\n\t\t\t\t\t\tf.write(   ''+OlsSurf+'')\n\t\t\t\t\t\tf.write(   ''+str(Hn)+'')\n\t\t\t\t\t\tf.write(   ''+str(Hm)+'')\n\t\t\t\t\t\tf.write(   '')\t\n\t\t\t\t\t\tf.write(   \"\")\n\t\t\t\t\t\tf.write(   \"\\n\")\n\t\t\t\t\t\tf.write(   \"absolute\\n\")\n\t\t\t\t\t\tf.write(   \"\\n\")\n\t\t\t\t\t\tf.write(   \"\\n\")\n\t\t\t\t\t\tf.write(   \"\\n\")\n\t\t\t\t\t\tfor h in range(len(xx)):\n\t\t\t\t\t\t\te = RED+xx[h][2]\n\t\t\t\t\t\t\tUtm = mdl.toUTM(NTE,NTN,STE,STN,ARP,SE,NE,xx[h][0],xx[h][1],xx[h][2],ns)\n\t\t\t\t\t\t\tWgs = list(mdl.U_W(Utm[0],Utm[1],zone, e))\n\t\t\t\t\t\t\tf.write(str(Wgs[0])+\",\"+str(Wgs[1])+\",\"+str(Wgs[2]))\n\t\t\t\t\t\t\tf.write(   \"\\n\")\n\t\t\t\t\t\tf.write(   \"\\n\")\n\t\t\t\t\t\tf.write(   \"\\n\")\n\t\t\t\t\t\tf.write(   \"\\n\"\t)\t\n\t\t\t\t\t\tf.write(   \"\\n\"\t)\t\t\n\t\t\t\t\t\tf.write(   \"\\n\")\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\t\t\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n", "description": null, "category": "simple", "imports": ["import math", "import OLSDims", "import mdl", "import EnvSettings", "from osgeo import osr"]}, {"term": "def", "name": "ApTransS", "data": "def ApTransS(accur):\n\taccur = int(accur)\n\ts = []\n\tSquare = []\n\tcount = 0\n\tct = 0\n\t#The I and J for part adjacent to the runway strip.\n\tI = range(1+int(math.ceil((LatExt-(RSW/2))/(accur*(1-Slope)))))\n\tJ = range(int(1+math.ceil((RwyLen/2)/accur)))\n\tfor i in I:\n\t\tK = []\n\t\tU = []\n\t\tT = []\n\t\tfor j in J:\n\t\t\tpar  =   j*accur\n\t\t\tperp = LatExt - i*accur*(1-Slope)\n\t\t\tif par >= RwyLen/2:\n\t\t\t\tpar = RwyLen/2\n\t\t\tif perp <= RSW/2:\n\t\t\t\tperp = RSW/2\n\t\t\tZ = (SE-RED) + (par)*(NE-SE)/RwyLen + (perp-RSW/2)*Slope\n\t\t\tK.append([par,perp,Z])\n\t\t\tif perp == RSW/2:\n\t\t\t\tT.append(i)\n\t\t\tif par == RwyLen/2:\n\t\t\t\tU.append(j)\n\t\ts.append(K)\n\t\tif len(U) > 0:\n\t\t\tJ = range(U[0]+1)\n\t\tif len(T) > 0:\n\t\t\tI = range(T[0]+1)\n\n\t## I and J for the adjacent part of the approach surface.\n\tt = []\n\tSquare = []\n\tcount = 0\n\tct = 0\n\n\tD = []\n\tx = LatExt #  = perp of Outer Edge of Trans adjacent to NthTrsld\n\ty = RSW/2+(((LatExt-(RSW/2))*Slope )/.05 )* Div # = perp of TranMeetApp\n\tn1 = (x-y)/((LatExt-(RSW/2))*Slope /.05)\n\tn2 = Div\n\tI = range(1+int(math.ceil(x/(accur*(1-Slope)) )))\n\tJ = range(int(1+math.ceil(\\\n\t\t(((LatExt - RSW/2)/Div)/accur)\\\n\t\t)))\n\tfor i in I:\n\t\tK = []\n\t\tT = []\n\t\tfor j in J:\n\t\t   \n\t\t\tpar = j*accur\n\t\t\tif par >= ((LatExt - RSW/2)/Div):\n\t\t\t\tpar = ((LatExt - RSW/2)/Div)\n\t\t\tperp = x - accur*n1*j - i*(accur*(1-Slope))\n\t\t\tZ =(SE-RED) + (LatExt-(RSW/2))*Slope -  i*accur*(1-Slope)*(Slope)\n\t\t\tif perp <= (par*Div + RSW/2):\n\t\t\t\tperp = (par*Div + RSW/2)\n\t\t\t\tZ =(SE-RED) + par*0.05\n\t\t\tK.append([par,perp,Z])\n\t\t\tif perp == (par*Div + RSW/2):\n\t\t\t\tT.append(j)\n\t\tif len(T) > 0:\n\t\t\tJ = range(T[0]+1)\n\t\tt.append(K)\n\n\tF = [1,-1]\n\tfor n in range(4):\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( 'Runway: Code '+str(CN)+'\\n')\n\t\tf.write( '0\\n')\n\t\n\t\tf.write('\\n')\n\t\tf.write('\\n')\n\t\tf.write('\\n')\n\t\tf.write('\\n')\t\n\t\tf.write('#KMLStyler\\n')\n\t\tf.write('\\n')\t\t\t\t\n\t\tf.write('\\n')\n\t\tf.write('Dimensions\\n')\n\t\tf.write('-\\n')\n\t\tfor b in range(len(ToOls)):\n\t\t\tf.write(''+str(ToOls[1][b])+'\\n')\n\n\t\t\t\t\t\t\n\t\tf.write('\\n')\n\t\tf.write('\\n')\n\t\tf.write('\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tif n == 0:\n\t\t\tOlsSurf = 'NorthTransitional1'\n\t\tif n == 1:\n\t\t\tOlsSurf = 'NorthTransitional2'\n\t\tif n == 2:\n\t\t\tOlsSurf = 'NorthTransitional3'\n\t\tif n == 3:\n\t\t\tOlsSurf = 'NorthTransitional4'\n\t\tf.write( ''+OlsSurf+'\\n') \n\t\thero = []\n\t\tif n == 0 or n == 1:\n\t\t\tI = range(len(s))\n\t\tif n == 2 or n == 3:\n\t\t\tI = range(len(t))\n\t\tfor i in I:\n\t\t\tif n == 0 or n == 1:\n\t\t\t\tbip = range(len(s[i]))\n\t\t\tif n == 2 or n == 3:\n\t\t\t\tbip = range(len(t[i]))\n\t\t\tfor j in bip:\t\t\t\n\t\t\t\tif i < max(I):\n\t\t\t\t\tif n == 0 or n == 1:\n\t\t\t\t\t\tbap = (len(s[i+1])-1)\n\t\t\t\t\tif n == 2 or n == 3:\n\t\t\t\t\t\tbap = (len(t[i+1])-1)\n\t\t\t\t\tif j < bap:\n\t\t\t\t\t\tif n == 0: #adjacent to runway right\n\t\t\t\t\t\t\txx =[\n\t\t\t\t\t\t\t[s[i][j][0]*F[0],\ts[i][j][1]*F[0],\t\ts[i][j][2]],\n\t\t\t\t\t\t\t[s[i][j+1][0]*F[0],  s[i][j+1][1]*F[0],\t  s[i][j+1][2]],\n\t\t\t\t\t\t\t[s[i+1][j+1][0]*F[0],s[i+1][j+1][1]*F[0],\ts[i+1][j+1][2]],\n\t\t\t\t\t\t\t[s[i+1][j][0]*F[0],  s[i+1][j][1]*F[0],\t  s[i+1][j][2]],\n\t\t\t\t\t\t\t[s[i][j][0]*F[0],\ts[i][j][1]*F[0],\t\ts[i][j][2]]\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t\tns = 's'\n\t\t\t\t\t\tif n == 1: #adjacent to runway left\n\t\t\t\t\t\t\txx =[\n\t\t\t\t\t\t\t[s[i][j][0]*F[0],\ts[i][j][1]*F[1],\t\ts[i][j][2]],\n\t\t\t\t\t\t\t[s[i][j+1][0]*F[0],  s[i][j+1][1]*F[1],\t  s[i][j+1][2]],\n\t\t\t\t\t\t\t[s[i+1][j+1][0]*F[0],s[i+1][j+1][1]*F[1],\ts[i+1][j+1][2]],\n\t\t\t\t\t\t\t[s[i+1][j][0]*F[0],  s[i+1][j][1]*F[1],\t  s[i+1][j][2]],\n\t\t\t\t\t\t\t[s[i][j][0]*F[0],\ts[i][j][1]*F[1],\t\ts[i][j][2]]\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t\tns = 's'\n\t\t\t\t\t\tif n == 2: #converging parts right\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\txx =[\n\t\t\t\t\t\t\t[t[i][j][0]*F[1],\tt[i][j][1]*F[0],\t\tt[i][j][2]],\n\t\t\t\t\t\t\t[t[i][j+1][0]*F[1],  t[i][j+1][1]*F[0],\t  t[i][j+1][2]],\n\t\t\t\t\t\t\t[t[i+1][j+1][0]*F[1],t[i+1][j+1][1]*F[0],\tt[i+1][j+1][2]],\n\t\t\t\t\t\t\t[t[i+1][j][0]*F[1],  t[i+1][j][1]*F[0],\t  t[i+1][j][2]],\n\t\t\t\t\t\t\t[t[i][j][0]*F[1],\tt[i][j][1]*F[0],\t\tt[i][j][2]]\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t\tns = 's'\n\t\t\t\t\t\tif n == 3:#converging parts left\n\t\t\t\t\t\t\txx =[\n\t\t\t\t\t\t\t[t[i][j][0]*F[1],\tt[i][j][1]*F[1],\t\tt[i][j][2]],\n\t\t\t\t\t\t\t[t[i][j+1][0]*F[1],  t[i][j+1][1]*F[1],\t  t[i][j+1][2]],\n\t\t\t\t\t\t\t[t[i+1][j+1][0]*F[1],t[i+1][j+1][1]*F[1],\tt[i+1][j+1][2]],\n\t\t\t\t\t\t\t[t[i+1][j][0]*F[1],  t[i+1][j][1]*F[1],\t  t[i+1][j][2]],\n\t\t\t\t\t\t\t[t[i][j][0]*F[1],\tt[i][j][1]*F[1],\t\tt[i][j][2]]\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t\tns = 's'\n\t\t\t\t\t\tf.write(   \"\\n\")\n\t\t\t\t\t\tf.write(   \"n=\"+str(n)+\" i=\"+str(i)+\" j=\"+str(j)+\"\\n\")  \n\t\t\t\t\t\tf.write(   \"#m_ylw-pushpin\\n\")\n\t\t\t\t\t\t##extended data\n\t\t\t\t\t\tH = []\n\t\t\t\t\t\tfor h in range(len(xx)):\n\t\t\t\t\t\t\te = RED+xx[h][2]\n\t\t\t\t\t\t\tUtm = mdl.toUTM(NTE,NTN,STE,STN,ARP,SE,NE,xx[h][0],xx[h][1],xx[h][2],ns)\n\t\t\t\t\t\t\tWgs = list(mdl.U_W(Utm[0],Utm[1],zone, e))\n\t\t\t\t\t\t\tH.append(Wgs[2])\n\t\t\t\t\t\tHn = min(H)\n\t\t\t\t\t\tHm = max(H)\n\t\t\t\t\t\tf.write(   \"\")\n\t\t\t\t\t\tf.write(   '')\n\t\t\t\t\t\tf.write(   ''+OlsSurf+'')\n\t\t\t\t\t\tf.write(   ''+str(Hn)+'')\n\t\t\t\t\t\tf.write(   ''+str(Hm)+'')\n\t\t\t\t\t\tf.write(   '')\t\n\t\t\t\t\t\tf.write(   \"\")\n\t\t\t\t\t\tf.write(   \"\\n\")\n\t\t\t\t\t\tf.write(   \"absolute\\n\")\n\t\t\t\t\t\tf.write(   \"\\n\")\n\t\t\t\t\t\tf.write(   \"\\n\")\n\t\t\t\t\t\tf.write(   \"\\n\")\n\t\t\t\t\t\tfor h in range(len(xx)):\n\t\t\t\t\t\t\te = RED+xx[h][2]\n\t\t\t\t\t\t\tUtm = mdl.toUTM(NTE,NTN,STE,STN,ARP,SE,NE,xx[h][0],xx[h][1],xx[h][2],ns)\n\t\t\t\t\t\t\tWgs = list(mdl.U_W(Utm[0],Utm[1],zone, e))\n\t\t\t\t\t\t\tf.write(str(Wgs[0])+\",\"+str(Wgs[1])+\",\"+str(Wgs[2]))\n\t\t\t\t\t\t\tf.write(   \"\\n\")\n\t\t\t\t\t\tf.write(   \"\\n\")\n\t\t\t\t\t\tf.write(   \"\\n\")\n\t\t\t\t\t\tf.write(   \"\\n\"\t)\t\n\t\t\t\t\t\tf.write(   \"\\n\"\t)\t\t\n\t\t\t\t\t\tf.write(   \"\\n\")\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\t\t\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n\t\tf.write( '\\n')\n", "description": null, "category": "simple", "imports": ["import math", "import OLSDims", "import mdl", "import EnvSettings", "from osgeo import osr"]}], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [{"term": "def", "name": "get_preprocessor_by_name", "data": "def get_preprocessor_by_name(preprocessor_name):\n\treturn PREPROCESSORS_REGISTRY[preprocessor_name]\n\n", "description": null, "category": "simple", "imports": ["from abc import ABC", "from functools import wraps, lru_cache", "import hashlib", "from pathlib import Path", "import dill as pickle", "import re", "import shutil", "from nevergrad.instrumentation import var", "import numpy as np", "import sentencepiece as spm", "from access.feature_extraction import (get_lexical_complexity_score, get_levenshtein_similarity,", "from access.resources.paths import VARIOUS_DIR, get_data_filepath", "from access.utils.helpers import (write_lines_in_parallel, yield_lines_in_parallel, add_dicts, get_default_args,"]}, {"term": "def", "name": "get_preprocessors", "data": "def get_preprocessors(preprocessor_kwargs):\n\tpreprocessors = []\n\tfor preprocessor_name, kwargs in preprocessor_kwargs.items():\n\t\tpreprocessors.append(get_preprocessor_by_name(preprocessor_name)(**kwargs))\n\treturn preprocessors\n\n", "description": null, "category": "simple", "imports": ["from abc import ABC", "from functools import wraps, lru_cache", "import hashlib", "from pathlib import Path", "import dill as pickle", "import re", "import shutil", "from nevergrad.instrumentation import var", "import numpy as np", "import sentencepiece as spm", "from access.feature_extraction import (get_lexical_complexity_score, get_levenshtein_similarity,", "from access.resources.paths import VARIOUS_DIR, get_data_filepath", "from access.utils.helpers import (write_lines_in_parallel, yield_lines_in_parallel, add_dicts, get_default_args,"]}, {"term": "def", "name": "extract_special_tokens", "data": "def extract_special_tokens(sentence):\n\t'''Remove any number of token at the beginning of the sentence'''\n\tmatch = re.match(fr'(^(?:{SPECIAL_TOKEN_REGEX} *)+) *(.*)$', sentence)\n\tif match is None:\n\t\treturn '', sentence\n\tspecial_tokens, sentence = match.groups()\n\treturn special_tokens.strip(), sentence\n\n", "description": null, "category": "simple", "imports": ["from abc import ABC", "from functools import wraps, lru_cache", "import hashlib", "from pathlib import Path", "import dill as pickle", "import re", "import shutil", "from nevergrad.instrumentation import var", "import numpy as np", "import sentencepiece as spm", "from access.feature_extraction import (get_lexical_complexity_score, get_levenshtein_similarity,", "from access.resources.paths import VARIOUS_DIR, get_data_filepath", "from access.utils.helpers import (write_lines_in_parallel, yield_lines_in_parallel, add_dicts, get_default_args,"]}, {"term": "def", "name": "remove_special_tokens", "data": "def remove_special_tokens(sentence):\n\treturn extract_special_tokens(sentence)[1]\n\n", "description": null, "category": "simple", "imports": ["from abc import ABC", "from functools import wraps, lru_cache", "import hashlib", "from pathlib import Path", "import dill as pickle", "import re", "import shutil", "from nevergrad.instrumentation import var", "import numpy as np", "import sentencepiece as spm", "from access.feature_extraction import (get_lexical_complexity_score, get_levenshtein_similarity,", "from access.resources.paths import VARIOUS_DIR, get_data_filepath", "from access.utils.helpers import (write_lines_in_parallel, yield_lines_in_parallel, add_dicts, get_default_args,"]}, {"term": "def", "name": "store_args", "data": "def store_args(constructor):\n\t@wraps(constructor)\n\tdef wrapped(self, *args, **kwargs):\n\t\tif not hasattr(self, 'args') or not hasattr(self, 'kwargs'):\n\t\t\t# TODO: Default args are not overwritten if provided as args\n\t\t\tself.args = args\n\t\t\tself.kwargs = add_dicts(get_default_args(constructor), kwargs)\n\t\treturn constructor(self, *args, **kwargs)\n\n\treturn wrapped\n\n", "description": null, "category": "simple", "imports": ["from abc import ABC", "from functools import wraps, lru_cache", "import hashlib", "from pathlib import Path", "import dill as pickle", "import re", "import shutil", "from nevergrad.instrumentation import var", "import numpy as np", "import sentencepiece as spm", "from access.feature_extraction import (get_lexical_complexity_score, get_levenshtein_similarity,", "from access.resources.paths import VARIOUS_DIR, get_data_filepath", "from access.utils.helpers import (write_lines_in_parallel, yield_lines_in_parallel, add_dicts, get_default_args,"]}, {"term": "def", "name": "dump_preprocessors", "data": "def dump_preprocessors(preprocessors, dir_path):\n\twith open(Path(dir_path) / 'preprocessors.pickle', 'wb') as f:\n\t\tpickle.dump(preprocessors, f)\n\n", "description": null, "category": "simple", "imports": ["from abc import ABC", "from functools import wraps, lru_cache", "import hashlib", "from pathlib import Path", "import dill as pickle", "import re", "import shutil", "from nevergrad.instrumentation import var", "import numpy as np", "import sentencepiece as spm", "from access.feature_extraction import (get_lexical_complexity_score, get_levenshtein_similarity,", "from access.resources.paths import VARIOUS_DIR, get_data_filepath", "from access.utils.helpers import (write_lines_in_parallel, yield_lines_in_parallel, add_dicts, get_default_args,"]}, {"term": "def", "name": "load_preprocessors", "data": "def load_preprocessors(dir_path):\n\tpath = Path(dir_path) / 'preprocessors.pickle'\n\tif not path.exists():\n\t\treturn None\n\twith open(path, 'rb') as f:\n\t\treturn pickle.load(f)\n\n", "description": null, "category": "simple", "imports": ["from abc import ABC", "from functools import wraps, lru_cache", "import hashlib", "from pathlib import Path", "import dill as pickle", "import re", "import shutil", "from nevergrad.instrumentation import var", "import numpy as np", "import sentencepiece as spm", "from access.feature_extraction import (get_lexical_complexity_score, get_levenshtein_similarity,", "from access.resources.paths import VARIOUS_DIR, get_data_filepath", "from access.utils.helpers import (write_lines_in_parallel, yield_lines_in_parallel, add_dicts, get_default_args,"]}, {"term": "class", "name": "AbstractPreprocessor", "data": "class AbstractPreprocessor(ABC):\n\tdef __init_subclass__(cls, **kwargs):\n\t\t'''Register all children in registry'''\n\t\tsuper().__init_subclass__(**kwargs)\n\t\tPREPROCESSORS_REGISTRY[cls.__name__] = cls\n\n\tdef __repr__(self):\n\t\targs = getattr(self, 'args', ())\n\t\tkwargs = getattr(self, 'kwargs', {})\n\t\targs_repr = [repr(arg) for arg in args]\n\t\tkwargs_repr = [f'{k}={repr(v)}' for k, v in sorted(kwargs.items(), key=lambda kv: kv[0])]\n\t\targs_kwargs_str = ', '.join(args_repr + kwargs_repr)\n\t\treturn f'{self.__class__.__name__}({args_kwargs_str})'\n\n\tdef get_hash_string(self):\n\t\treturn self.__class__.__name__\n\n\tdef get_hash(self):\n\t\treturn hashlib.md5(self.get_hash_string().encode()).hexdigest()\n\n\tdef get_nevergrad_variables(self):\n\t\treturn {}\n\n\t@property\n\tdef prefix(self):\n\t\treturn self.__class__.__name__.replace('Preprocessor', '')\n\n\tdef fit(self, complex_filepath, simple_filepath):\n\t\tpass\n\n\tdef encode_sentence(self, sentence, encoder_sentence=None):\n\t\traise NotImplementedError\n\n\tdef decode_sentence(self, sentence, encoder_sentence=None):\n\t\traise NotImplementedError\n\n\tdef encode_sentence_pair(self, complex_sentence, simple_sentence):\n\t\tif complex_sentence is not None:\n\t\t\tcomplex_sentence = self.encode_sentence(complex_sentence)\n\t\tif simple_sentence is not None:\n\t\t\tsimple_sentence = self.encode_sentence(simple_sentence)\n\t\treturn complex_sentence, simple_sentence\n\n\tdef encode_file(self, input_filepath, output_filepath, encoder_filepath=None):\n\t\tif encoder_filepath is None:\n\t\t\t# We will use an empty temporary file which will yield None for each line\n\t\t\tencoder_filepath = get_temp_filepath(create=True)\n\t\twith open(output_filepath, 'w') as f:\n\t\t\tfor input_line, encoder_line in yield_lines_in_parallel([input_filepath, encoder_filepath], strict=False):\n\t\t\t\tf.write(self.encode_sentence(input_line, encoder_line) + '\\n')\n\n\tdef decode_file(self, input_filepath, output_filepath, encoder_filepath=None):\n\t\tif encoder_filepath is None:\n\t\t\t# We will use an empty temporary file which will yield None for each line\n\t\t\tencoder_filepath = get_temp_filepath(create=True)\n\t\twith open(output_filepath, 'w') as f:\n\t\t\tfor encoder_sentence, input_sentence in yield_lines_in_parallel([encoder_filepath, input_filepath],\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tstrict=False):\n\t\t\t\tdecoded_sentence = self.decode_sentence(input_sentence, encoder_sentence=encoder_sentence)\n\t\t\t\tf.write(decoded_sentence + '\\n')\n\n\tdef encode_file_pair(self, complex_filepath, simple_filepath, output_complex_filepath, output_simple_filepath):\n\t\t'''Jointly encode a complex file and a simple file (can be aligned or not)'''\n\t\twith write_lines_in_parallel([output_complex_filepath, output_simple_filepath], strict=False) as output_files:\n\t\t\tfor complex_line, simple_line in yield_lines_in_parallel([complex_filepath, simple_filepath], strict=False):\n\t\t\t\toutput_files.write(self.encode_sentence_pair(complex_line, simple_line))\n\n", "description": null, "category": "simple", "imports": ["from abc import ABC", "from functools import wraps, lru_cache", "import hashlib", "from pathlib import Path", "import dill as pickle", "import re", "import shutil", "from nevergrad.instrumentation import var", "import numpy as np", "import sentencepiece as spm", "from access.feature_extraction import (get_lexical_complexity_score, get_levenshtein_similarity,", "from access.resources.paths import VARIOUS_DIR, get_data_filepath", "from access.utils.helpers import (write_lines_in_parallel, yield_lines_in_parallel, add_dicts, get_default_args,"]}, {"term": "class", "name": "ComposedPreprocessor", "data": "class ComposedPreprocessor(AbstractPreprocessor):\n\t@store_args\n\tdef __init__(self, preprocessors, sort=False):\n\t\tif preprocessors is None:\n\t\t\tpreprocessors = []\n\t\tif sort:\n\t\t\t# Make sure preprocessors are always in the same order\n\t\t\tpreprocessors = sorted(preprocessors, key=lambda preprocessor: preprocessor.__class__.__name__)\n\t\tself.preprocessors = preprocessors\n\n\tdef get_hash_string(self):\n\t\tpreprocessors_hash_strings = [preprocessor.get_hash_string() for preprocessor in self.preprocessors]\n\t\treturn f'ComposedPreprocessor(preprocessors={preprocessors_hash_strings})'\n\n\tdef get_suffix(self):\n\t\treturn '_'.join([p.prefix.lower() for p in self.preprocessors])\n\n\tdef fit(self, complex_filepath, simple_filepath):\n\t\tfor preprocessor in self.preprocessors:\n\t\t\tpass\n\n\tdef encode_sentence(self, sentence, encoder_sentence=None):\n\t\tfor preprocessor in self.preprocessors:\n\t\t\tsentence = preprocessor.encode_sentence(sentence, encoder_sentence)\n\t\treturn sentence\n\n\tdef decode_sentence(self, sentence, encoder_sentence=None):\n\t\tfor preprocessor in self.preprocessors:\n\t\t\tsentence = preprocessor.decode_sentence(sentence, encoder_sentence)\n\t\treturn sentence\n\n\tdef encode_file(self, input_filepath, output_filepath, encoder_filepath=None):\n\t\tfor preprocessor in self.preprocessors:\n\t\t\tintermediary_output_filepath = get_temp_filepath()\n\t\t\tpreprocessor.encode_file(input_filepath, intermediary_output_filepath, encoder_filepath)\n\t\t\tinput_filepath = intermediary_output_filepath\n\t\tshutil.copyfile(input_filepath, output_filepath)\n\n\tdef decode_file(self, input_filepath, output_filepath, encoder_filepath=None):\n\t\tfor preprocessor in self.preprocessors:\n\t\t\tintermediary_output_filepath = get_temp_filepath()\n\t\t\tpreprocessor.decode_file(input_filepath, intermediary_output_filepath, encoder_filepath)\n\t\t\tinput_filepath = intermediary_output_filepath\n\t\tshutil.copyfile(input_filepath, output_filepath)\n\n\tdef encode_file_pair(self, complex_filepath, simple_filepath, output_complex_filepath, output_simple_filepath):\n\t\tfor preprocessor in self.preprocessors:\n\t\t\tintermediary_output_complex_filepath = get_temp_filepath()\n\t\t\tintermediary_output_simple_filepath = get_temp_filepath()\n\t\t\tpreprocessor.encode_file_pair(complex_filepath, simple_filepath, intermediary_output_complex_filepath,\n\t\t\t\t\t\t\t\t\t\t  intermediary_output_simple_filepath)\n\t\t\tcomplex_filepath = intermediary_output_complex_filepath\n\t\t\tsimple_filepath = intermediary_output_simple_filepath\n\t\tshutil.copyfile(complex_filepath, output_complex_filepath)\n\t\tshutil.copyfile(simple_filepath, output_simple_filepath)\n\n\tdef encode_sentence_pair(self, complex_sentence, simple_sentence):\n\t\tfor preprocessor in self.preprocessors:\n\t\t\tcomplex_sentence, simple_sentence = preprocessor.encode_sentence_pair(complex_sentence, simple_sentence)\n\t\treturn complex_sentence, simple_sentence\n\n", "description": null, "category": "simple", "imports": ["from abc import ABC", "from functools import wraps, lru_cache", "import hashlib", "from pathlib import Path", "import dill as pickle", "import re", "import shutil", "from nevergrad.instrumentation import var", "import numpy as np", "import sentencepiece as spm", "from access.feature_extraction import (get_lexical_complexity_score, get_levenshtein_similarity,", "from access.resources.paths import VARIOUS_DIR, get_data_filepath", "from access.utils.helpers import (write_lines_in_parallel, yield_lines_in_parallel, add_dicts, get_default_args,"]}, {"term": "class", "name": "FeaturePreprocessor", "data": "class FeaturePreprocessor(AbstractPreprocessor):\n\t'''Prepend a computed feature at the beginning of the sentence'''\n\t@store_args\n\tdef __init__(self, feature_name, get_feature_value, get_target_feature_value, bucket_size=0.05, noise_std=0):\n\t\tself.get_feature_value = get_feature_value\n\t\tself.get_target_feature_value = get_target_feature_value\n\t\tself.bucket_size = bucket_size\n\t\tself.noise_std = noise_std\n\t\tself.feature_name = feature_name.upper()\n\n\tdef get_hash_string(self):\n\t\treturn (f'{self.__class__.__name__}(feature_name={repr(self.feature_name)}, bucket_size={self.bucket_size},'\n\t\t\t\tf'noise_std={self.noise_std})')\n\n\tdef bucketize(self, value):\n\t\t'''Round value to bucket_size to reduce the number of different values'''\n\t\treturn round(round(value / self.bucket_size) * self.bucket_size, 10)\n\n\tdef add_noise(self, value):\n\t\treturn value + np.random.normal(0, self.noise_std)\n\n\tdef get_feature_token(self, feature_value):\n\t\treturn f'<{self.feature_name}_{feature_value}>'\n\n\tdef encode_sentence(self, sentence, encoder_sentence=None):\n\t\tdesired_feature = self.bucketize(self.get_target_feature_value(remove_special_tokens(sentence)))\n\t\treturn f'{self.get_feature_token(desired_feature)} {sentence}'\n\n\tdef decode_sentence(self, sentence, encoder_sentence=None):\n\t\treturn sentence\n\n\tdef encode_sentence_pair(self, complex_sentence, simple_sentence):\n\t\tfeature = self.bucketize(\n\t\t\tself.add_noise(\n\t\t\t\tself.get_feature_value(remove_special_tokens(complex_sentence),\n\t\t\t\t\t\t\t\t\t   remove_special_tokens(simple_sentence))))\n\t\treturn f'{self.get_feature_token(feature)} {complex_sentence}', simple_sentence\n\n", "description": null, "category": "simple", "imports": ["from abc import ABC", "from functools import wraps, lru_cache", "import hashlib", "from pathlib import Path", "import dill as pickle", "import re", "import shutil", "from nevergrad.instrumentation import var", "import numpy as np", "import sentencepiece as spm", "from access.feature_extraction import (get_lexical_complexity_score, get_levenshtein_similarity,", "from access.resources.paths import VARIOUS_DIR, get_data_filepath", "from access.utils.helpers import (write_lines_in_parallel, yield_lines_in_parallel, add_dicts, get_default_args,"]}, {"term": "class", "name": "LevenshteinPreprocessor", "data": "class LevenshteinPreprocessor(FeaturePreprocessor):\n\t@store_args\n\tdef __init__(self, target_ratio=0.8, bucket_size=0.05, noise_std=0):\n\t\tself.target_ratio = target_ratio\n\t\tsuper().__init__(self.prefix.upper(), self.get_feature_value, self.get_target_feature_value, bucket_size,\n\t\t\t\t\t\t noise_std)\n\n\tdef get_nevergrad_variables(self):\n\t\treturn {'target_ratio': var.OrderedDiscrete(np.arange(0.4, 1 + 1e-6, self.bucket_size))}\n\n\tdef get_feature_value(self, complex_sentence, simple_sentence):\n\t\treturn get_levenshtein_similarity(complex_sentence, simple_sentence)\n\n\tdef get_target_feature_value(self, complex_sentence):\n\t\treturn self.target_ratio\n\n", "description": null, "category": "simple", "imports": ["from abc import ABC", "from functools import wraps, lru_cache", "import hashlib", "from pathlib import Path", "import dill as pickle", "import re", "import shutil", "from nevergrad.instrumentation import var", "import numpy as np", "import sentencepiece as spm", "from access.feature_extraction import (get_lexical_complexity_score, get_levenshtein_similarity,", "from access.resources.paths import VARIOUS_DIR, get_data_filepath", "from access.utils.helpers import (write_lines_in_parallel, yield_lines_in_parallel, add_dicts, get_default_args,"]}, {"term": "class", "name": "RatioPreprocessor", "data": "class RatioPreprocessor(FeaturePreprocessor):\n\t@store_args\n\tdef __init__(self, feature_extractor, target_ratio=0.8, bucket_size=0.05, noise_std=0):\n\t\tself.feature_extractor = feature_extractor\n\t\tself.target_ratio = target_ratio\n\t\tsuper().__init__(self.prefix.upper(), self.get_feature_value, self.get_target_feature_value, bucket_size,\n\t\t\t\t\t\t noise_std)\n\n\tdef get_nevergrad_variables(self):\n\t\treturn {'target_ratio': var.OrderedDiscrete(np.arange(0.4, 1.4 + 1e-6, self.bucket_size))}\n\n\tdef get_feature_value(self, complex_sentence, simple_sentence):\n\t\treturn min(safe_division(self.feature_extractor(simple_sentence), self.feature_extractor(complex_sentence)), 2)\n\n\tdef get_target_feature_value(self, complex_sentence):\n\t\treturn self.target_ratio\n\n", "description": null, "category": "simple", "imports": ["from abc import ABC", "from functools import wraps, lru_cache", "import hashlib", "from pathlib import Path", "import dill as pickle", "import re", "import shutil", "from nevergrad.instrumentation import var", "import numpy as np", "import sentencepiece as spm", "from access.feature_extraction import (get_lexical_complexity_score, get_levenshtein_similarity,", "from access.resources.paths import VARIOUS_DIR, get_data_filepath", "from access.utils.helpers import (write_lines_in_parallel, yield_lines_in_parallel, add_dicts, get_default_args,"]}, {"term": "class", "name": "LengthRatioPreprocessor", "data": "class LengthRatioPreprocessor(RatioPreprocessor):\n\t@store_args\n\tdef __init__(self, *args, **kwargs):\n\t\tsuper().__init__(len, *args, **kwargs)\n\n", "description": null, "category": "simple", "imports": ["from abc import ABC", "from functools import wraps, lru_cache", "import hashlib", "from pathlib import Path", "import dill as pickle", "import re", "import shutil", "from nevergrad.instrumentation import var", "import numpy as np", "import sentencepiece as spm", "from access.feature_extraction import (get_lexical_complexity_score, get_levenshtein_similarity,", "from access.resources.paths import VARIOUS_DIR, get_data_filepath", "from access.utils.helpers import (write_lines_in_parallel, yield_lines_in_parallel, add_dicts, get_default_args,"]}, {"term": "class", "name": "WordRankRatioPreprocessor", "data": "class WordRankRatioPreprocessor(RatioPreprocessor):\n\t@store_args\n\tdef __init__(self, *args, **kwargs):\n\t\tsuper().__init__(get_lexical_complexity_score, *args, **kwargs)\n\n", "description": null, "category": "simple", "imports": ["from abc import ABC", "from functools import wraps, lru_cache", "import hashlib", "from pathlib import Path", "import dill as pickle", "import re", "import shutil", "from nevergrad.instrumentation import var", "import numpy as np", "import sentencepiece as spm", "from access.feature_extraction import (get_lexical_complexity_score, get_levenshtein_similarity,", "from access.resources.paths import VARIOUS_DIR, get_data_filepath", "from access.utils.helpers import (write_lines_in_parallel, yield_lines_in_parallel, add_dicts, get_default_args,"]}, {"term": "class", "name": "DependencyTreeDepthRatioPreprocessor", "data": "class DependencyTreeDepthRatioPreprocessor(RatioPreprocessor):\n\t@store_args\n\tdef __init__(self, *args, **kwargs):\n\t\tsuper().__init__(get_dependency_tree_depth, *args, **kwargs)\n\n", "description": null, "category": "simple", "imports": ["from abc import ABC", "from functools import wraps, lru_cache", "import hashlib", "from pathlib import Path", "import dill as pickle", "import re", "import shutil", "from nevergrad.instrumentation import var", "import numpy as np", "import sentencepiece as spm", "from access.feature_extraction import (get_lexical_complexity_score, get_levenshtein_similarity,", "from access.resources.paths import VARIOUS_DIR, get_data_filepath", "from access.utils.helpers import (write_lines_in_parallel, yield_lines_in_parallel, add_dicts, get_default_args,"]}, {"term": "class", "name": "SentencePiecePreprocessor", "data": "class SentencePiecePreprocessor(AbstractPreprocessor):\n\t@store_args\n\tdef __init__(self, vocab_size=10000, input_filepaths=None):\n\t\tself.vocab_size = vocab_size\n\t\tself.sentencepiece_model_path = VARIOUS_DIR / f'sentencepiece_model/sentencepiece_model_{self.vocab_size}.model'\n\t\tself.input_filepaths = input_filepaths\n\t\tif self.input_filepaths is None:\n\t\t\tself.input_filepaths = [\n\t\t\t\tget_data_filepath('wikilarge', 'train', 'complex'),\n\t\t\t\tget_data_filepath('wikilarge', 'train', 'simple')\n\t\t\t]\n\t\tself.learn_sentencepiece()\n\n\t@property\n\t@lru_cache(maxsize=1)\n\tdef sp(self):\n\t\t'''\n\t\tWe need to use a property because SentencenPieceProcessor is cannot pickled\n\t\t> pickle.dumps(spm.SentencePieceProcessor())\n\t\t----> TypeError: can't pickle SwigPyObject objects\n\t\t'''\n\t\tsp = spm.SentencePieceProcessor()\n\t\tsp.Load(str(self.sentencepiece_model_path))\n\t\treturn sp\n\n\tdef get_hash_string(self):\n\t\treturn f'{self.__class__.__name__}(vocab_size={self.vocab_size})'\n\n\tdef learn_sentencepiece(self):\n\t\tif self.sentencepiece_model_path.exists():\n\t\t\treturn\n\t\tself.sentencepiece_model_path.parent.mkdir(parents=True, exist_ok=True)\n\t\tsentencepiece_model_prefix = self.sentencepiece_model_path.parent / self.sentencepiece_model_path.stem\n\t\targs_str = ' '.join([\n\t\t\tf'--input={\",\".join([str(path) for path in self.input_filepaths])}',\n\t\t\tf'--model_prefix={sentencepiece_model_prefix}',\n\t\t\tf'--vocab_size={self.vocab_size}',\n\t\t])\n\t\tmax_lines = 10**6\n\t\tif sum([count_lines(filepath) for filepath in self.input_filepaths]) > max_lines:\n\t\t\targs_str += f' --input_sentence_size={max_lines} --shuffle_input_sentence=true'\n\t\tspm.SentencePieceTrainer.Train(args_str)\n\n\tdef fit(self, complex_filepath, simple_filepath):\n\t\t# Args are not used\n\t\tself.learn_sentencepiece()\n\n\tdef encode_sentence(self, sentence, encoder_sentence=None):\n\t\t# TODO: Do we really need to extract the tokens\n\t\tspecial_tokens, sentence = extract_special_tokens(sentence)\n\t\tencoded_sentence = ' '.join(self.sp.EncodeAsPieces(sentence))\n\t\tif special_tokens != '':\n\t\t\tencoded_sentence = f'{special_tokens} {encoded_sentence}'\n\t\treturn encoded_sentence\n\n\tdef decode_sentence(self, sentence, encoder_sentence=None):\n\t\treturn self.sp.DecodePieces(sentence.split(' '))\n", "description": null, "category": "simple", "imports": ["from abc import ABC", "from functools import wraps, lru_cache", "import hashlib", "from pathlib import Path", "import dill as pickle", "import re", "import shutil", "from nevergrad.instrumentation import var", "import numpy as np", "import sentencepiece as spm", "from access.feature_extraction import (get_lexical_complexity_score, get_levenshtein_similarity,", "from access.resources.paths import VARIOUS_DIR, get_data_filepath", "from access.utils.helpers import (write_lines_in_parallel, yield_lines_in_parallel, add_dicts, get_default_args,"]}], [{"term": "class", "name": "RedirectToTest", "data": "class RedirectToTest(TestCase):\n\turls = 'regressiontests.views.generic_urls'\n\n\tdef setUp(self):\n\t\tself.save_warnings_state()\n\t\twarnings.filterwarnings('ignore', category=DeprecationWarning,\n\t\t\t\t\t\t\t\tmodule='django.views.generic.simple')\n\n\tdef tearDown(self):\n\t\tself.restore_warnings_state()\n\n\tdef test_redirect_to_returns_permanent_redirect(self):\n\t\t\"simple.redirect_to returns a permanent redirect (301) by default\"\n\t\tresponse = self.client.get('/simple/redirect_to/')\n\t\tself.assertEqual(response.status_code, 301)\n\t\tself.assertEqual('http://testserver/simple/target/', response['Location'])\n\n\tdef test_redirect_to_can_return_a_temporary_redirect(self):\n\t\t\"simple.redirect_to returns a temporary redirect (302) when explicitely asked to\"\n\t\tresponse = self.client.get('/simple/redirect_to_temp/')\n\t\tself.assertEqual(response.status_code, 302)\n\t\tself.assertEqual('http://testserver/simple/target/', response['Location'])\n\n\tdef test_redirect_to_on_empty_url_returns_gone(self):\n\t\t\"simple.redirect_to returns resource gone (410) when given a None url\"\n\t\tresponse = self.client.get('/simple/redirect_to_none/')\n\t\tself.assertEqual(response.status_code, 410)\n\n\tdef test_redirect_to_allows_formatted_url_string(self):\n\t\t\"simple.redirect_to uses string interpolation on target url for keyword args\"\n\t\tresponse = self.client.get('/simple/redirect_to_arg/42/')\n\t\tself.assertEqual(response.status_code, 301)\n\t\tself.assertEqual('http://testserver/simple/target_arg/42/', response['Location'])\n\n\tdef test_redirect_to_allows_query_string_to_be_passed(self):\n\t\t\"simple.redirect_to configured with query_string=True passes on any query string\"\n\t\t# the default is to not forward the query string\n\t\tresponse = self.client.get('/simple/redirect_to/?param1=foo&param2=bar')\n\t\tself.assertEqual(response.status_code, 301)\n\t\tself.assertEqual('http://testserver/simple/target/', response['Location'])\n\t\t# views configured with query_string=True however passes the query string along\n\t\tresponse = self.client.get('/simple/redirect_to_query/?param1=foo&param2=bar')\n\t\tself.assertEqual(response.status_code, 301)\n\t\tself.assertEqual('http://testserver/simple/target/?param1=foo&param2=bar', response['Location'])\n\n\t\t# Confirm that the contents of the query string are not subject to\n\t\t# string interpolation (Refs #17111):\n\t\tresponse = self.client.get('/simple/redirect_to_query/?param1=foo&param2=hist%C3%B3ria')\n\t\tself.assertEqual(response.status_code, 301)\n\t\tself.assertEqual('http://testserver/simple/target/?param1=foo&param2=hist%C3%B3ria', response['Location'])\n\t\tresponse = self.client.get('/simple/redirect_to_arg_and_query/99/?param1=foo&param2=hist%C3%B3ria')\n\t\tself.assertEqual(response.status_code, 301)\n\t\tself.assertEqual('http://testserver/simple/target_arg/99/?param1=foo&param2=hist%C3%B3ria', response['Location'])\n\n\tdef test_redirect_to_when_meta_contains_no_query_string(self):\n\t\t\"regression for #16705\"\n\t\t# we can't use self.client.get because it always sets QUERY_STRING\n\t\tresponse = self.client.request(PATH_INFO='/simple/redirect_to/')\n\t\tself.assertEqual(response.status_code, 301)\n", "description": null, "category": "simple", "imports": ["import warnings", "from django.test import TestCase"]}], [{"term": "def", "name": "fwith_tp_del", "data": "\tdef with_tp_del(cls):\n\t\tclass C(object):\n\t\t\tdef __new__(cls, *args, **kwargs):\n\t\t\t\traise TypeError('requires _testcapi.with_tp_del')\n\t\treturn C\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "def", "name": "fwithout_gc", "data": "\tdef without_gc(cls):\n\t\tclass C:\n\t\t\tdef __new__(cls, *args, **kwargs):\n\t\t\t\traise TypeError('requires _testcapi.without_gc')\n\t\treturn C\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "classNonGCSimpleBase:", "data": "class NonGCSimpleBase:\n\t\"\"\"\n\tThe base class for all the objects under test, equipped with various\n\ttesting features.\n\t\"\"\"\n\n\tsurvivors = []\n\tdel_calls = []\n\ttp_del_calls = []\n\terrors = []\n\n\t_cleaning = False\n\n\t__slots__ = ()\n\n\t@classmethod\n\tdef _cleanup(cls):\n\t\tcls.survivors.clear()\n\t\tcls.errors.clear()\n\t\tgc.garbage.clear()\n\t\tgc.collect()\n\t\tcls.del_calls.clear()\n\t\tcls.tp_del_calls.clear()\n\n\t@classmethod\n\t@contextlib.contextmanager\n\tdef test(cls):\n\t\t\"\"\"\n\t\tA context manager to use around all finalization tests.\n\t\t\"\"\"\n\t\twith support.disable_gc():\n\t\t\tcls.del_calls.clear()\n\t\t\tcls.tp_del_calls.clear()\n\t\t\tNonGCSimpleBase._cleaning = False\n\t\t\ttry:\n\t\t\t\tyield\n\t\t\t\tif cls.errors:\n\t\t\t\t\traise cls.errors[0]\n\t\t\tfinally:\n\t\t\t\tNonGCSimpleBase._cleaning = True\n\t\t\t\tcls._cleanup()\n\n\tdef check_sanity(self):\n\t\t\"\"\"\n\t\tCheck the object is sane (non-broken).\n\t\t\"\"\"\n\n\tdef __del__(self):\n\t\t\"\"\"\n\t\tPEP 442 finalizer.  Record that this was called, check the\n\t\tobject is in a sane state, and invoke a side effect.\n\t\t\"\"\"\n\t\ttry:\n\t\t\tif not self._cleaning:\n\t\t\t\tself.del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\t\t\tself.side_effect()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tA side effect called on destruction.\n\t\t\"\"\"\n\n", "description": "\n\tThe base class for all the objects under test, equipped with various\n\ttesting features.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "SimpleBase", "data": "class SimpleBase(NonGCSimpleBase):\n\n\tdef __init__(self):\n\t\tself.id_ = id(self)\n\n\tdef check_sanity(self):\n\t\tassert self.id_ == id(self)\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "NonGC", "data": "class NonGC(NonGCSimpleBase):\n\t__slots__ = ()\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "NonGCResurrector", "data": "class NonGCResurrector(NonGCSimpleBase):\n\t__slots__ = ()\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tResurrect self by storing self in a class-wide list.\n\t\t\"\"\"\n\t\tself.survivors.append(self)\n", "description": "\n\t\tResurrect self by storing self in a class-wide list.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "Simple", "data": "class Simple(SimpleBase):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "SimpleResurrector", "data": "class SimpleResurrector(SimpleBase):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tResurrect self by storing self in a class-wide list.\n\t\t\"\"\"\n\t\tself.survivors.append(self)\n\n", "description": "\n\t\tResurrect self by storing self in a class-wide list.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "classTestBase:", "data": "class TestBase:\n\n\tdef setUp(self):\n\t\tself.old_garbage = gc.garbage[:]\n\t\tgc.garbage[:] = []\n\n\tdef tearDown(self):\n\t\t# None of the tests here should put anything in gc.garbage\n\t\ttry:\n\t\t\tself.assertEqual(gc.garbage, [])\n\t\tfinally:\n\t\t\tdel self.old_garbage\n\t\t\tgc.collect()\n\n\tdef assert_del_calls(self, ids):\n\t\tself.assertEqual(sorted(SimpleBase.del_calls), sorted(ids))\n\n\tdef assert_tp_del_calls(self, ids):\n\t\tself.assertEqual(sorted(SimpleBase.tp_del_calls), sorted(ids))\n\n\tdef assert_survivors(self, ids):\n\t\tself.assertEqual(sorted(id(x) for x in SimpleBase.survivors), sorted(ids))\n\n\tdef assert_garbage(self, ids):\n\t\tself.assertEqual(sorted(id(x) for x in gc.garbage), sorted(ids))\n\n\tdef clear_survivors(self):\n\t\tSimpleBase.survivors.clear()\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "SimpleFinalizationTest", "data": "class SimpleFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization without refcycles.\n\t\"\"\"\n\n\tdef test_simple(self):\n\t\twith SimpleBase.test():\n\t\t\ts = Simple()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_simple_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = SimpleResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\tself.assertIsNot(wr(), None)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\tself.assertIs(wr(), None)\n\n\t@support.cpython_only\n\tdef test_non_gc(self):\n\t\twith SimpleBase.test():\n\t\t\ts = NonGC()\n\t\t\tself.assertFalse(gc.is_tracked(s))\n\t\t\tids = [id(s)]\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\t@support.cpython_only\n\tdef test_non_gc_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = NonGCResurrector()\n\t\t\tself.assertFalse(gc.is_tracked(s))\n\t\t\tids = [id(s)]\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids * 2)\n\t\t\tself.assert_survivors(ids)\n\n", "description": "\n\tTest finalization without refcycles.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "classSelfCycleBase:", "data": "class SelfCycleBase:\n\n\tdef __init__(self):\n\t\tsuper().__init__()\n\t\tself.ref = self\n\n\tdef check_sanity(self):\n\t\tsuper().check_sanity()\n\t\tassert self.ref is self\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "SimpleSelfCycle", "data": "class SimpleSelfCycle(SelfCycleBase, Simple):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "SelfCycleResurrector", "data": "class SelfCycleResurrector(SelfCycleBase, SimpleResurrector):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "SuicidalSelfCycle", "data": "class SuicidalSelfCycle(SelfCycleBase, Simple):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tExplicitly break the reference cycle.\n\t\t\"\"\"\n\t\tself.ref = None\n\n", "description": "\n\t\tExplicitly break the reference cycle.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "SelfCycleFinalizationTest", "data": "class SelfCycleFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of an object having a single cyclic reference to\n\titself.\n\t\"\"\"\n\n\tdef test_simple(self):\n\t\twith SimpleBase.test():\n\t\t\ts = SimpleSelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_simple_resurrect(self):\n\t\t# Test that __del__ can resurrect the object being finalized.\n\t\twith SimpleBase.test():\n\t\t\ts = SelfCycleResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\t# XXX is this desirable?\n\t\t\tself.assertIs(wr(), None)\n\t\t\t# When trying to destroy the object a second time, __del__\n\t\t\t# isn't called anymore (and the object isn't resurrected).\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\n\tdef test_simple_suicide(self):\n\t\t# Test the GC is able to deal with an object that kills its last\n\t\t# reference during __del__.\n\t\twith SimpleBase.test():\n\t\t\ts = SuicidalSelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\n", "description": "\n\tTest finalization of an object having a single cyclic reference to\n\titself.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "classChainedBase:", "data": "class ChainedBase:\n\n\tdef chain(self, left):\n\t\tself.suicided = False\n\t\tself.left = left\n\t\tleft.right = self\n\n\tdef check_sanity(self):\n\t\tsuper().check_sanity()\n\t\tif self.suicided:\n\t\t\tassert self.left is None\n\t\t\tassert self.right is None\n\t\telse:\n\t\t\tleft = self.left\n\t\t\tif left.suicided:\n\t\t\t\tassert left.right is None\n\t\t\telse:\n\t\t\t\tassert left.right is self\n\t\t\tright = self.right\n\t\t\tif right.suicided:\n\t\t\t\tassert right.left is None\n\t\t\telse:\n\t\t\t\tassert right.left is self\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "SimpleChained", "data": "class SimpleChained(ChainedBase, Simple):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "ChainedResurrector", "data": "class ChainedResurrector(ChainedBase, SimpleResurrector):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "SuicidalChained", "data": "class SuicidalChained(ChainedBase, Simple):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tExplicitly break the reference cycle.\n\t\t\"\"\"\n\t\tself.suicided = True\n\t\tself.left = None\n\t\tself.right = None\n\n", "description": "\n\t\tExplicitly break the reference cycle.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "CycleChainFinalizationTest", "data": "class CycleChainFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of a cyclic chain.  These tests are similar in\n\tspirit to the self-cycle tests above, but the collectable object\n\tgraph isn't trivial anymore.\n\t\"\"\"\n\n\tdef build_chain(self, classes):\n\t\tnodes = [cls() for cls in classes]\n\t\tfor i in range(len(nodes)):\n\t\t\tnodes[i].chain(nodes[i-1])\n\t\treturn nodes\n\n\tdef check_non_resurrecting_chain(self, classes):\n\t\tN = len(classes)\n\t\twith SimpleBase.test():\n\t\t\tnodes = self.build_chain(classes)\n\t\t\tids = [id(s) for s in nodes]\n\t\t\twrs = [weakref.ref(s) for s in nodes]\n\t\t\tdel nodes\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertEqual([wr() for wr in wrs], [None] * N)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\n\tdef check_resurrecting_chain(self, classes):\n\t\tN = len(classes)\n\t\twith SimpleBase.test():\n\t\t\tnodes = self.build_chain(classes)\n\t\t\tN = len(nodes)\n\t\t\tids = [id(s) for s in nodes]\n\t\t\tsurvivor_ids = [id(s) for s in nodes if isinstance(s, SimpleResurrector)]\n\t\t\twrs = [weakref.ref(s) for s in nodes]\n\t\t\tdel nodes\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(survivor_ids)\n\t\t\t# XXX desirable?\n\t\t\tself.assertEqual([wr() for wr in wrs], [None] * N)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_homogenous(self):\n\t\tself.check_non_resurrecting_chain([SimpleChained] * 3)\n\n\tdef test_homogenous_resurrect(self):\n\t\tself.check_resurrecting_chain([ChainedResurrector] * 3)\n\n\tdef test_homogenous_suicidal(self):\n\t\tself.check_non_resurrecting_chain([SuicidalChained] * 3)\n\n\tdef test_heterogenous_suicidal_one(self):\n\t\tself.check_non_resurrecting_chain([SuicidalChained, SimpleChained] * 2)\n\n\tdef test_heterogenous_suicidal_two(self):\n\t\tself.check_non_resurrecting_chain(\n\t\t\t[SuicidalChained] * 2 + [SimpleChained] * 2)\n\n\tdef test_heterogenous_resurrect_one(self):\n\t\tself.check_resurrecting_chain([ChainedResurrector, SimpleChained] * 2)\n\n\tdef test_heterogenous_resurrect_two(self):\n\t\tself.check_resurrecting_chain(\n\t\t\t[ChainedResurrector, SimpleChained, SuicidalChained] * 2)\n\n\tdef test_heterogenous_resurrect_three(self):\n\t\tself.check_resurrecting_chain(\n\t\t\t[ChainedResurrector] * 2 + [SimpleChained] * 2 + [SuicidalChained] * 2)\n\n", "description": "\n\tTest finalization of a cyclic chain.  These tests are similar in\n\tspirit to the self-cycle tests above, but the collectable object\n\tgraph isn't trivial anymore.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "LegacyBase", "data": "class LegacyBase(SimpleBase):\n\n\tdef __del__(self):\n\t\ttry:\n\t\t\t# Do not invoke side_effect here, since we are now exercising\n\t\t\t# the tp_del slot.\n\t\t\tif not self._cleaning:\n\t\t\t\tself.del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n\n\tdef __tp_del__(self):\n\t\t\"\"\"\n\t\tLegacy (pre-PEP 442) finalizer, mapped to a tp_del slot.\n\t\t\"\"\"\n\t\ttry:\n\t\t\tif not self._cleaning:\n\t\t\t\tself.tp_del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\t\t\tself.side_effect()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n", "description": "\n\t\tLegacy (pre-PEP 442) finalizer, mapped to a tp_del slot.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "Legacy", "data": "class Legacy(LegacyBase):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "LegacyResurrector", "data": "class LegacyResurrector(LegacyBase):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tResurrect self by storing self in a class-wide list.\n\t\t\"\"\"\n\t\tself.survivors.append(self)\n", "description": "\n\t\tResurrect self by storing self in a class-wide list.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "LegacySelfCycle", "data": "class LegacySelfCycle(SelfCycleBase, LegacyBase):\n\tpass\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "LegacyFinalizationTest", "data": "class LegacyFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of objects with a tp_del.\n\t\"\"\"\n\n\tdef tearDown(self):\n\t\t# These tests need to clean up a bit more, since they create\n\t\t# uncollectable objects.\n\t\tgc.garbage.clear()\n\t\tgc.collect()\n\t\tsuper().tearDown()\n\n\tdef test_legacy(self):\n\t\twith SimpleBase.test():\n\t\t\ts = Legacy()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\n\tdef test_legacy_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = LegacyResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\t# weakrefs are cleared before tp_del is called.\n\t\t\tself.assertIs(wr(), None)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids * 2)\n\t\t\tself.assert_survivors(ids)\n\t\tself.assertIs(wr(), None)\n\n\tdef test_legacy_self_cycle(self):\n\t\t# Self-cycles with legacy finalizers end up in gc.garbage.\n\t\twith SimpleBase.test():\n\t\t\ts = LegacySelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls([])\n\t\t\tself.assert_tp_del_calls([])\n\t\t\tself.assert_survivors([])\n\t\t\tself.assert_garbage(ids)\n\t\t\tself.assertIsNot(wr(), None)\n\t\t\t# Break the cycle to allow collection\n\t\t\tgc.garbage[0].ref = None\n\t\tself.assert_garbage([])\n\t\tself.assertIs(wr(), None)\n\n", "description": "\n\tTest finalization of objects with a tp_del.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}], [{"term": "class", "name": "TestClimateAPI", "data": "class TestClimateAPI(tests.TestCase):\n\t\"\"\"Tests for functions in simple_wbd.utils module.\"\"\"\n\n\tdef setUp(self):\n\t\tsuper().setUp()\n\t\tself.api = simple_wbd.ClimateAPI()\n\n\tdef test_init(self):\n\t\t\"\"\"Test Climate api init function.\n\n\t\tTest if the default response class gets set correctly if the given\n\t\tclass is a subclass of ClimateDataset.\n\t\t\"\"\"\n\t\t# pylint: disable=protected-access\n\n\t\tclass Dummy(object):\n\t\t\t# pylint: disable=too-few-public-methods\n\t\t\tpass\n\n\t\tclass DummyClimateSubclass(simple_wbd.ClimateDataset):\n\t\t\t# pylint: disable=too-few-public-methods\n\t\t\tpass\n\n\t\tapi = simple_wbd.ClimateAPI()\n\t\tself.assertEqual(api._dataset_class, simple_wbd.ClimateDataset)\n\n\t\tapi = simple_wbd.ClimateAPI(Dummy)\n\t\tself.assertEqual(api._dataset_class, simple_wbd.ClimateDataset)\n\n\t\tapi = simple_wbd.ClimateAPI(\"bad data\")\n\t\tself.assertEqual(api._dataset_class, simple_wbd.ClimateDataset)\n\n\t\tapi = simple_wbd.ClimateAPI(DummyClimateSubclass)\n\t\tself.assertEqual(api._dataset_class, DummyClimateSubclass)\n\n\t@tests.MY_VCR.use_cassette(\"climate.json\")\n\tdef test_get_instrumental_specific(self):\n\t\t\"\"\"Test specific instrumental data query.\"\"\"\n\t\tresponse = self.api.get_instrumental(\n\t\t\t[\"SVN\"], data_types=[\"pr\"], intervals=[\"month\"])\n\t\tself.assertIn(\"SVN\", response.api_responses)\n\t\tself.assertIn(\"pr\", response.api_responses[\"SVN\"])\n\t\tself.assertIn(\"month\", response.api_responses[\"SVN\"][\"pr\"])\n\n\t@tests.MY_VCR.use_cassette(\"climate.json\")\n\tdef test_get_instrumental_generic(self):\n\t\t\"\"\"Test generic instrumental data query.\"\"\"\n\t\t# pylint: disable=protected-access\n\t\t# We need access to api protected members for testing\n\t\tlocations = [\"SVN\", \"TUN\"]\n\t\tresponse = self.api.get_instrumental(locations)\n\t\tself.assertEqual(set(locations), set(response.api_responses))\n\t\tself.assertEqual(set(self.api.INSTRUMENTAL_TYPES),\n\t\t\t\t\t\t set(response.api_responses[\"SVN\"]))\n\t\tself.assertEqual(set(self.api._default_intervals),\n\t\t\t\t\t\t set(response.api_responses[\"SVN\"][\"pr\"]))\n\n\tdef test_get_location_good(self):\n\t\t\"\"\"Test get location with proper locations.\"\"\"\n\t\t# pylint: disable=protected-access\n\t\tself.assertEqual((\"country\", \"SVN\"), self.api._get_location(\"SI\"))\n\t\tself.assertEqual((\"country\", \"TON\"), self.api._get_location(\"Tonga\"))\n\t\tself.assertEqual((\"country\", \"USA\"), self.api._get_location(\"us\"))\n\t\tself.assertEqual((\"basin\", \"1\"), self.api._get_location(\"1\"))\n\t\tself.assertEqual((\"basin\", \"28\"), self.api._get_location(\"28\"))\n\n\tdef test_get_location_bad(self):\n\t\t\"\"\"Test get location with invalid locations.\"\"\"\n\t\t# pylint: disable=protected-access\n\t\tbad_locations = [\"-1\", \"Orange3\", \"books\", \"555\", \"XYZ1\"]\n\t\tfor location in bad_locations:\n\t\t\tself.assertRaises(ValueError, self.api._get_location, location)\n", "description": "Tests for functions in simple_wbd.utils module.", "category": "simple", "imports": ["import simple_wbd", "import tests"]}], [], [], [], [{"term": "class", "name": "MWSTestCase", "data": "class MWSTestCase(unittest.TestCase):\n\n\tdef setUp(self):\n\t\tself.mws = MWSConnection(Merchant=simple, debug=0)\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_feedlist(self):\n\t\tself.mws.get_feed_submission_list()\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_inbound_status(self):\n\t\tresponse = self.mws.get_inbound_service_status()\n\t\tstatus = response.GetServiceStatusResult.Status\n\t\tself.assertIn(status, ('GREEN', 'GREEN_I', 'YELLOW', 'RED'))\n\n\t@property\n\tdef marketplace(self):\n\t\ttry:\n\t\t\treturn self._marketplace\n\t\texcept AttributeError:\n\t\t\tresponse = self.mws.list_marketplace_participations()\n\t\t\tresult = response.ListMarketplaceParticipationsResult\n\t\t\tself._marketplace = result.ListMarketplaces.Marketplace[0]\n\t\t\treturn self.marketplace\n\n\t@property\n\tdef marketplace_id(self):\n\t\treturn self.marketplace.MarketplaceId\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_marketplace_participations(self):\n\t\tresponse = self.mws.list_marketplace_participations()\n\t\tresult = response.ListMarketplaceParticipationsResult\n\t\tself.assertTrue(result.ListMarketplaces.Marketplace[0].MarketplaceId)\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_get_product_categories_for_asin(self):\n\t\tasin = '144930544X'\n\t\tresponse = self.mws.get_product_categories_for_asin(\n\t\t\tMarketplaceId=self.marketplace_id,\n\t\t\tASIN=asin)\n\t\tself.assertEqual(len(response._result.Self), 3)\n\t\tcategoryids = [x.ProductCategoryId for x in response._result.Self]\n\t\tself.assertSequenceEqual(categoryids, ['285856', '21', '491314'])\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_list_matching_products(self):\n\t\tresponse = self.mws.list_matching_products(\n\t\t\tMarketplaceId=self.marketplace_id,\n\t\t\tQuery='boto')\n\t\tproducts = response._result.Products\n\t\tself.assertTrue(len(products))\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_get_matching_product(self):\n\t\tasin = 'B001UDRNHO'\n\t\tresponse = self.mws.get_matching_product(\n\t\t\tMarketplaceId=self.marketplace_id,\n\t\t\tASINList=[asin])\n\t\tattributes = response._result[0].Product.AttributeSets.ItemAttributes\n\t\tself.assertEqual(attributes[0].Label, 'Serengeti')\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_get_matching_product_for_id(self):\n\t\tasins = ['B001UDRNHO', '144930544X']\n\t\tresponse = self.mws.get_matching_product_for_id(\n\t\t\tMarketplaceId=self.marketplace_id,\n\t\t\tIdType='ASIN',\n\t\t\tIdList=asins)\n\t\tself.assertEqual(len(response._result), 2)\n\t\tfor result in response._result:\n\t\t\tself.assertEqual(len(result.Products.Product), 1)\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_get_lowest_offer_listings_for_asin(self):\n\t\tasin = '144930544X'\n\t\tresponse = self.mws.get_lowest_offer_listings_for_asin(\n\t\t\tMarketplaceId=self.marketplace_id,\n\t\t\tItemCondition='New',\n\t\t\tASINList=[asin])\n\t\tlistings = response._result[0].Product.LowestOfferListings\n\t\tself.assertTrue(len(listings.LowestOfferListing))\n\n\t@unittest.skipUnless(simple and isolator, \"skipping simple test\")\n\tdef test_list_inventory_supply(self):\n\t\tasof = (datetime.today() - timedelta(days=30)).isoformat()\n\t\tresponse = self.mws.list_inventory_supply(QueryStartDateTime=asof,\n\t\t\t\t\t\t\t\t\t\t\t\t  ResponseGroup='Basic')\n\t\tself.assertTrue(hasattr(response._result, 'InventorySupplyList'))\n", "description": null, "category": "simple", "imports": ["from __future__ import print_function", "import sys", "import os", "import os.path", "from datetime import datetime, timedelta", "from boto.mws.connection import MWSConnection", "from tests.compat import unittest"]}], [{"term": "class", "name": "SimpleSwitchRest13", "data": "class SimpleSwitchRest13(simple_switch_13.SimpleSwitch13):\n\n\t_CONTEXTS = {'wsgi': WSGIApplication}\n\n\tdef __init__(self, *args, **kwargs):\n\t\tsuper(SimpleSwitchRest13, self).__init__(*args, **kwargs)\n\t\tself.switches = {}\n\t\twsgi = kwargs['wsgi']\n\t\twsgi.register(SimpleSwitchController,\n\t\t\t\t\t  {simple_switch_instance_name: self})\n\n\t@set_ev_cls(ofp_event.EventOFPSwitchFeatures, CONFIG_DISPATCHER)\n\tdef switch_features_handler(self, ev):\n\t\tsuper(SimpleSwitchRest13, self).switch_features_handler(ev)\n\t\tdatapath = ev.msg.datapath\n\t\tself.switches[datapath.id] = datapath\n\t\tself.mac_to_port.setdefault(datapath.id, {})\n\n\tdef set_mac_to_port(self, dpid, entry):\n\t\tmac_table = self.mac_to_port.setdefault(dpid, {})\n\t\tdatapath = self.switches.get(dpid)\n\n\t\tentry_port = entry['port']\n\t\tentry_mac = entry['mac']\n\n\t\tif datapath is not None:\n\t\t\tparser = datapath.ofproto_parser\n\t\t\tif entry_port not in mac_table.values():\n\n\t\t\t\tfor mac, port in mac_table.items():\n\n\t\t\t\t\t# from known device to new device\n\t\t\t\t\tactions = [parser.OFPActionOutput(entry_port)]\n\t\t\t\t\tmatch = parser.OFPMatch(in_port=port, eth_dst=entry_mac)\n\t\t\t\t\tself.add_flow(datapath, 1, match, actions)\n\n\t\t\t\t\t# from new device to known device\n\t\t\t\t\tactions = [parser.OFPActionOutput(port)]\n\t\t\t\t\tmatch = parser.OFPMatch(in_port=entry_port, eth_dst=mac)\n\t\t\t\t\tself.add_flow(datapath, 1, match, actions)\n\n\t\t\t\tmac_table.update({entry_mac: entry_port})\n\t\treturn mac_table\n\n", "description": null, "category": "simple", "imports": ["import json", "from ryu.app import simple_switch_13", "from ryu.controller import ofp_event", "from ryu.controller.handler import CONFIG_DISPATCHER", "from ryu.controller.handler import set_ev_cls", "from ryu.app.wsgi import ControllerBase", "from ryu.app.wsgi import Response", "from ryu.app.wsgi import route", "from ryu.app.wsgi import WSGIApplication", "from ryu.lib import dpid as dpid_lib"]}, {"term": "class", "name": "SimpleSwitchController", "data": "class SimpleSwitchController(ControllerBase):\n\n\tdef __init__(self, req, link, data, **config):\n\t\tsuper(SimpleSwitchController, self).__init__(req, link, data, **config)\n\t\tself.simple_switch_app = data[simple_switch_instance_name]\n\n\t@route('simpleswitch', url, methods=['GET'],\n\t\t   requirements={'dpid': dpid_lib.DPID_PATTERN})\n\tdef list_mac_table(self, req, **kwargs):\n\n\t\tsimple_switch = self.simple_switch_app\n\t\tdpid = dpid_lib.str_to_dpid(kwargs['dpid'])\n\n\t\tif dpid not in simple_switch.mac_to_port:\n\t\t\treturn Response(status=404)\n\n\t\tmac_table = simple_switch.mac_to_port.get(dpid, {})\n\t\tbody = json.dumps(mac_table)\n\t\treturn Response(content_type='application/json', body=body)\n\n\t@route('simpleswitch', url, methods=['PUT'],\n\t\t   requirements={'dpid': dpid_lib.DPID_PATTERN})\n\tdef put_mac_table(self, req, **kwargs):\n\n\t\tsimple_switch = self.simple_switch_app\n\t\tdpid = dpid_lib.str_to_dpid(kwargs['dpid'])\n\t\ttry:\n\t\t\tnew_entry = req.json if req.body else {}\n\t\texcept ValueError:\n\t\t\traise Response(status=400)\n\n\t\tif dpid not in simple_switch.mac_to_port:\n\t\t\treturn Response(status=404)\n\n\t\ttry:\n\t\t\tmac_table = simple_switch.set_mac_to_port(dpid, new_entry)\n\t\t\tbody = json.dumps(mac_table)\n\t\t\treturn Response(content_type='application/json', body=body)\n\t\texcept Exception as e:\n\t\t\treturn Response(status=500)\n", "description": null, "category": "simple", "imports": ["import json", "from ryu.app import simple_switch_13", "from ryu.controller import ofp_event", "from ryu.controller.handler import CONFIG_DISPATCHER", "from ryu.controller.handler import set_ev_cls", "from ryu.app.wsgi import ControllerBase", "from ryu.app.wsgi import Response", "from ryu.app.wsgi import route", "from ryu.app.wsgi import WSGIApplication", "from ryu.lib import dpid as dpid_lib"]}], [{"term": "def", "name": "test1_simple_string", "data": "def test1_simple_string():\n\tactual = generate_diff('./tests/fixtures/simple_before.yaml',\n\t\t\t\t\t\t   './tests/fixtures/simple_after.yaml',\n\t\t\t\t\t\t   'string')\n\tassert actual == expected.SIMPLE_STRING\n\n", "description": null, "category": "simple", "imports": ["from gendiff.generator import generate_diff", "import tests.expected as expected"]}, {"term": "def", "name": "test2_simple_plain", "data": "def test2_simple_plain():\n\tactual = generate_diff('./tests/fixtures/simple_before.yaml',\n\t\t\t\t\t\t   './tests/fixtures/simple_after.yaml',\n\t\t\t\t\t\t   'plain')\n\tassert actual == expected.SIMPLE_PLAIN\n\n", "description": null, "category": "simple", "imports": ["from gendiff.generator import generate_diff", "import tests.expected as expected"]}, {"term": "def", "name": "test3_simple_json", "data": "def test3_simple_json():\n\tactual = generate_diff('./tests/fixtures/simple_before.yaml',\n\t\t\t\t\t\t   './tests/fixtures/simple_after.yaml',\n\t\t\t\t\t\t   'json')\n\tassert actual == expected.SIMPLE_JSON\n\n", "description": null, "category": "simple", "imports": ["from gendiff.generator import generate_diff", "import tests.expected as expected"]}, {"term": "def", "name": "test4_complex_string", "data": "def test4_complex_string():\n\tactual = generate_diff('./tests/fixtures/complex_before.yaml',\n\t\t\t\t\t\t   './tests/fixtures/complex_after.yaml',\n\t\t\t\t\t\t   'string')\n\tassert actual == expected.COMPLEX_STRING\n\n", "description": null, "category": "simple", "imports": ["from gendiff.generator import generate_diff", "import tests.expected as expected"]}, {"term": "def", "name": "test5_complex_plain", "data": "def test5_complex_plain():\n\tactual = generate_diff('./tests/fixtures/complex_before.yaml',\n\t\t\t\t\t\t   './tests/fixtures/complex_after.yaml',\n\t\t\t\t\t\t   'plain')\n\tassert actual == expected.COMPLEX_PLAIN\n\n", "description": null, "category": "simple", "imports": ["from gendiff.generator import generate_diff", "import tests.expected as expected"]}, {"term": "def", "name": "test6_complex_json", "data": "def test6_complex_json():\n\tactual = generate_diff('./tests/fixtures/complex_before.yaml',\n\t\t\t\t\t\t   './tests/fixtures/complex_after.yaml',\n\t\t\t\t\t\t   'json')\n\tassert actual == expected.COMPLEX_JSON\n", "description": null, "category": "simple", "imports": ["from gendiff.generator import generate_diff", "import tests.expected as expected"]}], [{"term": "def", "name": "test1_simple_string", "data": "def test1_simple_string():\n\tactual = generate_diff('./tests/fixtures/simple_before.json',\n\t\t\t\t\t\t   './tests/fixtures/simple_after.json',\n\t\t\t\t\t\t   'string')\n\tassert actual == expected.SIMPLE_STRING\n\n", "description": null, "category": "simple", "imports": ["from gendiff.generator import generate_diff", "import tests.expected as expected"]}, {"term": "def", "name": "test2_simple_plain", "data": "def test2_simple_plain():\n\tactual = generate_diff('./tests/fixtures/simple_before.json',\n\t\t\t\t\t\t   './tests/fixtures/simple_after.json',\n\t\t\t\t\t\t   'plain')\n\tassert actual == expected.SIMPLE_PLAIN\n\n", "description": null, "category": "simple", "imports": ["from gendiff.generator import generate_diff", "import tests.expected as expected"]}, {"term": "def", "name": "test3_simple_json", "data": "def test3_simple_json():\n\tactual = generate_diff('./tests/fixtures/simple_before.json',\n\t\t\t\t\t\t   './tests/fixtures/simple_after.json',\n\t\t\t\t\t\t   'json')\n\tassert actual == expected.SIMPLE_JSON\n\n", "description": null, "category": "simple", "imports": ["from gendiff.generator import generate_diff", "import tests.expected as expected"]}, {"term": "def", "name": "test4_complex_string", "data": "def test4_complex_string():\n\tactual = generate_diff('./tests/fixtures/complex_before.json',\n\t\t\t\t\t\t   './tests/fixtures/complex_after.json',\n\t\t\t\t\t\t   'string')\n\tassert actual == expected.COMPLEX_STRING\n\n", "description": null, "category": "simple", "imports": ["from gendiff.generator import generate_diff", "import tests.expected as expected"]}, {"term": "def", "name": "test5_complex_plain", "data": "def test5_complex_plain():\n\tactual = generate_diff('./tests/fixtures/complex_before.json',\n\t\t\t\t\t\t   './tests/fixtures/complex_after.json',\n\t\t\t\t\t\t   'plain')\n\tassert actual == expected.COMPLEX_PLAIN\n\n", "description": null, "category": "simple", "imports": ["from gendiff.generator import generate_diff", "import tests.expected as expected"]}, {"term": "def", "name": "test6_complex_json", "data": "def test6_complex_json():\n\tactual = generate_diff('./tests/fixtures/complex_before.json',\n\t\t\t\t\t\t   './tests/fixtures/complex_after.json',\n\t\t\t\t\t\t   'json')\n\tassert actual == expected.COMPLEX_JSON\n", "description": null, "category": "simple", "imports": ["from gendiff.generator import generate_diff", "import tests.expected as expected"]}], [{"term": "def", "name": "printMetrics", "data": "def printMetrics(testActualVal, predictions):\n\t#classification evaluation measures\n\tprint('\\n==============================================================================')\n\tprint(\"MAE: \", metrics.mean_absolute_error(testActualVal, predictions))\n\t#print(\"MSE: \", metrics.mean_squared_error(testActualVal, predictions))\n\tprint(\"RMSE: \", metrics.mean_squared_error(testActualVal, predictions)**0.5)\n\tprint(\"R2: \", metrics.r2_score(testActualVal, predictions))\n\n", "description": null, "category": "simple", "imports": ["from sklearn.linear_model import LinearRegression", "from sklearn.linear_model import LogisticRegression", "from sklearn.tree import DecisionTreeClassifier", "from sklearn.ensemble import RandomForestClassifier", "from sklearn.model_selection import train_test_split", "from sklearn import metrics", "from sklearn.model_selection import cross_validate", "from sklearn.model_selection import cross_val_score", "from sklearn.tree import export_graphviz", "import matplotlib.pyplot as plt", "import pandas as pd", "# from sklearn import svm"]}], [{"term": "def", "name": "setup", "data": "def setup():\n\tsetup_session_dir()\n", "description": null, "category": "simple", "imports": ["import tg", "from tg.controllers import TGController", "from tg.decorators import expose", "from pylons.decorators.cache import beaker_cache", "from pylons.controllers.util import etag_cache", "from pylons import cache", "from routes import Mapper", "from routes.middleware import RoutesMiddleware", "from webob.exc import HTTPNotModified", "from tg.tests.base import TestWSGIController, make_app, setup_session_dir, teardown_session_dir", "import beaker.container"]}, {"term": "def", "name": "teardown", "data": "def teardown():\n\tteardown_session_dir()\n", "description": null, "category": "simple", "imports": ["import tg", "from tg.controllers import TGController", "from tg.decorators import expose", "from pylons.decorators.cache import beaker_cache", "from pylons.controllers.util import etag_cache", "from pylons import cache", "from routes import Mapper", "from routes.middleware import RoutesMiddleware", "from webob.exc import HTTPNotModified", "from tg.tests.base import TestWSGIController, make_app, setup_session_dir, teardown_session_dir", "import beaker.container"]}, {"term": "class", "name": "classMockTime:", "data": "class MockTime:\n\t\n\t\"\"\" A very simple class to mock the time module. This lets us slide time\n\taround to fake expiry in beaker.container. \"\"\"\n\t\n\tmock_time = 0\n\t\n\tdef time(self):\n\t\treturn self.mock_time\n\t\n\tdef set_time(self, v):\n\t\tself.mock_time = v\n", "description": " A very simple class to mock the time module. This lets us slide time\n\taround to fake expiry in beaker.container. ", "category": "simple", "imports": ["import tg", "from tg.controllers import TGController", "from tg.decorators import expose", "from pylons.decorators.cache import beaker_cache", "from pylons.controllers.util import etag_cache", "from pylons import cache", "from routes import Mapper", "from routes.middleware import RoutesMiddleware", "from webob.exc import HTTPNotModified", "from tg.tests.base import TestWSGIController, make_app, setup_session_dir, teardown_session_dir", "import beaker.container"]}, {"term": "class", "name": "SimpleCachingController", "data": "class SimpleCachingController(TGController):\n\t\n\t\"\"\" Pylons supports a mechanism for arbitrary caches that can be allocated\n\twithin controllers. Each cache value has a creation function associated\n\twith it that is called to retrieve it's results. \"\"\"\n\t\n\t@expose()\n\tdef simple(self, a):\n\t\tc = cache.get_cache(\"BasicTGController.index\")\n\t\tx = c.get_value(key=a, \n\t\t\t\t\t\tcreatefunc=lambda: \"cached %s\" % a,\n\t\t\t\t\t\ttype=\"memory\",\n\t\t\t\t\t\texpiretime=3600)\n\t\treturn x\n\t\n\tdef createfunc(self):\n\t\treturn \"cached %s\" % mockdb['expiry']\n\t\n\t@expose()\n\tdef expiry(self, a):\n\t\tmockdb['expiry'] = a # inject a value into the context\n\t\tc = cache.get_cache(\"BasicTGController.index\")\n\t\tx = c.get_value(key='test', \n\t\t\t\t\t\tcreatefunc=self.createfunc,\n\t\t\t\t\t\ttype=\"memory\",\n\t\t\t\t\t\texpiretime=100)\n\t\treturn x\n", "description": " Pylons supports a mechanism for arbitrary caches that can be allocated\n\twithin controllers. Each cache value has a creation function associated\n\twith it that is called to retrieve it's results. ", "category": "simple", "imports": ["import tg", "from tg.controllers import TGController", "from tg.decorators import expose", "from pylons.decorators.cache import beaker_cache", "from pylons.controllers.util import etag_cache", "from pylons import cache", "from routes import Mapper", "from routes.middleware import RoutesMiddleware", "from webob.exc import HTTPNotModified", "from tg.tests.base import TestWSGIController, make_app, setup_session_dir, teardown_session_dir", "import beaker.container"]}, {"term": "class", "name": "TestSimpleCaching", "data": "class TestSimpleCaching(TestWSGIController):\n\tdef __init__(self, *args, **kargs):\n\t\tTestWSGIController.__init__(self, *args, **kargs)\n\t\tself.baseenviron = {}\n\t\tself.app = make_app(SimpleCachingController, self.baseenviron)\n\n\tdef test_simple_cache(self):\n\t\t\"\"\" test that caches get different results for different cache keys. \"\"\"\n\t\tresp = self.app.get('/simple/', params={'a':'foo'})\n\t\tassert resp.body == 'cached foo'\n\t\tresp = self.app.get('/simple/', params={'a':'bar'})\n\t\tassert resp.body == 'cached bar'\n\t\tresp = self.app.get('/simple/', params={'a':'baz'})\n\t\tassert resp.body == 'cached baz'\n\n\tdef test_expiry(self):\n\t\t\"\"\" test that values expire from a single cache key. \"\"\"\n\t\tmocktime.set_time(0)\n\t\tresp = self.app.get('/expiry/', params={'a':'foo1'})\n\t\tassert resp.body == 'cached foo1'\n\t\tmocktime.set_time(1)\n\t\tresp = self.app.get('/expiry/', params={'a':'foo2'})\n\t\tassert resp.body == 'cached foo1'\n\t\tmocktime.set_time(200) # wind clock past expiry\n\t\tresp = self.app.get('/expiry/', params={'a':'foo2'})\n\t\tassert resp.body == 'cached foo2'\n", "description": " test that caches get different results for different cache keys. ", "category": "simple", "imports": ["import tg", "from tg.controllers import TGController", "from tg.decorators import expose", "from pylons.decorators.cache import beaker_cache", "from pylons.controllers.util import etag_cache", "from pylons import cache", "from routes import Mapper", "from routes.middleware import RoutesMiddleware", "from webob.exc import HTTPNotModified", "from tg.tests.base import TestWSGIController, make_app, setup_session_dir, teardown_session_dir", "import beaker.container"]}, {"term": "class", "name": "DecoratorController", "data": "class DecoratorController(TGController):\n\t\n\t@beaker_cache(expire=100, type='memory')\n\t@expose()\n\tdef simple(self):\n\t\treturn \"cached %s\" % mockdb['DecoratorController.simple']\n", "description": null, "category": "simple", "imports": ["import tg", "from tg.controllers import TGController", "from tg.decorators import expose", "from pylons.decorators.cache import beaker_cache", "from pylons.controllers.util import etag_cache", "from pylons import cache", "from routes import Mapper", "from routes.middleware import RoutesMiddleware", "from webob.exc import HTTPNotModified", "from tg.tests.base import TestWSGIController, make_app, setup_session_dir, teardown_session_dir", "import beaker.container"]}, {"term": "class", "name": "TestDecoratorCaching", "data": "class TestDecoratorCaching(TestWSGIController):\n\t\n\t\"\"\" Test that the decorators function. \"\"\"\n\t\n\tdef __init__(self, *args, **kargs):\n\t\tTestWSGIController.__init__(self, *args, **kargs)\n\t\tself.baseenviron = {}\n\t\tself.app = make_app(DecoratorController, self.baseenviron)\n\t\n\tdef test_simple(self):\n\t\t\"\"\" Test expiry of cached results for decorated functions. \"\"\"\n\t\tmocktime.set_time(0)\n\t\tmockdb['DecoratorController.simple'] = 'foo1'\n\t\tresp = self.app.get('/simple/')\n\t\tassert resp.body == 'cached foo1'\n\t\tmocktime.set_time(1)\n\t\tmockdb['DecoratorController.simple'] = 'foo2'\n\t\tresp = self.app.get('/simple/')\n\t\tassert resp.body == 'cached foo1'\n\t\tmocktime.set_time(200)\n\t\tmockdb['DecoratorController.simple'] = 'foo2'\n\t\tresp = self.app.get('/simple/')\n\t\tassert resp.body == 'cached foo2'\n", "description": " Test that the decorators function. ", "category": "simple", "imports": ["import tg", "from tg.controllers import TGController", "from tg.decorators import expose", "from pylons.decorators.cache import beaker_cache", "from pylons.controllers.util import etag_cache", "from pylons import cache", "from routes import Mapper", "from routes.middleware import RoutesMiddleware", "from webob.exc import HTTPNotModified", "from tg.tests.base import TestWSGIController, make_app, setup_session_dir, teardown_session_dir", "import beaker.container"]}, {"term": "class", "name": "EtagController", "data": "class EtagController(TGController):\n\n\t@expose()\n\tdef etagged(self, etag):\n\t\tetag_cache(etag)\n\t\treturn \"bar\"\n", "description": null, "category": "simple", "imports": ["import tg", "from tg.controllers import TGController", "from tg.decorators import expose", "from pylons.decorators.cache import beaker_cache", "from pylons.controllers.util import etag_cache", "from pylons import cache", "from routes import Mapper", "from routes.middleware import RoutesMiddleware", "from webob.exc import HTTPNotModified", "from tg.tests.base import TestWSGIController, make_app, setup_session_dir, teardown_session_dir", "import beaker.container"]}, {"term": "class", "name": "TestEtagCaching", "data": "class TestEtagCaching(TestWSGIController):\n\t\n\t\"\"\" A simple mechanism is provided to set the etag header for returned results. \"\"\"\n\t\n\tdef __init__(self, *args, **kargs):\n\t\tTestWSGIController.__init__(self, *args, **kargs)\n\t\tself.app = make_app(EtagController)\n\n\tdef test_etags(self):\n\t\t\"\"\" Test that the etag in the response headers is the one we expect. \"\"\"\n\t\tresp = self.app.get('/etagged/', params={'etag':'foo'})\n\t\tassert resp.etag == 'foo', resp.etag\n\t\tresp = self.app.get('/etagged/', params={'etag':'bar'})\n\t\tassert resp.etag == 'bar', resp.etag\t\n\t\t\n\tdef test_304(self):\n\t\tresp = self.app.get('/etagged/', params={'etag':'foo'}, headers={'if-none-match': 'foo'})\n\t\tprint resp.status_int\n\t\tassert \"304\" in resp.status\n\n", "description": " A simple mechanism is provided to set the etag header for returned results. ", "category": "simple", "imports": ["import tg", "from tg.controllers import TGController", "from tg.decorators import expose", "from pylons.decorators.cache import beaker_cache", "from pylons.controllers.util import etag_cache", "from pylons import cache", "from routes import Mapper", "from routes.middleware import RoutesMiddleware", "from webob.exc import HTTPNotModified", "from tg.tests.base import TestWSGIController, make_app, setup_session_dir, teardown_session_dir", "import beaker.container"]}], [], [{"term": "class", "name": "SimpleCookieJar", "data": "class SimpleCookieJar(object):\n\tdef __init__(self):\n\t\tself.jar = dict()\n\n\tdef add(self, set_cookie):\n\t\tif set_cookie:\n\t\t\ttry:\n\t\t\t\tsimpleCookie = Cookie.SimpleCookie(set_cookie)\n\t\t\texcept:\n\t\t\t\tsimpleCookie = Cookie.SimpleCookie(set_cookie.encode('ascii', 'ignore'))\n\n\t\t\tfor k, v in simpleCookie.items():\n\t\t\t\tdomain = v.get(\"domain\")\n\t\t\t\tif domain:\n\t\t\t\t\tif not domain.startswith(\".\"):\n\t\t\t\t\t\tdomain = \".\" + domain\n\t\t\t\t\tcookie = self.jar.get(domain) if self.jar.get(domain) else Cookie.SimpleCookie()\n\t\t\t\t\tcookie.update(simpleCookie)\n\t\t\t\t\tself.jar[domain.lower()] = cookie\n\n\tdef set(self, set_cookie):\n\t\tif set_cookie:\n\t\t\ttry:\n\t\t\t\tsimpleCookie = Cookie.SimpleCookie(set_cookie)\n\t\t\texcept:\n\t\t\t\tsimpleCookie = Cookie.SimpleCookie(set_cookie.encode('ascii', 'ignore'))\n\n\t\t\tfor k, v in simpleCookie.items():\n\t\t\t\tdomain = v.get(\"domain\")\n\t\t\t\tif domain:\n\t\t\t\t\tif not domain.startswith(\".\"):\n\t\t\t\t\t\tdomain = \".\" + domain\n\t\t\t\t\tself.jar[domain.lower()] = simpleCookie\n\n\tdef get(self, host):\n\t\tif not host:\n\t\t\treturn \"\"\n\n\t\tcookies = []\n\t\tfor domain, simpleCookie in self.jar.items():\n\t\t\thost = host.lower()\n\t\t\tif host.endswith(domain) or host == domain[1:]:\n\t\t\t\tcookies.append(self.jar.get(domain))\n\n\t\treturn \"; \".join(filter(None, [\"%s=%s\" % (k, v.value) for cookie in filter(None, sorted(cookies)) for k, v in\n\t\t\t\t\t\t\t\t\t   sorted(cookie.items())]))\n", "description": null, "category": "simple", "imports": ["\timport Cookie", "\timport http.cookies as Cookie"]}], [{"term": "class", "name": "TestLibraryInfo", "data": "class TestLibraryInfo(object):\n\tdef test_simple(self):\n\t\twith temppath('foo.ini') as path:\n\t\t\twith open(path,  'w') as f:\n\t\t\t\tf.write(simple)\n\t\t\tpkg = os.path.splitext(path)[0]\n\t\t\tout = read_config(pkg)\n\n\t\tassert_(out.cflags() == simple_d['cflags'])\n\t\tassert_(out.libs() == simple_d['libflags'])\n\t\tassert_(out.name == simple_d['name'])\n\t\tassert_(out.version == simple_d['version'])\n\n\tdef test_simple_variable(self):\n\t\twith temppath('foo.ini') as path:\n\t\t\twith open(path,  'w') as f:\n\t\t\t\tf.write(simple_variable)\n\t\t\tpkg = os.path.splitext(path)[0]\n\t\t\tout = read_config(pkg)\n\n\t\tassert_(out.cflags() == simple_variable_d['cflags'])\n\t\tassert_(out.libs() == simple_variable_d['libflags'])\n\t\tassert_(out.name == simple_variable_d['name'])\n\t\tassert_(out.version == simple_variable_d['version'])\n\t\tout.vars['prefix'] = '/Users/david'\n\t\tassert_(out.cflags() == '-I/Users/david/include')\n", "description": null, "category": "simple", "imports": ["from __future__ import division, absolute_import, print_function", "import os", "from numpy.distutils.npy_pkg_config import read_config, parse_flags", "from numpy.testing import run_module_suite, temppath, assert_"]}, {"term": "class", "name": "TestParseFlags", "data": "class TestParseFlags(object):\n\tdef test_simple_cflags(self):\n\t\td = parse_flags(\"-I/usr/include\")\n\t\tassert_(d['include_dirs'] == ['/usr/include'])\n\n\t\td = parse_flags(\"-I/usr/include -DFOO\")\n\t\tassert_(d['include_dirs'] == ['/usr/include'])\n\t\tassert_(d['macros'] == ['FOO'])\n\n\t\td = parse_flags(\"-I /usr/include -DFOO\")\n\t\tassert_(d['include_dirs'] == ['/usr/include'])\n\t\tassert_(d['macros'] == ['FOO'])\n\n\tdef test_simple_lflags(self):\n\t\td = parse_flags(\"-L/usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tassert_(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tassert_(d['libraries'] == ['foo', 'bar'])\n\n\t\td = parse_flags(\"-L /usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tassert_(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tassert_(d['libraries'] == ['foo', 'bar'])\n\n", "description": null, "category": "simple", "imports": ["from __future__ import division, absolute_import, print_function", "import os", "from numpy.distutils.npy_pkg_config import read_config, parse_flags", "from numpy.testing import run_module_suite, temppath, assert_"]}], [{"term": "def", "name": "fwith_tp_del", "data": "\tdef with_tp_del(cls):\n\t\tclass C(object):\n\t\t\tdef __new__(cls, *args, **kwargs):\n\t\t\t\traise TypeError('requires _testcapi.with_tp_del')\n\t\treturn C\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "classNonGCSimpleBase:", "data": "class NonGCSimpleBase:\n\t\"\"\"\n\tThe base class for all the objects under test, equipped with various\n\ttesting features.\n\t\"\"\"\n\n\tsurvivors = []\n\tdel_calls = []\n\ttp_del_calls = []\n\terrors = []\n\n\t_cleaning = False\n\n\t__slots__ = ()\n\n\t@classmethod\n\tdef _cleanup(cls):\n\t\tcls.survivors.clear()\n\t\tcls.errors.clear()\n\t\tgc.garbage.clear()\n\t\tgc.collect()\n\t\tcls.del_calls.clear()\n\t\tcls.tp_del_calls.clear()\n\n\t@classmethod\n\t@contextlib.contextmanager\n\tdef test(cls):\n\t\t\"\"\"\n\t\tA context manager to use around all finalization tests.\n\t\t\"\"\"\n\t\twith support.disable_gc():\n\t\t\tcls.del_calls.clear()\n\t\t\tcls.tp_del_calls.clear()\n\t\t\tNonGCSimpleBase._cleaning = False\n\t\t\ttry:\n\t\t\t\tyield\n\t\t\t\tif cls.errors:\n\t\t\t\t\traise cls.errors[0]\n\t\t\tfinally:\n\t\t\t\tNonGCSimpleBase._cleaning = True\n\t\t\t\tcls._cleanup()\n\n\tdef check_sanity(self):\n\t\t\"\"\"\n\t\tCheck the object is sane (non-broken).\n\t\t\"\"\"\n\n\tdef __del__(self):\n\t\t\"\"\"\n\t\tPEP 442 finalizer.  Record that this was called, check the\n\t\tobject is in a sane state, and invoke a side effect.\n\t\t\"\"\"\n\t\ttry:\n\t\t\tif not self._cleaning:\n\t\t\t\tself.del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\t\t\tself.side_effect()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tA side effect called on destruction.\n\t\t\"\"\"\n\n", "description": "\n\tThe base class for all the objects under test, equipped with various\n\ttesting features.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleBase", "data": "class SimpleBase(NonGCSimpleBase):\n\n\tdef __init__(self):\n\t\tself.id_ = id(self)\n\n\tdef check_sanity(self):\n\t\tassert self.id_ == id(self)\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "NonGC", "data": "class NonGC(NonGCSimpleBase):\n\t__slots__ = ()\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "NonGCResurrector", "data": "class NonGCResurrector(NonGCSimpleBase):\n\t__slots__ = ()\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tResurrect self by storing self in a class-wide list.\n\t\t\"\"\"\n\t\tself.survivors.append(self)\n", "description": "\n\t\tResurrect self by storing self in a class-wide list.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "Simple", "data": "class Simple(SimpleBase):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleResurrector", "data": "class SimpleResurrector(NonGCResurrector, SimpleBase):\n\tpass\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "classTestBase:", "data": "class TestBase:\n\n\tdef setUp(self):\n\t\tself.old_garbage = gc.garbage[:]\n\t\tgc.garbage[:] = []\n\n\tdef tearDown(self):\n\t\t# None of the tests here should put anything in gc.garbage\n\t\ttry:\n\t\t\tself.assertEqual(gc.garbage, [])\n\t\tfinally:\n\t\t\tdel self.old_garbage\n\t\t\tgc.collect()\n\n\tdef assert_del_calls(self, ids):\n\t\tself.assertEqual(sorted(SimpleBase.del_calls), sorted(ids))\n\n\tdef assert_tp_del_calls(self, ids):\n\t\tself.assertEqual(sorted(SimpleBase.tp_del_calls), sorted(ids))\n\n\tdef assert_survivors(self, ids):\n\t\tself.assertEqual(sorted(id(x) for x in SimpleBase.survivors), sorted(ids))\n\n\tdef assert_garbage(self, ids):\n\t\tself.assertEqual(sorted(id(x) for x in gc.garbage), sorted(ids))\n\n\tdef clear_survivors(self):\n\t\tSimpleBase.survivors.clear()\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleFinalizationTest", "data": "class SimpleFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization without refcycles.\n\t\"\"\"\n\n\tdef test_simple(self):\n\t\twith SimpleBase.test():\n\t\t\ts = Simple()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_simple_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = SimpleResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\tself.assertIsNot(wr(), None)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\tself.assertIs(wr(), None)\n\n\tdef test_non_gc(self):\n\t\twith SimpleBase.test():\n\t\t\ts = NonGC()\n\t\t\tself.assertFalse(gc.is_tracked(s))\n\t\t\tids = [id(s)]\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_non_gc_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = NonGCResurrector()\n\t\t\tself.assertFalse(gc.is_tracked(s))\n\t\t\tids = [id(s)]\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids * 2)\n\t\t\tself.assert_survivors(ids)\n\n", "description": "\n\tTest finalization without refcycles.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "classSelfCycleBase:", "data": "class SelfCycleBase:\n\n\tdef __init__(self):\n\t\tsuper().__init__()\n\t\tself.ref = self\n\n\tdef check_sanity(self):\n\t\tsuper().check_sanity()\n\t\tassert self.ref is self\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleSelfCycle", "data": "class SimpleSelfCycle(SelfCycleBase, Simple):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SelfCycleResurrector", "data": "class SelfCycleResurrector(SelfCycleBase, SimpleResurrector):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SuicidalSelfCycle", "data": "class SuicidalSelfCycle(SelfCycleBase, Simple):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tExplicitly break the reference cycle.\n\t\t\"\"\"\n\t\tself.ref = None\n\n", "description": "\n\t\tExplicitly break the reference cycle.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SelfCycleFinalizationTest", "data": "class SelfCycleFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of an object having a single cyclic reference to\n\titself.\n\t\"\"\"\n\n\tdef test_simple(self):\n\t\twith SimpleBase.test():\n\t\t\ts = SimpleSelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_simple_resurrect(self):\n\t\t# Test that __del__ can resurrect the object being finalized.\n\t\twith SimpleBase.test():\n\t\t\ts = SelfCycleResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\t# XXX is this desirable?\n\t\t\tself.assertIs(wr(), None)\n\t\t\t# When trying to destroy the object a second time, __del__\n\t\t\t# isn't called anymore (and the object isn't resurrected).\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\n\tdef test_simple_suicide(self):\n\t\t# Test the GC is able to deal with an object that kills its last\n\t\t# reference during __del__.\n\t\twith SimpleBase.test():\n\t\t\ts = SuicidalSelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\n", "description": "\n\tTest finalization of an object having a single cyclic reference to\n\titself.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "classChainedBase:", "data": "class ChainedBase:\n\n\tdef chain(self, left):\n\t\tself.suicided = False\n\t\tself.left = left\n\t\tleft.right = self\n\n\tdef check_sanity(self):\n\t\tsuper().check_sanity()\n\t\tif self.suicided:\n\t\t\tassert self.left is None\n\t\t\tassert self.right is None\n\t\telse:\n\t\t\tleft = self.left\n\t\t\tif left.suicided:\n\t\t\t\tassert left.right is None\n\t\t\telse:\n\t\t\t\tassert left.right is self\n\t\t\tright = self.right\n\t\t\tif right.suicided:\n\t\t\t\tassert right.left is None\n\t\t\telse:\n\t\t\t\tassert right.left is self\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleChained", "data": "class SimpleChained(ChainedBase, Simple):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "ChainedResurrector", "data": "class ChainedResurrector(ChainedBase, SimpleResurrector):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SuicidalChained", "data": "class SuicidalChained(ChainedBase, Simple):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tExplicitly break the reference cycle.\n\t\t\"\"\"\n\t\tself.suicided = True\n\t\tself.left = None\n\t\tself.right = None\n\n", "description": "\n\t\tExplicitly break the reference cycle.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "CycleChainFinalizationTest", "data": "class CycleChainFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of a cyclic chain.  These tests are similar in\n\tspirit to the self-cycle tests above, but the collectable object\n\tgraph isn't trivial anymore.\n\t\"\"\"\n\n\tdef build_chain(self, classes):\n\t\tnodes = [cls() for cls in classes]\n\t\tfor i in range(len(nodes)):\n\t\t\tnodes[i].chain(nodes[i-1])\n\t\treturn nodes\n\n\tdef check_non_resurrecting_chain(self, classes):\n\t\tN = len(classes)\n\t\twith SimpleBase.test():\n\t\t\tnodes = self.build_chain(classes)\n\t\t\tids = [id(s) for s in nodes]\n\t\t\twrs = [weakref.ref(s) for s in nodes]\n\t\t\tdel nodes\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertEqual([wr() for wr in wrs], [None] * N)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\n\tdef check_resurrecting_chain(self, classes):\n\t\tN = len(classes)\n\t\twith SimpleBase.test():\n\t\t\tnodes = self.build_chain(classes)\n\t\t\tN = len(nodes)\n\t\t\tids = [id(s) for s in nodes]\n\t\t\tsurvivor_ids = [id(s) for s in nodes if isinstance(s, SimpleResurrector)]\n\t\t\twrs = [weakref.ref(s) for s in nodes]\n\t\t\tdel nodes\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(survivor_ids)\n\t\t\t# XXX desirable?\n\t\t\tself.assertEqual([wr() for wr in wrs], [None] * N)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_homogenous(self):\n\t\tself.check_non_resurrecting_chain([SimpleChained] * 3)\n\n\tdef test_homogenous_resurrect(self):\n\t\tself.check_resurrecting_chain([ChainedResurrector] * 3)\n\n\tdef test_homogenous_suicidal(self):\n\t\tself.check_non_resurrecting_chain([SuicidalChained] * 3)\n\n\tdef test_heterogenous_suicidal_one(self):\n\t\tself.check_non_resurrecting_chain([SuicidalChained, SimpleChained] * 2)\n\n\tdef test_heterogenous_suicidal_two(self):\n\t\tself.check_non_resurrecting_chain(\n\t\t\t[SuicidalChained] * 2 + [SimpleChained] * 2)\n\n\tdef test_heterogenous_resurrect_one(self):\n\t\tself.check_resurrecting_chain([ChainedResurrector, SimpleChained] * 2)\n\n\tdef test_heterogenous_resurrect_two(self):\n\t\tself.check_resurrecting_chain(\n\t\t\t[ChainedResurrector, SimpleChained, SuicidalChained] * 2)\n\n\tdef test_heterogenous_resurrect_three(self):\n\t\tself.check_resurrecting_chain(\n\t\t\t[ChainedResurrector] * 2 + [SimpleChained] * 2 + [SuicidalChained] * 2)\n\n", "description": "\n\tTest finalization of a cyclic chain.  These tests are similar in\n\tspirit to the self-cycle tests above, but the collectable object\n\tgraph isn't trivial anymore.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "LegacyBase", "data": "class LegacyBase(SimpleBase):\n\n\tdef __del__(self):\n\t\ttry:\n\t\t\t# Do not invoke side_effect here, since we are now exercising\n\t\t\t# the tp_del slot.\n\t\t\tif not self._cleaning:\n\t\t\t\tself.del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n\n\tdef __tp_del__(self):\n\t\t\"\"\"\n\t\tLegacy (pre-PEP 442) finalizer, mapped to a tp_del slot.\n\t\t\"\"\"\n\t\ttry:\n\t\t\tif not self._cleaning:\n\t\t\t\tself.tp_del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\t\t\tself.side_effect()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n", "description": "\n\t\tLegacy (pre-PEP 442) finalizer, mapped to a tp_del slot.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "Legacy", "data": "class Legacy(LegacyBase):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "LegacyResurrector", "data": "class LegacyResurrector(LegacyBase):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tResurrect self by storing self in a class-wide list.\n\t\t\"\"\"\n\t\tself.survivors.append(self)\n", "description": "\n\t\tResurrect self by storing self in a class-wide list.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "LegacySelfCycle", "data": "class LegacySelfCycle(SelfCycleBase, LegacyBase):\n\tpass\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "LegacyFinalizationTest", "data": "class LegacyFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of objects with a tp_del.\n\t\"\"\"\n\n\tdef tearDown(self):\n\t\t# These tests need to clean up a bit more, since they create\n\t\t# uncollectable objects.\n\t\tgc.garbage.clear()\n\t\tgc.collect()\n\t\tsuper().tearDown()\n\n\tdef test_legacy(self):\n\t\twith SimpleBase.test():\n\t\t\ts = Legacy()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\n\tdef test_legacy_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = LegacyResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\t# weakrefs are cleared before tp_del is called.\n\t\t\tself.assertIs(wr(), None)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids * 2)\n\t\t\tself.assert_survivors(ids)\n\t\tself.assertIs(wr(), None)\n\n\tdef test_legacy_self_cycle(self):\n\t\t# Self-cycles with legacy finalizers end up in gc.garbage.\n\t\twith SimpleBase.test():\n\t\t\ts = LegacySelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls([])\n\t\t\tself.assert_tp_del_calls([])\n\t\t\tself.assert_survivors([])\n\t\t\tself.assert_garbage(ids)\n\t\t\tself.assertIsNot(wr(), None)\n\t\t\t# Break the cycle to allow collection\n\t\t\tgc.garbage[0].ref = None\n\t\tself.assert_garbage([])\n\t\tself.assertIs(wr(), None)\n\n", "description": "\n\tTest finalization of objects with a tp_del.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}], [{"term": "def", "name": "fwith_tp_del", "data": "\tdef with_tp_del(cls):\n\t\tclass C(object):\n\t\t\tdef __new__(cls, *args, **kwargs):\n\t\t\t\traise TypeError('requires _testcapi.with_tp_del')\n\t\treturn C\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "classNonGCSimpleBase:", "data": "class NonGCSimpleBase:\n\t\"\"\"\n\tThe base class for all the objects under test, equipped with various\n\ttesting features.\n\t\"\"\"\n\n\tsurvivors = []\n\tdel_calls = []\n\ttp_del_calls = []\n\terrors = []\n\n\t_cleaning = False\n\n\t__slots__ = ()\n\n\t@classmethod\n\tdef _cleanup(cls):\n\t\tcls.survivors.clear()\n\t\tcls.errors.clear()\n\t\tgc.garbage.clear()\n\t\tgc.collect()\n\t\tcls.del_calls.clear()\n\t\tcls.tp_del_calls.clear()\n\n\t@classmethod\n\t@contextlib.contextmanager\n\tdef test(cls):\n\t\t\"\"\"\n\t\tA context manager to use around all finalization tests.\n\t\t\"\"\"\n\t\twith support.disable_gc():\n\t\t\tcls.del_calls.clear()\n\t\t\tcls.tp_del_calls.clear()\n\t\t\tNonGCSimpleBase._cleaning = False\n\t\t\ttry:\n\t\t\t\tyield\n\t\t\t\tif cls.errors:\n\t\t\t\t\traise cls.errors[0]\n\t\t\tfinally:\n\t\t\t\tNonGCSimpleBase._cleaning = True\n\t\t\t\tcls._cleanup()\n\n\tdef check_sanity(self):\n\t\t\"\"\"\n\t\tCheck the object is sane (non-broken).\n\t\t\"\"\"\n\n\tdef __del__(self):\n\t\t\"\"\"\n\t\tPEP 442 finalizer.  Record that this was called, check the\n\t\tobject is in a sane state, and invoke a side effect.\n\t\t\"\"\"\n\t\ttry:\n\t\t\tif not self._cleaning:\n\t\t\t\tself.del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\t\t\tself.side_effect()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tA side effect called on destruction.\n\t\t\"\"\"\n\n", "description": "\n\tThe base class for all the objects under test, equipped with various\n\ttesting features.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleBase", "data": "class SimpleBase(NonGCSimpleBase):\n\n\tdef __init__(self):\n\t\tself.id_ = id(self)\n\n\tdef check_sanity(self):\n\t\tassert self.id_ == id(self)\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "NonGC", "data": "class NonGC(NonGCSimpleBase):\n\t__slots__ = ()\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "NonGCResurrector", "data": "class NonGCResurrector(NonGCSimpleBase):\n\t__slots__ = ()\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tResurrect self by storing self in a class-wide list.\n\t\t\"\"\"\n\t\tself.survivors.append(self)\n", "description": "\n\t\tResurrect self by storing self in a class-wide list.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "Simple", "data": "class Simple(SimpleBase):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleResurrector", "data": "class SimpleResurrector(NonGCResurrector, SimpleBase):\n\tpass\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "classTestBase:", "data": "class TestBase:\n\n\tdef setUp(self):\n\t\tself.old_garbage = gc.garbage[:]\n\t\tgc.garbage[:] = []\n\n\tdef tearDown(self):\n\t\t# None of the tests here should put anything in gc.garbage\n\t\ttry:\n\t\t\tself.assertEqual(gc.garbage, [])\n\t\tfinally:\n\t\t\tdel self.old_garbage\n\t\t\tgc.collect()\n\n\tdef assert_del_calls(self, ids):\n\t\tself.assertEqual(sorted(SimpleBase.del_calls), sorted(ids))\n\n\tdef assert_tp_del_calls(self, ids):\n\t\tself.assertEqual(sorted(SimpleBase.tp_del_calls), sorted(ids))\n\n\tdef assert_survivors(self, ids):\n\t\tself.assertEqual(sorted(id(x) for x in SimpleBase.survivors), sorted(ids))\n\n\tdef assert_garbage(self, ids):\n\t\tself.assertEqual(sorted(id(x) for x in gc.garbage), sorted(ids))\n\n\tdef clear_survivors(self):\n\t\tSimpleBase.survivors.clear()\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleFinalizationTest", "data": "class SimpleFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization without refcycles.\n\t\"\"\"\n\n\tdef test_simple(self):\n\t\twith SimpleBase.test():\n\t\t\ts = Simple()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_simple_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = SimpleResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\tself.assertIsNot(wr(), None)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\tself.assertIs(wr(), None)\n\n\tdef test_non_gc(self):\n\t\twith SimpleBase.test():\n\t\t\ts = NonGC()\n\t\t\tself.assertFalse(gc.is_tracked(s))\n\t\t\tids = [id(s)]\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_non_gc_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = NonGCResurrector()\n\t\t\tself.assertFalse(gc.is_tracked(s))\n\t\t\tids = [id(s)]\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids * 2)\n\t\t\tself.assert_survivors(ids)\n\n", "description": "\n\tTest finalization without refcycles.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "classSelfCycleBase:", "data": "class SelfCycleBase:\n\n\tdef __init__(self):\n\t\tsuper().__init__()\n\t\tself.ref = self\n\n\tdef check_sanity(self):\n\t\tsuper().check_sanity()\n\t\tassert self.ref is self\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleSelfCycle", "data": "class SimpleSelfCycle(SelfCycleBase, Simple):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SelfCycleResurrector", "data": "class SelfCycleResurrector(SelfCycleBase, SimpleResurrector):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SuicidalSelfCycle", "data": "class SuicidalSelfCycle(SelfCycleBase, Simple):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tExplicitly break the reference cycle.\n\t\t\"\"\"\n\t\tself.ref = None\n\n", "description": "\n\t\tExplicitly break the reference cycle.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SelfCycleFinalizationTest", "data": "class SelfCycleFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of an object having a single cyclic reference to\n\titself.\n\t\"\"\"\n\n\tdef test_simple(self):\n\t\twith SimpleBase.test():\n\t\t\ts = SimpleSelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_simple_resurrect(self):\n\t\t# Test that __del__ can resurrect the object being finalized.\n\t\twith SimpleBase.test():\n\t\t\ts = SelfCycleResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\t# XXX is this desirable?\n\t\t\tself.assertIs(wr(), None)\n\t\t\t# When trying to destroy the object a second time, __del__\n\t\t\t# isn't called anymore (and the object isn't resurrected).\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\n\tdef test_simple_suicide(self):\n\t\t# Test the GC is able to deal with an object that kills its last\n\t\t# reference during __del__.\n\t\twith SimpleBase.test():\n\t\t\ts = SuicidalSelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\n", "description": "\n\tTest finalization of an object having a single cyclic reference to\n\titself.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "classChainedBase:", "data": "class ChainedBase:\n\n\tdef chain(self, left):\n\t\tself.suicided = False\n\t\tself.left = left\n\t\tleft.right = self\n\n\tdef check_sanity(self):\n\t\tsuper().check_sanity()\n\t\tif self.suicided:\n\t\t\tassert self.left is None\n\t\t\tassert self.right is None\n\t\telse:\n\t\t\tleft = self.left\n\t\t\tif left.suicided:\n\t\t\t\tassert left.right is None\n\t\t\telse:\n\t\t\t\tassert left.right is self\n\t\t\tright = self.right\n\t\t\tif right.suicided:\n\t\t\t\tassert right.left is None\n\t\t\telse:\n\t\t\t\tassert right.left is self\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleChained", "data": "class SimpleChained(ChainedBase, Simple):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "ChainedResurrector", "data": "class ChainedResurrector(ChainedBase, SimpleResurrector):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SuicidalChained", "data": "class SuicidalChained(ChainedBase, Simple):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tExplicitly break the reference cycle.\n\t\t\"\"\"\n\t\tself.suicided = True\n\t\tself.left = None\n\t\tself.right = None\n\n", "description": "\n\t\tExplicitly break the reference cycle.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "CycleChainFinalizationTest", "data": "class CycleChainFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of a cyclic chain.  These tests are similar in\n\tspirit to the self-cycle tests above, but the collectable object\n\tgraph isn't trivial anymore.\n\t\"\"\"\n\n\tdef build_chain(self, classes):\n\t\tnodes = [cls() for cls in classes]\n\t\tfor i in range(len(nodes)):\n\t\t\tnodes[i].chain(nodes[i-1])\n\t\treturn nodes\n\n\tdef check_non_resurrecting_chain(self, classes):\n\t\tN = len(classes)\n\t\twith SimpleBase.test():\n\t\t\tnodes = self.build_chain(classes)\n\t\t\tids = [id(s) for s in nodes]\n\t\t\twrs = [weakref.ref(s) for s in nodes]\n\t\t\tdel nodes\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertEqual([wr() for wr in wrs], [None] * N)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\n\tdef check_resurrecting_chain(self, classes):\n\t\tN = len(classes)\n\t\twith SimpleBase.test():\n\t\t\tnodes = self.build_chain(classes)\n\t\t\tN = len(nodes)\n\t\t\tids = [id(s) for s in nodes]\n\t\t\tsurvivor_ids = [id(s) for s in nodes if isinstance(s, SimpleResurrector)]\n\t\t\twrs = [weakref.ref(s) for s in nodes]\n\t\t\tdel nodes\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(survivor_ids)\n\t\t\t# XXX desirable?\n\t\t\tself.assertEqual([wr() for wr in wrs], [None] * N)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_homogenous(self):\n\t\tself.check_non_resurrecting_chain([SimpleChained] * 3)\n\n\tdef test_homogenous_resurrect(self):\n\t\tself.check_resurrecting_chain([ChainedResurrector] * 3)\n\n\tdef test_homogenous_suicidal(self):\n\t\tself.check_non_resurrecting_chain([SuicidalChained] * 3)\n\n\tdef test_heterogenous_suicidal_one(self):\n\t\tself.check_non_resurrecting_chain([SuicidalChained, SimpleChained] * 2)\n\n\tdef test_heterogenous_suicidal_two(self):\n\t\tself.check_non_resurrecting_chain(\n\t\t\t[SuicidalChained] * 2 + [SimpleChained] * 2)\n\n\tdef test_heterogenous_resurrect_one(self):\n\t\tself.check_resurrecting_chain([ChainedResurrector, SimpleChained] * 2)\n\n\tdef test_heterogenous_resurrect_two(self):\n\t\tself.check_resurrecting_chain(\n\t\t\t[ChainedResurrector, SimpleChained, SuicidalChained] * 2)\n\n\tdef test_heterogenous_resurrect_three(self):\n\t\tself.check_resurrecting_chain(\n\t\t\t[ChainedResurrector] * 2 + [SimpleChained] * 2 + [SuicidalChained] * 2)\n\n", "description": "\n\tTest finalization of a cyclic chain.  These tests are similar in\n\tspirit to the self-cycle tests above, but the collectable object\n\tgraph isn't trivial anymore.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "LegacyBase", "data": "class LegacyBase(SimpleBase):\n\n\tdef __del__(self):\n\t\ttry:\n\t\t\t# Do not invoke side_effect here, since we are now exercising\n\t\t\t# the tp_del slot.\n\t\t\tif not self._cleaning:\n\t\t\t\tself.del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n\n\tdef __tp_del__(self):\n\t\t\"\"\"\n\t\tLegacy (pre-PEP 442) finalizer, mapped to a tp_del slot.\n\t\t\"\"\"\n\t\ttry:\n\t\t\tif not self._cleaning:\n\t\t\t\tself.tp_del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\t\t\tself.side_effect()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n", "description": "\n\t\tLegacy (pre-PEP 442) finalizer, mapped to a tp_del slot.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "Legacy", "data": "class Legacy(LegacyBase):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "LegacyResurrector", "data": "class LegacyResurrector(LegacyBase):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tResurrect self by storing self in a class-wide list.\n\t\t\"\"\"\n\t\tself.survivors.append(self)\n", "description": "\n\t\tResurrect self by storing self in a class-wide list.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "LegacySelfCycle", "data": "class LegacySelfCycle(SelfCycleBase, LegacyBase):\n\tpass\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "LegacyFinalizationTest", "data": "class LegacyFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of objects with a tp_del.\n\t\"\"\"\n\n\tdef tearDown(self):\n\t\t# These tests need to clean up a bit more, since they create\n\t\t# uncollectable objects.\n\t\tgc.garbage.clear()\n\t\tgc.collect()\n\t\tsuper().tearDown()\n\n\tdef test_legacy(self):\n\t\twith SimpleBase.test():\n\t\t\ts = Legacy()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\n\tdef test_legacy_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = LegacyResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\t# weakrefs are cleared before tp_del is called.\n\t\t\tself.assertIs(wr(), None)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids * 2)\n\t\t\tself.assert_survivors(ids)\n\t\tself.assertIs(wr(), None)\n\n\tdef test_legacy_self_cycle(self):\n\t\t# Self-cycles with legacy finalizers end up in gc.garbage.\n\t\twith SimpleBase.test():\n\t\t\ts = LegacySelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls([])\n\t\t\tself.assert_tp_del_calls([])\n\t\t\tself.assert_survivors([])\n\t\t\tself.assert_garbage(ids)\n\t\t\tself.assertIsNot(wr(), None)\n\t\t\t# Break the cycle to allow collection\n\t\t\tgc.garbage[0].ref = None\n\t\tself.assert_garbage([])\n\t\tself.assertIs(wr(), None)\n\n", "description": "\n\tTest finalization of objects with a tp_del.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}], [{"term": "def", "name": "createScene", "data": "def createScene(root):\n\t\n\troot.dt = 0.01\n\troot.gravity = [0, -10, 0]\n\t\n\t\t\n\troot.createObject('VisualStyle', name=\"visualStyle1\",  displayFlags=\"hideVisual showBehaviorModels showForceFields showInteractionForceFields showMechanicalMappings\" )\n\n\t\n\troot.createObject('RequiredPlugin', pluginName=\"Compliant\")\n\t#root.createObject('CompliantAttachButton')\n\t\n\t\n\tstiffnessNode = root.createChild(\"stiffness\")\n\t\n\t\n\t\n\t# A SIMPLE SPRING BETWEEN TWO PARTICLES IN THE SAME MECHANICALOBJECT\n\tsimpleNode = stiffnessNode.createChild(\"SimpleForceField\")\n\tsimpleNode.createObject('CompliantImplicitSolver',debug=\"0\" )\n\tsimpleNode.createObject('MinresSolver' )\n\t#simpleNode.createObject('EulerImplicitSolver')\n\t#simpleNode.createObject('CGLinearSolver' )\n\tsimpleNode.createObject('MeshTopology', name=\"mesh\", position=\"0 2 0  1 2 0\", edges=\"0 1\" )\n\tsimpleNode.createObject('MechanicalObject', template=\"Vec3d\", name=\"defoDOF\", showObject=\"1\", showObjectScale=\"0.05\", drawMode=1 )\n\tsimpleNode.createObject('FixedConstraint', indices=\"0\", drawSize=0.07 )\n\tsimpleNode.createObject('UniformMass',  name=\"mass\", mass=\"1\")\n\tsimpleNode.createObject('StiffSpringForceField',  name=\"ff\", spring=\"0 1 1e4 0 1\")\n\t\n\t\n\t# A INTERACTION SPRING BETWEEN TWO PARTICLES IN SEPARATED MECHANICALOBJECTS\n\tmultiNode = stiffnessNode.createChild(\"InteractionForceField\")\n\tmultiNode.createObject('CompliantImplicitSolver',debug=\"0\" )\n\tmultiNode.createObject('MinresSolver' )\n\t#multiNode.createObject('EulerImplicitSolver')\n\t#multiNode.createObject('CGLinearSolver' )\n\t\n\tfirstNode = multiNode.createChild(\"0\")\n\tfirstNode.createObject('MechanicalObject', template=\"Vec3d\", name=\"DOF0\", showObject=\"1\", showObjectScale=\"0.05\", drawMode=1, position=\"0 1 0\" )\n\tfirstNode.createObject('FixedConstraint', indices=\"0\", drawSize=0.07 )\n\tfirstNode.createObject('UniformMass',  name=\"mass\", mass=\"1\")\n\t\n\tsecondNode = multiNode.createChild(\"1\")\n\tsecondNode.createObject('MechanicalObject', template=\"Vec3d\", name=\"DOF1\", showObject=\"1\", showObjectScale=\"0.05\", drawMode=1, position=\"1 1 0\" )\n\tsecondNode.createObject('UniformMass',  name=\"mass\", mass=\"1\")\n\t\n\tmultiNode.createObject('StiffSpringForceField', name=\"iff\", object1=\"@0/DOF0\", object2=\"@1/DOF1\", spring=\"0 0 1e4 0 1\" )\n\t\n\t\n\t\n\t\n\t\n   \n\t\n\t# A SIMPLE DISTANCEMAPPING BETWEEN TWO PARTICLES IN THE SAME MECHANICALOBJECT\n\tsimpleNode = stiffnessNode.createChild(\"DistanceMapping\")\n\tsimpleNode.createObject('CompliantImplicitSolver',debug=\"0\" )\n\tsimpleNode.createObject('MinresSolver' )\n\t#simpleNode.createObject('EulerImplicitSolver')\n\t#simpleNode.createObject('CGLinearSolver' )\n\tsimpleNode.createObject('MeshTopology', name=\"mesh\", position=\"0 0 0  1 0 0\", edges=\"0 1\" )\n\tsimpleNode.createObject('MechanicalObject', template=\"Vec3d\", name=\"defoDOF\", showObject=\"1\", showObjectScale=\"0.05\", drawMode=1 )\n\tsimpleNode.createObject('FixedConstraint', indices=\"0\", drawSize=0.07 )\n\tsimpleNode.createObject('UniformMass',  name=\"mass\", mass=\"1\")\n\tbehaviorNode = simpleNode.createChild(\"behavior\")\n\tbehaviorNode.createObject('MechanicalObject', template=\"Vec1d\",  name=\"extensionsDOF\" )\n\tbehaviorNode.createObject('EdgeSetTopologyContainer', edges=\"@../mesh.edges\" )\n\tbehaviorNode.createObject('DistanceMapping', showObjectScale=\"0.02\"  )\n\tbehaviorNode.createObject('UniformCompliance', name=\"ucomp\" ,template=\"Vec1d\", compliance=1e-4,  isCompliance=0 )\n\t\n\n\n\n\t# A TWO-LAYERS DISTANCEMAPPING BETWEEN TWO PARTICLES IN SEPARATED MECHANICALOBJECTS\n\tmultiNode = stiffnessNode.createChild(\"SubsetMultiMapping+DistanceMapping\")\n\tmultiNode.createObject('CompliantImplicitSolver',debug=\"0\" )\n\tmultiNode.createObject('MinresSolver' )\n\t#multiNode.createObject('EulerImplicitSolver')\n\t#multiNode.createObject('CGLinearSolver' )\n\t\n\tfirstNode = multiNode.createChild(\"0\")\n\tfirstNode.createObject('MechanicalObject', template=\"Vec3d\", name=\"DOF0\", showObject=\"1\", showObjectScale=\"0.05\", drawMode=1, position=\"0 -1 0\" )\n\tfirstNode.createObject('FixedConstraint', indices=\"0\", drawSize=0.07 )\n\tfirstNode.createObject('UniformMass',  name=\"mass\", mass=\"1\")\n\t\n\tsecondNode = multiNode.createChild(\"1\")\n\tsecondNode.createObject('MechanicalObject', template=\"Vec3d\", name=\"DOF1\", showObject=\"1\", showObjectScale=\"0.05\", drawMode=1, position=\"1 -1 0\" )\n\tsecondNode.createObject('UniformMass',  name=\"mass\", mass=\"1\")\n\t\n\tallNode = firstNode.createChild(\"all\")\n\tallNode.createObject('MechanicalObject', template=\"Vec3d\", name=\"allDOF\" )\n\tallNode.createObject('SubsetMultiMapping',  template=\"Vec3d,Vec3d\", input='@../DOF0 @../../1/DOF1', output='@allDOF', indexPairs=\"0 0  1 0\"  )\n\tsecondNode.addChild( allNode )\n\t\n\tbehaviorNode = allNode.createChild(\"behavior\")\n\tbehaviorNode.createObject('MechanicalObject', template=\"Vec1d\",  name=\"extensionsDOF\" )\n\tbehaviorNode.createObject('EdgeSetTopologyContainer', edges=\"0 1\" )\n\tbehaviorNode.createObject('DistanceMapping', showObjectScale=\"0.02\"  )\n\tbehaviorNode.createObject('UniformCompliance', name=\"ucomp\" ,template=\"Vec1d\", compliance=1e-4,  isCompliance=0 )\n\t\n\t\n\t\n\t# A DISTANCEMULTIMAPPING BETWEEN TWO PARTICLES IN SEPARATED MECHANICALOBJECTS\n\tmultiNode = stiffnessNode.createChild(\"DistanceMultiMapping\")\n\tmultiNode.createObject('CompliantImplicitSolver',debug=\"0\" )\n\tmultiNode.createObject('MinresSolver' )\n\t#multiNode.createObject('EulerImplicitSolver')\n\t#multiNode.createObject('CGLinearSolver' )\n\t\n\tfirstNode = multiNode.createChild(\"0\")\n\tfirstNode.createObject('MechanicalObject', template=\"Vec3d\", name=\"DOF0\", showObject=\"1\", showObjectScale=\"0.05\", drawMode=1, position=\"0 -2 0\" )\n\tfirstNode.createObject('FixedConstraint', indices=\"0\", drawSize=0.07 )\n\tfirstNode.createObject('UniformMass',  name=\"mass\", mass=\"1\")\n\t\n\tsecondNode = multiNode.createChild(\"1\")\n\tsecondNode.createObject('MechanicalObject', template=\"Vec3d\", name=\"DOF1\", showObject=\"1\", showObjectScale=\"0.05\", drawMode=1, position=\"1 -2 0\" )\n\tsecondNode.createObject('UniformMass',  name=\"mass\", mass=\"1\")\n\t\n\tbehaviorNode = firstNode.createChild(\"behavior\")\n\tbehaviorNode.createObject('MechanicalObject', template=\"Vec1d\", name=\"extensionsDOF\" )\n\tbehaviorNode.createObject('EdgeSetTopologyContainer', edges=\"0 1\" )\n\tbehaviorNode.createObject('DistanceMultiMapping',  template=\"Vec3d,Vec1d\", input='@../DOF0 @../../1/DOF1', output='@extensionsDOF', indexPairs=\"0 0  1 0\", showObjectScale=\"0.02\"  )\n\tbehaviorNode.createObject('UniformCompliance', name=\"ucomp\" ,template=\"Vec1d\", compliance=1e-4,  isCompliance=0 )\n\tsecondNode.addChild( behaviorNode )\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\tconstraintNode = root.createChild(\"constraint\")\n\t\n\t\n\t\n\t# A SIMPLE SPRING BETWEEN TWO PARTICLES IN THE SAME MECHANICALOBJECT\n\t#simpleNode = constraintNode.createChild(\"SimpleForceField\")\n\t#simpleNode.createObject('CompliantImplicitSolver',debug=\"0\", neglecting_compliance_forces_in_geometric_stiffness=False )\n\t#simpleNode.createObject('MinresSolver' )\n\t##simpleNode.createObject('EulerImplicitSolver')\n\t##simpleNode.createObject('CGLinearSolver' )\n\t#simpleNode.createObject('MeshTopology', name=\"mesh\", position=\"2 2 0  3 2 0\", edges=\"0 1\" )\n\t#simpleNode.createObject('MechanicalObject', template=\"Vec3d\", name=\"defoDOF\", showObject=\"1\", showObjectScale=\"0.05\", drawMode=1 )\n\t#simpleNode.createObject('FixedConstraint', indices=\"0\", drawSize=0.07 )\n\t#simpleNode.createObject('UniformMass',  name=\"mass\", mass=\"1\")\n\t#behaviorNode = simpleNode.createChild(\"behavior\")\n\t#behaviorNode.createObject('MechanicalObject', template=\"Vec3d\",  name=\"constraintDOF\" )\n\t#behaviorNode.createObject('StiffSpringForceField',  name=\"ff\", spring=\"0 1 1e4 0 1\", isCompliance=\"1\")   # getC is not implemented\n\t#behaviorNode.createObject('ConstraintValue')\n\t#behaviorNode.createObject('IdentityMapping')\n\t\n\t# A INTERACTION SPRING BETWEEN TWO PARTICLES IN SEPARATED MECHANICALOBJECTS\n\t# NOT POSSIBLE\n   \n\t\n   \n\t\n\t## A SIMPLE DISTANCEMAPPING BETWEEN TWO PARTICLES IN THE SAME MECHANICALOBJECT\n\tsimpleNode = constraintNode.createChild(\"DistanceMapping\")\n\tsimpleNode.createObject('CompliantImplicitSolver',debug=\"0\", neglecting_compliance_forces_in_geometric_stiffness=False )\n\tsimpleNode.createObject('MinresSolver' )\n\t#simpleNode.createObject('EulerImplicitSolver')\n\t#simpleNode.createObject('CGLinearSolver' )\n\tsimpleNode.createObject('MeshTopology', name=\"mesh\", position=\"2 0 0  3 0 0\", edges=\"0 1\" )\n\tsimpleNode.createObject('MechanicalObject', template=\"Vec3d\", name=\"defoDOF\", showObject=\"1\", showObjectScale=\"0.05\", drawMode=1 )\n\tsimpleNode.createObject('FixedConstraint', indices=\"0\", drawSize=0.07 )\n\tsimpleNode.createObject('UniformMass',  name=\"mass\", mass=\"1\")\n\tbehaviorNode = simpleNode.createChild(\"behavior\")\n\tbehaviorNode.createObject('MechanicalObject', template=\"Vec1d\",  name=\"extensionsDOF\" )\n\tbehaviorNode.createObject('EdgeSetTopologyContainer', edges=\"@../mesh.edges\" )\n\tbehaviorNode.createObject('DistanceMapping', showObjectScale=\"0.02\"  )\n\tbehaviorNode.createObject('UniformCompliance', name=\"ucomp\" ,template=\"Vec1d\", compliance=1e-4,  isCompliance=1 )\n\tbehaviorNode.createObject('ConstraintValue')\n\t\n\n\n\n\t# A TWO-LAYERS DISTANCEMAPPING BETWEEN TWO PARTICLES IN SEPARATED MECHANICALOBJECTS\n\tmultiNode = constraintNode.createChild(\"SubsetMultiMapping+DistanceMapping\")\n\tmultiNode.createObject('CompliantImplicitSolver',debug=\"0\", neglecting_compliance_forces_in_geometric_stiffness=False )\n\tmultiNode.createObject('MinresSolver' )\n\t#multiNode.createObject('EulerImplicitSolver')\n\t#multiNode.createObject('CGLinearSolver' )\n\t\n\tfirstNode = multiNode.createChild(\"0\")\n\tfirstNode.createObject('MechanicalObject', template=\"Vec3d\", name=\"DOF0\", showObject=\"1\", showObjectScale=\"0.05\", drawMode=1, position=\"2 -1 0\" )\n\tfirstNode.createObject('FixedConstraint', indices=\"0\", drawSize=0.07 )\n\tfirstNode.createObject('UniformMass',  name=\"mass\", mass=\"1\")\n\t\n\tsecondNode = multiNode.createChild(\"1\")\n\tsecondNode.createObject('MechanicalObject', template=\"Vec3d\", name=\"DOF1\", showObject=\"1\", showObjectScale=\"0.05\", drawMode=1, position=\"3 -1 0\" )\n\tsecondNode.createObject('UniformMass',  name=\"mass\", mass=\"1\")\n\t\n\tallNode = firstNode.createChild(\"all\")\n\tallNode.createObject('MechanicalObject', template=\"Vec3d\", name=\"allDOF\" )\n\tallNode.createObject('SubsetMultiMapping',  template=\"Vec3d,Vec3d\", input='@../DOF0 @../../1/DOF1', output='@allDOF', indexPairs=\"0 0  1 0\"  )\n\tsecondNode.addChild( allNode )\n\t\n\tbehaviorNode = allNode.createChild(\"behavior\")\n\tbehaviorNode.createObject('MechanicalObject', template=\"Vec1d\",  name=\"extensionsDOF\" )\n\tbehaviorNode.createObject('EdgeSetTopologyContainer', edges=\"0 1\" )\n\tbehaviorNode.createObject('DistanceMapping', showObjectScale=\"0.02\"  )\n\tbehaviorNode.createObject('UniformCompliance', name=\"ucomp\" ,template=\"Vec1d\", compliance=1e-4,  isCompliance=1 )\n\tbehaviorNode.createObject('ConstraintValue')\n\t\n\t\n\t\n\t# A DISTANCEMULTIMAPPING BETWEEN TWO PARTICLES IN SEPARATED MECHANICALOBJECTS\n\tmultiNode = constraintNode.createChild(\"DistanceMultiMapping\")\n\tmultiNode.createObject('CompliantImplicitSolver',debug=\"0\", neglecting_compliance_forces_in_geometric_stiffness=False )\n\tmultiNode.createObject('MinresSolver' )\n\t#multiNode.createObject('EulerImplicitSolver')\n\t#multiNode.createObject('CGLinearSolver' )\n\t\n\tfirstNode = multiNode.createChild(\"0\")\n\tfirstNode.createObject('MechanicalObject', template=\"Vec3d\", name=\"DOF0\", showObject=\"1\", showObjectScale=\"0.05\", drawMode=1, position=\"2 -2 0\" )\n\tfirstNode.createObject('FixedConstraint', indices=\"0\", drawSize=0.07 )\n\tfirstNode.createObject('UniformMass',  name=\"mass\", mass=\"1\")\n\t\n\tsecondNode = multiNode.createChild(\"1\")\n\tsecondNode.createObject('MechanicalObject', template=\"Vec3d\", name=\"DOF1\", showObject=\"1\", showObjectScale=\"0.05\", drawMode=1, position=\"3 -2 0\" )\n\tsecondNode.createObject('UniformMass',  name=\"mass\", mass=\"1\")\n\t\n\tbehaviorNode = firstNode.createChild(\"behavior\")\n\tbehaviorNode.createObject('MechanicalObject', template=\"Vec1d\", name=\"extensionsDOF\" )\n\tbehaviorNode.createObject('EdgeSetTopologyContainer', edges=\"0 1\" )\n\tbehaviorNode.createObject('DistanceMultiMapping',  template=\"Vec3d,Vec1d\", input='@../DOF0 @../../1/DOF1', output='@extensionsDOF', indexPairs=\"0 0  1 0\", showObjectScale=\"0.02\"  )\n\tbehaviorNode.createObject('UniformCompliance', name=\"ucomp\" ,template=\"Vec1d\", compliance=1e-4,  isCompliance=1 )\n\tbehaviorNode.createObject('ConstraintValue')\n\tsecondNode.addChild( behaviorNode )\n", "description": null, "category": "simple", "imports": ["import Sofa", "import sys", "from SofaPython import Tools"]}], [{"term": "def", "name": "fglGetDoublev", "data": "\tdef glGetDoublev( pname ):\n\t\t\"Natural writing of glGetDoublev using standard ctypes\"\n\t\toutput = c_double*sizes.get( pname )\n\t\tresult = output()\n\t\tresult = platform.OpenGL.glGetDoublev( pname, byref(result) )\n", "description": null, "category": "simple", "imports": ["from OpenGL import platform, arrays, error, wrapper, converters", "from OpenGL.raw import GL as simple", "import ctypes"]}, {"term": "def", "name": "addGLGetConstant", "data": "def addGLGetConstant( constant, arraySize ):\n\t\"\"\"Add a glGet* constant to return an output array of correct size\"\"\"\n", "description": "Add a glGet* constant to return an output array of correct size", "category": "simple", "imports": ["from OpenGL import platform, arrays, error, wrapper, converters", "from OpenGL.raw import GL as simple", "import ctypes"]}, {"term": "def", "name": "GL_GET_PIXEL_MAP_SIZE", "data": "def GL_GET_PIXEL_MAP_SIZE( pname ):\n\t\"\"\"Given a pname, lookup the size using a glGet query...\"\"\"\n\tconstant = PIXEL_MAP_SIZE_CONSTANT_MAP[ pname ]\n", "description": "Given a pname, lookup the size using a glGet query...", "category": "simple", "imports": ["from OpenGL import platform, arrays, error, wrapper, converters", "from OpenGL.raw import GL as simple", "import ctypes"]}], [], [], [], [], [], [], [], [{"term": "def", "name": "simple", "data": "def simple():\n\tprint('simple:', a + b)\n\n", "description": null, "category": "simple", "imports": []}, {"term": "def", "name": "simple", "data": "def simple():\n\t# \u041b\u043e\u043a\u0430\u043b\u044c\u043d\u043e\u0435 \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u043e \u0438\u043c\u0435\u043d  \u0438\u043c\u0435\u043d \u043f\u043e\u044f\u0432\u043b\u044f\u0435\u0442\u0441\u044f \u0432 \u043c\u043e\u043c\u0435\u043d\u0442 \u0432\u044b\u0437\u043e\u0432\u0430 \u0444\u0443\u043d\u043a\u0446\u0438\u0438\n\tc, d = 3, 4\n\tprint('simple:', c + d)\n\n", "description": null, "category": "simple", "imports": []}, {"term": "def", "name": "simple_2", "data": "def simple_2():\n\t# \u041b\u043e\u043a\u0430\u043b\u044c\u043d\u043e\u0435 \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u043e \u0438\u043c\u0435\u043d\n\tx, y = 3, 4\n\tprint('simple_2:', x + y)\n\t# print('simple_2:', c + d)\n", "description": null, "category": "simple", "imports": []}, {"term": "def", "name": "simple", "data": "def simple():\n\t# \u041b\u043e\u043a\u0430\u043b\u044c\u043d\u043e\u0435 \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u043e \u0438\u043c\u0435\u043d\n\ta, b = 3, 4\n\tprint('simple:', a + b)\n\n", "description": null, "category": "simple", "imports": []}, {"term": "def", "name": "simple", "data": "def simple():\n\t# \u041b\u043e\u043a\u0430\u043b\u044c\u043d\u043e\u0435 \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u043e \u0438\u043c\u0435\u043d\n\tb = 4\n\tprint('simple:', a + b)\n\n", "description": null, "category": "simple", "imports": []}, {"term": "def", "name": "simple", "data": "def simple():\n\t# \u041b\u043e\u043a\u0430\u043b\u044c\u043d\u043e\u0435 \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u043e \u0438\u043c\u0435\u043d\n\tprint('simple:', a + b)\n\ta = 9\n\tprint('simple:', a + b)\n\n", "description": null, "category": "simple", "imports": []}, {"term": "def", "name": "simple_3", "data": "def simple_3(a, b):\n\tprint('simple:', a + b)\n\n", "description": null, "category": "simple", "imports": []}], [{"term": "class", "name": "SimpleSitemap", "data": "class SimpleSitemap(Sitemap):\n\tchangefreq = \"never\"\n\tpriority = 0.5\n\tlocation = '/location/'\n\tlastmod = datetime.now()\n\n\tdef items(self):\n\t\treturn [object()]\n", "description": null, "category": "simple", "imports": ["from datetime import datetime", "from django.conf.urls import patterns, url", "from django.contrib.sitemaps import Sitemap, GenericSitemap, FlatPageSitemap, views", "from django.contrib.auth.models import User", "from django.views.decorators.cache import cache_page", "from django.contrib.sitemaps.tests.base import TestModel"]}], [{"term": "def", "name": "test_float_to_srt_time_format", "data": "def test_float_to_srt_time_format():\n\tcaption1 = Caption(\n\t\t{\"url\": \"url1\", \"name\": {\"simpleText\": \"name1\"}, \"languageCode\": \"en\", \"vssId\": \".en\"}\n\t)\n\tassert caption1.float_to_srt_time_format(3.89) == \"00:00:03,890\"\n\n", "description": null, "category": "simple", "imports": ["import os", "import pytest", "from unittest import mock", "from unittest.mock import MagicMock, mock_open, patch", "from Py-DL import Caption, CaptionQuery, captions"]}, {"term": "def", "name": "test_caption_query_sequence", "data": "def test_caption_query_sequence():\n\tcaption1 = Caption(\n\t\t{\"url\": \"url1\", \"name\": {\"simpleText\": \"name1\"}, \"languageCode\": \"en\", \"vssId\": \".en\"}\n\t)\n\tcaption2 = Caption(\n\t\t{\"url\": \"url2\", \"name\": {\"simpleText\": \"name2\"}, \"languageCode\": \"fr\", \"vssId\": \".fr\"}\n\t)\n\tcaption_query = CaptionQuery(captions=[caption1, caption2])\n\tassert len(caption_query) == 2\n\tassert caption_query[\"en\"] == caption1\n\tassert caption_query[\"fr\"] == caption2\n\twith pytest.raises(KeyError):\n\t\tassert caption_query[\"nada\"] is not None\n\n", "description": null, "category": "simple", "imports": ["import os", "import pytest", "from unittest import mock", "from unittest.mock import MagicMock, mock_open, patch", "from Py-DL import Caption, CaptionQuery, captions"]}, {"term": "def", "name": "test_caption_query_get_by_language_code_when_exists", "data": "def test_caption_query_get_by_language_code_when_exists():\n\tcaption1 = Caption(\n\t\t{\"url\": \"url1\", \"name\": {\"simpleText\": \"name1\"}, \"languageCode\": \"en\", \"vssId\": \".en\"}\n\t)\n\tcaption2 = Caption(\n\t\t{\"url\": \"url2\", \"name\": {\"simpleText\": \"name2\"}, \"languageCode\": \"fr\", \"vssId\": \".fr\"}\n\t)\n\tcaption_query = CaptionQuery(captions=[caption1, caption2])\n\tassert caption_query[\"en\"] == caption1\n\n", "description": null, "category": "simple", "imports": ["import os", "import pytest", "from unittest import mock", "from unittest.mock import MagicMock, mock_open, patch", "from Py-DL import Caption, CaptionQuery, captions"]}, {"term": "def", "name": "test_caption_query_get_by_language_code_when_not_exists", "data": "def test_caption_query_get_by_language_code_when_not_exists():\n\tcaption1 = Caption(\n\t\t{\"url\": \"url1\", \"name\": {\"simpleText\": \"name1\"}, \"languageCode\": \"en\", \"vssId\": \".en\"}\n\t)\n\tcaption2 = Caption(\n\t\t{\"url\": \"url2\", \"name\": {\"simpleText\": \"name2\"}, \"languageCode\": \"fr\", \"vssId\": \".fr\"}\n\t)\n\tcaption_query = CaptionQuery(captions=[caption1, caption2])\n\twith pytest.raises(KeyError):\n\t\tassert caption_query[\"hello\"] is not None\n\t\t# assert not_found is not None  # should never reach here\n\n", "description": null, "category": "simple", "imports": ["import os", "import pytest", "from unittest import mock", "from unittest.mock import MagicMock, mock_open, patch", "from Py-DL import Caption, CaptionQuery, captions"]}, {"term": "def", "name": "test_download", "data": "def test_download(srt):\n\topen_mock = mock_open()\n\twith patch(\"builtins.open\", open_mock):\n\t\tsrt.return_value = \"\"\n\t\tcaption = Caption(\n\t\t\t{\n\t\t\t\t\"url\": \"url1\",\n\t\t\t\t\"name\": {\"simpleText\": \"name1\"},\n\t\t\t\t\"languageCode\": \"en\",\n\t\t\t\t\"vssId\": \".en\"\n\t\t\t}\n\t\t)\n\t\tcaption.download(\"title\")\n\t\tassert (\n\t\t\topen_mock.call_args_list[0][0][0].split(os.path.sep)[-1] == \"title (en).srt\"\n\t\t)\n\n", "description": null, "category": "simple", "imports": ["import os", "import pytest", "from unittest import mock", "from unittest.mock import MagicMock, mock_open, patch", "from Py-DL import Caption, CaptionQuery, captions"]}, {"term": "def", "name": "test_download_with_prefix", "data": "def test_download_with_prefix(srt):\n\topen_mock = mock_open()\n\twith patch(\"builtins.open\", open_mock):\n\t\tsrt.return_value = \"\"\n\t\tcaption = Caption(\n\t\t\t{\n\t\t\t\t\"url\": \"url1\",\n\t\t\t\t\"name\": {\"simpleText\": \"name1\"},\n\t\t\t\t\"languageCode\": \"en\",\n\t\t\t\t\"vssId\": \".en\"\n\t\t\t}\n\t\t)\n\t\tcaption.download(\"title\", filename_prefix=\"1 \")\n\t\tassert (\n\t\t\topen_mock.call_args_list[0][0][0].split(os.path.sep)[-1]\n\t\t\t== \"1 title (en).srt\"\n\t\t)\n\n", "description": null, "category": "simple", "imports": ["import os", "import pytest", "from unittest import mock", "from unittest.mock import MagicMock, mock_open, patch", "from Py-DL import Caption, CaptionQuery, captions"]}, {"term": "def", "name": "test_download_with_output_path", "data": "def test_download_with_output_path(srt):\n\topen_mock = mock_open()\n\tcaptions.target_directory = MagicMock(return_value=\"/target\")\n\twith patch(\"builtins.open\", open_mock):\n\t\tsrt.return_value = \"\"\n\t\tcaption = Caption(\n\t\t\t{\n\t\t\t\t\"url\": \"url1\",\n\t\t\t\t\"name\": {\"simpleText\": \"name1\"},\n\t\t\t\t\"languageCode\": \"en\",\n\t\t\t\t\"vssId\": \".en\"\n\t\t\t}\n\t\t)\n\t\tfile_path = caption.download(\"title\", output_path=\"blah\")\n\t\tassert file_path == os.path.join(\"/target\",\"title (en).srt\")\n\t\tcaptions.target_directory.assert_called_with(\"blah\")\n\n", "description": null, "category": "simple", "imports": ["import os", "import pytest", "from unittest import mock", "from unittest.mock import MagicMock, mock_open, patch", "from Py-DL import Caption, CaptionQuery, captions"]}, {"term": "def", "name": "test_download_xml_and_trim_extension", "data": "def test_download_xml_and_trim_extension(xml):\n\topen_mock = mock_open()\n\twith patch(\"builtins.open\", open_mock):\n\t\txml.return_value = \"\"\n\t\tcaption = Caption(\n\t\t\t{\n\t\t\t\t\"url\": \"url1\",\n\t\t\t\t\"name\": {\"simpleText\": \"name1\"},\n\t\t\t\t\"languageCode\": \"en\",\n\t\t\t\t\"vssId\": \".en\"\n\t\t\t}\n\t\t)\n\t\tcaption.download(\"title.xml\", srt=False)\n\t\tassert (\n\t\t\topen_mock.call_args_list[0][0][0].split(os.path.sep)[-1] == \"title (en).xml\"\n\t\t)\n\n", "description": null, "category": "simple", "imports": ["import os", "import pytest", "from unittest import mock", "from unittest.mock import MagicMock, mock_open, patch", "from Py-DL import Caption, CaptionQuery, captions"]}, {"term": "def", "name": "test_repr", "data": "def test_repr():\n\tcaption = Caption(\n\t\t{\"url\": \"url1\", \"name\": {\"simpleText\": \"name1\"}, \"languageCode\": \"en\", \"vssId\": \".en\"}\n\t)\n\tassert str(caption) == ''\n\n\tcaption_query = CaptionQuery(captions=[caption])\n\tassert repr(caption_query) == '{\\'en\\': }'\n\n", "description": null, "category": "simple", "imports": ["import os", "import pytest", "from unittest import mock", "from unittest.mock import MagicMock, mock_open, patch", "from Py-DL import Caption, CaptionQuery, captions"]}, {"term": "def", "name": "test_xml_captions", "data": "def test_xml_captions(request_get):\n\trequest_get.return_value = \"test\"\n\tcaption = Caption(\n\t\t{\"url\": \"url1\", \"name\": {\"simpleText\": \"name1\"}, \"languageCode\": \"en\", \"vssId\": \".en\"}\n\t)\n\tassert caption.xml_captions == \"test\"\n\n", "description": null, "category": "simple", "imports": ["import os", "import pytest", "from unittest import mock", "from unittest.mock import MagicMock, mock_open, patch", "from Py-DL import Caption, CaptionQuery, captions"]}, {"term": "def", "name": "test_generate_srt_captions", "data": "def test_generate_srt_captions(request):\n\trequest.get.return_value = (\n\t\t'['\n\t\t'Herb, Software Engineer]\\n\u672c\u5f71\u7247\u5305\u542b\u96b1\u85cf\u5f0f\u5b57\u5e55\u3002'\n\t\t\"\u5982\u8981\u5553\u52d5\u5b57\u5e55\uff0c\u8acb\u6309\u4e00\u4e0b\u9019\u88e1\u7684\u5716\u793a\u3002\"\n\t)\n\tcaption = Caption(\n\t\t{\"url\": \"url1\", \"name\": {\"simpleText\": \"name1\"}, \"languageCode\": \"en\", \"vssId\": \".en\"}\n\t)\n\tassert caption.generate_srt_captions() == (\n\t\t\"1\\n\"\n\t\t\"00:00:06,500 --> 00:00:08,200\\n\"\n\t\t\"[Herb, Software Engineer] \u672c\u5f71\u7247\u5305\u542b\u96b1\u85cf\u5f0f\u5b57\u5e55\u3002\\n\"\n\t\t\"\\n\"\n\t\t\"2\\n\"\n\t\t\"00:00:08,300 --> 00:00:11,000\\n\"\n\t\t\"\u5982\u8981\u5553\u52d5\u5b57\u5e55\uff0c\u8acb\u6309\u4e00\u4e0b\u9019\u88e1\u7684\u5716\u793a\u3002\"\n\t)\n", "description": null, "category": "simple", "imports": ["import os", "import pytest", "from unittest import mock", "from unittest.mock import MagicMock, mock_open, patch", "from Py-DL import Caption, CaptionQuery, captions"]}], [{"term": "def", "name": "in_tree", "data": "def in_tree(response, name, uclass, drv, depth, last_child):\n\tlines = [x.strip() for x in response.splitlines()]\n\tleaf = ' ' * 4 * depth;\n\tif not last_child:\n\t\tleaf = leaf + '\\|'\n\telse:\n\t\tleaf = leaf + '`'\n\tleaf = leaf + '-- ' + name\n\tline = ' *{:10.10}  [0-9]*  \\[ [ +] \\]   {:10.10}  {}$'.format(uclass, drv,leaf)\n\tprog = re.compile(line)\n\tfor l in lines:\n\t\tif prog.match(l):\n\t\t\treturn True\n\treturn False\n\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}, {"term": "def", "name": "test_bind_unbind_with_node", "data": "def test_bind_unbind_with_node(u_boot_console):\n\n\t#bind /bind-test. Device should come up as well as its children\n\tresponse = u_boot_console.run_command(\"bind  /bind-test generic_simple_bus\")\n\tassert response == ''\n\ttree = u_boot_console.run_command(\"dm tree\")\n\tassert in_tree(tree, \"bind-test\", \"simple_bus\", \"generic_simple\", 0, True)\n\tassert in_tree(tree, \"bind-test-child1\", \"phy\", \"phy_sandbox\", 1, False)\n\tassert in_tree(tree, \"bind-test-child2\", \"simple_bus\", \"generic_simple\", 1, True)\n\n\t#Unbind child #1. No error expected and all devices should be there except for bind-test-child1\n\tresponse = u_boot_console.run_command(\"unbind  /bind-test/bind-test-child1\")\n\tassert response == ''\n\ttree = u_boot_console.run_command(\"dm tree\")\n\tassert in_tree(tree, \"bind-test\", \"simple_bus\", \"generic_simple\", 0, True)\n\tassert \"bind-test-child1\" not in tree\n\tassert in_tree(tree, \"bind-test-child2\", \"simple_bus\", \"generic_simple\", 1, True)\n\n\t#bind child #1. No error expected and all devices should be there\n\tresponse = u_boot_console.run_command(\"bind  /bind-test/bind-test-child1 phy_sandbox\")\n\tassert response == ''\n\ttree = u_boot_console.run_command(\"dm tree\")\n\tassert in_tree(tree, \"bind-test\", \"simple_bus\", \"generic_simple\", 0, True)\n\tassert in_tree(tree, \"bind-test-child1\", \"phy\", \"phy_sandbox\", 1, True)\n\tassert in_tree(tree, \"bind-test-child2\", \"simple_bus\", \"generic_simple\", 1, False)\n\n\t#Unbind child #2. No error expected and all devices should be there except for bind-test-child2\n\tresponse = u_boot_console.run_command(\"unbind  /bind-test/bind-test-child2\")\n\tassert response == ''\n\ttree = u_boot_console.run_command(\"dm tree\")\n\tassert in_tree(tree, \"bind-test\", \"simple_bus\", \"generic_simple\", 0, True)\n\tassert in_tree(tree, \"bind-test-child1\", \"phy\", \"phy_sandbox\", 1, True)\n\tassert \"bind-test-child2\" not in tree\n\n\n\t#Bind child #2. No error expected and all devices should be there\n\tresponse = u_boot_console.run_command(\"bind /bind-test/bind-test-child2 generic_simple_bus\")\n\tassert response == ''\n\ttree = u_boot_console.run_command(\"dm tree\")\n\tassert in_tree(tree, \"bind-test\", \"simple_bus\", \"generic_simple\", 0, True)\n\tassert in_tree(tree, \"bind-test-child1\", \"phy\", \"phy_sandbox\", 1, False)\n\tassert in_tree(tree, \"bind-test-child2\", \"simple_bus\", \"generic_simple\", 1, True)\n\n\t#Unbind parent. No error expected. All devices should be removed and unbound\n\tresponse = u_boot_console.run_command(\"unbind  /bind-test\")\n\tassert response == ''\n\ttree = u_boot_console.run_command(\"dm tree\")\n\tassert \"bind-test\" not in tree\n\tassert \"bind-test-child1\" not in tree\n\tassert \"bind-test-child2\" not in tree\n\n\t#try binding invalid node with valid driver\n\tresponse = u_boot_console.run_command(\"bind  /not-a-valid-node generic_simple_bus\")\n\tassert response != ''\n\ttree = u_boot_console.run_command(\"dm tree\")\n\tassert \"not-a-valid-node\" not in tree\n\n\t#try binding valid node with invalid driver\n\tresponse = u_boot_console.run_command(\"bind  /bind-test not_a_driver\")\n\tassert response != ''\n\ttree = u_boot_console.run_command(\"dm tree\")\n\tassert \"bind-test\" not in tree\n\n\t#bind /bind-test. Device should come up as well as its children\n\tresponse = u_boot_console.run_command(\"bind  /bind-test generic_simple_bus\")\n\tassert response == ''\n\ttree = u_boot_console.run_command(\"dm tree\")\n\tassert in_tree(tree, \"bind-test\", \"simple_bus\", \"generic_simple\", 0, True)\n\tassert in_tree(tree, \"bind-test-child1\", \"phy\", \"phy_sandbox\", 1, False)\n\tassert in_tree(tree, \"bind-test-child2\", \"simple_bus\", \"generic_simple\", 1, True)\n\n\tresponse = u_boot_console.run_command(\"unbind  /bind-test\")\n\tassert response == ''\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}, {"term": "def", "name": "get_next_line", "data": "def get_next_line(tree, name):\n\ttreelines = [x.strip() for x in tree.splitlines() if x.strip()]\n\tchild_line = \"\"\n\tfor idx, line in enumerate(treelines):\n\t\tif (\"-- \" + name) in line:\n\t\t\ttry:\n\t\t\t\tchild_line = treelines[idx+1]\n\t\t\texcept:\n\t\t\t\tpass\n\t\t\tbreak\n\treturn child_line\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}, {"term": "def", "name": "test_bind_unbind_with_uclass", "data": "def test_bind_unbind_with_uclass(u_boot_console):\n\t#bind /bind-test\n\tresponse = u_boot_console.run_command(\"bind  /bind-test generic_simple_bus\")\n\tassert response == ''\n\n\t#make sure bind-test-child2 is there and get its uclass/index pair\n\ttree = u_boot_console.run_command(\"dm tree\")\n\tchild2_line = [x.strip() for x in tree.splitlines() if \"-- bind-test-child2\" in x]\n\tassert len(child2_line) == 1\n\n\tchild2_uclass = child2_line[0].split()[0]\n\tchild2_index = int(child2_line[0].split()[1])\n\n\t#bind generic_simple_bus as a child of bind-test-child2\n\tresponse = u_boot_console.run_command(\"bind  {} {} generic_simple_bus\".format(child2_uclass, child2_index, \"generic_simple_bus\"))\n\n\t#check that the child is there and its uclass/index pair is right\n\ttree = u_boot_console.run_command(\"dm tree\")\n\n\tchild_of_child2_line = get_next_line(tree, \"bind-test-child2\")\n\tassert child_of_child2_line\n\tchild_of_child2_index = int(child_of_child2_line.split()[1])\n\tassert in_tree(tree, \"generic_simple_bus\", \"simple_bus\", \"generic_simple_bus\", 2, True)\n\tassert child_of_child2_index == child2_index + 1\n\n\t#unbind the child and check it has been removed\n\tresponse = u_boot_console.run_command(\"unbind  simple_bus {}\".format(child_of_child2_index))\n\tassert response == ''\n\ttree = u_boot_console.run_command(\"dm tree\")\n\tassert in_tree(tree, \"bind-test-child2\", \"simple_bus\", \"generic_simple\", 1, True)\n\tassert not in_tree(tree, \"generic_simple_bus\", \"simple_bus\", \"generic_simple_bus\", 2, True)\n\tchild_of_child2_line = get_next_line(tree, \"bind-test-child2\")\n\tassert child_of_child2_line == \"\"\n\n\t#bind generic_simple_bus as a child of bind-test-child2\n\tresponse = u_boot_console.run_command(\"bind  {} {} generic_simple_bus\".format(child2_uclass, child2_index, \"generic_simple_bus\"))\n\n\t#check that the child is there and its uclass/index pair is right\n\ttree = u_boot_console.run_command(\"dm tree\")\n\ttreelines = [x.strip() for x in tree.splitlines() if x.strip()]\n\n\tchild_of_child2_line = get_next_line(tree, \"bind-test-child2\")\n\tassert child_of_child2_line\n\tchild_of_child2_index = int(child_of_child2_line.split()[1])\n\tassert in_tree(tree, \"generic_simple_bus\", \"simple_bus\", \"generic_simple_bus\", 2, True)\n\tassert child_of_child2_index == child2_index + 1\n\n\t#unbind the child and check it has been removed\n\tresponse = u_boot_console.run_command(\"unbind  {} {} generic_simple_bus\".format(child2_uclass, child2_index, \"generic_simple_bus\"))\n\tassert response == ''\n\n\ttree = u_boot_console.run_command(\"dm tree\")\n\tassert in_tree(tree, \"bind-test-child2\", \"simple_bus\", \"generic_simple\", 1, True)\n\n\tchild_of_child2_line = get_next_line(tree, \"bind-test-child2\")\n\tassert child_of_child2_line == \"\"\n\n\t#unbind the child again and check it doesn't change the tree\n\ttree_old = u_boot_console.run_command(\"dm tree\")\n\tresponse = u_boot_console.run_command(\"unbind  {} {} generic_simple_bus\".format(child2_uclass, child2_index, \"generic_simple_bus\"))\n\ttree_new = u_boot_console.run_command(\"dm tree\")\n\n\tassert response == ''\n\tassert tree_old == tree_new\n\n\tresponse = u_boot_console.run_command(\"unbind  /bind-test\")\n\tassert response == ''\n", "description": null, "category": "simple", "imports": ["import os.path", "import pytest", "import re"]}], [{"term": "def", "name": "parseFeedback", "data": "def parseFeedback( buffer, entryCount ):\n\t\"\"\"Parse the feedback buffer into Python object records\"\"\"\n\tbufferIndex = 0\n\tresult = []\n\tgetVertex = createGetVertex( )\n\twhile bufferIndex < entryCount:\n\t\ttoken = int(buffer[bufferIndex])\n\t\tbufferIndex += 1\n\t\tif token in SINGLE_VERTEX_TOKENS:\n\t\t\tvData, bufferIndex = getVertex( buffer, bufferIndex )\n\t\t\tresult.append( (SINGLE_VERTEX_TOKENS.get(token), Vertex(*vData)) )\n\t\telif token in DOUBLE_VERTEX_TOKENS:\n\t\t\tvData, bufferIndex = getVertex( buffer, bufferIndex )\n\t\t\tvData2, bufferIndex = getVertex( buffer, bufferIndex )\n\t\t\tresult.append( (\n\t\t\t\tDOUBLE_VERTEX_TOKENS.get(token), \n\t\t\t\tVertex(*vData),\n\t\t\t\tVertex(*vData2),\n\t\t\t) )\n\t\telif token == _simple.GL_PASS_THROUGH_TOKEN:\n\t\t\tresult.append( (_simple.GL_PASS_THROUGH_TOKEN, buffer[bufferIndex]))\n\t\t\tbufferIndex += 1\n\t\telif token == _simple.GL_POLYGON_TOKEN:\n\t\t\ttemp = [_simple.GL_POLYGON_TOKEN]\n\t\t\tcount = int(buffer[bufferIndex])\n\t\t\tbufferIndex += 1\n\t\t\tfor item in range(count):\n\t\t\t\tvData,bufferIndex = getVertex( buffer, bufferIndex )\n\t\t\t\ttemp.append( Vertex(*vData))\n\t\t\tresult.append( tuple(temp))\n\t\telse:\n\t\t\traise ValueError( \n\t\t\t\t\"\"\"Unrecognised token %r in feedback stream\"\"\"%(token,)\n\t\t\t)\n\treturn result\n", "description": "Parse the feedback buffer into Python object records", "category": "simple", "imports": ["from OpenGL import contextdata", "from OpenGL.GL.VERSION import GL_1_1 as _simple"]}, {"term": "class", "name": "Vertex", "data": "class Vertex( object ):\n\t\"\"\"Simplistic holder for vertex data from a feedback buffer\"\"\"\n\t__slots__ = ('vertex','color','texture')\n\tdef __init__( self, vertex,color=None,texture=None):\n\t\t\"\"\"Store values for access\"\"\"\n\t\tself.vertex = vertex \n\t\tself.color = color \n", "description": "Simplistic holder for vertex data from a feedback buffer", "category": "simple", "imports": ["from OpenGL import contextdata", "from OpenGL.GL.VERSION import GL_1_1 as _simple"]}, {"term": "def", "name": "createGetVertex", "data": "def createGetVertex( ):\n\tmode = contextdata.getValue( \"GL_FEEDBACK_BUFFER_TYPE\" )\n\tindexMode = _simple.glGetBooleanv( _simple.GL_INDEX_MODE )\n\tcolorSize = [ 4,1 ][ int(indexMode) ]\n\tif mode in (_simple.GL_2D,_simple.GL_3D):\n\t\tif mode == _simple.GL_2D:\n\t\t\tsize = 2\n\t\telse:\n\t\t\tsize = 3\n\t\tdef getVertex( buffer, bufferIndex ):\n\t\t\tend = bufferIndex+size\n\t\t\treturn (buffer[bufferIndex:end],None,None),end \n\telif mode == _simple.GL_3D_COLOR:\n\t\tdef getVertex( buffer, bufferIndex ):\n\t\t\tend = bufferIndex+3\n\t\t\tcolorEnd = end + colorSize\n\t\t\treturn (buffer[bufferIndex:end],buffer[end:colorEnd],None),colorEnd \n\telse:\n\t\tif mode == _simple.GL_3D_COLOR_TEXTURE:\n\t\t\tsize = 3\n\t\telse:\n\t\t\tsize = 4\n\t\tdef getVertex( buffer, bufferIndex ):\n\t\t\tend = bufferIndex+size\n\t\t\tcolorEnd = end + colorSize\n\t\t\ttextureEnd = colorEnd + 4\n\t\t\treturn (buffer[bufferIndex:end],buffer[end:colorEnd],buffer[colorEnd:textureEnd]),textureEnd\n\treturn getVertex\n", "description": null, "category": "simple", "imports": ["from OpenGL import contextdata", "from OpenGL.GL.VERSION import GL_1_1 as _simple"]}], [{"term": "class", "name": "SimpleSitemap", "data": "class SimpleSitemap(Sitemap):\n\tchangefreq = \"never\"\n\tpriority = 0.5\n\tlocation = '/location/'\n\tlastmod = datetime.now()\n\n\tdef items(self):\n\t\treturn [object()]\n\n", "description": null, "category": "simple", "imports": ["from datetime import date, datetime", "from django.conf.urls import url", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import (", "from django.http import HttpResponse", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "SimpleI18nSitemap", "data": "class SimpleI18nSitemap(Sitemap):\n\tchangefreq = \"never\"\n\tpriority = 0.5\n\ti18n = True\n\n\tdef items(self):\n\t\treturn I18nTestModel.objects.all()\n\n", "description": null, "category": "simple", "imports": ["from datetime import date, datetime", "from django.conf.urls import url", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import (", "from django.http import HttpResponse", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "EmptySitemap", "data": "class EmptySitemap(Sitemap):\n\tchangefreq = \"never\"\n\tpriority = 0.5\n\tlocation = '/location/'\n\n\tdef items(self):\n\t\treturn []\n\n", "description": null, "category": "simple", "imports": ["from datetime import date, datetime", "from django.conf.urls import url", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import (", "from django.http import HttpResponse", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "FixedLastmodSitemap", "data": "class FixedLastmodSitemap(SimpleSitemap):\n\tlastmod = datetime(2013, 3, 13, 10, 0, 0)\n\n", "description": null, "category": "simple", "imports": ["from datetime import date, datetime", "from django.conf.urls import url", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import (", "from django.http import HttpResponse", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "FixedLastmodMixedSitemap", "data": "class FixedLastmodMixedSitemap(Sitemap):\n\tchangefreq = \"never\"\n\tpriority = 0.5\n\tlocation = '/location/'\n\tloop = 0\n\n\tdef items(self):\n\t\to1 = TestModel()\n\t\to1.lastmod = datetime(2013, 3, 13, 10, 0, 0)\n\t\to2 = TestModel()\n\t\treturn [o1, o2]\n\n", "description": null, "category": "simple", "imports": ["from datetime import date, datetime", "from django.conf.urls import url", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import (", "from django.http import HttpResponse", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "DateSiteMap", "data": "class DateSiteMap(SimpleSitemap):\n\tlastmod = date(2013, 3, 13)\n\n", "description": null, "category": "simple", "imports": ["from datetime import date, datetime", "from django.conf.urls import url", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import (", "from django.http import HttpResponse", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "TimezoneSiteMap", "data": "class TimezoneSiteMap(SimpleSitemap):\n\tlastmod = datetime(2013, 3, 13, 10, 0, 0, tzinfo=timezone.get_fixed_timezone(-300))\n\n", "description": null, "category": "simple", "imports": ["from datetime import date, datetime", "from django.conf.urls import url", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import (", "from django.http import HttpResponse", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "def", "name": "testmodelview", "data": "def testmodelview(request, id):\n\treturn HttpResponse()\n\n", "description": null, "category": "simple", "imports": ["from datetime import date, datetime", "from django.conf.urls import url", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import (", "from django.http import HttpResponse", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}], [{"term": "def", "name": "glVertexPointerd", "data": "def glVertexPointerd( array ):\n\t\"Natural writing of glVertexPointerd using standard ctypes\"\n\targ2 = GL_DOUBLE\n\targ3 = 0 # stride\n\targ4 = arrays.asArray(array, GL_DOUBLE)\n\targ1 = arrays.arraySize( arg4, 'd' )\n\tplatform.PLATFORM.GL.glVertexPointer( arg1, arg2, arg3, arrays.ArrayDatatype.dataPointer(arg4) )\n\t# only store if we successfully set the value...\n\tstoredPointers[ GL_VERTEX_ARRAY ] = arg4\n", "description": null, "category": "simple", "imports": ["from OpenGL import platform, error, wrapper, contextdata, converters, constant", "from OpenGL.arrays import arrayhelpers, arraydatatype", "from OpenGL.raw.GL.VERSION import GL_1_1 as _simple", "import ctypes", "\tfrom OpenGL.GL import glGetIntegerv", "\tfrom OpenGL.GL import selection, feedback"]}, {"term": "def", "name": "wrapPointerFunction", "data": "def wrapPointerFunction( name, baseFunction, glType, arrayType,startArgs, defaultSize ):\n\t\"\"\"Wrap the given pointer-setting function\"\"\"\n\tfunction= wrapper.wrapper( baseFunction )\n\tif 'ptr' in baseFunction.argNames:\n\t\tpointer_name = 'ptr'\n\telse:\n\t\tpointer_name = 'pointer'\n\tassert not getattr( function, 'pyConverters', None ), \"\"\"Reusing wrappers?\"\"\"\n\tif arrayType:\n\t\tarrayModuleType = arraydatatype.GL_CONSTANT_TO_ARRAY_TYPE[ glType ]\n\t\tfunction.setPyConverter( pointer_name, arrayhelpers.asArrayType(arrayModuleType) )\n\telse:\n\t\tfunction.setPyConverter( pointer_name, arrayhelpers.AsArrayOfType(pointer_name,'type') )\n\tfunction.setCConverter( pointer_name, converters.getPyArgsName( pointer_name ) )\n\tif 'size' in function.argNames:\n\t\tfunction.setPyConverter( 'size' )\n\t\tfunction.setCConverter( 'size', arrayhelpers.arraySizeOfFirstType(arrayModuleType,defaultSize) )\n\tif 'type' in function.argNames:\n\t\tfunction.setPyConverter( 'type' )\n\t\tfunction.setCConverter( 'type', glType )\n\tif 'stride' in function.argNames:\n\t\tfunction.setPyConverter( 'stride' )\n\t\tfunction.setCConverter( 'stride', 0 )\n\tfunction.setStoreValues( arrayhelpers.storePointerType( pointer_name, arrayType ) )\n\tfunction.setReturnValues( wrapper.returnPyArgument( pointer_name ) )\n\treturn name,function\n\n\n", "description": "Wrap the given pointer-setting function", "category": "simple", "imports": ["from OpenGL import platform, error, wrapper, contextdata, converters, constant", "from OpenGL.arrays import arrayhelpers, arraydatatype", "from OpenGL.raw.GL.VERSION import GL_1_1 as _simple", "import ctypes", "\tfrom OpenGL.GL import glGetIntegerv", "\tfrom OpenGL.GL import selection, feedback"]}, {"term": "def", "name": "glDrawElementsTyped", "data": "def glDrawElementsTyped( type, suffix ):\n\tarrayType = arraydatatype.GL_CONSTANT_TO_ARRAY_TYPE[ type ]\n\tfunction = wrapper.wrapper(\n\t\t_simple.glDrawElements\n\t).setPyConverter('type').setCConverter(\n\t\t'type', type\n\t).setPyConverter('count').setCConverter(\n\t\t'count', arrayhelpers.AsArrayTypedSize( 'indices', arrayType ),\n\t).setPyConverter(\n\t\t'indices', arrayhelpers.AsArrayTyped( 'indices', arrayType ),\n\t).setReturnValues(\n\t\twrapper.returnPyArgument( 'indices' )\n\t)\n", "description": null, "category": "simple", "imports": ["from OpenGL import platform, error, wrapper, contextdata, converters, constant", "from OpenGL.arrays import arrayhelpers, arraydatatype", "from OpenGL.raw.GL.VERSION import GL_1_1 as _simple", "import ctypes", "\tfrom OpenGL.GL import glGetIntegerv", "\tfrom OpenGL.GL import selection, feedback"]}, {"term": "def", "name": "glSelectBuffer", "data": "def glSelectBuffer( size, buffer = None ):\n\t\"\"\"Create a selection buffer of the given size\n\t\"\"\"\n\tif buffer is None:\n\t\tbuffer = arraydatatype.GLuintArray.zeros( (size,) )\n\t_simple.glSelectBuffer( size, buffer )\n\tcontextdata.setValue( _simple.GL_SELECTION_BUFFER_POINTER, buffer )\n", "description": "Create a selection buffer of the given size\n\t", "category": "simple", "imports": ["from OpenGL import platform, error, wrapper, contextdata, converters, constant", "from OpenGL.arrays import arrayhelpers, arraydatatype", "from OpenGL.raw.GL.VERSION import GL_1_1 as _simple", "import ctypes", "\tfrom OpenGL.GL import glGetIntegerv", "\tfrom OpenGL.GL import selection, feedback"]}, {"term": "def", "name": "glFeedbackBuffer", "data": "def glFeedbackBuffer( size, type, buffer = None ):\n\t\"\"\"Create a selection buffer of the given size\n\t\"\"\"\n\tif buffer is None:\n\t\tbuffer = arraydatatype.GLfloatArray.zeros( (size,) )\n\t_simple.glFeedbackBuffer( size, type, buffer )\n\tcontextdata.setValue( _simple.GL_FEEDBACK_BUFFER_POINTER, buffer )\n\tcontextdata.setValue( \"GL_FEEDBACK_BUFFER_TYPE\", type )\n\treturn buffer\n", "description": "Create a selection buffer of the given size\n\t", "category": "simple", "imports": ["from OpenGL import platform, error, wrapper, contextdata, converters, constant", "from OpenGL.arrays import arrayhelpers, arraydatatype", "from OpenGL.raw.GL.VERSION import GL_1_1 as _simple", "import ctypes", "\tfrom OpenGL.GL import glGetIntegerv", "\tfrom OpenGL.GL import selection, feedback"]}, {"term": "def", "name": "glRenderMode", "data": "def glRenderMode( newMode ):\n\t\"\"\"Change to the given rendering mode\n\n\tIf the current mode is GL_FEEDBACK or GL_SELECT, return\n\tthe current buffer appropriate to the mode\n\t\"\"\"\n\t# must get the current mode to determine operation...\n\tfrom OpenGL.GL import glGetIntegerv\n\tfrom OpenGL.GL import selection, feedback\n\tcurrentMode = glGetIntegerv( _simple.GL_RENDER_MODE )\n\ttry:\n\t\tcurrentMode = currentMode[0]\n\texcept (TypeError,ValueError,IndexError) as err:\n\t\tpass\n\tif currentMode in (_simple.GL_RENDER,0):\n\t\t# no array needs to be returned...\n\t\treturn _simple.glRenderMode( newMode )\n\tresult = _simple.glRenderMode( newMode )\n\t# result is now an integer telling us how many elements were copied...\n\n\tif result < 0:\n\t\tif currentMode == _simple.GL_SELECT:\n\t\t\traise error.GLError(\n\t\t\t\t_simple.GL_STACK_OVERFLOW,\n\t\t\t\t\"glSelectBuffer too small to hold selection results\",\n\t\t\t)\n\t\telif currentMode == _simple.GL_FEEDBACK:\n\t\t\traise error.GLError(\n\t\t\t\t_simple.GL_STACK_OVERFLOW,\n\t\t\t\t\"glFeedbackBuffer too small to hold selection results\",\n\t\t\t)\n\t\telse:\n\t\t\traise error.GLError(\n\t\t\t\t_simple.GL_STACK_OVERFLOW,\n\t\t\t\t\"Unknown glRenderMode buffer (%s) too small to hold selection results\"%(\n\t\t\t\t\tcurrentMode,\n\t\t\t\t),\n\t\t\t)\n\t# Okay, now that the easy cases are out of the way...\n\t#  Do we have a pre-stored pointer about which the user already knows?\n\tcontext = platform.GetCurrentContext()\n\tif context == 0:\n\t\traise error.Error(\n\t\t\t\"\"\"Returning from glRenderMode without a valid context!\"\"\"\n\t\t)\n\tarrayConstant, wrapperFunction = {\n\t\t_simple.GL_FEEDBACK: (_simple.GL_FEEDBACK_BUFFER_POINTER,feedback.parseFeedback),\n\t\t_simple.GL_SELECT: (_simple.GL_SELECTION_BUFFER_POINTER, selection.GLSelectRecord.fromArray),\n\t}[ currentMode ]\n\tcurrent = contextdata.getValue( arrayConstant )\n\t# XXX check to see if it's the *same* array we set currently!\n\tif current is None:\n\t\tcurrent = glGetPointerv( arrayConstant )\n\t# XXX now, can turn the array into the appropriate wrapper type...\n\tif wrapperFunction:\n\t\tcurrent = wrapperFunction( current, result )\n\treturn current\n", "description": "Change to the given rendering mode\n\n\tIf the current mode is GL_FEEDBACK or GL_SELECT, return\n\tthe current buffer appropriate to the mode\n\t", "category": "simple", "imports": ["from OpenGL import platform, error, wrapper, contextdata, converters, constant", "from OpenGL.arrays import arrayhelpers, arraydatatype", "from OpenGL.raw.GL.VERSION import GL_1_1 as _simple", "import ctypes", "\tfrom OpenGL.GL import glGetIntegerv", "\tfrom OpenGL.GL import selection, feedback"]}, {"term": "def", "name": "glGetPointerv", "data": "def glGetPointerv( constant ):\n\t\"\"\"Retrieve a stored pointer constant\"\"\"\n\t# do we have a cached version of the pointer?\n\t# get the base pointer from the underlying operation\n\tvp = ctypes.voidp()\n\t_simple.glGetPointerv( constant, ctypes.byref(vp) )\n\tcurrent = contextdata.getValue( constant )\n\tif current is not None:\n\t\tif arraydatatype.ArrayDatatype.dataPointer( current ) == vp.value:\n\t\t\treturn current\n\t# XXX should be coercing to the proper type and converting to an array\n\treturn vp\n", "description": "Retrieve a stored pointer constant", "category": "simple", "imports": ["from OpenGL import platform, error, wrapper, contextdata, converters, constant", "from OpenGL.arrays import arrayhelpers, arraydatatype", "from OpenGL.raw.GL.VERSION import GL_1_1 as _simple", "import ctypes", "\tfrom OpenGL.GL import glGetIntegerv", "\tfrom OpenGL.GL import selection, feedback"]}], [{"term": "class", "name": "MarketTestCase", "data": "class MarketTestCase(unittest.TestCase):\n\n\tdef test_libor_market(self):\n\t\t\"\"\"\n\t\tBasic test of Libor market\n\t\tNot checking numerical accuracy\n\t\t\"\"\"\n\n\t\t# US libor market, with default conventions:\n\t\t# semi-annual fixed vs. 3M Libor\n\t\tm = libor_market('USD(NY)')\n\n\t\t# add quotes\n\t\teval_date = Date(20, 9, 2004)\n\n\t\tquotes = [('DEP', '1W', SimpleQuote(0.0382)),\n\t\t\t\t  ('DEP', '1M', SimpleQuote(0.0372)),\n\t\t\t\t  ('DEP', '3M', SimpleQuote(0.0363)),\n\t\t\t\t  ('DEP', '6M', SimpleQuote(0.0353)),\n\t\t\t\t  ('DEP', '9M', SimpleQuote(0.0348)),\n\t\t\t\t  ('DEP', '1Y', SimpleQuote(0.0345)),\n\t\t\t\t  ('SWAP', '2Y', SimpleQuote(0.037125)),\n\t\t\t\t  ('SWAP', '3Y', SimpleQuote(0.0398)),\n\t\t\t\t  ('SWAP', '5Y', SimpleQuote(0.0443)),\n\t\t\t\t  ('SWAP', '10Y', SimpleQuote(0.05165)),\n\t\t\t\t  ('SWAP', '15Y', SimpleQuote(0.055175))]\n\t\t\n\t\tm.set_quotes(eval_date, quotes)\n\n\t\tm.bootstrap_term_structure()\n\n\t\tdt = Date(1, 1, 2010)\n\t\tdf = m.discount(dt)\n\n\t\tprint('discount factor for %s (USD Libor): %f' % (dt, df))\n\n\t\t# Euribor market, with default conventions:\n\t\t# annual fixed vs. 6M Libor\n\t\tm = libor_market('EUR:>1Y')\n\n\t\tm.set_quotes(eval_date, quotes)\n\n\t\tm.bootstrap_term_structure()\n\n\t\tdf = m.discount(dt)\n\n\t\tprint('discount factor for %s (Euribor): %f' % (dt, df))\n\t\tself.assertTrue(df > 0)\n\n\tdef test_ed(self):\n\t\t\"\"\"\n\t\tCurve construction with EuroDollar futures\n\t\tNot checking numerical accuracy\n\t\t\"\"\"\n\n\t\t# US libor market, with default conventions:\n\t\t# semi-annual fixed vs. 3M Libor\n\t\tm = libor_market('USD(LONDON)')\n\n\t\t# add quotes\n\t\teval_date = Date(20, 9, 2004)\n\n\t\tquotes = [\n\t\t\t('ED', 1, 96.2875),\n\t\t\t('ED', 2, 96.7875),\n\t\t\t('ED', 3, 96.9875),\n\t\t\t('ED', 4, 96.6875),\n\t\t\t('ED', 5, 96.4875),\n\t\t\t('ED', 6, 96.3875),\n\t\t\t('ED', 7, 96.2875),\n\t\t\t('ED', 8, 96.0875)]\n\n\t\tm.set_quotes(eval_date, quotes)\n\n\t\tm.bootstrap_term_structure()\n\n\t\tdt = Date(1, 1, 2005)\n\t\tdf = m.discount(dt)\n\n\t\tprint('discount factor for %s (USD Libor): %f' % (dt, df))\n\n\t\tself.assertTrue(df > 0)\n\n\tdef test_euribor(self):\n\t\t\"\"\"\n\t\tMarket tests for Euribor futures.\n\n\t\tNot checking numerical accuracy.\n\n\t\t\"\"\"\n\t\t# Euribor market instance.\n\t\tm = IborMarket('Euribor Market', 'EUR:1Y')\n\n\t\tevaluation_date = Date(20, 3, 2014)\n\t\tquotes = [\n\t\t\t(u'ERM4', Date(18,  6, 2014), 99.67),\n\t\t\t(u'ERU4', Date(17,  9, 2014), 99.67),\n\t\t\t(u'ERZ4', Date(17, 12, 2014), 99.66),\n\t\t\t(u'ERH5', Date(18,  3, 2015), 99.63),\n\t\t\t(u'ERM5', Date(17,  6, 2015), 99.59),\n\t\t\t(u'ERU5', Date(16,  9, 2015), 99.53),\n\t\t\t(u'ERZ5', Date(16, 12, 2015), 99.46),\n\t\t\t(u'ERH6', Date(16,  3, 2016), 99.38),\n\t\t]\n\n\t\tm.set_quotes(evaluation_date, quotes)\n\t\tm.bootstrap_term_structure()\n\n\t\tdt = Date(20, 6, 2014)\n\t\tdf = m.discount(dt)\n\t\tself.assertTrue(df > 0)\n\n\tdef test_fixed_rate_bonds(self):\n\t\t\"\"\"\n\t\tMarket tests for fixed rate bond quotes.\n\n\t\tNot checking numerical accuracy.\n\n\t\t\"\"\"\n\t\tm = IborMarket('Euribor Market', 'EUR:1Y')\n\n\t\tevaluation_date = Date(20, 3, 2014)\n\t\tquotes = [\n\t\t\t(103.455, [0.02], '1Y', Date(14, 1, 2011), Date(26, 2, 2016)),\n\t\t\t(100.075, [0.0025], '1Y', Date(14, 2, 2014), Date(11, 3, 2016)),\n\t\t\t(105.15, [0.0275], '1Y', Date(26, 4, 2011), Date(8, 4, 2016))\n\t\t]\n\n\t\tm.set_bonds(evaluation_date, quotes)\n\t\tm.bootstrap_term_structure()\n\n\t\tdt = Date(20, 6, 2014)\n\t\tdf = m.discount(dt)\n\t\tself.assertTrue(df > 0)\n\n\tdef test_market_internals(self):\n\t\t# FIXME: this should be a test case in its own right, closer to\n\t\t# YieldTermStructure.\n\n\t\tm = libor_market('USD(NY)')\n\t\teval_date = Date(20, 9, 2004)\n\n\t\tquotes = [('DEP', '1W', SimpleQuote(0.0382)),\n\t\t\t\t  ('DEP', '1M', SimpleQuote(0.0372)),\n\t\t\t\t  ('DEP', '3M', SimpleQuote(0.0363)),\n\t\t\t\t  ('DEP', '6M', SimpleQuote(0.0353)),\n\t\t\t\t  ('DEP', '9M', SimpleQuote(0.0348)),\n\t\t\t\t  ('DEP', '1Y', SimpleQuote(0.0345))]\n\n\t\tm.set_quotes(eval_date, quotes)\n\t\tts = m.bootstrap_term_structure()\n\n\t\t# Compute zero and forward rates.\n\t\tzero_rate = ts.zero_rate(Date(1, 1, 2005), Actual360(), Simple)\n\t\tforward_rate = ts.forward_rate(Date(1, 1, 2005), Date(30, 1, 2005),\n\t\t\t\t\t\t\t\t\t   Actual360(), Simple)\n\n\t\t# We don't test for numerical accuracy.\n\t\tself.assertGreater(zero_rate.rate, 0)\n\t\tself.assertGreater(forward_rate.rate, 0)\n\n\t\t# Check that the linked term structures are consistent with the\n\t\t# original term structure.\n\t\tdiscount_ts = m._discount_term_structure\n\t\tforecast_ts = m._forecast_term_structure\n\t\tself.assertIsNotNone(discount_ts)\n\t\tself.assertIsNotNone(forecast_ts)\n\n\t\tfor linked_ts in [discount_ts, forecast_ts]:\n\t\t\trate = linked_ts.zero_rate(\n\t\t\t\tDate(1, 1, 2005), Actual360(), Simple)\n\t\t\tself.assertEqual(rate.rate, zero_rate.rate)\n\n\t\t\trate = linked_ts.forward_rate(\n\t\t\t\tDate(1, 1, 2005), Date(30, 1, 2005), Actual360(), Simple)\n\t\t\tself.assertEqual(rate.rate, forward_rate.rate)\n\n", "description": "\n\t\tBasic test of Libor market\n\t\tNot checking numerical accuracy\n\t\t", "category": "simple", "imports": ["import unittest", "from quantlib.compounding import Simple", "from quantlib.time.api import Date, Actual360, Frequency", "from quantlib.market.market import libor_market, IborMarket", "from quantlib.quotes import SimpleQuote"]}], [], [{"term": "def", "name": "get_model", "data": "def get_model(cfg: object) -> object:\n\t\"\"\"Get model function\n\n\tThis is function to get model.\n\n\tArgs:\n\t\tcfg: Config of the project.\n\n\tReturns:\n\t\tModel object.\n\n\tRaises:\n\t\tNotImplementedError: If the model you want to use is not suppoeted.\n\n\t\"\"\"\n\n\tmodel_name = cfg.model.name\n\n\tif model_name not in SUPPORTED_MODEL:\n\t\traise NotImplementedError('The model is not supported.')\n\n\tif model_name == \"resnet18\":\n\t\treturn ResNet18(cfg)\n\telif model_name == \"simple_cnn\":\n\t\treturn SimpleCNN(cfg)  \n\telif model_name == \"simple_lstm\":\n\t\treturn SimpleLSTM(cfg)  \n\telif model_name == \"simple_rnn\":\n\t\treturn SimpleRNN(cfg)  \n\telif model_name == \"simple_nn\":\n\t\treturn SimpleNN(cfg)  \n\telif model_name == \"cbow_embedder\":\n", "description": "Get model function\n\n\tThis is function to get model.\n\n\tArgs:\n\t\tcfg: Config of the project.\n\n\tReturns:\n\t\tModel object.\n\n\tRaises:\n\t\tNotImplementedError: If the model you want to use is not suppoeted.\n\n\t", "category": "simple", "imports": ["from configs.supported_info import SUPPORTED_MODEL", "from models.networks.resnet18 import ResNet18", "from models.networks.simple_cnn import SimpleCNN", "from models.networks.simple_lstm import SimpleLSTM", "from models.networks.simple_rnn import SimpleRNN", "from models.networks.simple_nn import SimpleNN", "from models.networks.cbow_embedder import CBOW"]}], [{"term": "class", "name": "TestAtom", "data": "class TestAtom(unittest.TestCase):\n\tdef test_one(self):\n\t\tst = BasicState(simple)\n\t\tfor i in range(len(simple)):\n\t\t\tidx = st.index\n\t\t\tre = one(st)\n\t\t\tself.assertEqual(re, st.data[idx])\n\t\twith self.assertRaises(Exception) as err:\n\t\t\tone(st)\n\t\tself.assertTrue(issubclass(type(err.exception), ParsecEof))\n\n\tdef test_eof(self):\n\t\tst = BasicState(simple)\n\t\tfor i in range(len(simple)):\n\t\t\tre = one(st)\n\t\tself.assertIsNone(eof(st))\n\n\tdef test_eq(self):\n\t\tst = BasicState(simple)\n\t\tfor i in range(len(simple)):\n\t\t\tc = st.data[st.index]\n\t\t\tnext_parser = eq(c)\n\t\t\tre = next_parser(st)\n\t\t\tself.assertEqual(re, c)\n\n\tdef test_ne(self):\n\t\tst = BasicState(simple)\n\t\tnext_parser = ne(\"\")\n\t\tfor i in range(len(simple)):\n\t\t\tc = st.data[st.index]\n\t\t\tre = next_parser(st)\n\t\t\tself.assertEqual(re, c)\n\t\t\tnext_parser = ne(c)\n\n\tdef test_one_of(self):\n\t\tst = BasicState(simple)\n\t\tnext_parser = oneOf(simple)\n\t\tfor i in range(len(simple)):\n\t\t\tidx = st.index\n\t\t\tre = next_parser(st)\n\t\t\tself.assertEqual(re, st.data[idx])\n\n\tdef test_none_of(self):\n\t\tst = BasicState(simple)\n\t\tn = noneOf(\"xyzcf\")\n\t\tfor i in range(1, len(simple)):\n\t\t\tidx = st.index\n\t\t\tre = n(st)\n\t\t\tself.assertEqual(re, st.data[idx])\n\n\tdef test_pack(self):\n\t\tst = BasicState(simple)\n\t\tp = pack(\"z\")\n\t\tfor i in range(1, len(simple)):\n\t\t\tidx = st.index\n\t\t\tre = p(st)\n\t\t\tself.assertEqual(\"z\", re)\n\n\tdef test_fail(self):\n\t\tst = BasicState(simple)\n\t\tp = fail(\"z\")\n\t\twith self.assertRaises(ParsecError):\n\t\t\tp(st)\n\n", "description": null, "category": "simple", "imports": ["import unittest", "from src.parsec import BasicState, one, eof, ParsecEof, ne, eq, oneOf, noneOf, pack, fail, ParsecError"]}], [{"term": "def", "name": "fwith_tp_del", "data": "\tdef with_tp_del(cls):\n\t\tclass C(object):\n\t\t\tdef __new__(cls, *args, **kwargs):\n\t\t\t\traise TypeError('requires _testcapi.with_tp_del')\n\t\treturn C\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "classNonGCSimpleBase:", "data": "class NonGCSimpleBase:\n\t\"\"\"\n\tThe base class for all the objects under test, equipped with various\n\ttesting features.\n\t\"\"\"\n\n\tsurvivors = []\n\tdel_calls = []\n\ttp_del_calls = []\n\terrors = []\n\n\t_cleaning = False\n\n\t__slots__ = ()\n\n\t@classmethod\n\tdef _cleanup(cls):\n\t\tcls.survivors.clear()\n\t\tcls.errors.clear()\n\t\tgc.garbage.clear()\n\t\tgc.collect()\n\t\tcls.del_calls.clear()\n\t\tcls.tp_del_calls.clear()\n\n\t@classmethod\n\t@contextlib.contextmanager\n\tdef test(cls):\n\t\t\"\"\"\n\t\tA context manager to use around all finalization tests.\n\t\t\"\"\"\n\t\twith support.disable_gc():\n\t\t\tcls.del_calls.clear()\n\t\t\tcls.tp_del_calls.clear()\n\t\t\tNonGCSimpleBase._cleaning = False\n\t\t\ttry:\n\t\t\t\tyield\n\t\t\t\tif cls.errors:\n\t\t\t\t\traise cls.errors[0]\n\t\t\tfinally:\n\t\t\t\tNonGCSimpleBase._cleaning = True\n\t\t\t\tcls._cleanup()\n\n\tdef check_sanity(self):\n\t\t\"\"\"\n\t\tCheck the object is sane (non-broken).\n\t\t\"\"\"\n\n\tdef __del__(self):\n\t\t\"\"\"\n\t\tPEP 442 finalizer.  Record that this was called, check the\n\t\tobject is in a sane state, and invoke a side effect.\n\t\t\"\"\"\n\t\ttry:\n\t\t\tif not self._cleaning:\n\t\t\t\tself.del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\t\t\tself.side_effect()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tA side effect called on destruction.\n\t\t\"\"\"\n\n", "description": "\n\tThe base class for all the objects under test, equipped with various\n\ttesting features.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleBase", "data": "class SimpleBase(NonGCSimpleBase):\n\n\tdef __init__(self):\n\t\tself.id_ = id(self)\n\n\tdef check_sanity(self):\n\t\tassert self.id_ == id(self)\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "NonGC", "data": "class NonGC(NonGCSimpleBase):\n\t__slots__ = ()\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "NonGCResurrector", "data": "class NonGCResurrector(NonGCSimpleBase):\n\t__slots__ = ()\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tResurrect self by storing self in a class-wide list.\n\t\t\"\"\"\n\t\tself.survivors.append(self)\n", "description": "\n\t\tResurrect self by storing self in a class-wide list.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "Simple", "data": "class Simple(SimpleBase):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleResurrector", "data": "class SimpleResurrector(NonGCResurrector, SimpleBase):\n\tpass\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "classTestBase:", "data": "class TestBase:\n\n\tdef setUp(self):\n\t\tself.old_garbage = gc.garbage[:]\n\t\tgc.garbage[:] = []\n\n\tdef tearDown(self):\n\t\t# None of the tests here should put anything in gc.garbage\n\t\ttry:\n\t\t\tself.assertEqual(gc.garbage, [])\n\t\tfinally:\n\t\t\tdel self.old_garbage\n\t\t\tgc.collect()\n\n\tdef assert_del_calls(self, ids):\n\t\tself.assertEqual(sorted(SimpleBase.del_calls), sorted(ids))\n\n\tdef assert_tp_del_calls(self, ids):\n\t\tself.assertEqual(sorted(SimpleBase.tp_del_calls), sorted(ids))\n\n\tdef assert_survivors(self, ids):\n\t\tself.assertEqual(sorted(id(x) for x in SimpleBase.survivors), sorted(ids))\n\n\tdef assert_garbage(self, ids):\n\t\tself.assertEqual(sorted(id(x) for x in gc.garbage), sorted(ids))\n\n\tdef clear_survivors(self):\n\t\tSimpleBase.survivors.clear()\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleFinalizationTest", "data": "class SimpleFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization without refcycles.\n\t\"\"\"\n\n\tdef test_simple(self):\n\t\twith SimpleBase.test():\n\t\t\ts = Simple()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_simple_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = SimpleResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\tself.assertIsNot(wr(), None)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\tself.assertIs(wr(), None)\n\n\tdef test_non_gc(self):\n\t\twith SimpleBase.test():\n\t\t\ts = NonGC()\n\t\t\tself.assertFalse(gc.is_tracked(s))\n\t\t\tids = [id(s)]\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_non_gc_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = NonGCResurrector()\n\t\t\tself.assertFalse(gc.is_tracked(s))\n\t\t\tids = [id(s)]\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids * 2)\n\t\t\tself.assert_survivors(ids)\n\n", "description": "\n\tTest finalization without refcycles.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "classSelfCycleBase:", "data": "class SelfCycleBase:\n\n\tdef __init__(self):\n\t\tsuper().__init__()\n\t\tself.ref = self\n\n\tdef check_sanity(self):\n\t\tsuper().check_sanity()\n\t\tassert self.ref is self\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleSelfCycle", "data": "class SimpleSelfCycle(SelfCycleBase, Simple):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SelfCycleResurrector", "data": "class SelfCycleResurrector(SelfCycleBase, SimpleResurrector):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SuicidalSelfCycle", "data": "class SuicidalSelfCycle(SelfCycleBase, Simple):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tExplicitly break the reference cycle.\n\t\t\"\"\"\n\t\tself.ref = None\n\n", "description": "\n\t\tExplicitly break the reference cycle.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SelfCycleFinalizationTest", "data": "class SelfCycleFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of an object having a single cyclic reference to\n\titself.\n\t\"\"\"\n\n\tdef test_simple(self):\n\t\twith SimpleBase.test():\n\t\t\ts = SimpleSelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_simple_resurrect(self):\n\t\t# Test that __del__ can resurrect the object being finalized.\n\t\twith SimpleBase.test():\n\t\t\ts = SelfCycleResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\t# XXX is this desirable?\n\t\t\tself.assertIs(wr(), None)\n\t\t\t# When trying to destroy the object a second time, __del__\n\t\t\t# isn't called anymore (and the object isn't resurrected).\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\n\tdef test_simple_suicide(self):\n\t\t# Test the GC is able to deal with an object that kills its last\n\t\t# reference during __del__.\n\t\twith SimpleBase.test():\n\t\t\ts = SuicidalSelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\n", "description": "\n\tTest finalization of an object having a single cyclic reference to\n\titself.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "classChainedBase:", "data": "class ChainedBase:\n\n\tdef chain(self, left):\n\t\tself.suicided = False\n\t\tself.left = left\n\t\tleft.right = self\n\n\tdef check_sanity(self):\n\t\tsuper().check_sanity()\n\t\tif self.suicided:\n\t\t\tassert self.left is None\n\t\t\tassert self.right is None\n\t\telse:\n\t\t\tleft = self.left\n\t\t\tif left.suicided:\n\t\t\t\tassert left.right is None\n\t\t\telse:\n\t\t\t\tassert left.right is self\n\t\t\tright = self.right\n\t\t\tif right.suicided:\n\t\t\t\tassert right.left is None\n\t\t\telse:\n\t\t\t\tassert right.left is self\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SimpleChained", "data": "class SimpleChained(ChainedBase, Simple):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "ChainedResurrector", "data": "class ChainedResurrector(ChainedBase, SimpleResurrector):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "SuicidalChained", "data": "class SuicidalChained(ChainedBase, Simple):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tExplicitly break the reference cycle.\n\t\t\"\"\"\n\t\tself.suicided = True\n\t\tself.left = None\n\t\tself.right = None\n\n", "description": "\n\t\tExplicitly break the reference cycle.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "CycleChainFinalizationTest", "data": "class CycleChainFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of a cyclic chain.  These tests are similar in\n\tspirit to the self-cycle tests above, but the collectable object\n\tgraph isn't trivial anymore.\n\t\"\"\"\n\n\tdef build_chain(self, classes):\n\t\tnodes = [cls() for cls in classes]\n\t\tfor i in range(len(nodes)):\n\t\t\tnodes[i].chain(nodes[i-1])\n\t\treturn nodes\n\n\tdef check_non_resurrecting_chain(self, classes):\n\t\tN = len(classes)\n\t\twith SimpleBase.test():\n\t\t\tnodes = self.build_chain(classes)\n\t\t\tids = [id(s) for s in nodes]\n\t\t\twrs = [weakref.ref(s) for s in nodes]\n\t\t\tdel nodes\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertEqual([wr() for wr in wrs], [None] * N)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\n\tdef check_resurrecting_chain(self, classes):\n\t\tN = len(classes)\n\t\twith SimpleBase.test():\n\t\t\tnodes = self.build_chain(classes)\n\t\t\tN = len(nodes)\n\t\t\tids = [id(s) for s in nodes]\n\t\t\tsurvivor_ids = [id(s) for s in nodes if isinstance(s, SimpleResurrector)]\n\t\t\twrs = [weakref.ref(s) for s in nodes]\n\t\t\tdel nodes\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(survivor_ids)\n\t\t\t# XXX desirable?\n\t\t\tself.assertEqual([wr() for wr in wrs], [None] * N)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_homogenous(self):\n\t\tself.check_non_resurrecting_chain([SimpleChained] * 3)\n\n\tdef test_homogenous_resurrect(self):\n\t\tself.check_resurrecting_chain([ChainedResurrector] * 3)\n\n\tdef test_homogenous_suicidal(self):\n\t\tself.check_non_resurrecting_chain([SuicidalChained] * 3)\n\n\tdef test_heterogenous_suicidal_one(self):\n\t\tself.check_non_resurrecting_chain([SuicidalChained, SimpleChained] * 2)\n\n\tdef test_heterogenous_suicidal_two(self):\n\t\tself.check_non_resurrecting_chain(\n\t\t\t[SuicidalChained] * 2 + [SimpleChained] * 2)\n\n\tdef test_heterogenous_resurrect_one(self):\n\t\tself.check_resurrecting_chain([ChainedResurrector, SimpleChained] * 2)\n\n\tdef test_heterogenous_resurrect_two(self):\n\t\tself.check_resurrecting_chain(\n\t\t\t[ChainedResurrector, SimpleChained, SuicidalChained] * 2)\n\n\tdef test_heterogenous_resurrect_three(self):\n\t\tself.check_resurrecting_chain(\n\t\t\t[ChainedResurrector] * 2 + [SimpleChained] * 2 + [SuicidalChained] * 2)\n\n", "description": "\n\tTest finalization of a cyclic chain.  These tests are similar in\n\tspirit to the self-cycle tests above, but the collectable object\n\tgraph isn't trivial anymore.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "LegacyBase", "data": "class LegacyBase(SimpleBase):\n\n\tdef __del__(self):\n\t\ttry:\n\t\t\t# Do not invoke side_effect here, since we are now exercising\n\t\t\t# the tp_del slot.\n\t\t\tif not self._cleaning:\n\t\t\t\tself.del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n\n\tdef __tp_del__(self):\n\t\t\"\"\"\n\t\tLegacy (pre-PEP 442) finalizer, mapped to a tp_del slot.\n\t\t\"\"\"\n\t\ttry:\n\t\t\tif not self._cleaning:\n\t\t\t\tself.tp_del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\t\t\tself.side_effect()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n", "description": "\n\t\tLegacy (pre-PEP 442) finalizer, mapped to a tp_del slot.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "Legacy", "data": "class Legacy(LegacyBase):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "LegacyResurrector", "data": "class LegacyResurrector(LegacyBase):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tResurrect self by storing self in a class-wide list.\n\t\t\"\"\"\n\t\tself.survivors.append(self)\n", "description": "\n\t\tResurrect self by storing self in a class-wide list.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "LegacySelfCycle", "data": "class LegacySelfCycle(SelfCycleBase, LegacyBase):\n\tpass\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}, {"term": "class", "name": "LegacyFinalizationTest", "data": "class LegacyFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of objects with a tp_del.\n\t\"\"\"\n\n\tdef tearDown(self):\n\t\t# These tests need to clean up a bit more, since they create\n\t\t# uncollectable objects.\n\t\tgc.garbage.clear()\n\t\tgc.collect()\n\t\tsuper().tearDown()\n\n\tdef test_legacy(self):\n\t\twith SimpleBase.test():\n\t\t\ts = Legacy()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\n\tdef test_legacy_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = LegacyResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\t# weakrefs are cleared before tp_del is called.\n\t\t\tself.assertIs(wr(), None)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids * 2)\n\t\t\tself.assert_survivors(ids)\n\t\tself.assertIs(wr(), None)\n\n\tdef test_legacy_self_cycle(self):\n\t\t# Self-cycles with legacy finalizers end up in gc.garbage.\n\t\twith SimpleBase.test():\n\t\t\ts = LegacySelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls([])\n\t\t\tself.assert_tp_del_calls([])\n\t\t\tself.assert_survivors([])\n\t\t\tself.assert_garbage(ids)\n\t\t\tself.assertIsNot(wr(), None)\n\t\t\t# Break the cycle to allow collection\n\t\t\tgc.garbage[0].ref = None\n\t\tself.assert_garbage([])\n\t\tself.assertIs(wr(), None)\n\n", "description": "\n\tTest finalization of objects with a tp_del.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "from test import support"]}], [{"term": "class", "name": "_AnonBase", "data": "class _AnonBase(_VimTest):\n\targs = \"\"\n\n\tdef _extra_vim_config(self, vim_config):\n\t\tvim_config.append(\n\t\t\t\"inoremap  %s =UltiSnips#Anon(%s)\" % (EA, self.args)\n\t\t)\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "Anon_NoTrigger_Simple", "data": "class Anon_NoTrigger_Simple(_AnonBase):\n\targs = '\"simple expand\"'\n\tkeys = \"abc\" + EA\n\twanted = \"abcsimple expand\"\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "Anon_NoTrigger_AfterSpace", "data": "class Anon_NoTrigger_AfterSpace(_AnonBase):\n\targs = '\"simple expand\"'\n\tkeys = \"abc \" + EA\n\twanted = \"abc simple expand\"\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "Anon_NoTrigger_BeginningOfLine", "data": "class Anon_NoTrigger_BeginningOfLine(_AnonBase):\n\targs = r\"':latex:\\`$1\\`$0'\"\n\tkeys = EA + \"Hello\" + JF + \"World\"\n\twanted = \":latex:`Hello`World\"\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "Anon_NoTrigger_FirstCharOfLine", "data": "class Anon_NoTrigger_FirstCharOfLine(_AnonBase):\n\targs = r\"':latex:\\`$1\\`$0'\"\n\tkeys = \" \" + EA + \"Hello\" + JF + \"World\"\n\twanted = \" :latex:`Hello`World\"\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "Anon_NoTrigger_Multi", "data": "class Anon_NoTrigger_Multi(_AnonBase):\n\targs = '\"simple $1 expand $1 $0\"'\n\tkeys = \"abc\" + EA + \"123\" + JF + \"456\"\n\twanted = \"abcsimple 123 expand 123 456\"\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "Anon_Trigger_Multi", "data": "class Anon_Trigger_Multi(_AnonBase):\n\targs = '\"simple $1 expand $1 $0\", \"abc\"'\n\tkeys = \"123 abc\" + EA + \"123\" + JF + \"456\"\n\twanted = \"123 simple 123 expand 123 456\"\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "Anon_Trigger_Simple", "data": "class Anon_Trigger_Simple(_AnonBase):\n\targs = '\"simple expand\", \"abc\"'\n\tkeys = \"abc\" + EA\n\twanted = \"simple expand\"\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "Anon_Trigger_Twice", "data": "class Anon_Trigger_Twice(_AnonBase):\n\targs = '\"simple expand\", \"abc\"'\n\tkeys = \"abc\" + EA + \"\\nabc\" + EX\n\twanted = \"simple expand\\nabc\" + EX\n\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}, {"term": "class", "name": "Anon_Trigger_Opts", "data": "class Anon_Trigger_Opts(_AnonBase):\n\targs = '\"simple expand\", \".*abc\", \"desc\", \"r\"'\n\tkeys = \"blah blah abc\" + EA\n\twanted = \"simple expand\"\n", "description": null, "category": "simple", "imports": ["from test.vim_test_case import VimTestCase as _VimTest", "from test.constant import *"]}], [], [], [], [{"term": "def", "name": "parseFeedback", "data": "def parseFeedback( buffer, entryCount ):\n\t\"\"\"Parse the feedback buffer into Python object records\"\"\"\n\tbufferIndex = 0\n\tresult = []\n\tgetVertex = createGetVertex( )\n\twhile bufferIndex < entryCount:\n\t\ttoken = int(buffer[bufferIndex])\n\t\tbufferIndex += 1\n\t\tif SINGLE_VERTEX_TOKENS.has_key( token):\n\t\t\tvData, bufferIndex = getVertex( buffer, bufferIndex )\n\t\t\tresult.append( (SINGLE_VERTEX_TOKENS.get(token), Vertex(*vData)) )\n\t\telif DOUBLE_VERTEX_TOKENS.has_key( token ):\n\t\t\tvData, bufferIndex = getVertex( buffer, bufferIndex )\n\t\t\tvData2, bufferIndex = getVertex( buffer, bufferIndex )\n\t\t\tresult.append( (\n\t\t\t\tDOUBLE_VERTEX_TOKENS.get(token), \n\t\t\t\tVertex(*vData),\n\t\t\t\tVertex(*vData2),\n\t\t\t) )\n\t\telif token == simple.GL_PASS_THROUGH_TOKEN:\n\t\t\tresult.append( (simple.GL_PASS_THROUGH_TOKEN, buffer[bufferIndex]))\n\t\t\tbufferIndex += 1\n\t\telif token == simple.GL_POLYGON_TOKEN:\n\t\t\ttemp = [simple.GL_POLYGON_TOKEN]\n\t\t\tcount = int(buffer[bufferIndex])\n\t\t\tbufferIndex += 1\n\t\t\tfor item in range(count):\n\t\t\t\tvData,bufferIndex = getVertex( buffer, bufferIndex )\n\t\t\t\ttemp.append( Vertex(*vData))\n\t\t\tresult.append( tuple(temp))\n\t\telse:\n\t\t\traise ValueError( \n\t\t\t\t\"\"\"Unrecognised token %r in feedback stream\"\"\"%(token,)\n\t\t\t)\n\treturn result\n", "description": "Parse the feedback buffer into Python object records", "category": "simple", "imports": ["from OpenGL import contextdata", "from OpenGL.raw import GL as simple", "from OpenGL.GL import glget"]}, {"term": "class", "name": "Vertex", "data": "class Vertex( object ):\n\t\"\"\"Simplistic holder for vertex data from a feedback buffer\"\"\"\n\t__slots__ = ('vertex','color','texture')\n\tdef __init__( self, vertex,color=None,texture=None):\n\t\t\"\"\"Store values for access\"\"\"\n\t\tself.vertex = vertex \n\t\tself.color = color \n", "description": "Simplistic holder for vertex data from a feedback buffer", "category": "simple", "imports": ["from OpenGL import contextdata", "from OpenGL.raw import GL as simple", "from OpenGL.GL import glget"]}, {"term": "def", "name": "createGetVertex", "data": "def createGetVertex( ):\n\tmode = contextdata.getValue( \"GL_FEEDBACK_BUFFER_TYPE\" )\n\tindexMode = glget.glGetBoolean( simple.GL_INDEX_MODE )\n\tcolorSize = [ 4,1 ][ int(indexMode) ]\n\tif mode in (simple.GL_2D,simple.GL_3D):\n\t\tif mode == simple.GL_2D:\n\t\t\tsize = 2\n\t\telse:\n\t\t\tsize = 3\n\t\tdef getVertex( buffer, bufferIndex ):\n\t\t\tend = bufferIndex+size\n\t\t\treturn (buffer[bufferIndex:end],None,None),end \n\telif mode == simple.GL_3D_COLOR:\n\t\tdef getVertex( buffer, bufferIndex ):\n\t\t\tend = bufferIndex+3\n\t\t\tcolorEnd = end + colorSize\n\t\t\treturn (buffer[bufferIndex:end],buffer[end:colorEnd],None),colorEnd \n\telse:\n\t\tif mode == simple.GL_3D_COLOR_TEXTURE:\n\t\t\tsize = 3\n\t\telse:\n\t\t\tsize = 4\n\t\tdef getVertex( buffer, bufferIndex ):\n\t\t\tend = bufferIndex+size\n\t\t\tcolorEnd = end + colorSize\n\t\t\ttextureEnd = colorEnd + 4\n\t\t\treturn (buffer[bufferIndex:end],buffer[end:colorEnd],buffer[colorEnd:textureEnd]),textureEnd\n", "description": null, "category": "simple", "imports": ["from OpenGL import contextdata", "from OpenGL.raw import GL as simple", "from OpenGL.GL import glget"]}], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [{"term": "class", "name": "classTestLibraryInfo:", "data": "class TestLibraryInfo:\n\tdef test_simple(self):\n\t\twith temppath('foo.ini') as path:\n\t\t\twith open(path,  'w') as f:\n\t\t\t\tf.write(simple)\n\t\t\tpkg = os.path.splitext(path)[0]\n\t\t\tout = read_config(pkg)\n\n\t\tassert_(out.cflags() == simple_d['cflags'])\n\t\tassert_(out.libs() == simple_d['libflags'])\n\t\tassert_(out.name == simple_d['name'])\n\t\tassert_(out.version == simple_d['version'])\n\n\tdef test_simple_variable(self):\n\t\twith temppath('foo.ini') as path:\n\t\t\twith open(path,  'w') as f:\n\t\t\t\tf.write(simple_variable)\n\t\t\tpkg = os.path.splitext(path)[0]\n\t\t\tout = read_config(pkg)\n\n\t\tassert_(out.cflags() == simple_variable_d['cflags'])\n\t\tassert_(out.libs() == simple_variable_d['libflags'])\n\t\tassert_(out.name == simple_variable_d['name'])\n\t\tassert_(out.version == simple_variable_d['version'])\n\t\tout.vars['prefix'] = '/Users/david'\n\t\tassert_(out.cflags() == '-I/Users/david/include')\n", "description": null, "category": "simple", "imports": ["import os", "from numpy.distutils.npy_pkg_config import read_config, parse_flags", "from numpy.testing import temppath, assert_"]}, {"term": "class", "name": "classTestParseFlags:", "data": "class TestParseFlags:\n\tdef test_simple_cflags(self):\n\t\td = parse_flags(\"-I/usr/include\")\n\t\tassert_(d['include_dirs'] == ['/usr/include'])\n\n\t\td = parse_flags(\"-I/usr/include -DFOO\")\n\t\tassert_(d['include_dirs'] == ['/usr/include'])\n\t\tassert_(d['macros'] == ['FOO'])\n\n\t\td = parse_flags(\"-I /usr/include -DFOO\")\n\t\tassert_(d['include_dirs'] == ['/usr/include'])\n\t\tassert_(d['macros'] == ['FOO'])\n\n\tdef test_simple_lflags(self):\n\t\td = parse_flags(\"-L/usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tassert_(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tassert_(d['libraries'] == ['foo', 'bar'])\n\n\t\td = parse_flags(\"-L /usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tassert_(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tassert_(d['libraries'] == ['foo', 'bar'])\n", "description": null, "category": "simple", "imports": ["import os", "from numpy.distutils.npy_pkg_config import read_config, parse_flags", "from numpy.testing import temppath, assert_"]}], [{"term": "def", "name": "read_data", "data": "def read_data():\n\tprint(\"read data ...\")\n\ttrain_dingdan_data = pd.read_csv(config.dingdan_train_path, encoding=\"gb2312\")\n\ttrain_xuqiu_data = pd.read_csv(config.xuqiu_train_path, encoding=\"gb2312\")\n\n\ttest_dingdan_data = pd.read_csv(config.dingdan_test_path)\n\ttest_xuqiu_data = pd.read_csv(config.xuqiu_test_path)\n\n\tprint(\"transform data\")\n\t# \u65f6\u95f4\u7c7b\u578b\n\ttrain_xuqiu_data[\"date\"] = pd.to_datetime(train_xuqiu_data[\"date\"])\n\ttrain_xuqiu_data[\"year_month\"] = train_xuqiu_data[\"date\"].dt.strftime(\"%Y%m\")\n\ttrain_xuqiu_data[\"year\"] = train_xuqiu_data[\"date\"].dt.year\n\ttrain_xuqiu_data[\"month\"] = train_xuqiu_data[\"date\"].dt.month\n\t# train_xuqiu_data[\"quarter\"] = train_xuqiu_data[\"date\"].dt.quarter\n\n\ttest_xuqiu_data[\"date\"] = pd.to_datetime(test_xuqiu_data[\"date\"])\n\ttest_xuqiu_data[\"year_month\"] = test_xuqiu_data[\"date\"].dt.strftime(\"%Y%m\")\n\ttest_xuqiu_data[\"year\"] = test_xuqiu_data[\"date\"].dt.year\n\ttest_xuqiu_data[\"month\"] = test_xuqiu_data[\"date\"].dt.month\n\t# test_xuqiu_data[\"quarter\"] = test_xuqiu_data[\"date\"].dt.quarter\n\n\ttrain_data = train_xuqiu_data.merge(train_dingdan_data, how=\"left\", on=[\"product_id\", \"year\", \"month\"])\n\ttest_data = test_xuqiu_data.merge(test_dingdan_data, how=\"left\", on=[\"product_id\", \"year\", \"month\"])\n\n\tdata = pd.concat([train_data, test_data]).reset_index(drop=True)\n\tdata = data.sort_values(['product_id', 'year_month'])\n\n\tsimple = data[~data[\"label\"].isnull()]\n\tsimple[\"sale_count\"] = simple.groupby([\"product_id\", \"year_month\"])[\"is_sale_day\"].transform(\"sum\")\n\tsimple = simple.loc[:, [\"product_id\", \"year_month\", \"sale_count\"]].drop_duplicates([\"product_id\", \"year_month\"])\n\tdata = data.merge(simple, on=[\"product_id\", \"year_month\"], how=\"left\")\n\n\t# \u6708\u6c47\u96c6\n\tdata[\"label_month\"] = data.groupby([\"product_id\", \"year\", \"month\"])[\"label\"].transform(\"sum\")\n\tdata[\"sale_count\"] = data.groupby([\"product_id\", \"year_month\"])[\"is_sale_day\"].transform(\"sum\")\n\tdata = data.drop_duplicates([\"product_id\", \"year\", \"month\"]).reset_index(drop=True)\n\n\t# \u7edf\u8ba1\u552e\u5356\u6708\u4efd\u6570\n\t# \u83b7\u53d6\u7b2c\u4e00\u6b21\u552e\u5356\u7684\u6708\u4efd\n\tsimple = data[data[\"label_month\"] > 0]\n\tsimple[\"qty_first_month\"] = simple.groupby([\"product_id\"])[\"year_month\"].transform(\"first\")\n\tsimple = simple.loc[:, [\"product_id\", \"qty_first_month\"]].drop_duplicates()\n\tdata = data.merge(simple, on=[\"product_id\"], how=\"left\")\n\t# \u8fc7\u6ee4\u8fd8\u672a\u552e\u5356\u7684\u65f6\u95f4\n\tdata_first = data[data[\"qty_first_month\"] <= data[\"year_month\"]].reset_index(drop=True)\n\n\tsimple = data_first[~data_first[\"label\"].isnull()]\n\tsimple[\"qty_month_count\"] = simple.groupby([\"product_id\"])[\"year_month\"].transform(\"count\")\n\tsimple = simple.loc[:, [\"product_id\", \"qty_month_count\"]].drop_duplicates()\n\tdata = data.merge(simple, on=[\"product_id\"], how=\"left\")\n\n\t# \u6570\u636e\u6807\u51c6\u5316\n\tdata[\"all_qty\"] = data.groupby([\"product_id\"])[\"label_month\"].transform(\"sum\")\n\tdata[\"mean_qty\"] = data[\"all_qty\"] / data[\"qty_month_count\"]\n\tdata[\"scan_qty\"] = data[\"label_month\"] / data[\"mean_qty\"]\n\tdata[\"date_block_num\"] = (data[\"year\"] - 2018) * 12 + data[\"month\"]\n\tdata[\"scan_qty\"].fillna(0, inplace=True)\n\t# data[\"qty_year_mean\"] = data.groupby([\"product_id\", \"year\"])[\"scan_qty\"].transform(\"mean\")\n\t# data[\"scan_qty\"] = data[\"scan_qty\"] - data[\"qty_year_mean\"]\n\t# data[\"scan_qty\"] = data[\"scan_qty\"].map(lambda x: x if x > 0 else 0)\n\n\tsimple = data[data[\"year_month\"] == data[\"qty_first_month\"]]\n\tsimple[\"qty_first\"] = simple[\"date_block_num\"]\n\tsimple = simple.loc[:, [\"product_id\", \"qty_first\"]]\n\tdata = data.merge(simple, on=[\"product_id\"], how=\"left\")\n\tdata[\"qty_num\"] = data[\"date_block_num\"] - data[\"qty_first\"] + 1\n\tdata[\"qty_num\"] = data[\"qty_num\"].map(lambda x: x if x > 0 else 0)\n\tdata[\"stock_diff\"] = data[\"end_stock\"] - data[\"start_stock\"]\n\t# \u6784\u9020\u6625\u8282\u6708\n\tdata['is_chunjie'] = list(map(lambda x: 1 if x == 2 or x == 14 or x == 26 or x == 38 else 0, data['date_block_num']))\n\t# data['is_chunjie_before'] = list(map(lambda x: 1 if x == 1 or x == 13 or x == 25 or x == 37 else 0, data['date_block_num']))\n\t# data['is_chunjie_late'] = list(map(lambda x: 1 if x == 3 or x == 15 or x == 27 or x == 39 else 0, data['date_block_num']))\n\t# data[\"order_mean\"] = data.groupby([\"product_id\"])[\"order\"].transform(\"mean\")\n\t# data[\"order\"] = data[\"order\"] / data[\"order_mean\"]\n\t# del data[\"order_mean\"]\n\tdel data[\"qty_first\"]\n\tdel data[\"label\"]\n\tdel data[\"is_sale_day\"]\n\tdel data[\"year_month\"]\n\tdel data[\"all_qty\"]\n\tdel data[\"qty_first_month\"]\n\tdel data[\"qty_month_count\"]\n\t# del data[\"qty_num\"]\n\treturn data\n\n", "description": null, "category": "simple", "imports": ["import pandas as pd", "import numpy as np", "import warnings", "from tqdm import tqdm", "import pandas as pd", "from scipy import stats", "import config"]}], [{"term": "def", "name": "test_size", "data": "def test_size():\n\t\"\"\" test that the searchspace after applying restrictions is the expected size \"\"\"\n\tassert simple_searchspace.size == 12\n\tassert searchspace.size == 10660\n\n", "description": " test that the searchspace after applying restrictions is the expected size ", "category": "simple", "imports": ["from __future__ import print_function", "from collections import OrderedDict", "from random import randrange", "from math import ceil", "\tfrom mock import patch", "\tfrom unittest.mock import patch", "from kernel_tuner.interface import Options", "from kernel_tuner.searchspace import Searchspace", "from constraint import ExactSumConstraint, FunctionConstraint", "import numpy as np"]}, {"term": "def", "name": "test_internal_representation", "data": "def test_internal_representation():\n\t\"\"\" test that the list and dict representations match in size, type and elements \"\"\"\n\tassert searchspace.size == len(searchspace.list)\n\tassert searchspace.size == len(searchspace.get_list_dict().keys())\n\tassert isinstance(searchspace.list[0], tuple)\n\n\tfor index, dict_config in enumerate(searchspace.get_list_dict().keys()):\n\t\tassert dict_config == searchspace.list[index]\n", "description": " test that the list and dict representations match in size, type and elements ", "category": "simple", "imports": ["from __future__ import print_function", "from collections import OrderedDict", "from random import randrange", "from math import ceil", "\tfrom mock import patch", "\tfrom unittest.mock import patch", "from kernel_tuner.interface import Options", "from kernel_tuner.searchspace import Searchspace", "from constraint import ExactSumConstraint, FunctionConstraint", "import numpy as np"]}, {"term": "def", "name": "test_sort", "data": "def test_sort():\n\t\"\"\" test that the sort searchspace option works as expected \"\"\"\n\tsimple_searchspace_sort = Searchspace(simple_tuning_options, max_threads, sort=True, sort_last_param_first=False)\n\tassert simple_searchspace_sort.list == [(1, 4, 'string_1'), (1, 4, 'string_2'), (1, 5.5, 'string_1'), (1, 5.5, 'string_2'), (2, 4, 'string_1'), (2, 4, 'string_2'), (2, 5.5, 'string_1'), (2, 5.5, 'string_2'), (3, 4, 'string_1'), (3, 4, 'string_2'), (3, 5.5, 'string_1'), (3, 5.5, 'string_2')]\n\n\tsearchspace_sort = Searchspace(sort_tuning_options, max_threads, sort=True, sort_last_param_first=False)\n\tnum_params = len(searchspace_sort.list[0])\n\tfor param_config_index, (param_config_first, param_config_second) in enumerate(zip(searchspace_sort.list, searchspace_sort.list[1:])):\n\t\tif (param_config_index + 1) % num_layers == 0:\n\t\t\tcontinue\n\t\tfor param_index in range(num_params):\n\t\t\tassert param_config_first[param_index] <= param_config_second[param_index]\n", "description": " test that the sort searchspace option works as expected ", "category": "simple", "imports": ["from __future__ import print_function", "from collections import OrderedDict", "from random import randrange", "from math import ceil", "\tfrom mock import patch", "\tfrom unittest.mock import patch", "from kernel_tuner.interface import Options", "from kernel_tuner.searchspace import Searchspace", "from constraint import ExactSumConstraint, FunctionConstraint", "import numpy as np"]}, {"term": "def", "name": "test_sort_reversed", "data": "def test_sort_reversed():\n\t\"\"\" test that the sort searchspace option with the sort_last_param_first option enabled works as expected \"\"\"\n\tsimple_searchspace_sort_reversed = Searchspace(simple_tuning_options, max_threads, sort=True, sort_last_param_first=True)\n\tassert simple_searchspace_sort_reversed.list == [(1, 4, 'string_1'), (2, 4, 'string_1'), (3, 4, 'string_1'), (1, 5.5, 'string_1'), (2, 5.5, 'string_1'), (3, 5.5, 'string_1'), (1, 4, 'string_2'), (2, 4, 'string_2'), (3, 4, 'string_2'), (1, 5.5, 'string_2'), (2, 5.5, 'string_2'), (3, 5.5, 'string_2')]\n\n\tsearchspace_sort = Searchspace(sort_tuning_options, max_threads, sort=True, sort_last_param_first=True)\n\tnum_params = len(searchspace_sort.list[0])\n\tfor param_config_index, (param_config_first, param_config_second) in enumerate(zip(searchspace_sort.list, searchspace_sort.list[1:])):\n\t\tif (param_config_index + 1) % num_layers == 0:\n\t\t\tcontinue\n\t\tfor param_index in range(num_params):\n\t\t\tassert param_config_first[param_index] <= param_config_second[param_index]\n", "description": " test that the sort searchspace option with the sort_last_param_first option enabled works as expected ", "category": "simple", "imports": ["from __future__ import print_function", "from collections import OrderedDict", "from random import randrange", "from math import ceil", "\tfrom mock import patch", "\tfrom unittest.mock import patch", "from kernel_tuner.interface import Options", "from kernel_tuner.searchspace import Searchspace", "from constraint import ExactSumConstraint, FunctionConstraint", "import numpy as np"]}, {"term": "def", "name": "test_index_lookup", "data": "def test_index_lookup():\n\t\"\"\" test that index lookups are consistent for ~1% of the searchspace \"\"\"\n\tsize = searchspace.size\n\tfor _ in range(ceil(size / 100)):\n\t\trandom_index = randrange(0, size)\n\t\trandom_param_config = tuple(searchspace.list[random_index])\n\t\tindex = searchspace.get_param_config_index(random_param_config)\n\t\tassert index == random_index\n\n", "description": " test that index lookups are consistent for ~1% of the searchspace ", "category": "simple", "imports": ["from __future__ import print_function", "from collections import OrderedDict", "from random import randrange", "from math import ceil", "\tfrom mock import patch", "\tfrom unittest.mock import patch", "from kernel_tuner.interface import Options", "from kernel_tuner.searchspace import Searchspace", "from constraint import ExactSumConstraint, FunctionConstraint", "import numpy as np"]}, {"term": "def", "name": "test_param_index_lookup", "data": "def test_param_index_lookup():\n\t\"\"\" test the parameter index lookup for a parameter config is as expected \"\"\"\n\tfirst = tuple([1, 4, 'string_1'])\n\tlast = tuple([3, 5.5, 'string_2'])\n\tassert simple_searchspace.get_param_indices(first) == (0, 0, 0)\n\tassert simple_searchspace.get_param_indices(last) == (3, 1, 1)\n\n", "description": " test the parameter index lookup for a parameter config is as expected ", "category": "simple", "imports": ["from __future__ import print_function", "from collections import OrderedDict", "from random import randrange", "from math import ceil", "\tfrom mock import patch", "\tfrom unittest.mock import patch", "from kernel_tuner.interface import Options", "from kernel_tuner.searchspace import Searchspace", "from constraint import ExactSumConstraint, FunctionConstraint", "import numpy as np"]}, {"term": "def", "name": "test_random_sample", "data": "def test_random_sample():\n\t\"\"\" test whether the random sample indices exists and are unique, and if it throws an error for too many samples \"\"\"\n\trandom_sample_indices = searchspace.get_random_sample_indices(100)\n\tassert len(random_sample_indices) == 100\n\tfor index in random_sample_indices:\n\t\tassert isinstance(searchspace.list[index], tuple)\n\tassert random_sample_indices.size == np.unique(random_sample_indices).size\n\n\trandom_samples = searchspace.get_random_sample(100)\n\tfor sample in random_samples:\n\t\tassert sample in searchspace.list\n\n\t# num_samples equal to the number of configs should return the list\n\tsimple_random_sample_indices = simple_searchspace.get_random_sample_indices(simple_searchspace.size)\n\tassert simple_random_sample_indices.size == simple_searchspace.size\n\tassert simple_random_sample_indices.size == np.unique(simple_random_sample_indices).size\n\n\t# too many samples should result in a ValueError\n\ttry:\n\t\tsimple_searchspace.get_random_sample_indices(simple_searchspace.size + 1)\n\t\tprint(value_error_expectation_message)\n\t\tassert False\n\texcept ValueError as e:\n\t\tassert \"number of samples requested is greater than the searchspace size\" in str(e)\n\texcept Exception:\n\t\tprint(value_error_expectation_message)\n\t\tassert False\n\n", "description": " test whether the random sample indices exists and are unique, and if it throws an error for too many samples ", "category": "simple", "imports": ["from __future__ import print_function", "from collections import OrderedDict", "from random import randrange", "from math import ceil", "\tfrom mock import patch", "\tfrom unittest.mock import patch", "from kernel_tuner.interface import Options", "from kernel_tuner.searchspace import Searchspace", "from constraint import ExactSumConstraint, FunctionConstraint", "import numpy as np"]}, {"term": "def", "name": "__test_neighbors_prebuilt", "data": "def __test_neighbors_prebuilt(param_config: tuple, expected_neighbors: list, neighbor_method: str):\n\tsimple_searchspace_prebuilt = Searchspace(simple_tuning_options, max_threads, build_neighbors_index=True, neighbor_method=neighbor_method)\n\tneighbors = simple_searchspace_prebuilt.get_neighbors_no_cache(param_config)\n\tassert param_config not in neighbors\n\tfor neighbor in neighbors:\n\t\tassert neighbor in expected_neighbors\n\tassert len(neighbors) == len(expected_neighbors)\n\n", "description": null, "category": "simple", "imports": ["from __future__ import print_function", "from collections import OrderedDict", "from random import randrange", "from math import ceil", "\tfrom mock import patch", "\tfrom unittest.mock import patch", "from kernel_tuner.interface import Options", "from kernel_tuner.searchspace import Searchspace", "from constraint import ExactSumConstraint, FunctionConstraint", "import numpy as np"]}, {"term": "def", "name": "__test_neighbors_direct", "data": "def __test_neighbors_direct(param_config: tuple, expected_neighbors: list, neighbor_method: str):\n\tneighbors = simple_searchspace.get_neighbors_no_cache(param_config, neighbor_method)\n\tassert param_config not in neighbors\n\tfor neighbor in neighbors:\n\t\tassert neighbor in expected_neighbors\n\tassert len(neighbors) == len(expected_neighbors)\n\n", "description": null, "category": "simple", "imports": ["from __future__ import print_function", "from collections import OrderedDict", "from random import randrange", "from math import ceil", "\tfrom mock import patch", "\tfrom unittest.mock import patch", "from kernel_tuner.interface import Options", "from kernel_tuner.searchspace import Searchspace", "from constraint import ExactSumConstraint, FunctionConstraint", "import numpy as np"]}, {"term": "def", "name": "__test_neighbors", "data": "def __test_neighbors(param_config: tuple, expected_neighbors: list, neighbor_method: str):\n\t__test_neighbors_prebuilt(param_config, expected_neighbors, neighbor_method)\n\t__test_neighbors_direct(param_config, expected_neighbors, neighbor_method)\n\n", "description": null, "category": "simple", "imports": ["from __future__ import print_function", "from collections import OrderedDict", "from random import randrange", "from math import ceil", "\tfrom mock import patch", "\tfrom unittest.mock import patch", "from kernel_tuner.interface import Options", "from kernel_tuner.searchspace import Searchspace", "from constraint import ExactSumConstraint, FunctionConstraint", "import numpy as np"]}, {"term": "def", "name": "test_neighbors_hamming", "data": "def test_neighbors_hamming():\n\t\"\"\" test whether the neighbors with Hamming distance are as expected \"\"\"\n\ttest_config = tuple([1, 4, 'string_1'])\n\texpected_neighbors = [(2, 4, 'string_1'), (3, 4, 'string_1'), (1, 5.5, 'string_1'), (1, 4, 'string_2')]\n\t__test_neighbors(test_config, expected_neighbors, 'Hamming')\n\n", "description": " test whether the neighbors with Hamming distance are as expected ", "category": "simple", "imports": ["from __future__ import print_function", "from collections import OrderedDict", "from random import randrange", "from math import ceil", "\tfrom mock import patch", "\tfrom unittest.mock import patch", "from kernel_tuner.interface import Options", "from kernel_tuner.searchspace import Searchspace", "from constraint import ExactSumConstraint, FunctionConstraint", "import numpy as np"]}, {"term": "def", "name": "test_neighbors_strictlyadjacent", "data": "def test_neighbors_strictlyadjacent():\n\t\"\"\" test whether the strictly adjacent neighbors are as expected \"\"\"\n\ttest_config = tuple([1, 4, 'string_1'])\n\texpected_neighbors = [(1, 5.5, 'string_2'), (1, 5.5, 'string_1'), (1, 4, 'string_2')]\n\n\t__test_neighbors(test_config, expected_neighbors, 'strictly-adjacent')\n\n", "description": " test whether the strictly adjacent neighbors are as expected ", "category": "simple", "imports": ["from __future__ import print_function", "from collections import OrderedDict", "from random import randrange", "from math import ceil", "\tfrom mock import patch", "\tfrom unittest.mock import patch", "from kernel_tuner.interface import Options", "from kernel_tuner.searchspace import Searchspace", "from constraint import ExactSumConstraint, FunctionConstraint", "import numpy as np"]}, {"term": "def", "name": "test_neighbors_adjacent", "data": "def test_neighbors_adjacent():\n\t\"\"\" test whether the adjacent neighbors are as expected \"\"\"\n\ttest_config = tuple([1, 4, 'string_1'])\n\texpected_neighbors = [(2, 5.5, 'string_2'), (1, 5.5, 'string_2'), (2, 5.5, 'string_1'), (1, 5.5, 'string_1'), (2, 4, 'string_2'), (1, 4, 'string_2'),\n\t\t\t\t\t\t  (2, 4, 'string_1')]\n\n\t__test_neighbors(test_config, expected_neighbors, 'adjacent')\n\n", "description": " test whether the adjacent neighbors are as expected ", "category": "simple", "imports": ["from __future__ import print_function", "from collections import OrderedDict", "from random import randrange", "from math import ceil", "\tfrom mock import patch", "\tfrom unittest.mock import patch", "from kernel_tuner.interface import Options", "from kernel_tuner.searchspace import Searchspace", "from constraint import ExactSumConstraint, FunctionConstraint", "import numpy as np"]}, {"term": "def", "name": "test_neighbors_fictious", "data": "def test_neighbors_fictious():\n\t\"\"\" test whether the neighbors are as expected for a fictious parameter configuration (i.e. not existing in the search space due to restrictions) \"\"\"\n\ttest_config = tuple([1.5, 4, 'string_1'])\n\texpected_neighbors_hamming = [(1, 4, 'string_1'), (2, 4, 'string_1'), (3, 4, 'string_1')]\n\texpected_neighbors_strictlyadjacent = [(2, 5.5, 'string_2'), (1, 5.5, 'string_2'), (2, 5.5, 'string_1'), (1, 5.5, 'string_1'), (2, 4, 'string_2'),\n\t\t\t\t\t\t\t\t\t\t   (1, 4, 'string_2'), (2, 4, 'string_1'), (1, 4, 'string_1')]\n\n\texpected_neighbors_adjacent = expected_neighbors_strictlyadjacent\n\n\t__test_neighbors_direct(test_config, expected_neighbors_hamming, 'Hamming')\n\t__test_neighbors_direct(test_config, expected_neighbors_strictlyadjacent, 'strictly-adjacent')\n\t__test_neighbors_direct(test_config, expected_neighbors_adjacent, 'adjacent')\n\n", "description": " test whether the neighbors are as expected for a fictious parameter configuration (i.e. not existing in the search space due to restrictions) ", "category": "simple", "imports": ["from __future__ import print_function", "from collections import OrderedDict", "from random import randrange", "from math import ceil", "\tfrom mock import patch", "\tfrom unittest.mock import patch", "from kernel_tuner.interface import Options", "from kernel_tuner.searchspace import Searchspace", "from constraint import ExactSumConstraint, FunctionConstraint", "import numpy as np"]}, {"term": "def", "name": "test_neighbors_cached", "data": "def test_neighbors_cached():\n\t\"\"\" test whether retrieving a set of neighbors twice returns the cached version \"\"\"\n\tsimple_searchspace_duplicate = Searchspace(simple_tuning_options, max_threads, neighbor_method='Hamming')\n\ttest_configs = simple_searchspace_duplicate.get_random_sample(10)\n\tfor test_config in test_configs:\n\t\tassert not simple_searchspace_duplicate.are_neighbors_indices_cached(test_config)\n\t\tneighbors = simple_searchspace_duplicate.get_neighbors(test_config)\n\t\tassert simple_searchspace_duplicate.are_neighbors_indices_cached(test_config)\n\t\tneighbors_2 = simple_searchspace_duplicate.get_neighbors(test_config)\n\t\tassert neighbors == neighbors_2\n\n", "description": " test whether retrieving a set of neighbors twice returns the cached version ", "category": "simple", "imports": ["from __future__ import print_function", "from collections import OrderedDict", "from random import randrange", "from math import ceil", "\tfrom mock import patch", "\tfrom unittest.mock import patch", "from kernel_tuner.interface import Options", "from kernel_tuner.searchspace import Searchspace", "from constraint import ExactSumConstraint, FunctionConstraint", "import numpy as np"]}, {"term": "def", "name": "test_param_neighbors", "data": "def test_param_neighbors():\n\t\"\"\" test whether for a given parameter configuration and index the correct neighboring parameters are returned \"\"\"\n\ttest_config = tuple([1.5, 4, 'string_1'])\n\texpected_neighbors = [[1, 2], [5.5], ['string_2']]\n\n\tfor index in range(3):\n\t\tneighbor_params = simple_searchspace.get_param_neighbors(test_config, index, 'adjacent', randomize=False)\n\t\tprint(neighbor_params)\n\t\tassert len(neighbor_params) == len(expected_neighbors[index])\n\t\tfor param_index, param in enumerate(neighbor_params):\n\t\t\tassert param == expected_neighbors[index][param_index]\n\n", "description": " test whether for a given parameter configuration and index the correct neighboring parameters are returned ", "category": "simple", "imports": ["from __future__ import print_function", "from collections import OrderedDict", "from random import randrange", "from math import ceil", "\tfrom mock import patch", "\tfrom unittest.mock import patch", "from kernel_tuner.interface import Options", "from kernel_tuner.searchspace import Searchspace", "from constraint import ExactSumConstraint, FunctionConstraint", "import numpy as np"]}, {"term": "def", "name": "test_order_param_configs", "data": "def test_order_param_configs():\n\t\"\"\" test whether the ordering of parameter configurations according to parameter index happens as expected \"\"\"\n\ttest_order = [1, 2, 0]\n\ttest_config = tuple([1, 4, 'string_1'])\n\texpected_order = [(2, 5.5, 'string_2'), (2, 4, 'string_2'), (1, 4, 'string_2'), (2, 4, 'string_1'), (2, 5.5, 'string_1'), (1, 5.5, 'string_1'),\n\t\t\t\t\t  (1, 5.5, 'string_2')]\n\tneighbors = simple_searchspace.get_neighbors_no_cache(test_config, 'adjacent')\n\n\t# test failsafe too few indices\n\ttry:\n\t\tsimple_searchspace.order_param_configs(neighbors, [1, 2])\n\t\tprint(value_error_expectation_message)\n\t\tassert False\n\texcept ValueError as e:\n\t\tassert \"must be equal to the number of parameters\" in str(e)\n\texcept Exception:\n\t\tprint(value_error_expectation_message)\n\t\tassert False\n\n\t# test failsafe too many indices\n\ttry:\n\t\tsimple_searchspace.order_param_configs(neighbors, [1, 2, 0, 2])\n\t\tprint(value_error_expectation_message)\n\t\tassert False\n\texcept ValueError as e:\n\t\tassert \"must be equal to the number of parameters\" in str(e)\n\texcept Exception:\n\t\tprint(value_error_expectation_message)\n\t\tassert False\n\n\t# test failsafe invalid indices\n\ttry:\n\t\tsimple_searchspace.order_param_configs(neighbors, [1, 3, 0])\n\t\tprint(value_error_expectation_message)\n\t\tassert False\n\texcept ValueError as e:\n\t\tassert \"order needs to be a list of the parameter indices, but index\" in str(e)\n\texcept Exception:\n\t\tprint(value_error_expectation_message)\n\t\tassert False\n\n\t# test usecase\n\tordered_neighbors = simple_searchspace.order_param_configs(neighbors, test_order, randomize_in_params=False)\n\tfor index, expected_param_config in enumerate(expected_order):\n\t\tassert expected_param_config == ordered_neighbors[index]\n\n\t# test randomize in params\n\tordered_neighbors = simple_searchspace.order_param_configs(neighbors, test_order, randomize_in_params=True)\n\tfor expected_param_config in expected_order:\n\t\tassert expected_param_config in ordered_neighbors\n\tassert len(ordered_neighbors) == len(expected_order)\n\n", "description": " test whether the ordering of parameter configurations according to parameter index happens as expected ", "category": "simple", "imports": ["from __future__ import print_function", "from collections import OrderedDict", "from random import randrange", "from math import ceil", "\tfrom mock import patch", "\tfrom unittest.mock import patch", "from kernel_tuner.interface import Options", "from kernel_tuner.searchspace import Searchspace", "from constraint import ExactSumConstraint, FunctionConstraint", "import numpy as np"]}, {"term": "def", "name": "test_max_threads", "data": "def test_max_threads():\n\tmax_threads = 1024\n\ttune_params = dict()\n\ttune_params[\"block_size_x\"] = [512, 1024]\n\ttune_params[\"block_size_y\"] = [1]\n\ttuning_options = Options(dict(tune_params=tune_params, restrictions=None))\n\n\tsearchspace = Searchspace(tuning_options, max_threads)\n\n\tprint(searchspace.list)\n\n\tassert len(searchspace.list) > 1\n", "description": null, "category": "simple", "imports": ["from __future__ import print_function", "from collections import OrderedDict", "from random import randrange", "from math import ceil", "\tfrom mock import patch", "\tfrom unittest.mock import patch", "from kernel_tuner.interface import Options", "from kernel_tuner.searchspace import Searchspace", "from constraint import ExactSumConstraint, FunctionConstraint", "import numpy as np"]}], [{"term": "def", "name": "all_patterns", "data": "def all_patterns(name):\n\tu\"\"\"\n\tAccepts a string and returns a pattern of possible patterns involving that name\n\tCalled by simple_mapping_to_pattern for each name in the mapping it receives.\n\t\"\"\"\n\n\t# i_ denotes an import-like node\n\t# u_ denotes a node that appears to be a usage of the name\n\tif u'.' in name:\n\t\tname, attr = name.split(u'.', 1)\n\t\tsimple_name = simple_name_match % (name)\n\t\tsimple_attr = subname_match % (attr)\n\t\tdotted_name = dotted_name_match % (simple_name, simple_attr)\n\t\ti_from = from_import_match % (dotted_name)\n\t\ti_from_submod = from_import_submod_match % (simple_name, simple_attr, simple_attr, simple_attr, simple_attr)\n\t\ti_name = name_import_match % (dotted_name, dotted_name)\n\t\tu_name = power_twoname_match % (simple_name, simple_attr)\n\t\tu_subname = power_subname_match % (simple_attr)\n\t\treturn u' | \\n'.join((i_name, i_from, i_from_submod, u_name, u_subname))\n\telse:\n\t\tsimple_name = simple_name_match % (name)\n\t\ti_name = name_import_match % (simple_name, simple_name)\n\t\ti_from = from_import_match % (simple_name)\n\t\tu_name = power_onename_match % (simple_name)\n\t\treturn u' | \\n'.join((i_name, i_from, u_name))\n\n", "description": "\n\tAccepts a string and returns a pattern of possible patterns involving that name\n\tCalled by simple_mapping_to_pattern for each name in the mapping it receives.\n\t", "category": "simple", "imports": ["Fixer for standard library imports renamed in Python 3", "from lib2to3 import fixer_base", "from lib2to3.fixer_util import Name, is_probably_builtin, Newline, does_tree_import", "from lib2to3.pygram import python_symbols as syms", "from lib2to3.pgen2 import token", "from lib2to3.pytree import Node, Leaf", "from libfuturize.fixer_util import touch_import_top", "# from ..fixer_util import NameImport", "# helps match 'queue', as in 'from queue import ...'", "# helps match 'client', to be used if client has been imported from http", "# helps match 'http.client', as in 'import urllib.request'", "# helps match 'client.HTTPConnection', if 'client' has been imported from http", "# helps match 'from http.client import HTTPConnection'", "from_import_match = u\"from_import=import_from< 'from' %s 'import' imported=any >\"", "# helps match 'from http import client'", "from_import_submod_match = u\"from_import_submod=import_from< 'from' %s 'import' (%s | import_as_name< %s 'as' renamed=any > | import_as_names< any* (%s | import_as_name< %s 'as' renamed=any >) any* > ) >\"", "# helps match 'import urllib.request'", "name_import_match = u\"name_import=import_name< 'import' %s > | name_import=import_name< 'import' dotted_as_name< %s 'as' renamed=any > >\"", "# helps match 'import http.client, winreg'", "multiple_name_import_match = u\"name_import=import_name< 'import' dotted_as_names< names=any* > >\"", "\t# i_ denotes an import-like node", "\t\ti_from = from_import_match % (dotted_name)", "\t\ti_from_submod = from_import_submod_match % (simple_name, simple_attr, simple_attr, simple_attr, simple_attr)", "\t\ti_name = name_import_match % (dotted_name, dotted_name)", "\t\ti_name = name_import_match % (simple_name, simple_name)", "\t\ti_from = from_import_match % (simple_name)", "\tPATTERN = u' | \\n'.join((PATTERN, multiple_name_import_match))", "\t\ttouch_import_top(u'future', u'standard_library', node)"]}, {"term": "class", "name": "FixImports", "data": "class FixImports(fixer_base.BaseFix):\n\n\tPATTERN = u' | \\n'.join([all_patterns(name) for name in MAPPING])\n\tPATTERN = u' | \\n'.join((PATTERN, multiple_name_import_match))\n\n\tdef transform(self, node, results):\n\t\ttouch_import_top(u'future', u'standard_library', node)\n", "description": null, "category": "simple", "imports": ["Fixer for standard library imports renamed in Python 3", "from lib2to3 import fixer_base", "from lib2to3.fixer_util import Name, is_probably_builtin, Newline, does_tree_import", "from lib2to3.pygram import python_symbols as syms", "from lib2to3.pgen2 import token", "from lib2to3.pytree import Node, Leaf", "from libfuturize.fixer_util import touch_import_top", "# from ..fixer_util import NameImport", "# helps match 'queue', as in 'from queue import ...'", "# helps match 'client', to be used if client has been imported from http", "# helps match 'http.client', as in 'import urllib.request'", "# helps match 'client.HTTPConnection', if 'client' has been imported from http", "# helps match 'from http.client import HTTPConnection'", "from_import_match = u\"from_import=import_from< 'from' %s 'import' imported=any >\"", "# helps match 'from http import client'", "from_import_submod_match = u\"from_import_submod=import_from< 'from' %s 'import' (%s | import_as_name< %s 'as' renamed=any > | import_as_names< any* (%s | import_as_name< %s 'as' renamed=any >) any* > ) >\"", "# helps match 'import urllib.request'", "name_import_match = u\"name_import=import_name< 'import' %s > | name_import=import_name< 'import' dotted_as_name< %s 'as' renamed=any > >\"", "# helps match 'import http.client, winreg'", "multiple_name_import_match = u\"name_import=import_name< 'import' dotted_as_names< names=any* > >\"", "\t# i_ denotes an import-like node", "\t\ti_from = from_import_match % (dotted_name)", "\t\ti_from_submod = from_import_submod_match % (simple_name, simple_attr, simple_attr, simple_attr, simple_attr)", "\t\ti_name = name_import_match % (dotted_name, dotted_name)", "\t\ti_name = name_import_match % (simple_name, simple_name)", "\t\ti_from = from_import_match % (simple_name)", "\tPATTERN = u' | \\n'.join((PATTERN, multiple_name_import_match))", "\t\ttouch_import_top(u'future', u'standard_library', node)"]}], [{"term": "def", "name": "all_patterns", "data": "def all_patterns(name):\n\tu\"\"\"\n\tAccepts a string and returns a pattern of possible patterns involving that name\n\tCalled by simple_mapping_to_pattern for each name in the mapping it receives.\n\t\"\"\"\n\n\t# i_ denotes an import-like node\n\t# u_ denotes a node that appears to be a usage of the name\n\tif u'.' in name:\n\t\tname, attr = name.split(u'.', 1)\n\t\tsimple_name = simple_name_match % (name)\n\t\tsimple_attr = subname_match % (attr)\n\t\tdotted_name = dotted_name_match % (simple_name, simple_attr)\n\t\ti_from = from_import_match % (dotted_name)\n\t\ti_from_submod = from_import_submod_match % (simple_name, simple_attr, simple_attr, simple_attr, simple_attr)\n\t\ti_name = name_import_match % (dotted_name, dotted_name)\n\t\tu_name = power_twoname_match % (simple_name, simple_attr)\n\t\tu_subname = power_subname_match % (simple_attr)\n\t\treturn u' | \\n'.join((i_name, i_from, i_from_submod, u_name, u_subname))\n\telse:\n\t\tsimple_name = simple_name_match % (name)\n\t\ti_name = name_import_match % (simple_name, simple_name)\n\t\ti_from = from_import_match % (simple_name)\n\t\tu_name = power_onename_match % (simple_name)\n\t\treturn u' | \\n'.join((i_name, i_from, u_name))\n\n", "description": "\n\tAccepts a string and returns a pattern of possible patterns involving that name\n\tCalled by simple_mapping_to_pattern for each name in the mapping it receives.\n\t", "category": "simple", "imports": ["Fixer for standard library imports renamed in Python 3", "from lib2to3 import fixer_base", "from lib2to3.fixer_util import Name, is_probably_builtin, Newline, does_tree_import", "from lib2to3.pygram import python_symbols as syms", "from lib2to3.pgen2 import token", "from lib2to3.pytree import Node, Leaf", "from libfuturize.fixer_util import touch_import_top", "# from ..fixer_util import NameImport", "# helps match 'queue', as in 'from queue import ...'", "# helps match 'client', to be used if client has been imported from http", "# helps match 'http.client', as in 'import urllib.request'", "# helps match 'client.HTTPConnection', if 'client' has been imported from http", "# helps match 'from http.client import HTTPConnection'", "from_import_match = u\"from_import=import_from< 'from' %s 'import' imported=any >\"", "# helps match 'from http import client'", "from_import_submod_match = u\"from_import_submod=import_from< 'from' %s 'import' (%s | import_as_name< %s 'as' renamed=any > | import_as_names< any* (%s | import_as_name< %s 'as' renamed=any >) any* > ) >\"", "# helps match 'import urllib.request'", "name_import_match = u\"name_import=import_name< 'import' %s > | name_import=import_name< 'import' dotted_as_name< %s 'as' renamed=any > >\"", "# helps match 'import http.client, winreg'", "multiple_name_import_match = u\"name_import=import_name< 'import' dotted_as_names< names=any* > >\"", "\t# i_ denotes an import-like node", "\t\ti_from = from_import_match % (dotted_name)", "\t\ti_from_submod = from_import_submod_match % (simple_name, simple_attr, simple_attr, simple_attr, simple_attr)", "\t\ti_name = name_import_match % (dotted_name, dotted_name)", "\t\ti_name = name_import_match % (simple_name, simple_name)", "\t\ti_from = from_import_match % (simple_name)", "\tPATTERN = u' | \\n'.join((PATTERN, multiple_name_import_match))", "\t\ttouch_import_top(u'future', u'standard_library', node)"]}, {"term": "class", "name": "FixImports", "data": "class FixImports(fixer_base.BaseFix):\n\n\tPATTERN = u' | \\n'.join([all_patterns(name) for name in MAPPING])\n\tPATTERN = u' | \\n'.join((PATTERN, multiple_name_import_match))\n\n\tdef transform(self, node, results):\n\t\ttouch_import_top(u'future', u'standard_library', node)\n", "description": null, "category": "simple", "imports": ["Fixer for standard library imports renamed in Python 3", "from lib2to3 import fixer_base", "from lib2to3.fixer_util import Name, is_probably_builtin, Newline, does_tree_import", "from lib2to3.pygram import python_symbols as syms", "from lib2to3.pgen2 import token", "from lib2to3.pytree import Node, Leaf", "from libfuturize.fixer_util import touch_import_top", "# from ..fixer_util import NameImport", "# helps match 'queue', as in 'from queue import ...'", "# helps match 'client', to be used if client has been imported from http", "# helps match 'http.client', as in 'import urllib.request'", "# helps match 'client.HTTPConnection', if 'client' has been imported from http", "# helps match 'from http.client import HTTPConnection'", "from_import_match = u\"from_import=import_from< 'from' %s 'import' imported=any >\"", "# helps match 'from http import client'", "from_import_submod_match = u\"from_import_submod=import_from< 'from' %s 'import' (%s | import_as_name< %s 'as' renamed=any > | import_as_names< any* (%s | import_as_name< %s 'as' renamed=any >) any* > ) >\"", "# helps match 'import urllib.request'", "name_import_match = u\"name_import=import_name< 'import' %s > | name_import=import_name< 'import' dotted_as_name< %s 'as' renamed=any > >\"", "# helps match 'import http.client, winreg'", "multiple_name_import_match = u\"name_import=import_name< 'import' dotted_as_names< names=any* > >\"", "\t# i_ denotes an import-like node", "\t\ti_from = from_import_match % (dotted_name)", "\t\ti_from_submod = from_import_submod_match % (simple_name, simple_attr, simple_attr, simple_attr, simple_attr)", "\t\ti_name = name_import_match % (dotted_name, dotted_name)", "\t\ti_name = name_import_match % (simple_name, simple_name)", "\t\ti_from = from_import_match % (simple_name)", "\tPATTERN = u' | \\n'.join((PATTERN, multiple_name_import_match))", "\t\ttouch_import_top(u'future', u'standard_library', node)"]}], [{"term": "def", "name": "simple_act_state_processor", "data": "def simple_act_state_processor(monkeypatch) -> SimpleActStateProcessor:\n\tdef inverse_ordering(pathogens: List[Pathogen], game_state: GameState) -> List[Pathogen]:\n\t\treturn list(reversed(pathogens))\n\n\treturn SimpleActStateProcessor(inverse_ordering)\n\n", "description": null, "category": "simple", "imports": ["from datetime import timedelta", "from typing import List, Optional", "from unittest.mock import Mock", "import hypothesis", "import pytest", "from gym import spaces", "from hypothesis.strategies import integers", "from approaches.reinforced.action_state_processor import SimpleActStateProcessor", "from approaches.reinforced.constants import MAX_ACTIONSPACE, INVALID_ACTION, INVALID_ACTION_PENALTY, NEUTRAL_REWARD, \\", "from models import actions", "from models.actions import Action", "from models.city import City", "from models.gamestate import GameState", "from models.pathogen import Pathogen"]}, {"term": "def", "name": "test_generate_action_space", "data": "def test_generate_action_space(simple_act_state_processor: SimpleActStateProcessor):\n\tassert spaces.Discrete(MAX_ACTIONSPACE) == simple_act_state_processor.generate_action_space()\n\n", "description": null, "category": "simple", "imports": ["from datetime import timedelta", "from typing import List, Optional", "from unittest.mock import Mock", "import hypothesis", "import pytest", "from gym import spaces", "from hypothesis.strategies import integers", "from approaches.reinforced.action_state_processor import SimpleActStateProcessor", "from approaches.reinforced.constants import MAX_ACTIONSPACE, INVALID_ACTION, INVALID_ACTION_PENALTY, NEUTRAL_REWARD, \\", "from models import actions", "from models.actions import Action", "from models.city import City", "from models.gamestate import GameState", "from models.pathogen import Pathogen"]}, {"term": "def", "name": "test_generate_city_vaccine_actions", "data": "def test_generate_city_vaccine_actions(simple_act_state_processor: SimpleActStateProcessor,\n\t\t\t\t\t\t\t\t\t   city_with_pathogens: City,\n\t\t\t\t\t\t\t\t\t   available_pathogens: List[Pathogen],\n\t\t\t\t\t\t\t\t\t   pathogens_with_vaccination: List[Pathogen]):\n\tdeploy_vaccine_actions = [actions.deploy_vaccine(pathogen.index, city_with_pathogens.index)\n\t\t\t\t\t\t\t  if pathogen in city_with_pathogens.pathogens and pathogen in pathogens_with_vaccination\n\t\t\t\t\t\t\t  else INVALID_ACTION\n\t\t\t\t\t\t\t  for pathogen in available_pathogens]\n\n\tassert simple_act_state_processor._generate_city_vaccine_actions(city_with_pathogens,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t available_pathogens,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t pathogens_with_vaccination) == deploy_vaccine_actions\n\n\tassert simple_act_state_processor._generate_city_vaccine_actions(\n\t\tcity_with_pathogens,\n\t\tavailable_pathogens,\n\t\tlist(reversed(pathogens_with_vaccination))) == deploy_vaccine_actions\n\n\tassert simple_act_state_processor._generate_city_vaccine_actions(\n\t\tcity_with_pathogens,\n\t\tlist(reversed(available_pathogens)),\n\t\tpathogens_with_vaccination) == list(reversed(deploy_vaccine_actions))\n\n", "description": null, "category": "simple", "imports": ["from datetime import timedelta", "from typing import List, Optional", "from unittest.mock import Mock", "import hypothesis", "import pytest", "from gym import spaces", "from hypothesis.strategies import integers", "from approaches.reinforced.action_state_processor import SimpleActStateProcessor", "from approaches.reinforced.constants import MAX_ACTIONSPACE, INVALID_ACTION, INVALID_ACTION_PENALTY, NEUTRAL_REWARD, \\", "from models import actions", "from models.actions import Action", "from models.city import City", "from models.gamestate import GameState", "from models.pathogen import Pathogen"]}, {"term": "def", "name": "test_generate_city_med_actions", "data": "def test_generate_city_med_actions(simple_act_state_processor: SimpleActStateProcessor,\n\t\t\t\t\t\t\t\t   city_with_pathogens: City,\n\t\t\t\t\t\t\t\t   available_pathogens: List[Pathogen],\n\t\t\t\t\t\t\t\t   pathogens_with_medication: List[Pathogen]):\n\tdeploy_med_actions = [actions.deploy_medication(pathogen.index, city_with_pathogens.index)\n\t\t\t\t\t\t  if (pathogen in city_with_pathogens.pathogens and pathogen in pathogens_with_medication)\n\t\t\t\t\t\t  else INVALID_ACTION\n\t\t\t\t\t\t  for pathogen in available_pathogens]\n\n\tassert simple_act_state_processor._generate_city_med_actions(city_with_pathogens,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t available_pathogens,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t pathogens_with_medication) == deploy_med_actions\n\n\tassert simple_act_state_processor._generate_city_med_actions(\n\t\tcity_with_pathogens,\n\t\tavailable_pathogens,\n\t\tlist(reversed(pathogens_with_medication))) == deploy_med_actions\n\n\tassert simple_act_state_processor._generate_city_med_actions(\n\t\tcity_with_pathogens,\n\t\tlist(reversed(available_pathogens)),\n\t\tpathogens_with_medication) == list(reversed(deploy_med_actions))\n\n", "description": null, "category": "simple", "imports": ["from datetime import timedelta", "from typing import List, Optional", "from unittest.mock import Mock", "import hypothesis", "import pytest", "from gym import spaces", "from hypothesis.strategies import integers", "from approaches.reinforced.action_state_processor import SimpleActStateProcessor", "from approaches.reinforced.constants import MAX_ACTIONSPACE, INVALID_ACTION, INVALID_ACTION_PENALTY, NEUTRAL_REWARD, \\", "from models import actions", "from models.actions import Action", "from models.city import City", "from models.gamestate import GameState", "from models.pathogen import Pathogen"]}, {"term": "def", "name": "test_generate_global_vaccine_actions", "data": "def test_generate_global_vaccine_actions(simple_act_state_processor: SimpleActStateProcessor,\n\t\t\t\t\t\t\t\t\t\t available_pathogens: List[Pathogen],\n\t\t\t\t\t\t\t\t\t\t pathogens_with_vaccination: List[Pathogen]):\n\tdevelop_vaccine_actions = [actions.develop_vaccine(pathogen.index)\n\t\t\t\t\t\t\t   if (pathogen not in pathogens_with_vaccination)\n\t\t\t\t\t\t\t   else INVALID_ACTION\n\t\t\t\t\t\t\t   for pathogen in available_pathogens]\n\n\tassert list(simple_act_state_processor._generate_global_vaccine_actions(\n\t\tavailable_pathogens,\n\t\tpathogens_with_vaccination)) == develop_vaccine_actions\n\n\tassert list(simple_act_state_processor._generate_global_vaccine_actions(\n\t\tavailable_pathogens,\n\t\tlist(reversed(pathogens_with_vaccination)))) == develop_vaccine_actions\n\n\tassert list(simple_act_state_processor._generate_global_vaccine_actions(\n\t\tlist(reversed(available_pathogens)), pathogens_with_vaccination)) == list(\n\t\treversed(develop_vaccine_actions))\n\n", "description": null, "category": "simple", "imports": ["from datetime import timedelta", "from typing import List, Optional", "from unittest.mock import Mock", "import hypothesis", "import pytest", "from gym import spaces", "from hypothesis.strategies import integers", "from approaches.reinforced.action_state_processor import SimpleActStateProcessor", "from approaches.reinforced.constants import MAX_ACTIONSPACE, INVALID_ACTION, INVALID_ACTION_PENALTY, NEUTRAL_REWARD, \\", "from models import actions", "from models.actions import Action", "from models.city import City", "from models.gamestate import GameState", "from models.pathogen import Pathogen"]}, {"term": "def", "name": "test_generate_global_med_actions", "data": "def test_generate_global_med_actions(simple_act_state_processor: SimpleActStateProcessor,\n\t\t\t\t\t\t\t\t\t available_pathogens: List[Pathogen],\n\t\t\t\t\t\t\t\t\t pathogens_with_medication: List[Pathogen]):\n\tdevelop_med_actions = [actions.develop_medication(pathogen.index)\n\t\t\t\t\t\t   if (pathogen not in pathogens_with_medication)\n\t\t\t\t\t\t   else INVALID_ACTION\n\t\t\t\t\t\t   for pathogen in available_pathogens]\n\n\tassert list(simple_act_state_processor._generate_global_med_actions(\n\t\tavailable_pathogens,\n\t\tpathogens_with_medication)) == develop_med_actions\n\n\tassert list(simple_act_state_processor._generate_global_med_actions(\n\t\tavailable_pathogens,\n\t\tlist(reversed(pathogens_with_medication)))) == develop_med_actions\n\n\tassert list(simple_act_state_processor._generate_global_med_actions(\n\t\tlist(reversed(available_pathogens)), pathogens_with_medication)) == list(reversed(develop_med_actions))\n\n", "description": null, "category": "simple", "imports": ["from datetime import timedelta", "from typing import List, Optional", "from unittest.mock import Mock", "import hypothesis", "import pytest", "from gym import spaces", "from hypothesis.strategies import integers", "from approaches.reinforced.action_state_processor import SimpleActStateProcessor", "from approaches.reinforced.constants import MAX_ACTIONSPACE, INVALID_ACTION, INVALID_ACTION_PENALTY, NEUTRAL_REWARD, \\", "from models import actions", "from models.actions import Action", "from models.city import City", "from models.gamestate import GameState", "from models.pathogen import Pathogen"]}, {"term": "def", "name": "test_penalize_action", "data": "def test_penalize_action(simple_act_state_processor: SimpleActStateProcessor, gamestate_stub: Mock, monkeypatch,\n\t\t\t\t\t\t chosen_action: Optional[Action], possible_actions: List[Action], expected_penalty: int):\n\t# GIVEN\n\tmonkeypatch.setattr('models.actions.generate_possible_actions', lambda _: possible_actions)\n\t# THEN\n\tassert simple_act_state_processor.penalize_action(chosen_action, gamestate_stub) \\\n\t\t   == (chosen_action, expected_penalty)\n\n", "description": null, "category": "simple", "imports": ["from datetime import timedelta", "from typing import List, Optional", "from unittest.mock import Mock", "import hypothesis", "import pytest", "from gym import spaces", "from hypothesis.strategies import integers", "from approaches.reinforced.action_state_processor import SimpleActStateProcessor", "from approaches.reinforced.constants import MAX_ACTIONSPACE, INVALID_ACTION, INVALID_ACTION_PENALTY, NEUTRAL_REWARD, \\", "from models import actions", "from models.actions import Action", "from models.city import City", "from models.gamestate import GameState", "from models.pathogen import Pathogen"]}, {"term": "def", "name": "test_transform_for_city_action", "data": "def test_transform_for_city_action(simple_act_state_processor: SimpleActStateProcessor,\n\t\t\t\t\t\t\t\t   random_city_id: int, random_action_id: int):\n\taction: int = random_city_id * CITY_ACTIONSPACE + random_action_id\n\tassert simple_act_state_processor._transform_for_city_action(action) == (random_action_id, random_city_id)\n\n", "description": null, "category": "simple", "imports": ["from datetime import timedelta", "from typing import List, Optional", "from unittest.mock import Mock", "import hypothesis", "import pytest", "from gym import spaces", "from hypothesis.strategies import integers", "from approaches.reinforced.action_state_processor import SimpleActStateProcessor", "from approaches.reinforced.constants import MAX_ACTIONSPACE, INVALID_ACTION, INVALID_ACTION_PENALTY, NEUTRAL_REWARD, \\", "from models import actions", "from models.actions import Action", "from models.city import City", "from models.gamestate import GameState", "from models.pathogen import Pathogen"]}, {"term": "def", "name": "test_map_city_actions", "data": "def test_map_city_actions(simple_act_state_processor: SimpleActStateProcessor, gamestate_stub: GameState,\n\t\t\t\t\t\t  random_action_id: int):\n\tchosen_action: int = random_action_id % CITY_ACTIONSPACE\n\tpathogens_with_vacc_or_med = (6, 8, 10, 12, 13, 14)\n\tif chosen_action in range(0, 6) or chosen_action in pathogens_with_vacc_or_med:\n\t\tassert simple_act_state_processor._map_city_actions(chosen_action, gamestate_stub) \\\n\t\t\t   in actions.generate_possible_actions(gamestate_stub)\n\telse:\n\t\tassert simple_act_state_processor._map_city_actions(chosen_action, gamestate_stub) == INVALID_ACTION\n\n", "description": null, "category": "simple", "imports": ["from datetime import timedelta", "from typing import List, Optional", "from unittest.mock import Mock", "import hypothesis", "import pytest", "from gym import spaces", "from hypothesis.strategies import integers", "from approaches.reinforced.action_state_processor import SimpleActStateProcessor", "from approaches.reinforced.constants import MAX_ACTIONSPACE, INVALID_ACTION, INVALID_ACTION_PENALTY, NEUTRAL_REWARD, \\", "from models import actions", "from models.actions import Action", "from models.city import City", "from models.gamestate import GameState", "from models.pathogen import Pathogen"]}, {"term": "def", "name": "test_map_global_actions", "data": "def test_map_global_actions(simple_act_state_processor: SimpleActStateProcessor, gamestate_stub: GameState,\n\t\t\t\t\t\t\trandom_action_id: int):\n\tchosen_action: int = random_action_id\n\tpathogens_with_vacc_or_med = (1, 2, 3, 5, 6, 7, 8, 9)\n\tif random_action_id == 0 or random_action_id not in pathogens_with_vacc_or_med:\n\t\tassert simple_act_state_processor._map_global_actions(chosen_action, gamestate_stub) \\\n\t\t\t   in actions.generate_possible_actions(gamestate_stub)\n\telse:\n\t\tassert simple_act_state_processor._map_global_actions(chosen_action, gamestate_stub) == INVALID_ACTION\n\n", "description": null, "category": "simple", "imports": ["from datetime import timedelta", "from typing import List, Optional", "from unittest.mock import Mock", "import hypothesis", "import pytest", "from gym import spaces", "from hypothesis.strategies import integers", "from approaches.reinforced.action_state_processor import SimpleActStateProcessor", "from approaches.reinforced.constants import MAX_ACTIONSPACE, INVALID_ACTION, INVALID_ACTION_PENALTY, NEUTRAL_REWARD, \\", "from models import actions", "from models.actions import Action", "from models.city import City", "from models.gamestate import GameState", "from models.pathogen import Pathogen"]}, {"term": "def", "name": "test_map_action", "data": "def test_map_action(simple_act_state_processor: SimpleActStateProcessor, gamestate_stub: GameState,\n\t\t\t\t\trandom_action_id: int):\n\tif random_action_id < GLOBAL_ACTIONSPACE:\n\t\texpected = simple_act_state_processor.penalize_action(\n\t\t\tsimple_act_state_processor._map_global_actions(random_action_id, gamestate_stub), gamestate_stub)\n\t\tassert expected == simple_act_state_processor.map_action(random_action_id, gamestate_stub)\n\telse:\n\t\trandom_city_action_id = random_action_id - GLOBAL_ACTIONSPACE\n\t\texpected = simple_act_state_processor.penalize_action(\n\t\t\tsimple_act_state_processor._map_city_actions(random_city_action_id, gamestate_stub), gamestate_stub)\n\t\tassert expected == simple_act_state_processor.map_action(random_action_id, gamestate_stub)\n", "description": null, "category": "simple", "imports": ["from datetime import timedelta", "from typing import List, Optional", "from unittest.mock import Mock", "import hypothesis", "import pytest", "from gym import spaces", "from hypothesis.strategies import integers", "from approaches.reinforced.action_state_processor import SimpleActStateProcessor", "from approaches.reinforced.constants import MAX_ACTIONSPACE, INVALID_ACTION, INVALID_ACTION_PENALTY, NEUTRAL_REWARD, \\", "from models import actions", "from models.actions import Action", "from models.city import City", "from models.gamestate import GameState", "from models.pathogen import Pathogen"]}], [{"term": "def", "name": "suite", "data": "def suite():\n\ts = DocutilsTestSupport.HtmlPublishPartsTestSuite()\n\ts.generateTests(totest)\n\treturn s\n\n", "description": null, "category": "simple", "imports": ["from __init__ import DocutilsTestSupport", "from docutils import core", "\timport unittest"]}], [], [], [{"term": "class", "name": "ComplexReflectionOrGeneralizedCoxeterGroups", "data": "class ComplexReflectionOrGeneralizedCoxeterGroups(Category_singleton):\n\tr\"\"\"\n\tThe category of complex reflection groups or generalized Coxeter groups.\n\n\tFinite Coxeter groups can be defined equivalently as groups\n\tgenerated by reflections, or by presentations. Over the last\n\tdecades, the theory has been generalized in both directions,\n\tleading to the study of (finite) complex reflection groups on the\n\tone hand, and (finite) generalized Coxeter groups on the other\n\thand. Many of the features remain similar, yet, in the current\n\tstate of the art, there is no general theory covering both\n\tdirections.\n\n\tThis is reflected by the name of this category which is about\n\tfactoring out the common code, tests, and declarations.\n\n\tA group in this category has:\n\n\t- A distinguished finite set of generators `(s_i)_I`, called\n\t  *simple reflections*. The set `I` is called the *index set*. The\n\t  name \"reflection\" is somewhat of an abuse as they can have\n\t  higher order; still, they are all of finite order: `s_i^k=1` for\n\t  some `k`.\n\n\t- A collection of *distinguished reflections* which are the\n\t  conjugates of the simple reflections. For complex reflection\n\t  groups, they are in one-to-one correspondence with the\n\t  reflection hyperplanes and share the same index set.\n\n\t- A collection of *reflections* which are the conjugates of all\n\t  the non trivial powers of the simple reflections.\n\n\tThe usual notions of reduced words, length, irreducibility, etc\n\tcan be canonically defined from the above.\n\n\tThe following methods must be implemented:\n\n\t- :meth:`ComplexReflectionOrGeneralizedCoxeterGroups.ParentMethods.index_set`\n\t- :meth:`ComplexReflectionOrGeneralizedCoxeterGroups.ParentMethods.simple_reflection`\n\n\tOptionally one can define analog methods for distinguished\n\treflections and reflections (see below).\n\n\tAt least one of the following methods must be implemented:\n\n\t- :meth:`ComplexReflectionOrGeneralizedCoxeterGroups.ElementMethods.apply_simple_reflection`\n\t- :meth:`ComplexReflectionOrGeneralizedCoxeterGroups.ElementMethods.apply_simple_reflection_left`\n\t- :meth:`ComplexReflectionOrGeneralizedCoxeterGroups.ElementMethods.apply_simple_reflection_right`\n\t- :meth:`ComplexReflectionOrGeneralizedCoxeterGroups.ElementMethods._mul_`\n\n\tIt's recommended to implement either ``_mul_`` or both\n\t``apply_simple_reflection_left`` and ``apply_simple_reflection_right``.\n\n\t.. SEEALSO::\n\n\t\t- :class:`complex_reflection_groups.ComplexReflectionGroups`\n\t\t- :class:`generalized_coxeter_groups.GeneralizedCoxeterGroups`\n\n\tEXAMPLES::\n\n\t\tsage: from sage.categories.complex_reflection_or_generalized_coxeter_groups import ComplexReflectionOrGeneralizedCoxeterGroups\n\t\tsage: C = ComplexReflectionOrGeneralizedCoxeterGroups(); C\n\t\tCategory of complex reflection or generalized coxeter groups\n\t\tsage: C.super_categories()\n\t\t[Category of finitely generated enumerated groups]\n\n\t\tsage: C.required_methods()\n\t\t{'element': {'optional': ['reflection_length'],\n\t\t\t\t\t 'required': []},\n\t\t  'parent': {'optional': ['distinguished_reflection', 'hyperplane_index_set',\n\t\t\t\t\t\t\t\t  'irreducible_components',\n\t\t\t\t\t\t\t\t  'reflection', 'reflection_index_set'],\n\t\t\t\t\t'required':  ['__contains__', 'index_set']}}\n\n\tTESTS::\n\n\t\tsage: TestSuite(C).run()\n\t\"\"\"\n\n\t@cached_method\n\tdef super_categories(self):\n\t\tr\"\"\"\n\t\tReturn the super categories of ``self``.\n\n\t\tEXAMPLES::\n\n\t\t\tsage: from sage.categories.complex_reflection_groups import ComplexReflectionGroups\n\t\t\tsage: ComplexReflectionGroups().super_categories()\n\t\t\t[Category of complex reflection or generalized coxeter groups]\n\t\t\"\"\"\n\t\treturn [Groups().FinitelyGenerated()]\n\n\tclass SubcategoryMethods:\n\t\tdef Irreducible(self):\n\t\t\tr\"\"\"\n\t\t\tReturn the full subcategory of irreducible objects of ``self``.\n\n\t\t\tA complex reflection group, or generalized coxeter group\n\t\t\tis *reducible* if its simple reflections can be split in\n\t\t\ttwo sets `X` and `Y` such that the elements of `X` commute\n\t\t\twith that of `Y`. In particular, the group is then direct\n\t\t\tproduct of `\\langle X \\rangle` and `\\langle Y \\rangle`.\n\t\t\tIt's *irreducible* otherwise.\n\n\t\t\tEXAMPLES::\n\n\t\t\t\tsage: from sage.categories.complex_reflection_groups import ComplexReflectionGroups\n\t\t\t\tsage: ComplexReflectionGroups().Irreducible()\n\t\t\t\tCategory of irreducible complex reflection groups\n\t\t\t\tsage: CoxeterGroups().Irreducible()\n\t\t\t\tCategory of irreducible coxeter groups\n\n\t\t\tTESTS::\n\n\t\t\t\tsage: TestSuite(ComplexReflectionGroups().Irreducible()).run()\n\t\t\t\tsage: CoxeterGroups().Irreducible.__module__\n\t\t\t\t'sage.categories.complex_reflection_or_generalized_coxeter_groups'\n\t\t\t\"\"\"\n\t\t\treturn self._with_axiom('Irreducible')\n\n\tclass ParentMethods:\n\t\t@abstract_method\n\t\tdef index_set(self):\n\t\t\tr\"\"\"\n\t\t\tReturn the index set of (the simple reflections of)\n\t\t\t``self``, as a list (or iterable).\n\n\t\t\t.. SEEALSO::\n\n\t\t\t\t- :meth:`simple_reflection`\n\t\t\t\t- :meth:`simple_reflections`\n\n\t\t\tEXAMPLES::\n\n\t\t\t\tsage: W = CoxeterGroups().Finite().example(); W\n\t\t\t\tThe 5-th dihedral group of order 10\n\t\t\t\tsage: W.index_set()\n\t\t\t\t(1, 2)\n\n\t\t\t\tsage: W = ColoredPermutations(1, 4)\n\t\t\t\tsage: W.index_set()\n\t\t\t\t(1, 2, 3)\n\t\t\t\tsage: W = ReflectionGroup((1,1,4), index_set=[1,3,'asdf'])  # optional - gap3\n\t\t\t\tsage: W.index_set()\t\t\t\t\t\t\t\t\t # optional - gap3\n\t\t\t\t(1, 3, 'asdf')\n\t\t\t\tsage: W = ReflectionGroup((1,1,4), index_set=('a','b','c')) # optional - gap3\n\t\t\t\tsage: W.index_set()\t\t\t\t\t\t\t\t\t # optional - gap3\n\t\t\t\t('a', 'b', 'c')\n\t\t\t\"\"\"\n\t\t\t# return self.simple_reflections().keys()\n\n\t\tdef simple_reflection(self, i):\n\t\t\t\"\"\"\n\t\t\tReturn the `i`-th simple reflection `s_i` of ``self``.\n\n\t\t\tINPUT:\n\n\t\t\t- ``i`` -- an element from the index set\n\n\t\t\t.. SEEALSO::\n\n\t\t\t\t- :meth:`index_set`\n\t\t\t\t- :meth:`simple_reflections`\n\n\t\t\tEXAMPLES::\n\n\t\t\t\tsage: W = CoxeterGroups().example()\n\t\t\t\tsage: W\n\t\t\t\tThe symmetric group on {0, ..., 3}\n\t\t\t\tsage: W.simple_reflection(1)\n\t\t\t\t(0, 2, 1, 3)\n\t\t\t\tsage: s = W.simple_reflections()\n\t\t\t\tsage: s[1]\n\t\t\t\t(0, 2, 1, 3)\n\n\t\t\t\tsage: W = ReflectionGroup((1,1,4), index_set=[1,3,'asdf'])  # optional - gap3\n\t\t\t\tsage: for i in W.index_set():\t\t\t\t\t\t   # optional - gap3\n\t\t\t\t....:\t print('%s %s'%(i, W.simple_reflection(i)))\t# optional - gap3\n\t\t\t\t1 (1,7)(2,4)(5,6)(8,10)(11,12)\n\t\t\t\t3 (1,4)(2,8)(3,5)(7,10)(9,11)\n\t\t\t\tasdf (2,5)(3,9)(4,6)(8,11)(10,12)\n\t\t\t\"\"\"\n\t\t\tif not i in self.index_set():\n\t\t\t\traise ValueError(\"%s is not in the Dynkin node set %s\" % (i, self.index_set()))\n\t\t\treturn self.one().apply_simple_reflection(i)  # don't care about left/right\n\n\t\t@cached_method\n\t\tdef simple_reflections(self):\n\t\t\tr\"\"\"\n\t\t\tReturn the simple reflections `(s_i)_{i\\in I}` of ``self`` as\n\t\t\ta family indexed by :meth:`index_set`.\n\n\t\t\t.. SEEALSO::\n\n\t\t\t\t- :meth:`simple_reflection`\n\t\t\t\t- :meth:`index_set`\n\n\t\t\tEXAMPLES:\n\n\t\t\tFor the symmetric group, we recognize the simple transpositions::\n\n\t\t\t\tsage: W = SymmetricGroup(4); W\n\t\t\t\tSymmetric group of order 4! as a permutation group\n\t\t\t\tsage: s = W.simple_reflections()\n\t\t\t\tsage: s\n\t\t\t\tFinite family {1: (1,2), 2: (2,3), 3: (3,4)}\n\t\t\t\tsage: s[1]\n\t\t\t\t(1,2)\n\t\t\t\tsage: s[2]\n\t\t\t\t(2,3)\n\t\t\t\tsage: s[3]\n\t\t\t\t(3,4)\n\n\t\t\tHere are the simple reflections for a colored symmetric\n\t\t\tgroup and a reflection group::\n\n\t\t\t\tsage: W = ColoredPermutations(1,3)\n\t\t\t\tsage: W.simple_reflections()\n\t\t\t\tFinite family {1: [[0, 0, 0], [2, 1, 3]], 2: [[0, 0, 0], [1, 3, 2]]}\n\n\t\t\t\tsage: W = ReflectionGroup((1,1,3), index_set=['a','b']) # optional - gap3\n\t\t\t\tsage: W.simple_reflections()\t\t\t\t\t\t\t# optional - gap3\n\t\t\t\tFinite family {'a': (1,4)(2,3)(5,6), 'b': (1,3)(2,5)(4,6)}\n\n\t\t\tThis default implementation uses :meth:`.index_set` and\n\t\t\t:meth:`.simple_reflection`.\n\t\t\t\"\"\"\n\t\t\tfrom sage.sets.family import Family\n\t\t\treturn Family(self.index_set(), self.simple_reflection)\n\n\t\tdef number_of_simple_reflections(self):\n\t\t\tr\"\"\"\n\t\t\tReturn the number of simple reflections of ``self``.\n\n\t\t\tEXAMPLES::\n\n\t\t\t\tsage: W = ColoredPermutations(1,3)\n\t\t\t\tsage: W.number_of_simple_reflections()\n\t\t\t\t2\n\t\t\t\tsage: W = ColoredPermutations(2,3)\n\t\t\t\tsage: W.number_of_simple_reflections()\n\t\t\t\t3\n\t\t\t\tsage: W = ColoredPermutations(4,3)\n\t\t\t\tsage: W.number_of_simple_reflections()\n\t\t\t\t3\n\t\t\t\tsage: W = ReflectionGroup((4,2,3))\t\t\t\t\t  # optional - gap3\n\t\t\t\tsage: W.number_of_simple_reflections()\t\t\t\t  # optional - gap3\n\t\t\t\t4\n\t\t\t\"\"\"\n\t\t\treturn len(self.index_set())\n\n\t\t##########################################################################\n\t\t# Group generators, etc from simple reflections\n\t\t##########################################################################\n\n\t\tdef group_generators(self):\n\t\t\tr\"\"\"\n\t\t\tReturn the simple reflections of ``self``, as\n\t\t\tdistinguished group generators.\n\n\t\t\t.. SEEALSO::\n\n\t\t\t\t- :meth:`simple_reflections`\n\t\t\t\t- :meth:`Groups.ParentMethods.group_generators`\n\t\t\t\t- :meth:`Semigroups.ParentMethods.semigroup_generators`\n\n\t\t\tEXAMPLES::\n\n\t\t\t\tsage: D10 = FiniteCoxeterGroups().example(10)\n\t\t\t\tsage: D10.group_generators()\n\t\t\t\tFinite family {1: (1,), 2: (2,)}\n\t\t\t\tsage: SymmetricGroup(5).group_generators()\n\t\t\t\tFinite family {1: (1,2), 2: (2,3), 3: (3,4), 4: (4,5)}\n\n\t\t\t\tsage: W = ColoredPermutations(3,2)\n\t\t\t\tsage: W.group_generators()\n\t\t\t\tFinite family {1: [[0, 0],\n\t\t\t\t\t\t\t\t   [2, 1]],\n\t\t\t\t\t\t\t   2: [[0, 1],\n\t\t\t\t\t\t\t\t   [1, 2]]}\n\n\t\t\tThe simple reflections are also semigroup generators, even\n\t\t\tfor an infinite group::\n\n\t\t\t\tsage: W = WeylGroup([\"A\",2,1])\n\t\t\t\tsage: W.semigroup_generators()\n\t\t\t\tFinite family {0: [-1  1  1]\n\t\t\t\t\t\t\t\t  [ 0  1  0]\n\t\t\t\t\t\t\t\t  [ 0  0  1],\n\t\t\t\t\t\t\t   1: [ 1  0  0]\n\t\t\t\t\t\t\t\t  [ 1 -1  1]\n\t\t\t\t\t\t\t\t  [ 0  0  1],\n\t\t\t\t\t\t\t   2: [ 1  0  0]\n\t\t\t\t\t\t\t\t  [ 0  1  0]\n\t\t\t\t\t\t\t\t  [ 1  1 -1]}\n\t\t\t\"\"\"\n\t\t\treturn self.simple_reflections()\n\n\t\tsemigroup_generators = group_generators\n\n\t\tdef simple_reflection_orders(self):\n\t\t\t\"\"\"\n\t\t\tReturn the orders of the simple reflections.\n\n\t\t\tEXAMPLES::\n\n\t\t\t\tsage: W = WeylGroup(['B',3])\n\t\t\t\tsage: W.simple_reflection_orders()\n\t\t\t\t[2, 2, 2]\n\t\t\t\tsage: W = CoxeterGroup(['C',4])\n\t\t\t\tsage: W.simple_reflection_orders()\n\t\t\t\t[2, 2, 2, 2]\n\t\t\t\tsage: SymmetricGroup(5).simple_reflection_orders()\n\t\t\t\t[2, 2, 2, 2]\n\t\t\t\tsage: C = ColoredPermutations(4, 3)\n\t\t\t\tsage: C.simple_reflection_orders()\n\t\t\t\t[2, 2, 4]\n\t\t\t\"\"\"\n\t\t\tone = self.one()\n\t\t\ts = self.simple_reflections()\n\t\t\tfrom sage.rings.integer_ring import ZZ\n\n\t\t\tdef mult_order(x):\n\t\t\t\tct = ZZ.one()\n\t\t\t\tcur = x\n\t\t\t\twhile cur != one:\n\t\t\t\t\tcur *= x\n\t\t\t\t\tct += ZZ.one()\n\t\t\t\treturn ZZ(ct)\n\t\t\treturn [mult_order(s[i]) for i in self.index_set()]\n\n\t\tdef _an_element_(self):\n\t\t\t\"\"\"\n\t\t\tImplement: :meth:`Sets.ParentMethods.an_element` by\n\t\t\treturning the product of the simple reflections (a Coxeter\n\t\t\telement).\n\n\t\t\tEXAMPLES::\n\n\t\t\t\tsage: W = SymmetricGroup(4); W\n\t\t\t\tSymmetric group of order 4! as a permutation group\n\t\t\t\tsage: W.an_element()\t\t\t   # indirect doctest\n\t\t\t\t(2,3,4)\n\n\t\t\tFor a complex reflection group::\n\n\t\t\t\tsage: from sage.categories.complex_reflection_groups import ComplexReflectionGroups\n\t\t\t\tsage: W = ComplexReflectionGroups().example(); W\n\t\t\t\t5-colored permutations of size 3\n\t\t\t\tsage: W.an_element()\n\t\t\t\t[[1, 0, 0], [3, 1, 2]]\n\t\t\t\"\"\"\n\t\t\treturn self.prod(self.simple_reflections())\n\n\t\tdef some_elements(self):\n\t\t\tr\"\"\"\n\t\t\tImplement :meth:`Sets.ParentMethods.some_elements` by\n\t\t\treturning some typical elements of ``self``.\n\n\t\t\tThe result is currently composed of the simple reflections\n\t\t\ttogether with the unit and the result of :meth:`an_element`.\n\n\t\t\tEXAMPLES::\n\n\t\t\t\tsage: W = WeylGroup(['A',3])\n\t\t\t\tsage: W.some_elements()\n\t\t\t\t[\n\t\t\t\t[0 1 0 0]  [1 0 0 0]  [1 0 0 0]  [1 0 0 0]  [0 0 0 1]\n\t\t\t\t[1 0 0 0]  [0 0 1 0]  [0 1 0 0]  [0 1 0 0]  [1 0 0 0]\n\t\t\t\t[0 0 1 0]  [0 1 0 0]  [0 0 0 1]  [0 0 1 0]  [0 1 0 0]\n\t\t\t\t[0 0 0 1], [0 0 0 1], [0 0 1 0], [0 0 0 1], [0 0 1 0]\n\t\t\t\t]\n\n\t\t\t\tsage: W = ColoredPermutations(1,4)\n\t\t\t\tsage: W.some_elements()\n\t\t\t\t[[[0, 0, 0, 0], [2, 1, 3, 4]],\n\t\t\t\t [[0, 0, 0, 0], [1, 3, 2, 4]],\n\t\t\t\t [[0, 0, 0, 0], [1, 2, 4, 3]],\n\t\t\t\t [[0, 0, 0, 0], [1, 2, 3, 4]],\n\t\t\t\t [[0, 0, 0, 0], [4, 1, 2, 3]]]\n\t\t\t\"\"\"\n\t\t\treturn list(self.simple_reflections()) + [self.one(), self.an_element()]\n\n\t\t##########################################################################\n\t\t# Reflections\n\t\t##########################################################################\n\n\t\t@abstract_method(optional=True)\n\t\tdef reflection_index_set(self):\n\t\t\tr\"\"\"\n\t\t\tReturn the index set of the reflections of ``self``.\n\n\t\t\t.. SEEALSO::\n\n\t\t\t\t- :meth:`reflection`\n\t\t\t\t- :meth:`reflections`\n\n\t\t\tEXAMPLES::\n\n\t\t\t\tsage: W = ReflectionGroup((1,1,4))\t\t\t\t\t  # optional - gap3\n\t\t\t\tsage: W.reflection_index_set()\t\t\t\t\t\t  # optional - gap3\n\t\t\t\t(1, 2, 3, 4, 5, 6)\n\t\t\t\tsage: W = ReflectionGroup((1,1,4), reflection_index_set=[1,3,'asdf',7,9,11])\t# optional - gap3\n\t\t\t\tsage: W.reflection_index_set()\t\t\t\t\t\t  # optional - gap3\n\t\t\t\t(1, 3, 'asdf', 7, 9, 11)\n\t\t\t\tsage: W = ReflectionGroup((1,1,4), reflection_index_set=('a','b','c','d','e','f'))  # optional - gap3\n\t\t\t\tsage: W.reflection_index_set()\t\t\t\t\t\t  # optional - gap3\n\t\t\t\t('a', 'b', 'c', 'd', 'e', 'f')\n\t\t\t\"\"\"\n\n\t\t@abstract_method(optional=True)\n\t\tdef reflection(self, i):\n\t\t\tr\"\"\"\n\t\t\tReturn the `i`-th reflection of ``self``.\n\n\t\t\tFor `i` in `1,\\dots,N`, this gives the `i`-th reflection of\n\t\t\t``self``.\n\n\t\t\t.. SEEALSO::\n\n\t\t\t\t- :meth:`reflections_index_set`\n\t\t\t\t- :meth:`reflections`\n\n\t\t\tEXAMPLES::\n\n\t\t\t\tsage: W = ReflectionGroup((1,1,4))\t\t\t\t\t  # optional - gap3\n\t\t\t\tsage: for i in W.reflection_index_set():\t\t\t\t# optional - gap3\n\t\t\t\t....:\t print('%s %s'%(i, W.reflection(i)))\t\t   # optional - gap3\n\t\t\t\t1 (1,7)(2,4)(5,6)(8,10)(11,12)\n\t\t\t\t2 (1,4)(2,8)(3,5)(7,10)(9,11)\n\t\t\t\t3 (2,5)(3,9)(4,6)(8,11)(10,12)\n\t\t\t\t4 (1,8)(2,7)(3,6)(4,10)(9,12)\n\t\t\t\t5 (1,6)(2,9)(3,8)(5,11)(7,12)\n\t\t\t\t6 (1,11)(3,10)(4,9)(5,7)(6,12)\n\t\t\t\"\"\"\n\n\t\t@cached_method\n\t\tdef reflections(self):\n\t\t\tr\"\"\"\n\t\t\tReturn a finite family containing the reflections of\n\t\t\t``self``, indexed by :meth:`reflection_index_set`.\n\n\t\t\t.. SEEALSO::\n\n\t\t\t\t- :meth:`reflection`\n\t\t\t\t- :meth:`reflection_index_set`\n\n\t\t\tEXAMPLES::\n\n\t\t\t\tsage: W = ReflectionGroup((1,1,3))\t\t\t\t\t  # optional - gap3\n\t\t\t\tsage: reflections = W.reflections()\t\t\t\t\t # optional - gap3\n\t\t\t\tsage: for index in sorted(reflections.keys()):\t\t  # optional - gap3\n\t\t\t\t....:\t print('%s %s'%(index, reflections[index]))\t# optional - gap3\n\t\t\t\t1 (1,4)(2,3)(5,6)\n\t\t\t\t2 (1,3)(2,5)(4,6)\n\t\t\t\t3 (1,5)(2,4)(3,6)\n\n\t\t\t\tsage: W = ReflectionGroup((1,1,3),reflection_index_set=['a','b','c'])   # optional - gap3\n\t\t\t\tsage: reflections = W.reflections()\t\t\t\t\t # optional - gap3\n\t\t\t\tsage: for index in sorted(reflections.keys()):\t\t  # optional - gap3\n\t\t\t\t....:\t print('%s %s'%(index, reflections[index]))\t# optional - gap3\n\t\t\t\ta (1,4)(2,3)(5,6)\n\t\t\t\tb (1,3)(2,5)(4,6)\n\t\t\t\tc (1,5)(2,4)(3,6)\n\n\t\t\t\tsage: W = ReflectionGroup((3,1,1))\t\t\t\t\t  # optional - gap3\n\t\t\t\tsage: reflections = W.reflections()\t\t\t\t\t # optional - gap3\n\t\t\t\tsage: for index in sorted(reflections.keys()):\t\t  # optional - gap3\n\t\t\t\t....:\t print('%s %s'%(index, reflections[index]))\t# optional - gap3\n\t\t\t\t1 (1,2,3)\n\t\t\t\t2 (1,3,2)\n\n\t\t\t\tsage: W = ReflectionGroup((1,1,3), (3,1,2))\t\t\t # optional - gap3\n\t\t\t\tsage: reflections = W.reflections()\t\t\t\t\t # optional - gap3\n\t\t\t\tsage: for index in sorted(reflections.keys()):\t\t  # optional - gap3\n\t\t\t\t....:\t print('%s %s'%(index, reflections[index]))\t# optional - gap3\n\t\t\t\t1 (1,6)(2,5)(7,8)\n\t\t\t\t2 (1,5)(2,7)(6,8)\n\t\t\t\t3 (3,9,15)(4,10,16)(12,17,23)(14,18,24)(20,25,29)(21,22,26)(27,28,30)\n\t\t\t\t4 (3,11)(4,12)(9,13)(10,14)(15,19)(16,20)(17,21)(18,22)(23,27)(24,28)(25,26)(29,30)\n\t\t\t\t5 (1,7)(2,6)(5,8)\n\t\t\t\t6 (3,19)(4,25)(9,11)(10,17)(12,28)(13,15)(14,30)(16,18)(20,27)(21,29)(22,23)(24,26)\n\t\t\t\t7 (4,21,27)(10,22,28)(11,13,19)(12,14,20)(16,26,30)(17,18,25)(23,24,29)\n\t\t\t\t8 (3,13)(4,24)(9,19)(10,29)(11,15)(12,26)(14,21)(16,23)(17,30)(18,27)(20,22)(25,28)\n\t\t\t\t9 (3,15,9)(4,16,10)(12,23,17)(14,24,18)(20,29,25)(21,26,22)(27,30,28)\n\t\t\t\t10 (4,27,21)(10,28,22)(11,19,13)(12,20,14)(16,30,26)(17,25,18)(23,29,24)\n\t\t\t\"\"\"\n\t\t\tfrom sage.sets.family import Family\n\t\t\treturn Family(self.reflection_index_set(), self.reflection)\n\n\t\t##########################################################################\n\t\t# distinguished reflections\n\t\t##########################################################################\n\n\t\t@abstract_method(optional=True)\n\t\tdef hyperplane_index_set(self):\n\t\t\tr\"\"\"\n\t\t\tReturn the index set of the distinguished reflections of ``self``.\n\n\t\t\tThis is also the index set of the reflection hyperplanes\n\t\t\tof ``self``, hence the name. This name is slightly abusive\n\t\t\tsince the concept of reflection hyperplanes is not defined\n\t\t\tfor all generalized Coxeter groups. However for all\n\t\t\tpractical purposes this is only used for complex\n\t\t\treflection groups, and there this is the desirable name.\n\n\t\t\t.. SEEALSO::\n\n\t\t\t\t- :meth:`distinguished_reflection`\n\t\t\t\t- :meth:`distinguished_reflections`\n\n\t\t\tEXAMPLES::\n\n\t\t\t\tsage: W = ReflectionGroup((1,1,4))\t\t\t\t\t  # optional - gap3\n\t\t\t\tsage: W.hyperplane_index_set()\t\t\t\t\t\t  # optional - gap3\n\t\t\t\t(1, 2, 3, 4, 5, 6)\n\t\t\t\tsage: W = ReflectionGroup((1,1,4), hyperplane_index_set=[1,3,'asdf',7,9,11])\t# optional - gap3\n\t\t\t\tsage: W.hyperplane_index_set()\t\t\t\t\t\t  # optional - gap3\n\t\t\t\t(1, 3, 'asdf', 7, 9, 11)\n\t\t\t\tsage: W = ReflectionGroup((1,1,4), hyperplane_index_set=('a','b','c','d','e','f'))  # optional - gap3\n\t\t\t\tsage: W.hyperplane_index_set()\t\t\t\t\t\t  # optional - gap3\n\t\t\t\t('a', 'b', 'c', 'd', 'e', 'f')\n\t\t\t\"\"\"\n\n\t\t@abstract_method(optional=True)\n\t\tdef distinguished_reflection(self, i):\n\t\t\tr\"\"\"\n\t\t\tReturn the `i`-th distinguished reflection of ``self``.\n\n\t\t\tINPUT:\n\n\t\t\t- ``i`` -- an element of the index set of the distinguished reflections.\n\n\t\t\t.. SEEALSO::\n\n\t\t\t\t- :meth:`distinguished_reflections`\n\t\t\t\t- :meth:`hyperplane_index_set`\n\n\t\t\tEXAMPLES::\n\n\t\t\t\tsage: W = ReflectionGroup((1,1,4), hyperplane_index_set=('a','b','c','d','e','f'))  # optional - gap3\n\t\t\t\tsage: for i in W.hyperplane_index_set():\t\t\t\t\t# optional - gap3\n\t\t\t\t....:\t print('%s %s'%(i, W.distinguished_reflection(i))) # optional - gap3\n\t\t\t\ta (1,7)(2,4)(5,6)(8,10)(11,12)\n\t\t\t\tb (1,4)(2,8)(3,5)(7,10)(9,11)\n\t\t\t\tc (2,5)(3,9)(4,6)(8,11)(10,12)\n\t\t\t\td (1,8)(2,7)(3,6)(4,10)(9,12)\n\t\t\t\te (1,6)(2,9)(3,8)(5,11)(7,12)\n\t\t\t\tf (1,11)(3,10)(4,9)(5,7)(6,12)\n\t\t\t\"\"\"\n\n\t\t@cached_method\n\t\tdef distinguished_reflections(self):\n\t\t\tr\"\"\"\n\t\t\tReturn a finite family containing the distinguished\n\t\t\treflections of ``self``, indexed by\n\t\t\t:meth:`hyperplane_index_set`.\n\n\t\t\tA *distinguished reflection* is a conjugate of a simple\n\t\t\treflection. For a Coxeter group, reflections and\n\t\t\tdistinguished reflections coincide. For a Complex\n\t\t\treflection groups this is a reflection acting on the\n\t\t\tcomplement of the fixed hyperplane `H` as\n\t\t\t`\\operatorname{exp}(2 \\pi i / n)`, where `n` is the order\n\t\t\tof the reflection subgroup fixing `H`.\n\n\t\t\t.. SEEALSO::\n\n\t\t\t\t- :meth:`distinguished_reflection`\n\t\t\t\t- :meth:`hyperplane_index_set`\n\n\t\t\tEXAMPLES::\n\n\t\t\t\tsage: W = ReflectionGroup((1,1,3))\t\t\t\t\t  # optional - gap3\n\t\t\t\tsage: distinguished_reflections = W.distinguished_reflections() # optional - gap3\n\t\t\t\tsage: for index in sorted(distinguished_reflections.keys()):\t\t# optional - gap3\n\t\t\t\t....:\t print('%s %s'%(index, distinguished_reflections[index]))  # optional - gap3\n\t\t\t\t1 (1,4)(2,3)(5,6)\n\t\t\t\t2 (1,3)(2,5)(4,6)\n\t\t\t\t3 (1,5)(2,4)(3,6)\n\n\t\t\t\tsage: W = ReflectionGroup((1,1,3),hyperplane_index_set=['a','b','c'])   # optional - gap3\n\t\t\t\tsage: distinguished_reflections = W.distinguished_reflections() # optional - gap3\n\t\t\t\tsage: for index in sorted(distinguished_reflections.keys()):\t\t# optional - gap3\n\t\t\t\t....:\t print('%s %s'%(index, distinguished_reflections[index]))  # optional - gap3\n\t\t\t\ta (1,4)(2,3)(5,6)\n\t\t\t\tb (1,3)(2,5)(4,6)\n\t\t\t\tc (1,5)(2,4)(3,6)\n\n\t\t\t\tsage: W = ReflectionGroup((3,1,1))\t\t\t\t\t  # optional - gap3\n\t\t\t\tsage: distinguished_reflections = W.distinguished_reflections() # optional - gap3\n\t\t\t\tsage: for index in sorted(distinguished_reflections.keys()):\t\t# optional - gap3\n\t\t\t\t....:\t print('%s %s'%(index, distinguished_reflections[index]))  # optional - gap3\n\t\t\t\t1 (1,2,3)\n\n\t\t\t\tsage: W = ReflectionGroup((1,1,3), (3,1,2))\t\t\t # optional - gap3\n\t\t\t\tsage: distinguished_reflections = W.distinguished_reflections() # optional - gap3\n\t\t\t\tsage: for index in sorted(distinguished_reflections.keys()):\t# optional - gap3\n\t\t\t\t....:\t print('%s %s'%(index, distinguished_reflections[index]))  # optional - gap3\n\t\t\t\t1 (1,6)(2,5)(7,8)\n\t\t\t\t2 (1,5)(2,7)(6,8)\n\t\t\t\t3 (3,9,15)(4,10,16)(12,17,23)(14,18,24)(20,25,29)(21,22,26)(27,28,30)\n\t\t\t\t4 (3,11)(4,12)(9,13)(10,14)(15,19)(16,20)(17,21)(18,22)(23,27)(24,28)(25,26)(29,30)\n\t\t\t\t5 (1,7)(2,6)(5,8)\n\t\t\t\t6 (3,19)(4,25)(9,11)(10,17)(12,28)(13,15)(14,30)(16,18)(20,27)(21,29)(22,23)(24,26)\n\t\t\t\t7 (4,21,27)(10,22,28)(11,13,19)(12,14,20)(16,26,30)(17,18,25)(23,24,29)\n\t\t\t\t8 (3,13)(4,24)(9,19)(10,29)(11,15)(12,26)(14,21)(16,23)(17,30)(18,27)(20,22)(25,28)\n\t\t\t\"\"\"\n\t\t\tfrom sage.sets.family import Family\n\t\t\treturn Family(self.hyperplane_index_set(), self.distinguished_reflection)\n\n\t\t##########################################################################\n\t\t# from_reduced_word\n\t\t##########################################################################\n\n\t\tdef from_reduced_word(self, word, word_type='simple'):\n\t\t\tr\"\"\"\n\t\t\tReturn an element of ``self`` from its (reduced) word.\n\n\t\t\tINPUT:\n\n\t\t\t- ``word`` -- a list (or iterable) of elements of the\n\t\t\t  index set of ``self`` (resp. of the distinguished\n\t\t\t  or of all reflections)\n\t\t\t- ``word_type`` -- (optional, default: ``'simple'``):\n\t\t\t  either ``'simple'``, ``'distinguished'``, or ``'all'``\n\n\t\t\tIf ``word`` is `[i_1,i_2,\\ldots,i_k]`, then this returns\n\t\t\tthe corresponding product of simple reflections\n\t\t\t`s_{i_1} s_{i_2} \\cdots s_{i_k}`.\n\n\t\t\tIf ``word_type`` is ``'distinguished'`` (resp. ``'all'``),\n\t\t\tthen the product of the distinguished reflections (resp. all\n\t\t\treflections) is returned.\n\n\t\t\t.. NOTE::\n\n\t\t\t\tThe main use case is for constructing elements from\n\t\t\t\treduced words, hence the name of this method.\n\t\t\t\tHowever, the input word need *not* be reduced.\n\n\t\t\t.. SEEALSO::\n\n\t\t\t\t- :meth:`index_set`\n\t\t\t\t- :meth:`reflection_index_set`\n\t\t\t\t- :meth:`hyperplane_index_set`\n\t\t\t\t- :meth:`~ComplexReflectionOrGeneralizedCoxeterGroups.ElementMethods.apply_simple_reflections`\n\t\t\t\t- :meth:`~CoxeterGroup.ElementMethods.reduced_word`\n\t\t\t\t- :meth:`~CoxeterGroup.ParentMethods._test_reduced_word`\n\n\t\t\tEXAMPLES::\n\n\t\t\t\tsage: W = CoxeterGroups().example()\n\t\t\t\tsage: W\n\t\t\t\tThe symmetric group on {0, ..., 3}\n\t\t\t\tsage: s = W.simple_reflections()\n\t\t\t\tsage: W.from_reduced_word([0,2,0,1])\n\t\t\t\t(0, 3, 1, 2)\n\t\t\t\tsage: W.from_reduced_word((0,2,0,1))\n\t\t\t\t(0, 3, 1, 2)\n\t\t\t\tsage: s[0]*s[2]*s[0]*s[1]\n\t\t\t\t(0, 3, 1, 2)\n\n\t\t\tWe now experiment with the different values for\n\t\t\t``word_type`` for the colored symmetric group::\n\n\t\t\t\tsage: W = ColoredPermutations(1,4)\n\t\t\t\tsage: W.from_reduced_word([1,2,1,2,1,2])\n\t\t\t\t[[0, 0, 0, 0], [1, 2, 3, 4]]\n\n\t\t\t\tsage: W.from_reduced_word([1, 2, 3]).reduced_word()\n\t\t\t\t[1, 2, 3]\n\n\t\t\t\tsage: W = WeylGroup(\"A3\", prefix='s')\n\t\t\t\tsage: AS = W.domain()\n\t\t\t\tsage: r1 = AS.roots()[4]\n\t\t\t\tsage: r1\n\t\t\t\t(0, 1, 0, -1)\n\t\t\t\tsage: r2 = AS.roots()[5]\n\t\t\t\tsage: r2\n\t\t\t\t(0, 0, 1, -1)\n\t\t\t\tsage: W.from_reduced_word([r1, r2], word_type='all')\n\t\t\t\ts3*s2\n\n\t\t\t\tsage: W = WeylGroup(\"G2\", prefix='s')\n\t\t\t\tsage: W.from_reduced_word(W.domain().positive_roots(), word_type='all')\n\t\t\t\ts1*s2\n\n\t\t\t\tsage: W = ReflectionGroup((1,1,4))\t\t   # optional - gap3\n\t\t\t\tsage: W.from_reduced_word([1,2,3], word_type='all').reduced_word()  # optional - gap3\n\t\t\t\t[1, 2, 3]\n\n\t\t\t\tsage: W.from_reduced_word([1,2,3], word_type='all').reduced_word_in_reflections()   # optional - gap3\n\t\t\t\t[1, 2, 3]\n\n\t\t\t\tsage: W.from_reduced_word([1,2,3]).reduced_word_in_reflections()\t# optional - gap3\n\t\t\t\t[1, 2, 3]\n\n\t\t\tTESTS::\n\n\t\t\t\tsage: W=WeylGroup(['E',6])\n\t\t\t\tsage: W.from_reduced_word([2,3,4,2])\n\t\t\t\t[ 0  1  0  0  0  0  0  0]\n\t\t\t\t[ 0  0 -1  0  0  0  0  0]\n\t\t\t\t[-1  0  0  0  0  0  0  0]\n\t\t\t\t[ 0  0  0  1  0  0  0  0]\n\t\t\t\t[ 0  0  0  0  1  0  0  0]\n\t\t\t\t[ 0  0  0  0  0  1  0  0]\n\t\t\t\t[ 0  0  0  0  0  0  1  0]\n\t\t\t\t[ 0  0  0  0  0  0  0  1]\n\t\t\t\"\"\"\n\t\t\tif word_type == 'simple':\n\t\t\t\treturn self.one().apply_simple_reflections(word)\n\t\t\telse:\n\t\t\t\treturn self.one().apply_reflections(word, word_type=word_type)\n\n\t\t##########################################################################\n\t\t# Irreducible components\n\t\t##########################################################################\n\n\t\tdef irreducible_component_index_sets(self):\n\t\t\tr\"\"\"\n\t\t\tReturn a list containing the index sets of the irreducible components of\n\t\t\t``self`` as finite reflection groups.\n\n\t\t\tEXAMPLES::\n\n\t\t\t\tsage: W = ReflectionGroup([1,1,3], [3,1,3], 4); W\t   # optional - gap3\n\t\t\t\tReducible complex reflection group of rank 7 and type A2 x G(3,1,3) x ST4\n\t\t\t\tsage: sorted(W.irreducible_component_index_sets())\t  # optional - gap3\n\t\t\t\t[[1, 2], [3, 4, 5], [6, 7]]\n\n\t\t\tALGORITHM:\n\n\t\t\tTake the connected components of the graph on the\n\t\t\tindex set with edges ``(i,j)``, where ``s[i]`` and\n\t\t\t``s[j]`` do not commute.\n\t\t\t\"\"\"\n\t\t\tI = self.index_set()\n\t\t\ts = self.simple_reflections()\n\t\t\tfrom sage.graphs.graph import Graph\n\t\t\tG = Graph([I,\n\t\t\t\t\t   [[i,j]\n\t\t\t\t\t\tfor i,j in itertools.combinations(I,2)\n\t\t\t\t\t\tif s[i]*s[j] != s[j]*s[i] ]],\n\t\t\t\t\t  format=\"vertices_and_edges\")\n\t\t\treturn G.connected_components()\n\n\t\t@abstract_method(optional=True)\n\t\tdef irreducible_components(self):\n\t\t\tr\"\"\"\n\t\t\tReturn the irreducible components of ``self`` as finite\n\t\t\treflection groups.\n\n\t\t\tEXAMPLES::\n\n\t\t\t\tsage: W = ReflectionGroup([1,1,3], [3,1,3], 4)\t\t  # optional - gap3\n\t\t\t\tsage: W.irreducible_components()\t\t\t\t\t\t# optional - gap3\n\t\t\t\t[Irreducible real reflection group of rank 2 and type A2,\n\t\t\t\t Irreducible complex reflection group of rank 3 and type G(3,1,3),\n\t\t\t\t Irreducible complex reflection group of rank 2 and type ST4]\n\t\t\t\"\"\"\n\t\t\t# TODO: provide a default implementation using the above and parabolic subgroups\n\n\t\tdef number_of_irreducible_components(self):\n\t\t\tr\"\"\"\n\t\t\tReturn the number of irreducible components of ``self``.\n\n\t\t\tEXAMPLES::\n\n\t\t\t\tsage: SymmetricGroup(3).number_of_irreducible_components()\n\t\t\t\t1\n\n\t\t\t\tsage: ColoredPermutations(1,3).number_of_irreducible_components()\n\t\t\t\t1\n\n\t\t\t\tsage: ReflectionGroup((1,1,3),(2,1,3)).number_of_irreducible_components()   # optional - gap3\n\t\t\t\t2\n\n\t\t\tTESTS::\n\n\t\t\t\tsage: SymmetricGroup(3).number_of_irreducible_components.__module__\n\t\t\t\t'sage.categories.complex_reflection_or_generalized_coxeter_groups'\n\t\t\t\"\"\"\n\t\t\treturn len(self.irreducible_component_index_sets())\n\n\t\tdef is_irreducible(self):\n\t\t\tr\"\"\"\n\t\t\tReturn ``True`` if ``self`` is irreducible.\n\n\t\t\tEXAMPLES::\n\n\t\t\t\tsage: W = ColoredPermutations(1,3); W\n\t\t\t\t1-colored permutations of size 3\n\t\t\t\tsage: W.is_irreducible()\n\t\t\t\tTrue\n\n\t\t\t\tsage: W = ReflectionGroup((1,1,3),(2,1,3)); W\t\t   # optional - gap3\n\t\t\t\tReducible real reflection group of rank 5 and type A2 x B3\n\t\t\t\tsage: W.is_irreducible()\t\t\t\t\t\t\t\t# optional - gap3\n\t\t\t\tFalse\n\t\t\t\"\"\"\n\t\t\treturn self.number_of_irreducible_components() == 1\n\n\t\tdef is_reducible(self):\n\t\t\tr\"\"\"\n\t\t\tReturn ``True`` if ``self`` is not irreducible.\n\n\t\t\tEXAMPLES::\n\n\t\t\t\tsage: W = ColoredPermutations(1,3); W\n\t\t\t\t1-colored permutations of size 3\n\t\t\t\tsage: W.is_reducible()\n\t\t\t\tFalse\n\n\t\t\t\tsage: W = ReflectionGroup((1,1,3), (2,1,3)); W\t\t  # optional - gap3\n\t\t\t\tReducible real reflection group of rank 5 and type A2 x B3\n\t\t\t\tsage: W.is_reducible()\t\t\t\t\t\t\t\t  # optional - gap3\n\t\t\t\tTrue\n\t\t\t\"\"\"\n\t\t\treturn not self.is_irreducible()\n\n\n\tclass ElementMethods:\n\t\tdef apply_simple_reflection_left(self, i):\n\t\t\tr\"\"\"\n\t\t\tReturn ``self`` multiplied by the simple reflection ``s[i]``\n\t\t\ton the left.\n\n\t\t\tThis low level method is used intensively. Coxeter groups\n\t\t\tare encouraged to override this straightforward\n\t\t\timplementation whenever a faster approach exists.\n\n\t\t\tEXAMPLES::\n\n\t\t\t\tsage: W = CoxeterGroups().example()\n\t\t\t\tsage: w = W.an_element(); w\n\t\t\t\t(1, 2, 3, 0)\n\t\t\t\tsage: w.apply_simple_reflection_left(0)\n\t\t\t\t(0, 2, 3, 1)\n\t\t\t\tsage: w.apply_simple_reflection_left(1)\n\t\t\t\t(2, 1, 3, 0)\n\t\t\t\tsage: w.apply_simple_reflection_left(2)\n\t\t\t\t(1, 3, 2, 0)\n\n\t\t\tEXAMPLES::\n\n\t\t\t\tsage: from sage.categories.complex_reflection_groups import ComplexReflectionGroups\n\t\t\t\tsage: W = ComplexReflectionGroups().example()\n\t\t\t\tsage: w = W.an_element(); w\n\t\t\t\t[[1, 0, 0], [3, 1, 2]]\n\t\t\t\tsage: w.apply_simple_reflection_left(1)\n\t\t\t\t[[0, 1, 0], [1, 3, 2]]\n\t\t\t\tsage: w.apply_simple_reflection_left(2)\n\t\t\t\t[[1, 0, 0], [3, 2, 1]]\n\t\t\t\tsage: w.apply_simple_reflection_left(3)\n\t\t\t\t[[1, 0, 1], [3, 1, 2]]\n\n\t\t\tTESTS::\n\n\t\t\t\tsage: w.apply_simple_reflection_left.__module__\n\t\t\t\t'sage.categories.complex_reflection_or_generalized_coxeter_groups'\n\t\t\t\"\"\"\n\t\t\ts = self.parent().simple_reflections()\n\t\t\treturn s[i] * self\n\n\t\tdef apply_simple_reflection_right(self, i):\n\t\t\t\"\"\"\n\t\t\tReturn ``self`` multiplied by the simple reflection ``s[i]``\n\t\t\ton the right.\n\n\t\t\tThis low level method is used intensively. Coxeter groups\n\t\t\tare encouraged to override this straightforward\n\t\t\timplementation whenever a faster approach exists.\n\n\t\t\tEXAMPLES::\n\n\t\t\t\tsage: W=CoxeterGroups().example()\n\t\t\t\tsage: w = W.an_element(); w\n\t\t\t\t(1, 2, 3, 0)\n\t\t\t\tsage: w.apply_simple_reflection_right(0)\n\t\t\t\t(2, 1, 3, 0)\n\t\t\t\tsage: w.apply_simple_reflection_right(1)\n\t\t\t\t(1, 3, 2, 0)\n\t\t\t\tsage: w.apply_simple_reflection_right(2)\n\t\t\t\t(1, 2, 0, 3)\n\n\t\t\t\tsage: from sage.categories.complex_reflection_groups import ComplexReflectionGroups\n\t\t\t\tsage: W = ComplexReflectionGroups().example()\n\t\t\t\tsage: w = W.an_element(); w\n\t\t\t\t[[1, 0, 0], [3, 1, 2]]\n\t\t\t\tsage: w.apply_simple_reflection_right(1)\n\t\t\t\t[[1, 0, 0], [3, 2, 1]]\n\t\t\t\tsage: w.apply_simple_reflection_right(2)\n\t\t\t\t[[1, 0, 0], [2, 1, 3]]\n\t\t\t\tsage: w.apply_simple_reflection_right(3)\n\t\t\t\t[[2, 0, 0], [3, 1, 2]]\n\n\t\t\tTESTS::\n\n\t\t\t\tsage: w.apply_simple_reflection_right.__module__\n\t\t\t\t'sage.categories.complex_reflection_or_generalized_coxeter_groups'\n\t\t\t\"\"\"\n\t\t\ts = self.parent().simple_reflections()\n\t\t\treturn self * s[i]\n\n\t\tdef apply_simple_reflection(self, i, side='right'):\n\t\t\t\"\"\"\n\t\t\tReturn ``self`` multiplied by the simple reflection ``s[i]``.\n\n\t\t\tINPUT:\n\n\t\t\t- ``i`` -- an element of the index set\n\t\t\t- ``side`` -- (default: ``\"right\"``) ``\"left\"`` or ``\"right\"``\n\n\t\t\tThis default implementation simply calls\n\t\t\t:meth:`apply_simple_reflection_left` or\n\t\t\t:meth:`apply_simple_reflection_right`.\n\n\t\t\tEXAMPLES::\n\n\t\t\t\tsage: W = CoxeterGroups().example()\n\t\t\t\tsage: w = W.an_element(); w\n\t\t\t\t(1, 2, 3, 0)\n\t\t\t\tsage: w.apply_simple_reflection(0, side = \"left\")\n\t\t\t\t(0, 2, 3, 1)\n\t\t\t\tsage: w.apply_simple_reflection(1, side = \"left\")\n\t\t\t\t(2, 1, 3, 0)\n\t\t\t\tsage: w.apply_simple_reflection(2, side = \"left\")\n\t\t\t\t(1, 3, 2, 0)\n\n\t\t\t\tsage: w.apply_simple_reflection(0, side = \"right\")\n\t\t\t\t(2, 1, 3, 0)\n\t\t\t\tsage: w.apply_simple_reflection(1, side = \"right\")\n\t\t\t\t(1, 3, 2, 0)\n\t\t\t\tsage: w.apply_simple_reflection(2, side = \"right\")\n\t\t\t\t(1, 2, 0, 3)\n\n\t\t\tBy default, ``side`` is ``\"right\"``::\n\n\t\t\t\tsage: w.apply_simple_reflection(0)\n\t\t\t\t(2, 1, 3, 0)\n\n\t\t\tSome tests with a complex reflection group::\n\n\t\t\t\tsage: from sage.categories.complex_reflection_groups import ComplexReflectionGroups\n\t\t\t\tsage: W = ComplexReflectionGroups().example(); W\n\t\t\t\t5-colored permutations of size 3\n\t\t\t\tsage: w = W.an_element(); w\n\t\t\t\t[[1, 0, 0], [3, 1, 2]]\n\t\t\t\tsage: w.apply_simple_reflection(1, side=\"left\")\n\t\t\t\t[[0, 1, 0], [1, 3, 2]]\n\t\t\t\tsage: w.apply_simple_reflection(2, side=\"left\")\n\t\t\t\t[[1, 0, 0], [3, 2, 1]]\n\t\t\t\tsage: w.apply_simple_reflection(3, side=\"left\")\n\t\t\t\t[[1, 0, 1], [3, 1, 2]]\n\n\t\t\t\tsage: w.apply_simple_reflection(1, side=\"right\")\n\t\t\t\t[[1, 0, 0], [3, 2, 1]]\n\t\t\t\tsage: w.apply_simple_reflection(2, side=\"right\")\n\t\t\t\t[[1, 0, 0], [2, 1, 3]]\n\t\t\t\tsage: w.apply_simple_reflection(3, side=\"right\")\n\t\t\t\t[[2, 0, 0], [3, 1, 2]]\n\n\t\t\tTESTS::\n\n\t\t\t\tsage: w.apply_simple_reflection_right.__module__\n\t\t\t\t'sage.categories.complex_reflection_or_generalized_coxeter_groups'\n\t\t\t\"\"\"\n\t\t\tif side == 'right':\n\t\t\t\treturn self.apply_simple_reflection_right(i)\n\t\t\telse:\n\t\t\t\treturn self.apply_simple_reflection_left(i)\n\n\t\tdef apply_simple_reflections(self, word, side='right', type='simple'):\n\t\t\tr\"\"\"\n\t\t\tReturn the result of the (left/right) multiplication of\n\t\t\t``self`` by ``word``.\n\n\t\t\tINPUT:\n\n\t\t\t- ``word`` -- a sequence of indices of simple reflections\n\t\t\t- ``side`` -- (default: ``'right'``) indicates multiplying\n\t\t\t  from left or right\n\n\t\t\tThis is a specialized implementation of\n\t\t\t:meth:`apply_reflections` for the simple reflections. The\n\t\t\trationale for its existence are:\n\n\t\t\t- It can take advantage of ``apply_simple_reflection``,\n\t\t\t  which often is less expensive than computing a product.\n\n\t\t\t- It reduced burden on implementations that would want to\n\t\t\t  provide an optimized version of this method.\n\n\t\t\tEXAMPLES::\n\n\t\t\t   sage: W = CoxeterGroups().example()\n\t\t\t   sage: w = W.an_element(); w\n\t\t\t   (1, 2, 3, 0)\n\t\t\t   sage: w.apply_simple_reflections([0,1])\n\t\t\t   (2, 3, 1, 0)\n\t\t\t   sage: w\n\t\t\t   (1, 2, 3, 0)\n\t\t\t   sage: w.apply_simple_reflections([0,1],side='left')\n\t\t\t   (0, 1, 3, 2)\n\t\t\t\"\"\"\n\t\t\tfor i in word:\n\t\t\t\tself = self.apply_simple_reflection(i, side)\n\t\t\treturn self\n\n\t\tdef apply_reflections(self, word, side='right', word_type='all'):\n\t\t\tr\"\"\"\n\t\t\tReturn the result of the (left/right) multiplication of\n\t\t\t``self`` by ``word``.\n\n\t\t\tINPUT:\n\n\t\t\t- ``word`` -- a sequence of indices of reflections\n\t\t\t- ``side`` -- (default: ``'right'``) indicates multiplying\n\t\t\t  from left or right\n\t\t\t- ``word_type`` -- (optional, default: ``'all'``):\n\t\t\t  either ``'simple'``, ``'distinguished'``, or ``'all'``\n\n\t\t\tEXAMPLES::\n\n\t\t\t\tsage: W = ReflectionGroup((1,1,3))\t\t  # optional - gap3\n\t\t\t\tsage: W.one().apply_reflections([1])\t\t# optional - gap3\n\t\t\t\t(1,4)(2,3)(5,6)\n\t\t\t\tsage: W.one().apply_reflections([2])\t\t# optional - gap3\n\t\t\t\t(1,3)(2,5)(4,6)\n\t\t\t\tsage: W.one().apply_reflections([2,1])\t  # optional - gap3\n\t\t\t\t(1,2,6)(3,4,5)\n\n\n\t\t\t\tsage: W = CoxeterGroups().example()\n\t\t\t\tsage: w = W.an_element(); w\n\t\t\t\t(1, 2, 3, 0)\n\t\t\t\tsage: w.apply_reflections([0,1], word_type='simple')\n\t\t\t\t(2, 3, 1, 0)\n\t\t\t\tsage: w\n\t\t\t\t(1, 2, 3, 0)\n\t\t\t\tsage: w.apply_reflections([0,1], side='left', word_type='simple')\n\t\t\t\t(0, 1, 3, 2)\n\n\n\t\t\t\tsage: W = WeylGroup(\"A3\", prefix='s')\n\t\t\t\tsage: w = W.an_element(); w\n\t\t\t\ts1*s2*s3\n\t\t\t\tsage: AS = W.domain()\n\t\t\t\tsage: r1 = AS.roots()[4]\n\t\t\t\tsage: r1\n\t\t\t\t(0, 1, 0, -1)\n\t\t\t\tsage: r2 = AS.roots()[5]\n\t\t\t\tsage: r2\n\t\t\t\t(0, 0, 1, -1)\n\t\t\t\tsage: w.apply_reflections([r1, r2], word_type='all')\n\t\t\t\ts1\n\n\n\t\t\t\tsage: W = ReflectionGroup((1,1,3))\t\t  # optional - gap3\n\t\t\t\tsage: W.one().apply_reflections([1], word_type='distinguished')   # optional - gap3\n\t\t\t\t(1,4)(2,3)(5,6)\n\t\t\t\tsage: W.one().apply_reflections([2],   word_type='distinguished')   # optional - gap3\n\t\t\t\t(1,3)(2,5)(4,6)\n\t\t\t\tsage: W.one().apply_reflections([3],   word_type='distinguished')   # optional - gap3\n\t\t\t\t(1,5)(2,4)(3,6)\n\t\t\t\tsage: W.one().apply_reflections([2,1], word_type='distinguished')   # optional - gap3\n\t\t\t\t(1,2,6)(3,4,5)\n\n\t\t\t\tsage: W = ReflectionGroup((1,1,3), hyperplane_index_set=['A','B','C']); W   # optional - gap3\n\t\t\t\tIrreducible real reflection group of rank 2 and type A2\n\t\t\t\tsage: W.one().apply_reflections(['A'], word_type='distinguished')   # optional - gap3\n\t\t\t\t(1,4)(2,3)(5,6)\n\t\t\t\"\"\"\n\t\t\tif word_type == 'simple':\n\t\t\t\treflections = self.parent().simple_reflections()\n\t\t\telif word_type == 'distinguished':\n\t\t\t\treflections = self.parent().distinguished_reflections()\n\t\t\telse:\n\t\t\t\treflections = self.parent().reflections()\n\t\t\tif side == 'left':\n\t\t\t\tfor i in word:\n\t\t\t\t\tself = reflections[i] * self\n\t\t\telse:\n\t\t\t\tfor i in word:\n\t\t\t\t\tself = self * reflections[i]\n\t\t\treturn self\n\n\t\tdef _mul_(self, other):\n\t\t\tr\"\"\"\n\t\t\tReturn the product of ``self`` and ``other``\n\n\t\t\tThis default implementation computes a reduced word of\n\t\t\t``other`` using :meth:`reduced_word`, and applies the\n\t\t\tcorresponding simple reflections on ``self`` using\n\t\t\t:meth:`apply_simple_reflections`.\n\n\t\t\tEXAMPLES::\n\n\t\t\t\tsage: W = FiniteCoxeterGroups().example(); W\n\t\t\t\tThe 5-th dihedral group of order 10\n\t\t\t\tsage: w = W.an_element()\n\t\t\t\tsage: w\n\t\t\t\t(1, 2)\n\t\t\t\tsage: w._mul_(w)\n\t\t\t\t(1, 2, 1, 2)\n\t\t\t\tsage: w._mul_(w)._mul_(w)\n\t\t\t\t(2, 1, 2, 1)\n\n\t\t\tThis method is called when computing ``self * other``::\n\n\t\t\t\tsage: w * w\n\t\t\t\t(1, 2, 1, 2)\n\n\t\t\tTESTS::\n\n\t\t\t\tsage: w._mul_.__module__\n\t\t\t\t'sage.categories.complex_reflection_or_generalized_coxeter_groups'\n\t\t\t\"\"\"\n\t\t\treturn self.apply_simple_reflections(other.reduced_word())\n\n\t\tdef inverse(self):\n\t\t\t\"\"\"\n\t\t\tReturn the inverse of ``self``.\n\n\t\t\tEXAMPLES::\n\n\t\t\t\tsage: W = WeylGroup(['B',7])\n\t\t\t\tsage: w = W.an_element()\n\t\t\t\tsage: u = w.inverse()\n\t\t\t\tsage: u == ~w\n\t\t\t\tTrue\n\t\t\t\tsage: u * w == w * u\n\t\t\t\tTrue\n\t\t\t\tsage: u * w\n\t\t\t\t[1 0 0 0 0 0 0]\n\t\t\t\t[0 1 0 0 0 0 0]\n\t\t\t\t[0 0 1 0 0 0 0]\n\t\t\t\t[0 0 0 1 0 0 0]\n\t\t\t\t[0 0 0 0 1 0 0]\n\t\t\t\t[0 0 0 0 0 1 0]\n\t\t\t\t[0 0 0 0 0 0 1]\n\t\t\t\"\"\"\n\t\t\treturn self.parent().one().apply_simple_reflections(self.reduced_word_reverse_iterator())\n\n\t\t__invert__ = inverse\n\n\t\tdef apply_conjugation_by_simple_reflection(self, i):\n\t\t\tr\"\"\"\n\t\t\tConjugate ``self`` by the ``i``-th simple reflection.\n\n\t\t\tEXAMPLES::\n\n\t\t\t\tsage: W = WeylGroup(['A',3])\n\t\t\t\tsage: w = W.from_reduced_word([3,1,2,1])\n\t\t\t\tsage: w.apply_conjugation_by_simple_reflection(1).reduced_word()\n\t\t\t\t[3, 2]\n\t\t\t\"\"\"\n\t\t\treturn self.apply_simple_reflection(i).apply_simple_reflection(i, side='left')\n\n\t\t@abstract_method(optional=True)\n\t\tdef reflection_length(self):\n\t\t\tr\"\"\"\n\t\t\tReturn the reflection length of ``self``.\n\n\t\t\tThis is the minimal length of a factorization of ``self``\n\t\t\tinto reflections.\n\n\t\t\tEXAMPLES::\n\n\t\t\t\tsage: W = ReflectionGroup((1,1,2))\t\t\t\t\t  # optional - gap3\n\t\t\t\tsage: sorted([t.reflection_length() for t in W])\t\t# optional - gap3\n\t\t\t\t[0, 1]\n\n\t\t\t\tsage: W = ReflectionGroup((2,1,2))\t\t\t\t\t  # optional - gap3\n\t\t\t\tsage: sorted([t.reflection_length() for t in W])\t\t# optional - gap3\n\t\t\t\t[0, 1, 1, 1, 1, 2, 2, 2]\n\n\t\t\t\tsage: W = ReflectionGroup((3,1,2))\t\t\t\t\t  # optional - gap3\n\t\t\t\tsage: sorted([t.reflection_length() for t in W])\t\t# optional - gap3\n\t\t\t\t[0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n\n\t\t\t\tsage: W = ReflectionGroup((2,2,2))\t\t\t\t\t  # optional - gap3\n\t\t\t\tsage: sorted([t.reflection_length() for t in W])\t\t# optional - gap3\n\t\t\t\t[0, 1, 1, 2]\n\t\t\t\"\"\"\n\n\t\tdef is_reflection(self):\n\t\t\tr\"\"\"\n\t\t\tReturn whether ``self`` is a reflection.\n\n\t\t\tEXAMPLES::\n\n\t\t\t\tsage: W = ReflectionGroup((1,1,4))\t\t\t\t\t  # optional - gap3\n\t\t\t\tsage: [t.is_reflection() for t in W.reflections()]\t  # optional - gap3\n\t\t\t\t[True, True, True, True, True, True]\n\t\t\t\tsage: len([t for t in W.reflections() if t.is_reflection()])\t# optional - gap3\n\t\t\t\t6\n\n\t\t\t\tsage: W = ReflectionGroup((2,1,3))\t\t\t\t\t  # optional - gap3\n\t\t\t\tsage: [t.is_reflection() for t in W.reflections()]\t  # optional - gap3\n\t\t\t\t[True, True, True, True, True, True, True, True, True]\n\t\t\t\tsage: len([t for t in W.reflections() if t.is_reflection()])\t# optional - gap3\n\t\t\t\t9\n\t\t\t\"\"\"\n\t\t\treturn self.reflection_length() == 1\n\n\tclass Irreducible(CategoryWithAxiom):\n\t\tclass ParentMethods:\n\t\t\tdef irreducible_components(self):\n\t\t\t\tr\"\"\"\n\t\t\t\tReturn a list containing all irreducible components of\n\t\t\t\t``self`` as finite reflection groups.\n\n\t\t\t\tEXAMPLES::\n\n\t\t\t\t\tsage: W = ColoredPermutations(4, 3)\n\t\t\t\t\tsage: W.irreducible_components()\n\t\t\t\t\t[4-colored permutations of size 3]\n\t\t\t\t\"\"\"\n\t\t\t\treturn [self]\n", "description": "\n\tThe category of complex reflection groups or generalized Coxeter groups.\n\n\tFinite Coxeter groups can be defined equivalently as groups\n\tgenerated by reflections, or by presentations. Over the last\n\tdecades, the theory has been generalized in both directions,\n\tleading to the study of (finite) complex reflection groups on the\n\tone hand, and (finite) generalized Coxeter groups on the other\n\thand. Many of the features remain similar, yet, in the current\n\tstate of the art, there is no general theory covering both\n\tdirections.\n\n\tThis is reflected by the name of this category which is about\n\tfactoring out the common code, tests, and declarations.\n\n\tA group in this category has:\n\n\t- A distinguished finite set of generators `(s_i)_I`, called\n\t  *simple reflections*. The set `I` is called the *index set*. The\n\t  name \"reflection\" is somewhat of an abuse as they can have\n\t  higher order; still, they are all of finite order: `s_i^k=1` for\n\t  some `k`.\n\n\t- A collection of *distinguished reflections* which are the\n\t  conjugates of the simple reflections. For complex reflection\n\t  groups, they are in one-to-one correspondence with the\n\t  reflection hyperplanes and share the same index set.\n\n\t- A collection of *reflections* which are the conjugates of all\n\t  the non trivial powers of the simple reflections.\n\n\tThe usual notions of reduced words, length, irreducibility, etc\n\tcan be canonically defined from the above.\n\n\tThe following methods must be implemented:\n\n\t- :meth:`ComplexReflectionOrGeneralizedCoxeterGroups.ParentMethods.index_set`\n\t- :meth:`ComplexReflectionOrGeneralizedCoxeterGroups.ParentMethods.simple_reflection`\n\n\tOptionally one can define analog methods for distinguished\n\treflections and reflections (see below).\n\n\tAt least one of the following methods must be implemented:\n\n\t- :meth:`ComplexReflectionOrGeneralizedCoxeterGroups.ElementMethods.apply_simple_reflection`\n\t- :meth:`ComplexReflectionOrGeneralizedCoxeterGroups.ElementMethods.apply_simple_reflection_left`\n\t- :meth:`ComplexReflectionOrGeneralizedCoxeterGroups.ElementMethods.apply_simple_reflection_right`\n\t- :meth:`ComplexReflectionOrGeneralizedCoxeterGroups.ElementMethods._mul_`\n\n\tIt's recommended to implement either ``_mul_`` or both\n\t``apply_simple_reflection_left`` and ``apply_simple_reflection_right``.\n\n\t.. SEEALSO::\n\n\t\t- :class:`complex_reflection_groups.ComplexReflectionGroups`\n\t\t- :class:`generalized_coxeter_groups.GeneralizedCoxeterGroups`\n\n\tEXAMPLES::\n\n\t\tsage: from sage.categories.complex_reflection_or_generalized_coxeter_groups import ComplexReflectionOrGeneralizedCoxeterGroups\n\t\tsage: C = ComplexReflectionOrGeneralizedCoxeterGroups(); C\n\t\tCategory of complex reflection or generalized coxeter groups\n\t\tsage: C.super_categories()\n\t\t[Category of finitely generated enumerated groups]\n\n\t\tsage: C.required_methods()\n\t\t{'element': {'optional': ['reflection_length'],\n\t\t\t\t\t 'required': []},\n\t\t  'parent': {'optional': ['distinguished_reflection', 'hyperplane_index_set',\n\t\t\t\t\t\t\t\t  'irreducible_components',\n\t\t\t\t\t\t\t\t  'reflection', 'reflection_index_set'],\n\t\t\t\t\t'required':  ['__contains__', 'index_set']}}\n\n\tTESTS::\n\n\t\tsage: TestSuite(C).run()\n\t", "category": "simple", "imports": ["import itertools", "from sage.misc.abstract_method import abstract_method", "from sage.misc.cachefunc import cached_method", "from sage.categories.category_singleton import Category_singleton", "from sage.categories.category_with_axiom import CategoryWithAxiom", "from sage.categories.groups import Groups", "\t\tsage: from sage.categories.complex_reflection_or_generalized_coxeter_groups import ComplexReflectionOrGeneralizedCoxeterGroups", "\t\t\tsage: from sage.categories.complex_reflection_groups import ComplexReflectionGroups", "\t\t\t\tsage: from sage.categories.complex_reflection_groups import ComplexReflectionGroups", "\t\t\tfrom sage.sets.family import Family", "\t\t\tfrom sage.rings.integer_ring import ZZ", "\t\t\t\tsage: from sage.categories.complex_reflection_groups import ComplexReflectionGroups", "\t\t\tfrom sage.sets.family import Family", "\t\t\tfrom sage.sets.family import Family", "\t\t\tfrom sage.graphs.graph import Graph", "\t\t\t\tsage: from sage.categories.complex_reflection_groups import ComplexReflectionGroups", "\t\t\t\tsage: from sage.categories.complex_reflection_groups import ComplexReflectionGroups", "\t\t\t\tsage: from sage.categories.complex_reflection_groups import ComplexReflectionGroups"]}], [{"term": "class", "name": "TestLibraryInfo", "data": "class TestLibraryInfo(object):\n\tdef test_simple(self):\n\t\twith temppath('foo.ini') as path:\n\t\t\twith open(path,  'w') as f:\n\t\t\t\tf.write(simple)\n\t\t\tpkg = os.path.splitext(path)[0]\n\t\t\tout = read_config(pkg)\n\n\t\tassert_(out.cflags() == simple_d['cflags'])\n\t\tassert_(out.libs() == simple_d['libflags'])\n\t\tassert_(out.name == simple_d['name'])\n\t\tassert_(out.version == simple_d['version'])\n\n\tdef test_simple_variable(self):\n\t\twith temppath('foo.ini') as path:\n\t\t\twith open(path,  'w') as f:\n\t\t\t\tf.write(simple_variable)\n\t\t\tpkg = os.path.splitext(path)[0]\n\t\t\tout = read_config(pkg)\n\n\t\tassert_(out.cflags() == simple_variable_d['cflags'])\n\t\tassert_(out.libs() == simple_variable_d['libflags'])\n\t\tassert_(out.name == simple_variable_d['name'])\n\t\tassert_(out.version == simple_variable_d['version'])\n\t\tout.vars['prefix'] = '/Users/david'\n\t\tassert_(out.cflags() == '-I/Users/david/include')\n", "description": null, "category": "simple", "imports": ["from __future__ import division, absolute_import, print_function", "import os", "from numpy.distutils.npy_pkg_config import read_config, parse_flags", "from numpy.testing import run_module_suite, temppath, assert_"]}, {"term": "class", "name": "TestParseFlags", "data": "class TestParseFlags(object):\n\tdef test_simple_cflags(self):\n\t\td = parse_flags(\"-I/usr/include\")\n\t\tassert_(d['include_dirs'] == ['/usr/include'])\n\n\t\td = parse_flags(\"-I/usr/include -DFOO\")\n\t\tassert_(d['include_dirs'] == ['/usr/include'])\n\t\tassert_(d['macros'] == ['FOO'])\n\n\t\td = parse_flags(\"-I /usr/include -DFOO\")\n\t\tassert_(d['include_dirs'] == ['/usr/include'])\n\t\tassert_(d['macros'] == ['FOO'])\n\n\tdef test_simple_lflags(self):\n\t\td = parse_flags(\"-L/usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tassert_(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tassert_(d['libraries'] == ['foo', 'bar'])\n\n\t\td = parse_flags(\"-L /usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tassert_(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tassert_(d['libraries'] == ['foo', 'bar'])\n\n", "description": null, "category": "simple", "imports": ["from __future__ import division, absolute_import, print_function", "import os", "from numpy.distutils.npy_pkg_config import read_config, parse_flags", "from numpy.testing import run_module_suite, temppath, assert_"]}], [], [], [], [], [], [], [], [], [], [], [], [], [{"term": "class", "name": "DocumentStore", "data": "class DocumentStore(object):\n\t\"\"\"\n\tLocal XML document content repository.\n\n\tEach XML document is identified by its location, i.e. URL without any\n\tprotocol identifier. Contained XML documents can be looked up using any URL\n\treferencing that same location.\n\n\t\"\"\"\n\n\tdef __init__(self, *args, **kwargs):\n\t\tself.__store = {\n\t\t\t'schemas.xmlsoap.org/soap/encoding/': soap5_encoding_schema}\n\t\tself.update = self.__store.update\n\t\tself.update(*args, **kwargs)\n\n\tdef __len__(self):\n\t\treturn len(self.__store)\n\n\tdef open(self, url):\n\t\t\"\"\"\n\t\tOpen a document at the specified URL.\n\n\t\tThe document URL's needs not contain a protocol identifier, and if it\n\t\tdoes, that protocol identifier is ignored when looking up the store\n\t\tcontent.\n\n\t\tMissing documents referenced using the internal 'suds' protocol are\n\t\treported by raising an exception. For other protocols, None is returned\n\t\tinstead.\n\n\t\t@param url: A document URL.\n\t\t@type url: str\n\t\t@return: Document content or None if not found.\n\t\t@rtype: bytes\n\n\t\t\"\"\"\n\t\tprotocol, location = self.__split(url)\n\t\tcontent = self.__find(location)\n\t\tif protocol == 'suds' and content is None:\n\t\t\traise Exception('location \"%s\" not in document store' % location)\n\t\treturn content\n\n\tdef __find(self, location):\n\t\t\"\"\"\n\t\tFind the specified location in the store.\n\n\t\t@param location: The I{location} part of a URL.\n\t\t@type location: str\n\t\t@return: Document content or None if not found.\n\t\t@rtype: bytes\n\n\t\t\"\"\"\n\t\treturn self.__store.get(location)\n\n\tdef __split(self, url):\n\t\t\"\"\"\n\t\tSplit the given URL into its I{protocol} & I{location} components.\n\n\t\t@param url: A URL.\n\t\t@param url: str\n\t\t@return: (I{protocol}, I{location})\n\t\t@rtype: (str, str)\n\n\t\t\"\"\"\n\t\tparts = url.split('://', 1)\n\t\tif len(parts) == 2:\n\t\t\treturn parts\n\t\treturn None, url\n\n", "description": "\n\tLocal XML document content repository.\n\n\tEach XML document is identified by its location, i.e. URL without any\n\tprotocol identifier. Contained XML documents can be looked up using any URL\n\treferencing that same location.\n\n\t", "category": "simple", "imports": ["import suds"]}], [{"term": "class", "name": "DocumentStore", "data": "class DocumentStore(object):\n\t\"\"\"\n\tLocal XML document content repository.\n\n\tEach XML document is identified by its location, i.e. URL without any\n\tprotocol identifier. Contained XML documents can be looked up using any URL\n\treferencing that same location.\n\n\t\"\"\"\n\n\tdef __init__(self, *args, **kwargs):\n\t\tself.__store = {\n\t\t\t'schemas.xmlsoap.org/soap/encoding/': soap5_encoding_schema}\n\t\tself.update = self.__store.update\n\t\tself.update(*args, **kwargs)\n\n\tdef __len__(self):\n\t\treturn len(self.__store)\n\n\tdef open(self, url):\n\t\t\"\"\"\n\t\tOpen a document at the specified URL.\n\n\t\tThe document URL's needs not contain a protocol identifier, and if it\n\t\tdoes, that protocol identifier is ignored when looking up the store\n\t\tcontent.\n\n\t\tMissing documents referenced using the internal 'suds' protocol are\n\t\treported by raising an exception. For other protocols, None is returned\n\t\tinstead.\n\n\t\t@param url: A document URL.\n\t\t@type url: str\n\t\t@return: Document content or None if not found.\n\t\t@rtype: bytes\n\n\t\t\"\"\"\n\t\tprotocol, location = self.__split(url)\n\t\tcontent = self.__find(location)\n\t\tif protocol == 'suds' and content is None:\n\t\t\traise Exception, 'location \"%s\" not in document store' % location\n\t\treturn content\n\n\tdef __find(self, location):\n\t\t\"\"\"\n\t\tFind the specified location in the store.\n\n\t\t@param location: The I{location} part of a URL.\n\t\t@type location: str\n\t\t@return: Document content or None if not found.\n\t\t@rtype: bytes\n\n\t\t\"\"\"\n\t\treturn self.__store.get(location)\n\n\tdef __split(self, url):\n\t\t\"\"\"\n\t\tSplit the given URL into its I{protocol} & I{location} components.\n\n\t\t@param url: A URL.\n\t\t@param url: str\n\t\t@return: (I{protocol}, I{location})\n\t\t@rtype: (str, str)\n\n\t\t\"\"\"\n\t\tparts = url.split('://', 1)\n\t\tif len(parts) == 2:\n\t\t\treturn parts\n\t\treturn None, url\n\n", "description": "\n\tLocal XML document content repository.\n\n\tEach XML document is identified by its location, i.e. URL without any\n\tprotocol identifier. Contained XML documents can be looked up using any URL\n\treferencing that same location.\n\n\t", "category": "simple", "imports": ["import suds"]}], [{"term": "class", "name": "CookieTests", "data": "class CookieTests(unittest.TestCase):\n\n\tdef setUp(self):\n\t\tself._warnings_manager = check_warnings()\n\t\tself._warnings_manager.__enter__()\n\t\twarnings.filterwarnings(\"ignore\", \".* class is insecure.*\",\n\t\t\t\t\t\t\t\tDeprecationWarning)\n\n\tdef tearDown(self):\n\t\tself._warnings_manager.__exit__(None, None, None)\n\n\tdef test_basic(self):\n\t\tcases = [\n\t\t\t{'data': 'chips=ahoy; vienna=finger',\n\t\t\t 'dict': {'chips':'ahoy', 'vienna':'finger'},\n\t\t\t 'repr': \"\",\n\t\t\t 'output': 'Set-Cookie: chips=ahoy\\nSet-Cookie: vienna=finger'},\n\n\t\t\t{'data': 'keebler=\"E=mc2; L=\\\\\"Loves\\\\\"; fudge=\\\\012;\"',\n\t\t\t 'dict': {'keebler' : 'E=mc2; L=\"Loves\"; fudge=\\012;'},\n\t\t\t 'repr': '''''',\n\t\t\t 'output': 'Set-Cookie: keebler=\"E=mc2; L=\\\\\"Loves\\\\\"; fudge=\\\\012;\"'},\n\n\t\t\t# Check illegal cookies that have an '=' char in an unquoted value\n\t\t\t{'data': 'keebler=E=mc2',\n\t\t\t 'dict': {'keebler' : 'E=mc2'},\n\t\t\t 'repr': \"\",\n\t\t\t 'output': 'Set-Cookie: keebler=E=mc2'},\n\n\t\t\t# Cookies with ':' character in their name. Though not mentioned in\n\t\t\t# RFC, servers / browsers allow it.\n\n\t\t\t {'data': 'key:term=value:term',\n\t\t\t 'dict': {'key:term' : 'value:term'},\n\t\t\t 'repr': \"\",\n\t\t\t 'output': 'Set-Cookie: key:term=value:term'},\n\n\t\t]\n\n\t\tfor case in cases:\n\t\t\tC = cookies.SimpleCookie()\n\t\t\tC.load(case['data'])\n\t\t\tself.assertEqual(repr(C), case['repr'])\n\t\t\tself.assertEqual(C.output(sep='\\n'), case['output'])\n\t\t\tfor k, v in sorted(case['dict'].items()):\n\t\t\t\tself.assertEqual(C[k].value, v)\n\n\tdef test_load(self):\n\t\tC = cookies.SimpleCookie()\n\t\tC.load('Customer=\"WILE_E_COYOTE\"; Version=1; Path=/acme')\n\n\t\tself.assertEqual(C['Customer'].value, 'WILE_E_COYOTE')\n\t\tself.assertEqual(C['Customer']['version'], '1')\n\t\tself.assertEqual(C['Customer']['path'], '/acme')\n\n\t\tself.assertEqual(C.output(['path']),\n\t\t\t'Set-Cookie: Customer=\"WILE_E_COYOTE\"; Path=/acme')\n\t\tself.assertEqual(C.js_output(), r\"\"\"\n\t\t\n\t\t\"\"\")\n\t\tself.assertEqual(C.js_output(['path']), r\"\"\"\n\t\t\n\t\t\"\"\")\n\n\tdef test_extended_encode(self):\n\t\t# Issue 9824: some browsers don't follow the standard; we now\n\t\t# encode , and ; to keep them from tripping up.\n\t\tC = cookies.SimpleCookie()\n\t\tC['val'] = \"some,funky;stuff\"\n\t\tself.assertEqual(C.output(['val']),\n\t\t\t'Set-Cookie: val=\"some\\\\054funky\\\\073stuff\"')\n\n\tdef test_special_attrs(self):\n\t\t# 'expires'\n\t\tC = cookies.SimpleCookie('Customer=\"WILE_E_COYOTE\"')\n\t\tC['Customer']['expires'] = 0\n\t\t# can't test exact output, it always depends on current date/time\n\t\tself.assertTrue(C.output().endswith('GMT'))\n\n\t\t# loading 'expires'\n\t\tC = cookies.SimpleCookie()\n\t\tC.load('Customer=\"W\"; expires=Wed, 01 Jan 2010 00:00:00 GMT')\n\t\tself.assertEqual(C['Customer']['expires'],\n\t\t\t\t\t\t 'Wed, 01 Jan 2010 00:00:00 GMT')\n\t\tC = cookies.SimpleCookie()\n\t\tC.load('Customer=\"W\"; expires=Wed, 01 Jan 98 00:00:00 GMT')\n\t\tself.assertEqual(C['Customer']['expires'],\n\t\t\t\t\t\t 'Wed, 01 Jan 98 00:00:00 GMT')\n\n\t\t# 'max-age'\n\t\tC = cookies.SimpleCookie('Customer=\"WILE_E_COYOTE\"')\n\t\tC['Customer']['max-age'] = 10\n\t\tself.assertEqual(C.output(),\n\t\t\t\t\t\t 'Set-Cookie: Customer=\"WILE_E_COYOTE\"; Max-Age=10')\n\n\tdef test_set_secure_httponly_attrs(self):\n\t\tC = cookies.SimpleCookie('Customer=\"WILE_E_COYOTE\"')\n\t\tC['Customer']['secure'] = True\n\t\tC['Customer']['httponly'] = True\n\t\tself.assertEqual(C.output(),\n\t\t\t'Set-Cookie: Customer=\"WILE_E_COYOTE\"; httponly; secure')\n\n\tdef test_secure_httponly_false_if_not_present(self):\n\t\tC = cookies.SimpleCookie()\n\t\tC.load('eggs=scrambled; Path=/bacon')\n\t\tself.assertFalse(C['eggs']['httponly'])\n\t\tself.assertFalse(C['eggs']['secure'])\n\n\tdef test_secure_httponly_true_if_present(self):\n\t\t# Issue 16611\n\t\tC = cookies.SimpleCookie()\n\t\tC.load('eggs=scrambled; httponly; secure; Path=/bacon')\n\t\tself.assertTrue(C['eggs']['httponly'])\n\t\tself.assertTrue(C['eggs']['secure'])\n\n\tdef test_secure_httponly_true_if_have_value(self):\n\t\t# This isn't really valid, but demonstrates what the current code\n\t\t# is expected to do in this case.\n\t\tC = cookies.SimpleCookie()\n\t\tC.load('eggs=scrambled; httponly=foo; secure=bar; Path=/bacon')\n\t\tself.assertTrue(C['eggs']['httponly'])\n\t\tself.assertTrue(C['eggs']['secure'])\n\t\t# Here is what it actually does; don't depend on this behavior.  These\n\t\t# checks are testing backward compatibility for issue 16611.\n\t\tself.assertEqual(C['eggs']['httponly'], 'foo')\n\t\tself.assertEqual(C['eggs']['secure'], 'bar')\n\n\tdef test_bad_attrs(self):\n\t\t# issue 16611: make sure we don't break backward compatibility.\n\t\tC = cookies.SimpleCookie()\n\t\tC.load('cookie=with; invalid; version; second=cookie;')\n\t\tself.assertEqual(C.output(),\n\t\t\t'Set-Cookie: cookie=with\\r\\nSet-Cookie: second=cookie')\n\n\tdef test_extra_spaces(self):\n\t\tC = cookies.SimpleCookie()\n\t\tC.load('eggs  =  scrambled  ;  secure  ;  path  =  bar   ; foo=foo   ')\n\t\tself.assertEqual(C.output(),\n\t\t\t'Set-Cookie: eggs=scrambled; Path=bar; secure\\r\\nSet-Cookie: foo=foo')\n\n\tdef test_quoted_meta(self):\n\t\t# Try cookie with quoted meta-data\n\t\tC = cookies.SimpleCookie()\n\t\tC.load('Customer=\"WILE_E_COYOTE\"; Version=\"1\"; Path=\"/acme\"')\n\t\tself.assertEqual(C['Customer'].value, 'WILE_E_COYOTE')\n\t\tself.assertEqual(C['Customer']['version'], '1')\n\t\tself.assertEqual(C['Customer']['path'], '/acme')\n\n\t\tself.assertEqual(C.output(['path']),\n\t\t\t\t\t\t 'Set-Cookie: Customer=\"WILE_E_COYOTE\"; Path=/acme')\n\t\tself.assertEqual(C.js_output(), r\"\"\"\n\t\t\n\t\t\"\"\")\n\t\tself.assertEqual(C.js_output(['path']), r\"\"\"\n\t\t\n\t\t\"\"\")\n", "description": "\n\t\t\n\t\t", "category": "simple", "imports": ["from test.support import run_unittest, run_doctest, check_warnings", "import unittest", "from http import cookies", "import warnings"]}, {"term": "class", "name": "MorselTests", "data": "class MorselTests(unittest.TestCase):\n\t\"\"\"Tests for the Morsel object.\"\"\"\n\n\tdef test_reserved_keys(self):\n\t\tM = cookies.Morsel()\n\t\t# tests valid and invalid reserved keys for Morsels\n\t\tfor i in M._reserved:\n\t\t\t# Test that all valid keys are reported as reserved and set them\n\t\t\tself.assertTrue(M.isReservedKey(i))\n\t\t\tM[i] = '%s_value' % i\n\t\tfor i in M._reserved:\n\t\t\t# Test that valid key values come out fine\n\t\t\tself.assertEqual(M[i], '%s_value' % i)\n\t\tfor i in \"the holy hand grenade\".split():\n\t\t\t# Test that invalid keys raise CookieError\n\t\t\tself.assertRaises(cookies.CookieError,\n\t\t\t\t\t\t\t  M.__setitem__, i, '%s_value' % i)\n\n\tdef test_setter(self):\n\t\tM = cookies.Morsel()\n\t\t# tests the .set method to set keys and their values\n\t\tfor i in M._reserved:\n\t\t\t# Makes sure that all reserved keys can't be set this way\n\t\t\tself.assertRaises(cookies.CookieError,\n\t\t\t\t\t\t\t  M.set, i, '%s_value' % i, '%s_value' % i)\n\t\tfor i in \"thou cast _the- !holy! ^hand| +*grenade~\".split():\n\t\t\t# Try typical use case. Setting decent values.\n\t\t\t# Check output and js_output.\n\t\t\tM['path'] = '/foo' # Try a reserved key as well\n\t\t\tM.set(i, \"%s_val\" % i, \"%s_coded_val\" % i)\n\t\t\tself.assertEqual(\n\t\t\t\tM.output(),\n\t\t\t\t\"Set-Cookie: %s=%s; Path=/foo\" % (i, \"%s_coded_val\" % i))\n\t\t\texpected_js_output = \"\"\"\n\t\t\n\t\t\"\"\" % (i, \"%s_coded_val\" % i)\n\t\t\tself.assertEqual(M.js_output(), expected_js_output)\n\t\tfor i in [\"foo bar\", \"foo@bar\"]:\n\t\t\t# Try some illegal characters\n\t\t\tself.assertRaises(cookies.CookieError,\n\t\t\t\t\t\t\t  M.set, i, '%s_value' % i, '%s_value' % i)\n\n", "description": "Tests for the Morsel object.", "category": "simple", "imports": ["from test.support import run_unittest, run_doctest, check_warnings", "import unittest", "from http import cookies", "import warnings"]}, {"term": "def", "name": "test_main", "data": "def test_main():\n\trun_unittest(CookieTests, MorselTests)\n\trun_doctest(cookies)\n", "description": null, "category": "simple", "imports": ["from test.support import run_unittest, run_doctest, check_warnings", "import unittest", "from http import cookies", "import warnings"]}], [{"term": "class", "name": "ScannerError", "data": "class ScannerError(MarkedError):\n\tpass\n\n", "description": null, "category": "simple", "imports": ["from __future__ import (unicode_literals, division, absolute_import, print_function)", "from powerline.lint.markedjson.error import MarkedError", "from powerline.lint.markedjson import tokens", "from powerline.lib.unicode import unicode"]}, {"term": "class", "name": "classSimpleKey:", "data": "class SimpleKey:\n\t# See below simple keys treatment.\n\tdef __init__(self, token_number, index, line, column, mark):\n\t\tself.token_number = token_number\n\t\tself.index = index\n\t\tself.line = line\n\t\tself.column = column\n\t\tself.mark = mark\n\n", "description": null, "category": "simple", "imports": ["from __future__ import (unicode_literals, division, absolute_import, print_function)", "from powerline.lint.markedjson.error import MarkedError", "from powerline.lint.markedjson import tokens", "from powerline.lib.unicode import unicode"]}, {"term": "class", "name": "classScanner:", "data": "class Scanner:\n\tdef __init__(self):\n\t\t'''Initialize the scanner.'''\n\t\t# It is assumed that Scanner and Reader will have a common descendant.\n\t\t# Reader do the dirty work of checking for BOM and converting the\n\t\t# input data to Unicode. It also adds NUL to the end.\n\t\t#\n\t\t# Reader supports the following methods\n\t\t# \tself.peek(i=0)\t\t # peek the next i-th character\n\t\t# \tself.prefix(l=1)\t # peek the next l characters\n\t\t# \tself.forward(l=1)\t # read the next l characters and move the pointer.\n\n\t\t# Had we reached the end of the stream?\n\t\tself.done = False\n\n\t\t# The number of unclosed '{' and '['. `flow_level == 0` means block\n\t\t# context.\n\t\tself.flow_level = 0\n\n\t\t# List of processed tokens that are not yet emitted.\n\t\tself.tokens = []\n\n\t\t# Add the STREAM-START token.\n\t\tself.fetch_stream_start()\n\n\t\t# Number of tokens that were emitted through the `get_token` method.\n\t\tself.tokens_taken = 0\n\n\t\t# Variables related to simple keys treatment.\n\n\t\t# A simple key is a key that is not denoted by the '?' indicator.\n\t\t# We emit the KEY token before all keys, so when we find a potential\n\t\t# simple key, we try to locate the corresponding ':' indicator.\n\t\t# Simple keys should be limited to a single line.\n\n\t\t# Can a simple key start at the current position? A simple key may\n\t\t# start:\n\t\t# - after '{', '[', ',' (in the flow context),\n\t\tself.allow_simple_key = False\n\n\t\t# Keep track of possible simple keys. This is a dictionary. The key\n\t\t# is `flow_level`; there can be no more that one possible simple key\n\t\t# for each level. The value is a SimpleKey record:\n\t\t# \t(token_number, index, line, column, mark)\n\t\t# A simple key may start with SCALAR(flow), '[', or '{' tokens.\n\t\tself.possible_simple_keys = {}\n\n\t# Public methods.\n\n\tdef check_token(self, *choices):\n\t\t# Check if the next token is one of the given types.\n\t\twhile self.need_more_tokens():\n\t\t\tself.fetch_more_tokens()\n\t\tif self.tokens:\n\t\t\tif not choices:\n\t\t\t\treturn True\n\t\t\tfor choice in choices:\n\t\t\t\tif isinstance(self.tokens[0], choice):\n\t\t\t\t\treturn True\n\t\treturn False\n\n\tdef peek_token(self):\n\t\t# Return the next token, but do not delete if from the queue.\n\t\twhile self.need_more_tokens():\n\t\t\tself.fetch_more_tokens()\n\t\tif self.tokens:\n\t\t\treturn self.tokens[0]\n\n\tdef get_token(self):\n\t\t# Return the next token.\n\t\twhile self.need_more_tokens():\n\t\t\tself.fetch_more_tokens()\n\t\tif self.tokens:\n\t\t\tself.tokens_taken += 1\n\t\t\treturn self.tokens.pop(0)\n\n\t# Private methods.\n\n\tdef need_more_tokens(self):\n\t\tif self.done:\n\t\t\treturn False\n\t\tif not self.tokens:\n\t\t\treturn True\n\t\t# The current token may be a potential simple key, so we\n\t\t# need to look further.\n\t\tself.stale_possible_simple_keys()\n\t\tif self.next_possible_simple_key() == self.tokens_taken:\n\t\t\treturn True\n\n\tdef fetch_more_tokens(self):\n\n\t\t# Eat whitespaces and comments until we reach the next token.\n\t\tself.scan_to_next_token()\n\n\t\t# Remove obsolete possible simple keys.\n\t\tself.stale_possible_simple_keys()\n\n\t\t# Peek the next character.\n\t\tch = self.peek()\n\n\t\t# Is it the end of stream?\n\t\tif ch == '\\0':\n\t\t\treturn self.fetch_stream_end()\n\n\t\t# Note: the order of the following checks is NOT significant.\n\n\t\t# Is it the flow sequence start indicator?\n\t\tif ch == '[':\n\t\t\treturn self.fetch_flow_sequence_start()\n\n\t\t# Is it the flow mapping start indicator?\n\t\tif ch == '{':\n\t\t\treturn self.fetch_flow_mapping_start()\n\n\t\t# Is it the flow sequence end indicator?\n\t\tif ch == ']':\n\t\t\treturn self.fetch_flow_sequence_end()\n\n\t\t# Is it the flow mapping end indicator?\n\t\tif ch == '}':\n\t\t\treturn self.fetch_flow_mapping_end()\n\n\t\t# Is it the flow entry indicator?\n\t\tif ch == ',':\n\t\t\treturn self.fetch_flow_entry()\n\n\t\t# Is it the value indicator?\n\t\tif ch == ':' and self.flow_level:\n\t\t\treturn self.fetch_value()\n\n\t\t# Is it a double quoted scalar?\n\t\tif ch == '\"':\n\t\t\treturn self.fetch_double()\n\n\t\t# It must be a plain scalar then.\n\t\tif self.check_plain():\n\t\t\treturn self.fetch_plain()\n\n\t\t# No? It\u2019s an error. Let\u2019s produce a nice error message.\n\t\traise ScannerError(\n\t\t\t'while scanning for the next token', None,\n\t\t\t'found character %r that cannot start any token' % ch,\n\t\t\tself.get_mark()\n\t\t)\n\n\t# Simple keys treatment.\n\n\tdef next_possible_simple_key(self):\n\t\t# Return the number of the nearest possible simple key. Actually we\n\t\t# don\u2019t need to loop through the whole dictionary. We may replace it\n\t\t# with the following code:\n\t\t# \tif not self.possible_simple_keys:\n\t\t# \t\treturn None\n\t\t# \treturn self.possible_simple_keys[\n\t\t# \t\t\tmin(self.possible_simple_keys.keys())].token_number\n\t\tmin_token_number = None\n\t\tfor level in self.possible_simple_keys:\n\t\t\tkey = self.possible_simple_keys[level]\n\t\t\tif min_token_number is None or key.token_number < min_token_number:\n\t\t\t\tmin_token_number = key.token_number\n\t\treturn min_token_number\n\n\tdef stale_possible_simple_keys(self):\n\t\t# Remove entries that are no longer possible simple keys. According to\n\t\t# the YAML specification, simple keys\n\t\t# - should be limited to a single line,\n\t\t# Disabling this procedure will allow simple keys of any length and\n\t\t# height (may cause problems if indentation is broken though).\n\t\tfor level in list(self.possible_simple_keys):\n\t\t\tkey = self.possible_simple_keys[level]\n\t\t\tif key.line != self.line:\n\t\t\t\tdel self.possible_simple_keys[level]\n\n\tdef save_possible_simple_key(self):\n\t\t# The next token may start a simple key. We check if it\u2019s possible\n\t\t# and save its position. This function is called for\n\t\t# \tSCALAR(flow), '[', and '{'.\n\n\t\t# The next token might be a simple key. Let\u2019s save it\u2019s number and\n\t\t# position.\n\t\tif self.allow_simple_key:\n\t\t\tself.remove_possible_simple_key()\n\t\t\ttoken_number = self.tokens_taken + len(self.tokens)\n\t\t\tkey = SimpleKey(token_number, self.index, self.line, self.column, self.get_mark())\n\t\t\tself.possible_simple_keys[self.flow_level] = key\n\n\tdef remove_possible_simple_key(self):\n\t\t# Remove the saved possible key position at the current flow level.\n\t\tif self.flow_level in self.possible_simple_keys:\n\t\t\tdel self.possible_simple_keys[self.flow_level]\n\n\t# Fetchers.\n\n\tdef fetch_stream_start(self):\n\t\t# We always add STREAM-START as the first token and STREAM-END as the\n\t\t# last token.\n\n\t\t# Read the token.\n\t\tmark = self.get_mark()\n\n\t\t# Add STREAM-START.\n\t\tself.tokens.append(tokens.StreamStartToken(mark, mark, encoding=self.encoding))\n\n\tdef fetch_stream_end(self):\n\t\t# Reset simple keys.\n\t\tself.remove_possible_simple_key()\n\t\tself.allow_simple_key = False\n\t\tself.possible_simple_keys = {}\n\n\t\t# Read the token.\n\t\tmark = self.get_mark()\n\n\t\t# Add STREAM-END.\n\t\tself.tokens.append(tokens.StreamEndToken(mark, mark))\n\n\t\t# The steam is finished.\n\t\tself.done = True\n\n\tdef fetch_flow_sequence_start(self):\n\t\tself.fetch_flow_collection_start(tokens.FlowSequenceStartToken)\n\n\tdef fetch_flow_mapping_start(self):\n\t\tself.fetch_flow_collection_start(tokens.FlowMappingStartToken)\n\n\tdef fetch_flow_collection_start(self, TokenClass):\n\t\t# '[' and '{' may start a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# Increase the flow level.\n\t\tself.flow_level += 1\n\n\t\t# Simple keys are allowed after '[' and '{'.\n\t\tself.allow_simple_key = True\n\n\t\t# Add FLOW-SEQUENCE-START or FLOW-MAPPING-START.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(TokenClass(start_mark, end_mark))\n\n\tdef fetch_flow_sequence_end(self):\n\t\tself.fetch_flow_collection_end(tokens.FlowSequenceEndToken)\n\n\tdef fetch_flow_mapping_end(self):\n\t\tself.fetch_flow_collection_end(tokens.FlowMappingEndToken)\n\n\tdef fetch_flow_collection_end(self, TokenClass):\n\t\t# Reset possible simple key on the current level.\n\t\tself.remove_possible_simple_key()\n\n\t\t# Decrease the flow level.\n\t\tself.flow_level -= 1\n\n\t\t# No simple keys after ']' or '}'.\n\t\tself.allow_simple_key = False\n\n\t\t# Add FLOW-SEQUENCE-END or FLOW-MAPPING-END.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(TokenClass(start_mark, end_mark))\n\n\tdef fetch_value(self):\n\t\t# Do we determine a simple key?\n\t\tif self.flow_level in self.possible_simple_keys:\n\n\t\t\t# Add KEY.\n\t\t\tkey = self.possible_simple_keys[self.flow_level]\n\t\t\tdel self.possible_simple_keys[self.flow_level]\n\t\t\tself.tokens.insert(key.token_number - self.tokens_taken, tokens.KeyToken(key.mark, key.mark))\n\n\t\t\t# There cannot be two simple keys one after another.\n\t\t\tself.allow_simple_key = False\n\n\t\t# Add VALUE.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(tokens.ValueToken(start_mark, end_mark))\n\n\tdef fetch_flow_entry(self):\n\t\t# Simple keys are allowed after ','.\n\t\tself.allow_simple_key = True\n\n\t\t# Reset possible simple key on the current level.\n\t\tself.remove_possible_simple_key()\n\n\t\t# Add FLOW-ENTRY.\n\t\tstart_mark = self.get_mark()\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\tself.tokens.append(tokens.FlowEntryToken(start_mark, end_mark))\n\n\tdef fetch_double(self):\n\t\t# A flow scalar could be a simple key.\n\t\tself.save_possible_simple_key()\n\n\t\t# No simple keys after flow scalars.\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add SCALAR.\n\t\tself.tokens.append(self.scan_flow_scalar())\n\n\tdef fetch_plain(self):\n\n\t\tself.save_possible_simple_key()\n\n\t\t# No simple keys after plain scalars.\n\t\tself.allow_simple_key = False\n\n\t\t# Scan and add SCALAR. May change `allow_simple_key`.\n\t\tself.tokens.append(self.scan_plain())\n\n\t# Checkers.\n\n\tdef check_plain(self):\n\t\treturn self.peek() in '0123456789-ntf'\n\n\t# Scanners.\n\n\tdef scan_to_next_token(self):\n\t\twhile self.peek() in ' \\t\\n':\n\t\t\tself.forward()\n\n\tdef scan_flow_scalar(self):\n\t\t# See the specification for details.\n\t\t# Note that we loose indentation rules for quoted scalars. Quoted\n\t\t# scalars don\u2019t need to adhere indentation because \" and ' clearly\n\t\t# mark the beginning and the end of them. Therefore we are less\n\t\t# restrictive then the specification requires. We only need to check\n\t\t# that document separators are not included in scalars.\n\t\tchunks = []\n\t\tstart_mark = self.get_mark()\n\t\tquote = self.peek()\n\t\tself.forward()\n\t\tchunks.extend(self.scan_flow_scalar_non_spaces(start_mark))\n\t\twhile self.peek() != quote:\n\t\t\tchunks.extend(self.scan_flow_scalar_spaces(start_mark))\n\t\t\tchunks.extend(self.scan_flow_scalar_non_spaces(start_mark))\n\t\tself.forward()\n\t\tend_mark = self.get_mark()\n\t\treturn tokens.ScalarToken(unicode().join(chunks), False, start_mark, end_mark, '\"')\n\n\tESCAPE_REPLACEMENTS = {\n\t\t'b': '\\x08',\n\t\t't': '\\x09',\n\t\t'n': '\\x0A',\n\t\t'f': '\\x0C',\n\t\t'r': '\\x0D',\n\t\t'\"': '\\\"',\n\t\t'\\\\': '\\\\',\n\t}\n\n\tESCAPE_CODES = {\n\t\t'u': 4,\n\t}\n\n\tdef scan_flow_scalar_non_spaces(self, start_mark):\n\t\t# See the specification for details.\n\t\tchunks = []\n\t\twhile True:\n\t\t\tlength = 0\n\t\t\twhile self.peek(length) not in '\\\"\\\\\\0 \\t\\n':\n\t\t\t\tlength += 1\n\t\t\tif length:\n\t\t\t\tchunks.append(self.prefix(length))\n\t\t\t\tself.forward(length)\n\t\t\tch = self.peek()\n\t\t\tif ch == '\\\\':\n\t\t\t\tself.forward()\n\t\t\t\tch = self.peek()\n\t\t\t\tif ch in self.ESCAPE_REPLACEMENTS:\n\t\t\t\t\tchunks.append(self.ESCAPE_REPLACEMENTS[ch])\n\t\t\t\t\tself.forward()\n\t\t\t\telif ch in self.ESCAPE_CODES:\n\t\t\t\t\tlength = self.ESCAPE_CODES[ch]\n\t\t\t\t\tself.forward()\n\t\t\t\t\tfor k in range(length):\n\t\t\t\t\t\tif self.peek(k) not in '0123456789ABCDEFabcdef':\n\t\t\t\t\t\t\traise ScannerError(\n\t\t\t\t\t\t\t\t'while scanning a double-quoted scalar', start_mark,\n\t\t\t\t\t\t\t\t'expected escape sequence of %d hexdecimal numbers, but found %r' % (\n\t\t\t\t\t\t\t\t\tlength, self.peek(k)),\n\t\t\t\t\t\t\t\tself.get_mark()\n\t\t\t\t\t\t\t)\n\t\t\t\t\tcode = int(self.prefix(length), 16)\n\t\t\t\t\tchunks.append(chr(code))\n\t\t\t\t\tself.forward(length)\n\t\t\t\telse:\n\t\t\t\t\traise ScannerError(\n\t\t\t\t\t\t'while scanning a double-quoted scalar', start_mark,\n\t\t\t\t\t\t('found unknown escape character %r' % ch), self.get_mark()\n\t\t\t\t\t)\n\t\t\telse:\n\t\t\t\treturn chunks\n\n\tdef scan_flow_scalar_spaces(self, start_mark):\n\t\t# See the specification for details.\n\t\tchunks = []\n\t\tlength = 0\n\t\twhile self.peek(length) in ' \\t':\n\t\t\tlength += 1\n\t\twhitespaces = self.prefix(length)\n\t\tself.forward(length)\n\t\tch = self.peek()\n\t\tif ch == '\\0':\n\t\t\traise ScannerError(\n\t\t\t\t'while scanning a quoted scalar', start_mark,\n\t\t\t\t'found unexpected end of stream', self.get_mark()\n\t\t\t)\n\t\telif ch == '\\n':\n\t\t\traise ScannerError(\n\t\t\t\t'while scanning a quoted scalar', start_mark,\n\t\t\t\t'found unexpected line end', self.get_mark()\n\t\t\t)\n\t\telse:\n\t\t\tchunks.append(whitespaces)\n\t\treturn chunks\n\n\tdef scan_plain(self):\n\t\tchunks = []\n\t\tstart_mark = self.get_mark()\n\t\tspaces = []\n\t\twhile True:\n\t\t\tlength = 0\n\t\t\twhile True:\n\t\t\t\tif self.peek(length) not in 'eE.0123456789nul-tr+fas':\n\t\t\t\t\tbreak\n\t\t\t\tlength += 1\n\t\t\tif length == 0:\n\t\t\t\tbreak\n\t\t\tself.allow_simple_key = False\n\t\t\tchunks.extend(spaces)\n\t\t\tchunks.append(self.prefix(length))\n\t\t\tself.forward(length)\n\t\tend_mark = self.get_mark()\n\t\treturn tokens.ScalarToken(''.join(chunks), True, start_mark, end_mark)\n", "description": null, "category": "simple", "imports": ["from __future__ import (unicode_literals, division, absolute_import, print_function)", "from powerline.lint.markedjson.error import MarkedError", "from powerline.lint.markedjson import tokens", "from powerline.lib.unicode import unicode"]}], [{"term": "def", "name": "trim", "data": "def trim(value, num):\n\treturn value[:num]\n\n", "description": null, "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "noop", "data": "def noop(value, param=None):\n\t\"\"\"A noop filter that always return its first argument and does nothing with\n\tits second (optional) one.\n\tUseful for testing out whitespace in filter arguments (see #19882).\"\"\"\n\treturn value\n\n", "description": "A noop filter that always return its first argument and does nothing with\n\tits second (optional) one.\n\tUseful for testing out whitespace in filter arguments (see #19882).", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "context_stack_length", "data": "def context_stack_length(context):\n\treturn len(context.dicts)\n\n", "description": null, "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "no_params", "data": "def no_params():\n\t\"\"\"Expected no_params __doc__\"\"\"\n", "description": "Expected no_params __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "one_param", "data": "def one_param(arg):\n\t\"\"\"Expected one_param __doc__\"\"\"\n", "description": "Expected one_param __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "explicit_no_context", "data": "def explicit_no_context(arg):\n\t\"\"\"Expected explicit_no_context __doc__\"\"\"\n", "description": "Expected explicit_no_context __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "no_params_with_context", "data": "def no_params_with_context(context):\n\t\"\"\"Expected no_params_with_context __doc__\"\"\"\n", "description": "Expected no_params_with_context __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "params_and_context", "data": "def params_and_context(context, arg):\n\t\"\"\"Expected params_and_context __doc__\"\"\"\n", "description": "Expected params_and_context __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "simple_two_params", "data": "def simple_two_params(one, two):\n\t\"\"\"Expected simple_two_params __doc__\"\"\"\n", "description": "Expected simple_two_params __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "simple_one_default", "data": "def simple_one_default(one, two='hi'):\n\t\"\"\"Expected simple_one_default __doc__\"\"\"\n", "description": "Expected simple_one_default __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "simple_unlimited_args", "data": "def simple_unlimited_args(one, two='hi', *args):\n\t\"\"\"Expected simple_unlimited_args __doc__\"\"\"\n\treturn \"simple_unlimited_args - Expected result: %s\" % (\n\t\t', '.join(six.text_type(arg) for arg in [one, two] + list(args))\n", "description": "Expected simple_unlimited_args __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "simple_only_unlimited_args", "data": "def simple_only_unlimited_args(*args):\n\t\"\"\"Expected simple_only_unlimited_args __doc__\"\"\"\n", "description": "Expected simple_only_unlimited_args __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "simple_unlimited_args_kwargs", "data": "def simple_unlimited_args_kwargs(one, two='hi', *args, **kwargs):\n\t\"\"\"Expected simple_unlimited_args_kwargs __doc__\"\"\"\n\t# Sort the dictionary by key to guarantee the order for testing.\n\tsorted_kwarg = sorted(six.iteritems(kwargs), key=operator.itemgetter(0))\n\treturn \"simple_unlimited_args_kwargs - Expected result: %s / %s\" % (\n\t\t', '.join(six.text_type(arg) for arg in [one, two] + list(args)),\n\t\t', '.join('%s=%s' % (k, v) for (k, v) in sorted_kwarg)\n", "description": "Expected simple_unlimited_args_kwargs __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "simple_tag_without_context_parameter", "data": "def simple_tag_without_context_parameter(arg):\n\t\"\"\"Expected simple_tag_without_context_parameter __doc__\"\"\"\n", "description": "Expected simple_tag_without_context_parameter __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "escape_naive", "data": "def escape_naive(context):\n\t\"\"\"A tag that doesn't even think about escaping issues\"\"\"\n\treturn \"Hello {0}!\".format(context['name'])\n\n", "description": "A tag that doesn't even think about escaping issues", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "escape_explicit", "data": "def escape_explicit(context):\n\t\"\"\"A tag that uses escape explicitly\"\"\"\n\treturn escape(\"Hello {0}!\".format(context['name']))\n\n", "description": "A tag that uses escape explicitly", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "escape_format_html", "data": "def escape_format_html(context):\n\t\"\"\"A tag that uses format_html\"\"\"\n\treturn format_html(\"Hello {0}!\", context['name'])\n\n", "description": "A tag that uses format_html", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "current_app", "data": "def current_app(context):\n\treturn \"%s\" % context.current_app\n\n", "description": null, "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "use_l10n", "data": "def use_l10n(context):\n\treturn \"%s\" % context.use_l10n\n\n", "description": null, "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "minustwo_overridden_name", "data": "def minustwo_overridden_name(value):\n\treturn value - 2\n", "description": null, "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "fassignment_no_params", "data": "\tdef assignment_no_params():\n\t\t\"\"\"Expected assignment_no_params __doc__\"\"\"\n", "description": "Expected assignment_no_params __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}, {"term": "def", "name": "fassignment_tag_without_context_parameter", "data": "\tdef assignment_tag_without_context_parameter(arg):\n\t\t\"\"\"Expected assignment_tag_without_context_parameter __doc__\"\"\"\n", "description": "Expected assignment_tag_without_context_parameter __doc__", "category": "simple", "imports": ["import operator", "import warnings", "from django import template", "from django.template.defaultfilters import stringfilter", "from django.utils import six", "from django.utils.html import escape, format_html"]}], [], [{"term": "class", "name": "classTestModelsGeneral:", "data": "class TestModelsGeneral:\n\tdef test_simple(self):\n\t\tresult = SimpleSPJResult(True, '123', '12345')\n\t\tassert load_result(result) == result\n\t\tassert load_result(result.to_json()) == result\n\t\tassert load_result((True,)) == SimpleSPJResult(True, )\n\t\tassert load_result(True) == SimpleSPJResult(True, )\n\t\tassert load_result(None) == SimpleSPJResult(False, )\n\t\tassert load_result((True, '123')) == SimpleSPJResult(True, '123')\n\t\tassert load_result((True, '123', '12345')) == result\n\n\tdef test_continuity(self):\n\t\tresult = ContinuitySPJResult(True, 0.5, '123', '12345')\n\t\tassert load_result(result) == result\n\t\tassert load_result(result.to_json()) == result\n\t\tassert load_result(((True, 0.5),)) == ContinuitySPJResult(True, 0.5)\n\t\tassert load_result(((True, 0.5), '123')) == ContinuitySPJResult(True, 0.5, '123')\n\t\tassert load_result(((True, 0.5), '123', '12345')) == result\n\n\tdef test_simple_force(self):\n\t\tresult = SimpleSPJResult(True, '123', '12345')\n\t\tassert load_result(result, 'simple') == result\n\t\tassert load_result(result.to_json(), 'simple') == result\n\t\tassert load_result((True,), 'simple') == SimpleSPJResult(True, )\n\t\tassert load_result(True, 'simple') == SimpleSPJResult(True, )\n\t\tassert load_result(None, 'simple') == SimpleSPJResult(False, )\n\t\tassert load_result((True, '123'), 'simple') == SimpleSPJResult(True, '123')\n\t\tassert load_result((True, '123', '12345'), 'simple') == result\n\n\t\tresult = ContinuitySPJResult(True, 0.5, '123', '12345')\n\t\tassert load_result(result, 'simple') == SimpleSPJResult(True, '123', '12345')\n\t\tassert load_result(result.to_json(), 'simple') == SimpleSPJResult(True, '123', '12345')\n\t\tassert load_result(((True, 0.5),), 'simple') == SimpleSPJResult(True)\n\t\tassert load_result(((True, 0.5), '123'), 'simple') == SimpleSPJResult(True, '123')\n\t\tassert load_result(((True, 0.5), '123', '12345'), 'simple') == SimpleSPJResult(True, '123', '12345')\n\n\tdef test_continuity_force(self):\n\t\tresult = SimpleSPJResult(True, '123', '12345')\n\t\tassert load_result(result, 'continuity') == ContinuitySPJResult(True, 0.0, '123', '12345')\n\t\tassert load_result(result.to_json(), 'continuity') == ContinuitySPJResult(True, 0.0, '123', '12345')\n\t\tassert load_result((True,), 'continuity') == ContinuitySPJResult(True, 0.0)\n\t\tassert load_result(True, 'continuity') == ContinuitySPJResult(True, 0.0)\n\t\tassert load_result(None, 'continuity') == ContinuitySPJResult(False, 0.0, )\n\t\tassert load_result((True, '123'), 'continuity') == ContinuitySPJResult(True, 0.0, '123')\n\t\tassert load_result((True, '123', '12345'), 'continuity') == ContinuitySPJResult(True, 0.0, '123', '12345')\n\n\t\tresult = ContinuitySPJResult(True, 0.5, '123', '12345')\n\t\tassert load_result(result, 'continuity') == result\n\t\tassert load_result(result.to_json(), 'continuity') == result\n\t\tassert load_result(((True, 0.5),), 'continuity') == ContinuitySPJResult(True, 0.5)\n\t\tassert load_result(((True, 0.5), '123'), 'continuity') == ContinuitySPJResult(True, 0.5, '123')\n\t\tassert load_result(((True, 0.5), '123', '12345'), 'continuity') == result\n\n\tdef test_invalid(self):\n\t\twith pytest.raises(ValueError):\n\t\t\tassert load_result(())\n\t\twith pytest.raises(ValueError):\n\t\t\tassert load_result((1, 2, 3, 4))\n\n\tdef test_result_type(self):\n\t\tassert ResultType.loads(ResultType.FREE) == ResultType.FREE\n\t\tassert ResultType.loads(ResultType.SIMPLE) == ResultType.SIMPLE\n\t\tassert ResultType.loads(ResultType.CONTINUITY) == ResultType.CONTINUITY\n\n\t\tassert ResultType.loads('free') == ResultType.FREE\n\t\tassert ResultType.loads('simple') == ResultType.SIMPLE\n\t\tassert ResultType.loads('continuity') == ResultType.CONTINUITY\n\t\twith pytest.raises(KeyError):\n\t\t\tResultType.loads('sdkfjlsd')\n\n\t\tassert ResultType.loads(0) == ResultType.FREE\n\t\tassert ResultType.loads(1) == ResultType.SIMPLE\n\t\tassert ResultType.loads(2) == ResultType.CONTINUITY\n\t\twith pytest.raises(KeyError):\n\t\t\tResultType.loads(-100)\n\n\t\twith pytest.raises(TypeError):\n\t\t\tResultType.loads([])\n", "description": null, "category": "simple", "imports": ["import pytest", "from pyspj.models import load_result, SimpleSPJResult, ContinuitySPJResult, ResultType"]}], [{"term": "class", "name": "GLUtesselator", "data": "class GLUtesselator( glustruct.GLUStruct, simple.GLUtesselator):\n\t\"\"\"Implementation class for GLUTessellator structures in OpenGL-ctypes\"\"\"\n\tFUNCTION_TYPE = PLATFORM.functionTypeFor(PLATFORM.GLU)\n\tCALLBACK_TYPES = {\n\t\t# mapping from \"which\" GLU enumeration to a ctypes function type\n\t\tsimple.GLU_TESS_BEGIN: FUNCTION_TYPE( None, simple.GLenum ),\n\t\tsimple.GLU_TESS_BEGIN_DATA: FUNCTION_TYPE( \n\t\t\tNone, simple.GLenum, ctypes.c_void_p \n\t\t),\n\t\tsimple.GLU_TESS_EDGE_FLAG: FUNCTION_TYPE( None, simple.GLboolean),\n\t\tsimple.GLU_TESS_EDGE_FLAG_DATA: FUNCTION_TYPE( \n\t\t\tNone, simple.GLboolean, ctypes.c_void_p \n\t\t),\n\t\tsimple.GLU_TESS_VERTEX: FUNCTION_TYPE( None, ctypes.c_void_p ),\n\t\tsimple.GLU_TESS_VERTEX_DATA: FUNCTION_TYPE( \n\t\t\tNone, ctypes.c_void_p, ctypes.c_void_p\n\t\t),\n\t\tsimple.GLU_TESS_END: FUNCTION_TYPE( None ),\n\t\tsimple.GLU_TESS_END_DATA: FUNCTION_TYPE( None, ctypes.c_void_p), \n\t\tsimple.GLU_TESS_COMBINE: FUNCTION_TYPE( \n\t\t\tNone, \n\t\t\tctypes.POINTER(simple.GLdouble), \n\t\t\tctypes.POINTER(ctypes.c_void_p), \n\t\t\tctypes.POINTER(simple.GLfloat),\n\t\t\tctypes.POINTER(ctypes.c_void_p)\n\t\t),\n\t\tsimple.GLU_TESS_COMBINE_DATA: FUNCTION_TYPE( \n\t\t\tNone, \n\t\t\tctypes.POINTER(simple.GLdouble), \n\t\t\tctypes.POINTER(ctypes.c_void_p), \n\t\t\tctypes.POINTER(simple.GLfloat),\n\t\t\tctypes.POINTER(ctypes.c_void_p),\n\t\t\tctypes.c_void_p,\n\t\t),\n\t\tsimple.GLU_TESS_ERROR: FUNCTION_TYPE( None, simple.GLenum), \n\t\tsimple.GLU_TESS_ERROR_DATA: FUNCTION_TYPE( \n\t\t\tNone, simple.GLenum, ctypes.c_void_p\n\t\t), \n\t\tsimple.GLU_ERROR : FUNCTION_TYPE( None, simple.GLenum )\n\t}\n\tWRAPPER_METHODS = {\n\t\tsimple.GLU_TESS_BEGIN_DATA: 'dataWrapper',\n\t\tsimple.GLU_TESS_EDGE_FLAG_DATA: 'dataWrapper',\n\t\tsimple.GLU_TESS_VERTEX: 'vertexWrapper',\n\t\tsimple.GLU_TESS_VERTEX_DATA: 'vertexWrapper',\n\t\tsimple.GLU_TESS_END_DATA: 'dataWrapper', \n\t\tsimple.GLU_TESS_COMBINE: 'combineWrapper',\n\t\tsimple.GLU_TESS_COMBINE_DATA: 'combineWrapper',\n\t\tsimple.GLU_TESS_ERROR_DATA: 'dataWrapper', \n\t}\n\tdef gluTessVertex( self, location, data=None ):\n\t\t\"\"\"Add a vertex to this tessellator, storing data for later lookup\"\"\"\n\t\tvertexCache = getattr( self, 'vertexCache', None )\n\t\tif vertexCache is None:\n\t\t\tself.vertexCache = []\n\t\t\tvertexCache = self.vertexCache\n\t\tlocation = arrays.GLdoubleArray.asArray( location, constants.GL_DOUBLE )\n\t\tif arrays.GLdoubleArray.arraySize( location ) != 3:\n\t\t\traise ValueError( \"\"\"Require 3 doubles for array location, got: %s\"\"\"%(location,))\n\t\toorValue = self.noteObject(data)\n\t\tvp = ctypes.c_void_p( oorValue )\n\t\tself.vertexCache.append( location )\n\t\treturn gluTessVertexBase( self, location, vp )\n\tdef gluTessBeginPolygon( self, data ):\n\t\t\"\"\"Note the object pointer to return it as a Python object\"\"\"\n\t\treturn simple.gluTessBeginPolygon( \n\t\t\tself, ctypes.c_void_p(self.noteObject( data ))\n\t\t)\n\tdef combineWrapper( self, function ):\n\t\t\"\"\"Wrap a Python function with ctypes-compatible wrapper for combine callback\n\t\t\n\t\tFor a Python combine callback, the signature looks like this:\n\t\t\tdef combine(\n\t\t\t\tGLdouble coords[3], \n\t\t\t\tvoid *vertex_data[4], \n\t\t\t\tGLfloat weight[4]\n\t\t\t):\n\t\t\t\treturn data\n\t\tWhile the C signature looks like this:\n\t\t\tvoid combine( \n\t\t\t\tGLdouble coords[3], \n\t\t\t\tvoid *vertex_data[4], \n\t\t\t\tGLfloat weight[4], \n\t\t\t\tvoid **outData \n\t\t\t)\n\t\t\"\"\"\n\t\tif (function is not None) and (not hasattr( function,'__call__' )):\n\t\t\traise TypeError( \"\"\"Require a callable callback, got:  %s\"\"\"%(function,))\n\t\tdef wrap( coords, vertex_data, weight, outData, *args ):\n\t\t\t\"\"\"The run-time wrapper around the function\"\"\"\n\t\t\tcoords = self.ptrAsArray( coords, 3, arrays.GLdoubleArray )\n\t\t\tweight = self.ptrAsArray( weight, 4, arrays.GLfloatArray )\n\t\t\t# find the original python objects for vertex data\n\t\t\tvertex_data = [ self.originalObject( vertex_data[i] ) for i in range(4) ]\n\t\t\targs = tuple( [ self.originalObject( x ) for x in args ] )\n\t\t\ttry:\n\t\t\t\tresult = function( coords, vertex_data, weight, *args )\n\t\t\texcept Exception, err:\n\t\t\t\traise err.__class__(\n\t\t\t\t\t\"\"\"Failure during combine callback %r with args( %s,%s,%s,*%s):\\n%s\"\"\"%(\n\t\t\t\t\t\tfunction, coords, vertex_data, weight, args, str(err),\n\t\t\t\t\t)\n\t\t\t\t)\n\t\t\toutP = ctypes.c_void_p(self.noteObject(result))\n\t\t\toutData[0] = outP\n\t\t\treturn None\n\t\treturn wrap\n\tdef dataWrapper( self, function ):\n\t\t\"\"\"Wrap a function which only has the one data-pointer as last arg\"\"\"\n\t\tif (function is not None) and (not hasattr( function,'__call__' )):\n\t\t\traise TypeError( \"\"\"Require a callable callback, got:  %s\"\"\"%(function,))\n\t\tdef wrap( *args ):\n\t\t\t\"\"\"Just return the original object for polygon_data\"\"\"\n\t\t\targs = args[:-1] + ( self.originalObject(args[-1]), )\n\t\t\ttry:\n\t\t\t\treturn function( *args )\n\t\t\texcept Exception, err:\n\t\t\t\terr.args += (function,args)\n\t\t\t\traise\n\t\treturn wrap\n\tdef dataWrapper2( self, function ):\n\t\t\"\"\"Wrap a function which has two data-pointers as last args\"\"\"\n\t\tif (function is not None) and (not hasattr( function,'__call__' )):\n\t\t\traise TypeError( \"\"\"Require a callable callback, got:  %s\"\"\"%(function,))\n\t\tdef wrap( *args ):\n\t\t\t\"\"\"Just return the original object for polygon_data\"\"\"\n\t\t\targs = args[:-2] + ( self.originalObject(args[-2]), self.originalObject(args[-1]), )\n\t\t\ttry:\n\t\t\t\treturn function( *args )\n\t\t\texcept Exception, err:\n\t\t\t\terr.args += (function,args)\n\t\t\t\traise\n\t\treturn wrap\n\tdef vertexWrapper( self, function ):\n\t\t\"\"\"Converts a vertex-pointer into an OOR vertex for processing\"\"\"\n\t\tif (function is not None) and (not hasattr( function,'__call__' )):\n\t\t\traise TypeError( \"\"\"Require a callable callback, got:  %s\"\"\"%(function,))\n\t\tdef wrap( vertex, data=None ):\n\t\t\t\"\"\"Just return the original object for polygon_data\"\"\"\n\t\t\tvertex = self.originalObject(vertex)\n\t\t\ttry:\n\t\t\t\tif data is not None:\n\t\t\t\t\tdata = self.originalObject(data)\n\t\t\t\t\treturn function( vertex, data )\n\t\t\t\telse:\n\t\t\t\t\treturn function( vertex )\n\t\t\texcept Exception, err:\n\t\t\t\terr.args += (function,(vertex,data))\n\t\t\t\traise\n\t\treturn wrap\n", "description": "Implementation class for GLUTessellator structures in OpenGL-ctypes", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL.platform import GLU,createBaseFunction", "from OpenGL.GLU import glustruct", "from OpenGL import arrays, constants", "from OpenGL.platform import PLATFORM", "from OpenGL.lazywrapper import lazy", "import ctypes"]}, {"term": "def", "name": "gluTessCallback", "data": "def gluTessCallback( tess, which, function ):\n\t\"\"\"Set a given gluTessellator callback for the given tessellator\"\"\"\n", "description": "Set a given gluTessellator callback for the given tessellator", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL.platform import GLU,createBaseFunction", "from OpenGL.GLU import glustruct", "from OpenGL import arrays, constants", "from OpenGL.platform import PLATFORM", "from OpenGL.lazywrapper import lazy", "import ctypes"]}, {"term": "def", "name": "gluTessBeginPolygon", "data": "def gluTessBeginPolygon( tess, data ):\n\t\"\"\"Start definition of polygon in the tessellator\"\"\"\n", "description": "Start definition of polygon in the tessellator", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL.platform import GLU,createBaseFunction", "from OpenGL.GLU import glustruct", "from OpenGL import arrays, constants", "from OpenGL.platform import PLATFORM", "from OpenGL.lazywrapper import lazy", "import ctypes"]}, {"term": "def", "name": "gluTessVertex", "data": "def gluTessVertex( tess, location, data=None ):\n\t\"\"\"Add a vertex to the tessellator's current polygon\"\"\"\n\treturn tess.gluTessVertex( location, data )\n", "description": "Add a vertex to the tessellator's current polygon", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL.platform import GLU,createBaseFunction", "from OpenGL.GLU import glustruct", "from OpenGL import arrays, constants", "from OpenGL.platform import PLATFORM", "from OpenGL.lazywrapper import lazy", "import ctypes"]}, {"term": "def", "name": "gluNewTess", "data": "def gluNewTess( baseFunction ):\n\t\"\"\"Get a new tessellator object (just unpacks the pointer for you)\"\"\"\n\treturn baseFunction()[0]\n", "description": "Get a new tessellator object (just unpacks the pointer for you)", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL.platform import GLU,createBaseFunction", "from OpenGL.GLU import glustruct", "from OpenGL import arrays, constants", "from OpenGL.platform import PLATFORM", "from OpenGL.lazywrapper import lazy", "import ctypes"]}, {"term": "def", "name": "gluGetTessProperty", "data": "def gluGetTessProperty( baseFunction, tess, which, data=None ):\n\t\"\"\"Retrieve single double for a tessellator property\"\"\"\n\tif data is None:\n\t\tdata = simple.GLdouble( 0.0 )\n\t\tbaseFunction( tess, which, data )\n\t\treturn data.value \n\telse:\n\t\treturn baseFunction( tess, which, data )\n", "description": "Retrieve single double for a tessellator property", "category": "simple", "imports": ["from OpenGL.raw import GLU as simple", "from OpenGL.platform import GLU,createBaseFunction", "from OpenGL.GLU import glustruct", "from OpenGL import arrays, constants", "from OpenGL.platform import PLATFORM", "from OpenGL.lazywrapper import lazy", "import ctypes"]}], [{"term": "def", "name": "simple_dataset", "data": "def simple_dataset(make_indicator_set, make_equipment_set):\n\tindicator_set = make_indicator_set(propertyId=('indicator_id_1', 'indicator_id_2'))\n\tequipment_set = make_equipment_set(\n\t\tequipmentId=('equipment_id_1', 'equipment_id_2'),\n\t\tmodelId=('equipment_model_id_1', 'equipment_model_id_1')\n\t)\n\n\treturn make_dataset(indicator_set, equipment_set)\n\n", "description": null, "category": "simple", "imports": ["import math", "import pytest", "import pandas as pd", "from sailor.assetcentral.indicators import IndicatorSet", "from sailor.assetcentral.equipment import EquipmentSet", "from sailor.sap_iot.wrappers import TimeseriesDataset", "from ..data_generators import make_dataset"]}, {"term": "def", "name": "test_aggregation_happy_path", "data": "def test_aggregation_happy_path(simple_dataset, aggregation_functions, expected_indicator_count, description):\n\tinterval = pd.Timedelta('20min')\n\n\taggregate_dataset = simple_dataset.aggregate(interval, aggregation_functions=aggregation_functions)\n\n\tassert len(aggregate_dataset.indicator_set) == expected_indicator_count\n\tassert aggregate_dataset._df.timestamp.min() <= simple_dataset._df.timestamp.min()\n\tassert aggregate_dataset._df.timestamp.min() > simple_dataset._df.timestamp.min() - interval\n\tassert aggregate_dataset._df.timestamp.max() <= simple_dataset._df.timestamp.max()\n\tassert aggregate_dataset._df.timestamp.max() > simple_dataset._df.timestamp.max() - interval\n\n", "description": null, "category": "simple", "imports": ["import math", "import pytest", "import pandas as pd", "from sailor.assetcentral.indicators import IndicatorSet", "from sailor.assetcentral.equipment import EquipmentSet", "from sailor.sap_iot.wrappers import TimeseriesDataset", "from ..data_generators import make_dataset"]}, {"term": "def", "name": "test_interpolation_happy_path", "data": "def test_interpolation_happy_path(simple_dataset):\n\tinterval = pd.Timedelta('20min')\n\texpected_count = math.ceil((simple_dataset.nominal_data_end - simple_dataset.nominal_data_start) / interval)\n\n\tinterpolated_dataset = simple_dataset.interpolate(interval)\n\n\tassert all(interpolated_dataset._df.groupby('equipment_id').timestamp.count() == expected_count)\n\tassert interpolated_dataset.indicator_set == simple_dataset.indicator_set\n\tassert interpolated_dataset._df.timestamp.min() == simple_dataset.nominal_data_start\n\tassert interpolated_dataset._df.timestamp.max() < simple_dataset.nominal_data_end\n\n", "description": null, "category": "simple", "imports": ["import math", "import pytest", "import pandas as pd", "from sailor.assetcentral.indicators import IndicatorSet", "from sailor.assetcentral.equipment import EquipmentSet", "from sailor.sap_iot.wrappers import TimeseriesDataset", "from ..data_generators import make_dataset"]}, {"term": "def", "name": "test_interpolate_missing_data", "data": "def test_interpolate_missing_data(simple_dataset, method, expect_ffill, expect_bfill):\n\ttest_dataset = simple_dataset.filter(equipment_set=simple_dataset.equipment_set.filter(id='equipment_id_1'))\n\tactual_start = test_dataset._df.timestamp.min()\n\tactual_end = test_dataset._df.timestamp.max()\n\n\ttest_dataset.nominal_data_start = (actual_start - pd.Timedelta('1h')).round('1h')\n\ttest_dataset.nominal_data_end = actual_end + pd.Timedelta('1h')\n\tremove_times = ((test_dataset._df.timestamp >= actual_start + pd.Timedelta('1h')) &\n\t\t\t\t\t(test_dataset._df.timestamp < actual_start + pd.Timedelta('3h')))\n\tfor indicator in test_dataset.indicator_set:\n\t\ttest_dataset._df.loc[remove_times, indicator._unique_id] = float('NaN')\n\n\t# this is not an regular test assert, but makes sure that during setup we actually introduced a 'hole' in the data\n\tassert test_dataset._df.loc[remove_times].isnull().all().any()\n\n\tinterpolated_dataset = test_dataset.interpolate('1h', method=method)\n\n\tassert interpolated_dataset._df.timestamp.min() == test_dataset.nominal_data_start\n\tassert interpolated_dataset._df.timestamp.max() < test_dataset.nominal_data_end\n\tremove_times = ((interpolated_dataset._df.timestamp >= actual_start + pd.Timedelta('1h')) &\n\t\t\t\t\t(interpolated_dataset._df.timestamp < actual_start + pd.Timedelta('3h')))\n\tassert not interpolated_dataset._df.loc[remove_times].isnull().any().any()\n\n\tif expect_bfill:\n\t\tassert not interpolated_dataset._df[interpolated_dataset._df.timestamp < actual_start].isnull().any().any()\n\tif expect_ffill:\n\t\tassert not interpolated_dataset._df[interpolated_dataset._df.timestamp > actual_end].isnull().any().any()\n\n", "description": null, "category": "simple", "imports": ["import math", "import pytest", "import pandas as pd", "from sailor.assetcentral.indicators import IndicatorSet", "from sailor.assetcentral.equipment import EquipmentSet", "from sailor.sap_iot.wrappers import TimeseriesDataset", "from ..data_generators import make_dataset"]}, {"term": "def", "name": "test_filter_equipment_set", "data": "def test_filter_equipment_set(simple_dataset):\n\tfiltered_dataset = simple_dataset.filter(equipment_set=simple_dataset.equipment_set.filter(id='equipment_id_1'))\n\n\tassert len(filtered_dataset.equipment_set) == 1\n\tassert len(filtered_dataset._df) == 100\n\tassert filtered_dataset._df.equipment_id.unique() == ['equipment_id_1']\n\tassert filtered_dataset.indicator_set == simple_dataset.indicator_set\n\n", "description": null, "category": "simple", "imports": ["import math", "import pytest", "import pandas as pd", "from sailor.assetcentral.indicators import IndicatorSet", "from sailor.assetcentral.equipment import EquipmentSet", "from sailor.sap_iot.wrappers import TimeseriesDataset", "from ..data_generators import make_dataset"]}, {"term": "def", "name": "test_filter_indicator_set", "data": "def test_filter_indicator_set(simple_dataset):\n\tselected_indicators = simple_dataset.indicator_set.filter(id='indicator_id_1')\n\n\tfiltered_dataset = simple_dataset.filter(indicator_set=selected_indicators)\n\n\tassert len(filtered_dataset.equipment_set) == 2\n\tassert len(filtered_dataset._df) == len(simple_dataset._df)\n\tassert filtered_dataset.indicator_set == selected_indicators\n\tassert len(filtered_dataset._df.columns) == 3\n\tassert all(filtered_dataset._df.columns == (filtered_dataset.get_index_columns(include_model=False) +\n\t\t\t\t\t\t\t\t\t\t\t\t[indicator._unique_id for indicator in selected_indicators]))\n\n", "description": null, "category": "simple", "imports": ["import math", "import pytest", "import pandas as pd", "from sailor.assetcentral.indicators import IndicatorSet", "from sailor.assetcentral.equipment import EquipmentSet", "from sailor.sap_iot.wrappers import TimeseriesDataset", "from ..data_generators import make_dataset"]}, {"term": "def", "name": "test_as_df_no_indicators", "data": "def test_as_df_no_indicators(include_model):\n\tdf = pd.DataFrame({'equipment_id': [], 'timestamp': pd.to_datetime([], utc=True)})\n\tdf = df.astype({'equipment_id': 'object'})\n\tdata = TimeseriesDataset(df, IndicatorSet([]), EquipmentSet([]),\n\t\t\t\t\t\t\t pd.Timestamp('2021-01-01', tz='Etc/UTC'), pd.Timestamp('2021-01-03', tz='Etc/UTC'))\n\n\tdata.as_df(speaking_names=True, include_model=include_model)\n\t# this used to lead to a TypeError, we're effectively testing that doesn't happen.\n\n", "description": null, "category": "simple", "imports": ["import math", "import pytest", "import pandas as pd", "from sailor.assetcentral.indicators import IndicatorSet", "from sailor.assetcentral.equipment import EquipmentSet", "from sailor.sap_iot.wrappers import TimeseriesDataset", "from ..data_generators import make_dataset"]}, {"term": "def", "name": "test_plotting_happy_path", "data": "def test_plotting_happy_path(simple_dataset):\n\tsimple_dataset.plot()\n\n", "description": null, "category": "simple", "imports": ["import math", "import pytest", "import pandas as pd", "from sailor.assetcentral.indicators import IndicatorSet", "from sailor.assetcentral.equipment import EquipmentSet", "from sailor.sap_iot.wrappers import TimeseriesDataset", "from ..data_generators import make_dataset"]}, {"term": "def", "name": "test_normalize_happy_path", "data": "def test_normalize_happy_path(simple_dataset):\n\tnormalized_dataset, _ = simple_dataset.normalize()\n\n\tassert all(normalized_dataset._df.columns == simple_dataset._df.columns)\n\tassert len(normalized_dataset._df) == len(simple_dataset._df)\n", "description": null, "category": "simple", "imports": ["import math", "import pytest", "import pandas as pd", "from sailor.assetcentral.indicators import IndicatorSet", "from sailor.assetcentral.equipment import EquipmentSet", "from sailor.sap_iot.wrappers import TimeseriesDataset", "from ..data_generators import make_dataset"]}], [{"term": "def", "name": "simple", "data": "def simple(e):\n\terr = json.loads(e.error_message)\n\tcode = err['Error']['Code']\n\n\ttry:\n\t\t# Dynamically get the error class.\n\t\tsimple_e = getattr(sys.modules[__name__], code)(e, err)\n\texcept AttributeError:\n\t\t# Return original exception on failure.\n\t\treturn e\n\n\treturn simple_e\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "SimpleException", "data": "class SimpleException(BotoServerError):\n\tdef __init__(self, e, err):\n\t\tsuper(SimpleException, self).__init__(e.status, e.reason, e.body)\n\t\tself.body = e.error_message\n\t\tself.request_id = err['RequestId']\n\t\tself.error_code = err['Error']['Code']\n\t\tself.error_message = err['Error']['Message']\n\n\tdef __repr__(self):\n\t\treturn self.__class__.__name__ + ': ' + self.error_message\n\tdef __str__(self):\n\t\treturn self.__class__.__name__ + ': ' + self.error_message\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "ValidationError", "data": "class ValidationError(SimpleException): pass\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "Throttling", "data": "class Throttling(SimpleException): pass\n\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}, {"term": "class", "name": "SourceBundleDeletion", "data": "class SourceBundleDeletion(SimpleException): pass\n", "description": null, "category": "simple", "imports": ["import sys", "from boto.compat import json", "from boto.exception import BotoServerError"]}], [{"term": "class", "name": "TestLibraryInfo", "data": "class TestLibraryInfo(TestCase):\n\tdef test_simple(self):\n\t\tfd, filename = mkstemp('foo.ini')\n\t\ttry:\n\t\t\tpkg = os.path.splitext(filename)[0]\n\t\t\ttry:\n\t\t\t\tos.write(fd, simple.encode('ascii'))\n\t\t\tfinally:\n\t\t\t\tos.close(fd)\n\n\t\t\tout = read_config(pkg)\n\t\t\tself.assertTrue(out.cflags() == simple_d['cflags'])\n\t\t\tself.assertTrue(out.libs() == simple_d['libflags'])\n\t\t\tself.assertTrue(out.name == simple_d['name'])\n\t\t\tself.assertTrue(out.version == simple_d['version'])\n\t\tfinally:\n\t\t\tos.remove(filename)\n\n\tdef test_simple_variable(self):\n\t\tfd, filename = mkstemp('foo.ini')\n\t\ttry:\n\t\t\tpkg = os.path.splitext(filename)[0]\n\t\t\ttry:\n\t\t\t\tos.write(fd, simple_variable.encode('ascii'))\n\t\t\tfinally:\n\t\t\t\tos.close(fd)\n\n\t\t\tout = read_config(pkg)\n\t\t\tself.assertTrue(out.cflags() == simple_variable_d['cflags'])\n\t\t\tself.assertTrue(out.libs() == simple_variable_d['libflags'])\n\t\t\tself.assertTrue(out.name == simple_variable_d['name'])\n\t\t\tself.assertTrue(out.version == simple_variable_d['version'])\n\n\t\t\tout.vars['prefix'] = '/Users/david'\n\t\t\tself.assertTrue(out.cflags() == '-I/Users/david/include')\n\t\tfinally:\n\t\t\tos.remove(filename)\n", "description": null, "category": "simple", "imports": ["import os", "from tempfile import mkstemp", "from numpy.testing import *", "from numpy.distutils.npy_pkg_config import read_config, parse_flags"]}, {"term": "class", "name": "TestParseFlags", "data": "class TestParseFlags(TestCase):\n\tdef test_simple_cflags(self):\n\t\td = parse_flags(\"-I/usr/include\")\n\t\tself.assertTrue(d['include_dirs'] == ['/usr/include'])\n\n\t\td = parse_flags(\"-I/usr/include -DFOO\")\n\t\tself.assertTrue(d['include_dirs'] == ['/usr/include'])\n\t\tself.assertTrue(d['macros'] == ['FOO'])\n\n\t\td = parse_flags(\"-I /usr/include -DFOO\")\n\t\tself.assertTrue(d['include_dirs'] == ['/usr/include'])\n\t\tself.assertTrue(d['macros'] == ['FOO'])\n\n\tdef test_simple_lflags(self):\n\t\td = parse_flags(\"-L/usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tself.assertTrue(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tself.assertTrue(d['libraries'] == ['foo', 'bar'])\n\n\t\td = parse_flags(\"-L /usr/lib -lfoo -L/usr/lib -lbar\")\n\t\tself.assertTrue(d['library_dirs'] == ['/usr/lib', '/usr/lib'])\n\t\tself.assertTrue(d['libraries'] == ['foo', 'bar'])\n", "description": null, "category": "simple", "imports": ["import os", "from tempfile import mkstemp", "from numpy.testing import *", "from numpy.distutils.npy_pkg_config import read_config, parse_flags"]}], [{"term": "def", "name": "test_txn_sender", "data": "def test_txn_sender():\n\texpr = Txn.sender()\n\tassert expr.type_of() == TealType.bytes\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"Sender\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_fee", "data": "def test_txn_fee():\n\texpr = Txn.fee()\n\tassert expr.type_of() == TealType.uint64\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"Fee\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_first_valid", "data": "def test_txn_first_valid():\n\texpr = Txn.first_valid()\n\tassert expr.type_of() == TealType.uint64\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"FirstValid\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_last_valid", "data": "def test_txn_last_valid():\n\texpr = Txn.last_valid()\n\tassert expr.type_of() == TealType.uint64\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"LastValid\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_note", "data": "def test_txn_note():\n\texpr = Txn.note()\n\tassert expr.type_of() == TealType.bytes\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"Note\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_lease", "data": "def test_txn_lease():\n\texpr = Txn.lease()\n\tassert expr.type_of() == TealType.bytes\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"Lease\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_receiver", "data": "def test_txn_receiver():\n\texpr = Txn.receiver()\n\tassert expr.type_of() == TealType.bytes\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"Receiver\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_amount", "data": "def test_txn_amount():\n\texpr = Txn.amount()\n\tassert expr.type_of() == TealType.uint64\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"Amount\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_close_remainder_to", "data": "def test_txn_close_remainder_to():\n\texpr = Txn.close_remainder_to()\n\tassert expr.type_of() == TealType.bytes\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"CloseRemainderTo\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_vote_pk", "data": "def test_txn_vote_pk():\n\texpr = Txn.vote_pk()\n\tassert expr.type_of() == TealType.bytes\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"VotePK\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_selection_pk", "data": "def test_txn_selection_pk():\n\texpr = Txn.selection_pk()\n\tassert expr.type_of() == TealType.bytes\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"SelectionPK\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_vote_first", "data": "def test_txn_vote_first():\n\texpr = Txn.vote_first()\n\tassert expr.type_of() == TealType.uint64\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"VoteFirst\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_vote_last", "data": "def test_txn_vote_last():\n\texpr = Txn.vote_last()\n\tassert expr.type_of() == TealType.uint64\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"VoteLast\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_vote_key_dilution", "data": "def test_txn_vote_key_dilution():\n\texpr = Txn.vote_key_dilution()\n\tassert expr.type_of() == TealType.uint64\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"VoteKeyDilution\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_type", "data": "def test_txn_type():\n\texpr = Txn.type()\n\tassert expr.type_of() == TealType.bytes\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"Type\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_type_enum", "data": "def test_txn_type_enum():\n\texpr = Txn.type_enum()\n\tassert expr.type_of() == TealType.uint64\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"TypeEnum\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_xfer_asset", "data": "def test_txn_xfer_asset():\n\texpr = Txn.xfer_asset()\n\tassert expr.type_of() == TealType.uint64\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"XferAsset\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_asset_amount", "data": "def test_txn_asset_amount():\n\texpr = Txn.asset_amount()\n\tassert expr.type_of() == TealType.uint64\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"AssetAmount\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_asset_sender", "data": "def test_txn_asset_sender():\n\texpr = Txn.asset_sender()\n\tassert expr.type_of() == TealType.bytes\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"AssetSender\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_asset_receiver", "data": "def test_txn_asset_receiver():\n\texpr = Txn.asset_receiver()\n\tassert expr.type_of() == TealType.bytes\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"AssetReceiver\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_asset_close_to", "data": "def test_txn_asset_close_to():\n\texpr = Txn.asset_close_to()\n\tassert expr.type_of() == TealType.bytes\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"AssetCloseTo\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_group_index", "data": "def test_txn_group_index():\n\texpr = Txn.group_index()\n\tassert expr.type_of() == TealType.uint64\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"GroupIndex\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_id", "data": "def test_txn_id():\n\texpr = Txn.tx_id()\n\tassert expr.type_of() == TealType.bytes\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"TxID\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_application_id", "data": "def test_txn_application_id():\n\texpr = Txn.application_id()\n\tassert expr.type_of() == TealType.uint64\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"ApplicationID\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_on_completion", "data": "def test_txn_on_completion():\n\texpr = Txn.on_completion()\n\tassert expr.type_of() == TealType.uint64\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"OnCompletion\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_application_args", "data": "def test_txn_application_args():\n\tfor i in range(4):\n\t\texpr = Txn.application_args[i]\n\t\tassert expr.type_of() == TealType.bytes\n\t\t\n\t\texpected = TealSimpleBlock([\n\t\t\tTealOp(Op.txna, \"ApplicationArgs\", i)\n\t\t])\n\n\t\tactual, _ = expr.__teal__()\n\n\t\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_application_args_length", "data": "def test_txn_application_args_length():\n\texpr = Txn.application_args.length()\n\tassert expr.type_of() == TealType.uint64\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"NumAppArgs\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_accounts", "data": "def test_txn_accounts():\n\tfor i in range(4):\n\t\texpr = Txn.accounts[i]\n\t\tassert expr.type_of() == TealType.bytes\n\t\t\n\t\texpected = TealSimpleBlock([\n\t\t\tTealOp(Op.txna, \"Accounts\", i)\n\t\t])\n\n\t\tactual, _ = expr.__teal__()\n\n\t\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_accounts_length", "data": "def test_txn_accounts_length():\n\texpr = Txn.accounts.length()\n\tassert expr.type_of() == TealType.uint64\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"NumAccounts\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_approval_program", "data": "def test_txn_approval_program():\n\texpr = Txn.approval_program()\n\tassert expr.type_of() == TealType.bytes\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"ApprovalProgram\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_clear_state_program", "data": "def test_txn_clear_state_program():\n\texpr = Txn.clear_state_program()\n\tassert expr.type_of() == TealType.bytes\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"ClearStateProgram\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_rekey_to", "data": "def test_txn_rekey_to():\n\texpr = Txn.rekey_to()\n\tassert expr.type_of() == TealType.bytes\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"RekeyTo\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_config_asset", "data": "def test_txn_config_asset():\n\texpr = Txn.config_asset()\n\tassert expr.type_of() == TealType.uint64\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"ConfigAsset\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_config_asset_total", "data": "def test_txn_config_asset_total():\n\texpr = Txn.config_asset_total()\n\tassert expr.type_of() == TealType.uint64\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"ConfigAssetTotal\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_config_asset_decimals", "data": "def test_txn_config_asset_decimals():\n\texpr = Txn.config_asset_decimals()\n\tassert expr.type_of() == TealType.uint64\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"ConfigAssetDecimals\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_config_asset_default_frozen", "data": "def test_txn_config_asset_default_frozen():\n\texpr = Txn.config_asset_default_frozen()\n\tassert expr.type_of() == TealType.uint64\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"ConfigAssetDefaultFrozen\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_config_asset_unit_name", "data": "def test_txn_config_asset_unit_name():\n\texpr = Txn.config_asset_unit_name()\n\tassert expr.type_of() == TealType.bytes\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"ConfigAssetUnitName\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_config_asset_name", "data": "def test_txn_config_asset_name():\n\texpr = Txn.config_asset_name()\n\tassert expr.type_of() == TealType.bytes\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"ConfigAssetName\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_config_asset_url", "data": "def test_txn_config_asset_url():\n\texpr = Txn.config_asset_url()\n\tassert expr.type_of() == TealType.bytes\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"ConfigAssetURL\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_config_asset_metadata_hash", "data": "def test_txn_config_asset_metadata_hash():\n\texpr = Txn.config_asset_metadata_hash()\n\tassert expr.type_of() == TealType.bytes\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"ConfigAssetMetadataHash\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_config_asset_manager", "data": "def test_txn_config_asset_manager():\n\texpr = Txn.config_asset_manager()\n\tassert expr.type_of() == TealType.bytes\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"ConfigAssetManager\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_config_asset_reserve", "data": "def test_txn_config_asset_reserve():\n\texpr = Txn.config_asset_reserve()\n\tassert expr.type_of() == TealType.bytes\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"ConfigAssetReserve\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_config_asset_freeze", "data": "def test_txn_config_asset_freeze():\n\texpr = Txn.config_asset_freeze()\n\tassert expr.type_of() == TealType.bytes\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"ConfigAssetFreeze\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_config_asset_clawback", "data": "def test_txn_config_asset_clawback():\n\texpr = Txn.config_asset_clawback()\n\tassert expr.type_of() == TealType.bytes\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"ConfigAssetClawback\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_freeze_asset", "data": "def test_txn_freeze_asset():\n\texpr = Txn.freeze_asset()\n\tassert expr.type_of() == TealType.uint64\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"FreezeAsset\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_freeze_asset_account", "data": "def test_txn_freeze_asset_account():\n\texpr = Txn.freeze_asset_account()\n\tassert expr.type_of() == TealType.bytes\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"FreezeAssetAccount\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}, {"term": "def", "name": "test_txn_freeze_asset_frozen", "data": "def test_txn_freeze_asset_frozen():\n\texpr = Txn.freeze_asset_frozen()\n\tassert expr.type_of() == TealType.uint64\n\t\n\texpected = TealSimpleBlock([\n\t\tTealOp(Op.txn, \"FreezeAssetFrozen\")\n\t])\n\n\tactual, _ = expr.__teal__()\n\n\tassert actual == expected\n", "description": null, "category": "simple", "imports": ["import pytest", "from .. import *"]}], [{"term": "class", "name": "SimpleSitemap", "data": "class SimpleSitemap(Sitemap):\n\tchangefreq = \"never\"\n\tpriority = 0.5\n\tlocation = '/location/'\n\tlastmod = datetime.now()\n\n\tdef items(self):\n\t\treturn [object()]\n\n", "description": null, "category": "simple", "imports": ["from collections import OrderedDict", "from datetime import date, datetime", "from django.conf.urls import url", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "SimplePagedSitemap", "data": "class SimplePagedSitemap(Sitemap):\n\tdef items(self):\n\t\treturn [object() for x in range(Sitemap.limit + 1)]\n\n", "description": null, "category": "simple", "imports": ["from collections import OrderedDict", "from datetime import date, datetime", "from django.conf.urls import url", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "SimpleI18nSitemap", "data": "class SimpleI18nSitemap(Sitemap):\n\tchangefreq = \"never\"\n\tpriority = 0.5\n\ti18n = True\n\n\tdef items(self):\n\t\treturn I18nTestModel.objects.order_by('pk').all()\n\n", "description": null, "category": "simple", "imports": ["from collections import OrderedDict", "from datetime import date, datetime", "from django.conf.urls import url", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "EmptySitemap", "data": "class EmptySitemap(Sitemap):\n\tchangefreq = \"never\"\n\tpriority = 0.5\n\tlocation = '/location/'\n\n", "description": null, "category": "simple", "imports": ["from collections import OrderedDict", "from datetime import date, datetime", "from django.conf.urls import url", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "FixedLastmodSitemap", "data": "class FixedLastmodSitemap(SimpleSitemap):\n\tlastmod = datetime(2013, 3, 13, 10, 0, 0)\n\n", "description": null, "category": "simple", "imports": ["from collections import OrderedDict", "from datetime import date, datetime", "from django.conf.urls import url", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "FixedLastmodMixedSitemap", "data": "class FixedLastmodMixedSitemap(Sitemap):\n\tchangefreq = \"never\"\n\tpriority = 0.5\n\tlocation = '/location/'\n\tloop = 0\n\n\tdef items(self):\n\t\to1 = TestModel()\n\t\to1.lastmod = datetime(2013, 3, 13, 10, 0, 0)\n\t\to2 = TestModel()\n\t\treturn [o1, o2]\n\n", "description": null, "category": "simple", "imports": ["from collections import OrderedDict", "from datetime import date, datetime", "from django.conf.urls import url", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "FixedNewerLastmodSitemap", "data": "class FixedNewerLastmodSitemap(SimpleSitemap):\n\tlastmod = datetime(2013, 4, 20, 5, 0, 0)\n\n", "description": null, "category": "simple", "imports": ["from collections import OrderedDict", "from datetime import date, datetime", "from django.conf.urls import url", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "DateSiteMap", "data": "class DateSiteMap(SimpleSitemap):\n\tlastmod = date(2013, 3, 13)\n\n", "description": null, "category": "simple", "imports": ["from collections import OrderedDict", "from datetime import date, datetime", "from django.conf.urls import url", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "class", "name": "TimezoneSiteMap", "data": "class TimezoneSiteMap(SimpleSitemap):\n\tlastmod = datetime(2013, 3, 13, 10, 0, 0, tzinfo=timezone.get_fixed_timezone(-300))\n\n", "description": null, "category": "simple", "imports": ["from collections import OrderedDict", "from datetime import date, datetime", "from django.conf.urls import url", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}, {"term": "def", "name": "testmodelview", "data": "def testmodelview(request, id):\n\treturn HttpResponse()\n\n", "description": null, "category": "simple", "imports": ["from collections import OrderedDict", "from datetime import date, datetime", "from django.conf.urls import url", "from django.conf.urls.i18n import i18n_patterns", "from django.contrib.sitemaps import GenericSitemap, Sitemap, views", "from django.http import HttpResponse", "from django.utils import timezone", "from django.views.decorators.cache import cache_page", "from ..models import I18nTestModel, TestModel"]}], [{"term": "class", "name": "classDocumentStore:", "data": "class DocumentStore:\n\t\"\"\"\n\tThe I{suds} document store provides a local repository for XML documents.\n\n\t@cvar protocol: The URL protocol for the store.\n\t@type protocol: str\n\t@cvar store: The mapping of URL location to documents.\n\t@type store: dict\n\t\"\"\"\n\n\tdef __init__(self, *args, **kwargs):\n\t\tself.__store = {\n\t\t\t'schemas.xmlsoap.org/soap/encoding/':soap5_encoding_schema}\n\t\tself.update = self.__store.update\n\t\tself.update(*args, **kwargs)\n\n\tdef __len__(self):\n\t\t# Implementation note:\n\t\t#   We can not implement '__len__' as simply self.__store.__len__, as\n\t\t# we do for 'update' because that causes py2to3 conversion to fail.\n\t\t#\t\t\t\t\t\t\t\t\t\t\t(08.05.2013.) (Jurko)\n\t\treturn len(self.__store)\n\n\tdef open(self, url):\n\t\t\"\"\"\n\t\tOpen a document at the specified URL.\n\n\t\tMissing documents referenced using the internal 'suds' protocol are\n\t\treported by raising an exception. For other protocols, None is returned\n\t\tinstead.\n\n\t\t@param url: A document URL.\n\t\t@type url: str\n\t\t@return: Document content or None if not found.\n\t\t@rtype: bytes\n\t\t\"\"\"\n\t\tprotocol, location = self.__split(url)\n\t\tcontent = self.__find(location)\n\t\tif protocol == 'suds' and content is None:\n\t\t\traise Exception('location \"%s\" not in document store' % location)\n\t\treturn content\n\n\tdef __find(self, location):\n\t\t\"\"\"\n\t\tFind the specified location in the store.\n\t\t@param location: The I{location} part of a URL.\n\t\t@type location: str\n\t\t@return: Document content or None if not found.\n\t\t@rtype: bytes\n\t\t\"\"\"\n\t\treturn self.__store.get(location)\n\n\tdef __split(self, url):\n\t\t\"\"\"\n\t\tSplit the URL into I{protocol} and I{location}\n\t\t@param url: A URL.\n\t\t@param url: str\n\t\t@return: (I{url}, I{location})\n\t\t@rtype: tuple\n\t\t\"\"\"\n\t\tparts = url.split('://', 1)\n\t\tif len(parts) == 2:\n\t\t\treturn parts\n\t\treturn None, url\n\n", "description": "\n\tThe I{suds} document store provides a local repository for XML documents.\n\n\t@cvar protocol: The URL protocol for the store.\n\t@type protocol: str\n\t@cvar store: The mapping of URL location to documents.\n\t@type store: dict\n\t", "category": "simple", "imports": ["import suds"]}], [{"term": "class", "name": "classDocumentStore:", "data": "class DocumentStore:\n\t\"\"\"\n\tThe I{suds} document store provides a local repository\n\tfor xml documnts.\n\t@cvar protocol: The URL protocol for the store.\n\t@type protocol: str\n\t@cvar store: The mapping of URL location to documents.\n\t@type store: dict\n\t\"\"\"\n\t\n\tprotocol = 'suds'\n\t\n\tstore = {\n\t\t'schemas.xmlsoap.org/soap/encoding/' : encoding\n\t}\n\t\n\tdef open(self, url):\n\t\t\"\"\"\n\t\tOpen a document at the specified url.\n\t\t@param url: A document URL.\n\t\t@type url: str\n\t\t@return: A file pointer to the document.\n\t\t@rtype: StringIO\n\t\t\"\"\"\n\t\tprotocol, location = self.split(url)\n\t\tif protocol == self.protocol:\n\t\t\treturn self.find(location)\n\t\telse:\n\t\t\treturn None\n\t\t\n\tdef find(self, location):\n\t\t\"\"\"\n\t\tFind the specified location in the store.\n\t\t@param location: The I{location} part of a URL.\n\t\t@type location: str\n\t\t@return: An input stream to the document.\n\t\t@rtype: StringIO\n\t\t\"\"\"\n\t\ttry:\n\t\t\tcontent = self.store[location]\n\t\t\treturn StringIO(content)\n\t\texcept:\n\t\t\treason = 'location \"%s\" not in document store' % location\n\t\t\traise Exception, reason\n\t\t\n\tdef split(self, url):\n\t\t\"\"\"\n\t\tSplit the url into I{protocol} and I{location}\n\t\t@param url: A URL.\n\t\t@param url: str\n\t\t@return: (I{url}, I{location})\n\t\t@rtype: tuple\n\t\t\"\"\"\n\t\tparts = url.split('://', 1)\n\t\tif len(parts) == 2:\n\t\t\treturn parts\n\t\telse:\n", "description": "\n\tThe I{suds} document store provides a local repository\n\tfor xml documnts.\n\t@cvar protocol: The URL protocol for the store.\n\t@type protocol: str\n\t@cvar store: The mapping of URL location to documents.\n\t@type store: dict\n\t", "category": "simple", "imports": ["from StringIO import StringIO", "from logging import getLogger"]}], [{"term": "class", "name": "TestSimple", "data": "class TestSimple(VMBaseClass):\n\t\"\"\" Test that curtin runs block-meta simple mode correctly. \"\"\"\n\tconf_file = \"examples/tests/simple.yaml\"\n\textra_disks = []\n\textra_nics = []\n\textra_collect_scripts = [textwrap.dedent(\"\"\"\n\t\tcd OUTPUT_COLLECT_D\n\t\tcp /etc/netplan/50-cloud-init.yaml netplan.yaml\n\n\t\texit 0\n\t\t\"\"\")]\n\n", "description": " Test that curtin runs block-meta simple mode correctly. ", "category": "simple", "imports": ["from . import VMBaseClass", "from .releases import base_vm_classes as relbase", "from .releases import centos_base_vm_classes as centos_relbase", "import os", "import textwrap"]}, {"term": "class", "name": "Centos70XenialTestSimple", "data": "class Centos70XenialTestSimple(centos_relbase.centos70_xenial, TestSimple):\n\t__test__ = True\n\n", "description": null, "category": "simple", "imports": ["from . import VMBaseClass", "from .releases import base_vm_classes as relbase", "from .releases import centos_base_vm_classes as centos_relbase", "import os", "import textwrap"]}, {"term": "class", "name": "Centos70BionicTestSimple", "data": "class Centos70BionicTestSimple(centos_relbase.centos70_bionic, TestSimple):\n\t__test__ = True\n\n", "description": null, "category": "simple", "imports": ["from . import VMBaseClass", "from .releases import base_vm_classes as relbase", "from .releases import centos_base_vm_classes as centos_relbase", "import os", "import textwrap"]}, {"term": "class", "name": "XenialTestSimple", "data": "class XenialTestSimple(relbase.xenial, TestSimple):\n\t__test__ = True\n\n", "description": null, "category": "simple", "imports": ["from . import VMBaseClass", "from .releases import base_vm_classes as relbase", "from .releases import centos_base_vm_classes as centos_relbase", "import os", "import textwrap"]}, {"term": "class", "name": "BionicTestSimple", "data": "class BionicTestSimple(relbase.bionic, TestSimple):\n\t__test__ = True\n\n\tdef test_output_files_exist(self):\n\t\tself.output_files_exist([\"netplan.yaml\"])\n\n", "description": null, "category": "simple", "imports": ["from . import VMBaseClass", "from .releases import base_vm_classes as relbase", "from .releases import centos_base_vm_classes as centos_relbase", "import os", "import textwrap"]}, {"term": "class", "name": "FocalTestSimple", "data": "class FocalTestSimple(relbase.focal, TestSimple):\n\t__test__ = True\n\n\tdef test_output_files_exist(self):\n\t\tself.output_files_exist([\"netplan.yaml\"])\n\n", "description": null, "category": "simple", "imports": ["from . import VMBaseClass", "from .releases import base_vm_classes as relbase", "from .releases import centos_base_vm_classes as centos_relbase", "import os", "import textwrap"]}, {"term": "class", "name": "HirsuteTestSimple", "data": "class HirsuteTestSimple(relbase.hirsute, TestSimple):\n\t__test__ = True\n\n\tdef test_output_files_exist(self):\n\t\tself.output_files_exist([\"netplan.yaml\"])\n\n", "description": null, "category": "simple", "imports": ["from . import VMBaseClass", "from .releases import base_vm_classes as relbase", "from .releases import centos_base_vm_classes as centos_relbase", "import os", "import textwrap"]}, {"term": "class", "name": "ImpishTestSimple", "data": "class ImpishTestSimple(relbase.impish, TestSimple):\n\t__test__ = True\n\n\tdef test_output_files_exist(self):\n\t\tself.output_files_exist([\"netplan.yaml\"])\n\n", "description": null, "category": "simple", "imports": ["from . import VMBaseClass", "from .releases import base_vm_classes as relbase", "from .releases import centos_base_vm_classes as centos_relbase", "import os", "import textwrap"]}, {"term": "class", "name": "TestSimpleStorage", "data": "class TestSimpleStorage(VMBaseClass):\n\t\"\"\" Test curtin runs clear-holders when mode=simple with storage cfg. \"\"\"\n\tconf_file = \"examples/tests/simple-storage.yaml\"\n\tdirty_disks = True\n\textra_disks = ['5G', '5G']\n\textra_nics = []\n\textra_collect_scripts = [textwrap.dedent(\"\"\"\n\t\tcd OUTPUT_COLLECT_D\n\t\tsfdisk --list > sfdisk_list\n\t\tfor d in /dev/[sv]d[a-z] /dev/xvd?; do\n\t\t\t[ -b \"$d\" ] || continue\n\t\t\techo == $d ==\n\t\t\tsgdisk --print $d\n\t\tdone > sgdisk_list\n\t\tblkid > blkid\n\t\tcat /proc/partitions > proc_partitions\n\t\tcp /etc/network/interfaces interfaces\n\t\tcp /etc/netplan/50-cloud-init.yaml netplan.yaml\n\t\tif [ -f /var/log/cloud-init-output.log ]; then\n\t\t   cp /var/log/cloud-init-output.log .\n\t\tfi\n\t\tcp /var/log/cloud-init.log .\n\t\tfind /etc/network/interfaces.d > find_interfacesd\n\t\texit 0\n\t\t\"\"\")]\n\n\tdef test_output_files_exist(self):\n\t\tself.output_files_exist([\"sfdisk_list\", \"blkid\",\n\t\t\t\t\t\t\t\t \"proc_partitions\"])\n\n", "description": " Test curtin runs clear-holders when mode=simple with storage cfg. ", "category": "simple", "imports": ["from . import VMBaseClass", "from .releases import base_vm_classes as relbase", "from .releases import centos_base_vm_classes as centos_relbase", "import os", "import textwrap"]}, {"term": "class", "name": "XenialGATestSimpleStorage", "data": "class XenialGATestSimpleStorage(relbase.xenial, TestSimpleStorage):\n\t__test__ = True\n\n", "description": null, "category": "simple", "imports": ["from . import VMBaseClass", "from .releases import base_vm_classes as relbase", "from .releases import centos_base_vm_classes as centos_relbase", "import os", "import textwrap"]}, {"term": "class", "name": "BionicTestSimpleStorage", "data": "class BionicTestSimpleStorage(relbase.bionic, TestSimpleStorage):\n\t__test__ = True\n\n\tdef test_output_files_exist(self):\n\t\tself.output_files_exist([\"netplan.yaml\"])\n\n", "description": null, "category": "simple", "imports": ["from . import VMBaseClass", "from .releases import base_vm_classes as relbase", "from .releases import centos_base_vm_classes as centos_relbase", "import os", "import textwrap"]}, {"term": "class", "name": "FocalTestSimpleStorage", "data": "class FocalTestSimpleStorage(relbase.focal, TestSimpleStorage):\n\t__test__ = True\n\n\tdef test_output_files_exist(self):\n\t\tself.output_files_exist([\"netplan.yaml\"])\n\n", "description": null, "category": "simple", "imports": ["from . import VMBaseClass", "from .releases import base_vm_classes as relbase", "from .releases import centos_base_vm_classes as centos_relbase", "import os", "import textwrap"]}, {"term": "class", "name": "HirsuteTestSimpleStorage", "data": "class HirsuteTestSimpleStorage(relbase.hirsute, TestSimpleStorage):\n\t__test__ = True\n\n\tdef test_output_files_exist(self):\n\t\tself.output_files_exist([\"netplan.yaml\"])\n\n", "description": null, "category": "simple", "imports": ["from . import VMBaseClass", "from .releases import base_vm_classes as relbase", "from .releases import centos_base_vm_classes as centos_relbase", "import os", "import textwrap"]}, {"term": "class", "name": "ImpishTestSimpleStorage", "data": "class ImpishTestSimpleStorage(relbase.impish, TestSimpleStorage):\n\t__test__ = True\n\n\tdef test_output_files_exist(self):\n\t\tself.output_files_exist([\"netplan.yaml\"])\n\n", "description": null, "category": "simple", "imports": ["from . import VMBaseClass", "from .releases import base_vm_classes as relbase", "from .releases import centos_base_vm_classes as centos_relbase", "import os", "import textwrap"]}, {"term": "class", "name": "TestGrubNoDefaults", "data": "class TestGrubNoDefaults(VMBaseClass):\n\t\"\"\" Test that curtin does not emit any grub configuration files. \"\"\"\n\tconf_file = \"examples/tests/no-grub-file.yaml\"\n\textra_disks = []\n\textra_nics = []\n\textra_collect_scripts = [textwrap.dedent(\"\"\"\n\t\tcd OUTPUT_COLLECT_D\n\t\tcp /etc/netplan/50-cloud-init.yaml netplan.yaml\n\n\t\texit 0\n\t\t\"\"\")]\n\n\tdef test_no_grub_file_created(self):\n\t\t\"\"\" Curtin did not write a grub configuration file. \"\"\"\n\t\tgrub_d_path = self.collect_path('etc_default_grub_d')\n\t\tgrub_d_files = os.listdir(grub_d_path)\n\t\tself.assertNotIn('50-curtin-settings.cfg', grub_d_files)\n\n", "description": " Test that curtin does not emit any grub configuration files. ", "category": "simple", "imports": ["from . import VMBaseClass", "from .releases import base_vm_classes as relbase", "from .releases import centos_base_vm_classes as centos_relbase", "import os", "import textwrap"]}, {"term": "class", "name": "FocalTestGrubNoDefaults", "data": "class FocalTestGrubNoDefaults(relbase.focal, TestGrubNoDefaults):\n\t__test__ = True\n\n\tdef test_output_files_exist(self):\n\t\tself.output_files_exist([\"netplan.yaml\"])\n\n", "description": null, "category": "simple", "imports": ["from . import VMBaseClass", "from .releases import base_vm_classes as relbase", "from .releases import centos_base_vm_classes as centos_relbase", "import os", "import textwrap"]}, {"term": "class", "name": "HirsuteTestGrubNoDefaults", "data": "class HirsuteTestGrubNoDefaults(relbase.hirsute, TestGrubNoDefaults):\n\t__test__ = True\n\n\tdef test_output_files_exist(self):\n\t\tself.output_files_exist([\"netplan.yaml\"])\n\n", "description": null, "category": "simple", "imports": ["from . import VMBaseClass", "from .releases import base_vm_classes as relbase", "from .releases import centos_base_vm_classes as centos_relbase", "import os", "import textwrap"]}, {"term": "class", "name": "ImpishTestGrubNoDefaults", "data": "class ImpishTestGrubNoDefaults(relbase.impish, TestGrubNoDefaults):\n\t__test__ = True\n\n\tdef test_output_files_exist(self):\n\t\tself.output_files_exist([\"netplan.yaml\"])\n\n", "description": null, "category": "simple", "imports": ["from . import VMBaseClass", "from .releases import base_vm_classes as relbase", "from .releases import centos_base_vm_classes as centos_relbase", "import os", "import textwrap"]}], [{"term": "def", "name": "fwith_tp_del", "data": "\tdef with_tp_del(cls):\n\t\tclass C(object):\n\t\t\tdef __new__(cls, *args, **kwargs):\n\t\t\t\traise TypeError('requires _testcapi.with_tp_del')\n\t\treturn C\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "def", "name": "fwithout_gc", "data": "\tdef without_gc(cls):\n\t\tclass C:\n\t\t\tdef __new__(cls, *args, **kwargs):\n\t\t\t\traise TypeError('requires _testcapi.without_gc')\n\t\treturn C\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "classNonGCSimpleBase:", "data": "class NonGCSimpleBase:\n\t\"\"\"\n\tThe base class for all the objects under test, equipped with various\n\ttesting features.\n\t\"\"\"\n\n\tsurvivors = []\n\tdel_calls = []\n\ttp_del_calls = []\n\terrors = []\n\n\t_cleaning = False\n\n\t__slots__ = ()\n\n\t@classmethod\n\tdef _cleanup(cls):\n\t\tcls.survivors.clear()\n\t\tcls.errors.clear()\n\t\tgc.garbage.clear()\n\t\tgc.collect()\n\t\tcls.del_calls.clear()\n\t\tcls.tp_del_calls.clear()\n\n\t@classmethod\n\t@contextlib.contextmanager\n\tdef test(cls):\n\t\t\"\"\"\n\t\tA context manager to use around all finalization tests.\n\t\t\"\"\"\n\t\twith support.disable_gc():\n\t\t\tcls.del_calls.clear()\n\t\t\tcls.tp_del_calls.clear()\n\t\t\tNonGCSimpleBase._cleaning = False\n\t\t\ttry:\n\t\t\t\tyield\n\t\t\t\tif cls.errors:\n\t\t\t\t\traise cls.errors[0]\n\t\t\tfinally:\n\t\t\t\tNonGCSimpleBase._cleaning = True\n\t\t\t\tcls._cleanup()\n\n\tdef check_sanity(self):\n\t\t\"\"\"\n\t\tCheck the object is sane (non-broken).\n\t\t\"\"\"\n\n\tdef __del__(self):\n\t\t\"\"\"\n\t\tPEP 442 finalizer.  Record that this was called, check the\n\t\tobject is in a sane state, and invoke a side effect.\n\t\t\"\"\"\n\t\ttry:\n\t\t\tif not self._cleaning:\n\t\t\t\tself.del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\t\t\tself.side_effect()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tA side effect called on destruction.\n\t\t\"\"\"\n\n", "description": "\n\tThe base class for all the objects under test, equipped with various\n\ttesting features.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "SimpleBase", "data": "class SimpleBase(NonGCSimpleBase):\n\n\tdef __init__(self):\n\t\tself.id_ = id(self)\n\n\tdef check_sanity(self):\n\t\tassert self.id_ == id(self)\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "NonGC", "data": "class NonGC(NonGCSimpleBase):\n\t__slots__ = ()\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "NonGCResurrector", "data": "class NonGCResurrector(NonGCSimpleBase):\n\t__slots__ = ()\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tResurrect self by storing self in a class-wide list.\n\t\t\"\"\"\n\t\tself.survivors.append(self)\n", "description": "\n\t\tResurrect self by storing self in a class-wide list.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "Simple", "data": "class Simple(SimpleBase):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "SimpleResurrector", "data": "class SimpleResurrector(SimpleBase):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tResurrect self by storing self in a class-wide list.\n\t\t\"\"\"\n\t\tself.survivors.append(self)\n\n", "description": "\n\t\tResurrect self by storing self in a class-wide list.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "classTestBase:", "data": "class TestBase:\n\n\tdef setUp(self):\n\t\tself.old_garbage = gc.garbage[:]\n\t\tgc.garbage[:] = []\n\n\tdef tearDown(self):\n\t\t# None of the tests here should put anything in gc.garbage\n\t\ttry:\n\t\t\tself.assertEqual(gc.garbage, [])\n\t\tfinally:\n\t\t\tdel self.old_garbage\n\t\t\tgc.collect()\n\n\tdef assert_del_calls(self, ids):\n\t\tself.assertEqual(sorted(SimpleBase.del_calls), sorted(ids))\n\n\tdef assert_tp_del_calls(self, ids):\n\t\tself.assertEqual(sorted(SimpleBase.tp_del_calls), sorted(ids))\n\n\tdef assert_survivors(self, ids):\n\t\tself.assertEqual(sorted(id(x) for x in SimpleBase.survivors), sorted(ids))\n\n\tdef assert_garbage(self, ids):\n\t\tself.assertEqual(sorted(id(x) for x in gc.garbage), sorted(ids))\n\n\tdef clear_survivors(self):\n\t\tSimpleBase.survivors.clear()\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "SimpleFinalizationTest", "data": "class SimpleFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization without refcycles.\n\t\"\"\"\n\n\tdef test_simple(self):\n\t\twith SimpleBase.test():\n\t\t\ts = Simple()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_simple_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = SimpleResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\tself.assertIsNot(wr(), None)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\tself.assertIs(wr(), None)\n\n\t@support.cpython_only\n\tdef test_non_gc(self):\n\t\twith SimpleBase.test():\n\t\t\ts = NonGC()\n\t\t\tself.assertFalse(gc.is_tracked(s))\n\t\t\tids = [id(s)]\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\t@support.cpython_only\n\tdef test_non_gc_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = NonGCResurrector()\n\t\t\tself.assertFalse(gc.is_tracked(s))\n\t\t\tids = [id(s)]\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids * 2)\n\t\t\tself.assert_survivors(ids)\n\n", "description": "\n\tTest finalization without refcycles.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "classSelfCycleBase:", "data": "class SelfCycleBase:\n\n\tdef __init__(self):\n\t\tsuper().__init__()\n\t\tself.ref = self\n\n\tdef check_sanity(self):\n\t\tsuper().check_sanity()\n\t\tassert self.ref is self\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "SimpleSelfCycle", "data": "class SimpleSelfCycle(SelfCycleBase, Simple):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "SelfCycleResurrector", "data": "class SelfCycleResurrector(SelfCycleBase, SimpleResurrector):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "SuicidalSelfCycle", "data": "class SuicidalSelfCycle(SelfCycleBase, Simple):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tExplicitly break the reference cycle.\n\t\t\"\"\"\n\t\tself.ref = None\n\n", "description": "\n\t\tExplicitly break the reference cycle.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "SelfCycleFinalizationTest", "data": "class SelfCycleFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of an object having a single cyclic reference to\n\titself.\n\t\"\"\"\n\n\tdef test_simple(self):\n\t\twith SimpleBase.test():\n\t\t\ts = SimpleSelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_simple_resurrect(self):\n\t\t# Test that __del__ can resurrect the object being finalized.\n\t\twith SimpleBase.test():\n\t\t\ts = SelfCycleResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\t# XXX is this desirable?\n\t\t\tself.assertIs(wr(), None)\n\t\t\t# When trying to destroy the object a second time, __del__\n\t\t\t# isn't called anymore (and the object isn't resurrected).\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\n\tdef test_simple_suicide(self):\n\t\t# Test the GC is able to deal with an object that kills its last\n\t\t# reference during __del__.\n\t\twith SimpleBase.test():\n\t\t\ts = SuicidalSelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\n", "description": "\n\tTest finalization of an object having a single cyclic reference to\n\titself.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "classChainedBase:", "data": "class ChainedBase:\n\n\tdef chain(self, left):\n\t\tself.suicided = False\n\t\tself.left = left\n\t\tleft.right = self\n\n\tdef check_sanity(self):\n\t\tsuper().check_sanity()\n\t\tif self.suicided:\n\t\t\tassert self.left is None\n\t\t\tassert self.right is None\n\t\telse:\n\t\t\tleft = self.left\n\t\t\tif left.suicided:\n\t\t\t\tassert left.right is None\n\t\t\telse:\n\t\t\t\tassert left.right is self\n\t\t\tright = self.right\n\t\t\tif right.suicided:\n\t\t\t\tassert right.left is None\n\t\t\telse:\n\t\t\t\tassert right.left is self\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "SimpleChained", "data": "class SimpleChained(ChainedBase, Simple):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "ChainedResurrector", "data": "class ChainedResurrector(ChainedBase, SimpleResurrector):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "SuicidalChained", "data": "class SuicidalChained(ChainedBase, Simple):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tExplicitly break the reference cycle.\n\t\t\"\"\"\n\t\tself.suicided = True\n\t\tself.left = None\n\t\tself.right = None\n\n", "description": "\n\t\tExplicitly break the reference cycle.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "CycleChainFinalizationTest", "data": "class CycleChainFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of a cyclic chain.  These tests are similar in\n\tspirit to the self-cycle tests above, but the collectable object\n\tgraph isn't trivial anymore.\n\t\"\"\"\n\n\tdef build_chain(self, classes):\n\t\tnodes = [cls() for cls in classes]\n\t\tfor i in range(len(nodes)):\n\t\t\tnodes[i].chain(nodes[i-1])\n\t\treturn nodes\n\n\tdef check_non_resurrecting_chain(self, classes):\n\t\tN = len(classes)\n\t\twith SimpleBase.test():\n\t\t\tnodes = self.build_chain(classes)\n\t\t\tids = [id(s) for s in nodes]\n\t\t\twrs = [weakref.ref(s) for s in nodes]\n\t\t\tdel nodes\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertEqual([wr() for wr in wrs], [None] * N)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\n\tdef check_resurrecting_chain(self, classes):\n\t\tN = len(classes)\n\t\twith SimpleBase.test():\n\t\t\tnodes = self.build_chain(classes)\n\t\t\tN = len(nodes)\n\t\t\tids = [id(s) for s in nodes]\n\t\t\tsurvivor_ids = [id(s) for s in nodes if isinstance(s, SimpleResurrector)]\n\t\t\twrs = [weakref.ref(s) for s in nodes]\n\t\t\tdel nodes\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(survivor_ids)\n\t\t\t# XXX desirable?\n\t\t\tself.assertEqual([wr() for wr in wrs], [None] * N)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_homogenous(self):\n\t\tself.check_non_resurrecting_chain([SimpleChained] * 3)\n\n\tdef test_homogenous_resurrect(self):\n\t\tself.check_resurrecting_chain([ChainedResurrector] * 3)\n\n\tdef test_homogenous_suicidal(self):\n\t\tself.check_non_resurrecting_chain([SuicidalChained] * 3)\n\n\tdef test_heterogenous_suicidal_one(self):\n\t\tself.check_non_resurrecting_chain([SuicidalChained, SimpleChained] * 2)\n\n\tdef test_heterogenous_suicidal_two(self):\n\t\tself.check_non_resurrecting_chain(\n\t\t\t[SuicidalChained] * 2 + [SimpleChained] * 2)\n\n\tdef test_heterogenous_resurrect_one(self):\n\t\tself.check_resurrecting_chain([ChainedResurrector, SimpleChained] * 2)\n\n\tdef test_heterogenous_resurrect_two(self):\n\t\tself.check_resurrecting_chain(\n\t\t\t[ChainedResurrector, SimpleChained, SuicidalChained] * 2)\n\n\tdef test_heterogenous_resurrect_three(self):\n\t\tself.check_resurrecting_chain(\n\t\t\t[ChainedResurrector] * 2 + [SimpleChained] * 2 + [SuicidalChained] * 2)\n\n", "description": "\n\tTest finalization of a cyclic chain.  These tests are similar in\n\tspirit to the self-cycle tests above, but the collectable object\n\tgraph isn't trivial anymore.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "LegacyBase", "data": "class LegacyBase(SimpleBase):\n\n\tdef __del__(self):\n\t\ttry:\n\t\t\t# Do not invoke side_effect here, since we are now exercising\n\t\t\t# the tp_del slot.\n\t\t\tif not self._cleaning:\n\t\t\t\tself.del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n\n\tdef __tp_del__(self):\n\t\t\"\"\"\n\t\tLegacy (pre-PEP 442) finalizer, mapped to a tp_del slot.\n\t\t\"\"\"\n\t\ttry:\n\t\t\tif not self._cleaning:\n\t\t\t\tself.tp_del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\t\t\tself.side_effect()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n", "description": "\n\t\tLegacy (pre-PEP 442) finalizer, mapped to a tp_del slot.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "Legacy", "data": "class Legacy(LegacyBase):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "LegacyResurrector", "data": "class LegacyResurrector(LegacyBase):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tResurrect self by storing self in a class-wide list.\n\t\t\"\"\"\n\t\tself.survivors.append(self)\n", "description": "\n\t\tResurrect self by storing self in a class-wide list.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "LegacySelfCycle", "data": "class LegacySelfCycle(SelfCycleBase, LegacyBase):\n\tpass\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "LegacyFinalizationTest", "data": "class LegacyFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of objects with a tp_del.\n\t\"\"\"\n\n\tdef tearDown(self):\n\t\t# These tests need to clean up a bit more, since they create\n\t\t# uncollectable objects.\n\t\tgc.garbage.clear()\n\t\tgc.collect()\n\t\tsuper().tearDown()\n\n\tdef test_legacy(self):\n\t\twith SimpleBase.test():\n\t\t\ts = Legacy()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\n\tdef test_legacy_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = LegacyResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\t# weakrefs are cleared before tp_del is called.\n\t\t\tself.assertIs(wr(), None)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids * 2)\n\t\t\tself.assert_survivors(ids)\n\t\tself.assertIs(wr(), None)\n\n\tdef test_legacy_self_cycle(self):\n\t\t# Self-cycles with legacy finalizers end up in gc.garbage.\n\t\twith SimpleBase.test():\n\t\t\ts = LegacySelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls([])\n\t\t\tself.assert_tp_del_calls([])\n\t\t\tself.assert_survivors([])\n\t\t\tself.assert_garbage(ids)\n\t\t\tself.assertIsNot(wr(), None)\n\t\t\t# Break the cycle to allow collection\n\t\t\tgc.garbage[0].ref = None\n\t\tself.assert_garbage([])\n\t\tself.assertIs(wr(), None)\n\n", "description": "\n\tTest finalization of objects with a tp_del.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}], [{"term": "def", "name": "fwith_tp_del", "data": "\tdef with_tp_del(cls):\n\t\tclass C(object):\n\t\t\tdef __new__(cls, *args, **kwargs):\n\t\t\t\traise TypeError('requires _testcapi.with_tp_del')\n\t\treturn C\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "def", "name": "fwithout_gc", "data": "\tdef without_gc(cls):\n\t\tclass C:\n\t\t\tdef __new__(cls, *args, **kwargs):\n\t\t\t\traise TypeError('requires _testcapi.without_gc')\n\t\treturn C\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "classNonGCSimpleBase:", "data": "class NonGCSimpleBase:\n\t\"\"\"\n\tThe base class for all the objects under test, equipped with various\n\ttesting features.\n\t\"\"\"\n\n\tsurvivors = []\n\tdel_calls = []\n\ttp_del_calls = []\n\terrors = []\n\n\t_cleaning = False\n\n\t__slots__ = ()\n\n\t@classmethod\n\tdef _cleanup(cls):\n\t\tcls.survivors.clear()\n\t\tcls.errors.clear()\n\t\tgc.garbage.clear()\n\t\tgc.collect()\n\t\tcls.del_calls.clear()\n\t\tcls.tp_del_calls.clear()\n\n\t@classmethod\n\t@contextlib.contextmanager\n\tdef test(cls):\n\t\t\"\"\"\n\t\tA context manager to use around all finalization tests.\n\t\t\"\"\"\n\t\twith support.disable_gc():\n\t\t\tcls.del_calls.clear()\n\t\t\tcls.tp_del_calls.clear()\n\t\t\tNonGCSimpleBase._cleaning = False\n\t\t\ttry:\n\t\t\t\tyield\n\t\t\t\tif cls.errors:\n\t\t\t\t\traise cls.errors[0]\n\t\t\tfinally:\n\t\t\t\tNonGCSimpleBase._cleaning = True\n\t\t\t\tcls._cleanup()\n\n\tdef check_sanity(self):\n\t\t\"\"\"\n\t\tCheck the object is sane (non-broken).\n\t\t\"\"\"\n\n\tdef __del__(self):\n\t\t\"\"\"\n\t\tPEP 442 finalizer.  Record that this was called, check the\n\t\tobject is in a sane state, and invoke a side effect.\n\t\t\"\"\"\n\t\ttry:\n\t\t\tif not self._cleaning:\n\t\t\t\tself.del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\t\t\tself.side_effect()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tA side effect called on destruction.\n\t\t\"\"\"\n\n", "description": "\n\tThe base class for all the objects under test, equipped with various\n\ttesting features.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "SimpleBase", "data": "class SimpleBase(NonGCSimpleBase):\n\n\tdef __init__(self):\n\t\tself.id_ = id(self)\n\n\tdef check_sanity(self):\n\t\tassert self.id_ == id(self)\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "NonGC", "data": "class NonGC(NonGCSimpleBase):\n\t__slots__ = ()\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "NonGCResurrector", "data": "class NonGCResurrector(NonGCSimpleBase):\n\t__slots__ = ()\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tResurrect self by storing self in a class-wide list.\n\t\t\"\"\"\n\t\tself.survivors.append(self)\n", "description": "\n\t\tResurrect self by storing self in a class-wide list.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "Simple", "data": "class Simple(SimpleBase):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "SimpleResurrector", "data": "class SimpleResurrector(SimpleBase):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tResurrect self by storing self in a class-wide list.\n\t\t\"\"\"\n\t\tself.survivors.append(self)\n\n", "description": "\n\t\tResurrect self by storing self in a class-wide list.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "classTestBase:", "data": "class TestBase:\n\n\tdef setUp(self):\n\t\tself.old_garbage = gc.garbage[:]\n\t\tgc.garbage[:] = []\n\n\tdef tearDown(self):\n\t\t# None of the tests here should put anything in gc.garbage\n\t\ttry:\n\t\t\tself.assertEqual(gc.garbage, [])\n\t\tfinally:\n\t\t\tdel self.old_garbage\n\t\t\tgc.collect()\n\n\tdef assert_del_calls(self, ids):\n\t\tself.assertEqual(sorted(SimpleBase.del_calls), sorted(ids))\n\n\tdef assert_tp_del_calls(self, ids):\n\t\tself.assertEqual(sorted(SimpleBase.tp_del_calls), sorted(ids))\n\n\tdef assert_survivors(self, ids):\n\t\tself.assertEqual(sorted(id(x) for x in SimpleBase.survivors), sorted(ids))\n\n\tdef assert_garbage(self, ids):\n\t\tself.assertEqual(sorted(id(x) for x in gc.garbage), sorted(ids))\n\n\tdef clear_survivors(self):\n\t\tSimpleBase.survivors.clear()\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "SimpleFinalizationTest", "data": "class SimpleFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization without refcycles.\n\t\"\"\"\n\n\tdef test_simple(self):\n\t\twith SimpleBase.test():\n\t\t\ts = Simple()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_simple_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = SimpleResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\tself.assertIsNot(wr(), None)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\tself.assertIs(wr(), None)\n\n\t@support.cpython_only\n\tdef test_non_gc(self):\n\t\twith SimpleBase.test():\n\t\t\ts = NonGC()\n\t\t\tself.assertFalse(gc.is_tracked(s))\n\t\t\tids = [id(s)]\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\t@support.cpython_only\n\tdef test_non_gc_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = NonGCResurrector()\n\t\t\tself.assertFalse(gc.is_tracked(s))\n\t\t\tids = [id(s)]\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids * 2)\n\t\t\tself.assert_survivors(ids)\n\n", "description": "\n\tTest finalization without refcycles.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "classSelfCycleBase:", "data": "class SelfCycleBase:\n\n\tdef __init__(self):\n\t\tsuper().__init__()\n\t\tself.ref = self\n\n\tdef check_sanity(self):\n\t\tsuper().check_sanity()\n\t\tassert self.ref is self\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "SimpleSelfCycle", "data": "class SimpleSelfCycle(SelfCycleBase, Simple):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "SelfCycleResurrector", "data": "class SelfCycleResurrector(SelfCycleBase, SimpleResurrector):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "SuicidalSelfCycle", "data": "class SuicidalSelfCycle(SelfCycleBase, Simple):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tExplicitly break the reference cycle.\n\t\t\"\"\"\n\t\tself.ref = None\n\n", "description": "\n\t\tExplicitly break the reference cycle.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "SelfCycleFinalizationTest", "data": "class SelfCycleFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of an object having a single cyclic reference to\n\titself.\n\t\"\"\"\n\n\tdef test_simple(self):\n\t\twith SimpleBase.test():\n\t\t\ts = SimpleSelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_simple_resurrect(self):\n\t\t# Test that __del__ can resurrect the object being finalized.\n\t\twith SimpleBase.test():\n\t\t\ts = SelfCycleResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\t# XXX is this desirable?\n\t\t\tself.assertIs(wr(), None)\n\t\t\t# When trying to destroy the object a second time, __del__\n\t\t\t# isn't called anymore (and the object isn't resurrected).\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\n\tdef test_simple_suicide(self):\n\t\t# Test the GC is able to deal with an object that kills its last\n\t\t# reference during __del__.\n\t\twith SimpleBase.test():\n\t\t\ts = SuicidalSelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\n", "description": "\n\tTest finalization of an object having a single cyclic reference to\n\titself.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "classChainedBase:", "data": "class ChainedBase:\n\n\tdef chain(self, left):\n\t\tself.suicided = False\n\t\tself.left = left\n\t\tleft.right = self\n\n\tdef check_sanity(self):\n\t\tsuper().check_sanity()\n\t\tif self.suicided:\n\t\t\tassert self.left is None\n\t\t\tassert self.right is None\n\t\telse:\n\t\t\tleft = self.left\n\t\t\tif left.suicided:\n\t\t\t\tassert left.right is None\n\t\t\telse:\n\t\t\t\tassert left.right is self\n\t\t\tright = self.right\n\t\t\tif right.suicided:\n\t\t\t\tassert right.left is None\n\t\t\telse:\n\t\t\t\tassert right.left is self\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "SimpleChained", "data": "class SimpleChained(ChainedBase, Simple):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "ChainedResurrector", "data": "class ChainedResurrector(ChainedBase, SimpleResurrector):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "SuicidalChained", "data": "class SuicidalChained(ChainedBase, Simple):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tExplicitly break the reference cycle.\n\t\t\"\"\"\n\t\tself.suicided = True\n\t\tself.left = None\n\t\tself.right = None\n\n", "description": "\n\t\tExplicitly break the reference cycle.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "CycleChainFinalizationTest", "data": "class CycleChainFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of a cyclic chain.  These tests are similar in\n\tspirit to the self-cycle tests above, but the collectable object\n\tgraph isn't trivial anymore.\n\t\"\"\"\n\n\tdef build_chain(self, classes):\n\t\tnodes = [cls() for cls in classes]\n\t\tfor i in range(len(nodes)):\n\t\t\tnodes[i].chain(nodes[i-1])\n\t\treturn nodes\n\n\tdef check_non_resurrecting_chain(self, classes):\n\t\tN = len(classes)\n\t\twith SimpleBase.test():\n\t\t\tnodes = self.build_chain(classes)\n\t\t\tids = [id(s) for s in nodes]\n\t\t\twrs = [weakref.ref(s) for s in nodes]\n\t\t\tdel nodes\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertEqual([wr() for wr in wrs], [None] * N)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\n\tdef check_resurrecting_chain(self, classes):\n\t\tN = len(classes)\n\t\twith SimpleBase.test():\n\t\t\tnodes = self.build_chain(classes)\n\t\t\tN = len(nodes)\n\t\t\tids = [id(s) for s in nodes]\n\t\t\tsurvivor_ids = [id(s) for s in nodes if isinstance(s, SimpleResurrector)]\n\t\t\twrs = [weakref.ref(s) for s in nodes]\n\t\t\tdel nodes\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors(survivor_ids)\n\t\t\t# XXX desirable?\n\t\t\tself.assertEqual([wr() for wr in wrs], [None] * N)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\n\tdef test_homogenous(self):\n\t\tself.check_non_resurrecting_chain([SimpleChained] * 3)\n\n\tdef test_homogenous_resurrect(self):\n\t\tself.check_resurrecting_chain([ChainedResurrector] * 3)\n\n\tdef test_homogenous_suicidal(self):\n\t\tself.check_non_resurrecting_chain([SuicidalChained] * 3)\n\n\tdef test_heterogenous_suicidal_one(self):\n\t\tself.check_non_resurrecting_chain([SuicidalChained, SimpleChained] * 2)\n\n\tdef test_heterogenous_suicidal_two(self):\n\t\tself.check_non_resurrecting_chain(\n\t\t\t[SuicidalChained] * 2 + [SimpleChained] * 2)\n\n\tdef test_heterogenous_resurrect_one(self):\n\t\tself.check_resurrecting_chain([ChainedResurrector, SimpleChained] * 2)\n\n\tdef test_heterogenous_resurrect_two(self):\n\t\tself.check_resurrecting_chain(\n\t\t\t[ChainedResurrector, SimpleChained, SuicidalChained] * 2)\n\n\tdef test_heterogenous_resurrect_three(self):\n\t\tself.check_resurrecting_chain(\n\t\t\t[ChainedResurrector] * 2 + [SimpleChained] * 2 + [SuicidalChained] * 2)\n\n", "description": "\n\tTest finalization of a cyclic chain.  These tests are similar in\n\tspirit to the self-cycle tests above, but the collectable object\n\tgraph isn't trivial anymore.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "LegacyBase", "data": "class LegacyBase(SimpleBase):\n\n\tdef __del__(self):\n\t\ttry:\n\t\t\t# Do not invoke side_effect here, since we are now exercising\n\t\t\t# the tp_del slot.\n\t\t\tif not self._cleaning:\n\t\t\t\tself.del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n\n\tdef __tp_del__(self):\n\t\t\"\"\"\n\t\tLegacy (pre-PEP 442) finalizer, mapped to a tp_del slot.\n\t\t\"\"\"\n\t\ttry:\n\t\t\tif not self._cleaning:\n\t\t\t\tself.tp_del_calls.append(id(self))\n\t\t\t\tself.check_sanity()\n\t\t\t\tself.side_effect()\n\t\texcept Exception as e:\n\t\t\tself.errors.append(e)\n", "description": "\n\t\tLegacy (pre-PEP 442) finalizer, mapped to a tp_del slot.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "Legacy", "data": "class Legacy(LegacyBase):\n\tpass\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "LegacyResurrector", "data": "class LegacyResurrector(LegacyBase):\n\n\tdef side_effect(self):\n\t\t\"\"\"\n\t\tResurrect self by storing self in a class-wide list.\n\t\t\"\"\"\n\t\tself.survivors.append(self)\n", "description": "\n\t\tResurrect self by storing self in a class-wide list.\n\t\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "LegacySelfCycle", "data": "class LegacySelfCycle(SelfCycleBase, LegacyBase):\n\tpass\n\n", "description": null, "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}, {"term": "class", "name": "LegacyFinalizationTest", "data": "class LegacyFinalizationTest(TestBase, unittest.TestCase):\n\t\"\"\"\n\tTest finalization of objects with a tp_del.\n\t\"\"\"\n\n\tdef tearDown(self):\n\t\t# These tests need to clean up a bit more, since they create\n\t\t# uncollectable objects.\n\t\tgc.garbage.clear()\n\t\tgc.collect()\n\t\tsuper().tearDown()\n\n\tdef test_legacy(self):\n\t\twith SimpleBase.test():\n\t\t\ts = Legacy()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\t\t\tself.assert_survivors([])\n\t\t\tself.assertIs(wr(), None)\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\n\tdef test_legacy_resurrect(self):\n\t\twith SimpleBase.test():\n\t\t\ts = LegacyResurrector()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids)\n\t\t\tself.assert_survivors(ids)\n\t\t\t# weakrefs are cleared before tp_del is called.\n\t\t\tself.assertIs(wr(), None)\n\t\t\tself.clear_survivors()\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls(ids)\n\t\t\tself.assert_tp_del_calls(ids * 2)\n\t\t\tself.assert_survivors(ids)\n\t\tself.assertIs(wr(), None)\n\n\tdef test_legacy_self_cycle(self):\n\t\t# Self-cycles with legacy finalizers end up in gc.garbage.\n\t\twith SimpleBase.test():\n\t\t\ts = LegacySelfCycle()\n\t\t\tids = [id(s)]\n\t\t\twr = weakref.ref(s)\n\t\t\tdel s\n\t\t\tgc.collect()\n\t\t\tself.assert_del_calls([])\n\t\t\tself.assert_tp_del_calls([])\n\t\t\tself.assert_survivors([])\n\t\t\tself.assert_garbage(ids)\n\t\t\tself.assertIsNot(wr(), None)\n\t\t\t# Break the cycle to allow collection\n\t\t\tgc.garbage[0].ref = None\n\t\tself.assert_garbage([])\n\t\tself.assertIs(wr(), None)\n\n", "description": "\n\tTest finalization of objects with a tp_del.\n\t", "category": "simple", "imports": ["import contextlib", "import gc", "import unittest", "import weakref", "\tfrom _testcapi import with_tp_del", "\tfrom _testcapi import without_gc", "from test import support", "# Can't inherit from NonGCResurrector, in case importing without_gc fails."]}], [], [{"term": "class", "name": "_ComplexObject", "data": "class _ComplexObject(object):\n\tdef __init__(self, name):\n\t\tself.name = name\n\n\tdef __eq__(self, other):\n\t\treturn self.name == other.name\n\n\tdef __hash__(self):\n\t\treturn hash(self.name)\n\n\tdef __str__(self):\n\t\treturn \"I am _ComplexObject(%r)\" % self.name\n\n\tdef __unicode__(self):\n\t\treturn unicode(self.name)\n\n\tdef __repr__(self):\n\t\treturn \"_ComplexObject(%r)\" % self.name\n", "description": null, "category": "simple", "imports": ["import copy", "import pickle", "from django.utils.unittest import TestCase", "from django.utils.functional import SimpleLazyObject, empty", "\t\t# This is important for classes that use __class__ in things like"]}, {"term": "class", "name": "TestUtilsSimpleLazyObject", "data": "class TestUtilsSimpleLazyObject(TestCase):\n\t\"\"\"\n\tTests for SimpleLazyObject\n\t\"\"\"\n\t# Note that concrete use cases for SimpleLazyObject are also found in the\n\t# auth context processor tests (unless the implementation of that function\n\t# is changed).\n\n\tdef test_equality(self):\n\t\tself.assertEqual(complex_object(), SimpleLazyObject(complex_object))\n\t\tself.assertEqual(SimpleLazyObject(complex_object), complex_object())\n\n\tdef test_hash(self):\n\t\t# hash() equality would not be true for many objects, but it should be\n\t\t# for _ComplexObject\n\t\tself.assertEqual(hash(complex_object()),\n\t\t\t\t\t\t hash(SimpleLazyObject(complex_object)))\n\n\tdef test_repr(self):\n\t\t# For debugging, it will really confuse things if there is no clue that\n\t\t# SimpleLazyObject is actually a proxy object. So we don't\n\t\t# proxy __repr__\n\t\tself.assertTrue(\"SimpleLazyObject\" in repr(SimpleLazyObject(complex_object)))\n\n\tdef test_str(self):\n\t\tself.assertEqual(\"I am _ComplexObject('joe')\", str(SimpleLazyObject(complex_object)))\n\n\tdef test_unicode(self):\n\t\tself.assertEqual(u\"joe\", unicode(SimpleLazyObject(complex_object)))\n\n\tdef test_class(self):\n\t\t# This is important for classes that use __class__ in things like\n\t\t# equality tests.\n\t\tself.assertEqual(_ComplexObject, SimpleLazyObject(complex_object).__class__)\n\n\tdef test_deepcopy(self):\n\t\t# Check that we *can* do deep copy, and that it returns the right\n\t\t# objects.\n\n\t\t# First, for an unevaluated SimpleLazyObject\n\t\ts = SimpleLazyObject(complex_object)\n\t\tself.assertIs(s._wrapped, empty)\n\t\ts2 = copy.deepcopy(s)\n\t\t# something has gone wrong is s is evaluated\n\t\tself.assertIs(s._wrapped, empty)\n\t\tself.assertEqual(s2, complex_object())\n\n\t\t# Second, for an evaluated SimpleLazyObject\n\t\tname = s.name # evaluate\n\t\tself.assertIsNot(s._wrapped, empty)\n\t\ts3 = copy.deepcopy(s)\n\t\tself.assertEqual(s3, complex_object())\n\n\n\tdef test_none(self):\n\t\ti = [0]\n\t\tdef f():\n\t\t\ti[0] += 1\n\t\t\treturn None\n\n\t\tx = SimpleLazyObject(f)\n\t\tself.assertEqual(str(x), \"None\")\n\t\tself.assertEqual(i, [1])\n\t\tself.assertEqual(str(x), \"None\")\n\t\tself.assertEqual(i, [1])\n\n\tdef test_bool(self):\n\t\tx = SimpleLazyObject(lambda: 3)\n\t\tself.assertTrue(x)\n\t\tx = SimpleLazyObject(lambda: 0)\n\t\tself.assertFalse(x)\n\n\tdef test_pickle_complex(self):\n\t\t# See ticket #16563\n\t\tx = SimpleLazyObject(complex_object)\n\t\tpickled = pickle.dumps(x)\n\t\tunpickled = pickle.loads(pickled)\n\t\tself.assertEqual(unpickled, x)\n\t\tself.assertEqual(unicode(unpickled), unicode(x))\n\t\tself.assertEqual(unpickled.name, x.name)\n", "description": "\n\tTests for SimpleLazyObject\n\t", "category": "simple", "imports": ["import copy", "import pickle", "from django.utils.unittest import TestCase", "from django.utils.functional import SimpleLazyObject, empty", "\t\t# This is important for classes that use __class__ in things like"]}], [{"term": "class", "name": "CDLL", "data": "class CDLL(object):\r\n\t_func_flags_: ClassVar[int] = ...\r\n\t_func_restype_: ClassVar[_CData] = ...\r\n\t_name: str = ...\r\n\t_handle: int = ...\r\n\t_FuncPtr: Type[_FuncPointer] = ...\r\n\tdef __init__(self, name: str, mode: int = ..., handle: Optional[int] = ...,\r\n\t\t\t\t use_errno: bool = ..., use_last_error: bool = ...) -> None: ...\r\n\tdef __getattr__(self, name: str) -> _FuncPointer: ...\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "class", "name": "PyDLL", "data": "class PyDLL(CDLL): ...\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "class", "name": "LibraryLoader", "data": "class LibraryLoader(Generic[_DLLT]):\r\n\tdef __init__(self, dlltype: Type[_DLLT]) -> None: ...\r\n\tdef __getattr__(self, name: str) -> _DLLT: ...\r\n\tdef __getitem__(self, name: str) -> _DLLT: ...\r\n\tdef LoadLibrary(self, name: str) -> _DLLT: ...\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "class", "name": "_CDataMeta", "data": "class _CDataMeta(type):\r\n\t# By default mypy complains about the following two methods, because strictly speaking cls\r\n\t# might not be a Type[_CT]. However this can never actually happen, because the only class that\r\n\t# uses _CDataMeta as its metaclass is _CData. So it's safe to ignore the errors here.\r\n\tdef __mul__(cls: Type[_CT], other: int) -> Type[Array[_CT]]: ...  # type: ignore\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "class", "name": "_CData", "data": "class _CData(metaclass=_CDataMeta):\r\n\t_b_base: int = ...\r\n\t_b_needsfree_: bool = ...\r\n\t_objects: Optional[Mapping[Any, int]] = ...\r\n\t@classmethod\r\n\tdef from_buffer(cls: Type[_CT], source: bytearray, offset: int = ...) -> _CT: ...\r\n\t@classmethod\r\n\tdef from_buffer_copy(cls: Type[_CT], source: bytearray, offset: int = ...) -> _CT: ...\r\n\t@classmethod\r\n\tdef from_address(cls: Type[_CT], address: int) -> _CT: ...\r\n\t@classmethod\r\n\tdef from_param(cls: Type[_CT], obj: Any) -> _UnionT[_CT, _CArgObject]: ...\r\n\t@classmethod\r\n\tdef in_dll(cls: Type[_CT], library: CDLL, name: str) -> _CT: ...\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "class", "name": "_PointerLike", "data": "class _PointerLike(_CData): ...\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "class", "name": "_FuncPointer", "data": "class _FuncPointer(_PointerLike, _CData):\r\n\trestype: _UnionT[Type[_CData], Callable[[int], None], None] = ...\r\n\targtypes: Sequence[Type[_CData]] = ...\r\n\terrcheck: _ECT = ...\r\n\t@overload\r\n\tdef __init__(self, address: int) -> None: ...\r\n\t@overload\r\n\tdef __init__(self, callable: Callable[..., Any]) -> None: ...\r\n\t@overload\r\n\tdef __init__(self, func_spec: Tuple[_UnionT[str, int], CDLL],\r\n\t\t\t\t paramflags: Tuple[_PF, ...] = ...) -> None: ...\r\n\t@overload\r\n\tdef __init__(self, vtlb_index: int, name: str,\r\n\t\t\t\t paramflags: Tuple[_PF, ...] = ...,\r\n\t\t\t\t iid: pointer[c_int] = ...) -> None: ...\r\n\tdef __call__(self, *args: Any, **kwargs: Any) -> Any: ...\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "class", "name": "ArgumentError", "data": "class ArgumentError(Exception): ...\r\n\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "def", "name": "CFUNCTYPE", "data": "def CFUNCTYPE(restype: Optional[Type[_CData]],\r\n\t\t\t  *argtypes: Type[_CData],\r\n\t\t\t  use_errno: bool = ...,\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "def", "name": "fWINFUNCTYPE", "data": "\tdef WINFUNCTYPE(restype: Optional[Type[_CData]],\r\n\t\t\t\t\t*argtypes: Type[_CData],\r\n\t\t\t\t\tuse_errno: bool = ...,\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "def", "name": "PYFUNCTYPE", "data": "def PYFUNCTYPE(restype: Optional[Type[_CData]],\r\n\t\t\t   *argtypes: Type[_CData]) -> Type[_FuncPointer]: ...\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "class", "name": "class_CArgObject:...\r", "data": "class _CArgObject: ...\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "def", "name": "create_string_buffer", "data": "def create_string_buffer(init_or_size: _UnionT[int, bytes],\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "def", "name": "create_unicode_buffer", "data": "def create_unicode_buffer(init_or_size: _UnionT[int, Text],\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "def", "name": "POINTER", "data": "def POINTER(type: Type[_CT]) -> Type[pointer[_CT]]: ...\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "class", "name": "pointer", "data": "class pointer(Generic[_CT], _PointerLike, _CData):\r\n\t_type_: ClassVar[Type[_CT]] = ...\r\n\tcontents: _CT = ...\r\n\tdef __init__(self, arg: _CT = ...) -> None: ...\r\n\t@overload\r\n\tdef __getitem__(self, i: int) -> _CT: ...\r\n\t@overload\r\n\tdef __getitem__(self, s: slice) -> List[_CT]: ...\r\n\t@overload\r\n\tdef __setitem__(self, i: int, o: _CT) -> None: ...\r\n\t@overload\r\n\tdef __setitem__(self, s: slice, o: Iterable[_CT]) -> None: ...\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "def", "name": "fWinError", "data": "\tdef WinError(code: Optional[int] = ...,\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "def", "name": "wstring_at", "data": "def wstring_at(address: _CVoidConstPLike, size: int = ...) -> str: ...\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "class", "name": "_SimpleCData", "data": "class _SimpleCData(Generic[_T], _CData):\r\n\tvalue: _T = ...\r\n\tdef __init__(self, value: _T = ...) -> None: ...\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "class", "name": "c_byte", "data": "class c_byte(_SimpleCData[int]): ...\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "class", "name": "c_char", "data": "class c_char(_SimpleCData[bytes]):\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "class", "name": "c_char_p", "data": "class c_char_p(_PointerLike, _SimpleCData[Optional[bytes]]):\r\n\tdef __init__(self, value: Optional[_UnionT[int, bytes]] = ...) -> None: ...\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "class", "name": "c_float", "data": "class c_float(_SimpleCData[float]): ...\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "class", "name": "c_int64", "data": "class c_int64(_SimpleCData[int]): ...\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "class", "name": "c_longlong", "data": "class c_longlong(_SimpleCData[int]): ...\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "class", "name": "c_short", "data": "class c_short(_SimpleCData[int]): ...\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "class", "name": "c_ssize_t", "data": "class c_ssize_t(_SimpleCData[int]): ...\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "class", "name": "c_ubyte", "data": "class c_ubyte(_SimpleCData[int]): ...\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "class", "name": "c_uint64", "data": "class c_uint64(_SimpleCData[int]): ...\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "class", "name": "c_ulonglong", "data": "class c_ulonglong(_SimpleCData[int]): ...\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "class", "name": "c_ushort", "data": "class c_ushort(_SimpleCData[int]): ...\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "class", "name": "c_void_p", "data": "class c_void_p(_PointerLike, _SimpleCData[Optional[int]]): ...\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "class", "name": "c_wchar_p", "data": "class c_wchar_p(_PointerLike, _SimpleCData[Optional[Text]]):\r\n\tdef __init__(self, value: Optional[_UnionT[int, Text]] = ...) -> None: ...\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "class", "name": "c_bool", "data": "class c_bool(_SimpleCData[bool]):\r\n\tdef __init__(self, value: bool) -> None: ...\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "class", "name": "sHRESULT", "data": "\tclass HRESULT(_SimpleCData[int]): ...  # TODO undocumented\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "class", "name": "py_object", "data": "class py_object(_SimpleCData[_T]): ...\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "class", "name": "class_CField:\r", "data": "class _CField:\r\n\toffset: int = ...\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "class", "name": "_StructUnionMeta", "data": "class _StructUnionMeta(_CDataMeta):\r\n\t_fields_: Sequence[_UnionT[Tuple[str, Type[_CData]], Tuple[str, Type[_CData], int]]] = ...\r\n\t_pack_: int = ...\r\n\t_anonymous_: Sequence[str] = ...\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "class", "name": "_StructUnionBase", "data": "class _StructUnionBase(_CData, metaclass=_StructUnionMeta):\r\n\tdef __init__(self, *args: Any, **kw: Any) -> None: ...\r\n\tdef __getattr__(self, name: str) -> Any: ...\r\n\tdef __setattr__(self, name: str, value: Any) -> None: ...\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "class", "name": "LittleEndianStructure", "data": "class LittleEndianStructure(Structure): ...\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}, {"term": "class", "name": "Array", "data": "class Array(Generic[_T], _CData):\r\n\t_length_: ClassVar[int] = ...\r\n\t_type_: ClassVar[Type[_T]] = ...\r\n\traw: bytes = ...  # TODO only available with _T == c_char\r\n\tvalue: bytes = ...  # TODO only available with _T == c_char\r\n\t# TODO These methods cannot be annotated correctly at the moment.\r\n\t# All of these \"Any\"s stand for the array's element type, but it's not possible to use _T here,\r\n\t# because of a special feature of ctypes.\r\n\t# By default, when accessing an element of an Array[_T], the returned object has type _T.\r\n\t# However, when _T is a \"simple type\" like c_int, ctypes automatically \"unboxes\" the object\r\n\t# and converts it to the corresponding Python primitive. For example, when accessing an element\r\n\t# of an Array[c_int], a Python int object is returned, not a c_int.\r\n\t# This behavior does *not* apply to subclasses of \"simple types\".\r\n\t# If MyInt is a subclass of c_int, then accessing an element of an Array[MyInt] returns\r\n\t# a MyInt, not an int.\r\n\t# This special behavior is not easy to model in a stub, so for now all places where\r\n\t# the array element type would belong are annotated with Any instead.\r\n\tdef __init__(self, *args: Any) -> None: ...\r\n\t@overload\r\n\tdef __getitem__(self, i: int) -> Any: ...\r\n\t@overload\r\n\tdef __getitem__(self, s: slice) -> List[Any]: ...\r\n\t@overload\r\n\tdef __setitem__(self, i: int, o: Any) -> None: ...\r\n\t@overload\r\n\tdef __setitem__(self, s: slice, o: Iterable[Any]) -> None: ...\r\n\tdef __iter__(self) -> Iterator[Any]: ...\r\n\t# Can't inherit from Sized because the metaclass conflict between\r\n\t# Sized and _CData prevents using _CDataMeta.\r\n\tdef __len__(self) -> int: ...\r\n", "description": null, "category": "simple", "imports": ["from typing import (\r", "from typing import Union as _UnionT\r", "import sys\r"]}], [{"term": "class", "name": "SimpleSitemap", "data": "class SimpleSitemap(Sitemap):\n\tchangefreq = \"never\"\n\tpriority = 0.5\n\tlocation = '/location/'\n\tlastmod = datetime.now()\n\n\tdef items(self):\n\t\treturn [object()]\n", "description": null, "category": "simple", "imports": ["from datetime import datetime", "from django.conf.urls.defaults import *", "from django.contrib.sitemaps import Sitemap, GenericSitemap, FlatPageSitemap", "from django.contrib.auth.models import User"]}], [{"term": "class", "name": "TestSimpleFunctions", "data": "class TestSimpleFunctions(unittest.TestCase):\n\n\tdef test_add(self):\n\t\tself.assertEqual(simpleFunctions.add(10, 5), 15)\n\t\tself.assertEqual(simpleFunctions.add(-10, -5), -15)\n\t\tself.assertEqual(simpleFunctions.add(1, -1), 0)\n\n\tdef test_subtract(self):\n\t\tself.assertEqual(simpleFunctions.subtract(10, 2), 8)\n\t\tself.assertEqual(simpleFunctions.subtract(10, -2), 12)\n\t\tself.assertEqual(simpleFunctions.subtract(-10, 2), -12)\n\t\tself.assertEqual(simpleFunctions.subtract(-10, -2), -8)\n\n\tdef test_multiply(self):\n\t\tself.assertEqual(simpleFunctions.multiply(10, 2), 20)\n\t\tself.assertEqual(simpleFunctions.multiply(-10, 0), 0)\n\t\tself.assertEqual(simpleFunctions.multiply(10, 0), 0)\n\t\tself.assertEqual(simpleFunctions.multiply(-10, 2), -20)\n\t\tself.assertEqual(simpleFunctions.multiply(-10, -2), 20)\n\n\tdef test_divide(self):\n\t\tself.assertEqual(simpleFunctions.divide(10, 2), 5)\n\t\tself.assertEqual(simpleFunctions.divide(2, 10), 0.2)\n\t\tself.assertEqual(simpleFunctions.divide(10, -2), -5)\n\t\tself.assertEqual(simpleFunctions.divide(-2, 10), -0.2)\n\t\tself.assertEqual(simpleFunctions.divide(0, 10), 0)\n\t\tself.assertRaises(ValueError, simpleFunctions.divide, 10, 0)\n\t\twith self.assertRaises(ValueError):  # context manager\n\t\t\tsimpleFunctions.divide(10, 0)\n\n\tdef test_exponentiate(self):\n\t\tself.assertEqual(simpleFunctions.exponentiate(10, 2), 100)\n\t\tself.assertEqual(simpleFunctions.exponentiate(2, 10), 1024)\n\t\tself.assertEqual(simpleFunctions.exponentiate(-10, 2), 100)\n\t\tself.assertEqual(simpleFunctions.exponentiate(-10, 3), -1000)\n\t\tself.assertEqual(simpleFunctions.exponentiate(10, -2), 0.01)\n\n", "description": null, "category": "simple", "imports": ["import unittest", "import simpleFunctions"]}], [{"term": "class", "name": "MyForm", "data": "class MyForm(Form):\n\t\"\"\"\n\tTest form. If you want to test rendering of a field,\n\tadd it to this form and use one of 'render_...' functions\n\tfrom this module.\n\t\"\"\"\n\n\tsimple = CharField()\n\twith_attrs = CharField(widget=TextInput(attrs={\"foo\": \"baz\", \"egg\": \"spam\"}))\n\twith_cls = CharField(widget=TextInput(attrs={\"class\": \"class0\"}))\n\tdate = forms.DateField(widget=SelectDateWidget(attrs={\"egg\": \"spam\"}))\n\n", "description": "\n\tTest form. If you want to test rendering of a field,\n\tadd it to this form and use one of 'render_...' functions\n\tfrom this module.\n\t", "category": "simple", "imports": ["import string", "\tfrom unittest import TestCase, skipIf", "\tfrom unittest2 import TestCase, skipIf", "from django import VERSION", "from django import forms", "from django.forms import Form, CharField, TextInput", "from django.template import Template, Context", "\tfrom django.forms import SelectDateWidget  # django >= 2.0", "\tfrom django.forms.extras.widgets import SelectDateWidget  # django < 2.0"]}, {"term": "def", "name": "render_form", "data": "def render_form(text, form=None, **context_args):\n\t\"\"\"\n\tRenders template ``text`` with widget_tweaks library loaded\n\tand MyForm instance available in context as ``form``.\n\t\"\"\"\n\ttpl = Template(\"{% load widget_tweaks %}\" + text)\n\tcontext_args.update({\"form\": MyForm() if form is None else form})\n\tcontext = Context(context_args)\n\treturn tpl.render(context)\n\n", "description": "\n\tRenders template ``text`` with widget_tweaks library loaded\n\tand MyForm instance available in context as ``form``.\n\t", "category": "simple", "imports": ["import string", "\tfrom unittest import TestCase, skipIf", "\tfrom unittest2 import TestCase, skipIf", "from django import VERSION", "from django import forms", "from django.forms import Form, CharField, TextInput", "from django.template import Template, Context", "\tfrom django.forms import SelectDateWidget  # django >= 2.0", "\tfrom django.forms.extras.widgets import SelectDateWidget  # django < 2.0"]}, {"term": "def", "name": "render_field", "data": "def render_field(field, template_filter, params, *args, **kwargs):\n\t\"\"\"\n\tRenders ``field`` of MyForm with filter ``template_filter`` applied.\n\t``params`` are filter arguments.\n\n\tIf you want to apply several filters (in a chain),\n\tpass extra ``template_filter`` and ``params`` as positional arguments.\n\n\tIn order to use custom form, pass form instance as ``form``\n\tkeyword argument.\n\t\"\"\"\n\tfilters = [(template_filter, params)]\n\tfilters.extend(zip(args[::2], args[1::2]))\n\tfilter_strings = ['|%s:\"%s\"' % (f[0], f[1]) for f in filters]\n\trender_field_str = \"{{ form.%s%s }}\" % (field, \"\".join(filter_strings))\n\treturn render_form(render_field_str, **kwargs)\n\n", "description": "\n\tRenders ``field`` of MyForm with filter ``template_filter`` applied.\n\t``params`` are filter arguments.\n\n\tIf you want to apply several filters (in a chain),\n\tpass extra ``template_filter`` and ``params`` as positional arguments.\n\n\tIn order to use custom form, pass form instance as ``form``\n\tkeyword argument.\n\t", "category": "simple", "imports": ["import string", "\tfrom unittest import TestCase, skipIf", "\tfrom unittest2 import TestCase, skipIf", "from django import VERSION", "from django import forms", "from django.forms import Form, CharField, TextInput", "from django.template import Template, Context", "\tfrom django.forms import SelectDateWidget  # django >= 2.0", "\tfrom django.forms.extras.widgets import SelectDateWidget  # django < 2.0"]}, {"term": "def", "name": "render_field_from_tag", "data": "def render_field_from_tag(field, *attributes):\n\t\"\"\"\n\tRenders MyForm's field ``field`` with attributes passed\n\tas positional arguments.\n\t\"\"\"\n\tattr_strings = [\" %s\" % f for f in attributes]\n\ttpl = string.Template(\"{% render_field form.$field$attrs %}\")\n\trender_field_str = tpl.substitute(field=field, attrs=\"\".join(attr_strings))\n\treturn render_form(render_field_str)\n\n", "description": "\n\tRenders MyForm's field ``field`` with attributes passed\n\tas positional arguments.\n\t", "category": "simple", "imports": ["import string", "\tfrom unittest import TestCase, skipIf", "\tfrom unittest2 import TestCase, skipIf", "from django import VERSION", "from django import forms", "from django.forms import Form, CharField, TextInput", "from django.template import Template, Context", "\tfrom django.forms import SelectDateWidget  # django >= 2.0", "\tfrom django.forms.extras.widgets import SelectDateWidget  # django < 2.0"]}, {"term": "def", "name": "assertIn", "data": "def assertIn(value, obj):\n\tassert value in obj, \"%s not in %s\" % (value, obj)\n\n", "description": null, "category": "simple", "imports": ["import string", "\tfrom unittest import TestCase, skipIf", "\tfrom unittest2 import TestCase, skipIf", "from django import VERSION", "from django import forms", "from django.forms import Form, CharField, TextInput", "from django.template import Template, Context", "\tfrom django.forms import SelectDateWidget  # django >= 2.0", "\tfrom django.forms.extras.widgets import SelectDateWidget  # django < 2.0"]}, {"term": "def", "name": "assertNotIn", "data": "def assertNotIn(value, obj):\n\tassert value not in obj, \"%s in %s\" % (value, obj)\n\n", "description": null, "category": "simple", "imports": ["import string", "\tfrom unittest import TestCase, skipIf", "\tfrom unittest2 import TestCase, skipIf", "from django import VERSION", "from django import forms", "from django.forms import Form, CharField, TextInput", "from django.template import Template, Context", "\tfrom django.forms import SelectDateWidget  # django >= 2.0", "\tfrom django.forms.extras.widgets import SelectDateWidget  # django < 2.0"]}, {"term": "class", "name": "SimpleAttrTest", "data": "class SimpleAttrTest(TestCase):\n\tdef test_attr(self):\n\t\tres = render_field(\"simple\", \"attr\", \"foo:bar\")\n\t\tassertIn('type=\"text\"', res)\n\t\tassertIn('name=\"simple\"', res)\n\t\tassertIn('id=\"id_simple\"', res)\n\t\tassertIn('foo=\"bar\"', res)\n\n\tdef test_attr_chaining(self):\n\t\tres = render_field(\"simple\", \"attr\", \"foo:bar\", \"attr\", \"bar:baz\")\n\t\tassertIn('type=\"text\"', res)\n\t\tassertIn('name=\"simple\"', res)\n\t\tassertIn('id=\"id_simple\"', res)\n\t\tassertIn('foo=\"bar\"', res)\n\t\tassertIn('bar=\"baz\"', res)\n\n\tdef test_add_class(self):\n\t\tres = render_field(\"simple\", \"add_class\", \"foo\")\n\t\tassertIn('class=\"foo\"', res)\n\n\tdef test_add_multiple_classes(self):\n\t\tres = render_field(\"simple\", \"add_class\", \"foo bar\")\n\t\tassertIn('class=\"foo bar\"', res)\n\n\tdef test_add_class_chaining(self):\n\t\tres = render_field(\"simple\", \"add_class\", \"foo\", \"add_class\", \"bar\")\n\t\tassertIn('class=\"bar foo\"', res)\n\n\tdef test_set_data(self):\n\t\tres = render_field(\"simple\", \"set_data\", \"key:value\")\n\t\tassertIn('data-key=\"value\"', res)\n\n\tdef test_replace_type(self):\n\t\tres = render_field(\"simple\", \"attr\", \"type:date\")\n\t\tself.assertTrue(res.count(\"type=\") == 1, (res, res.count(\"type=\")))\n\t\tassertIn('type=\"date\"', res)\n\n\tdef test_replace_hidden(self):\n\t\tres = render_field(\"simple\", \"attr\", \"type:hidden\")\n\t\tself.assertTrue(res.count(\"type=\") == 1, (res, res.count(\"type=\")))\n\t\tassertIn('type=\"hidden\"', res)\n\n", "description": null, "category": "simple", "imports": ["import string", "\tfrom unittest import TestCase, skipIf", "\tfrom unittest2 import TestCase, skipIf", "from django import VERSION", "from django import forms", "from django.forms import Form, CharField, TextInput", "from django.template import Template, Context", "\tfrom django.forms import SelectDateWidget  # django >= 2.0", "\tfrom django.forms.extras.widgets import SelectDateWidget  # django < 2.0"]}, {"term": "class", "name": "ErrorsTest", "data": "class ErrorsTest(TestCase):\n\tdef _err_form(self):\n\t\tform = MyForm({\"foo\": \"bar\"})  # some random data\n\t\tform.is_valid()  # trigger form validation\n\t\treturn form\n\n\tdef test_error_class_no_error(self):\n\t\tres = render_field(\"simple\", \"add_error_class\", \"err\")\n\t\tassertNotIn('class=\"err\"', res)\n\n\tdef test_error_class_error(self):\n\t\tform = self._err_form()\n\t\tres = render_field(\"simple\", \"add_error_class\", \"err\", form=form)\n\t\tassertIn('class=\"err\"', res)\n\n\tdef test_required_class(self):\n\t\tres = render_field(\"simple\", \"add_required_class\", \"is-required\")\n\t\tassertIn('class=\"is-required\"', res)\n\n\tdef test_required_class_requiredfield(self):\n\t\tform = self._err_form()\n\t\tres = render_field(\"simple\", \"add_required_class\", \"is-required\", form=form)\n\t\tassertIn('class=\"is-required\"', res)\n\t\tassertIn(\"required\", res)\n\n\tdef test_error_attr_no_error(self):\n\t\tres = render_field(\"simple\", \"add_error_attr\", \"aria-invalid:true\")\n\t\tassertNotIn('aria-invalid=\"true\"', res)\n\n\tdef test_error_attr_error(self):\n\t\tform = self._err_form()\n\t\tres = render_field(\"simple\", \"add_error_attr\", \"aria-invalid:true\", form=form)\n\t\tassertIn('aria-invalid=\"true\"', res)\n\n", "description": null, "category": "simple", "imports": ["import string", "\tfrom unittest import TestCase, skipIf", "\tfrom unittest2 import TestCase, skipIf", "from django import VERSION", "from django import forms", "from django.forms import Form, CharField, TextInput", "from django.template import Template, Context", "\tfrom django.forms import SelectDateWidget  # django >= 2.0", "\tfrom django.forms.extras.widgets import SelectDateWidget  # django < 2.0"]}, {"term": "class", "name": "SilenceTest", "data": "class SilenceTest(TestCase):\n\tdef test_silence_without_field(self):\n\t\tres = render_field(\"nothing\", \"attr\", \"foo:bar\")\n\t\tself.assertEqual(res, \"\")\n\t\tres = render_field(\"nothing\", \"add_class\", \"some\")\n\t\tself.assertEqual(res, \"\")\n\t\tres = render_field(\"nothing\", \"remove_attr\", \"some\")\n\t\tself.assertEqual(res, \"\")\n\n", "description": null, "category": "simple", "imports": ["import string", "\tfrom unittest import TestCase, skipIf", "\tfrom unittest2 import TestCase, skipIf", "from django import VERSION", "from django import forms", "from django.forms import Form, CharField, TextInput", "from django.template import Template, Context", "\tfrom django.forms import SelectDateWidget  # django >= 2.0", "\tfrom django.forms.extras.widgets import SelectDateWidget  # django < 2.0"]}, {"term": "class", "name": "CustomizedWidgetTest", "data": "class CustomizedWidgetTest(TestCase):\n\tdef test_attr(self):\n\t\tres = render_field(\"with_attrs\", \"attr\", \"foo:bar\")\n\t\tassertIn('foo=\"bar\"', res)\n\t\tassertNotIn('foo=\"baz\"', res)\n\t\tassertIn('egg=\"spam\"', res)\n\n\t# XXX can be dropped once 1.8 is not supported\n\t@skipIf(\n\t\tVERSION < (1, 11, 0, \"final\", 0),\n\t\t\"see https://code.djangoproject.com/ticket/16754\",\n\t)\n\tdef test_selectdatewidget(self):\n\t\tres = render_field(\"date\", \"attr\", \"foo:bar\")\n\t\tassertIn('egg=\"spam\"', res)\n\t\tassertIn('foo=\"bar\"', res)\n\n\tdef test_attr_chaining(self):\n\t\tres = render_field(\"with_attrs\", \"attr\", \"foo:bar\", \"attr\", \"bar:baz\")\n\t\tassertIn('foo=\"bar\"', res)\n\t\tassertNotIn('foo=\"baz\"', res)\n\t\tassertIn('egg=\"spam\"', res)\n\t\tassertIn('bar=\"baz\"', res)\n\n\tdef test_attr_class(self):\n\t\tres = render_field(\"with_cls\", \"attr\", \"foo:bar\")\n\t\tassertIn('foo=\"bar\"', res)\n\t\tassertIn('class=\"class0\"', res)\n\n\tdef test_default_attr(self):\n\t\tres = render_field(\"with_cls\", \"attr\", \"type:search\")\n\t\tassertIn('class=\"class0\"', res)\n\t\tassertIn('type=\"search\"', res)\n\n\tdef test_add_class(self):\n\t\tres = render_field(\"with_cls\", \"add_class\", \"class1\")\n\t\tassertIn(\"class0\", res)\n\t\tassertIn(\"class1\", res)\n\n\tdef test_add_class_chaining(self):\n\t\tres = render_field(\"with_cls\", \"add_class\", \"class1\", \"add_class\", \"class2\")\n\t\tassertIn(\"class0\", res)\n\t\tassertIn(\"class1\", res)\n\t\tassertIn(\"class2\", res)\n\n\tdef test_remove_attr(self):\n\t\tres = render_field(\"with_attrs\", \"remove_attr\", \"foo\")\n\t\tassertNotIn(\"foo\", res)\n\n", "description": null, "category": "simple", "imports": ["import string", "\tfrom unittest import TestCase, skipIf", "\tfrom unittest2 import TestCase, skipIf", "from django import VERSION", "from django import forms", "from django.forms import Form, CharField, TextInput", "from django.template import Template, Context", "\tfrom django.forms import SelectDateWidget  # django >= 2.0", "\tfrom django.forms.extras.widgets import SelectDateWidget  # django < 2.0"]}, {"term": "class", "name": "FieldReuseTest", "data": "class FieldReuseTest(TestCase):\n\tdef test_field_double_rendering_simple(self):\n\t\tres = render_form(\n\t\t\t'{{ form.simple }}{{ form.simple|attr:\"foo:bar\" }}{{ form.simple }}'\n\t\t)\n\t\tself.assertEqual(res.count(\"bar\"), 1)\n\n\tdef test_field_double_rendering_simple_css(self):\n\t\tres = render_form(\n\t\t\t'{{ form.simple }}{{ form.simple|add_class:\"bar\" }}{{ form.simple|add_class:\"baz\" }}'\n\t\t)\n\t\tself.assertEqual(res.count(\"baz\"), 1)\n\t\tself.assertEqual(res.count(\"bar\"), 1)\n\n\tdef test_field_double_rendering_attrs(self):\n\t\tres = render_form(\n\t\t\t'{{ form.with_cls }}{{ form.with_cls|add_class:\"bar\" }}{{ form.with_cls }}'\n\t\t)\n\t\tself.assertEqual(res.count(\"class0\"), 3)\n\t\tself.assertEqual(res.count(\"bar\"), 1)\n\n", "description": null, "category": "simple", "imports": ["import string", "\tfrom unittest import TestCase, skipIf", "\tfrom unittest2 import TestCase, skipIf", "from django import VERSION", "from django import forms", "from django.forms import Form, CharField, TextInput", "from django.template import Template, Context", "\tfrom django.forms import SelectDateWidget  # django >= 2.0", "\tfrom django.forms.extras.widgets import SelectDateWidget  # django < 2.0"]}, {"term": "class", "name": "SimpleRenderFieldTagTest", "data": "class SimpleRenderFieldTagTest(TestCase):\n\tdef test_attr(self):\n\t\tres = render_field_from_tag(\"simple\", 'foo=\"bar\"')\n\t\tassertIn('type=\"text\"', res)\n\t\tassertIn('name=\"simple\"', res)\n\t\tassertIn('id=\"id_simple\"', res)\n\t\tassertIn('foo=\"bar\"', res)\n\n\tdef test_multiple_attrs(self):\n\t\tres = render_field_from_tag(\"simple\", 'foo=\"bar\"', 'bar=\"baz\"')\n\t\tassertIn('type=\"text\"', res)\n\t\tassertIn('name=\"simple\"', res)\n\t\tassertIn('id=\"id_simple\"', res)\n\t\tassertIn('foo=\"bar\"', res)\n\t\tassertIn('bar=\"baz\"', res)\n\n", "description": null, "category": "simple", "imports": ["import string", "\tfrom unittest import TestCase, skipIf", "\tfrom unittest2 import TestCase, skipIf", "from django import VERSION", "from django import forms", "from django.forms import Form, CharField, TextInput", "from django.template import Template, Context", "\tfrom django.forms import SelectDateWidget  # django >= 2.0", "\tfrom django.forms.extras.widgets import SelectDateWidget  # django < 2.0"]}, {"term": "class", "name": "RenderFieldTagSilenceTest", "data": "class RenderFieldTagSilenceTest(TestCase):\n\tdef test_silence_without_field(self):\n\t\tres = render_field_from_tag(\"nothing\", 'foo=\"bar\"')\n\t\tself.assertEqual(res, \"\")\n\t\tres = render_field_from_tag(\"nothing\", 'class+=\"some\"')\n\t\tself.assertEqual(res, \"\")\n\n", "description": null, "category": "simple", "imports": ["import string", "\tfrom unittest import TestCase, skipIf", "\tfrom unittest2 import TestCase, skipIf", "from django import VERSION", "from django import forms", "from django.forms import Form, CharField, TextInput", "from django.template import Template, Context", "\tfrom django.forms import SelectDateWidget  # django >= 2.0", "\tfrom django.forms.extras.widgets import SelectDateWidget  # django < 2.0"]}, {"term": "class", "name": "RenderFieldTagCustomizedWidgetTest", "data": "class RenderFieldTagCustomizedWidgetTest(TestCase):\n\tdef test_attr(self):\n\t\tres = render_field_from_tag(\"with_attrs\", 'foo=\"bar\"')\n\t\tassertIn('foo=\"bar\"', res)\n\t\tassertNotIn('foo=\"baz\"', res)\n\t\tassertIn('egg=\"spam\"', res)\n\n\t# XXX can be dropped once 1.8 is not supported\n\t@skipIf(\n\t\tVERSION < (1, 11, 0, \"final\", 0),\n\t\t\"see https://code.djangoproject.com/ticket/16754\",\n\t)\n\tdef test_selectdatewidget(self):\n\t\tres = render_field_from_tag(\"date\", 'foo=\"bar\"')\n\t\tassertIn('egg=\"spam\"', res)\n\t\tassertIn('foo=\"bar\"', res)\n\n\tdef test_multiple_attrs(self):\n\t\tres = render_field_from_tag(\"with_attrs\", 'foo=\"bar\"', 'bar=\"baz\"')\n\t\tassertIn('foo=\"bar\"', res)\n\t\tassertNotIn('foo=\"baz\"', res)\n\t\tassertIn('egg=\"spam\"', res)\n\t\tassertIn('bar=\"baz\"', res)\n\n\tdef test_attr_class(self):\n\t\tres = render_field_from_tag(\"with_cls\", 'foo=\"bar\"')\n\t\tassertIn('foo=\"bar\"', res)\n\t\tassertIn('class=\"class0\"', res)\n\n\tdef test_default_attr(self):\n\t\tres = render_field_from_tag(\"with_cls\", 'type=\"search\"')\n\t\tassertIn('class=\"class0\"', res)\n\t\tassertIn('type=\"search\"', res)\n\n\tdef test_append_attr(self):\n\t\tres = render_field_from_tag(\"with_cls\", 'class+=\"class1\"')\n\t\tassertIn(\"class0\", res)\n\t\tassertIn(\"class1\", res)\n\n\tdef test_duplicate_append_attr(self):\n\t\tres = render_field_from_tag(\"with_cls\", 'class+=\"class1\"', 'class+=\"class2\"')\n\t\tassertIn(\"class0\", res)\n\t\tassertIn(\"class1\", res)\n\t\tassertIn(\"class2\", res)\n\n\tdef test_hyphenated_attributes(self):\n\t\tres = render_field_from_tag(\"with_cls\", 'data-foo=\"bar\"')\n\t\tassertIn('data-foo=\"bar\"', res)\n\t\tassertIn('class=\"class0\"', res)\n\n", "description": null, "category": "simple", "imports": ["import string", "\tfrom unittest import TestCase, skipIf", "\tfrom unittest2 import TestCase, skipIf", "from django import VERSION", "from django import forms", "from django.forms import Form, CharField, TextInput", "from django.template import Template, Context", "\tfrom django.forms import SelectDateWidget  # django >= 2.0", "\tfrom django.forms.extras.widgets import SelectDateWidget  # django < 2.0"]}, {"term": "class", "name": "RenderFieldWidgetClassesTest", "data": "class RenderFieldWidgetClassesTest(TestCase):\n\tdef test_use_widget_required_class(self):\n\t\tres = render_form(\n\t\t\t\"{% render_field form.simple %}\", WIDGET_REQUIRED_CLASS=\"required_class\"\n\t\t)\n\t\tassertIn('class=\"required_class\"', res)\n\n\tdef test_use_widget_error_class(self):\n\t\tres = render_form(\n\t\t\t\"{% render_field form.simple %}\",\n\t\t\tform=MyForm({}),\n\t\t\tWIDGET_ERROR_CLASS=\"error_class\",\n\t\t)\n\t\tassertIn('class=\"error_class\"', res)\n\n\tdef test_use_widget_error_class_with_other_classes(self):\n\t\tres = render_form(\n\t\t\t'{% render_field form.simple class=\"blue\" %}',\n\t\t\tform=MyForm({}),\n\t\t\tWIDGET_ERROR_CLASS=\"error_class\",\n\t\t)\n\t\tassertIn('class=\"blue error_class\"', res)\n\n\tdef test_use_widget_required_class_with_other_classes(self):\n\t\tres = render_form(\n\t\t\t'{% render_field form.simple class=\"blue\" %}',\n\t\t\tform=MyForm({}),\n\t\t\tWIDGET_REQUIRED_CLASS=\"required_class\",\n\t\t)\n\t\tassertIn('class=\"blue required_class\"', res)\n\n", "description": null, "category": "simple", "imports": ["import string", "\tfrom unittest import TestCase, skipIf", "\tfrom unittest2 import TestCase, skipIf", "from django import VERSION", "from django import forms", "from django.forms import Form, CharField, TextInput", "from django.template import Template, Context", "\tfrom django.forms import SelectDateWidget  # django >= 2.0", "\tfrom django.forms.extras.widgets import SelectDateWidget  # django < 2.0"]}, {"term": "class", "name": "RenderFieldTagFieldReuseTest", "data": "class RenderFieldTagFieldReuseTest(TestCase):\n\tdef test_field_double_rendering_simple(self):\n\t\tres = render_form(\n\t\t\t'{{ form.simple }}{% render_field form.simple foo=\"bar\" %}{% render_field form.simple %}'\n\t\t)\n\t\tself.assertEqual(res.count(\"bar\"), 1)\n\n\tdef test_field_double_rendering_simple_css(self):\n\t\tres = render_form(\n\t\t\t'{% render_field form.simple %}{% render_field form.simple class+=\"bar\" %}{% render_field form.simple class+=\"baz\" %}'\n\t\t)\n\t\tself.assertEqual(res.count(\"baz\"), 1)\n\t\tself.assertEqual(res.count(\"bar\"), 1)\n\n\tdef test_field_double_rendering_attrs(self):\n\t\tres = render_form(\n\t\t\t'{% render_field form.with_cls %}{% render_field form.with_cls class+=\"bar\" %}{% render_field form.with_cls %}'\n\t\t)\n\t\tself.assertEqual(res.count(\"class0\"), 3)\n\t\tself.assertEqual(res.count(\"bar\"), 1)\n\n\tdef test_field_double_rendering_id(self):\n\t\tres = render_form(\n\t\t\t\"{{ form.simple }}\"\n\t\t\t'{% render_field form.simple id=\"id_1\" %}'\n\t\t\t'{% render_field form.simple id=\"id_2\" %}'\n\t\t)\n\t\tself.assertEqual(res.count(\"id_1\"), 1)\n\t\tself.assertEqual(res.count(\"id_2\"), 1)\n\n\tdef test_field_double_rendering_id_name(self):\n\t\tres = render_form(\n\t\t\t\"{{ form.simple }}\"\n\t\t\t'{% render_field form.simple id=\"id_1\" name=\"n_1\" %}'\n\t\t\t'{% render_field form.simple id=\"id_2\" name=\"n_2\" %}'\n\t\t)\n\t\tself.assertEqual(res.count(\"id_1\"), 1)\n\t\tself.assertEqual(res.count(\"id_2\"), 1)\n\t\tself.assertEqual(res.count(\"n_1\"), 1)\n\t\tself.assertEqual(res.count(\"n_2\"), 1)\n\n\tdef test_field_double_rendering_id_class(self):\n\t\tres = render_form(\n\t\t\t\"{{ form.simple }}\"\n\t\t\t'{% render_field form.simple id=\"id_1\" class=\"c_1\" %}'\n\t\t\t'{% render_field form.simple id=\"id_2\" class=\"c_2\" %}'\n\t\t)\n\t\tself.assertEqual(res.count(\"id_1\"), 1)\n\t\tself.assertEqual(res.count(\"id_2\"), 1)\n\t\tself.assertEqual(res.count(\"c_1\"), 1)\n\t\tself.assertEqual(res.count(\"c_2\"), 1)\n\n\tdef test_field_double_rendering_name_class(self):\n\t\tres = render_form(\n\t\t\t\"{{ form.simple }}\"\n\t\t\t'{% render_field form.simple name=\"n_1\" class=\"c_1\" %}'\n\t\t\t'{% render_field form.simple name=\"n_2\" class=\"c_2\" %}'\n\t\t)\n\t\tself.assertEqual(res.count(\"n_1\"), 1)\n\t\tself.assertEqual(res.count(\"n_2\"), 1)\n\t\tself.assertEqual(res.count(\"c_1\"), 1)\n\t\tself.assertEqual(res.count(\"c_2\"), 1)\n\n\tdef test_field_double_rendering_simple(self):\n\t\tres = render_form('{% render_field form.simple foo=\"bar\" v-model=\"username\" %}')\n\t\tself.assertEqual(res.count('v-model=\"username\"'), 1)\n\n", "description": null, "category": "simple", "imports": ["import string", "\tfrom unittest import TestCase, skipIf", "\tfrom unittest2 import TestCase, skipIf", "from django import VERSION", "from django import forms", "from django.forms import Form, CharField, TextInput", "from django.template import Template, Context", "\tfrom django.forms import SelectDateWidget  # django >= 2.0", "\tfrom django.forms.extras.widgets import SelectDateWidget  # django < 2.0"]}, {"term": "class", "name": "RenderFieldTagUseTemplateVariableTest", "data": "class RenderFieldTagUseTemplateVariableTest(TestCase):\n\tdef test_use_template_variable_in_parametrs(self):\n\t\tres = render_form(\n\t\t\t'{% render_field form.with_attrs egg+=\"pahaz\" placeholder=form.with_attrs.label %}'\n\t\t)\n\t\tassertIn('egg=\"spam pahaz\"', res)\n\t\tassertIn('placeholder=\"With attrs\"', res)\n\n", "description": null, "category": "simple", "imports": ["import string", "\tfrom unittest import TestCase, skipIf", "\tfrom unittest2 import TestCase, skipIf", "from django import VERSION", "from django import forms", "from django.forms import Form, CharField, TextInput", "from django.template import Template, Context", "\tfrom django.forms import SelectDateWidget  # django >= 2.0", "\tfrom django.forms.extras.widgets import SelectDateWidget  # django < 2.0"]}, {"term": "class", "name": "RenderFieldFilter_field_type_widget_type_Test", "data": "class RenderFieldFilter_field_type_widget_type_Test(TestCase):\n\tdef test_field_type_widget_type_rendering_simple(self):\n\t\tres = render_form(\n\t\t\t'{{ form.simple }}'\n\t\t)\n\t\tassertIn('class=\"charfield textinput simple\"', res)\n\n", "description": null, "category": "simple", "imports": ["import string", "\tfrom unittest import TestCase, skipIf", "\tfrom unittest2 import TestCase, skipIf", "from django import VERSION", "from django import forms", "from django.forms import Form, CharField, TextInput", "from django.template import Template, Context", "\tfrom django.forms import SelectDateWidget  # django >= 2.0", "\tfrom django.forms.extras.widgets import SelectDateWidget  # django < 2.0"]}, {"term": "class", "name": "RenderFieldTagNonValueAttribute", "data": "class RenderFieldTagNonValueAttribute(TestCase):\n\tdef test_field_non_value(self):\n\t\tres = render_form('{{ form.simple|attr:\"foo\" }}')\n\t\tassertIn(\"foo\", res)\n\t\tassertNotIn(\"foo=\", res)\n\n\tdef test_field_empty_value(self):\n\t\tres = render_form('{{ form.simple|attr:\"foo:\" }}')\n\t\tassertIn('foo=\"\"', res)\n\n\tdef test_field_other_value(self):\n\t\tres = render_form('{{ form.simple|attr:\"foo:bar\" }}')\n\t\tassertIn('foo=\"bar\"', res)\n\n\tdef test_field_double_colon(self):\n\t\tres = render_form('{{ form.simple|attr:\"v-bind::class:value\" }}')\n\t\tassertIn('v-bind:class=\"value\"', res)\n\n\tdef test_field_double_colon_morethanone(self):\n\t\tres = render_form('{{ form.simple|attr:\"v-bind::class:{active:True}\" }}')\n\t\tassertIn('v-bind:class=\"{active:True}\"', res)\n\n\tdef test_field_arroba(self):\n\t\tres = render_form('{{ form.simple|attr:\"@click:onClick\" }}')\n\t\tassertIn('@click=\"onClick\"', res)\n\n\tdef test_field_arroba_dot(self):\n\t\tres = render_form('{{ form.simple|attr:\"@click.prevent:onClick\" }}')\n\t\tassertIn('@click.prevent=\"onClick\"', res)\n\n\tdef test_field_double_colon_missing(self):\n\t\tres = render_form('{{ form.simple|attr:\"::class:{active:True}\" }}')\n\t\tassertIn(':class=\"{active:True}\"', res)\n", "description": null, "category": "simple", "imports": ["import string", "\tfrom unittest import TestCase, skipIf", "\tfrom unittest2 import TestCase, skipIf", "from django import VERSION", "from django import forms", "from django.forms import Form, CharField, TextInput", "from django.template import Template, Context", "\tfrom django.forms import SelectDateWidget  # django >= 2.0", "\tfrom django.forms.extras.widgets import SelectDateWidget  # django < 2.0"]}], [{"term": "class", "name": "SitemapTests", "data": "class SitemapTests(TestCase):\n\turls = 'django.contrib.sitemaps.tests.urls'\n\n\tdef setUp(self):\n\t\tif Site._meta.installed:\n\t\t\tself.base_url = 'http://example.com'\n\t\telse:\n\t\t\tself.base_url = 'http://testserver'\n\t\tself.old_USE_L10N = settings.USE_L10N\n\t\tself.old_Site_meta_installed = Site._meta.installed\n\t\tself.old_TEMPLATE_DIRS = settings.TEMPLATE_DIRS\n\t\tself.old_Site_meta_installed = Site._meta.installed\n\t\tsettings.TEMPLATE_DIRS = (\n\t\t\tos.path.join(os.path.dirname(__file__), 'templates'),\n\t\t)\n\t\t# Create a user that will double as sitemap content\n\t\tUser.objects.create_user('testuser', 'test@example.com', 's3krit')\n\n\tdef tearDown(self):\n\t\tsettings.USE_L10N = self.old_USE_L10N\n\t\tSite._meta.installed = self.old_Site_meta_installed\n\t\tsettings.TEMPLATE_DIRS = self.old_TEMPLATE_DIRS\n\t\tSite._meta.installed = self.old_Site_meta_installed\n\n\tdef test_simple_sitemap_index(self):\n\t\t\"A simple sitemap index can be rendered\"\n\t\t# Retrieve the sitemap.\n\t\tresponse = self.client.get('/simple/index.xml')\n\t\t# Check for all the important bits:\n\t\tself.assertEqual(response.content, \"\"\"\n", "description": "\n", "category": "simple", "imports": ["import os", "from datetime import date", "from django.conf import settings", "from django.contrib.auth.models import User", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import TestCase", "from django.utils.unittest import skipUnless", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\tfrom django.contrib.flatpages.models import FlatPage", "\t\t# Check for all the important bits:"]}, {"term": "def", "name": "ftest_simple_sitemap_custom_index", "data": "\tdef test_simple_sitemap_custom_index(self):\n\t\t\"A simple sitemap index can be rendered with a custom template\"\n\t\t# Retrieve the sitemap.\n\t\tresponse = self.client.get('/simple/custom-index.xml')\n\t\t# Check for all the important bits:\n\t\tself.assertEqual(response.content, \"\"\"\n\n", "description": "\n\n", "category": "simple", "imports": ["import os", "from datetime import date", "from django.conf import settings", "from django.contrib.auth.models import User", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import TestCase", "from django.utils.unittest import skipUnless", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\tfrom django.contrib.flatpages.models import FlatPage", "\t\t# Check for all the important bits:"]}, {"term": "def", "name": "ftest_simple_sitemap", "data": "\tdef test_simple_sitemap(self):\n\t\t\"A simple sitemap can be rendered\"\n\t\t# Retrieve the sitemap.\n\t\tresponse = self.client.get('/simple/sitemap.xml')\n\t\t# Check for all the important bits:\n\t\tself.assertEqual(response.content, \"\"\"\n", "description": "\n", "category": "simple", "imports": ["import os", "from datetime import date", "from django.conf import settings", "from django.contrib.auth.models import User", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import TestCase", "from django.utils.unittest import skipUnless", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\tfrom django.contrib.flatpages.models import FlatPage", "\t\t# Check for all the important bits:"]}, {"term": "def", "name": "ftest_simple_custom_sitemap", "data": "\tdef test_simple_custom_sitemap(self):\n\t\t\"A simple sitemap can be rendered with a custom template\"\n\t\t# Retrieve the sitemap.\n\t\tresponse = self.client.get('/simple/custom-sitemap.xml')\n\t\t# Check for all the important bits:\n\t\tself.assertEqual(response.content, \"\"\"\n\n", "description": "\n\n", "category": "simple", "imports": ["import os", "from datetime import date", "from django.conf import settings", "from django.contrib.auth.models import User", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import TestCase", "from django.utils.unittest import skipUnless", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\tfrom django.contrib.flatpages.models import FlatPage", "\t\t# Check for all the important bits:"]}, {"term": "def", "name": "ftest_localized_priority", "data": "\tdef test_localized_priority(self):\n\t\t\"The priority value should not be localized (Refs #14164)\"\n\t\t# Localization should be active\n\t\tsettings.USE_L10N = True\n\t\tactivate('fr')\n\t\tself.assertEqual(u'0,3', localize(0.3))\n\n\t\t# Retrieve the sitemap. Check that priorities\n\t\t# haven't been rendered in localized format\n\t\tresponse = self.client.get('/simple/sitemap.xml')\n\t\tself.assertContains(response, '0.5')\n\t\tself.assertContains(response, '%s' % date.today().strftime('%Y-%m-%d'))\n\t\tdeactivate()\n", "description": null, "category": "simple", "imports": ["import os", "from datetime import date", "from django.conf import settings", "from django.contrib.auth.models import User", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import TestCase", "from django.utils.unittest import skipUnless", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\tfrom django.contrib.flatpages.models import FlatPage", "\t\t# Check for all the important bits:"]}, {"term": "def", "name": "ftest_generic_sitemap", "data": "\tdef test_generic_sitemap(self):\n\t\t\"A minimal generic sitemap can be rendered\"\n\t\t# Retrieve the sitemap.\n\t\tresponse = self.client.get('/generic/sitemap.xml')\n\n\t\texpected = ''\n\t\tfor username in User.objects.values_list(\"username\", flat=True):\n\t\t\texpected += \"%s/users/%s/\" % (self.base_url, username)\n\t\t# Check for all the important bits:\n\t\tself.assertEqual(response.content, \"\"\"\n", "description": "\n", "category": "simple", "imports": ["import os", "from datetime import date", "from django.conf import settings", "from django.contrib.auth.models import User", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import TestCase", "from django.utils.unittest import skipUnless", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\tfrom django.contrib.flatpages.models import FlatPage", "\t\t# Check for all the important bits:"]}, {"term": "def", "name": "ftest_flatpage_sitemap", "data": "\tdef test_flatpage_sitemap(self):\n\t\t\"Basic FlatPage sitemap test\"\n\n\t\t# Import FlatPage inside the test so that when django.contrib.flatpages\n\t\t# is not installed we don't get problems trying to delete Site\n\t\t# objects (FlatPage has an M2M to Site, Site.delete() tries to\n\t\t# delete related objects, but the M2M table doesn't exist.\n\t\tfrom django.contrib.flatpages.models import FlatPage\n\n\t\tpublic = FlatPage.objects.create(\n\t\t\turl=u'/public/',\n\t\t\ttitle=u'Public Page',\n\t\t\tenable_comments=True,\n\t\t\tregistration_required=False,\n\t\t)\n\t\tpublic.sites.add(settings.SITE_ID)\n\t\tprivate = FlatPage.objects.create(\n\t\t\turl=u'/private/',\n\t\t\ttitle=u'Private Page',\n\t\t\tenable_comments=True,\n\t\t\tregistration_required=True\n\t\t)\n\t\tprivate.sites.add(settings.SITE_ID)\n\t\tresponse = self.client.get('/flatpages/sitemap.xml')\n\t\t# Public flatpage should be in the sitemap\n\t\tself.assertContains(response, '%s%s' % (self.base_url, public.url))\n\t\t# Private flatpage should not be in the sitemap\n\t\tself.assertNotContains(response, '%s%s' % (self.base_url, private.url))\n", "description": null, "category": "simple", "imports": ["import os", "from datetime import date", "from django.conf import settings", "from django.contrib.auth.models import User", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import TestCase", "from django.utils.unittest import skipUnless", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\tfrom django.contrib.flatpages.models import FlatPage", "\t\t# Check for all the important bits:"]}, {"term": "def", "name": "ftest_requestsite_sitemap", "data": "\tdef test_requestsite_sitemap(self):\n\t\t# Make sure hitting the flatpages sitemap without the sites framework\n\t\t# installed doesn't raise an exception\n\t\tSite._meta.installed = False\n\t\t# Retrieve the sitemap.\n\t\tresponse = self.client.get('/simple/sitemap.xml')\n\t\t# Check for all the important bits:\n\t\tself.assertEqual(response.content, \"\"\"\n", "description": "\n", "category": "simple", "imports": ["import os", "from datetime import date", "from django.conf import settings", "from django.contrib.auth.models import User", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import TestCase", "from django.utils.unittest import skipUnless", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\tfrom django.contrib.flatpages.models import FlatPage", "\t\t# Check for all the important bits:"]}, {"term": "def", "name": "ftest_sitemap_get_urls_no_site_1", "data": "\tdef test_sitemap_get_urls_no_site_1(self):\n\t\t\"\"\"\n\t\tCheck we get ImproperlyConfigured if we don't pass a site object to\n\t\tSitemap.get_urls and no Site objects exist\n\t\t\"\"\"\n\t\tSite.objects.all().delete()\n\t\tself.assertRaises(ImproperlyConfigured, Sitemap().get_urls)\n", "description": "\n\t\tCheck we get ImproperlyConfigured if we don't pass a site object to\n\t\tSitemap.get_urls and no Site objects exist\n\t\t", "category": "simple", "imports": ["import os", "from datetime import date", "from django.conf import settings", "from django.contrib.auth.models import User", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import TestCase", "from django.utils.unittest import skipUnless", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\tfrom django.contrib.flatpages.models import FlatPage", "\t\t# Check for all the important bits:"]}, {"term": "def", "name": "ftest_sitemap_get_urls_no_site_2", "data": "\tdef test_sitemap_get_urls_no_site_2(self):\n\t\t\"\"\"\n\t\tCheck we get ImproperlyConfigured when we don't pass a site object to\n\t\tSitemap.get_urls if Site objects exists, but the sites framework is not\n\t\tactually installed.\n\t\t\"\"\"\n\t\tSite._meta.installed = False\n\t\tself.assertRaises(ImproperlyConfigured, Sitemap().get_urls)\n", "description": "\n\t\tCheck we get ImproperlyConfigured when we don't pass a site object to\n\t\tSitemap.get_urls if Site objects exists, but the sites framework is not\n\t\tactually installed.\n\t\t", "category": "simple", "imports": ["import os", "from datetime import date", "from django.conf import settings", "from django.contrib.auth.models import User", "from django.contrib.sitemaps import Sitemap", "from django.contrib.sites.models import Site", "from django.core.exceptions import ImproperlyConfigured", "from django.test import TestCase", "from django.utils.unittest import skipUnless", "from django.utils.formats import localize", "from django.utils.translation import activate, deactivate", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\t# Check for all the important bits:", "\t\tfrom django.contrib.flatpages.models import FlatPage", "\t\t# Check for all the important bits:"]}], [{"term": "class", "name": "TestBudgetEndToEnd", "data": "class TestBudgetEndToEnd(unittest.TestCase):\n\n\n\tdef setUp(self):\n\t\tself.testbed = testbed.Testbed()\n\t\tself.testbed.activate()\n\t\tself.testbed.init_datastore_v3_stub()\n\t\tself.testbed.init_memcache_stub()\n\n\t\tself.net_cfg = NetworkConfig(admob_pub_id='1234',\n\t\t\t\t\t\t\t\t\t adsense_pub_id='derp_derp_derp',\n\t\t\t\t\t\t\t\t\t brightroll_pub_id='lookitmeimroolllinnggsobright',\n\t\t\t\t\t\t\t\t\t chartboost_pub_id='WHREYOUATchartBOOSTMOBILE',\n\t\t\t\t\t\t\t\t\t ejam_pub_id='ejamsoundslikeinternetjelly',\n\t\t\t\t\t\t\t\t\t greystripe_pub_id='fruitstripe>>greystripe',\n\t\t\t\t\t\t\t\t\t inmobi_pub_id='indiaaaaaaaaaaaa',\n\t\t\t\t\t\t\t\t\t jumptap_pub_id='new_basketball_workout',\n\t\t\t\t\t\t\t\t\t millenial_pub_id='LOOKATMEIMAPUBLICCOMPANY',\n\t\t\t\t\t\t\t\t\t mobfox_pub_id='foxesareprettycool',\n\t\t\t\t\t\t\t\t\t rev_share=.01,\n\t\t\t\t\t\t\t\t\t price_floor=1.0,\n\t\t\t\t\t\t\t\t\t )\n\t\tself.net_cfg.put()\n\n\t\tself.acct = Account(company='BestCompany',\n\t\t\t\t\t\t\tdomain='boobs',\n\t\t\t\t\t\t\tnetwork_config=self.net_cfg,\n\t\t\t\t\t\t\tadsense_company_name='google.BestCompany',\n\t\t\t\t\t\t\tadsense_test_mode=True)\n\t\tself.acct.put()\n\n\t\tself.app = App(account=self.acct,\n\t\t\t\t\t   name='MCDERP',\n\t\t\t\t\t   global_id='earth',\n\t\t\t\t\t   adsense_app_name='google.MCDERP',\n\t\t\t\t\t   adsense_app_id='fake_id',\n\t\t\t\t\t   admob_textcolor='0x323423',\n\t\t\t\t\t   admob_bgcolor='0x1231231',\n\t\t\t\t\t   app_type='iphone',\n\t\t\t\t\t   package='derp.derp.derp',\n\t\t\t\t\t   url='www.mcderp.com',\n\t\t\t\t\t   experimental_fraction=0.01,\n\t\t\t\t\t   network_config=self.net_cfg,\n\t\t\t\t\t   primary_category=u'sports',\n\t\t\t\t\t   secondary_category=u'travel')\n\t\tself.app.put()\n\n\t\tself.au = AdUnit(name='MCDERPUNIT',\n\t\t\t\t\t\t account=self.acct,\n\t\t\t\t\t\t app_key=self.app,\n\t\t\t\t\t\t keywords='truck AND bannana',\n\t\t\t\t\t\t format='728x90',\n\t\t\t\t\t\t landscape=True,\n\t\t\t\t\t\t custom_height=728,\n\t\t\t\t\t\t custom_width=90,\n\t\t\t\t\t\t adsense_channel_id='WDERPDR',\n\t\t\t\t\t\t ad_type='image',\n\t\t\t\t\t\t refresh_interval=75,\n\t\t\t\t\t\t network_config=self.net_cfg,\n\t\t\t\t\t\t )\n\t\tself.au.put()\n\n\t\tstart= datetime.datetime(2000,1,1,1,1)\n\t\tend = datetime.datetime(2000,2,2,2,2,2)\n\n\t\tself.camp = Campaign(name='MEGACAMPAIGN',\n\t\t\t\t\t\t\t campaign_type='network',\n\t\t\t\t\t\t\t active=True,\n\t\t\t\t\t\t\t start_datetime=start,\n\t\t\t\t\t\t\t end_datetime=end,\n\t\t\t\t\t\t\t account=self.acct,\n\t\t\t\t\t\t\t full_budget=10000.,\n\t\t\t\t\t\t\t budget_type='full_campaign')\n\t\tself.camp.put()\n\n\t\tself.ag = AdGroup(name='MCADGROUP',\n\t\t\t\t\t\t  campaign=self.camp,\n\t\t\t\t\t\t  account=self.acct,\n\t\t\t\t\t\t  bid=1.0,\n\t\t\t\t\t\t  bid_strategy='cpm',\n\t\t\t\t\t\t  active=True,\n\t\t\t\t\t\t  minute_frequency_cap=3,\n\t\t\t\t\t\t  hourly_frequency_cap=5,\n\t\t\t\t\t\t  daily_frequency_cap=10,\n\t\t\t\t\t\t  weekly_frequency_cap=15,\n\t\t\t\t\t\t  monthly_frequency_cap=20,\n\t\t\t\t\t\t  lifetime_frequency_cap=1,\n\t\t\t\t\t\t  keywords=['a','b'],\n\t\t\t\t\t\t  site_keys=[self.au.key()],\n\t\t\t\t\t\t  mktplace_price_floor=10.0,\n\t\t\t\t\t\t  device_targeting=True,\n\t\t\t\t\t\t  target_iphone=True,\n\t\t\t\t\t\t  target_ipod=False,\n\t\t\t\t\t\t  target_ipad=True,\n\t\t\t\t\t\t  ios_version_max='4.0',\n\t\t\t\t\t\t  ios_version_min='3.2',\n\t\t\t\t\t\t  target_android=True,\n\t\t\t\t\t\t  android_version_max='1.5',\n\t\t\t\t\t\t  android_version_min='1.0',\n\t\t\t\t\t\t  target_other=True,\n\t\t\t\t\t\t  cities=['freeland','mexicaliwest'],\n\t\t\t\t\t\t  allocation_percentage=88.8,\n\t\t\t\t\t\t  optimizable=True,\n\t\t\t\t\t\t  default_cpm=3.6,\n\t\t\t\t\t\t  network_type='admob',\n\t\t\t\t\t\t  )\n\t\tself.ag.put()\n\n\t\tdefault_crtv_args = dict(active=True,\n\t\t\t\t\t\t\t\t name='unoriginal',\n\t\t\t\t\t\t\t\t custom_width=728,\n\t\t\t\t\t\t\t\t custom_heigt=100,\n\t\t\t\t\t\t\t\t landsacpe=True,\n\t\t\t\t\t\t\t\t ad_group=self.ag,\n\t\t\t\t\t\t\t\t ad_type='text',\n\t\t\t\t\t\t\t\t tracking_url='maps.google.com',\n\t\t\t\t\t\t\t\t url='www.lemonparty.com',\n\t\t\t\t\t\t\t\t display_url='www.www.google',\n\t\t\t\t\t\t\t\t conv_appid='mcderp',\n\t\t\t\t\t\t\t\t format='728x90',\n\t\t\t\t\t\t\t\t launchpage='www.wwwwwwwwwwwww',\n\t\t\t\t\t\t\t\t )\n\n\t\tself.crtv1 = Creative(**default_crtv_args)\n\t\tself.crtv1.put()\n\n\t\ttext_args = copy.copy(default_crtv_args)\n\t\ttext_args['headline'] = 'HEARYEHEARYE'\n\t\ttext_args['line1'] = 'NICKWINS5MILLIONDOLLARLOTTERY'\n\t\ttext_args['line2'] = 'SPENDSITALLONUGLYHOOKERS'\n\n\t\tself.crtv2 = TextCreative(**text_args)\n\t\tself.crtv2.put()\n\t\ttextandtile_args = copy.copy(default_crtv_args)\n\t\tdict2 = dict(line1='TURNSOUTUGLYHOOKERSAREACTUALLYPETERSMOM',\n\t\t\t\t\t line2='STILL,GROSSLYOVERPAID',\n\t\t\t\t\t image_url='www.ugly.jpg',\n\t\t\t\t\t action_icon='download_arrow4',\n\t\t\t\t\t color='00000',\n\t\t\t\t\t font_color='4f3fff',\n\t\t\t\t\t gradient=True,\n\t\t\t\t\t )\n\t\ttextandtile_args.update(dict2)\n\t\tself.crtv3 = TextAndTileCreative(**textandtile_args)\n\t\tself.crtv3.put()\n\n\t\tself.crtv4=HtmlCreative(html_data='LOOKITERNETS',\n\t\t\t\t\t\t\t\tormma_html=False,\n\t\t\t\t\t\t\t\t**default_crtv_args)\n\t\tself.crtv4.put()\n\t\tself.crtv5=ImageCreative(image_url='derpyderpy',\n\t\t\t\t\t\t\t\t **default_crtv_args\n\t\t\t\t\t\t\t\t )\n\t\tself.crtv5.put()\n\t\tself.crtv6 = MarketplaceCreative(**default_crtv_args)\n\t\tself.crtv6.put()\n\t\tself.crtv7 = CustomCreative(**default_crtv_args)\n\t\tself.crtv7.put()\n\t\tself.crtv8 = CustomNativeCreative(**default_crtv_args)\n\t\tself.crtv8.put()\n\t\tself.c9 = iAdCreative(**default_crtv_args)\n\t\tself.c9.put()\n\t\tself.c10 = AdSenseCreative(**default_crtv_args)\n\t\tself.c10.put()\n\t\tself.c11 = AdMobCreative(**default_crtv_args)\n\t\tself.c11.put()\n\t\tself.c12 = AdMobNativeCreative(**default_crtv_args)\n\t\tself.c12.put()\n\t\tself.c13 = MillennialCreative(**default_crtv_args)\n\t\tself.c13.put()\n\t\tself.c14 = MillennialNativeCreative(**default_crtv_args)\n\t\tself.c14.put()\n\t\tself.c15 = ChartBoostCreative(**default_crtv_args)\n\t\tself.c15.put()\n\t\tself.c16 = EjamCreative(**default_crtv_args)\n\t\tself.c16.put()\n\t\tself.c17 = InMobiCreative(**default_crtv_args)\n\t\tself.c17.put()\n\t\tself.c18 = AppNexusCreative(**default_crtv_args)\n\t\tself.c18.put()\n\t\tself.c19 = BrightRollCreative(**default_crtv_args)\n\t\tself.c19.put()\n\t\tself.c20 = JumptapCreative(**default_crtv_args)\n\t\tself.c20.put()\n\t\tself.c21 = GreyStripeCreative(**default_crtv_args)\n\t\tself.c21.put()\n\t\tself.c22 = MobFoxCreative(**default_crtv_args)\n\t\tself.c22.put()\n\n\t\tself.auc = AdUnitContext.wrap(self.au)\n\n\n\n\tdef mptest_basic_wrapping(self):\n\t\tsimple = self.auc.simplify()\n\t\tbasic = simple.to_basic_dict()\n\t\tprint simple\n\t\tprint from_basic_type(basic)\n\t\tassert from_basic_type(basic) == simple\n\n\tdef mptest_adding_random_params(self):\n\t\tfor c in self.auc.creatives:\n\t\t\tc.random_property = 'derpaderp'\n\t\t\tc.magic = 'WOOOOOO'\n\t\tsimple = self.auc.simplify()\n\t\tassert simple is not None\n\t\tfor c in simple.creatives:\n\t\t\tassert getattr(c, 'random_property', None) is None\n\t\t\tassert getattr(c, 'magic', None) is None\n\t\tfor c in self.auc.creatives:\n\t\t\tassert getattr(c, 'random_property', None) is not None\n\t\t\tassert getattr(c, 'magic', None) is not None\n\n\tdef mptest_basic_type_conversion(self):\n\t\t\"\"\" this test effectively doesn't test shit \"\"\"\n\t\tsimple_account = SimpleAccount(key = \"test account key\")\n\t\tsimple_adunit = SimpleAdUnit(\t key = \"test adunit key\",\tname = \"test adunit\",\taccount = simple_account, format = {1:2, 3:4}, app_key = simple_account) # Putting a random dict in format to test plain dict functionality.\n\t\tsimple_campaign = SimpleCampaign( key = \"test campaign key\",  name = \"test campaign\",  account = simple_account)\n\t\tsimple_adgroup = SimpleAdGroup(   key = \"test adgroup key\",   name = \"test adgroup\",   account = simple_account, campaign = simple_campaign)\n\t\tsimple_creative1 = SimpleCreative(key = \"test creative1 key\", name = \"test creative1\", account = simple_account, ad_group = simple_adgroup)\n\t\tsimple_creative2 = SimpleCreative(key = \"test creative2 key\", name = \"test creative2\", account = simple_account, ad_group = simple_adgroup)\n\t\tsimple_auc = SimpleAdUnitContext(adunit = simple_adunit,\n\t\t\t\t\t\t\t\t\t\t campaigns = [simple_campaign],\n\t\t\t\t\t\t\t\t\t\t adgroups = [simple_adgroup],\n\t\t\t\t\t\t\t\t\t\t creatives = [simple_creative1, simple_creative2])\n\n\t\tbasic_obj = simple_auc.to_basic_dict()\n\t\tnew_simple_auc = from_basic_type(basic_obj)\n\n\t\teq_(simple_auc, new_simple_auc)\n\n\tdef mptest_geo_predicates(self):\n\t\t\"\"\"\n\t\tTest that we don't let 'country=' get passed to ad_server\n\t\tbecause things break.\n\t\t\"\"\"\n\t\tself.ag.geo_predicates = ['country_name=']\n\t\tsimple_adgroup = self.ag.simplify()\n\t\teq_(simple_adgroup.geo_predicates, ['country_name=*'])\n", "description": " this test effectively doesn't test shit ", "category": "simple", "imports": ["import sys", "import os", "import datetime", "import copy", "import logging", "import common.utils.test.setup", "import unittest", "from nose.tools import eq_", "from google.appengine.ext import testbed", "logging.warning(\"trying to import campaign\")", "from advertiser.models import (Campaign,", "from publisher.models import App, AdUnit", "from account.models import Account, NetworkConfig", "from ad_server.adunit_context.adunit_context import AdUnitContext", "from simple_models import (SimpleAccount,"]}]]